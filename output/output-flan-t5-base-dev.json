[
    "mobile and edge device applications. Local differential privacy ( LDP ) ( Kasiviswanathan et al., 2011 ; Dwork et al., 2014 ) provides privacy protection on the individual level via applying randomized mechanisms that obfuscate the data before leaving the client. Local differential privacy ( LDP ) ( Kasiviswanathan et al., 2011 ; Dwork et al., 2014 ) provides privacy protection on the individual level via applying randomized mechanisms that obfuscate the data before leaving the client. Local differential privacy ( LDP ) ( Kasiviswana",
    "mobile and edge device applications. Local differential privacy ( LDP ) ( Kasiviswanathan et al., 2011 ; Dwork et al., 2014 ) provides privacy protection on the individual level via applying randomized mechanisms that obfuscate the data before leaving the client. Local differential privacy ( LDP ) ( Kasiviswanathan et al., 2011 ; Dwork et al., 2014 ) provides privacy protection on the individual level via applying randomized mechanisms that obfuscate the data before leaving the client. Local differential privacy ( LDP ) ( Kasiviswana",
    "mobile and edge device applications. Local differential privacy ( LDP ) ( Kasiviswanathan et al., 2011 ; Dwork et al., 2014 ) provides privacy protection on the individual level via applying randomized mechanisms that obfuscate the data before leaving the client. Local differential privacy ( LDP ) ( Kasiviswanathan et al., 2011 ; Dwork et al., 2014 ) provides privacy protection on the individual level via applying randomized mechanisms that obfuscate the data before leaving the client. Local differential privacy ( LDP ) ( Kasiviswana",
    "Self-attentive networks ( SANs ) have attracted increasing attention in the natural language processing community. Self-attentive networks ( SANs ) first use the positional encoding mechanism Gehring et al. ( 2017 ) to encode order dependencies in the language. The learned positional embedding is then added to corresponding word embedding to obtain an input representation, based on which SANs perform ( multi-head ) and stack ( multi-layer ) self-attentive functions ( Vaswani et al., 2017 ) in parallel to learn language representation. However, SANs gradually",
    "Self-attentive networks ( SANs ) have attracted increasing attention in the natural language processing community. Self-attentive networks ( SANs ) first use the positional encoding mechanism Gehring et al. ( 2017 ) to encode order dependencies in the language. The learned positional embedding is then added to corresponding word embedding to obtain an input representation, based on which SANs perform ( multi-head ) and stack ( multi-layer ) self-attentive functions ( Vaswani et al., 2017 ) in parallel to learn language representation. However, SANs gradually",
    "Self-attentive networks ( SANs ) have attracted increasing attention in the natural language processing community. Self-attentive networks ( SANs ) first use the positional encoding mechanism Gehring et al. ( 2017 ) to encode order dependencies in the language. The learned positional embedding is then added to corresponding word embedding to obtain an input representation, based on which SANs perform ( multi-head ) and stack ( multi-layer ) self-attentive functions ( Vaswani et al., 2017 ) in parallel to learn language representation. However, SANs gradually",
    "a single-stage normal-form formalism, the authors propose a multi-stage stochastic game.",
    "a single-stage normal-form formalism, the authors propose a multi-stage stochastic game.",
    "a single-stage normal-form formalism, the authors propose a multi-stage stochastic game.",
    "We propose a simple yet effective VAE ensemble framework consisting of multi-ple VAEs. We propose both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be triv- ial transformations, aligning the latent representations of different models to be \u201c alike \u201d.",
    "We propose a simple yet effective VAE ensemble framework consisting of multi-ple VAEs. We propose both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be triv- ial transformations, aligning the latent representations of different models to be \u201c alike \u201d.",
    "We propose a simple yet effective VAE ensemble framework consisting of multi-ple VAEs. We propose both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be triv- ial transformations, aligning the latent representations of different models to be \u201c alike \u201d.",
    "node prediction is that it predicts the pipeline for an unseen dataset.",
    "node prediction is that it predicts the pipeline for an unseen dataset.",
    "node prediction is that it predicts the pipeline for an unseen dataset.",
    "Compositionality learning is a bias toward non-compositional solutions, which violates the conditional independence property of compositionality. We propose that compositionality learning approaches are unlikely to achieve complete compositionality, and provide new research directions to equip machine learning models with such skills for human-level intelligence.",
    "Compositionality learning is a bias toward non-compositional solutions, which violates the conditional independence property of compositionality. We propose that compositionality learning approaches are unlikely to achieve complete compositionality, and provide new research directions to equip machine learning models with such skills for human-level intelligence.",
    "Compositionality learning is a bias toward non-compositional solutions, which violates the conditional independence property of compositionality. We propose that compositionality learning approaches are unlikely to achieve complete compositionality, and provide new research directions to equip machine learning models with such skills for human-level intelligence.",
    "We propose a new approach that explicitly learns KG-invariant and principled entity representations, thereby preserving the original infrastructure of existing methods.",
    "We propose a new approach that explicitly learns KG-invariant and principled entity representations, thereby preserving the original infrastructure of existing methods.",
    "We propose a new approach that explicitly learns KG-invariant and principled entity representations, thereby preserving the original infrastructure of existing methods.",
    "A generic neural architecture search would treat the camera as given, and only optimize the masks.",
    "A generic neural architecture search would treat the camera as given, and only optimize the masks.",
    "A generic neural architecture search would treat the camera as given, and only optimize the masks.",
    "There is no straightforward extension of this algorithm in temporal settings where the interaction matrices change over time.",
    "There is no straightforward extension of this algorithm in temporal settings where the interaction matrices change over time.",
    "There is no straightforward extension of this algorithm in temporal settings where the interaction matrices change over time.",
    "MRI applications.",
    "MRI applications.",
    "MRI applications.",
    "order learning ( Lim et al., 2020 )",
    "order learning ( Lim et al., 2020 )",
    "order learning ( Lim et al., 2020 )",
    "Exploration is an open challenge for deep reinforcement learning ( RL ) algorithms. Exploration methods have been investigated and demonstrated to be effective on hard-exploration environments. The key idea is to give intrinsic reward based on uncertainty, e.g., assigning higher rewards to novel states ( Ostrovski et al., 2017 ; Oudeyer & Kaplan, 2009 ; Guo et al., 2016 ; Zheng et al., 2018 ; Du et al., 2019 ). While many intrinsic reward methods have demonstrated superior performance on hard-exploration environments, most of the",
    "Exploration is an open challenge for deep reinforcement learning ( RL ) algorithms. Exploration methods have been investigated and demonstrated to be effective on hard-exploration environments. The key idea is to give intrinsic reward based on uncertainty, e.g., assigning higher rewards to novel states ( Ostrovski et al., 2017 ; Oudeyer & Kaplan, 2009 ; Guo et al., 2016 ; Zheng et al., 2018 ; Du et al., 2019 ). While many intrinsic reward methods have demonstrated superior performance on hard-exploration environments, most of the",
    "Exploration is an open challenge for deep reinforcement learning ( RL ) algorithms. Exploration methods have been investigated and demonstrated to be effective on hard-exploration environments. The key idea is to give intrinsic reward based on uncertainty, e.g., assigning higher rewards to novel states ( Ostrovski et al., 2017 ; Oudeyer & Kaplan, 2009 ; Guo et al., 2016 ; Zheng et al., 2018 ; Du et al., 2019 ). While many intrinsic reward methods have demonstrated superior performance on hard-exploration environments, most of the",
    "mapped to a category graph and propagated to a shared space for comparison between the seen classes and the unseen classes.",
    "mapped to a category graph and propagated to a shared space for comparison between the seen classes and the unseen classes.",
    "mapped to a category graph and propagated to a shared space for comparison between the seen classes and the unseen classes.",
    "HyperGrid Transformers for efficient modeling of multiple tasks within a single set of model parameters.",
    "HyperGrid Transformers for efficient modeling of multiple tasks within a single set of model parameters.",
    "HyperGrid Transformers for efficient modeling of multiple tasks within a single set of model parameters.",
    "sensitivity analysis of the learning algorithm to improve the overall performance of the task of \u201c learning to steer \u201d by analyzing the sensitivity of real-world neural network performance on the properties of simulated training images and a mechanism to leverage such a sensitivity analysis for improving learning outcomes based on quantitative analysis",
    "sensitivity analysis of the learning algorithm to improve the overall performance of the task of \u201c learning to steer \u201d by analyzing the sensitivity of real-world neural network performance on the properties of simulated training images and a mechanism to leverage such a sensitivity analysis for improving learning outcomes based on quantitative analysis",
    "sensitivity analysis of the learning algorithm to improve the overall performance of the task of \u201c learning to steer \u201d by analyzing the sensitivity of real-world neural network performance on the properties of simulated training images and a mechanism to leverage such a sensitivity analysis for improving learning outcomes based on quantitative analysis",
    "Deep Constraint Completion and Correction ( DC3 ) is a framework for incorporating hard constraints into deep learning-based optimization algorithms.",
    "Deep Constraint Completion and Correction ( DC3 ) is a framework for incorporating hard constraints into deep learning-based optimization algorithms.",
    "Deep Constraint Completion and Correction ( DC3 ) is a framework for incorporating hard constraints into deep learning-based optimization algorithms.",
    "A large penalty can push unimportant weights rather close to zero.",
    "A large penalty can push unimportant weights rather close to zero.",
    "A large penalty can push unimportant weights rather close to zero.",
    "Model-based reinforcement learning ( MBRL ) has a wide range of advantages and disadvantages, but there is a great deal of variation in the algorithms used to support it, and there is a great deal of variation in the algorithms used to support it.",
    "Model-based reinforcement learning ( MBRL ) has a wide range of advantages and disadvantages, but there is a great deal of variation in the algorithms used to support it, and there is a great deal of variation in the algorithms used to support it.",
    "Model-based reinforcement learning ( MBRL ) has a wide range of advantages and disadvantages, but there is a great deal of variation in the algorithms used to support it, and there is a great deal of variation in the algorithms used to support it.",
    "We explore implicit planning in reinforcement learning algorithms. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iter",
    "We explore implicit planning in reinforcement learning algorithms. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iter",
    "We explore implicit planning in reinforcement learning algorithms. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iteration networks. We explore implicit planning in generalized value iter",
    "We use empirical tools in addition to theory to analyze the non-convexity of neural networks in a challenging and novel setting which is not addressed in previous theoretical works.",
    "We use empirical tools in addition to theory to analyze the non-convexity of neural networks in a challenging and novel setting which is not addressed in previous theoretical works.",
    "We use empirical tools in addition to theory to analyze the non-convexity of neural networks in a challenging and novel setting which is not addressed in previous theoretical works.",
    "The first one is how can an agent effectively learn from sparse and delayed rewards. The second one is how to retrieve relevant past experiences that help to learn faster and improve sample efficiency.",
    "The first one is how can an agent effectively learn from sparse and delayed rewards. The second one is how to retrieve relevant past experiences that help to learn faster and improve sample efficiency.",
    "The first one is how can an agent effectively learn from sparse and delayed rewards. The second one is how to retrieve relevant past experiences that help to learn faster and improve sample efficiency.",
    "RL) the level generated by a procedural content generation ( PCG ) algorithm, which allows for a clean notion of train-test split and testing on held-out levels, in line with the best practices from supervised learning ( Risi & Togelius, 2020 ; 2020 ).",
    "RL) the level generated by a procedural content generation ( PCG ) algorithm, which allows for a clean notion of train-test split and testing on held-out levels, in line with the best practices from supervised learning ( Risi & Togelius, 2020 ; 2020 ).",
    "RL) the level generated by a procedural content generation ( PCG ) algorithm, which allows for a clean notion of train-test split and testing on held-out levels, in line with the best practices from supervised learning ( Risi & Togelius, 2020 ; 2020 ).",
    "Multi-Task Learning and Multi-Task Pretraining to improve generalization for a single task, the primary task, and the other tasks.",
    "Multi-Task Learning and Multi-Task Pretraining to improve generalization for a single task, the primary task, and the other tasks.",
    "Multi-Task Learning and Multi-Task Pretraining to improve generalization for a single task, the primary task, and the other tasks.",
    "fast-mapping is performed in a 3D game environment.",
    "fast-mapping is performed in a 3D game environment.",
    "fast-mapping is performed in a 3D game environment.",
    "state-of-the-art FSL methods underperform under three CI regimes ( linear, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step,",
    "state-of-the-art FSL methods underperform under three CI regimes ( linear, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step,",
    "state-of-the-art FSL methods underperform under three CI regimes ( linear, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step, step,",
    "We propose the Polynomial Graph Convolution ( PGC ) layer that independently considers neighbouring nodes.",
    "We propose the Polynomial Graph Convolution ( PGC ) layer that independently considers neighbouring nodes.",
    "We propose the Polynomial Graph Convolution ( PGC ) layer that independently considers neighbouring nodes.",
    "et al., 2018 ; Dosovitskiy et al., 2015 ; McCormac et al., 2016 ; Mueller et al., 2016 ; Richter et al., 2016 ; Suwajanakorn et al., 2018 ; Tremblay et al., 2018 ; Tsirikoglou et al., 2018 ; Tsirikoglou et al., 2018 ; Tremblay et al., 2018 ; Tsirikoglou e",
    "et al., 2018 ; Dosovitskiy et al., 2015 ; McCormac et al., 2016 ; Mueller et al., 2016 ; Richter et al., 2016 ; Suwajanakorn et al., 2018 ; Tremblay et al., 2018 ; Tsirikoglou et al., 2018 ; Tsirikoglou et al., 2018 ; Tremblay et al., 2018 ; Tsirikoglou e",
    "et al., 2018 ; Dosovitskiy et al., 2015 ; McCormac et al., 2016 ; Mueller et al., 2016 ; Richter et al., 2016 ; Suwajanakorn et al., 2018 ; Tremblay et al., 2018 ; Tsirikoglou et al., 2018 ; Tsirikoglou et al., 2018 ; Tremblay et al., 2018 ; Tsirikoglou e",
    "Randomized Ensemble Double Q Learning ( REDQ ) is a state-of-the-art model-free algorithm that achieves the performance of current state-of-the-art model-based algorithms without a model.",
    "Randomized Ensemble Double Q Learning ( REDQ ) is a state-of-the-art model-free algorithm that achieves the performance of current state-of-the-art model-based algorithms without a model.",
    "Randomized Ensemble Double Q Learning ( REDQ ) is a state-of-the-art model-free algorithm that achieves the performance of current state-of-the-art model-based algorithms without a model.",
    "On the one hand, they inherit the NN properties of universal approximation. On the other hand, they inherit the NN properties of universal approximation. On the one hand, they inherit the universal approximation properties of universal approximation. On the other hand, they inherit the universal approximation properties of universal approximation. On the one hand, they inherit the universal approximation properties of universal approximation. On the other hand, they inherit the universal approximation properties of universal approximation. On the other hand, they inherit the universal approximation properties of universal",
    "On the one hand, they inherit the NN properties of universal approximation. On the other hand, they inherit the NN properties of universal approximation. On the one hand, they inherit the universal approximation properties of universal approximation. On the other hand, they inherit the universal approximation properties of universal approximation. On the one hand, they inherit the universal approximation properties of universal approximation. On the other hand, they inherit the universal approximation properties of universal approximation. On the other hand, they inherit the universal approximation properties of universal",
    "On the one hand, they inherit the NN properties of universal approximation. On the other hand, they inherit the NN properties of universal approximation. On the one hand, they inherit the universal approximation properties of universal approximation. On the other hand, they inherit the universal approximation properties of universal approximation. On the one hand, they inherit the universal approximation properties of universal approximation. On the other hand, they inherit the universal approximation properties of universal approximation. On the other hand, they inherit the universal approximation properties of universal",
    "Graph learning is a key step of many existing machine learning and data mining applications. However, how to learn meaningful graphs from large data set at scale still remains a challenging problem.",
    "Graph learning is a key step of many existing machine learning and data mining applications. However, how to learn meaningful graphs from large data set at scale still remains a challenging problem.",
    "Graph learning is a key step of many existing machine learning and data mining applications. However, how to learn meaningful graphs from large data set at scale still remains a challenging problem.",
    "Non-parametric reward functions in original or embedding space may limit the repertoires of behaviors and impose manual training methods.",
    "Non-parametric reward functions in original or embedding space may limit the repertoires of behaviors and impose manual training methods.",
    "Non-parametric reward functions in original or embedding space may limit the repertoires of behaviors and impose manual training methods.",
    "1. Low switching cost : This is the purpose of this criterion. 2. High Reward : Since the deployed policy determines the collected samples and the agent uses fewer deployed policies, the collected data may not be informative enough to learn the optimal policy with high reward. We need this criterion to deploy policies that can collect informative samples. 3.",
    "1. Low switching cost : This is the purpose of this criterion. 2. High Reward : Since the deployed policy determines the collected samples and the agent uses fewer deployed policies, the collected data may not be informative enough to learn the optimal policy with high reward. We need this criterion to deploy policies that can collect informative samples. 3.",
    "1. Low switching cost : This is the purpose of this criterion. 2. High Reward : Since the deployed policy determines the collected samples and the agent uses fewer deployed policies, the collected data may not be informative enough to learn the optimal policy with high reward. We need this criterion to deploy policies that can collect informative samples. 3.",
    "We propose a stochastic optimization algorithm based on homotopy methods and stochastic gradient descent to solve finite-sum problems of the following form: w  arg min wRd f( w ) : = 1N N j=1 fj ( w ), ( 1 ) where f : Rd  R is continuously differentiable, bounded below and not necessarily convex. In particular, we assume that we only have access to noisy function values and gradients of the objective function in equation 1 via a stochastic first-order oracle, as in",
    "We propose a stochastic optimization algorithm based on homotopy methods and stochastic gradient descent to solve finite-sum problems of the following form: w  arg min wRd f( w ) : = 1N N j=1 fj ( w ), ( 1 ) where f : Rd  R is continuously differentiable, bounded below and not necessarily convex. In particular, we assume that we only have access to noisy function values and gradients of the objective function in equation 1 via a stochastic first-order oracle, as in",
    "We propose a stochastic optimization algorithm based on homotopy methods and stochastic gradient descent to solve finite-sum problems of the following form: w  arg min wRd f( w ) : = 1N N j=1 fj ( w ), ( 1 ) where f : Rd  R is continuously differentiable, bounded below and not necessarily convex. In particular, we assume that we only have access to noisy function values and gradients of the objective function in equation 1 via a stochastic first-order oracle, as in",
    "Bayesian meta-learning is a Bayesian meta-learning problem based on sparse sparse observations of the target task and a task-agnostic model/mechanism that can infer task-specific variables from sparse sparse observations of the target task.",
    "Bayesian meta-learning is a Bayesian meta-learning problem based on sparse sparse observations of the target task and a task-agnostic model/mechanism that can infer task-specific variables from sparse sparse observations of the target task.",
    "Bayesian meta-learning is a Bayesian meta-learning problem based on sparse sparse observations of the target task and a task-agnostic model/mechanism that can infer task-specific variables from sparse sparse observations of the target task.",
    "DNNs have been found to be vulnerable to adversarial examples ( or attacks ) ( Szegedy et al., 2014 ; Goodfellow et al., 2015 ; Szegedy et al., 2014 ; Goodfellow et al., 2015 ; Szegedy et al., 2014 ; Goodfellow et al., 2015 ; Goodfellow et al., 2015 ; Goodfellow et al., 2015 ; Goodfellow et al., 2015 ; Goodfellow et al.",
    "DNNs have been found to be vulnerable to adversarial examples ( or attacks ) ( Szegedy et al., 2014 ; Goodfellow et al., 2015 ; Szegedy et al., 2014 ; Goodfellow et al., 2015 ; Szegedy et al., 2014 ; Goodfellow et al., 2015 ; Goodfellow et al., 2015 ; Goodfellow et al., 2015 ; Goodfellow et al., 2015 ; Goodfellow et al.",
    "DNNs have been found to be vulnerable to adversarial examples ( or attacks ) ( Szegedy et al., 2014 ; Goodfellow et al., 2015 ; Szegedy et al., 2014 ; Goodfellow et al., 2015 ; Szegedy et al., 2014 ; Goodfellow et al., 2015 ; Goodfellow et al., 2015 ; Goodfellow et al., 2015 ; Goodfellow et al., 2015 ; Goodfellow et al.",
    "Is the kernel regime, which requires impractical bounds on the network width, necessary to achieve good generalization?",
    "Is the kernel regime, which requires impractical bounds on the network width, necessary to achieve good generalization?",
    "Is the kernel regime, which requires impractical bounds on the network width, necessary to achieve good generalization?",
    "Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK",
    "Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK",
    "Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK ). Over-parameterized Networks with Random Neurons ( NTK",
    "Mnih et al. ( 2013 ; 2015 ) ; Van Hasselt et al. ( 2016 ) ; Wang et al. ( 2015 ) ; Schaul et al. ( 2015 ) ; Lillicrap et al. ( 2015 ) ; Mnih et al. ( 2016 ) ; Lillicrap et al. ( 2015 ) ; Mnih et al. ( 2016 ) ; Lillicrap et al. ( 2015 ) ; Mnih et",
    "Mnih et al. ( 2013 ; 2015 ) ; Van Hasselt et al. ( 2016 ) ; Wang et al. ( 2015 ) ; Schaul et al. ( 2015 ) ; Lillicrap et al. ( 2015 ) ; Mnih et al. ( 2016 ) ; Lillicrap et al. ( 2015 ) ; Mnih et al. ( 2016 ) ; Lillicrap et al. ( 2015 ) ; Mnih et",
    "Mnih et al. ( 2013 ; 2015 ) ; Van Hasselt et al. ( 2016 ) ; Wang et al. ( 2015 ) ; Schaul et al. ( 2015 ) ; Lillicrap et al. ( 2015 ) ; Mnih et al. ( 2016 ) ; Lillicrap et al. ( 2015 ) ; Mnih et al. ( 2016 ) ; Lillicrap et al. ( 2015 ) ; Mnih et",
    "The IRL problem addresses an inverse problem that a set of expert demonstrations determines a reward function over a Markov decision process ( MDP ) if the model dynamics are known Russell ( 1998 ) ; Ng et al. ( 2000 ). The recovered reward function provides a succinct, robust, and transferable definition of the learning task and completely determines the optimal policy. However, the IRL problem is ill-posed that the policy may be optimal for many reward functions and expert demonstrations may be optimal for many policies. For example, all policies are optimal for a constant reward function. In a",
    "The IRL problem addresses an inverse problem that a set of expert demonstrations determines a reward function over a Markov decision process ( MDP ) if the model dynamics are known Russell ( 1998 ) ; Ng et al. ( 2000 ). The recovered reward function provides a succinct, robust, and transferable definition of the learning task and completely determines the optimal policy. However, the IRL problem is ill-posed that the policy may be optimal for many reward functions and expert demonstrations may be optimal for many policies. For example, all policies are optimal for a constant reward function. In a",
    "The IRL problem addresses an inverse problem that a set of expert demonstrations determines a reward function over a Markov decision process ( MDP ) if the model dynamics are known Russell ( 1998 ) ; Ng et al. ( 2000 ). The recovered reward function provides a succinct, robust, and transferable definition of the learning task and completely determines the optimal policy. However, the IRL problem is ill-posed that the policy may be optimal for many reward functions and expert demonstrations may be optimal for many policies. For example, all policies are optimal for a constant reward function. In a",
    ". Self-training is a common algorithmic paradigm for leveraging unlabeled data with deep networks.",
    ". Self-training is a common algorithmic paradigm for leveraging unlabeled data with deep networks.",
    ". Self-training is a common algorithmic paradigm for leveraging unlabeled data with deep networks.",
    "Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to",
    "Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to",
    "Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to generate future frames conditioned on a short video clip. Video prediction aims to",
    "GNN has been proved to be effective in processing graph structured data, and has been widely used in natural language processing, computer vision, data mining, social network and biochemistry. In recent years, GNN has developed a variety of architectures, such as GCN ( Kipf & Welling, 2017 ), GraphSAGE ( Hamilton et al., 2017 ), GAT ( Velikovi et al., 2018 ), DGI ( Velikovi et al., 2019 ), GIN ( Xu et al.",
    "GNN has been proved to be effective in processing graph structured data, and has been widely used in natural language processing, computer vision, data mining, social network and biochemistry. In recent years, GNN has developed a variety of architectures, such as GCN ( Kipf & Welling, 2017 ), GraphSAGE ( Hamilton et al., 2017 ), GAT ( Velikovi et al., 2018 ), DGI ( Velikovi et al., 2019 ), GIN ( Xu et al.",
    "GNN has been proved to be effective in processing graph structured data, and has been widely used in natural language processing, computer vision, data mining, social network and biochemistry. In recent years, GNN has developed a variety of architectures, such as GCN ( Kipf & Welling, 2017 ), GraphSAGE ( Hamilton et al., 2017 ), GAT ( Velikovi et al., 2018 ), DGI ( Velikovi et al., 2019 ), GIN ( Xu et al.",
    "Isomorphism Consistency Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency)",
    "Isomorphism Consistency Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency)",
    "Isomorphism Consistency Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency) Isomorphism Consistency ( Isomorphism Consistency)",
    "EXPLAINN, a novel method for describing neural networks, and a novel method for describing neural networks in general.",
    "EXPLAINN, a novel method for describing neural networks, and a novel method for describing neural networks in general.",
    "EXPLAINN, a novel method for describing neural networks, and a novel method for describing neural networks in general.",
    "Pessimism is a theoretical framework for the study of algorithms in fixed-dataset policy optimization ( FDPO ). We show why pessimistic algorithms can achieve good performance even when the dataset is not informative of every policy, and derive families of algorithms which follow the pessimism principle of exploitation.",
    "Pessimism is a theoretical framework for the study of algorithms in fixed-dataset policy optimization ( FDPO ). We show why pessimistic algorithms can achieve good performance even when the dataset is not informative of every policy, and derive families of algorithms which follow the pessimism principle of exploitation.",
    "Pessimism is a theoretical framework for the study of algorithms in fixed-dataset policy optimization ( FDPO ). We show why pessimistic algorithms can achieve good performance even when the dataset is not informative of every policy, and derive families of algorithms which follow the pessimism principle of exploitation.",
    "We propose the Memory-efficient ALF Integrator ( MALI ), which has a constant memory cost w.r.t number of solver steps in integration similar to the adjoint method, and guarantees accuracy in reverse-time trajectory ( hence accuracy in gradient estimation ). We validate MALI in various tasks : on image recognition tasks, to our knowledge, MALI is the first to enable feasible training of a Neural ODE on ImageNet and outperforms a well-tuned ResNet ; for time series modeling, MALI significantly outperforms the adjoint method ; and for continuous generative models, MALI achieves",
    "We propose the Memory-efficient ALF Integrator ( MALI ), which has a constant memory cost w.r.t number of solver steps in integration similar to the adjoint method, and guarantees accuracy in reverse-time trajectory ( hence accuracy in gradient estimation ). We validate MALI in various tasks : on image recognition tasks, to our knowledge, MALI is the first to enable feasible training of a Neural ODE on ImageNet and outperforms a well-tuned ResNet ; for time series modeling, MALI significantly outperforms the adjoint method ; and for continuous generative models, MALI achieves",
    "We propose the Memory-efficient ALF Integrator ( MALI ), which has a constant memory cost w.r.t number of solver steps in integration similar to the adjoint method, and guarantees accuracy in reverse-time trajectory ( hence accuracy in gradient estimation ). We validate MALI in various tasks : on image recognition tasks, to our knowledge, MALI is the first to enable feasible training of a Neural ODE on ImageNet and outperforms a well-tuned ResNet ; for time series modeling, MALI significantly outperforms the adjoint method ; and for continuous generative models, MALI achieves",
    "Generative Adversarial Networks ( GANs ) ( Goodfellow et al., 2014 ; Kingma & Welling, 2014 ; van den Oord et al., 2016a ; Miyato & Koyama, 2018 ; Miyato et al., 2018 ; Miyato et al., 2018 ; Brock et al., 2019 ; Miyato et al., 2018 ; Miyato et al., 2018 ; Brock et al., 2019 )",
    "Generative Adversarial Networks ( GANs ) ( Goodfellow et al., 2014 ; Kingma & Welling, 2014 ; van den Oord et al., 2016a ; Miyato & Koyama, 2018 ; Miyato et al., 2018 ; Miyato et al., 2018 ; Brock et al., 2019 ; Miyato et al., 2018 ; Miyato et al., 2018 ; Brock et al., 2019 )",
    "Generative Adversarial Networks ( GANs ) ( Goodfellow et al., 2014 ; Kingma & Welling, 2014 ; van den Oord et al., 2016a ; Miyato & Koyama, 2018 ; Miyato et al., 2018 ; Miyato et al., 2018 ; Brock et al., 2019 ; Miyato et al., 2018 ; Miyato et al., 2018 ; Brock et al., 2019 )",
    "A series of models have been developed to improve the scalability of multi-layer Graph Neural Networks ( GNNs ) by augmenting the original node features and applying a node-wise function to the augmented node features ( GA-MLPs ).",
    "A series of models have been developed to improve the scalability of multi-layer Graph Neural Networks ( GNNs ) by augmenting the original node features and applying a node-wise function to the augmented node features ( GA-MLPs ).",
    "A series of models have been developed to improve the scalability of multi-layer Graph Neural Networks ( GNNs ) by augmenting the original node features and applying a node-wise function to the augmented node features ( GA-MLPs ).",
    "Distributed onpolicy learning with a larger model capacity.",
    "Distributed onpolicy learning with a larger model capacity.",
    "Distributed onpolicy learning with a larger model capacity.",
    "Multi-domain few-shot classification is a promising direction to address the challenge of learning tasks from small data.",
    "Multi-domain few-shot classification is a promising direction to address the challenge of learning tasks from small data.",
    "Multi-domain few-shot classification is a promising direction to address the challenge of learning tasks from small data.",
    "We start by describing a problem, referred to as Unsupervised Progressive Learning ( UPL ). In the UPL problem, the agent observes a sequence ( or stream ) of unlabeled data vectors  xt  tN with xt  Rn. Each vector xt is associated with a class k ( xt ) and the vectors of class k follow a distribution Fk. The agent observes a sequence ( or stream ) of unlabeled data vectors  xt  tN with xt  Rn.",
    "We start by describing a problem, referred to as Unsupervised Progressive Learning ( UPL ). In the UPL problem, the agent observes a sequence ( or stream ) of unlabeled data vectors  xt  tN with xt  Rn. Each vector xt is associated with a class k ( xt ) and the vectors of class k follow a distribution Fk. The agent observes a sequence ( or stream ) of unlabeled data vectors  xt  tN with xt  Rn.",
    "We start by describing a problem, referred to as Unsupervised Progressive Learning ( UPL ). In the UPL problem, the agent observes a sequence ( or stream ) of unlabeled data vectors  xt  tN with xt  Rn. Each vector xt is associated with a class k ( xt ) and the vectors of class k follow a distribution Fk. The agent observes a sequence ( or stream ) of unlabeled data vectors  xt  tN with xt  Rn.",
    "Decentralized training for deep learning models is an essential training paradigm for efficient large scale training in the data-center, along with its orthogonal benefits on preserving users \u2019 privacy for edge AI ( Bellet et al., 2018 ; Kairouz et al., 2019 ; Assran et al., 2018 ; Vogels et al., 2020a ; Vogels et al., 2020a ; Assran et al., 2019 ; Assran et al., 2018 ; Assran et al., 2019 ; Assran",
    "Decentralized training for deep learning models is an essential training paradigm for efficient large scale training in the data-center, along with its orthogonal benefits on preserving users \u2019 privacy for edge AI ( Bellet et al., 2018 ; Kairouz et al., 2019 ; Assran et al., 2018 ; Vogels et al., 2020a ; Vogels et al., 2020a ; Assran et al., 2019 ; Assran et al., 2018 ; Assran et al., 2019 ; Assran",
    "Decentralized training for deep learning models is an essential training paradigm for efficient large scale training in the data-center, along with its orthogonal benefits on preserving users \u2019 privacy for edge AI ( Bellet et al., 2018 ; Kairouz et al., 2019 ; Assran et al., 2018 ; Vogels et al., 2020a ; Vogels et al., 2020a ; Assran et al., 2019 ; Assran et al., 2018 ; Assran et al., 2019 ; Assran",
    "Sequence-to-Sequence models ( Perrot & Habrard, 2015 ; Su & Wu, 2019 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thy",
    "Sequence-to-Sequence models ( Perrot & Habrard, 2015 ; Su & Wu, 2019 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thy",
    "Sequence-to-Sequence models ( Perrot & Habrard, 2015 ; Su & Wu, 2019 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thyagarajan, 2016 ; Yang & Thy",
    "synchronous data-parallel training ( Goyal et al., 2017 ; Vaswani et al., 2018 ; Devlin et al., 2018 ; Shoeybi et al., 2019 ; Huang et al., 2019 ; Kaplan et al., 2020 ; Lepikhin et al., 2020 ; Brown et al., 2020 ; Brown et al., 2020 ; Lepikhin et al., 2020 ; Lepikhin et al., 2020",
    "synchronous data-parallel training ( Goyal et al., 2017 ; Vaswani et al., 2018 ; Devlin et al., 2018 ; Shoeybi et al., 2019 ; Huang et al., 2019 ; Kaplan et al., 2020 ; Lepikhin et al., 2020 ; Brown et al., 2020 ; Brown et al., 2020 ; Lepikhin et al., 2020 ; Lepikhin et al., 2020",
    "synchronous data-parallel training ( Goyal et al., 2017 ; Vaswani et al., 2018 ; Devlin et al., 2018 ; Shoeybi et al., 2019 ; Huang et al., 2019 ; Kaplan et al., 2020 ; Lepikhin et al., 2020 ; Brown et al., 2020 ; Brown et al., 2020 ; Lepikhin et al., 2020 ; Lepikhin et al., 2020",
    "xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  x",
    "xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  x",
    "xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  xk1  x",
    "Graph Convolutional Networks ( GCNs ) are the state of the art in community detection ( Kipf & Welling, 2016 ). They correspond to Graph Neural Networks ( GNNs ) that propagate graph features through a cascade of linear operator and non-linearities, while exploiting the graph structure through a linear smoothing operator. However, the principles that allow GCNs to obtain good performances remain unclear. It is suggested in Li et al. ( 2018 ) that GCNs are eager to over-smooth their representation, which indicates they average too much neighborhood nodes and dilute",
    "Graph Convolutional Networks ( GCNs ) are the state of the art in community detection ( Kipf & Welling, 2016 ). They correspond to Graph Neural Networks ( GNNs ) that propagate graph features through a cascade of linear operator and non-linearities, while exploiting the graph structure through a linear smoothing operator. However, the principles that allow GCNs to obtain good performances remain unclear. It is suggested in Li et al. ( 2018 ) that GCNs are eager to over-smooth their representation, which indicates they average too much neighborhood nodes and dilute",
    "Graph Convolutional Networks ( GCNs ) are the state of the art in community detection ( Kipf & Welling, 2016 ). They correspond to Graph Neural Networks ( GNNs ) that propagate graph features through a cascade of linear operator and non-linearities, while exploiting the graph structure through a linear smoothing operator. However, the principles that allow GCNs to obtain good performances remain unclear. It is suggested in Li et al. ( 2018 ) that GCNs are eager to over-smooth their representation, which indicates they average too much neighborhood nodes and dilute",
    "A multi-task learning framework for semi-supervised classification where a graph structure is not readily available. We propose a multi-task learning framework in which we supplement the classification task with a self-supervised task. The task is generic and can be combined with several existing latent graph learning approaches.",
    "A multi-task learning framework for semi-supervised classification where a graph structure is not readily available. We propose a multi-task learning framework in which we supplement the classification task with a self-supervised task. The task is generic and can be combined with several existing latent graph learning approaches.",
    "A multi-task learning framework for semi-supervised classification where a graph structure is not readily available. We propose a multi-task learning framework in which we supplement the classification task with a self-supervised task. The task is generic and can be combined with several existing latent graph learning approaches.",
    "The primary challenge in the field of artificial intelligence is to mitigate catastrophic forgetting : learning new tasks while maintaining the ability to perform old ones. The primary challenge in the field of artificial intelligence remains to be a major obstacle in the field of artificial intelligence. The primary challenge is to mitigate catastrophic forgetting : learning new tasks while maintaining the ability to perform old ones. The primary challenge in the field of artificial intelligence remains to be a major obstacle in the field of artificial intelligence. The primary challenge is to mitigate catastrophic forgetting : learning new tasks while maintaining the ability to perform old ones. The primary challenge in the field of artificial intelligence remains to be a major obstacle in the field of artificial intelligence",
    "The primary challenge in the field of artificial intelligence is to mitigate catastrophic forgetting : learning new tasks while maintaining the ability to perform old ones. The primary challenge in the field of artificial intelligence remains to be a major obstacle in the field of artificial intelligence. The primary challenge is to mitigate catastrophic forgetting : learning new tasks while maintaining the ability to perform old ones. The primary challenge in the field of artificial intelligence remains to be a major obstacle in the field of artificial intelligence. The primary challenge is to mitigate catastrophic forgetting : learning new tasks while maintaining the ability to perform old ones. The primary challenge in the field of artificial intelligence remains to be a major obstacle in the field of artificial intelligence",
    "The primary challenge in the field of artificial intelligence is to mitigate catastrophic forgetting : learning new tasks while maintaining the ability to perform old ones. The primary challenge in the field of artificial intelligence remains to be a major obstacle in the field of artificial intelligence. The primary challenge is to mitigate catastrophic forgetting : learning new tasks while maintaining the ability to perform old ones. The primary challenge in the field of artificial intelligence remains to be a major obstacle in the field of artificial intelligence. The primary challenge is to mitigate catastrophic forgetting : learning new tasks while maintaining the ability to perform old ones. The primary challenge in the field of artificial intelligence remains to be a major obstacle in the field of artificial intelligence",
    "Natural language is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe",
    "Natural language is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe",
    "Natural language is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe constraints on learning. It is a natural language that can be used to describe",
    "classification tasks, few-shot learning can be used to train deep neural networks to learn previously unseen classification tasks using only a few relevant labeled examples (e.g.",
    "classification tasks, few-shot learning can be used to train deep neural networks to learn previously unseen classification tasks using only a few relevant labeled examples (e.g.",
    "classification tasks, few-shot learning can be used to train deep neural networks to learn previously unseen classification tasks using only a few relevant labeled examples (e.g.",
    "decomposing the outcome prediction to graph structures via backpropagating the gradient-like signals ( Pope et al., 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019",
    "decomposing the outcome prediction to graph structures via backpropagating the gradient-like signals ( Pope et al., 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019",
    "decomposing the outcome prediction to graph structures via backpropagating the gradient-like signals ( Pope et al., 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019 ; Baldassarre & Azizpour, 2019",
    "gap in understanding the generalization performance of highly overparameterized neural networks and their empirical generalization performance remains a fundamental mystery to the field ( Zhang et al., 2016 ; Jiang et al., 2020 ; Allen-Zhu et al., 2019 ; Zhang et al., 2016 ; Zhang et al., 2016 ; Allen-Zhu et al., 2019 ; Zhang et al., 2016 ; Zhang et al., 2016 ; Allen-Zhu et al., 2019 ; Zhang et al.",
    "gap in understanding the generalization performance of highly overparameterized neural networks and their empirical generalization performance remains a fundamental mystery to the field ( Zhang et al., 2016 ; Jiang et al., 2020 ; Allen-Zhu et al., 2019 ; Zhang et al., 2016 ; Zhang et al., 2016 ; Allen-Zhu et al., 2019 ; Zhang et al., 2016 ; Zhang et al., 2016 ; Allen-Zhu et al., 2019 ; Zhang et al.",
    "gap in understanding the generalization performance of highly overparameterized neural networks and their empirical generalization performance remains a fundamental mystery to the field ( Zhang et al., 2016 ; Jiang et al., 2020 ; Allen-Zhu et al., 2019 ; Zhang et al., 2016 ; Zhang et al., 2016 ; Allen-Zhu et al., 2019 ; Zhang et al., 2016 ; Zhang et al., 2016 ; Allen-Zhu et al., 2019 ; Zhang et al.",
    "et al., 2018 ; Watter et al., 2015 ; Anand et al., 2015 ; Ha & Schmidhuber, 2018 ; Kurutach et al., 2018 ; Hafner et al., 2019 ; Srinivas et al., 2020 ; Kurutach et al., 2018 ; Hafner et al., 2019 ; Srinivas et al., 2020 ; Watter et al., 2015 ; Anand et al., 2015",
    "et al., 2018 ; Watter et al., 2015 ; Anand et al., 2015 ; Ha & Schmidhuber, 2018 ; Kurutach et al., 2018 ; Hafner et al., 2019 ; Srinivas et al., 2020 ; Kurutach et al., 2018 ; Hafner et al., 2019 ; Srinivas et al., 2020 ; Watter et al., 2015 ; Anand et al., 2015",
    "et al., 2018 ; Watter et al., 2015 ; Anand et al., 2015 ; Ha & Schmidhuber, 2018 ; Kurutach et al., 2018 ; Hafner et al., 2019 ; Srinivas et al., 2020 ; Kurutach et al., 2018 ; Hafner et al., 2019 ; Srinivas et al., 2020 ; Watter et al., 2015 ; Anand et al., 2015",
    "pruning and factorization techniques to reduce model size while maintaining their performance.",
    "pruning and factorization techniques to reduce model size while maintaining their performance.",
    "pruning and factorization techniques to reduce model size while maintaining their performance.",
    "Binary Neural Networks ( BNNs ) by improving signal propagation without affecting the prediction of the classifier.",
    "Binary Neural Networks ( BNNs ) by improving signal propagation without affecting the prediction of the classifier.",
    "Binary Neural Networks ( BNNs ) by improving signal propagation without affecting the prediction of the classifier.",
    "Recurrent neural networks ( RNNs ) have been widely adopted in natural language processing. RNNs achieve the state-of-the-art performance by utilizing the contextual information in a \u201c memory \u201d mechanism modeled via hidden/cell states. However, the memory mechanism obstructs the interpretation of model decisions : as hidden states are carried over time steps, various pieces of information get intertwined across time steps, making RNN models a \u201c black box \u201d inherently. As will be discussed in Section 2, the attention-based approaches ( Karpathy et al., 2015 ; Strobelt et al",
    "Recurrent neural networks ( RNNs ) have been widely adopted in natural language processing. RNNs achieve the state-of-the-art performance by utilizing the contextual information in a \u201c memory \u201d mechanism modeled via hidden/cell states. However, the memory mechanism obstructs the interpretation of model decisions : as hidden states are carried over time steps, various pieces of information get intertwined across time steps, making RNN models a \u201c black box \u201d inherently. As will be discussed in Section 2, the attention-based approaches ( Karpathy et al., 2015 ; Strobelt et al",
    "Recurrent neural networks ( RNNs ) have been widely adopted in natural language processing. RNNs achieve the state-of-the-art performance by utilizing the contextual information in a \u201c memory \u201d mechanism modeled via hidden/cell states. However, the memory mechanism obstructs the interpretation of model decisions : as hidden states are carried over time steps, various pieces of information get intertwined across time steps, making RNN models a \u201c black box \u201d inherently. As will be discussed in Section 2, the attention-based approaches ( Karpathy et al., 2015 ; Strobelt et al",
    "Ayer et al., 2018 ), we propose HMRNNs - neural networks that mimic the computation of hidden Markov models while allowing for substantial modularity with other predictive networks ( Gupta et al., 2019 ; Zhou et al., 2018 ; Gupta et al., 2019 ; Zhou et al., 2018 ; Gupta et al., 2019 ; Zhou et al., 2018 ; Gupta et al., 2019 ; Zhou et al., 2018 ;",
    "Ayer et al., 2018 ), we propose HMRNNs - neural networks that mimic the computation of hidden Markov models while allowing for substantial modularity with other predictive networks ( Gupta et al., 2019 ; Zhou et al., 2018 ; Gupta et al., 2019 ; Zhou et al., 2018 ; Gupta et al., 2019 ; Zhou et al., 2018 ; Gupta et al., 2019 ; Zhou et al., 2018 ;",
    "Ayer et al., 2018 ), we propose HMRNNs - neural networks that mimic the computation of hidden Markov models while allowing for substantial modularity with other predictive networks ( Gupta et al., 2019 ; Zhou et al., 2018 ; Gupta et al., 2019 ; Zhou et al., 2018 ; Gupta et al., 2019 ; Zhou et al., 2018 ; Gupta et al., 2019 ; Zhou et al., 2018 ;",
    "We propose a supervised learning approach that factorizes gene expression data into components corresponding to individual phenotypic characteristics and their interactions. We further leverage our approach with a sparsity-based regularization algorithm, which selects a few genes important to a specific phenotypic feature or feature combination. We applied this approach to a single-cell RNA-Seq dataset of Drosophila T4/T5 neurons, focusing on their dendritic and axonal phenotypes.",
    "We propose a supervised learning approach that factorizes gene expression data into components corresponding to individual phenotypic characteristics and their interactions. We further leverage our approach with a sparsity-based regularization algorithm, which selects a few genes important to a specific phenotypic feature or feature combination. We applied this approach to a single-cell RNA-Seq dataset of Drosophila T4/T5 neurons, focusing on their dendritic and axonal phenotypes.",
    "We propose a supervised learning approach that factorizes gene expression data into components corresponding to individual phenotypic characteristics and their interactions. We further leverage our approach with a sparsity-based regularization algorithm, which selects a few genes important to a specific phenotypic feature or feature combination. We applied this approach to a single-cell RNA-Seq dataset of Drosophila T4/T5 neurons, focusing on their dendritic and axonal phenotypes.",
    "Deep Learning is that deep neural networks can be trained on unintended features and not on unintended features ( Ribeiro et al., 2016 ). The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map,",
    "Deep Learning is that deep neural networks can be trained on unintended features and not on unintended features ( Ribeiro et al., 2016 ). The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map,",
    "Deep Learning is that deep neural networks can be trained on unintended features and not on unintended features ( Ribeiro et al., 2016 ). The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map, or attribution map, is an implicit assumption shared by most of Deep Learning systems. The saliency map,",
    "The social bias of pretrained text encoders has not been adequately studied, and the fairness of pretrained text encoders has not been adequately studied.",
    "The social bias of pretrained text encoders has not been adequately studied, and the fairness of pretrained text encoders has not been adequately studied.",
    "The social bias of pretrained text encoders has not been adequately studied, and the fairness of pretrained text encoders has not been adequately studied.",
    "Cohen et al. ( 2019 ) used a randomized smoothing technique to build robust smoothed classifiers with provable l2-robustness.",
    "Cohen et al. ( 2019 ) used a randomized smoothing technique to build robust smoothed classifiers with provable l2-robustness.",
    "Cohen et al. ( 2019 ) used a randomized smoothing technique to build robust smoothed classifiers with provable l2-robustness.",
    "Tomographic auto-encoder can be used to reconstruct a clean data set without any prior knowledge of clean data or prior signal assumptions, it can be used to reconstruct a clean data set without any prior knowledge of clean data or prior signal assumptions.",
    "Tomographic auto-encoder can be used to reconstruct a clean data set without any prior knowledge of clean data or prior signal assumptions, it can be used to reconstruct a clean data set without any prior knowledge of clean data or prior signal assumptions.",
    "Tomographic auto-encoder can be used to reconstruct a clean data set without any prior knowledge of clean data or prior signal assumptions, it can be used to reconstruct a clean data set without any prior knowledge of clean data or prior signal assumptions.",
    ", 2018 ; Li et al., 2018 ; Wang et al., 2019a ; Liu et al., 2019b ; Oono & Suzuki, 2020 ) show that attention computation is limited to one-hop network neighborhoods, the one-hop attention mechanism in GATs does not perform well in practice.",
    ", 2018 ; Li et al., 2018 ; Wang et al., 2019a ; Liu et al., 2019b ; Oono & Suzuki, 2020 ) show that attention computation is limited to one-hop network neighborhoods, the one-hop attention mechanism in GATs does not perform well in practice.",
    ", 2018 ; Li et al., 2018 ; Wang et al., 2019a ; Liu et al., 2019b ; Oono & Suzuki, 2020 ) show that attention computation is limited to one-hop network neighborhoods, the one-hop attention mechanism in GATs does not perform well in practice.",
    "We design the benchmark to measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the benchmark more challenging and more similar to how we evaluate humans.",
    "We design the benchmark to measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the benchmark more challenging and more similar to how we evaluate humans.",
    "We design the benchmark to measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the benchmark more challenging and more similar to how we evaluate humans.",
    "natural language interface. We hypothesize that current pre-trained language models are not sufficient for cross-domain semantic parsing tasks. First, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a natural language interface. Second, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a natural language interface. Third, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a natural language interface. Fourth, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus",
    "natural language interface. We hypothesize that current pre-trained language models are not sufficient for cross-domain semantic parsing tasks. First, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a natural language interface. Second, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a natural language interface. Third, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a natural language interface. Fourth, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus",
    "natural language interface. We hypothesize that current pre-trained language models are not sufficient for cross-domain semantic parsing tasks. First, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a natural language interface. Second, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a natural language interface. Third, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a natural language interface. Fourth, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus",
    "MTL LS-SVM MTL) to the prediction of student test results for a collection of schools ( Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin,",
    "MTL LS-SVM MTL) to the prediction of student test results for a collection of schools ( Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin,",
    "MTL LS-SVM MTL) to the prediction of student test results for a collection of schools ( Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin, Aitkin,",
    "symmetries in deep neural networks.",
    "symmetries in deep neural networks.",
    "symmetries in deep neural networks.",
    "We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximize",
    "We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximize",
    "We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximizes the expected reward over trajectories induced by the policy ( model ) model. We propose an autoregressive model for text generation that maximize",
    "Gradient Checkpointing Technique ( GCT ) or the reversible architecture design ( reversible architecture design ) ( Hinton et al., 2006 ; Bengio et al., 2007 ; Nkland & Eidnes, 2019 ; Belilovsky et al., 2019 ; 2020 ; Hinton et al., 2006 ; Bengio et al., 2007 ; Nkland & Eidnes, 2019 ; Belilovsky et al., 2019 ; 2020 ; Hinton et al., 2006",
    "Gradient Checkpointing Technique ( GCT ) or the reversible architecture design ( reversible architecture design ) ( Hinton et al., 2006 ; Bengio et al., 2007 ; Nkland & Eidnes, 2019 ; Belilovsky et al., 2019 ; 2020 ; Hinton et al., 2006 ; Bengio et al., 2007 ; Nkland & Eidnes, 2019 ; Belilovsky et al., 2019 ; 2020 ; Hinton et al., 2006",
    "Gradient Checkpointing Technique ( GCT ) or the reversible architecture design ( reversible architecture design ) ( Hinton et al., 2006 ; Bengio et al., 2007 ; Nkland & Eidnes, 2019 ; Belilovsky et al., 2019 ; 2020 ; Hinton et al., 2006 ; Bengio et al., 2007 ; Nkland & Eidnes, 2019 ; Belilovsky et al., 2019 ; 2020 ; Hinton et al., 2006",
    ", 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a",
    ", 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a",
    ", 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a, 2018a",
    "Aydemir et al., 2018 ; Dziugaite et al., 2016 ; Das et al., 2018 ; Dziugaite et al., 2018 ; Das et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et",
    "Aydemir et al., 2018 ; Dziugaite et al., 2016 ; Das et al., 2018 ; Dziugaite et al., 2018 ; Das et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et",
    "Aydemir et al., 2018 ; Dziugaite et al., 2016 ; Das et al., 2018 ; Dziugaite et al., 2018 ; Das et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et al., 2018 ; Dziugaite et",
    "Node and graph embeddings have been established as standard feature representations in many learning tasks ( Cai et al., 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara",
    "Node and graph embeddings have been established as standard feature representations in many learning tasks ( Cai et al., 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara",
    "Node and graph embeddings have been established as standard feature representations in many learning tasks ( Cai et al., 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara, 2018 ; Goyal & Ferrara",
    "a large corpus of unlabeled mathematical expressions ( HOList ).",
    "a large corpus of unlabeled mathematical expressions ( HOList ).",
    "a large corpus of unlabeled mathematical expressions ( HOList ).",
    "Imbalanced gradients can cause robustness to be overestimated even when there are no obfuscated gradients.",
    "Imbalanced gradients can cause robustness to be overestimated even when there are no obfuscated gradients.",
    "Imbalanced gradients can cause robustness to be overestimated even when there are no obfuscated gradients.",
    "graph-to-sequence deep learning system to generate axiomatic proofs of equivalence between program pairs.",
    "graph-to-sequence deep learning system to generate axiomatic proofs of equivalence between program pairs.",
    "graph-to-sequence deep learning system to generate axiomatic proofs of equivalence between program pairs.",
    "Transformers ( Vaswani et al., 2017 ; Howard & Ruder, 2018 ; Peters et al., 2018 ; Radford et al., 2018 ; Devlin et al., 2019 ; Devlin et al., 2019 ; Liu et al., 2019 ; Yang et al., 2019 ).",
    "Transformers ( Vaswani et al., 2017 ; Howard & Ruder, 2018 ; Peters et al., 2018 ; Radford et al., 2018 ; Devlin et al., 2019 ; Devlin et al., 2019 ; Liu et al., 2019 ; Yang et al., 2019 ).",
    "Transformers ( Vaswani et al., 2017 ; Howard & Ruder, 2018 ; Peters et al., 2018 ; Radford et al., 2018 ; Devlin et al., 2019 ; Devlin et al., 2019 ; Liu et al., 2019 ; Yang et al., 2019 ).",
    "We propose a novel paradigm, online contextualized few-shot learning, that approximates the naturalistic conditions that humans and artificial agents encounter as they wander within a physical environment, and we develop deep-learning architectures well suited for this purpose.",
    "We propose a novel paradigm, online contextualized few-shot learning, that approximates the naturalistic conditions that humans and artificial agents encounter as they wander within a physical environment, and we develop deep-learning architectures well suited for this purpose.",
    "We propose a novel paradigm, online contextualized few-shot learning, that approximates the naturalistic conditions that humans and artificial agents encounter as they wander within a physical environment, and we develop deep-learning architectures well suited for this purpose.",
    "Temporal graphs have become a hot topic. Recent works include combining GNNs with recurrent modules ( Seo et al., 2018 ; Manessi et al., 2020 ; Sankar et al., 2020 ; Pareja et al., 2020 ; Pareja et al., 2020 ) and vertex embeddings as a function of time to cope with continuous-time temporal graphs ( da Xu et al., 2020 ; Rossi et al., 2020 ; Pareja et al.,",
    "Temporal graphs have become a hot topic. Recent works include combining GNNs with recurrent modules ( Seo et al., 2018 ; Manessi et al., 2020 ; Sankar et al., 2020 ; Pareja et al., 2020 ; Pareja et al., 2020 ) and vertex embeddings as a function of time to cope with continuous-time temporal graphs ( da Xu et al., 2020 ; Rossi et al., 2020 ; Pareja et al.,",
    "Temporal graphs have become a hot topic. Recent works include combining GNNs with recurrent modules ( Seo et al., 2018 ; Manessi et al., 2020 ; Sankar et al., 2020 ; Pareja et al., 2020 ; Pareja et al., 2020 ) and vertex embeddings as a function of time to cope with continuous-time temporal graphs ( da Xu et al., 2020 ; Rossi et al., 2020 ; Pareja et al.,",
    "state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information,",
    "state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information,",
    "state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information, modifying the input image might lose critical state information,",
    "1 ) select a small set of nodes to be perturbed 1 ) select a small set of nodes to be perturbed 2 ) select a small set of nodes to be perturbed 3 ) select a small set of nodes to be perturbed 4 ) select a small set of nodes to be perturbed 5 ) select a small set of nodes to be perturbed 6 ) select a small set of nodes to be perturbed 7 ) select a small set of nodes to be perturbed 8 ) select a small set of nodes to be perturbed 9 ) select",
    "1 ) select a small set of nodes to be perturbed 1 ) select a small set of nodes to be perturbed 2 ) select a small set of nodes to be perturbed 3 ) select a small set of nodes to be perturbed 4 ) select a small set of nodes to be perturbed 5 ) select a small set of nodes to be perturbed 6 ) select a small set of nodes to be perturbed 7 ) select a small set of nodes to be perturbed 8 ) select a small set of nodes to be perturbed 9 ) select",
    "1 ) select a small set of nodes to be perturbed 1 ) select a small set of nodes to be perturbed 2 ) select a small set of nodes to be perturbed 3 ) select a small set of nodes to be perturbed 4 ) select a small set of nodes to be perturbed 5 ) select a small set of nodes to be perturbed 6 ) select a small set of nodes to be perturbed 7 ) select a small set of nodes to be perturbed 8 ) select a small set of nodes to be perturbed 9 ) select",
    "Constraint- and score-based methods for causal structure learning with non-linear data have been developed in recent years.",
    "Constraint- and score-based methods for causal structure learning with non-linear data have been developed in recent years.",
    "Constraint- and score-based methods for causal structure learning with non-linear data have been developed in recent years.",
    "Automated data augmentation and joint optimization of NAS and HPO for a specific task were able to achieve a full-pipeline \u201c from data to model \u201d automation without human involvement.",
    "Automated data augmentation and joint optimization of NAS and HPO for a specific task were able to achieve a full-pipeline \u201c from data to model \u201d automation without human involvement.",
    "Automated data augmentation and joint optimization of NAS and HPO for a specific task were able to achieve a full-pipeline \u201c from data to model \u201d automation without human involvement.",
    "Prior Networks ( Malinin & Gales, 2018 ; 2019 ; Malinin & Gales, 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018",
    "Prior Networks ( Malinin & Gales, 2018 ; 2019 ; Malinin & Gales, 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018",
    "Prior Networks ( Malinin & Gales, 2018 ; 2019 ; Malinin & Gales, 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018",
    "Bayesian online meta-learning framework to overcome catastrophic forgetting and the sequential few-shot tasks problems.",
    "Bayesian online meta-learning framework to overcome catastrophic forgetting and the sequential few-shot tasks problems.",
    "Bayesian online meta-learning framework to overcome catastrophic forgetting and the sequential few-shot tasks problems.",
    "GNNs can use to learn graph representations, but their expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has",
    "GNNs can use to learn graph representations, but their expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has",
    "GNNs can use to learn graph representations, but their expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has been shown to be limited by the limited expressive power of MPNNs, and their limited expressive power has",
    "Evolutionary Game Theory ( EGT ) provides a dynamicalsystemic perspective to understand ML processes, which has already provided new insights into a number of ML-related problems. We characterize general normal games where popular learning algorithms exhibit chaotic behaviors. Lyapunov chaos captures the butterfly effect : when the starting point of a dynamical system is slightly perturbed, the resulting trajectories and final outcomes diverge quickly ; see Definition 1 for a formal definition. We characterize general normal games where popular learning algorithms exhibit chaotic behaviors. Lyapunov chaos captures the butterfly effect : when the starting point of a dynamical system",
    "Evolutionary Game Theory ( EGT ) provides a dynamicalsystemic perspective to understand ML processes, which has already provided new insights into a number of ML-related problems. We characterize general normal games where popular learning algorithms exhibit chaotic behaviors. Lyapunov chaos captures the butterfly effect : when the starting point of a dynamical system is slightly perturbed, the resulting trajectories and final outcomes diverge quickly ; see Definition 1 for a formal definition. We characterize general normal games where popular learning algorithms exhibit chaotic behaviors. Lyapunov chaos captures the butterfly effect : when the starting point of a dynamical system",
    "Evolutionary Game Theory ( EGT ) provides a dynamicalsystemic perspective to understand ML processes, which has already provided new insights into a number of ML-related problems. We characterize general normal games where popular learning algorithms exhibit chaotic behaviors. Lyapunov chaos captures the butterfly effect : when the starting point of a dynamical system is slightly perturbed, the resulting trajectories and final outcomes diverge quickly ; see Definition 1 for a formal definition. We characterize general normal games where popular learning algorithms exhibit chaotic behaviors. Lyapunov chaos captures the butterfly effect : when the starting point of a dynamical system",
    "performance of AdaGrad when the gradients were sparse, especially in high dimensional problems such as deep learning ( Reddi et al., 2018 ).",
    "performance of AdaGrad when the gradients were sparse, especially in high dimensional problems such as deep learning ( Reddi et al., 2018 ).",
    "performance of AdaGrad when the gradients were sparse, especially in high dimensional problems such as deep learning ( Reddi et al., 2018 ).",
    "high computational costs, Xie et al. proposed a method based on the Legendre-Fenchel duality ( Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004",
    "high computational costs, Xie et al. proposed a method based on the Legendre-Fenchel duality ( Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004",
    "high computational costs, Xie et al. proposed a method based on the Legendre-Fenchel duality ( Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004 ; Boyd & Vandenberghe, 2004",
    "Training with auxiliary tasks can improve the performance of deep neural networks. Training with auxiliary tasks increases the inductive bias that pushes learned models to capture meaningful representations and avoid overfitting to spurious correlations. In some domains, it is not clear what would be the best way to combine all auxiliary tasks into a single loss ( Doersch and Zisserman, 2017 ; Noroozi and Favaro, 2016 ; Doersch and Zisserman, 2017 ; Noroozi and Favaro, 2016 ; Doersch and Zisserman, 2017 ; Noroozi and Favaro, 2016",
    "Training with auxiliary tasks can improve the performance of deep neural networks. Training with auxiliary tasks increases the inductive bias that pushes learned models to capture meaningful representations and avoid overfitting to spurious correlations. In some domains, it is not clear what would be the best way to combine all auxiliary tasks into a single loss ( Doersch and Zisserman, 2017 ; Noroozi and Favaro, 2016 ; Doersch and Zisserman, 2017 ; Noroozi and Favaro, 2016 ; Doersch and Zisserman, 2017 ; Noroozi and Favaro, 2016",
    "Training with auxiliary tasks can improve the performance of deep neural networks. Training with auxiliary tasks increases the inductive bias that pushes learned models to capture meaningful representations and avoid overfitting to spurious correlations. In some domains, it is not clear what would be the best way to combine all auxiliary tasks into a single loss ( Doersch and Zisserman, 2017 ; Noroozi and Favaro, 2016 ; Doersch and Zisserman, 2017 ; Noroozi and Favaro, 2016 ; Doersch and Zisserman, 2017 ; Noroozi and Favaro, 2016",
    "Statistical Machine Translation ( SMT, ( Brown et al., 1993 ; Och, 2003 ) ), built on top of probabilistic modelling foundations such as the IBM alignment models ( Vogel et al., 1996 ; Brown et al., 1993 ; Och, 2003 ), has largely been replaced in recent years following the emergence of Neural Machine Translation approaches ( NMT, ( Kalchbrenner & Blunsom, 2013 ; Bahdanau et al., 2015 ; Luong et al., 2015 ; Vaswani e",
    "Statistical Machine Translation ( SMT, ( Brown et al., 1993 ; Och, 2003 ) ), built on top of probabilistic modelling foundations such as the IBM alignment models ( Vogel et al., 1996 ; Brown et al., 1993 ; Och, 2003 ), has largely been replaced in recent years following the emergence of Neural Machine Translation approaches ( NMT, ( Kalchbrenner & Blunsom, 2013 ; Bahdanau et al., 2015 ; Luong et al., 2015 ; Vaswani e",
    "Statistical Machine Translation ( SMT, ( Brown et al., 1993 ; Och, 2003 ) ), built on top of probabilistic modelling foundations such as the IBM alignment models ( Vogel et al., 1996 ; Brown et al., 1993 ; Och, 2003 ), has largely been replaced in recent years following the emergence of Neural Machine Translation approaches ( NMT, ( Kalchbrenner & Blunsom, 2013 ; Bahdanau et al., 2015 ; Luong et al., 2015 ; Vaswani e",
    "plethora of evidence that pruning early in training without affecting final accuracy may be feasible.",
    "plethora of evidence that pruning early in training without affecting final accuracy may be feasible.",
    "plethora of evidence that pruning early in training without affecting final accuracy may be feasible.",
    "Byzantine-robust FL protocols are designed to reduce the impact of the contaminated updates and output a mean estimation as accurate as possible.",
    "Byzantine-robust FL protocols are designed to reduce the impact of the contaminated updates and output a mean estimation as accurate as possible.",
    "Byzantine-robust FL protocols are designed to reduce the impact of the contaminated updates and output a mean estimation as accurate as possible.",
    "Online black-box optimization has been studied extensively, but the offline MBO problem has received comparatively less attention, due to the fact that these methods are proposed and evaluated on different tasks with distinct evaluation protocols.",
    "Online black-box optimization has been studied extensively, but the offline MBO problem has received comparatively less attention, due to the fact that these methods are proposed and evaluated on different tasks with distinct evaluation protocols.",
    "Online black-box optimization has been studied extensively, but the offline MBO problem has received comparatively less attention, due to the fact that these methods are proposed and evaluated on different tasks with distinct evaluation protocols.",
    "Multimodal generative models need to be adaptable to multiple data types in a self-supervised fashion. Multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across modalities. Multimodal generative models need to be adaptable to multiple data types in a self-supervised fashion. Multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across modalities. Multimodal generative models need to be adaptable to multiple data types in a self-supervised fashion. Multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across",
    "Multimodal generative models need to be adaptable to multiple data types in a self-supervised fashion. Multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across modalities. Multimodal generative models need to be adaptable to multiple data types in a self-supervised fashion. Multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across modalities. Multimodal generative models need to be adaptable to multiple data types in a self-supervised fashion. Multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across",
    "Multimodal generative models need to be adaptable to multiple data types in a self-supervised fashion. Multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across modalities. Multimodal generative models need to be adaptable to multiple data types in a self-supervised fashion. Multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across modalities. Multimodal generative models need to be adaptable to multiple data types in a self-supervised fashion. Multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across",
    "Bayesian Optimization ( ABO ) have used it in the past, but it has not been widely used in the present, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past",
    "Bayesian Optimization ( ABO ) have used it in the past, but it has not been widely used in the present, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past",
    "Bayesian Optimization ( ABO ) have used it in the past, but it has not been widely used in the present, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past, and has not been widely used in the past",
    "Binary weights and activations require significantly less memory, and also admit faster low-level implementations of key operations such as linear transformations than when using the usual floating-point precision.",
    "Binary weights and activations require significantly less memory, and also admit faster low-level implementations of key operations such as linear transformations than when using the usual floating-point precision.",
    "Binary weights and activations require significantly less memory, and also admit faster low-level implementations of key operations such as linear transformations than when using the usual floating-point precision.",
    "Djolonga et al., 2020 ; Taori et al., 2020 ; Hendrycks et al., 2020 ; Hendrycks & Dietterich, 2019 ) ).",
    "Djolonga et al., 2020 ; Taori et al., 2020 ; Hendrycks et al., 2020 ; Hendrycks & Dietterich, 2019 ) ).",
    "Djolonga et al., 2020 ; Taori et al., 2020 ; Hendrycks et al., 2020 ; Hendrycks & Dietterich, 2019 ) ).",
    "Convex neural networks with ReLU activations can be trained with equivalent finite dimensional convex regularizers.",
    "Convex neural networks with ReLU activations can be trained with equivalent finite dimensional convex regularizers.",
    "Convex neural networks with ReLU activations can be trained with equivalent finite dimensional convex regularizers.",
    "kinaesthetic teaching and supervised learning ( LfD ) ), which requires a mapping from the high-level notions humans use\u2014e.g. spatial concepts, different ways of applying force\u2014to the low-level perceptive and control signals robot agents utilise\u2014e.g. joint angles, efforts and camera images. With this in place, any constraints or elaborations from the human operator must be mapped to behaviour on the agent \u2019 s side that is consistent with the semantics of the operator \u2019 s desires.",
    "kinaesthetic teaching and supervised learning ( LfD ) ), which requires a mapping from the high-level notions humans use\u2014e.g. spatial concepts, different ways of applying force\u2014to the low-level perceptive and control signals robot agents utilise\u2014e.g. joint angles, efforts and camera images. With this in place, any constraints or elaborations from the human operator must be mapped to behaviour on the agent \u2019 s side that is consistent with the semantics of the operator \u2019 s desires.",
    "kinaesthetic teaching and supervised learning ( LfD ) ), which requires a mapping from the high-level notions humans use\u2014e.g. spatial concepts, different ways of applying force\u2014to the low-level perceptive and control signals robot agents utilise\u2014e.g. joint angles, efforts and camera images. With this in place, any constraints or elaborations from the human operator must be mapped to behaviour on the agent \u2019 s side that is consistent with the semantics of the operator \u2019 s desires.",
    "z is irrelevant to the target task. We propose a method that uses the Variational Information Bottleneck ( VIB ) principle to improve transfer learning in low-resource scenarios based on the Information Bottleneck ( IB ) principle ( Tishby et al., 1999 ; Alemi et al., 2017 ) to address the problem of overfitting on statistically spurious correlations between the irrelevant information and target labels.",
    "z is irrelevant to the target task. We propose a method that uses the Variational Information Bottleneck ( VIB ) principle to improve transfer learning in low-resource scenarios based on the Information Bottleneck ( IB ) principle ( Tishby et al., 1999 ; Alemi et al., 2017 ) to address the problem of overfitting on statistically spurious correlations between the irrelevant information and target labels.",
    "z is irrelevant to the target task. We propose a method that uses the Variational Information Bottleneck ( VIB ) principle to improve transfer learning in low-resource scenarios based on the Information Bottleneck ( IB ) principle ( Tishby et al., 1999 ; Alemi et al., 2017 ) to address the problem of overfitting on statistically spurious correlations between the irrelevant information and target labels.",
    "GANs are capable of modeling the 2D natural image manifold of diverse object categories with high fidelity. This phenomenon motivates us to ask - \u201c Is it possible to reconstruct the 3D shape of a single 2D image by exploiting the 3D-alike image manipulation effects produced by GANs? \u201d Despite its potential to serve as a powerful method to learn 3D shape from unconstrained RGB images, this problem remains much less explored. Some previous attempts ( Lunz et al., 2020 ; Henzler et al., 2019 ; Szab\u00f3 et al., 2019",
    "GANs are capable of modeling the 2D natural image manifold of diverse object categories with high fidelity. This phenomenon motivates us to ask - \u201c Is it possible to reconstruct the 3D shape of a single 2D image by exploiting the 3D-alike image manipulation effects produced by GANs? \u201d Despite its potential to serve as a powerful method to learn 3D shape from unconstrained RGB images, this problem remains much less explored. Some previous attempts ( Lunz et al., 2020 ; Henzler et al., 2019 ; Szab\u00f3 et al., 2019",
    "GANs are capable of modeling the 2D natural image manifold of diverse object categories with high fidelity. This phenomenon motivates us to ask - \u201c Is it possible to reconstruct the 3D shape of a single 2D image by exploiting the 3D-alike image manipulation effects produced by GANs? \u201d Despite its potential to serve as a powerful method to learn 3D shape from unconstrained RGB images, this problem remains much less explored. Some previous attempts ( Lunz et al., 2020 ; Henzler et al., 2019 ; Szab\u00f3 et al., 2019",
    "data groups, which gives more importance to tail instances ( Cao et al., 2019 ; Kang et al., 2020 ; Liu et al., 2019 ), 2 ) ensembling over different data groups, which gives more importance to tail instances ( Cao et al., 2019 ; Kang et al., 2020 ; Liu et al., 2019 ), 2 ) ensembling over different data groups, which gives more importance to tail instances ( Cao et al., 2019 ; Kang et",
    "data groups, which gives more importance to tail instances ( Cao et al., 2019 ; Kang et al., 2020 ; Liu et al., 2019 ), 2 ) ensembling over different data groups, which gives more importance to tail instances ( Cao et al., 2019 ; Kang et al., 2020 ; Liu et al., 2019 ), 2 ) ensembling over different data groups, which gives more importance to tail instances ( Cao et al., 2019 ; Kang et",
    "data groups, which gives more importance to tail instances ( Cao et al., 2019 ; Kang et al., 2020 ; Liu et al., 2019 ), 2 ) ensembling over different data groups, which gives more importance to tail instances ( Cao et al., 2019 ; Kang et al., 2020 ; Liu et al., 2019 ), 2 ) ensembling over different data groups, which gives more importance to tail instances ( Cao et al., 2019 ; Kang et",
    "Pruning [ 1, 2, 3, 4 ] a trained neural network is commonly seen in network compression. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refer",
    "Pruning [ 1, 2, 3, 4 ] a trained neural network is commonly seen in network compression. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refer",
    "Pruning [ 1, 2, 3, 4 ] a trained neural network is commonly seen in network compression. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refers to the pruning of the filters in the convolutional layers. In particular, for CNNs, channel pruning refer",
    "GraphCodeBERT is a pre-trained model for programming language that considers the inherent structure of code.",
    "GraphCodeBERT is a pre-trained model for programming language that considers the inherent structure of code.",
    "GraphCodeBERT is a pre-trained model for programming language that considers the inherent structure of code.",
    "We propose a new approach to improve the accuracy of a regression model that is trained on skewed data. We assume the presence of enough unlabeled data which follow the true distribution, and that the true distribution can be roughly estimated using domain knowledge or a few examples. We use a semi-supervised learning approach to improve the accuracy of a regression model that is trained on skewed data.",
    "We propose a new approach to improve the accuracy of a regression model that is trained on skewed data. We assume the presence of enough unlabeled data which follow the true distribution, and that the true distribution can be roughly estimated using domain knowledge or a few examples. We use a semi-supervised learning approach to improve the accuracy of a regression model that is trained on skewed data.",
    "We propose a new approach to improve the accuracy of a regression model that is trained on skewed data. We assume the presence of enough unlabeled data which follow the true distribution, and that the true distribution can be roughly estimated using domain knowledge or a few examples. We use a semi-supervised learning approach to improve the accuracy of a regression model that is trained on skewed data.",
    "Compositional generalization is a type of out-of-distribution generalization where the training and test distributions are different. Compositional generalization is enabled by recombining the seen components of the unseen combination during inference. The main approach for compositional generalization is to learn compositional representations ( Bengio, 2013 ), which contain several component representations. Each of them depends only on the underlying generative factor, and does not change when other factors change. We find that the extraction ability does not transfer naturally, because the extraction network suffers from the divergence of distributions ( Bengio, 2017 ; Pleis",
    "Compositional generalization is a type of out-of-distribution generalization where the training and test distributions are different. Compositional generalization is enabled by recombining the seen components of the unseen combination during inference. The main approach for compositional generalization is to learn compositional representations ( Bengio, 2013 ), which contain several component representations. Each of them depends only on the underlying generative factor, and does not change when other factors change. We find that the extraction ability does not transfer naturally, because the extraction network suffers from the divergence of distributions ( Bengio, 2017 ; Pleis",
    "Compositional generalization is a type of out-of-distribution generalization where the training and test distributions are different. Compositional generalization is enabled by recombining the seen components of the unseen combination during inference. The main approach for compositional generalization is to learn compositional representations ( Bengio, 2013 ), which contain several component representations. Each of them depends only on the underlying generative factor, and does not change when other factors change. We find that the extraction ability does not transfer naturally, because the extraction network suffers from the divergence of distributions ( Bengio, 2017 ; Pleis",
    "Poisoning in online RL is more difficult than poisoning in classic supervised learning ( SL ). Poisoning approaches in SL usually require the access to the entire training dataset.",
    "Poisoning in online RL is more difficult than poisoning in classic supervised learning ( SL ). Poisoning approaches in SL usually require the access to the entire training dataset.",
    "Poisoning in online RL is more difficult than poisoning in classic supervised learning ( SL ). Poisoning approaches in SL usually require the access to the entire training dataset.",
    "Dynamic Tensor Rematerialization ( DTR ) is a greedy online algorithm for heuristically checkpointing arbitrary deep learning models.",
    "Dynamic Tensor Rematerialization ( DTR ) is a greedy online algorithm for heuristically checkpointing arbitrary deep learning models.",
    "Dynamic Tensor Rematerialization ( DTR ) is a greedy online algorithm for heuristically checkpointing arbitrary deep learning models.",
    ", 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Tian et al., 2019 ) have shown that the faithfulness of machine outputs in conditional sequence generation tasks does not correlate well with the faithfulness of model outputs ( Maynez et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang e",
    ", 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Tian et al., 2019 ) have shown that the faithfulness of machine outputs in conditional sequence generation tasks does not correlate well with the faithfulness of model outputs ( Maynez et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang e",
    ", 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Tian et al., 2019 ) have shown that the faithfulness of machine outputs in conditional sequence generation tasks does not correlate well with the faithfulness of model outputs ( Maynez et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang et al., 2020 ; Wang e",
    "class-aware generators ) we propose a neural architecture search ( NAS ) algorithm on top of reinforcement learning so that the generator architecture of each class is automatically designed.",
    "class-aware generators ) we propose a neural architecture search ( NAS ) algorithm on top of reinforcement learning so that the generator architecture of each class is automatically designed.",
    "class-aware generators ) we propose a neural architecture search ( NAS ) algorithm on top of reinforcement learning so that the generator architecture of each class is automatically designed.",
    "We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal",
    "We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal",
    "We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal effect of a treatment from observational data. We estimate the average causal",
    "affine parameters used to transform features in BatchNorm ( Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy,",
    "affine parameters used to transform features in BatchNorm ( Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy,",
    "affine parameters used to transform features in BatchNorm ( Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy, 2015 ; Ioffe & Szegedy,",
    "error ( Figure 1 ). Entropy is related to error, as more confident predictions are all-in-all more correct ( Figure 1 ). Entropy is related to shifts due to corruption, as more corruption results in more error ( Figure 1 ). Entropy is related to error, as more confidence predictions are all-in-all more correct ( Figure 1 ). Entropy is related to error, as more confidence predictions are all-in-all more correct ( Figure 1 ). Entropy is related to shifts due to corruption, as more corruption results in more error ( Figure 1 ). Entropy",
    "error ( Figure 1 ). Entropy is related to error, as more confident predictions are all-in-all more correct ( Figure 1 ). Entropy is related to shifts due to corruption, as more corruption results in more error ( Figure 1 ). Entropy is related to error, as more confidence predictions are all-in-all more correct ( Figure 1 ). Entropy is related to error, as more confidence predictions are all-in-all more correct ( Figure 1 ). Entropy is related to shifts due to corruption, as more corruption results in more error ( Figure 1 ). Entropy",
    "error ( Figure 1 ). Entropy is related to error, as more confident predictions are all-in-all more correct ( Figure 1 ). Entropy is related to shifts due to corruption, as more corruption results in more error ( Figure 1 ). Entropy is related to error, as more confidence predictions are all-in-all more correct ( Figure 1 ). Entropy is related to error, as more confidence predictions are all-in-all more correct ( Figure 1 ). Entropy is related to shifts due to corruption, as more corruption results in more error ( Figure 1 ). Entropy",
    "We propose an orthogonal approach to quantify uncertainty in recurrent neural networks ( RNNs ). We use the Gumbel softmax trick ( Gumbel, 1954 ; Kendall, 1954 ; Gumbel, 1954 ; Kendall, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954",
    "We propose an orthogonal approach to quantify uncertainty in recurrent neural networks ( RNNs ). We use the Gumbel softmax trick ( Gumbel, 1954 ; Kendall, 1954 ; Gumbel, 1954 ; Kendall, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954",
    "We propose an orthogonal approach to quantify uncertainty in recurrent neural networks ( RNNs ). We use the Gumbel softmax trick ( Gumbel, 1954 ; Kendall, 1954 ; Gumbel, 1954 ; Kendall, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954 ; Gumbel, 1954",
    "differential privacy ( DP ) ( Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al.,",
    "differential privacy ( DP ) ( Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al.,",
    "differential privacy ( DP ) ( Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al., 2006 ; Dwork et al.,",
    "PoWER-BERT ( Goyal et al., 2020 ) which progressively reduces sequence length by eliminating word-vectors based on the attention values as passing layers.",
    "PoWER-BERT ( Goyal et al., 2020 ) which progressively reduces sequence length by eliminating word-vectors based on the attention values as passing layers.",
    "PoWER-BERT ( Goyal et al., 2020 ) which progressively reduces sequence length by eliminating word-vectors based on the attention values as passing layers.",
    "The WL test is used to measure the expressiveness of GNNs, especially on large graphs with complex topologies. The expressiveness analysis measured by the WL test assumes that aggregators are injective, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable",
    "The WL test is used to measure the expressiveness of GNNs, especially on large graphs with complex topologies. The expressiveness analysis measured by the WL test assumes that aggregators are injective, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable",
    "The WL test is used to measure the expressiveness of GNNs, especially on large graphs with complex topologies. The expressiveness analysis measured by the WL test assumes that aggregators are injective, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable, which is usually unreachable",
    ", 2018b ; Glorot et al., 2011 ; Grathwohl and Wilson, 2016 ; Karaletsos et al., 2015 ; Duan et al., 2015 ; Duan et al., 2020 ) ).",
    ", 2018b ; Glorot et al., 2011 ; Grathwohl and Wilson, 2016 ; Karaletsos et al., 2015 ; Duan et al., 2015 ; Duan et al., 2020 ) ).",
    ", 2018b ; Glorot et al., 2011 ; Grathwohl and Wilson, 2016 ; Karaletsos et al., 2015 ; Duan et al., 2015 ; Duan et al., 2020 ) ).",
    "We introduce unlearnable examples, which aim at making training examples unusable for Deep Neural Networks ( DNNs ). This paper aims at making training examples unusable by introducing unlearnable examples, which aims at making training examples unusable for Deep Neural Networks ( DNNs ). This paper aims at making training examples unusable by introducing unlearnable examples, which aims at making training examples unusable for Deep Neural Networks ( DNNs ). This paper aims at making training examples unusable by introducing unlearnable examples, which",
    "We introduce unlearnable examples, which aim at making training examples unusable for Deep Neural Networks ( DNNs ). This paper aims at making training examples unusable by introducing unlearnable examples, which aims at making training examples unusable for Deep Neural Networks ( DNNs ). This paper aims at making training examples unusable by introducing unlearnable examples, which aims at making training examples unusable for Deep Neural Networks ( DNNs ). This paper aims at making training examples unusable by introducing unlearnable examples, which",
    "We introduce unlearnable examples, which aim at making training examples unusable for Deep Neural Networks ( DNNs ). This paper aims at making training examples unusable by introducing unlearnable examples, which aims at making training examples unusable for Deep Neural Networks ( DNNs ). This paper aims at making training examples unusable by introducing unlearnable examples, which aims at making training examples unusable for Deep Neural Networks ( DNNs ). This paper aims at making training examples unusable by introducing unlearnable examples, which",
    "Monte Carlo Tree Search for perfect information games with chance events. NDMZ is an extension of MuZero to stochastic, two-player, zero-sum games of perfect information. We formalize the element of chance as a player in the game, determine a policy for the chance player via interaction with the environment, and augment the tree search to allow for chance actions. With the assumption of perfect information, we change the MuZero architecture to allow agents to learn two additional quantities : the player identity policy and the chance player policy. With the assumption of perfect information, we change the MuZero architecture to allow agents to learn two additional quantities :",
    "Monte Carlo Tree Search for perfect information games with chance events. NDMZ is an extension of MuZero to stochastic, two-player, zero-sum games of perfect information. We formalize the element of chance as a player in the game, determine a policy for the chance player via interaction with the environment, and augment the tree search to allow for chance actions. With the assumption of perfect information, we change the MuZero architecture to allow agents to learn two additional quantities : the player identity policy and the chance player policy. With the assumption of perfect information, we change the MuZero architecture to allow agents to learn two additional quantities :",
    "Monte Carlo Tree Search for perfect information games with chance events. NDMZ is an extension of MuZero to stochastic, two-player, zero-sum games of perfect information. We formalize the element of chance as a player in the game, determine a policy for the chance player via interaction with the environment, and augment the tree search to allow for chance actions. With the assumption of perfect information, we change the MuZero architecture to allow agents to learn two additional quantities : the player identity policy and the chance player policy. With the assumption of perfect information, we change the MuZero architecture to allow agents to learn two additional quantities :",
    "data-efficient, robust off-policy learning methods to achieve data-efficient, robust off-policy learning of options.",
    "data-efficient, robust off-policy learning methods to achieve data-efficient, robust off-policy learning of options.",
    "data-efficient, robust off-policy learning methods to achieve data-efficient, robust off-policy learning of options.",
    "The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an",
    "The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an",
    "The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an episode. The aim of this paper is to optimize for only the maximum reward achieved in an",
    "Adaptation of a deep learning model to accurately predict the new feature values in the low data regime is computationally costly, and may fall victim to severe over-fitting if there are only a small number of observations available for the new feature.",
    "Adaptation of a deep learning model to accurately predict the new feature values in the low data regime is computationally costly, and may fall victim to severe over-fitting if there are only a small number of observations available for the new feature.",
    "Adaptation of a deep learning model to accurately predict the new feature values in the low data regime is computationally costly, and may fall victim to severe over-fitting if there are only a small number of observations available for the new feature.",
    "Bayesian modeling ( Ghahramani, 2015 ; Gal, 2016 ; Osawa et al., 2019 ; Maddox et al., 2019 ; Foong et al., 2019 ; Foong et al., 2019 ; Ashukha et al., 2020a ) is intractable in DNNs.",
    "Bayesian modeling ( Ghahramani, 2015 ; Gal, 2016 ; Osawa et al., 2019 ; Maddox et al., 2019 ; Foong et al., 2019 ; Foong et al., 2019 ; Ashukha et al., 2020a ) is intractable in DNNs.",
    "Bayesian modeling ( Ghahramani, 2015 ; Gal, 2016 ; Osawa et al., 2019 ; Maddox et al., 2019 ; Foong et al., 2019 ; Foong et al., 2019 ; Ashukha et al., 2020a ) is intractable in DNNs.",
    "We propose to jointly learn embeddings for states and actions in the presence of large state-action spaces, aiming to improve the applicability of RL to real-world domains.",
    "We propose to jointly learn embeddings for states and actions in the presence of large state-action spaces, aiming to improve the applicability of RL to real-world domains.",
    "We propose to jointly learn embeddings for states and actions in the presence of large state-action spaces, aiming to improve the applicability of RL to real-world domains.",
    "We propose a general method for learning diverse and useful views for contrastive learning.",
    "We propose a general method for learning diverse and useful views for contrastive learning.",
    "We propose a general method for learning diverse and useful views for contrastive learning.",
    "Out-of-distribution ( OODs ) in deep neural networks",
    "Out-of-distribution ( OODs ) in deep neural networks",
    "Out-of-distribution ( OODs ) in deep neural networks",
    "et al., 2013 ), we propose a hierarchical VAE that generates samples quickly and outperforms the PixelCNN ( Van den Oord et al., 2014 ; Rezende et al., 2014 ; Dinh et al., 2014 ; 2016 ) in log-likelihood on all natural image benchmarks.",
    "et al., 2013 ), we propose a hierarchical VAE that generates samples quickly and outperforms the PixelCNN ( Van den Oord et al., 2014 ; Rezende et al., 2014 ; Dinh et al., 2014 ; 2016 ) in log-likelihood on all natural image benchmarks.",
    "et al., 2013 ), we propose a hierarchical VAE that generates samples quickly and outperforms the PixelCNN ( Van den Oord et al., 2014 ; Rezende et al., 2014 ; Dinh et al., 2014 ; 2016 ) in log-likelihood on all natural image benchmarks.",
    "amplify the encoding quality of the image.",
    "amplify the encoding quality of the image.",
    "amplify the encoding quality of the image.",
    "..........................................................................",
    "..........................................................................",
    "..........................................................................",
    "We propose DYnamic multi-Agent Relational Inference ( DYARI ) model, a deep generative model that can reason about dynamic relations. We perform comprehensive study on the trade-off between dynamic and inference period, the impact of training scheme, and model architecture on dynamic relational inference accuracy. We also showcase an application of our model to infer coordination and competition patterns from real-world multi-agent basketball trajectories.",
    "We propose DYnamic multi-Agent Relational Inference ( DYARI ) model, a deep generative model that can reason about dynamic relations. We perform comprehensive study on the trade-off between dynamic and inference period, the impact of training scheme, and model architecture on dynamic relational inference accuracy. We also showcase an application of our model to infer coordination and competition patterns from real-world multi-agent basketball trajectories.",
    "We propose DYnamic multi-Agent Relational Inference ( DYARI ) model, a deep generative model that can reason about dynamic relations. We perform comprehensive study on the trade-off between dynamic and inference period, the impact of training scheme, and model architecture on dynamic relational inference accuracy. We also showcase an application of our model to infer coordination and competition patterns from real-world multi-agent basketball trajectories.",
    "Matrix Factorization ( Matrix Factorization ). Matrix Factorization ( Matrix Factorization ) is a method based on collaborative filtering ( CF ) or, interchangeably, matrix factorization ( MF ), which has shown great power in this problem by factorizing the rating matrix into two classes of latent factors ( i.e., embeddings ) for users and items respectively, and further leverage dot-product of two factors to predict potential ratings ( Koren et al., 2009 ; Rendle et al., 2009 ; Srebro",
    "Matrix Factorization ( Matrix Factorization ). Matrix Factorization ( Matrix Factorization ) is a method based on collaborative filtering ( CF ) or, interchangeably, matrix factorization ( MF ), which has shown great power in this problem by factorizing the rating matrix into two classes of latent factors ( i.e., embeddings ) for users and items respectively, and further leverage dot-product of two factors to predict potential ratings ( Koren et al., 2009 ; Rendle et al., 2009 ; Srebro",
    "Matrix Factorization ( Matrix Factorization ). Matrix Factorization ( Matrix Factorization ) is a method based on collaborative filtering ( CF ) or, interchangeably, matrix factorization ( MF ), which has shown great power in this problem by factorizing the rating matrix into two classes of latent factors ( i.e., embeddings ) for users and items respectively, and further leverage dot-product of two factors to predict potential ratings ( Koren et al., 2009 ; Rendle et al., 2009 ; Srebro",
    "K  D. We propose a novel multi-stage modelling approach where the disentangled factors are first learned using a preexisting disentangled representation learning method ( such as -TCVAE ) ; then, the low-quality reconstruction is improved with another deep generative model that is trained to model the missing correlated latent variables, adding detail information while maintaining conditioning on the previously learned disentangled factors. We demonstrate that our multi-stage modelling approach has much higher reconstruction quality than current state-of-the-art methods with equivalent disentanglement performance across multiple standard benchmarks.",
    "K  D. We propose a novel multi-stage modelling approach where the disentangled factors are first learned using a preexisting disentangled representation learning method ( such as -TCVAE ) ; then, the low-quality reconstruction is improved with another deep generative model that is trained to model the missing correlated latent variables, adding detail information while maintaining conditioning on the previously learned disentangled factors. We demonstrate that our multi-stage modelling approach has much higher reconstruction quality than current state-of-the-art methods with equivalent disentanglement performance across multiple standard benchmarks.",
    "K  D. We propose a novel multi-stage modelling approach where the disentangled factors are first learned using a preexisting disentangled representation learning method ( such as -TCVAE ) ; then, the low-quality reconstruction is improved with another deep generative model that is trained to model the missing correlated latent variables, adding detail information while maintaining conditioning on the previously learned disentangled factors. We demonstrate that our multi-stage modelling approach has much higher reconstruction quality than current state-of-the-art methods with equivalent disentanglement performance across multiple standard benchmarks.",
    "Maximizing mutual information between random variables yields sufficient representations for the general class of MDPs, and we show that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is",
    "Maximizing mutual information between random variables yields sufficient representations for the general class of MDPs, and we show that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is",
    "Maximizing mutual information between random variables yields sufficient representations for the general class of MDPs, and we show that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is sufficient for the general class of MDPs, and that this objective is",
    "Arora et al., 2018 ), which focuses on the optimality of finite-width neural networks based on a convex semi-infinite strong dual and a convex program with infinitely many constraints.",
    "Arora et al., 2018 ), which focuses on the optimality of finite-width neural networks based on a convex semi-infinite strong dual and a convex program with infinitely many constraints.",
    "Arora et al., 2018 ), which focuses on the optimality of finite-width neural networks based on a convex semi-infinite strong dual and a convex program with infinitely many constraints.",
    "Language-Mediated Object-centred Representation Learning ( LORL ) with language-based object-centric representation learning.",
    "Language-Mediated Object-centred Representation Learning ( LORL ) with language-based object-centric representation learning.",
    "Language-Mediated Object-centred Representation Learning ( LORL ) with language-based object-centric representation learning.",
    "Knowledge graph completion aims to predict the missing links among the knowledge graph ( KG ), i.e., predicting the possibility that a certain triple belongs to the knowledge graph. Most mainstream embedding methods focus on fact triplets contained in the given KG, however, ignoring the rich background information provided by logic rules driven from knowledge base implicitly. Limited to the modeling of algebraic space, contradictory in expressing certain relational patterns usually exists in the embedding models. Therefore, the representation of the knowledge graph is incomplete and inaccurate. To solve this problem, we propose a general framework, named EM-R",
    "Knowledge graph completion aims to predict the missing links among the knowledge graph ( KG ), i.e., predicting the possibility that a certain triple belongs to the knowledge graph. Most mainstream embedding methods focus on fact triplets contained in the given KG, however, ignoring the rich background information provided by logic rules driven from knowledge base implicitly. Limited to the modeling of algebraic space, contradictory in expressing certain relational patterns usually exists in the embedding models. Therefore, the representation of the knowledge graph is incomplete and inaccurate. To solve this problem, we propose a general framework, named EM-R",
    "Knowledge graph completion aims to predict the missing links among the knowledge graph ( KG ), i.e., predicting the possibility that a certain triple belongs to the knowledge graph. Most mainstream embedding methods focus on fact triplets contained in the given KG, however, ignoring the rich background information provided by logic rules driven from knowledge base implicitly. Limited to the modeling of algebraic space, contradictory in expressing certain relational patterns usually exists in the embedding models. Therefore, the representation of the knowledge graph is incomplete and inaccurate. To solve this problem, we propose a general framework, named EM-R",
    "Frame A X B X C X D X E X Left Frame A X B X C X D X E X Right Frame A X B X C X D X E X Left Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X",
    "Frame A X B X C X D X E X Left Frame A X B X C X D X E X Right Frame A X B X C X D X E X Left Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X",
    "Frame A X B X C X D X E X Left Frame A X B X C X D X E X Right Frame A X B X C X D X E X Left Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X E X Right Frame A X B X C X D X",
    "visual cues from a video-grounded dialogue, which is a video-grounded language task.",
    "visual cues from a video-grounded dialogue, which is a video-grounded language task.",
    "visual cues from a video-grounded dialogue, which is a video-grounded language task.",
    "A meta-strategy solver ( MSS ) is a meta-strategy solver that extracts a meta-strategy profile from an empirical game. A meta-strategy solver is a meta-strategy solver that extracts a meta-strategy profile from an empirical game. A meta-strategy solver is a meta-strategy solver that extracts a meta-strategy profile from an empirical game. A meta-strategy solver is a meta-strategy solve",
    "A meta-strategy solver ( MSS ) is a meta-strategy solver that extracts a meta-strategy profile from an empirical game. A meta-strategy solver is a meta-strategy solver that extracts a meta-strategy profile from an empirical game. A meta-strategy solver is a meta-strategy solver that extracts a meta-strategy profile from an empirical game. A meta-strategy solver is a meta-strategy solve",
    "A meta-strategy solver ( MSS ) is a meta-strategy solver that extracts a meta-strategy profile from an empirical game. A meta-strategy solver is a meta-strategy solver that extracts a meta-strategy profile from an empirical game. A meta-strategy solver is a meta-strategy solver that extracts a meta-strategy profile from an empirical game. A meta-strategy solver is a meta-strategy solve",
    "Non-Attentive Tacotron based on the Tacotron 2 text-to-speech model. This paper proposes a method to train the duration predictor in a semi-supervised or unsupervised manner, with results almost as good as supervised training.",
    "Non-Attentive Tacotron based on the Tacotron 2 text-to-speech model. This paper proposes a method to train the duration predictor in a semi-supervised or unsupervised manner, with results almost as good as supervised training.",
    "Non-Attentive Tacotron based on the Tacotron 2 text-to-speech model. This paper proposes a method to train the duration predictor in a semi-supervised or unsupervised manner, with results almost as good as supervised training.",
    "3D to 2D BEV projection and occluded areas. Explicit depth estimation is not necessary for good BEV layout estimation.",
    "3D to 2D BEV projection and occluded areas. Explicit depth estimation is not necessary for good BEV layout estimation.",
    "3D to 2D BEV projection and occluded areas. Explicit depth estimation is not necessary for good BEV layout estimation.",
    "Li et al., 2019a ; 2020 ; Rahimi et al., 2018 ), skip connections can be used to improve the training of deep GNNs by avoiding vanishing gradients towards lower-layer representations of the same node, and reduces over-smoothing ( Hamilton, 2020 ; Hochreiter & Schmidhuber, 1997 ; Pascanu et al., 2013 ; He et al., 2016 ) problems in GNNs ( Li et al., 2019a ; 2020 ; Rahimi et al.,",
    "Li et al., 2019a ; 2020 ; Rahimi et al., 2018 ), skip connections can be used to improve the training of deep GNNs by avoiding vanishing gradients towards lower-layer representations of the same node, and reduces over-smoothing ( Hamilton, 2020 ; Hochreiter & Schmidhuber, 1997 ; Pascanu et al., 2013 ; He et al., 2016 ) problems in GNNs ( Li et al., 2019a ; 2020 ; Rahimi et al.,",
    "Li et al., 2019a ; 2020 ; Rahimi et al., 2018 ), skip connections can be used to improve the training of deep GNNs by avoiding vanishing gradients towards lower-layer representations of the same node, and reduces over-smoothing ( Hamilton, 2020 ; Hochreiter & Schmidhuber, 1997 ; Pascanu et al., 2013 ; He et al., 2016 ) problems in GNNs ( Li et al., 2019a ; 2020 ; Rahimi et al.,",
    "SMT solvers for explaining neural network decisions, we propose a gradient-based approach to the problem of scalability of SMT solvers by using gradient information to solve the problem of identifying a minimal set of features in a given input that is critical to a model \u2019 s prediction.",
    "SMT solvers for explaining neural network decisions, we propose a gradient-based approach to the problem of scalability of SMT solvers by using gradient information to solve the problem of identifying a minimal set of features in a given input that is critical to a model \u2019 s prediction.",
    "SMT solvers for explaining neural network decisions, we propose a gradient-based approach to the problem of scalability of SMT solvers by using gradient information to solve the problem of identifying a minimal set of features in a given input that is critical to a model \u2019 s prediction.",
    "Our experiment shows that current 3D pose estimation approaches are not robust to partial occlusion and when objects are viewed from a previously unseen pose.",
    "Our experiment shows that current 3D pose estimation approaches are not robust to partial occlusion and when objects are viewed from a previously unseen pose.",
    "Our experiment shows that current 3D pose estimation approaches are not robust to partial occlusion and when objects are viewed from a previously unseen pose.",
    "a cost-effective way to improve the quality of the search results. We propose a unified framework for feature compatible learning, and extend it to handle the case where the old model is a black-box. We propose a simple pseudo classifier in lieu of the old model, and further enhance it with a random walk algorithm. As a result, the embedding features produced by the new model can be matched with those from the old model without sacrificing performance. Experiments on ImageNet ILSVRC 2012 and Places365 data proved the efficacy of the proposed approach. We propose a unified framework for feature compatible learning without inheriting",
    "a cost-effective way to improve the quality of the search results. We propose a unified framework for feature compatible learning, and extend it to handle the case where the old model is a black-box. We propose a simple pseudo classifier in lieu of the old model, and further enhance it with a random walk algorithm. As a result, the embedding features produced by the new model can be matched with those from the old model without sacrificing performance. Experiments on ImageNet ILSVRC 2012 and Places365 data proved the efficacy of the proposed approach. We propose a unified framework for feature compatible learning without inheriting",
    "a cost-effective way to improve the quality of the search results. We propose a unified framework for feature compatible learning, and extend it to handle the case where the old model is a black-box. We propose a simple pseudo classifier in lieu of the old model, and further enhance it with a random walk algorithm. As a result, the embedding features produced by the new model can be matched with those from the old model without sacrificing performance. Experiments on ImageNet ILSVRC 2012 and Places365 data proved the efficacy of the proposed approach. We propose a unified framework for feature compatible learning without inheriting",
    "Generalization performance of deep learning through stochastic gradient descent-based optimization has been widely studied in recent work ( Li et al., 2020 ; Negrea et al., 2019 ; Thomas et al., 2019 ; Zhu et al., 2019 ; Hu et al., 2019 ; Hu et al., 2019 ; Zhang et al., 2016 ; Mou et al., 2017 ). This work studies the use of generalization performance measures ( Li et al., 2020 ; Negrea et al., 2019",
    "Generalization performance of deep learning through stochastic gradient descent-based optimization has been widely studied in recent work ( Li et al., 2020 ; Negrea et al., 2019 ; Thomas et al., 2019 ; Zhu et al., 2019 ; Hu et al., 2019 ; Hu et al., 2019 ; Zhang et al., 2016 ; Mou et al., 2017 ). This work studies the use of generalization performance measures ( Li et al., 2020 ; Negrea et al., 2019",
    "Generalization performance of deep learning through stochastic gradient descent-based optimization has been widely studied in recent work ( Li et al., 2020 ; Negrea et al., 2019 ; Thomas et al., 2019 ; Zhu et al., 2019 ; Hu et al., 2019 ; Hu et al., 2019 ; Zhang et al., 2016 ; Mou et al., 2017 ). This work studies the use of generalization performance measures ( Li et al., 2020 ; Negrea et al., 2019",
    "Bi-encoders ), which can be used to retrieve information from a large number of KBs ( e.g., Wikipedia articles ) by using a bi-encoder ( Wu et al., 2020 ; Karpukhin et al., 2020 ; Karpukhin et al., 2020 ; Wu et al., 2020 ; Karpukhin et al., 2020 ; Wu et al., 2020 ; Karpukhin et al., 2020 ; Karpukhin et al., 2020",
    "Bi-encoders ), which can be used to retrieve information from a large number of KBs ( e.g., Wikipedia articles ) by using a bi-encoder ( Wu et al., 2020 ; Karpukhin et al., 2020 ; Karpukhin et al., 2020 ; Wu et al., 2020 ; Karpukhin et al., 2020 ; Wu et al., 2020 ; Karpukhin et al., 2020 ; Karpukhin et al., 2020",
    "Bi-encoders ), which can be used to retrieve information from a large number of KBs ( e.g., Wikipedia articles ) by using a bi-encoder ( Wu et al., 2020 ; Karpukhin et al., 2020 ; Karpukhin et al., 2020 ; Wu et al., 2020 ; Karpukhin et al., 2020 ; Wu et al., 2020 ; Karpukhin et al., 2020 ; Karpukhin et al., 2020",
    "route if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to travers",
    "route if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to travers",
    "route if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to traverse the edge, or if they are unable to travers",
    "We propose PMI-Masking, a principled masking strategy based on the concept of Pointwise Mutual Information ( PMI ), which jointly masks a token n-gram if it exhibits high collocation over the corpus. We show experimentally that PMI-Masking reaches the performance of prior masking approaches in half the training time, and consistently improves performance at the end of training.",
    "We propose PMI-Masking, a principled masking strategy based on the concept of Pointwise Mutual Information ( PMI ), which jointly masks a token n-gram if it exhibits high collocation over the corpus. We show experimentally that PMI-Masking reaches the performance of prior masking approaches in half the training time, and consistently improves performance at the end of training.",
    "We propose PMI-Masking, a principled masking strategy based on the concept of Pointwise Mutual Information ( PMI ), which jointly masks a token n-gram if it exhibits high collocation over the corpus. We show experimentally that PMI-Masking reaches the performance of prior masking approaches in half the training time, and consistently improves performance at the end of training.",
    "The gap between the ELBO and the log marginal likelihood is the KL divergence from the approximate posterior to the true posterior.",
    "The gap between the ELBO and the log marginal likelihood is the KL divergence from the approximate posterior to the true posterior.",
    "The gap between the ELBO and the log marginal likelihood is the KL divergence from the approximate posterior to the true posterior.",
    "KRR with divide-and-conquer ( Zhang et al., 2013 ; 2015 ; Chang et al., 2017b ; a ; Guo et al., 2017 ; Lin et al., 2017 ; Li et al., 2019b ; d ;",
    "KRR with divide-and-conquer ( Zhang et al., 2013 ; 2015 ; Chang et al., 2017b ; a ; Guo et al., 2017 ; Lin et al., 2017 ; Li et al., 2019b ; d ;",
    "KRR with divide-and-conquer ( Zhang et al., 2013 ; 2015 ; Chang et al., 2017b ; a ; Guo et al., 2017 ; Lin et al., 2017 ; Li et al., 2019b ; d ;",
    "RandomNAS are able to select the architectures based on their performance ranking on the validation dataset, which is called weight-sharing performance, based on their weight-sharing performance, which is called weight-sharing performance.",
    "RandomNAS are able to select the architectures based on their performance ranking on the validation dataset, which is called weight-sharing performance, based on their weight-sharing performance, which is called weight-sharing performance.",
    "RandomNAS are able to select the architectures based on their performance ranking on the validation dataset, which is called weight-sharing performance, based on their weight-sharing performance, which is called weight-sharing performance.",
    "a new task using a meta-training dataset and a state representation based on the agent \u2019 s internal sensors, such as position encoders of a robot arm, and through interaction we implicitly recover the state of the external environment, such as the poses of objects which the robot is interacting with.",
    "a new task using a meta-training dataset and a state representation based on the agent \u2019 s internal sensors, such as position encoders of a robot arm, and through interaction we implicitly recover the state of the external environment, such as the poses of objects which the robot is interacting with.",
    "a new task using a meta-training dataset and a state representation based on the agent \u2019 s internal sensors, such as position encoders of a robot arm, and through interaction we implicitly recover the state of the external environment, such as the poses of objects which the robot is interacting with.",
    "the images are orthogonal and the classification is binary. We propose a novel generalization bound which is independent of the number of channels and is a low-degree polynomial of the filter dimension, which is usually low in practice.",
    "the images are orthogonal and the classification is binary. We propose a novel generalization bound which is independent of the number of channels and is a low-degree polynomial of the filter dimension, which is usually low in practice.",
    "the images are orthogonal and the classification is binary. We propose a novel generalization bound which is independent of the number of channels and is a low-degree polynomial of the filter dimension, which is usually low in practice.",
    "Contrastive learning is an approach to representation learning that utilizes naturally occurring similar and dissimilar pairs of data points to find useful embeddings of data. We apply this procedure in a semi-supervised setup and demonstrate empirically that linear classifiers with these representations perform well in document classification tasks with very few training examples.",
    "Contrastive learning is an approach to representation learning that utilizes naturally occurring similar and dissimilar pairs of data points to find useful embeddings of data. We apply this procedure in a semi-supervised setup and demonstrate empirically that linear classifiers with these representations perform well in document classification tasks with very few training examples.",
    "Contrastive learning is an approach to representation learning that utilizes naturally occurring similar and dissimilar pairs of data points to find useful embeddings of data. We apply this procedure in a semi-supervised setup and demonstrate empirically that linear classifiers with these representations perform well in document classification tasks with very few training examples.",
    "multimodal model, which relies on random pairing between modalities. We propose that a distinction between the \u201crelated \u201d and \u201cunrelated \u201d observations within a multimodal dataset could greatly reduce the amount of related data required for effective multimodal learning ( Figure 2a ).",
    "multimodal model, which relies on random pairing between modalities. We propose that a distinction between the \u201crelated \u201d and \u201cunrelated \u201d observations within a multimodal dataset could greatly reduce the amount of related data required for effective multimodal learning ( Figure 2a ).",
    "multimodal model, which relies on random pairing between modalities. We propose that a distinction between the \u201crelated \u201d and \u201cunrelated \u201d observations within a multimodal dataset could greatly reduce the amount of related data required for effective multimodal learning ( Figure 2a ).",
    "VAEs ), and reweighting factors ( z ) ). q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z )",
    "VAEs ), and reweighting factors ( z ) ). q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z )",
    "VAEs ), and reweighting factors ( z ) ). q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z ) q ( z ) p ( z ) r ( z )",
    "Inverse Reinforcement Learning ( IRL ) is more pragmatic than regularized Markov decision processes ( MDPs ).",
    "Inverse Reinforcement Learning ( IRL ) is more pragmatic than regularized Markov decision processes ( MDPs ).",
    "Inverse Reinforcement Learning ( IRL ) is more pragmatic than regularized Markov decision processes ( MDPs ).",
    "Multilingual Machine Translation ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT )",
    "Multilingual Machine Translation ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT )",
    "Multilingual Machine Translation ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT ), where the learning objective is commonly cast as a multi-task learning problem ( MNMT )",
    "We propose a novel Wasserstein distributional normalization algorithm to handle noisy labels for accurate classification. We split our data into uncertain and certain samples based on small loss criteria. We investigate the geometric relationship between these two different types of samples and enhance this relation to exploit useful information, even from uncertain samples. Experimental results demonstrate that our WDN outperforms other state-of-the-art methods on the Clothing1M and CIFAR-10/100 datasets, which have diverse noisy labels. However, annotating large-scale datasets is extremely expensive and a time-consuming task. Because obtaining high-quality datasets is extremely difficult, in most conventional works",
    "We propose a novel Wasserstein distributional normalization algorithm to handle noisy labels for accurate classification. We split our data into uncertain and certain samples based on small loss criteria. We investigate the geometric relationship between these two different types of samples and enhance this relation to exploit useful information, even from uncertain samples. Experimental results demonstrate that our WDN outperforms other state-of-the-art methods on the Clothing1M and CIFAR-10/100 datasets, which have diverse noisy labels. However, annotating large-scale datasets is extremely expensive and a time-consuming task. Because obtaining high-quality datasets is extremely difficult, in most conventional works",
    "We propose a novel Wasserstein distributional normalization algorithm to handle noisy labels for accurate classification. We split our data into uncertain and certain samples based on small loss criteria. We investigate the geometric relationship between these two different types of samples and enhance this relation to exploit useful information, even from uncertain samples. Experimental results demonstrate that our WDN outperforms other state-of-the-art methods on the Clothing1M and CIFAR-10/100 datasets, which have diverse noisy labels. However, annotating large-scale datasets is extremely expensive and a time-consuming task. Because obtaining high-quality datasets is extremely difficult, in most conventional works",
    "X ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )",
    "X ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )",
    "X ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )",
    "We present a novel regularized dual formulation of Wasserstein-2 barycenters of continuous distributions based on a novel regularized dual formulation where the convex potentials are parameterized by input convex neural networks ( Amos et al., 2017 ). This method is straightforward without introducing bias ( e.g. Li et al. ( 2020 ) ) or requiring minimax optimization ( e.g. Fan et al. ( 2020 ) ). This is made possible by combining a new congruent formulation of Wasserstein-2 barycenters of continuous distributions based on",
    "We present a novel regularized dual formulation of Wasserstein-2 barycenters of continuous distributions based on a novel regularized dual formulation where the convex potentials are parameterized by input convex neural networks ( Amos et al., 2017 ). This method is straightforward without introducing bias ( e.g. Li et al. ( 2020 ) ) or requiring minimax optimization ( e.g. Fan et al. ( 2020 ) ). This is made possible by combining a new congruent formulation of Wasserstein-2 barycenters of continuous distributions based on",
    "We present a novel regularized dual formulation of Wasserstein-2 barycenters of continuous distributions based on a novel regularized dual formulation where the convex potentials are parameterized by input convex neural networks ( Amos et al., 2017 ). This method is straightforward without introducing bias ( e.g. Li et al. ( 2020 ) ) or requiring minimax optimization ( e.g. Fan et al. ( 2020 ) ). This is made possible by combining a new congruent formulation of Wasserstein-2 barycenters of continuous distributions based on",
    "deterministic integral equations for the multiple manifold problem and for the one-dimensional case of the multiple manifold problem ( Fig. 1b ). We construct a certificate for the simple geometry in Fig. 3, guaranteeing generalization to unseen data ( Fig. 1a ).",
    "deterministic integral equations for the multiple manifold problem and for the one-dimensional case of the multiple manifold problem ( Fig. 1b ). We construct a certificate for the simple geometry in Fig. 3, guaranteeing generalization to unseen data ( Fig. 1a ).",
    "deterministic integral equations for the multiple manifold problem and for the one-dimensional case of the multiple manifold problem ( Fig. 1b ). We construct a certificate for the simple geometry in Fig. 3, guaranteeing generalization to unseen data ( Fig. 1a ).",
    "RL steps, we propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL.",
    "RL steps, we propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL.",
    "RL steps, we propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL. We propose a simple off-policy algorithm for model-free RL.",
    "WaveQ is a gradient-based joint optimization problem based on the stochastic gradient descent that trains the neural network to also learn the bitwidth of quantization levels corresponding to a bitwidth at per-layer granularity.",
    "WaveQ is a gradient-based joint optimization problem based on the stochastic gradient descent that trains the neural network to also learn the bitwidth of quantization levels corresponding to a bitwidth at per-layer granularity.",
    "WaveQ is a gradient-based joint optimization problem based on the stochastic gradient descent that trains the neural network to also learn the bitwidth of quantization levels corresponding to a bitwidth at per-layer granularity.",
    "data augmentation is more difficult than other NLP tasks because there is often a prerequisite to do some transformations without changing the meaning of the sentence.",
    "data augmentation is more difficult than other NLP tasks because there is often a prerequisite to do some transformations without changing the meaning of the sentence.",
    "data augmentation is more difficult than other NLP tasks because there is often a prerequisite to do some transformations without changing the meaning of the sentence.",
    "We propose a real-time contribution measurement method for horizontal federated learning with a small amount of calculation in horizontal federated learning",
    "We propose a real-time contribution measurement method for horizontal federated learning with a small amount of calculation in horizontal federated learning",
    "We propose a real-time contribution measurement method for horizontal federated learning with a small amount of calculation in horizontal federated learning",
    "a set of samples that are corrupted by a corrupted set of samples.",
    "a set of samples that are corrupted by a corrupted set of samples.",
    "a set of samples that are corrupted by a corrupted set of samples.",
    "optimally for long-horizon planning.",
    "optimally for long-horizon planning.",
    "optimally for long-horizon planning.",
    "Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. (",
    "Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. (",
    "Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. ( 2020 ). Wenzel et al. (",
    "Deep encoder and shallow decoder configurations",
    "Deep encoder and shallow decoder configurations",
    "Deep encoder and shallow decoder configurations",
    "U-shaped curve is a model-wise double descent in deep neural networks ( DNNs ). This phenomenon has been observed on many machine learning models ( Advani & Saxe, 2017 ; Belkin et al., 2019a ; Geiger et al., 2019 ; Maddox et al., 2019 ; Maddox et al., 2020 ; Nakkiran et al., 2020 ; Allen-Zhu et al., 2019 ; Allen-Zhu et al., 2019 ; Allen-Zhu et al.",
    "U-shaped curve is a model-wise double descent in deep neural networks ( DNNs ). This phenomenon has been observed on many machine learning models ( Advani & Saxe, 2017 ; Belkin et al., 2019a ; Geiger et al., 2019 ; Maddox et al., 2019 ; Maddox et al., 2020 ; Nakkiran et al., 2020 ; Allen-Zhu et al., 2019 ; Allen-Zhu et al., 2019 ; Allen-Zhu et al.",
    "U-shaped curve is a model-wise double descent in deep neural networks ( DNNs ). This phenomenon has been observed on many machine learning models ( Advani & Saxe, 2017 ; Belkin et al., 2019a ; Geiger et al., 2019 ; Maddox et al., 2019 ; Maddox et al., 2020 ; Nakkiran et al., 2020 ; Allen-Zhu et al., 2019 ; Allen-Zhu et al., 2019 ; Allen-Zhu et al.",
    "MAML, which can offer fast generalization adaptation to unseen tasks, has been studied from model- and metric-based methods ( Santoro et al., 2016 ; Munkhdalai & Yu, 2017 ; Koch et al., 2015 ; Snell et al., 2017 ; Koch et al., 2015 ; Snell et al., 2015 ; Snell et al., 2017 ) to optimization-based methods ( Ravi & Larochelle, 2016 ; Finn et al., 2017 ; Nichol",
    "MAML, which can offer fast generalization adaptation to unseen tasks, has been studied from model- and metric-based methods ( Santoro et al., 2016 ; Munkhdalai & Yu, 2017 ; Koch et al., 2015 ; Snell et al., 2017 ; Koch et al., 2015 ; Snell et al., 2015 ; Snell et al., 2017 ) to optimization-based methods ( Ravi & Larochelle, 2016 ; Finn et al., 2017 ; Nichol",
    "MAML, which can offer fast generalization adaptation to unseen tasks, has been studied from model- and metric-based methods ( Santoro et al., 2016 ; Munkhdalai & Yu, 2017 ; Koch et al., 2015 ; Snell et al., 2017 ; Koch et al., 2015 ; Snell et al., 2015 ; Snell et al., 2017 ) to optimization-based methods ( Ravi & Larochelle, 2016 ; Finn et al., 2017 ; Nichol",
    "meta-objective function remains polynomially bounded, the meta-gradient can be computed on a separate validation set instead of the original training set.",
    "meta-objective function remains polynomially bounded, the meta-gradient can be computed on a separate validation set instead of the original training set.",
    "meta-objective function remains polynomially bounded, the meta-gradient can be computed on a separate validation set instead of the original training set.",
    "Convolutional neural networks ( CNNs ) ( Krizhevsky et al., 2012 ) performed outstandingly in solving problems such as image classification ( Rawat & Wang, 2017 ), semantic segmentation ( Kampffmeyer et al., 2016 ) and machine translation ( Cho et al., 2014 ) etc. This is because CNNs can effectively reuse the convolution kernel and use the given input to train optimal parameters. The original data mentioned in above problems all have a grid-like data structure, that is Euclidean spatial data. In reality, there are also lots of non-Eu",
    "Convolutional neural networks ( CNNs ) ( Krizhevsky et al., 2012 ) performed outstandingly in solving problems such as image classification ( Rawat & Wang, 2017 ), semantic segmentation ( Kampffmeyer et al., 2016 ) and machine translation ( Cho et al., 2014 ) etc. This is because CNNs can effectively reuse the convolution kernel and use the given input to train optimal parameters. The original data mentioned in above problems all have a grid-like data structure, that is Euclidean spatial data. In reality, there are also lots of non-Eu",
    "Convolutional neural networks ( CNNs ) ( Krizhevsky et al., 2012 ) performed outstandingly in solving problems such as image classification ( Rawat & Wang, 2017 ), semantic segmentation ( Kampffmeyer et al., 2016 ) and machine translation ( Cho et al., 2014 ) etc. This is because CNNs can effectively reuse the convolution kernel and use the given input to train optimal parameters. The original data mentioned in above problems all have a grid-like data structure, that is Euclidean spatial data. In reality, there are also lots of non-Eu",
    "0.6 0.8 1.0 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4",
    "0.6 0.8 1.0 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4",
    "0.6 0.8 1.0 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4",
    "graph neural networks ( GNNs ) have shown great success in learning on graph-structured data with various applications in molecular design ( Stokes et al., 2020 ), computer vision ( Casas et al., 2019 ), combinatorial optimization ( Mazyavkina et al., 2020 ), and recommender systems ( Sun et al., 2020 ). The main driving force for progress is the existence of canonical GNN architecture that efficiently encodes the original input data into expressive representations, thereby achieving high-quality results on new datasets and tasks.",
    "graph neural networks ( GNNs ) have shown great success in learning on graph-structured data with various applications in molecular design ( Stokes et al., 2020 ), computer vision ( Casas et al., 2019 ), combinatorial optimization ( Mazyavkina et al., 2020 ), and recommender systems ( Sun et al., 2020 ). The main driving force for progress is the existence of canonical GNN architecture that efficiently encodes the original input data into expressive representations, thereby achieving high-quality results on new datasets and tasks.",
    "graph neural networks ( GNNs ) have shown great success in learning on graph-structured data with various applications in molecular design ( Stokes et al., 2020 ), computer vision ( Casas et al., 2019 ), combinatorial optimization ( Mazyavkina et al., 2020 ), and recommender systems ( Sun et al., 2020 ). The main driving force for progress is the existence of canonical GNN architecture that efficiently encodes the original input data into expressive representations, thereby achieving high-quality results on new datasets and tasks.",
    "Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and a lack of evaluation criterion at meta-test time. Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and a lack of evaluation criterion at meta-test time. Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and a lack of evaluation criterion at meta-test time. Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and",
    "Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and a lack of evaluation criterion at meta-test time. Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and a lack of evaluation criterion at meta-test time. Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and a lack of evaluation criterion at meta-test time. Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and",
    "Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and a lack of evaluation criterion at meta-test time. Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and a lack of evaluation criterion at meta-test time. Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and a lack of evaluation criterion at meta-test time. Meta-learning has been criticized for a lack of prior knowledge, a lack of training data, and",
    "Learning with noisy labels ( Angluin & Laird, 1988 ) aims to reduce the side-effect of label noise and therefore has become an important topic in machine learning ( Zhang & Sabuncu, 2018 ; Kremer et al., 2018 ; Liu & Tao, 2016 ; Scott, 2015 ; Natarajan et al., 2013 ; Goldberger & Ben-Reuven, 2017 ; Patrini et al., 2017 ; Thekumparampil et al., 2018 ; Yu et al., 2018 ; Li",
    "Learning with noisy labels ( Angluin & Laird, 1988 ) aims to reduce the side-effect of label noise and therefore has become an important topic in machine learning ( Zhang & Sabuncu, 2018 ; Kremer et al., 2018 ; Liu & Tao, 2016 ; Scott, 2015 ; Natarajan et al., 2013 ; Goldberger & Ben-Reuven, 2017 ; Patrini et al., 2017 ; Thekumparampil et al., 2018 ; Yu et al., 2018 ; Li",
    "Learning with noisy labels ( Angluin & Laird, 1988 ) aims to reduce the side-effect of label noise and therefore has become an important topic in machine learning ( Zhang & Sabuncu, 2018 ; Kremer et al., 2018 ; Liu & Tao, 2016 ; Scott, 2015 ; Natarajan et al., 2013 ; Goldberger & Ben-Reuven, 2017 ; Patrini et al., 2017 ; Thekumparampil et al., 2018 ; Yu et al., 2018 ; Li",
    "robust learning algorithms ( Ma et al., 2019 ; Rosenfeld et al., 2020 ; Levine & Feizi, 2020 ; Jia et al., 2020 ; Levine & Feizi, 2020 ; Jia et al., 2020 ; Ma et al., 2019 ; Rosenfeld et al., 2020 ; Levine & Feizi, 2020 ; Jia et al., 2020 ; Ma et al., 2019 ; Rosenfeld et al., 2020 ; Levine & Feizi",
    "robust learning algorithms ( Ma et al., 2019 ; Rosenfeld et al., 2020 ; Levine & Feizi, 2020 ; Jia et al., 2020 ; Levine & Feizi, 2020 ; Jia et al., 2020 ; Ma et al., 2019 ; Rosenfeld et al., 2020 ; Levine & Feizi, 2020 ; Jia et al., 2020 ; Ma et al., 2019 ; Rosenfeld et al., 2020 ; Levine & Feizi",
    "robust learning algorithms ( Ma et al., 2019 ; Rosenfeld et al., 2020 ; Levine & Feizi, 2020 ; Jia et al., 2020 ; Levine & Feizi, 2020 ; Jia et al., 2020 ; Ma et al., 2019 ; Rosenfeld et al., 2020 ; Levine & Feizi, 2020 ; Jia et al., 2020 ; Ma et al., 2019 ; Rosenfeld et al., 2020 ; Levine & Feizi",
    "batch sizes that are too small to fit in memory.",
    "batch sizes that are too small to fit in memory.",
    "batch sizes that are too small to fit in memory.",
    "prediction accuracy. 1........................................................................",
    "prediction accuracy. 1........................................................................",
    "prediction accuracy. 1........................................................................",
    "Information retrieval is based on hand-crafted sparse representations of text documents, such as TF-IDF or BM25 ( Jones, 1972 ; Robertson et al., 1995 ). Recently, methods based on dense vectors and machine learning have shown promising results ( Karpukhin et al., 2020 ; Khattab et al., 2020 ). Deep neural networks based on pre-training, such as BERT ( Devlin et al., 2019 ), have been used to encode documents into fixed-size representations. To train such models",
    "Information retrieval is based on hand-crafted sparse representations of text documents, such as TF-IDF or BM25 ( Jones, 1972 ; Robertson et al., 1995 ). Recently, methods based on dense vectors and machine learning have shown promising results ( Karpukhin et al., 2020 ; Khattab et al., 2020 ). Deep neural networks based on pre-training, such as BERT ( Devlin et al., 2019 ), have been used to encode documents into fixed-size representations. To train such models",
    "Information retrieval is based on hand-crafted sparse representations of text documents, such as TF-IDF or BM25 ( Jones, 1972 ; Robertson et al., 1995 ). Recently, methods based on dense vectors and machine learning have shown promising results ( Karpukhin et al., 2020 ; Khattab et al., 2020 ). Deep neural networks based on pre-training, such as BERT ( Devlin et al., 2019 ), have been used to encode documents into fixed-size representations. To train such models",
    "We propose specifying safety constraints in formal languages to add useful structure based on expert knowledge, e.g., building sensitivity to proximity into constraints on object collision or converting a non-Markovian constraint into a Markovian one ( De Giacomo et al., 2020 ).",
    "We propose specifying safety constraints in formal languages to add useful structure based on expert knowledge, e.g., building sensitivity to proximity into constraints on object collision or converting a non-Markovian constraint into a Markovian one ( De Giacomo et al., 2020 ).",
    "We propose specifying safety constraints in formal languages to add useful structure based on expert knowledge, e.g., building sensitivity to proximity into constraints on object collision or converting a non-Markovian constraint into a Markovian one ( De Giacomo et al., 2020 ).",
    "Binary classification is the process of classifying the given input set into two classes based on some classification criteria. However, in order for a model to be useful in real-world applications, it is imperative that users are able to understand and explain the logic underlying model predictions. Model comprehensibility1 in some real-world applications, especially in the medical and scientific domains, is of the utmost importance. In these cases, users need to understand the classification model to scientifically explain the reasons behind the classification or even rely on the model itself to discover the possible solution to the target problem. This lack of transparency may further discourage users from using the model",
    "Binary classification is the process of classifying the given input set into two classes based on some classification criteria. However, in order for a model to be useful in real-world applications, it is imperative that users are able to understand and explain the logic underlying model predictions. Model comprehensibility1 in some real-world applications, especially in the medical and scientific domains, is of the utmost importance. In these cases, users need to understand the classification model to scientifically explain the reasons behind the classification or even rely on the model itself to discover the possible solution to the target problem. This lack of transparency may further discourage users from using the model",
    "Binary classification is the process of classifying the given input set into two classes based on some classification criteria. However, in order for a model to be useful in real-world applications, it is imperative that users are able to understand and explain the logic underlying model predictions. Model comprehensibility1 in some real-world applications, especially in the medical and scientific domains, is of the utmost importance. In these cases, users need to understand the classification model to scientifically explain the reasons behind the classification or even rely on the model itself to discover the possible solution to the target problem. This lack of transparency may further discourage users from using the model",
    "We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant",
    "We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant",
    "We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant. We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant",
    "Pre-trained language models ( PLMs ) leverage large-scale unlabeled corpora to conduct selfsupervised training. They have achieved remarkable performance in various NLP tasks, exemplified by BERT ( Devlin et al., 2018 ), RoBERTa ( Liu et al., 2019b ), XLNet ( Yang et al., 2019 ), and GPT series ( Radford et al., 2018 ; 2019 ; Brown et al., 2020 ). It has been shown that PLMs can effectively character",
    "Pre-trained language models ( PLMs ) leverage large-scale unlabeled corpora to conduct selfsupervised training. They have achieved remarkable performance in various NLP tasks, exemplified by BERT ( Devlin et al., 2018 ), RoBERTa ( Liu et al., 2019b ), XLNet ( Yang et al., 2019 ), and GPT series ( Radford et al., 2018 ; 2019 ; Brown et al., 2020 ). It has been shown that PLMs can effectively character",
    "Pre-trained language models ( PLMs ) leverage large-scale unlabeled corpora to conduct selfsupervised training. They have achieved remarkable performance in various NLP tasks, exemplified by BERT ( Devlin et al., 2018 ), RoBERTa ( Liu et al., 2019b ), XLNet ( Yang et al., 2019 ), and GPT series ( Radford et al., 2018 ; 2019 ; Brown et al., 2020 ). It has been shown that PLMs can effectively character",
    "adaptive orders may be able to identify high-quality autoregressive models, but this is not the case with modern tasks ( Alvarez-Melis & Jaakkola, 2017 ; Stern et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b",
    "adaptive orders may be able to identify high-quality autoregressive models, but this is not the case with modern tasks ( Alvarez-Melis & Jaakkola, 2017 ; Stern et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b",
    "adaptive orders may be able to identify high-quality autoregressive models, but this is not the case with modern tasks ( Alvarez-Melis & Jaakkola, 2017 ; Stern et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b ; Welleck et al., 2019b",
    "Representation of each node in the mini-batch GCN training is computationally inadmissible, as it requires to continuously re-evaluate the relative importance of nodes during training ( e.g., current gradient or representation of nodes during training ).",
    "Representation of each node in the mini-batch GCN training is computationally inadmissible, as it requires to continuously re-evaluate the relative importance of nodes during training ( e.g., current gradient or representation of nodes during training ).",
    "Representation of each node in the mini-batch GCN training is computationally inadmissible, as it requires to continuously re-evaluate the relative importance of nodes during training ( e.g., current gradient or representation of nodes during training ).",
    "We introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods, as deep learning methods typically require many training samples. We introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods, as deep learning methods typically require many training samples. We introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods, as deep learning methods typically require many training samples. We introduce a novel method for training deep conditional generative models from a",
    "We introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods, as deep learning methods typically require many training samples. We introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods, as deep learning methods typically require many training samples. We introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods, as deep learning methods typically require many training samples. We introduce a novel method for training deep conditional generative models from a",
    "We introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods, as deep learning methods typically require many training samples. We introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods, as deep learning methods typically require many training samples. We introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods, as deep learning methods typically require many training samples. We introduce a novel method for training deep conditional generative models from a",
    "GLSEARCH ( Graph Learning to Search ) with branch and bound heuristics to provide a general framework for MCS detection.",
    "GLSEARCH ( Graph Learning to Search ) with branch and bound heuristics to provide a general framework for MCS detection.",
    "GLSEARCH ( Graph Learning to Search ) with branch and bound heuristics to provide a general framework for MCS detection.",
    "3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds",
    "3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds",
    "3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds. 3D point clouds",
    "We provide a different perspective on understanding the benefits of adaptive gradient methods by considering them in the context of non-stationary neural networks.",
    "We provide a different perspective on understanding the benefits of adaptive gradient methods by considering them in the context of non-stationary neural networks.",
    "We provide a different perspective on understanding the benefits of adaptive gradient methods by considering them in the context of non-stationary neural networks.",
    "The latter is to augment MT input with its corresponding target information to improve translation performance.",
    "The latter is to augment MT input with its corresponding target information to improve translation performance.",
    "The latter is to augment MT input with its corresponding target information to improve translation performance.",
    "We propose a benchmark which distills difficulties for MDPs that can be generalised across RL problems and allows to control these difficulties for more precise experiments.",
    "We propose a benchmark which distills difficulties for MDPs that can be generalised across RL problems and allows to control these difficulties for more precise experiments.",
    "We propose a benchmark which distills difficulties for MDPs that can be generalised across RL problems and allows to control these difficulties for more precise experiments.",
    "calibration is a measure of how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For supervised machine learning, the notion of calibration of a learned predictive model is a measure of evaluating how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For supervised machine learning, the notion of calibration of a learned predictive model is a measure of evaluating how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For supervised machine learning, the notion of calibration of a learned predictive model is a measure of evaluating how well",
    "calibration is a measure of how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For supervised machine learning, the notion of calibration of a learned predictive model is a measure of evaluating how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For supervised machine learning, the notion of calibration of a learned predictive model is a measure of evaluating how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For supervised machine learning, the notion of calibration of a learned predictive model is a measure of evaluating how well",
    "calibration is a measure of how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For supervised machine learning, the notion of calibration of a learned predictive model is a measure of evaluating how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For supervised machine learning, the notion of calibration of a learned predictive model is a measure of evaluating how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For supervised machine learning, the notion of calibration of a learned predictive model is a measure of evaluating how well",
    "Deep Sequential generative models to learn representations of spatial environments, perceived through RGB-D and inertial sensors, such as in mobile robots, vehicles or drones.",
    "Deep Sequential generative models to learn representations of spatial environments, perceived through RGB-D and inertial sensors, such as in mobile robots, vehicles or drones.",
    "Deep Sequential generative models to learn representations of spatial environments, perceived through RGB-D and inertial sensors, such as in mobile robots, vehicles or drones.",
    "EMMA, a multi-modal attention model that learns to select relevant sentences in the manual for each entity in the game as well as incorporate the corresponding text description into its control policy.",
    "EMMA, a multi-modal attention model that learns to select relevant sentences in the manual for each entity in the game as well as incorporate the corresponding text description into its control policy.",
    "EMMA, a multi-modal attention model that learns to select relevant sentences in the manual for each entity in the game as well as incorporate the corresponding text description into its control policy.",
    "State-of-the-art policy gradient methods are prone to biases, and state-action-dependent baselines do not improve gradient variance more than state-dependent ones ( Ilyas et al., 2018 ; Tucker et al., 2018 ; Ilyas et al., 2018 ; Tucker et al., 2018 ; Ilyas et al., 2018 ; Ilyas et al., 2018 ; Tucker et al., 2018 ; Ilyas et al., 2018 ; Ilyas et",
    "State-of-the-art policy gradient methods are prone to biases, and state-action-dependent baselines do not improve gradient variance more than state-dependent ones ( Ilyas et al., 2018 ; Tucker et al., 2018 ; Ilyas et al., 2018 ; Tucker et al., 2018 ; Ilyas et al., 2018 ; Ilyas et al., 2018 ; Tucker et al., 2018 ; Ilyas et al., 2018 ; Ilyas et",
    "State-of-the-art policy gradient methods are prone to biases, and state-action-dependent baselines do not improve gradient variance more than state-dependent ones ( Ilyas et al., 2018 ; Tucker et al., 2018 ; Ilyas et al., 2018 ; Tucker et al., 2018 ; Ilyas et al., 2018 ; Ilyas et al., 2018 ; Tucker et al., 2018 ; Ilyas et al., 2018 ; Ilyas et",
    "Overparameterized neural networks can achieve a global minimum of the training loss, which is a double-descent phenomenon.",
    "Overparameterized neural networks can achieve a global minimum of the training loss, which is a double-descent phenomenon.",
    "Overparameterized neural networks can achieve a global minimum of the training loss, which is a double-descent phenomenon.",
    "a large number of variables on the target task, such as the number of samples needed to learn the target task, the number of samples needed to learn the target task, and the number of samples needed to learn the target task from scratch.",
    "a large number of variables on the target task, such as the number of samples needed to learn the target task, the number of samples needed to learn the target task, and the number of samples needed to learn the target task from scratch.",
    "a large number of variables on the target task, such as the number of samples needed to learn the target task, the number of samples needed to learn the target task, and the number of samples needed to learn the target task from scratch.",
    "Input features can be perturbed by a variety of factors, such as the size of the neighborhood, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input",
    "Input features can be perturbed by a variety of factors, such as the size of the neighborhood, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input",
    "Input features can be perturbed by a variety of factors, such as the size of the neighborhood, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input, the size of the input",
    "Hybrid Approach to Multi-Task Learning",
    "Hybrid Approach to Multi-Task Learning",
    "Hybrid Approach to Multi-Task Learning",
    "Unsupervised representation learning can extract informative low-dimensional representations from raw time series by leveraging the data \u2019s inherent structure, without the need for explicit supervision. Unsupervised representation learning is well studied in domains such as vision ( Donahue & Simonyan, 2019 ; Denton et al., 2017 ; Radford et al., 2015 ; Radford et al., 2017 ; Young et al., 2018 ; Mikolov et al., 2013 ), but has been underexplored in the literature for time series settings.",
    "Unsupervised representation learning can extract informative low-dimensional representations from raw time series by leveraging the data \u2019s inherent structure, without the need for explicit supervision. Unsupervised representation learning is well studied in domains such as vision ( Donahue & Simonyan, 2019 ; Denton et al., 2017 ; Radford et al., 2015 ; Radford et al., 2017 ; Young et al., 2018 ; Mikolov et al., 2013 ), but has been underexplored in the literature for time series settings.",
    "Unsupervised representation learning can extract informative low-dimensional representations from raw time series by leveraging the data \u2019s inherent structure, without the need for explicit supervision. Unsupervised representation learning is well studied in domains such as vision ( Donahue & Simonyan, 2019 ; Denton et al., 2017 ; Radford et al., 2015 ; Radford et al., 2017 ; Young et al., 2018 ; Mikolov et al., 2013 ), but has been underexplored in the literature for time series settings.",
    "a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer",
    "a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer",
    "a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer to a single layer while specializing closer",
    "VAE-based generative models often suffer from posterior collapse ( Bowman et al., 2015 ; Snderby et al., 2016 ; Alemi et al., 2017 ; Xu & Durrett, 2018 ; He et al., 2019 ; Razavi et al., 2019a ; Ma et al., 2019a ; Razavi et al., 2019a ; Ma et al., 2019a ; Bowman et al., 2015 ; Snderby et al",
    "VAE-based generative models often suffer from posterior collapse ( Bowman et al., 2015 ; Snderby et al., 2016 ; Alemi et al., 2017 ; Xu & Durrett, 2018 ; He et al., 2019 ; Razavi et al., 2019a ; Ma et al., 2019a ; Razavi et al., 2019a ; Ma et al., 2019a ; Bowman et al., 2015 ; Snderby et al",
    "VAE-based generative models often suffer from posterior collapse ( Bowman et al., 2015 ; Snderby et al., 2016 ; Alemi et al., 2017 ; Xu & Durrett, 2018 ; He et al., 2019 ; Razavi et al., 2019a ; Ma et al., 2019a ; Razavi et al., 2019a ; Ma et al., 2019a ; Bowman et al., 2015 ; Snderby et al",
    "Unsupervised Global VAE ( UG-VAE ) can capture meaningful and interpretable correlation among data points in a completely unsupervised fashion.",
    "Unsupervised Global VAE ( UG-VAE ) can capture meaningful and interpretable correlation among data points in a completely unsupervised fashion.",
    "Unsupervised Global VAE ( UG-VAE ) can capture meaningful and interpretable correlation among data points in a completely unsupervised fashion.",
    "visual cues, we are able to learn a lot more about the world around us than we are able to from visual cues alone ( Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson",
    "visual cues, we are able to learn a lot more about the world around us than we are able to from visual cues alone ( Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson",
    "visual cues, we are able to learn a lot more about the world around us than we are able to from visual cues alone ( Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson, 2015 ; Adolph & Robinson",
    "Learning on a Path on a Learning Manifold to Maximize the Performance of a Model on a Target Task. We propose three ways to remove the negative pretraining effect that can occur for certain task changes in neural network training as depicted in Fig. 2.",
    "Learning on a Path on a Learning Manifold to Maximize the Performance of a Model on a Target Task. We propose three ways to remove the negative pretraining effect that can occur for certain task changes in neural network training as depicted in Fig. 2.",
    "Learning on a Path on a Learning Manifold to Maximize the Performance of a Model on a Target Task. We propose three ways to remove the negative pretraining effect that can occur for certain task changes in neural network training as depicted in Fig. 2.",
    "Athalye et al., 2018 ; Tramer et al., 2020 ). We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We",
    "Athalye et al., 2018 ; Tramer et al., 2020 ). We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We",
    "Athalye et al., 2018 ; Tramer et al., 2020 ). We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We propose a preemptive robustness approach to the adversarial robustness problem. We",
    "a suitable way to model point cloud dynamics.",
    "a suitable way to model point cloud dynamics.",
    "a suitable way to model point cloud dynamics.",
    "custom voice, a source TTS model is usually adapted on personalized voices with few adaptation data ( the data to train the source TTS model ), since the users of custom voice prefer to record as few adaptation data as possible ( several minutes or seconds ) for convenient purpose. For custom voice, a source TTS model is usually adapted on personalized voices with few adaptation data ( the data to train the source TTS model ). For custom voice, a source TTS model is usually adapted on personalized voices with few adaptation data ( the data to train the source TTS model ). For custom voice, a source TTS model is usually adapted",
    "custom voice, a source TTS model is usually adapted on personalized voices with few adaptation data ( the data to train the source TTS model ), since the users of custom voice prefer to record as few adaptation data as possible ( several minutes or seconds ) for convenient purpose. For custom voice, a source TTS model is usually adapted on personalized voices with few adaptation data ( the data to train the source TTS model ). For custom voice, a source TTS model is usually adapted on personalized voices with few adaptation data ( the data to train the source TTS model ). For custom voice, a source TTS model is usually adapted",
    "custom voice, a source TTS model is usually adapted on personalized voices with few adaptation data ( the data to train the source TTS model ), since the users of custom voice prefer to record as few adaptation data as possible ( several minutes or seconds ) for convenient purpose. For custom voice, a source TTS model is usually adapted on personalized voices with few adaptation data ( the data to train the source TTS model ). For custom voice, a source TTS model is usually adapted on personalized voices with few adaptation data ( the data to train the source TTS model ). For custom voice, a source TTS model is usually adapted",
    "We propose a broader view of training sparse networks and show that initialization is only one piece of the puzzle and a wider view of tailoring optimization to sparse networks yields promising results.",
    "We propose a broader view of training sparse networks and show that initialization is only one piece of the puzzle and a wider view of tailoring optimization to sparse networks yields promising results.",
    "We propose a broader view of training sparse networks and show that initialization is only one piece of the puzzle and a wider view of tailoring optimization to sparse networks yields promising results.",
    "graph. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end",
    "graph. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end",
    "graph. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end model that unifies GCN and LPA for node classification. We propose an end-to-end",
    "Rademacher Complexity Rm ( F ) is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of",
    "Rademacher Complexity Rm ( F ) is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of",
    "Rademacher Complexity Rm ( F ) is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of a classifier. It is a measure of the generalization gap of",
    "Quantization is a method for quantizing the neural networks without retraining, which is called Post-training Quantization, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is",
    "Quantization is a method for quantizing the neural networks without retraining, which is called Post-training Quantization, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is",
    "Quantization is a method for quantizing the neural networks without retraining, which is called Post-training Quantization, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is a method for quantizing the neural networks without retraining, which is",
    "Calibration in machine learning is influenced by dataset properties. We study how calibration is influenced by dataset properties. We propose a complementary approach : instead of focusing on network architecture, we focus on how calibration is influenced by dataset properties.",
    "Calibration in machine learning is influenced by dataset properties. We study how calibration is influenced by dataset properties. We propose a complementary approach : instead of focusing on network architecture, we focus on how calibration is influenced by dataset properties.",
    "Calibration in machine learning is influenced by dataset properties. We study how calibration is influenced by dataset properties. We propose a complementary approach : instead of focusing on network architecture, we focus on how calibration is influenced by dataset properties.",
    "modalities for communicating with other agents in a multi-agent setting.",
    "modalities for communicating with other agents in a multi-agent setting.",
    "modalities for communicating with other agents in a multi-agent setting.",
    "Meta-modeling is a framework for generating symmetric and asymmetric uncertainty estimates for sequential regression tasks in deep neural networks ( DNNs ). We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a meta-",
    "Meta-modeling is a framework for generating symmetric and asymmetric uncertainty estimates for sequential regression tasks in deep neural networks ( DNNs ). We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a meta-",
    "Meta-modeling is a framework for generating symmetric and asymmetric uncertainty estimates for sequential regression tasks in deep neural networks ( DNNs ). We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a sequential task as one involving an ordered series of input elements, and an ordered series of outputs. We define a meta-",
    "Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric",
    "Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric",
    "Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric Measure Spaces. Metric",
    "MP is a method of pruning a neural network based on sparsity. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on sali",
    "MP is a method of pruning a neural network based on sparsity. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on sali",
    "MP is a method of pruning a neural network based on sparsity. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on saliency. MP is a method of pruning a neural network based on sali",
    "GANs have been proposed for semantic image editing, but there are currently no existing GAN-based methods for semantic image editing.",
    "GANs have been proposed for semantic image editing, but there are currently no existing GAN-based methods for semantic image editing.",
    "GANs have been proposed for semantic image editing, but there are currently no existing GAN-based methods for semantic image editing.",
    "Generative Adversarial Networks ( GANs ) are trained to generate high-quality samples to fool the discriminator's training signal.",
    "Generative Adversarial Networks ( GANs ) are trained to generate high-quality samples to fool the discriminator's training signal.",
    "Generative Adversarial Networks ( GANs ) are trained to generate high-quality samples to fool the discriminator's training signal.",
    "Reward progressivity may be problematic for value-based deep reinforcement learning agents. We hypothesize that reward progressivity may be problematic for value-based deep reinforcement learning agents. Our rationale is that the temporal difference errors that arise under such algorithms typically scale with the magnitude of the training targets. Therefore, on progressive reward tasks, it may be necessary for the agent to perform well in relatively unrewarding regions before it can reach more rewarding regions before it can reach more rewarding regions. We hypothesize that reward clipping masks the optimal solution. However, it is straightforward to construct examples where reward clipping masks the optimal solution.",
    "Reward progressivity may be problematic for value-based deep reinforcement learning agents. We hypothesize that reward progressivity may be problematic for value-based deep reinforcement learning agents. Our rationale is that the temporal difference errors that arise under such algorithms typically scale with the magnitude of the training targets. Therefore, on progressive reward tasks, it may be necessary for the agent to perform well in relatively unrewarding regions before it can reach more rewarding regions before it can reach more rewarding regions. We hypothesize that reward clipping masks the optimal solution. However, it is straightforward to construct examples where reward clipping masks the optimal solution.",
    "Reward progressivity may be problematic for value-based deep reinforcement learning agents. We hypothesize that reward progressivity may be problematic for value-based deep reinforcement learning agents. Our rationale is that the temporal difference errors that arise under such algorithms typically scale with the magnitude of the training targets. Therefore, on progressive reward tasks, it may be necessary for the agent to perform well in relatively unrewarding regions before it can reach more rewarding regions before it can reach more rewarding regions. We hypothesize that reward clipping masks the optimal solution. However, it is straightforward to construct examples where reward clipping masks the optimal solution.",
    "We propose a simple task inspired by decision-making tasks in neuroscience, where inputs and outputs are carefully designed to probe specific information processing phenomena. We then extend our findings to standard image classification tasks trained with state-of-the-art models.",
    "We propose a simple task inspired by decision-making tasks in neuroscience, where inputs and outputs are carefully designed to probe specific information processing phenomena. We then extend our findings to standard image classification tasks trained with state-of-the-art models.",
    "We propose a simple task inspired by decision-making tasks in neuroscience, where inputs and outputs are carefully designed to probe specific information processing phenomena. We then extend our findings to standard image classification tasks trained with state-of-the-art models.",
    "This paper focuses on the nonconvex-strongly-concave min-max problem, in which f ( x, y ) is nonconvex with respect to x for all y  Rd2, and f ( x, y ) is -strongly concave with respect to y for all x  Rd1.",
    "This paper focuses on the nonconvex-strongly-concave min-max problem, in which f ( x, y ) is nonconvex with respect to x for all y  Rd2, and f ( x, y ) is -strongly concave with respect to y for all x  Rd1.",
    "This paper focuses on the nonconvex-strongly-concave min-max problem, in which f ( x, y ) is nonconvex with respect to x for all y  Rd2, and f ( x, y ) is -strongly concave with respect to y for all x  Rd1.",
    "We propose a class-agnostic object proposal mechanism that detects both known and previously unseen objects and learn to recognize them based on ( ideally ) a single example.",
    "We propose a class-agnostic object proposal mechanism that detects both known and previously unseen objects and learn to recognize them based on ( ideally ) a single example.",
    "We propose a class-agnostic object proposal mechanism that detects both known and previously unseen objects and learn to recognize them based on ( ideally ) a single example.",
    "We propose a class-agnostic object proposal mechanism that detects both known and previously unseen objects and learn to recognize them based on ( ideally ) a single example.",
    "Differentiable Gradient Sampling ( DGS ) is a novel closed-form DGS solution that enables backpropagation of the loss on spatial gradients to the feature maps, thus allowing training on large-scale scenes without dense 3D supervision.",
    "Differentiable Gradient Sampling ( DGS ) is a novel closed-form DGS solution that enables backpropagation of the loss on spatial gradients to the feature maps, thus allowing training on large-scale scenes without dense 3D supervision.",
    "Differentiable Gradient Sampling ( DGS ) is a novel closed-form DGS solution that enables backpropagation of the loss on spatial gradients to the feature maps, thus allowing training on large-scale scenes without dense 3D supervision.",
    "Differentiable Gradient Sampling ( DGS ) is a novel closed-form DGS solution that enables backpropagation of the loss on spatial gradients to the feature maps, thus allowing training on large-scale scenes without dense 3D supervision.",
    "Large-scale pretraining, dense models, and sparse expert models are the two tracks of research in large-scale pretraining, dense models, and sparse expert models.",
    "Large-scale pretraining, dense models, and sparse expert models are the two tracks of research in large-scale pretraining, dense models, and sparse expert models.",
    "Large-scale pretraining, dense models, and sparse expert models are the two tracks of research in large-scale pretraining, dense models, and sparse expert models.",
    "Large-scale pretraining, dense models, and sparse expert models are the two tracks of research in large-scale pretraining, dense models, and sparse expert models.",
    "We derive variational principles dual to maximum likelihood EBMs with shallow overparametrized neural network energies, both in the active ( aka featurelearning ) and lazy regimes. We also consider a variant of this algorithm in which the particles are sometimes restarted at random samples drawn from the data set, and show that performing these restarts at every iteration step corresponds to score matching training. These results are illustrated in simple numerical experiments.",
    "We derive variational principles dual to maximum likelihood EBMs with shallow overparametrized neural network energies, both in the active ( aka featurelearning ) and lazy regimes. We also consider a variant of this algorithm in which the particles are sometimes restarted at random samples drawn from the data set, and show that performing these restarts at every iteration step corresponds to score matching training. These results are illustrated in simple numerical experiments.",
    "We derive variational principles dual to maximum likelihood EBMs with shallow overparametrized neural network energies, both in the active ( aka featurelearning ) and lazy regimes. We also consider a variant of this algorithm in which the particles are sometimes restarted at random samples drawn from the data set, and show that performing these restarts at every iteration step corresponds to score matching training. These results are illustrated in simple numerical experiments.",
    "We derive variational principles dual to maximum likelihood EBMs with shallow overparametrized neural network energies, both in the active ( aka featurelearning ) and lazy regimes. We also consider a variant of this algorithm in which the particles are sometimes restarted at random samples drawn from the data set, and show that performing these restarts at every iteration step corresponds to score matching training. These results are illustrated in simple numerical experiments.",
    "We achieve tight  (  p log ( 1/ ) n ) lower bounds for both constrained and unconstrained cases by introducing a novel biased mean property for fingerprinting codes. We also introduce an auxiliary dimension to simplify the computation brought by  2 loss. Our results close a gap in our understanding of DP-ERM by presenting the fundamental limits.",
    "We achieve tight  (  p log ( 1/ ) n ) lower bounds for both constrained and unconstrained cases by introducing a novel biased mean property for fingerprinting codes. We also introduce an auxiliary dimension to simplify the computation brought by  2 loss. Our results close a gap in our understanding of DP-ERM by presenting the fundamental limits.",
    "We achieve tight  (  p log ( 1/ ) n ) lower bounds for both constrained and unconstrained cases by introducing a novel biased mean property for fingerprinting codes. We also introduce an auxiliary dimension to simplify the computation brought by  2 loss. Our results close a gap in our understanding of DP-ERM by presenting the fundamental limits.",
    "We achieve tight  (  p log ( 1/ ) n ) lower bounds for both constrained and unconstrained cases by introducing a novel biased mean property for fingerprinting codes. We also introduce an auxiliary dimension to simplify the computation brought by  2 loss. Our results close a gap in our understanding of DP-ERM by presenting the fundamental limits.",
    "JKO, 1998 ; Carlier et al., 2017 ; Li et al., 2020 ; Carrillo et al., 2021 ) and is based on the JKO scheme ( Jordan et al., 1998 ; Carlier et al., 2017 ; Li et al., 2020 ; Carrillo et al., 2021 ).",
    "JKO, 1998 ; Carlier et al., 2017 ; Li et al., 2020 ; Carrillo et al., 2021 ) and is based on the JKO scheme ( Jordan et al., 1998 ; Carlier et al., 2017 ; Li et al., 2020 ; Carrillo et al., 2021 ).",
    "JKO, 1998 ; Carlier et al., 2017 ; Li et al., 2020 ; Carrillo et al., 2021 ) and is based on the JKO scheme ( Jordan et al., 1998 ; Carlier et al., 2017 ; Li et al., 2020 ; Carrillo et al., 2021 ).",
    "JKO, 1998 ; Carlier et al., 2017 ; Li et al., 2020 ; Carrillo et al., 2021 ) and is based on the JKO scheme ( Jordan et al., 1998 ; Carlier et al., 2017 ; Li et al., 2020 ; Carrillo et al., 2021 ).",
    ", 2018 ; Hazan et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2018 ; Fusi et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2019 )",
    ", 2018 ; Hazan et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2018 ; Fusi et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2019 )",
    ", 2018 ; Hazan et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2018 ; Fusi et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2019 )",
    ", 2018 ; Hazan et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2018 ; Fusi et al., 2019 ; Yang et al., 2018 ; Fusi et al., 2018 ; Yang et al., 2019 )",
    "Deployment of models often has a great deal of complexity.",
    "Deployment of models often has a great deal of complexity.",
    "Deployment of models often has a great deal of complexity.",
    "Deployment of models often has a great deal of complexity.",
    "Nonconvex-nonconcave Minimax Problems",
    "Nonconvex-nonconcave Minimax Problems",
    "Nonconvex-nonconcave Minimax Problems",
    "Nonconvex-nonconcave Minimax Problems",
    "Lattimore & Szepesv\u00e1ri, 2020 ).",
    "Lattimore & Szepesv\u00e1ri, 2020 ).",
    "Lattimore & Szepesv\u00e1ri, 2020 ).",
    "Lattimore & Szepesv\u00e1ri, 2020 ).",
    "A RL agent is trained to map states to actions in order to maximize a long-term cumulative reward signal in a given environment. A RL agent is defined by a quartet of ( S, A, Pa, Ra ), where S is a set of states or the state space ; A is a set of actions or the action space available to influence S ; Pa ( s, s \u2032 ) = Pr ( st+1 = s \u2032|st = s, at = a ) is the transition probability which is the probability that action a in state s at time t will lead to state",
    "A RL agent is trained to map states to actions in order to maximize a long-term cumulative reward signal in a given environment. A RL agent is defined by a quartet of ( S, A, Pa, Ra ), where S is a set of states or the state space ; A is a set of actions or the action space available to influence S ; Pa ( s, s \u2032 ) = Pr ( st+1 = s \u2032|st = s, at = a ) is the transition probability which is the probability that action a in state s at time t will lead to state",
    "A RL agent is trained to map states to actions in order to maximize a long-term cumulative reward signal in a given environment. A RL agent is defined by a quartet of ( S, A, Pa, Ra ), where S is a set of states or the state space ; A is a set of actions or the action space available to influence S ; Pa ( s, s \u2032 ) = Pr ( st+1 = s \u2032|st = s, at = a ) is the transition probability which is the probability that action a in state s at time t will lead to state",
    "A RL agent is trained to map states to actions in order to maximize a long-term cumulative reward signal in a given environment. A RL agent is defined by a quartet of ( S, A, Pa, Ra ), where S is a set of states or the state space ; A is a set of actions or the action space available to influence S ; Pa ( s, s \u2032 ) = Pr ( st+1 = s \u2032|st = s, at = a ) is the transition probability which is the probability that action a in state s at time t will lead to state",
    "We propose an algorithm that constructs probably approximately correct prediction sets under bounded covariate shifts ( Valiant et al., 1984 ), where we are given labeled examples from the source domain, but only unlabeled examples from the target domain ( covariate shifted ) domain.",
    "We propose an algorithm that constructs probably approximately correct prediction sets under bounded covariate shifts ( Valiant et al., 1984 ), where we are given labeled examples from the source domain, but only unlabeled examples from the target domain ( covariate shifted ) domain.",
    "We propose an algorithm that constructs probably approximately correct prediction sets under bounded covariate shifts ( Valiant et al., 1984 ), where we are given labeled examples from the source domain, but only unlabeled examples from the target domain ( covariate shifted ) domain.",
    "We propose an algorithm that constructs probably approximately correct prediction sets under bounded covariate shifts ( Valiant et al., 1984 ), where we are given labeled examples from the source domain, but only unlabeled examples from the target domain ( covariate shifted ) domain.",
    "hypothesis is that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance",
    "hypothesis is that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance",
    "hypothesis is that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance",
    "hypothesis is that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance empirically. We propose that pseudo-labelling a subset of the unlabelled data at each iteration based on the previous output parameter can improve the generalization performance",
    "Action repeat-based temporal persistency has been shown to be very successful ( e.g. Mnih et al., 2015 ; Sharma et al., 2017 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma e",
    "Action repeat-based temporal persistency has been shown to be very successful ( e.g. Mnih et al., 2015 ; Sharma et al., 2017 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma e",
    "Action repeat-based temporal persistency has been shown to be very successful ( e.g. Mnih et al., 2015 ; Sharma et al., 2017 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma e",
    "Action repeat-based temporal persistency has been shown to be very successful ( e.g. Mnih et al., 2015 ; Sharma et al., 2017 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma et al., 2018 ; Sharma e",
    "matrices, tensors, and low-rank matrices ( LRMC, LRTC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LR",
    "matrices, tensors, and low-rank matrices ( LRMC, LRTC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LR",
    "matrices, tensors, and low-rank matrices ( LRMC, LRTC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LR",
    "matrices, tensors, and low-rank matrices ( LRMC, LRTC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LRMC, LR",
    "We propose a novel interpretation technique to explain the behavior of structured output models, which learn mappings between an input vector to a set of output variables simultaneously. Because of the complex relationship between the computational path of output variables in structured models, a feature can affect the value of output through other ones. We focus on one of the outputs as the target and try to find the most important features utilized by the structured model to decide on the target in each locality of the input space. We introduce an energy-based training process for the interpreter function, which effectively considers the structural information incorporated into the model to be explained. The effectiveness of the proposed method is confirmed using a variety",
    "We propose a novel interpretation technique to explain the behavior of structured output models, which learn mappings between an input vector to a set of output variables simultaneously. Because of the complex relationship between the computational path of output variables in structured models, a feature can affect the value of output through other ones. We focus on one of the outputs as the target and try to find the most important features utilized by the structured model to decide on the target in each locality of the input space. We introduce an energy-based training process for the interpreter function, which effectively considers the structural information incorporated into the model to be explained. The effectiveness of the proposed method is confirmed using a variety",
    "We propose a novel interpretation technique to explain the behavior of structured output models, which learn mappings between an input vector to a set of output variables simultaneously. Because of the complex relationship between the computational path of output variables in structured models, a feature can affect the value of output through other ones. We focus on one of the outputs as the target and try to find the most important features utilized by the structured model to decide on the target in each locality of the input space. We introduce an energy-based training process for the interpreter function, which effectively considers the structural information incorporated into the model to be explained. The effectiveness of the proposed method is confirmed using a variety",
    "We propose a novel interpretation technique to explain the behavior of structured output models, which learn mappings between an input vector to a set of output variables simultaneously. Because of the complex relationship between the computational path of output variables in structured models, a feature can affect the value of output through other ones. We focus on one of the outputs as the target and try to find the most important features utilized by the structured model to decide on the target in each locality of the input space. We introduce an energy-based training process for the interpreter function, which effectively considers the structural information incorporated into the model to be explained. The effectiveness of the proposed method is confirmed using a variety",
    "We propose a more direct approach, whereby the distribution of full-episode outcomes is optimized to maximize a chosen function of its cumulative distribution function ( CDF ). This technique allows for outcomes to be weighed based on relative quality, does not require modification of the reward function to modulate agent behavior, and may be used for both continuous and discrete action spaces. We show how to achieve an asymptotically consistent estimate of the policy gradient for a broad class of CDF-based objectives via sampling, subsequently incorporating variance reduction measures to facilitate effective on-policy learning.",
    "We propose a more direct approach, whereby the distribution of full-episode outcomes is optimized to maximize a chosen function of its cumulative distribution function ( CDF ). This technique allows for outcomes to be weighed based on relative quality, does not require modification of the reward function to modulate agent behavior, and may be used for both continuous and discrete action spaces. We show how to achieve an asymptotically consistent estimate of the policy gradient for a broad class of CDF-based objectives via sampling, subsequently incorporating variance reduction measures to facilitate effective on-policy learning.",
    "We propose a more direct approach, whereby the distribution of full-episode outcomes is optimized to maximize a chosen function of its cumulative distribution function ( CDF ). This technique allows for outcomes to be weighed based on relative quality, does not require modification of the reward function to modulate agent behavior, and may be used for both continuous and discrete action spaces. We show how to achieve an asymptotically consistent estimate of the policy gradient for a broad class of CDF-based objectives via sampling, subsequently incorporating variance reduction measures to facilitate effective on-policy learning.",
    "We propose a more direct approach, whereby the distribution of full-episode outcomes is optimized to maximize a chosen function of its cumulative distribution function ( CDF ). This technique allows for outcomes to be weighed based on relative quality, does not require modification of the reward function to modulate agent behavior, and may be used for both continuous and discrete action spaces. We show how to achieve an asymptotically consistent estimate of the policy gradient for a broad class of CDF-based objectives via sampling, subsequently incorporating variance reduction measures to facilitate effective on-policy learning.",
    "stochastic simulations, which are computationally expensive and difficult to learn.",
    "stochastic simulations, which are computationally expensive and difficult to learn.",
    "stochastic simulations, which are computationally expensive and difficult to learn.",
    "stochastic simulations, which are computationally expensive and difficult to learn.",
    "Large language models with hundreds of millions of parameters can be fine-tuned with DP-SGD.",
    "Large language models with hundreds of millions of parameters can be fine-tuned with DP-SGD.",
    "Large language models with hundreds of millions of parameters can be fine-tuned with DP-SGD.",
    "Large language models with hundreds of millions of parameters can be fine-tuned with DP-SGD.",
    "Transform2Act into a set of skeletal structures and joint attributes to optimize the agent\u2019s performance on a given task. We propose a new approach to agent design optimization by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure",
    "Transform2Act into a set of skeletal structures and joint attributes to optimize the agent\u2019s performance on a given task. We propose a new approach to agent design optimization by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure",
    "Transform2Act into a set of skeletal structures and joint attributes to optimize the agent\u2019s performance on a given task. We propose a new approach to agent design optimization by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure",
    "Transform2Act into a set of skeletal structures and joint attributes to optimize the agent\u2019s performance on a given task. We propose a new approach to agent design optimization by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure of an agent into its decision-making process by incorporating the design procedure",
    "We propose a new split MLP architecture, CoordX, to accelerate inference and training of coordinate-based MLPs for implicit neural representations by proposing a new split MLP architecture, CoordX. With CoordX, the initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This significantly reduces the amount of computation required and leads to large speedups in training and inference. We demonstrate a speedup of up to 2.92x compared to the baseline MLP for image, video",
    "We propose a new split MLP architecture, CoordX, to accelerate inference and training of coordinate-based MLPs for implicit neural representations by proposing a new split MLP architecture, CoordX. With CoordX, the initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This significantly reduces the amount of computation required and leads to large speedups in training and inference. We demonstrate a speedup of up to 2.92x compared to the baseline MLP for image, video",
    "We propose a new split MLP architecture, CoordX, to accelerate inference and training of coordinate-based MLPs for implicit neural representations by proposing a new split MLP architecture, CoordX. With CoordX, the initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This significantly reduces the amount of computation required and leads to large speedups in training and inference. We demonstrate a speedup of up to 2.92x compared to the baseline MLP for image, video",
    "We propose a new split MLP architecture, CoordX, to accelerate inference and training of coordinate-based MLPs for implicit neural representations by proposing a new split MLP architecture, CoordX. With CoordX, the initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This significantly reduces the amount of computation required and leads to large speedups in training and inference. We demonstrate a speedup of up to 2.92x compared to the baseline MLP for image, video",
    "InferNO is a model which learns object-centric representations and their 3D poses from a single image without relying on supervision and is a promising step towards visual reasoning valuable to several applications involving object manipulation, navigation or forecasting. We leverage these recent advances in object-centric representation learning ( Locatello et al., 2020 ) and 3D modelling through implicit functions ( Mildenhall et al., 2020 ; Niemeyer & Geiger, 2021 ) and propose INFERNO, a model which infers a structured representation of objects and their 3D poses from a single image. Each object is",
    "InferNO is a model which learns object-centric representations and their 3D poses from a single image without relying on supervision and is a promising step towards visual reasoning valuable to several applications involving object manipulation, navigation or forecasting. We leverage these recent advances in object-centric representation learning ( Locatello et al., 2020 ) and 3D modelling through implicit functions ( Mildenhall et al., 2020 ; Niemeyer & Geiger, 2021 ) and propose INFERNO, a model which infers a structured representation of objects and their 3D poses from a single image. Each object is",
    "InferNO is a model which learns object-centric representations and their 3D poses from a single image without relying on supervision and is a promising step towards visual reasoning valuable to several applications involving object manipulation, navigation or forecasting. We leverage these recent advances in object-centric representation learning ( Locatello et al., 2020 ) and 3D modelling through implicit functions ( Mildenhall et al., 2020 ; Niemeyer & Geiger, 2021 ) and propose INFERNO, a model which infers a structured representation of objects and their 3D poses from a single image. Each object is",
    "InferNO is a model which learns object-centric representations and their 3D poses from a single image without relying on supervision and is a promising step towards visual reasoning valuable to several applications involving object manipulation, navigation or forecasting. We leverage these recent advances in object-centric representation learning ( Locatello et al., 2020 ) and 3D modelling through implicit functions ( Mildenhall et al., 2020 ; Niemeyer & Geiger, 2021 ) and propose INFERNO, a model which infers a structured representation of objects and their 3D poses from a single image. Each object is",
    "Deconfounded Subgraph Evaluation ( DSE ) is proposed for feature attribution ( Selvaraju et al., 2017 ; Ying et al., 2019 ; Luo et al., 2020 ; Luo et al., 2019 ; Ying et al., 2019 ; Luo et al., 2019 ; Ying et al., 2019 ; Luo et al., 2019 ; Ying et al., 2019 ; Ying et al., 2019 ; Luo e",
    "Deconfounded Subgraph Evaluation ( DSE ) is proposed for feature attribution ( Selvaraju et al., 2017 ; Ying et al., 2019 ; Luo et al., 2020 ; Luo et al., 2019 ; Ying et al., 2019 ; Luo et al., 2019 ; Ying et al., 2019 ; Luo et al., 2019 ; Ying et al., 2019 ; Ying et al., 2019 ; Luo e",
    "Deconfounded Subgraph Evaluation ( DSE ) is proposed for feature attribution ( Selvaraju et al., 2017 ; Ying et al., 2019 ; Luo et al., 2020 ; Luo et al., 2019 ; Ying et al., 2019 ; Luo et al., 2019 ; Ying et al., 2019 ; Luo et al., 2019 ; Ying et al., 2019 ; Ying et al., 2019 ; Luo e",
    "Deconfounded Subgraph Evaluation ( DSE ) is proposed for feature attribution ( Selvaraju et al., 2017 ; Ying et al., 2019 ; Luo et al., 2020 ; Luo et al., 2019 ; Ying et al., 2019 ; Luo et al., 2019 ; Ying et al., 2019 ; Luo et al., 2019 ; Ying et al., 2019 ; Ying et al., 2019 ; Luo e",
    ") of a single data point ( and the effect of an individual data point ( and the difference ) of a single data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the",
    ") of a single data point ( and the effect of an individual data point ( and the difference ) of a single data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the",
    ") of a single data point ( and the effect of an individual data point ( and the difference ) of a single data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the",
    ") of a single data point ( and the effect of an individual data point ( and the difference ) of a single data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the effect of an individual data point ( and the",
    "The second line of work considers the bug-fix learning problem as sequence-based code generation and harnesses the power of sequence-to-sequence models with RNN ( Hata et al., 2018 ; Chen et al., 2019 ; Tufano et al., 2019 ; Tufano et al., 2019 ; Tufano et al., 2019 ; Chen et al., 2019 ; Tufano et al., 2019 ; Chen et al., 2019 ; Tufano et al., 2019 ;",
    "The second line of work considers the bug-fix learning problem as sequence-based code generation and harnesses the power of sequence-to-sequence models with RNN ( Hata et al., 2018 ; Chen et al., 2019 ; Tufano et al., 2019 ; Tufano et al., 2019 ; Tufano et al., 2019 ; Chen et al., 2019 ; Tufano et al., 2019 ; Chen et al., 2019 ; Tufano et al., 2019 ;",
    "The second line of work considers the bug-fix learning problem as sequence-based code generation and harnesses the power of sequence-to-sequence models with RNN ( Hata et al., 2018 ; Chen et al., 2019 ; Tufano et al., 2019 ; Tufano et al., 2019 ; Tufano et al., 2019 ; Chen et al., 2019 ; Tufano et al., 2019 ; Chen et al., 2019 ; Tufano et al., 2019 ;",
    "The second line of work considers the bug-fix learning problem as sequence-based code generation and harnesses the power of sequence-to-sequence models with RNN ( Hata et al., 2018 ; Chen et al., 2019 ; Tufano et al., 2019 ; Tufano et al., 2019 ; Tufano et al., 2019 ; Chen et al., 2019 ; Tufano et al., 2019 ; Chen et al., 2019 ; Tufano et al., 2019 ;",
    "Federated Adversarial Training ( FAT ) is a federated adversarial training method based on FedAvg ( McMahan, 2017 ; Kairouz, 2019 ; Goodfellow, 2015 ; Kurakin et al., 2016 ).",
    "Federated Adversarial Training ( FAT ) is a federated adversarial training method based on FedAvg ( McMahan, 2017 ; Kairouz, 2019 ; Goodfellow, 2015 ; Kurakin et al., 2016 ).",
    "Federated Adversarial Training ( FAT ) is a federated adversarial training method based on FedAvg ( McMahan, 2017 ; Kairouz, 2019 ; Goodfellow, 2015 ; Kurakin et al., 2016 ).",
    "Federated Adversarial Training ( FAT ) is a federated adversarial training method based on FedAvg ( McMahan, 2017 ; Kairouz, 2019 ; Goodfellow, 2015 ; Kurakin et al., 2016 ).",
    "Semi-supervised Lifelong Learning ( LML ) can be applied to any existing continuous learning algorithm.",
    "Semi-supervised Lifelong Learning ( LML ) can be applied to any existing continuous learning algorithm.",
    "Semi-supervised Lifelong Learning ( LML ) can be applied to any existing continuous learning algorithm.",
    "Semi-supervised Lifelong Learning ( LML ) can be applied to any existing continuous learning algorithm.",
    "ACW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b",
    "ACW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b",
    "ACW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b",
    "ACW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b ; MMS+17 ; CW17b",
    "A probabilistic treatment of cooperative games ( N, F ( S ) ) is proposed. We consider a probability distribution over coalitions p ( S = S ) 1, measuring the odds that a specific coalition S happens. We advocate to choose the pmf with the maximum entropy H ( p ). This principle makes sense since maximizing the entropy minimizes the amount of prior information built into the distribution. Now finding a proper p ( S ) becomes the following constrained optimization problem : suppose each coalition S is associated with a payoff F ( S ) with probability p ( S ) 1, measuring",
    "A probabilistic treatment of cooperative games ( N, F ( S ) ) is proposed. We consider a probability distribution over coalitions p ( S = S ) 1, measuring the odds that a specific coalition S happens. We advocate to choose the pmf with the maximum entropy H ( p ). This principle makes sense since maximizing the entropy minimizes the amount of prior information built into the distribution. Now finding a proper p ( S ) becomes the following constrained optimization problem : suppose each coalition S is associated with a payoff F ( S ) with probability p ( S ) 1, measuring",
    "A probabilistic treatment of cooperative games ( N, F ( S ) ) is proposed. We consider a probability distribution over coalitions p ( S = S ) 1, measuring the odds that a specific coalition S happens. We advocate to choose the pmf with the maximum entropy H ( p ). This principle makes sense since maximizing the entropy minimizes the amount of prior information built into the distribution. Now finding a proper p ( S ) becomes the following constrained optimization problem : suppose each coalition S is associated with a payoff F ( S ) with probability p ( S ) 1, measuring",
    "A probabilistic treatment of cooperative games ( N, F ( S ) ) is proposed. We consider a probability distribution over coalitions p ( S = S ) 1, measuring the odds that a specific coalition S happens. We advocate to choose the pmf with the maximum entropy H ( p ). This principle makes sense since maximizing the entropy minimizes the amount of prior information built into the distribution. Now finding a proper p ( S ) becomes the following constrained optimization problem : suppose each coalition S is associated with a payoff F ( S ) with probability p ( S ) 1, measuring",
    "Epistemic uncertainty ( EU ) is a measure of lack of knowledge, which could potentially be eliminated with enough data if the learner converges to a Bayesian predictor.",
    "Epistemic uncertainty ( EU ) is a measure of lack of knowledge, which could potentially be eliminated with enough data if the learner converges to a Bayesian predictor.",
    "Epistemic uncertainty ( EU ) is a measure of lack of knowledge, which could potentially be eliminated with enough data if the learner converges to a Bayesian predictor.",
    "Epistemic uncertainty ( EU ) is a measure of lack of knowledge, which could potentially be eliminated with enough data if the learner converges to a Bayesian predictor.",
    "Embedding indexes are used to encode users and items in a latent vector space, and represent their semantic proximity in terms of inner product or cosine similarity.",
    "Embedding indexes are used to encode users and items in a latent vector space, and represent their semantic proximity in terms of inner product or cosine similarity.",
    "Embedding indexes are used to encode users and items in a latent vector space, and represent their semantic proximity in terms of inner product or cosine similarity.",
    "Embedding indexes are used to encode users and items in a latent vector space, and represent their semantic proximity in terms of inner product or cosine similarity.",
    "Artificial Intelligence ( AI ) and Deep Learning ( DL ).",
    "Artificial Intelligence ( AI ) and Deep Learning ( DL ).",
    "Artificial Intelligence ( AI ) and Deep Learning ( DL ).",
    "Artificial Intelligence ( AI ) and Deep Learning ( DL ).",
    "Self-GenomeNet is a novel contrastive self-supervised method that learns a representation of nucleotide genomic data using domain-specific characteristics.",
    "Self-GenomeNet is a novel contrastive self-supervised method that learns a representation of nucleotide genomic data using domain-specific characteristics.",
    "Self-GenomeNet is a novel contrastive self-supervised method that learns a representation of nucleotide genomic data using domain-specific characteristics.",
    "Self-GenomeNet is a novel contrastive self-supervised method that learns a representation of nucleotide genomic data using domain-specific characteristics.",
    "We propose a new feed-forward learning-based approach that consists of spherical decision surfaces and operates on point clouds.",
    "We propose a new feed-forward learning-based approach that consists of spherical decision surfaces and operates on point clouds.",
    "We propose a new feed-forward learning-based approach that consists of spherical decision surfaces and operates on point clouds.",
    "We propose a new feed-forward learning-based approach that consists of spherical decision surfaces and operates on point clouds.",
    "ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs while ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs while ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs",
    "ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs while ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs while ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs",
    "ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs while ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs while ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs",
    "ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs while ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs while ALBERT ( Lan et al., 2020 ) and XLNET ( Yang et al., 2021 ) focus on input, output, and gradients information of PLMs",
    "a DNN is trained using Krum on the MNIST dataset, a stateful model reduces the contribution by suspicious clients to the global model update.",
    "a DNN is trained using Krum on the MNIST dataset, a stateful model reduces the contribution by suspicious clients to the global model update.",
    "a DNN is trained using Krum on the MNIST dataset, a stateful model reduces the contribution by suspicious clients to the global model update.",
    "a DNN is trained using Krum on the MNIST dataset, a stateful model reduces the contribution by suspicious clients to the global model update.",
    "Debiasing of linear functionals using Neural Nets and Random Forests",
    "Debiasing of linear functionals using Neural Nets and Random Forests",
    "Debiasing of linear functionals using Neural Nets and Random Forests",
    "Debiasing of linear functionals using Neural Nets and Random Forests",
    "We propose a mini-batch Markovian sampled fully decentralized actor-critic algorithm and analyze its finite-time convergence and sample complexity.",
    "We propose a mini-batch Markovian sampled fully decentralized actor-critic algorithm and analyze its finite-time convergence and sample complexity.",
    "We propose a mini-batch Markovian sampled fully decentralized actor-critic algorithm and analyze its finite-time convergence and sample complexity.",
    "We propose a mini-batch Markovian sampled fully decentralized actor-critic algorithm and analyze its finite-time convergence and sample complexity.",
    "Contrastive Learning ( CL ) is a promising paradigm for learning data representations without labeled data. However, a theoretical understanding of how contrastive learning actually works in practice is still under-explored. The general methodology of contrastive learning is quite simple, that is to maximize the similarity between augmented views of the same image ( a.k.a. positive samples ), and minimize the similarity between that of two random images ( a.k.a. negative samples ). However, as shown in Figure 1 ( a ), CL representations are also class-separated. Therefore, understanding",
    "Contrastive Learning ( CL ) is a promising paradigm for learning data representations without labeled data. However, a theoretical understanding of how contrastive learning actually works in practice is still under-explored. The general methodology of contrastive learning is quite simple, that is to maximize the similarity between augmented views of the same image ( a.k.a. positive samples ), and minimize the similarity between that of two random images ( a.k.a. negative samples ). However, as shown in Figure 1 ( a ), CL representations are also class-separated. Therefore, understanding",
    "Contrastive Learning ( CL ) is a promising paradigm for learning data representations without labeled data. However, a theoretical understanding of how contrastive learning actually works in practice is still under-explored. The general methodology of contrastive learning is quite simple, that is to maximize the similarity between augmented views of the same image ( a.k.a. positive samples ), and minimize the similarity between that of two random images ( a.k.a. negative samples ). However, as shown in Figure 1 ( a ), CL representations are also class-separated. Therefore, understanding",
    "Contrastive Learning ( CL ) is a promising paradigm for learning data representations without labeled data. However, a theoretical understanding of how contrastive learning actually works in practice is still under-explored. The general methodology of contrastive learning is quite simple, that is to maximize the similarity between augmented views of the same image ( a.k.a. positive samples ), and minimize the similarity between that of two random images ( a.k.a. negative samples ). However, as shown in Figure 1 ( a ), CL representations are also class-separated. Therefore, understanding",
    "We propose a new task called general speech restoration ( GSR ), which aims at restoring multiple distortions in a single model.",
    "We propose a new task called general speech restoration ( GSR ), which aims at restoring multiple distortions in a single model.",
    "We propose a new task called general speech restoration ( GSR ), which aims at restoring multiple distortions in a single model.",
    "We propose a new task called general speech restoration ( GSR ), which aims at restoring multiple distortions in a single model.",
    "Wu et al., 2020 ; Cheng et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Cheng et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et",
    "Wu et al., 2020 ; Cheng et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Cheng et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et",
    "Wu et al., 2020 ; Cheng et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Cheng et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et",
    "Wu et al., 2020 ; Cheng et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Cheng et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et al., 2020 ; Wu et",
    "GNN training on large graphs is computationally challenging due to the stochastic gradient obtained with sampled neighbor aggregation. Despite their good convergence property, SCO algorithms are not widely adopted for GNN training due to two reasons : first, although SCO algorithms achieve smaller training losses, the obtained GNN models usually have poor generalization \u2013 the validation and test accuracy are lower than the models trained by Adam SGD for small graphs. Second, the obtained GNN models usually have poor generalization \u2013 the validation and test accuracy are lower than the models trained by Adam SGD for small graphs.",
    "GNN training on large graphs is computationally challenging due to the stochastic gradient obtained with sampled neighbor aggregation. Despite their good convergence property, SCO algorithms are not widely adopted for GNN training due to two reasons : first, although SCO algorithms achieve smaller training losses, the obtained GNN models usually have poor generalization \u2013 the validation and test accuracy are lower than the models trained by Adam SGD for small graphs. Second, the obtained GNN models usually have poor generalization \u2013 the validation and test accuracy are lower than the models trained by Adam SGD for small graphs.",
    "GNN training on large graphs is computationally challenging due to the stochastic gradient obtained with sampled neighbor aggregation. Despite their good convergence property, SCO algorithms are not widely adopted for GNN training due to two reasons : first, although SCO algorithms achieve smaller training losses, the obtained GNN models usually have poor generalization \u2013 the validation and test accuracy are lower than the models trained by Adam SGD for small graphs. Second, the obtained GNN models usually have poor generalization \u2013 the validation and test accuracy are lower than the models trained by Adam SGD for small graphs.",
    "GNN training on large graphs is computationally challenging due to the stochastic gradient obtained with sampled neighbor aggregation. Despite their good convergence property, SCO algorithms are not widely adopted for GNN training due to two reasons : first, although SCO algorithms achieve smaller training losses, the obtained GNN models usually have poor generalization \u2013 the validation and test accuracy are lower than the models trained by Adam SGD for small graphs. Second, the obtained GNN models usually have poor generalization \u2013 the validation and test accuracy are lower than the models trained by Adam SGD for small graphs.",
    "Broder, 1997 ; Broder et al., 1997 ; 1998 ; Li & Church, 2005 ; Li & K\u00f6nig, 2011 ) is a standard technique for computing/estimating the Jaccard similarity in massive binary datasets, with numerous applications such as near neighbor search, duplicate detection, malware detection, web search, clustering, large-scale learning, social networks, computer vision, etc. The well-known method of \u201c minwise hashing \u201d ( MinHash ) ( Broder, 1997 ; Broder et al., 1997 ; 1998 ; Li",
    "Broder, 1997 ; Broder et al., 1997 ; 1998 ; Li & Church, 2005 ; Li & K\u00f6nig, 2011 ) is a standard technique for computing/estimating the Jaccard similarity in massive binary datasets, with numerous applications such as near neighbor search, duplicate detection, malware detection, web search, clustering, large-scale learning, social networks, computer vision, etc. The well-known method of \u201c minwise hashing \u201d ( MinHash ) ( Broder, 1997 ; Broder et al., 1997 ; 1998 ; Li",
    "Broder, 1997 ; Broder et al., 1997 ; 1998 ; Li & Church, 2005 ; Li & K\u00f6nig, 2011 ) is a standard technique for computing/estimating the Jaccard similarity in massive binary datasets, with numerous applications such as near neighbor search, duplicate detection, malware detection, web search, clustering, large-scale learning, social networks, computer vision, etc. The well-known method of \u201c minwise hashing \u201d ( MinHash ) ( Broder, 1997 ; Broder et al., 1997 ; 1998 ; Li",
    "Broder, 1997 ; Broder et al., 1997 ; 1998 ; Li & Church, 2005 ; Li & K\u00f6nig, 2011 ) is a standard technique for computing/estimating the Jaccard similarity in massive binary datasets, with numerous applications such as near neighbor search, duplicate detection, malware detection, web search, clustering, large-scale learning, social networks, computer vision, etc. The well-known method of \u201c minwise hashing \u201d ( MinHash ) ( Broder, 1997 ; Broder et al., 1997 ; 1998 ; Li",
    "We need robustness in one lp-ball for p 6= q ( Kang et al., 2019a ; Tram\u00e8r & Boneh, 2019 ; Laidlaw et al., 2021 ; Laidlaw et al., 2021 ). We need robustness in one lp-ball for p 6= q ( Kang et al., 2019a ; Tram\u00e8r & Boneh, 2019 ; Laidlaw et al., 2021 ; Laidlaw et al.",
    "We need robustness in one lp-ball for p 6= q ( Kang et al., 2019a ; Tram\u00e8r & Boneh, 2019 ; Laidlaw et al., 2021 ; Laidlaw et al., 2021 ). We need robustness in one lp-ball for p 6= q ( Kang et al., 2019a ; Tram\u00e8r & Boneh, 2019 ; Laidlaw et al., 2021 ; Laidlaw et al.",
    "We need robustness in one lp-ball for p 6= q ( Kang et al., 2019a ; Tram\u00e8r & Boneh, 2019 ; Laidlaw et al., 2021 ; Laidlaw et al., 2021 ). We need robustness in one lp-ball for p 6= q ( Kang et al., 2019a ; Tram\u00e8r & Boneh, 2019 ; Laidlaw et al., 2021 ; Laidlaw et al.",
    "We need robustness in one lp-ball for p 6= q ( Kang et al., 2019a ; Tram\u00e8r & Boneh, 2019 ; Laidlaw et al., 2021 ; Laidlaw et al., 2021 ). We need robustness in one lp-ball for p 6= q ( Kang et al., 2019a ; Tram\u00e8r & Boneh, 2019 ; Laidlaw et al., 2021 ; Laidlaw et al.",
    "MTL model performs no worse than its single-task counterpart on each task.",
    "MTL model performs no worse than its single-task counterpart on each task.",
    "MTL model performs no worse than its single-task counterpart on each task.",
    "MTL model performs no worse than its single-task counterpart on each task.",
    "represent probabilistic inference.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models",
    "represent probabilistic inference.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models",
    "represent probabilistic inference.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models",
    "represent probabilistic inference.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models.1 Energy-based sequence models are often parametrized as neural models",
    "The Wasserstein distance is an optimal transport theory that provides a powerful and flexible theoretical tool to compare degenerative distributions by accounting for the metric in the underlying spaces. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains ranging from generative models to transfer learning ( Gulrajani et al., 2017 ; Arjovsky et al., 2017 ; Kolouri et al., 2019b ; Cuturi and Doucet, 2014 ; Courty et al., 2016 ). Besides, the Wasserstein distance",
    "The Wasserstein distance is an optimal transport theory that provides a powerful and flexible theoretical tool to compare degenerative distributions by accounting for the metric in the underlying spaces. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains ranging from generative models to transfer learning ( Gulrajani et al., 2017 ; Arjovsky et al., 2017 ; Kolouri et al., 2019b ; Cuturi and Doucet, 2014 ; Courty et al., 2016 ). Besides, the Wasserstein distance",
    "The Wasserstein distance is an optimal transport theory that provides a powerful and flexible theoretical tool to compare degenerative distributions by accounting for the metric in the underlying spaces. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains ranging from generative models to transfer learning ( Gulrajani et al., 2017 ; Arjovsky et al., 2017 ; Kolouri et al., 2019b ; Cuturi and Doucet, 2014 ; Courty et al., 2016 ). Besides, the Wasserstein distance",
    "The Wasserstein distance is an optimal transport theory that provides a powerful and flexible theoretical tool to compare degenerative distributions by accounting for the metric in the underlying spaces. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains ranging from generative models to transfer learning ( Gulrajani et al., 2017 ; Arjovsky et al., 2017 ; Kolouri et al., 2019b ; Cuturi and Doucet, 2014 ; Courty et al., 2016 ). Besides, the Wasserstein distance",
    "QMIX ( Rashid et al., 2018 ), and QMIX ( Rashid et al., 2018 ) have been developed to improve coordination in multi-agent systems.",
    "QMIX ( Rashid et al., 2018 ), and QMIX ( Rashid et al., 2018 ) have been developed to improve coordination in multi-agent systems.",
    "QMIX ( Rashid et al., 2018 ), and QMIX ( Rashid et al., 2018 ) have been developed to improve coordination in multi-agent systems.",
    "QMIX ( Rashid et al., 2018 ), and QMIX ( Rashid et al., 2018 ) have been developed to improve coordination in multi-agent systems.",
    "Iteratively find evidence for one hop, and then use that evidence to update the query used in the next hop of the QA process ( Talmor & Berant, 2018 ; Sun et al., 2019 ; Xiong et al., 2021 ; Li et al., 2020 ; Li et al., 2020 ; Xiong et al., 2021 ; Zhao et al., 2021 ; Qi et al., 2021 ; Qi et al., 2021 ; Li et al.",
    "Iteratively find evidence for one hop, and then use that evidence to update the query used in the next hop of the QA process ( Talmor & Berant, 2018 ; Sun et al., 2019 ; Xiong et al., 2021 ; Li et al., 2020 ; Li et al., 2020 ; Xiong et al., 2021 ; Zhao et al., 2021 ; Qi et al., 2021 ; Qi et al., 2021 ; Li et al.",
    "Iteratively find evidence for one hop, and then use that evidence to update the query used in the next hop of the QA process ( Talmor & Berant, 2018 ; Sun et al., 2019 ; Xiong et al., 2021 ; Li et al., 2020 ; Li et al., 2020 ; Xiong et al., 2021 ; Zhao et al., 2021 ; Qi et al., 2021 ; Qi et al., 2021 ; Li et al.",
    "Iteratively find evidence for one hop, and then use that evidence to update the query used in the next hop of the QA process ( Talmor & Berant, 2018 ; Sun et al., 2019 ; Xiong et al., 2021 ; Li et al., 2020 ; Li et al., 2020 ; Xiong et al., 2021 ; Zhao et al., 2021 ; Qi et al., 2021 ; Qi et al., 2021 ; Li et al.",
    "( 2020 ; 2019 ; 2017 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018",
    "( 2020 ; 2019 ; 2017 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018",
    "( 2020 ; 2019 ; 2017 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018",
    "( 2020 ; 2019 ; 2017 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018 ; 2018",
    "federated learning ( FL ) on multiple systems or devices without violating the privacy of each client, thus enabling a fast training of the federated learning network without violating the privacy of each client.",
    "federated learning ( FL ) on multiple systems or devices without violating the privacy of each client, thus enabling a fast training of the federated learning network without violating the privacy of each client.",
    "federated learning ( FL ) on multiple systems or devices without violating the privacy of each client, thus enabling a fast training of the federated learning network without violating the privacy of each client.",
    "federated learning ( FL ) on multiple systems or devices without violating the privacy of each client, thus enabling a fast training of the federated learning network without violating the privacy of each client.",
    "Reinforcement Learning agents to exploit misspecified reward functions to achieve higher proxy reward and lower true reward than less capable agents. Reward hacking has been widely observed, but not yet systematically studied. We construct four RL environments with misspecified rewards. We investigate reward hacking as a function of agent capabilities : model capacity, action space resolution, observation space noise, and training time. We find instances of phase transitions : capability thresholds at which the agent \u2019 s behavior qualitatively shifts, leading to a sharp decrease in the true reward. We propose an anomaly detection task for aberrant policies and offer several baseline detectors.",
    "Reinforcement Learning agents to exploit misspecified reward functions to achieve higher proxy reward and lower true reward than less capable agents. Reward hacking has been widely observed, but not yet systematically studied. We construct four RL environments with misspecified rewards. We investigate reward hacking as a function of agent capabilities : model capacity, action space resolution, observation space noise, and training time. We find instances of phase transitions : capability thresholds at which the agent \u2019 s behavior qualitatively shifts, leading to a sharp decrease in the true reward. We propose an anomaly detection task for aberrant policies and offer several baseline detectors.",
    "Reinforcement Learning agents to exploit misspecified reward functions to achieve higher proxy reward and lower true reward than less capable agents. Reward hacking has been widely observed, but not yet systematically studied. We construct four RL environments with misspecified rewards. We investigate reward hacking as a function of agent capabilities : model capacity, action space resolution, observation space noise, and training time. We find instances of phase transitions : capability thresholds at which the agent \u2019 s behavior qualitatively shifts, leading to a sharp decrease in the true reward. We propose an anomaly detection task for aberrant policies and offer several baseline detectors.",
    "Reinforcement Learning agents to exploit misspecified reward functions to achieve higher proxy reward and lower true reward than less capable agents. Reward hacking has been widely observed, but not yet systematically studied. We construct four RL environments with misspecified rewards. We investigate reward hacking as a function of agent capabilities : model capacity, action space resolution, observation space noise, and training time. We find instances of phase transitions : capability thresholds at which the agent \u2019 s behavior qualitatively shifts, leading to a sharp decrease in the true reward. We propose an anomaly detection task for aberrant policies and offer several baseline detectors.",
    "We propose a f -divergence Thermodynamic Variational Objective ( f -TVO ). f -TVO generalizes the Thermodynamic Variational Objective ( TVO ) by replacing Kullback\u2013Leibler ( KL ) divergence with arbitary differeitiable f - divergence. In particular, f -TVO approximates dual function of model evidence f ( p ( x ) rather than the log model evidence log p ( x ) in TVO. By defining -exponential family exponential",
    "We propose a f -divergence Thermodynamic Variational Objective ( f -TVO ). f -TVO generalizes the Thermodynamic Variational Objective ( TVO ) by replacing Kullback\u2013Leibler ( KL ) divergence with arbitary differeitiable f - divergence. In particular, f -TVO approximates dual function of model evidence f ( p ( x ) rather than the log model evidence log p ( x ) in TVO. By defining -exponential family exponential",
    "We propose a f -divergence Thermodynamic Variational Objective ( f -TVO ). f -TVO generalizes the Thermodynamic Variational Objective ( TVO ) by replacing Kullback\u2013Leibler ( KL ) divergence with arbitary differeitiable f - divergence. In particular, f -TVO approximates dual function of model evidence f ( p ( x ) rather than the log model evidence log p ( x ) in TVO. By defining -exponential family exponential",
    "We propose a f -divergence Thermodynamic Variational Objective ( f -TVO ). f -TVO generalizes the Thermodynamic Variational Objective ( TVO ) by replacing Kullback\u2013Leibler ( KL ) divergence with arbitary differeitiable f - divergence. In particular, f -TVO approximates dual function of model evidence f ( p ( x ) rather than the log model evidence log p ( x ) in TVO. By defining -exponential family exponential",
    "The weighted Bellman backup ( Lee et al., 2020 ) can not replace the clipped double Q- Learning ( Fujimoto et al., 2020 ).",
    "The weighted Bellman backup ( Lee et al., 2020 ) can not replace the clipped double Q- Learning ( Fujimoto et al., 2020 ).",
    "The weighted Bellman backup ( Lee et al., 2020 ) can not replace the clipped double Q- Learning ( Fujimoto et al., 2020 ).",
    "The weighted Bellman backup ( Lee et al., 2020 ) can not replace the clipped double Q- Learning ( Fujimoto et al., 2020 ).",
    "African Americans. We propose an algorithm that is computationally more efficient than ELminimizer and finds a sub-optimal EL fair predictor using unconstrained convex programming tools.",
    "African Americans. We propose an algorithm that is computationally more efficient than ELminimizer and finds a sub-optimal EL fair predictor using unconstrained convex programming tools.",
    "African Americans. We propose an algorithm that is computationally more efficient than ELminimizer and finds a sub-optimal EL fair predictor using unconstrained convex programming tools.",
    "African Americans. We propose an algorithm that is computationally more efficient than ELminimizer and finds a sub-optimal EL fair predictor using unconstrained convex programming tools.",
    "semantic links between new concepts and existing ones, we augment prior knowledge through either inductive learning or deductive learning as what humans do in meaningful verbal learning ( Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer,",
    "semantic links between new concepts and existing ones, we augment prior knowledge through either inductive learning or deductive learning as what humans do in meaningful verbal learning ( Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer,",
    "semantic links between new concepts and existing ones, we augment prior knowledge through either inductive learning or deductive learning as what humans do in meaningful verbal learning ( Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer,",
    "semantic links between new concepts and existing ones, we augment prior knowledge through either inductive learning or deductive learning as what humans do in meaningful verbal learning ( Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer, 2002 ; Mayer,",
    "3D point cloud analysis is a crucial topic in computer vision and graphics, and has wide applications in robotics Chen et al. ( 2019 ), autonomous driving Qi et al. ( 2018 ), autonomous driving Qi et al. ( 2018 ), and visual SLAM Hitchcox & Forbes ( 2020 ). To better understand the 3D shapes, effective point cloud analysis techniques and methods are in great demand. With the thriving of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D point clouds with layered operations, in contrast to low-level handcrafted",
    "3D point cloud analysis is a crucial topic in computer vision and graphics, and has wide applications in robotics Chen et al. ( 2019 ), autonomous driving Qi et al. ( 2018 ), autonomous driving Qi et al. ( 2018 ), and visual SLAM Hitchcox & Forbes ( 2020 ). To better understand the 3D shapes, effective point cloud analysis techniques and methods are in great demand. With the thriving of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D point clouds with layered operations, in contrast to low-level handcrafted",
    "3D point cloud analysis is a crucial topic in computer vision and graphics, and has wide applications in robotics Chen et al. ( 2019 ), autonomous driving Qi et al. ( 2018 ), autonomous driving Qi et al. ( 2018 ), and visual SLAM Hitchcox & Forbes ( 2020 ). To better understand the 3D shapes, effective point cloud analysis techniques and methods are in great demand. With the thriving of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D point clouds with layered operations, in contrast to low-level handcrafted",
    "3D point cloud analysis is a crucial topic in computer vision and graphics, and has wide applications in robotics Chen et al. ( 2019 ), autonomous driving Qi et al. ( 2018 ), autonomous driving Qi et al. ( 2018 ), and visual SLAM Hitchcox & Forbes ( 2020 ). To better understand the 3D shapes, effective point cloud analysis techniques and methods are in great demand. With the thriving of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D point clouds with layered operations, in contrast to low-level handcrafted",
    "We are the first to demonstrate that this tradeoff is not necessary in natural language generation : we can achieve the best of both ID and OOD performance by choosing one of two families of finetuning approaches : full finetuning or freezing most of the pretrained parameters during finetuning, in e.g., adapters ( Rebuffi et al., 2017 ; Houlsby et al., 2019a ), prefix-tuning ( Li & Liang, 2021 ; Lester et al., 2021 ), prefix-tuning ( Li &",
    "We are the first to demonstrate that this tradeoff is not necessary in natural language generation : we can achieve the best of both ID and OOD performance by choosing one of two families of finetuning approaches : full finetuning or freezing most of the pretrained parameters during finetuning, in e.g., adapters ( Rebuffi et al., 2017 ; Houlsby et al., 2019a ), prefix-tuning ( Li & Liang, 2021 ; Lester et al., 2021 ), prefix-tuning ( Li &",
    "We are the first to demonstrate that this tradeoff is not necessary in natural language generation : we can achieve the best of both ID and OOD performance by choosing one of two families of finetuning approaches : full finetuning or freezing most of the pretrained parameters during finetuning, in e.g., adapters ( Rebuffi et al., 2017 ; Houlsby et al., 2019a ), prefix-tuning ( Li & Liang, 2021 ; Lester et al., 2021 ), prefix-tuning ( Li &",
    "We are the first to demonstrate that this tradeoff is not necessary in natural language generation : we can achieve the best of both ID and OOD performance by choosing one of two families of finetuning approaches : full finetuning or freezing most of the pretrained parameters during finetuning, in e.g., adapters ( Rebuffi et al., 2017 ; Houlsby et al., 2019a ), prefix-tuning ( Li & Liang, 2021 ; Lester et al., 2021 ), prefix-tuning ( Li &",
    "generative models can be used to create noisy labels on unseen training data.",
    "generative models can be used to create noisy labels on unseen training data.",
    "generative models can be used to create noisy labels on unseen training data.",
    "generative models can be used to create noisy labels on unseen training data.",
    "minority groups. We propose a new and simple algorithm that explicitly encourages learning of features that are shared across various groups. We show that our proposed algorithm matches or achieves better performance compared to strong contemporary baselines including ERM and Group-DRO on standard benchmarks on both minority groups and across all groups. The key insight behind our proposed algorithm is that while Group-DRO focuses on groups with worst regularized loss, focusing instead on groups that enable better performance even on other groups, could lead to learning of shared/common features, thereby enhancing minority performance beyond what is achieved by Group-DRO. Empirically, we show that our proposed algorithm matches",
    "minority groups. We propose a new and simple algorithm that explicitly encourages learning of features that are shared across various groups. We show that our proposed algorithm matches or achieves better performance compared to strong contemporary baselines including ERM and Group-DRO on standard benchmarks on both minority groups and across all groups. The key insight behind our proposed algorithm is that while Group-DRO focuses on groups with worst regularized loss, focusing instead on groups that enable better performance even on other groups, could lead to learning of shared/common features, thereby enhancing minority performance beyond what is achieved by Group-DRO. Empirically, we show that our proposed algorithm matches",
    "minority groups. We propose a new and simple algorithm that explicitly encourages learning of features that are shared across various groups. We show that our proposed algorithm matches or achieves better performance compared to strong contemporary baselines including ERM and Group-DRO on standard benchmarks on both minority groups and across all groups. The key insight behind our proposed algorithm is that while Group-DRO focuses on groups with worst regularized loss, focusing instead on groups that enable better performance even on other groups, could lead to learning of shared/common features, thereby enhancing minority performance beyond what is achieved by Group-DRO. Empirically, we show that our proposed algorithm matches",
    "minority groups. We propose a new and simple algorithm that explicitly encourages learning of features that are shared across various groups. We show that our proposed algorithm matches or achieves better performance compared to strong contemporary baselines including ERM and Group-DRO on standard benchmarks on both minority groups and across all groups. The key insight behind our proposed algorithm is that while Group-DRO focuses on groups with worst regularized loss, focusing instead on groups that enable better performance even on other groups, could lead to learning of shared/common features, thereby enhancing minority performance beyond what is achieved by Group-DRO. Empirically, we show that our proposed algorithm matches",
    "We propose a method to extend any given univariate removal-based explanation to a bivariate explanation model that can capture asymmetric feature interactions, represented as a directed graph.",
    "We propose a method to extend any given univariate removal-based explanation to a bivariate explanation model that can capture asymmetric feature interactions, represented as a directed graph.",
    "We propose a method to extend any given univariate removal-based explanation to a bivariate explanation model that can capture asymmetric feature interactions, represented as a directed graph.",
    "We propose a method to extend any given univariate removal-based explanation to a bivariate explanation model that can capture asymmetric feature interactions, represented as a directed graph.",
    "We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-",
    "We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-",
    "We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-",
    "We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-making by observing physician behaviour, in a form of epistemology. We propose a transparent model of decision-",
    "AutoAugment ( AA ), a new DA paradigm, is proposed to automate the search of the optimal DA policies ( i.e. DA operation, probability and magnitude ) from the training dataset.",
    "AutoAugment ( AA ), a new DA paradigm, is proposed to automate the search of the optimal DA policies ( i.e. DA operation, probability and magnitude ) from the training dataset.",
    "AutoAugment ( AA ), a new DA paradigm, is proposed to automate the search of the optimal DA policies ( i.e. DA operation, probability and magnitude ) from the training dataset.",
    "AutoAugment ( AA ), a new DA paradigm, is proposed to automate the search of the optimal DA policies ( i.e. DA operation, probability and magnitude ) from the training dataset.",
    "A causal graph to model the generation process of adversarial examples and define the adversarial distribution to formalize the intuition of adversarial attacks.",
    "A causal graph to model the generation process of adversarial examples and define the adversarial distribution to formalize the intuition of adversarial attacks.",
    "A causal graph to model the generation process of adversarial examples and define the adversarial distribution to formalize the intuition of adversarial attacks.",
    "A causal graph to model the generation process of adversarial examples and define the adversarial distribution to formalize the intuition of adversarial attacks.",
    "Continuous Learning ( CL ) for each task. We propose to learn for each task a new filter subspace for each convolutional layer over a small set of filter atoms.",
    "Continuous Learning ( CL ) for each task. We propose to learn for each task a new filter subspace for each convolutional layer over a small set of filter atoms.",
    "Continuous Learning ( CL ) for each task. We propose to learn for each task a new filter subspace for each convolutional layer over a small set of filter atoms.",
    "Continuous Learning ( CL ) for each task. We propose to learn for each task a new filter subspace for each convolutional layer over a small set of filter atoms.",
    "( ii) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv)",
    "( ii) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv)",
    "( ii) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv)",
    "( ii) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv) underestimating the variance leads to failure in explaining the uncertainty of model ( iv)",
    "adversarial training are more likely to be non-robust ( i.e., the predicted labels of adversarial training are more likely to be non-robust than the predicted labels of adversarial training ).",
    "adversarial training are more likely to be non-robust ( i.e., the predicted labels of adversarial training are more likely to be non-robust than the predicted labels of adversarial training ).",
    "adversarial training are more likely to be non-robust ( i.e., the predicted labels of adversarial training are more likely to be non-robust than the predicted labels of adversarial training ).",
    "adversarial training are more likely to be non-robust ( i.e., the predicted labels of adversarial training are more likely to be non-robust than the predicted labels of adversarial training ).",
    "adversarial inputs can cause erroneous outputs. We propose a new statistical method called Robustness Measurement and Assessment ( RoMA ), which can measure the expected robustness of a neural network model. This method can be applied to large-scale black-box neural networks, which is a significant advantage compared to recently proposed verification methods. We apply our approach in two ways : comparing the robustness of different models, and measuring how a model \u2019 s robustness is affected by the magnitude of input perturbation.",
    "adversarial inputs can cause erroneous outputs. We propose a new statistical method called Robustness Measurement and Assessment ( RoMA ), which can measure the expected robustness of a neural network model. This method can be applied to large-scale black-box neural networks, which is a significant advantage compared to recently proposed verification methods. We apply our approach in two ways : comparing the robustness of different models, and measuring how a model \u2019 s robustness is affected by the magnitude of input perturbation.",
    "adversarial inputs can cause erroneous outputs. We propose a new statistical method called Robustness Measurement and Assessment ( RoMA ), which can measure the expected robustness of a neural network model. This method can be applied to large-scale black-box neural networks, which is a significant advantage compared to recently proposed verification methods. We apply our approach in two ways : comparing the robustness of different models, and measuring how a model \u2019 s robustness is affected by the magnitude of input perturbation.",
    "adversarial inputs can cause erroneous outputs. We propose a new statistical method called Robustness Measurement and Assessment ( RoMA ), which can measure the expected robustness of a neural network model. This method can be applied to large-scale black-box neural networks, which is a significant advantage compared to recently proposed verification methods. We apply our approach in two ways : comparing the robustness of different models, and measuring how a model \u2019 s robustness is affected by the magnitude of input perturbation.",
    "A hierarchical chunking model that learns representations from non-i.i.d sequential data from the ground up enables flexible transfer between environments that share partial representational structure.",
    "A hierarchical chunking model that learns representations from non-i.i.d sequential data from the ground up enables flexible transfer between environments that share partial representational structure.",
    "A hierarchical chunking model that learns representations from non-i.i.d sequential data from the ground up enables flexible transfer between environments that share partial representational structure.",
    "A hierarchical chunking model that learns representations from non-i.i.d sequential data from the ground up enables flexible transfer between environments that share partial representational structure.",
    "We introduce a novel neural reparametrization scheme, which generalizes preconditioning to non-linear optimization problems.",
    "We introduce a novel neural reparametrization scheme, which generalizes preconditioning to non-linear optimization problems.",
    "We introduce a novel neural reparametrization scheme, which generalizes preconditioning to non-linear optimization problems.",
    "We introduce a novel neural reparametrization scheme, which generalizes preconditioning to non-linear optimization problems.",
    "DCNNs prone to underfitting and requiring large training sets of examples for training.",
    "DCNNs prone to underfitting and requiring large training sets of examples for training.",
    "DCNNs prone to underfitting and requiring large training sets of examples for training.",
    "DCNNs prone to underfitting and requiring large training sets of examples for training.",
    "GNNs are still inefficient for training on extremely large graphs, due to the unique structure of GNNs and the limited memory capacity/bandwidth of current servers. One potential solution to tackle these limitations is employing distributed training with data parallelism, which have become almost a de facto standard for fast and accurate training for natural language processing ( Lin et al., 2021 ; Hard et al., 2018 ; Chiang et al., 2019 ; Chen et al., 2018 ; Zhang et al., 2018 ; Zhang et al., 2021 ).",
    "GNNs are still inefficient for training on extremely large graphs, due to the unique structure of GNNs and the limited memory capacity/bandwidth of current servers. One potential solution to tackle these limitations is employing distributed training with data parallelism, which have become almost a de facto standard for fast and accurate training for natural language processing ( Lin et al., 2021 ; Hard et al., 2018 ; Chiang et al., 2019 ; Chen et al., 2018 ; Zhang et al., 2018 ; Zhang et al., 2021 ).",
    "GNNs are still inefficient for training on extremely large graphs, due to the unique structure of GNNs and the limited memory capacity/bandwidth of current servers. One potential solution to tackle these limitations is employing distributed training with data parallelism, which have become almost a de facto standard for fast and accurate training for natural language processing ( Lin et al., 2021 ; Hard et al., 2018 ; Chiang et al., 2019 ; Chen et al., 2018 ; Zhang et al., 2018 ; Zhang et al., 2021 ).",
    "GNNs are still inefficient for training on extremely large graphs, due to the unique structure of GNNs and the limited memory capacity/bandwidth of current servers. One potential solution to tackle these limitations is employing distributed training with data parallelism, which have become almost a de facto standard for fast and accurate training for natural language processing ( Lin et al., 2021 ; Hard et al., 2018 ; Chiang et al., 2019 ; Chen et al., 2018 ; Zhang et al., 2018 ; Zhang et al., 2021 ).",
    "adaptive or dynamic inference ( Veit & Belongie, 2018 ; Wu et al., 2018 ; Wang et al., 2018a ) where the model decides how much to compute instead of adaptive or dynamic inference ( Veit & Belongie, 2018 ; Wu et al., 2018a ) where the model decides how much to compute instead of adaptive or dynamic inference ( Veit & Belongie, 2018 ; Wu et al., 2018a ) where the model decides how much to compute instead of adaptive or dynamic inference ( Veit & Belongie,"
][
    "This paper studies FL under local differential privacy constraints. They identify two major concerns in designing practical privacy-preserving FL algorithms: communication efficiency and high\u0002dimensional compatibility, and develop a gradient-based learning algorithm sqSGD that addresses both concerns. They improve the base algorithm in two ways: First, apply a gradient subsampling strategy that offers simultaneously better training performance and smaller communication costs. Secondly, utilize randomized rotation as a preprocessing step to reduce quantization error. ",
    "This paper studies a low communication algorithm for multivariate mean estimation in the federated learning setting with differentially private communication. The algorithm uses quantization and dimension subsampling (only reporting some coordinates of the vector) to lower communication and randomized rotation (essentially applying a random orthogonal matrix) to reduce quantization error. They then apply this algorithm to ERM, using it as a subroutine in SGD. They experimentally explore the behavior of their algorithm on a number of benchmark datasets. They consider how the performance changes as they vary epsilon, the discretization parameter and the number of epochs (in SGD). ",
    "The paper proposed a differentially private training algorithm for federated learning. The target is to achieve communication reduction while keeping differential privacy during training. The proposed algorithm adds a few new components to SGD, including a privacy mechanism, a random rotation to reduce quantization error, a gradient coordinate selection mechanism to reduce communication/computation. Experiments with high \\epsilon local differentially privacy guarantees are conducted. The proposed algorithm outperforms a baseline algorithm.",
    "This submission works on the neural machine translation problem. The authors extend the previous works on leveraging language statistics or prior knowledge (SMT model or whatever) in LSTM based NMT models in self-attention based NMT models, Transformer model. The authors propose two alternatives to incorporate prior knowledge, which are the word frequency information for the monolingual data and the prior translation lexicon information for the bilingual data. These resources are integrated into the hidden representations from the self-attention computations and then the two output hidden representations are gated together for upper computations. The experiments are conducted on two typical NMT datasets: WMT14 En->De and WMT17 Zh->En, the results show that the proposed method can improve the NMT model performances. ",
    "This paper proposes a method to introduce **prior knowledge** into Transformer-based sentence encoders, here in the context of neural machine translation (NMT). More concretely, the prior knowledge is represented in the form of a matrix $\\boldsymbol{M}$, where each row denotes a vector of prior knowledge associated with each word $x_i$. The prior knowledge matrix $\\boldsymbol{M}$ is then represented as a (key, value) pair that can be attended by the query matrix $\\boldsymbol{Q}$ (the same query matrix as used in the main NMT component) using a standard Transformer self-attention mechanism. This procedure results in a prior knowledge representation matrix $\\boldsymbol{PK}$, which is then combined with the standard Transformer encoder output using a simple gating mechanism. ",
    "This paper presents a method for introducing prior knowledge into Transformer models. More specifically, the authors propose to use an additional self-attention block to incorporate prior knowledge about the word frequency and translation lexicon and use a gating mechanism to combine its output with that of the standard sefl-attention block. Experiments are conducted using English-to-German and Chinese-to-English translation datasets, and the results show the effectiveness of the proposed approach.",
    "This paper proposes the game-theoretic model of Bayesian Stackelberg Markov Games (BSMGs), a generalization of Markov games, as a formalism for studying Moving Target Defense (MTD) systems, a type of defender-attacker game with applications to cybersecurity. An algorithm for finding the Stackelberg equilibrium in BSMGs, called Bayesian Strong Stackelberg Q-Learning (BSS-Q) is proposed, and an OpenAI Gym-style environment for testing the derived policies in particular MTD settings is introduced, which allows for empirical evaluation of the policies' effectiveness. The paper then shows experimental results supporting the BSS-Q algorithm's success at finding the Strong Stackelberg Equilibrium of BSMGs.",
    "This paper studies the problem of learning how to adapt the defense methods in the domain of cybersecurity. The paper proposes a new model called Bayesian Stackelberg Markov Games (BSMG) to capture the uncertainty of the attacker's types as well as their strategic behaviors. The authors design Bayesian Strong Stackelberg Q-learning that can converge to the optimal movement policy for BSMG. The empirical studies verify the support the theoretical results.",
    "This paper introduces a Bayesian Stackelberg Markov Game (BSMG) model that considers a defender\u2019s uncertainty over attackers\u2019 types when implementing defensive strategies. It also proposes to use a Bayesian Strong Stackelberg Q-learning method to learn defense policies by first simulating an adversary to obtain feedback of an attack and then computing the Bayesian Strong Stackelberg Equilibrium for the BSMG with a solver. In this way, this work relaxes the assumption that the defender knows attackers\u2019 types in existing game-theoretic models for moving target defense.",
    "This paper proposes a simple and effective technique to improve disentanglement by coupling the latent spaces of different VAE models. It builds on Duan et al. (2019)\u2019s proposed method to rank the representations of different models. By learning a VAE ensemble with linear transformations between the latent spaces and an additional \u201ccross-model\u201d reconstruction loss, the authors show that they can achieve significantly better disentangling.",
    "The authors introduce a novel VAE-based approach for unsupervised learning of disentangled representations of image data.  The approach trains an ensemble of VAEs along with pair-wise linear transformations between their latent spaces.  The objective includes the ELBO objectives for each VAE as well as two additional pressures:  (i) An L2 similarity objective that pressures samples from each VAE latent space to match under linear transformations samples from the other VAE latent spaces, and (ii) A cross-model decoding objective that encourages decoding accuracy of the linearly transformed latent samples.  The authors provide a theoretical argument that the linear transformations should learn to be orthogonal, and show some experimental results indicating that their model performs well compared to baselines when evaluated with an established disentangling metric.",
    "This submission proposes an ensemble framework to improve learning disentangled representations with Variational Autoencoders (VAEs). The approach builds on the assumption that entangled latent representations learned by VAEs show some \u201cuniqueness\u201d in their latent space structure, while disentangled representations exhibit some \u201csimilarity\u201d; an assumption corroborated by recent studies. On that basis, a VAE ensemble approach is proposed where several VAEs are connected through linear mappings between the individual latent spaces to encourage alignment of latent representations and thus disentanglement. A formal derivation of the framework is provided and the formal validity of the underlying assumption demonstrated. Furthermore, empirical evaluation of the proposed approach in comparison to the standard VAE, beta-VAE and FactorVAE on the datasets dSprites (main results, main text) and CelebA (appendix) is performed, yielding improved results on the FactorVAE disentanglement metric (all baseline methods considered) as well as the Distance to Orthogonality (DtO) metric (only standard VAE considered).",
    "The paper proposes an efficient way to automatically choose the best or most suitable pipeline for different datasets. The proposed method can accelerate the AutoML using a pre-trained meta module. In particular, the AutoML job of a new supervised learning task can be accomplished without model evaluations, namely zero-shot / real-time AutoML. The meta module is constructed as a graph structure in which each node represents a dataset used for meta-training. ",
    "The problem that the authors attempt to solve is to determine what ML pipeline will perform best on any new dataset, without incurring in the extra cost of actually running a large number of such pipelines, as is typically done in AutoML algorithms. The way this paper tackles the problem is to train a neural network that given a new dataset as input, will output a pipeline that is predicted to perform well on that dataset. This neural network is trained on other datasets, for which high performing pipelines are already known. Predicting a pipeline for a new dataset thus only require a forward pass through their NN.",
    "This paper presents a very interesting idea of utilizing the documentation for the data and the operators in the pipeline to generate meta-features for meta-learning. This is a very novel application of graph neural networks GNNs and language models for AutoML meta-learning. This view of meta-learning takes a very intuitive on a very high level. The use of the outputs of existing AutoML systems (such as auto-sklearn, TPOT, etc) is also very intuitive and well motivated. All these intuitive ideas are put together into a novel AutoML recommendation architecture making use of modern deep learning components.",
    "the paper investigates what neural networks learn when trained with gradient descent, in case parts of the inputs are only partially relevant to the output. The main claim is that GD is what prevents compositionality. In a set of synthetic experiments it is shown that indeed GD learns to use all information in the input, which results in poor generalization ood when only a subset of it was relevant.",
    "This work analyzes the effect of gradient descent training on the compositionality of the learned model. It is shown that the gradient descent would use all the available information, even when it is redundant to learn the mapping from input to the output. It is then argued that the gradient descent training has the bias against compostionality despite the model architecture. Experiments are conducted on three simple benchmarks to demonstrate that when gradient descent trained model would use redundant information and not generalize compositionally. ",
    "This paper addresses the effects of gradient descent methods onto compositionality and compositional generalization of models. The authors claim that the optimization process imposes the models to deviate compositionality, which is defined with conditional independence among random variables of input, predicted output and the ground-truth. Since compositionality is one of important features of human intelligence, it has been interested widely in the field of AI/ML such as vision, language, neuro-symbolic approaches, common sense reasoning, disentangled representation, and the emergence conditions of compositionality. As it has been not much focused on the relationship with optimizers, it is fresh and interesting. However, it is not easy to figure out the position of this paper from two reasons: (1) the definitions on compositionality in this paper are not so compatible with recent related works, which mostly consider certain structures in models [ICLR19, JAIR20] or representative problems such as visual reasoning [CVPR17] and Raven progressive matrices [PNAS17]. (2) The authors do not consider quantitative approaches such as compositionality [ICLR19] or compositional generalization [ICLR20]. ",
    "The paper proposes NeoEA, an approach that further constrains KG embedding with ontology knowledge. The paper first tries to summarize the existing embedding-based entity alignment methods, stating that most of the methods choose TransE as scoring functions. But their embedding features are not aligned well compared to the neural-based or composition-based loss function. The paper, therefore, solves this problem by developing a new NeoEA architecture which shows that adding a KG-invariant ontology knowledge can minimize such difference. The experiment shows the new constraints can improve state-of-the-art baselines.",
    "Entity alignment plays an important role in improving the quality of cross-lingual knowledge graphs. As one of the most important solutions, embedding-based methods aim at learning a semantic space where the unique entity cross knowledge graphs can have the closest distance. Most of research focus on entity-level granular, but discard the whole picture of embedding space of cross-lingual KGs. Besides the aligned entity pairs as the labelled data, this paper extended the labelled data with the conditional neural and basic axioms, which are actually sets of randomly selected entities or entities with the same relation type. Then the final objective is to align the cross-lingual knowledge graphs by both optimizing the distance of labelled entity pairs and neural axioms.",
    "In the paper, the authors propose to minimize the discrepancy between pairs of (conditional) neural axioms to align the embedding spaces of different KGs. This method is justified by the authors' study of all kinds of OWL2 properties. The author also studied the influence of margin $\\lambda$ on less constrained/long-tail entities. The authors conducted experiments by adding the proposed model on top of the best models for entity alignment. The results are mixed, but the proposed model improves the SEA and RDGCN consistently. ",
    "The paper proposed to adopt differentiable network architecture search (DARTS) for the co-design of the sensor (a lensless camera) and the deep model for visual recognition tasks, so as to maximize the accuracy and minimize the energy consumption. The key idea is to include the sensor configuration, in this case the phase mask of a lensless camera modeled as 2D convolutions, as additional parameters in architecture search.  The proposed method was evaluated on simulated data for a number of vision tasks (image classification, face recognition and head pose estimation), as well as using fabricated masks on a real world camera. The results demonstrated significantly increase recognition performance given the same energy level.  ",
    "This paper presents a method called SACoD to develop a more efficient CNN-powered Phlatcam. The proposed method optimizes both the PhlatCam sensor and the backend CNN model simultaneously.  That is, the coded mask in Phlatcam and neural network weights are regarded as learnable parameters. The coded mask (the optical layer) can be considered as a special convolution layer. As a result, it achieves energy saving, model compressing as well as good accuracy. Extensive experiments and ablation studies are presented to show the effectiveness of the method.",
    "SACoD presents a novel attempt to integrate the computational capabilities of a lensless imaging system, PhlatCam, with the search for the optimal convolutional neural network design for a given task. SACoD provides a framework which enables joint optimization of sensor and CNN resulting in IoT devices that achieve higher task accuracy\u2019s with limited resource budgets of a typical IoT system. The authors present a new an optical layer design that enables above described features. Detailed experiments comparing SACoD sensor + CNN with other baseline models covering past papers, demonstrate the superiority of SACoD\u2019s accuracy/efficiency curve over that of separately optimizing CNN arch or sensor/CNN joint-optimizations that do not vary network architecture. Additionally, ablation studies and results from measurements from actual phase masks fabricated help breakdown the accuracy/efficiency benefits of SACoD while analyzing the noise limitations of mask fabrication process.",
    "The authors introduce a novel method for non-negative matrix factorization for timeseries and apply it to longitudinal honey bee interaction data.  The model leverages consistency of individuals over time by forcing the factors (or rather, the residuals of the factors with respect to a global trajectory) to be linear combinations of a small set of temporal basis functions.  These temporal basis functions are functions of the bee\u2019s age.  In other words, the factor embedding of each bee is a vector of linear combinations of 16 learned basis functions of time.  Since all bees use the same 16 temporal basis functions, given these basis functions the lifetime embedding of each bee is encapsulated by a small matrix of numbers, namely the coefficients for the temporal basis functions for each factor (and in practice only two factors were significant, so each bee\u2019s life is embedded in 32-dimensional space).  There are a number of regularizations on the temporal basis functions and the embedding coefficients.",
    "The authors present a matrix factorization model to jointly characterize the lifetime interactions of thousands of bees over generations. The problem is fascinating as both a technical and scientific question and the modeling framework appears novel. Although not directly addressed, the authors appear to be trying to solve a *tensor* factorization problem, not just the special case of a matrix (which is of course a 2-d tensor). It would have been interesting to see results comparing their method with a non-negative variant of, say, PARAFAC/CANDECOMP or generalizations thereof. It would have at least have been appropriate to explain why or why not existing tensor methods are not appropriate.",
    "This paper proposes a NMF formulation ||A-FF^T||^2 where A and F are different types of information extracted from social datasets. In the honeybee example the authors highlight, A represents the spatial relationship between bees, and F encodes the age of the bees. The authors setup F to be decomposable into two types of embeddings, one which characterizes the group activity and the other which characterizes the individual activity. ",
    "Review: This paper proposes data augmentation methods for medical imaging(especially for accelerated MRI) based on the MR physics. The augmentation includes both pixel preserving augmentations/general affine augmentations on both real and imaginary values in the image domain. Then, the augmented images are transformed to k-space domain and the k-space data are down-sampled for the input data generation for the accelerated MRI task. They claim that how to schedule p(the probability of applying combinations of augmentation) over the training is important and the schedules from p=0 and increasing over epochs shows best results, experimentally.",
    "In this paper, the authors design a data-augmentation pipeline for the domain of MRI reconstruction (specifically, by proposing sensible guidelines for augmenting k-space data when learning image reconstructions, to preserve the noise characteristics of the image data). They show that this pipeline works as you might expect data augmentation to work: it boosts results for small training sets and becomes increasingly less effective as the training set grows. However, while the problem domain is of interest, there are issues with the presented work.  ",
    "This paper presents a method to use data augmentation to improve accelerated MRI reconstruction when the amount of training data is limited. This is an important problem since MRI data is expensive to obtain. Traditional image augmentation methods can't be applied directly for this problem because MR images are complex valued. Further, the applied transformations need to preserve the noise distribution, without which model performance degrades significantly.",
    "The novelty of the network structure is marginal. The decomposition way of feature is very common in computer vision. Just utilizing the latent vector of the encoder with only the comparator loss to decompose the feature into two feature types is limited. The authors should show the visual differences between these two feature types. The expression of the article is very clear, but some basic theories need not be explained in detail (Such in Section 3.4)",
    "This paper considers the problem of order learning, which learns an ordinal classification function. This paper proposes to learn separarted order-relavent and order-irrelavent latent representations to improve the performance of existing methods, which is a very interesting and promising idea. However, the approach lacks novelty and convincing theoretical guarantees, as well as not showing convincing performance even through the insufficient empirical evaluation.",
    "- It is well presented. The idea of splitting the encoding feature space into task related features and non-task related features is probably not new. But the use of it in estimating rank might be new and intuitively it makes sense to use it. They also propose an extension to the clustering algorithm using a repulsive term and propose MAP estimation algorithm to assign a rank based on the output probabilities of the comparator when the max possible rank is known.",
    "This paper presents RAPID, an exploration algorithm for procedurally generated environments. The paper introduces an exploration scores composed of a local and global score. The local score is computed per-episode, it is the fraction of distinct states visited during an episode, the global score keeps track of the exploratory effort of the agent over the whole training procedure.",
    "This paper presents an exploration method for procedurally-generated environments, RAPID, which imitates the past episodes that have a good exploration behavior. First, authors introduce exploration scores, local score for per-episode view of the exploration behavior, and global score for long-term and historical view of exploration. The authors use the weighted sum of these two exploration scores and extrinsic reward as a final episodic exploration score. They rank the state-action pairs based on episodic exploration score and train the agent to imitate behaviors with high score. In experiments, they show the results by comparing state-of-the-art algorithms in several procedurally-generated environments.",
    "This paper tackles the problem of improving exploration in deep RL for procedurally-generated environments, where state-of-the-art exploration techniques typically fail. In the proposed approach, called RAPID, each agent-generated episode is evaluated with respect to its local exploration score (for the given episode), global exploration score (across all previous episodes), and extrinsic reward obtained. Episodes with high scores are stored in a replay buffer, and a policy is trained via behavioral cloning on batches of state-action pairs from this buffer. This policy is also used to produce the agent-generated episodes.",
    "This paper focuses on improving zero-shot classification by reducing the bias of the classifier towards seen classes. The bias occurs since the embedding is trained with visual examples from the seen classes, while using only the attribute information from unseen classes for testing. Authors propose an isometric propagation network that build a graph in both visual and semantic space, performs some steps of propagation, and then uses the updated prototypes for training a classifier. They use attention to construct the graph and also use attention to regularize the graph edges between the two spaces to be isometric. Authors also propose to use an episodic training method to improve learning. ",
    "In this paper Zero Shot Classification is studied using prototypes. Each class is represented with a visual and semantic prototype, and at test time compared to a visual example + prototype for a(n unseen) test class. The most similar test class is chosen. In this work a novel method is proposed to construct the prototypes, which are trained in an episode learning setting. On various benchmarks the proposed method performs better than existing method for the generalized zero-shot classification task (seen + unseen) test classes.",
    "The authors propose a novel computational pipeline to tackle a well-known problem in zero-shot learning: although multiple visual instances are available for the classes and categories to be recognized, one and only one semantic embedding is available to describe the classes/categories while using side information like attributes or relevant textual information. To cope with that problem, authors learn visual and semantic prototypes which are then adopted to perform gradient descent over a graph in which the topological relationship among similar/dissimilar classes are preserved. In the experimental validation, the proposed method shows its superiority among a number of prior methods in zero-shot learning, including discriminative and generative methods. ",
    "This paper presents a HyperGrid Transformer approach to fine-tuning, where one takes a pre-trained transformer model and then modifies it by introducing hypernetworks that modify the 2nd FFN in each transformer block by generating additional weights conditioned on input. These hyper-networks are trained on all tasks in GLUE/SuperGLUE datasets simultaneously and are task aware through prefixing of a task specific token to input. This allows one to fine-tune only a small number of parameters and end up with a model that performs quite well on all tasks at the same time, not much worse than fine-tuning the entire transformer model on all of these tasks.",
    "The authors propose HyperGrid Transformers with a decomposable hypernet-work that learns grid-wise projections to specialize regions in weight matrices for different tasks. Usually, people would use different models to solve different tasks respectively. In this paper, the authors focus on using a single model to solve all tasks and it will save a lot of model parameters for natural language understanding. And the authors have done comprehensive experiments on GLUE and SuperGLUE, and prove that the proposed single model can achieve much better performance than baseline and competitive performance with multiple task-specific models.",
    "This manuscript presents a HyperGrid Transformer, which is engaged in learning a single model to account for multi-tasks in NLP. The core idea of HyperGrid Transformer is to learn task-conditional dynamic weights in a grid-wise manner in the feed-forward layers, where the weights are factorized in local and global components. This idea is simple, materializing the goal of reducing the parameter cost for the used multi-task network. However, the conducted experiments look nice, showing promising performance on GLUE/SuperGLUE. Therefore, from my point of view, this work is worthy of a publication at ICLR. ",
    "This paper proposed a novel adaptive data augmentation algorithm that produces random perturbations on the training dataset to train an imitation learning-based self-driving network. It starts with a sensitivity analysis of network performance under different types and levels of perturbations. And a novel automated perturbed training dataset selection mechanism is then proposed to improve the performance. Validation has been conducted over simulated data with both seen and unseen perturbation types. ",
    "This work proposes a new method to improve the generalization of ML models for the task of vehicle steering using a hybrid of data augmentation and adversarial examples. In a nutshell, the proposed method attempts to increase the accuracy of the model by dynamically adding a selection of candidate datasets during training. Each of these \u201ccandidates\u201d is created offline applying a transform (e.g. blur, distortion, and changes in color representation) to the original (base) dataset. During training, the method chooses among the K transformed-datasets those who minimize the mean validation accuracy and based on this selection the steering model is retrained. The approach is evaluated on a driving dataset.",
    "This paper presents an algorithm to improve the model generalization of the task of \"learning to steer\". First, the sensitivity of a baseline learning algorithm to degraded images in varying qualities caused by different factors is carried out. Some empirical insights are gained. Then, a new training algorithm is proposed to solve a min-max optimization problem, where the most difficult datasets are chosen and used for training at each iteration. Experiments are conducted to validate the effectiveness of the proposed method. ",
    "+ The paper proposes a general framework to deal with constraints in optimization problems using neural networks. In my opinion this is an important problem since there exists no standard method in many existing deep neural network frameworks to deal with constraints, which are also inapplicable even if the constraints are only slightly nontrivial. The paper proposes to deal with equality and inequality constraints differently which may be often easier in large scale settings.",
    "There has been an increase of works using deep neural networks to heuristically predict solutions to constrained optimization problems. However, these methods cannot generalize to arbitrary constraints.  In this paper, the authors propose a method to build neural networks that output vectors that satisfy hard equality and inequality constraints. They do this by first having the network predict the underdetermined part of the system defined by the equalities, then doing a series of gradient steps to project the solution onto the space delineated by the inequalities. They evaluate on synthetic quadratic programs and problems derived from a AC power flow application.",
    "This paper proposes a method to strictly enforce hard constraints during a neural network, without compromising differentiability. The method has two stages 1) From a smaller set of predicted variables, compute the remaining ones so that equality constraints are satisfied; 2) Take a few gradient steps (w.r.t soft constraint) in case inequality constraints are violated. They perform experiments on synthetic and also somewhat applied instances of quadratic programs. The results look very promising.",
    "The authors propose regularization-based pruning methods with the penalty factors uniformly increased over the training session. The first algorithm (GReg-1) sorts the filters by L1-norm and only applies the increasing regularization to the \u201cunimportant\u201d filters; the second one (GReg-2) applies the increasing regularization to all the filters. The experiments are very extensive and convincing to support the claimed contributions.",
    "The paper proposes a new pruning scenario using regularization to better prune the network. The scenario has two-component, the first one proposes a new pruning schedule that does not directly remove the neurons that need to prune from the network. It removes the neurons by adding an L2 regularization and makes the neurons that need to remove gradually decrease to zero. The second one gives the importance score to the neurons. It uses the L2 regularization and studies how the coefficient \\lambda of the regularization term can influence the weight change to derive the neuron's importance in the neuron network. By perturbing the penalty term to the converged network, the algorithm can get the Hessian information to score the neurons but uses less time than calculating the Hessian. The paper also shows many empirical results on various benchmarks to show their advantages when using the new schedule and scoring criterion during the pruning process. The result shows that their method can get better at a fast speed.",
    "This paper explores how the basic L2 regularization can be exploited in a growing fashion for better deep network pruning. The authors proposed two algorithms in this work: (1) The first (called GReg-1) is a variant of the L1-norm based filter pruning method [Ref1]. The important/unimportant filters are decided by their L1-norms. Later the unimportant ones are forced to zero through the proposed rising penalty scheme. (2) The second algortihm (called Greg-2) imposes the rising L2 regularization on all the filters. It is theoretically shown in the paper that this makes the parameters to separate to different degrees according to their local curvatures (ie, Hessian values). The method takes advantage of this by driving the weights into two groups with stark magnitude difference and then prunes by the simple L1-norm criterion.  The two methods are demonstrated effective on CIFAR10/100 and ImageNet benchmarks in the comparison with many state-of-the-art methods. ",
    "The paper investigates how and why planning might be beneficial in model-based reinforcement learning settings. To that end, the authors ask three questions on planning in MBRL: (1) How does planning benefit MBRL agents? (2) Within planning, what choices drive performance? (3) To what extent does planning improve generalization? In order to answer these questions, the authors investigate the performance of MuZero in a variety of learning challenges while systematically ablating the algorithm to find how each part of the algorithm effects the overall performance.",
    "This paper tries to disentangle the role of planning in model-based reinforcement learning with a number of different ablations and modifications to MuZero. Specifically, the authors analyze the overall contribution of planning by omitting planning from which it is originally used in MuZero, and investigate different planner settings that can drive performance. In addition, they check the generalization advantage of MBRL. Overall, the paper is well-written, and experiments are conducted appropriately. The results provide some insights that other researchers in the MBRL community can leverage for their future work. My major concern is the lack of direct ablation study that can clearly show the advantage of planning in providing a good learning signal. See the detailed comments below.",
    "This paper analyzes the role of planning in the model-based reinforcement learning agent, based on evaluating MuZero on eight tasks (i.e. Ms.Pacman, Hero, Minipacman, Sokoban, 9x9Go, Acrobot, Cheetah, and Humanoid), which have discrete action spaces. The conducted experiments show three major implications: (1) Of the three parts in which search is used (i.e. search at evaluation time, search at training time for exploration, and using search result as a policy target), the role of serving as a policy improvement target was most substantial. (2) Deep tree search did not make a significant contribution to performance, and a simple Monte-Carlo rollout could be performant enough for MBRL. Also, a too small or too large search budget can be harmful to the performance of the MBRL agent. (3) Search at evaluation time was helpful for zero-shot generalization especially when the model is accurate.",
    "The authors propose a generalization of Value Iteration Networks to unknown, potentially continuous state spaces. They describe a framework for leveraging a learned graph embedding model (TransE) in combination with a deep RL model and an execution model based on graphical message passing to perform a VI-like operation. The authors show improved performance compared to baselines on a grid-world task with a known MDP, as well as several simple continuous control environments and the Atari game Freeway.",
    "The paper tackles an open problem of the value-iteration-network-paradigm. The proposed method (XLVIN) has a conceptual edge over traditional value iteration networks in that it can be applied to continuous problems and problems where the state space is either too big or not fully known in advance. The experiments mostly succeed in making the case that XLVINs:",
    "This paper proposed a novel policy prediction model that combines self-supervised contrastive learning, graph representation learning and neural algorithm execution to generalize the Value Iteration Networks to MDPs. The method described in the paper is a combination of existing works in the literature but seems to work well in practice. The experiments evaluate multiple aspects of the proposed model (E.g. number of executor layers, etc.) and show significant performance improvement over the existing approaches.",
    "This paper investigates the problem of learning monotone read-once DNF formulas using convex neural networks. Specifically, the authors explore the distribution-specific PAC setting, where training samples are drawn independently according to the uniform distributions and are labeled according to a target monotone read-once DNF. The main contribution of this study is essentially empirical: convex neural nets, trained with GD for minimizing the cumulative hinge loss, converge to global minima for which neural units coincide with the monomials of the target DNF. This remarkable stability is corroborated by theoretical insights about global minima.",
    "In this paper the aim in to understand the inductive bias of neural networks learning DNFs. The focus is in convex neural networks and gradient descent. It is shown that under a symmetric initialization, the global minimum that gradient descent converges to is similar to a DNF-recovery solution. Further, experimental evaluation demonstrates that gradient descent can recover read-once DNFs from data. ",
    "The paper considers learning Boolean functions represented by read-once DNFs by using neural networks. The neural network architecture consists of a hidden layer with 2^D components, which is rich enough to express any Boolean functions. Given a whole 2^D instances of some read-once DNF, the authors showed that (1) weights corresponds to the true DNF is the global minimum of the loss minimization problem with the network, (2) they empirically observe that gradient descent with a rounding heuristics finds the true DNF expression, and(3) the solution of a 2-norm minimization recovers the true DNF.",
    "This work presents a strategy for improving exploration and efficiency of RL by leveraging the graph structure of an episodic experience buffer. This strategy combines goal-oriented RL with structured exploration. The authors compare their proposed technique to two popular benchmarks for goal-reaching tasks. In addition, the authors provide some theoretical justification for their algorithmic choices.",
    "This paper proposes a new framework, GSRL, to handle the sparse reward challenge and better leverage past experiences. Specifically, it formulates trajectories as a dynamic graph, and generates hindsight-like goals based on sub-group division and attention mechanism. The authors provide theoretical analysis to show the efficiency and converge property of their method. The experimental result shows the proposed method significantly outperforms the baselines. ",
    "This paper introduces Graph Structured Reinforcement Learning (GSRL) framework, able to balance exploration and exploitation in RL. Actually, GSRL builds a dynamic graph based on historical trajectories. Then in order to learn from sparse or delayed rewards and  be able to reach a distant goal, it decomposes the main task into a sequence of easier and shorter tasks. An attention strategy has also been proposed that is able to select an appropriate goal for each one of the easiest tasks. Experiments have been conducted on various robotics manipulation tasks showing that GSRL performs better compared to HER and MAP algorithms. ",
    "This paper concerns about the use of experience replay in a way that past experience is sampled based on (implicit) levels so as for the agent to better adapt to the current task at hand. The authors defined a replay distribution (where experience is sampled) based on two scores relevant to learning potential and staleness. Due to its formulation, the change of replay distribution can be used as an outer-layer of a learning algorithm without any modification of the underlying learning mode. The authors conducted experiments over a set of benchmark data sets relevant to level-ness and found statistically significant improvements over more than half of the tasks.",
    "The present work considers the problem of learning in procedurally generated environments. This is a class of simulation environments in which each individual environment is created algorithmically where certain environmental factors are varied in each instance (referred to as levels in this work). Learning algorithms in this setting typically use a fixed set of training and evaluation environments. The present work proposes to sample the training environments such that the learning progress of the agent is optimized. This is achieved by proposing an algorithm for level prioritization during training. The performance of the approach is demonstrated on the Procgen Benchmark and two MiniGrid benchmarks and the authors argue that their approach induces an implicit curriculum in sparse reward settings.",
    "This paper allows agents to set the initial conditions (level) for procedurally generated episodes during exploration to past observed values, and proposes to have agents form an intrinsic curriculum by resampling past levels based on a heuristic measure of expected learning progress. The authors test several heuristic measures and find that the average absolute magnitude of the generalized advantage estimate works well. The authors hypothesize that this intrinsic curriculum will improve optimization/learning relative to an agent that always samples initial conditions from the environment distribution. The authors verify that their prioritization strategy usually improves performance in several Progen Benchmark and MiniGrid environments, usually by a small but statistically significant amount, but sometimes by a large amount. ",
    "The work studies the auxiliary task selection in deep learning to resolve the burden of selecting relevant tasks for pre-training or the multitask learning. By decomposing the auxiliary updates, one can reweight separately the beneficial and harmful directions so that the net contribution to the update of the primary task is always positive. The efficient implementation is experimented in text classification, image classification, and medical imaging transfer tasks.",
    "Leveraging the power of the data-rich related tasks have been studied (e.g., pre-training and multitask learning). This paper points out that careful utilization of auxiliary task is required to gain enhanced performance in primary tasks. In order to prevent harming the performance of primary tasks, they suggest the method to decompose auxiliary updates into three directions which have positive, negative and neutral impact on the primary task.",
    "The authors present a general formulation of different settings in multitask learning (including pretraining regimes), in a setting where the goal is to get best performance for a pre-specified primary task and additional auxiliary tasks. The main idea is to divide the gradients on the auxiliary task into 2 subspaces: a subspace where the gradients influence performance of the primary task and a subspace where they only influence the auxiliary task without changing the loss on the primary task. Within the subspace that does have influence on the primary task, it is easy to compute directions that have a positive or negative effect on the primary task, which allows to create different learning schemes given the gradients that point toward: i) auxiliary influence only, ii) positive influence on auxiliary tass, iii) negative influence on primary task. Experimental results show improvements over previously identified meta learning methods on 2 natural language datasets and 3 image datasets.",
    "The authors use a 3D world to explore grounded language learning, in which an agent uses RL to combine novel word-learning with stably acquired meanings to successfully identify and manipulate objects.  They show that a novel, psychologically-inspired memory mechanism is more memory-efficient than Transformers (both of which outperform plain LSTMs) and that it exhibits surprisingly robust generalization to novel action-object pairs.  The results should be of interest to many working in grounded language / multimodal representation learning, and the experiments are thorough and well-motivated. ",
    "This paper presents experiments for acquiring words via fast-mapping in an embodied environment. The technical contribution is interesting and solid, but the experiments fail to address some important questions that are yet scoped by the claims of the paper (namely, that learning is being done -both- fast and slow, as per the title). Notably, the paper is really well-written and readable, and the experiments on novel category + novel instance recognition are really convincing specifically for fast-mapping (4.1).",
    "An agent following instructions in a grounded world is a core task in AI. This paper studies agent that accomplish this using memory-based architecture. This paper presents an argument for a multi-modal memory-architecture called DCEM whose key/queries and values are dependent on language and vision modalities respectively (or vice versa). An argument is made that this will be helpful for generalizing to novel language at test-time. Results are presented in a simple 3D domain containing several objects randomly sampled each time from a set of 30 objects. Task contain two types of instructions: \"pick up an object\" and \"place an object on another object\". Interaction proceeds in episodes where each episode contains a discovery phase where the agent learns the phrase associated with each object, and an instruction phase where the agent solves a given instruction. The proposed DCEM model outperforms baselines on various metrics and ablation. Importantly, it is shown that the DCEM can generalize to novel object names. ",
    "The paper analyses the effect of class imbalance on few-shot learning problems. It draws a number of interesting (but kind of expected) conclusions e.g., the support set imbalance has a larger influence on the FSL performance compared to base class imbalance, a high impact of imbalance on gradient-based meta-learning methods compared to metric learning approaches. The paper is overall  ",
    "The authors present a detailed study of few-shot class-imbalance along three axes: dataset vs. support set imbalance, effect of different imbalance distributions (linear, step, random), and effect of rebalancing techniques. The authors extensively compare over 10 state-of-the-art few-shot learning methods using backbones of different depths on multiple datasets. The analysis reveals that 1) compared to the balanced task, the performances of their class-imbalance counterparts always drop, by up to 18.0% for optimization-based methods, although feature-transfer and metric-based methods generally suffer less, 2) strategies used to mitigate imbalance in supervised learning can be adapted to the few-shot case resulting in better performances, 3) the effects of imbalance at the dataset level are less significant than the effects at the support set level. ",
    "This paper conducts extensive comparison experiments to study the effect of class-imbalance for many few-shot approaches. A detailed study of few-shot class-imbalance along three axes: dataset vs. support set imbalance, effect of different imbalance distributions (linear, step, random), and effect of rebalancing techniques, are presented. Also, this paper is clearly written and easy to understand. ",
    "The paper proposes Polynomial Graph Convolution (PGC), which enjoys a larger-than-one-hop receptive field within a single layer. This is done by first propagating information with a fixed (not learned) propagation matrix (e.g. adjacency matrix or graph Laplacian), and then projecting the information from different topological distances with a learned linear layer. PGC is shown to be theoretically more expressive than linearly stacking simple graph convolutions; experiments on several graph classification tasks show good performance.",
    "This work proposes the Polynomial Graph Convolutional Networks (PGCNs), which is built upon the Polynomial Graph Convolution (PGC). The PGC is able to aggregate k-hop information in a single layer and comes with the hyper-parameter k. The PGCNs are composed of a PGC with k=1, followed by a PGC with a chosen k (usually > 1), and a complex readout layer using avg, max, and sum over all nodes. Theoretically, the proposed PGC has two major benefits as claimed: 1) Common graph convolution operators can be represented as special cases of the PGC; 2) A PGC with k = q (q > 1) is more expressive than linearly stacked q PGCs with k=1. The PGCNs are thus more general, expressive, and efficient than existing GNNs. Experimental studies are conducted on common graph classification benchmarks, showing the improved performances of the PGCNs.",
    "The article presents a novel framework for Graph Convolutional Neural Networks (GCNs). The method called  Polynomial Graph Convolution (PGC) is based on concatenating the powers of a transformed adjacent matrix in a given layer. The paper shows that various popular variants of GNNs can be expressed using the PGC framework.  Theoretical results presented show that PGC with higher degree is more expressive that deeper std. GNNs. Numerical results are presented on graph classification task that illustrate the performance of the method.",
    "This paper introduces a framework to utilize the synthetic data as augmentations in the scene graph generation task, which is able to narrow the domain gap by decomposing it into several discrepancies between the two domains. They are the first to propose the synthetic-to-real transfer learning for SGG. The experimental results show the Sim2SG can improve the baseline models in three different scenarios: CLEVR, Dining-Sim, and Drive-Sim.",
    "The paper addresses the problem of learning scene graphs from synthetic data and unlabeled real data while performing well on real data by narrowing the content and appearance gap between the two domains when training on synthetic data. Scene graphs are extracted in a two-step process, mapping input to an intermediate latent space and generating the final prediction from the latent space. The authors decompose the content gap into two components: (a) label discrepancy, i.e. how much do the label distributions between the two domains differ, and (b) prediction discrepancy, i.e. the difference in distributions of outputs predicted from the latent space for the two domains. They further model the appearance gap by aligning the latent representation for both domains after accounting for the content gap (to avoid spurious influence of differing content distributions as the latent space is expected to comprise content and appearance). Most of these components are intractable and the paper provides approximations. Empirical investigation on two entirely synthetic and one real/synthetic data set provide evidence for the benefit of the method in closing the posed domain gaps as well as the quality of chosen approximations, the influence of the individual content and appearance gap terms, and the effectiveness of the optimization procedure.",
    "The paper tackles the problem of sim2real transfer for scene graph inference. It proposes an approach for closing the gap between simulated training data and real test data, to allow models trained purely on simulated data to be deployed on real images. The approach is tested on multiple environments, including transfer from a driving scene simulator to real KITTI scenes.",
    "This paper proposes Randomized Ensembled Double Q-Learning (REDQ), a new model-free RL algorithm that aims to improve the sample efficiency over existing model-free methods. Experiments on Mujoco show that REDQ achieves better sample efficiency than popular model-free methods such as SAC and is comparable with model-based methods such as MBPO. The paper further provides extensive ablation studies that justify the necessity of the algorithmic components in REDQ and show that improved Q estimation bias may have been the key reason for the performance gain. The paper also provides some theoretical analysis of the Q estimation bias.",
    "The paper proposes three techniques that altogether greatly improves the performance of soft actor-critic (SAC), resulting in a new algorithm called REDQ. (1) A higher update-to-data ratio, which speeds up the critic update. (2) Using the average ensemble Q for the policy gradient, therefore reducing its variance. (3) Taking the min of a small subset of the ensemble Qs to compute the target Q, therefore reducing the Q bias. The paper also performs extensive ablation studies to prove the importance of each technique.",
    "This work proposes a modification for double Q-learning, termed as randomized ensembled double Q-learning (REDQ). REDQ maintains $N$ different Q functions, and for each update, the target value is a minimization over $M$ randomly chosen Q functions, where $1 \\le M \\le N$. In addition, REDQ adopts a high update-to-data ratio to improve the sample efficiency. Empirical results show that the proposed method outperforms state-of-the-art model-based algorithms in certain tasks with continuous action space.",
    "The method introduces the DIDA architecture to learn from distributions and be invariant to feature ordering and size.  The authors extend the ideas proposed by Maron et al. (2020) to the continuous domain and generalize their results.  The experiments are done on two tasks.  The patch identification (out-of-distribution test) clearly show the invariance to feature and dataset size. Nevertheless, it is not clear whether the method is invariant to feature permutation.  The performance model task shows properties of the architecture to predict global structures of the dataset within their meta-features.",
    "The paper presents a neural network layer designed to process distribution samples that is invariant to permutations of the samples and the features. The proposed method is compared empirically to DSS, which achieves the same types of invariance but is restricted to point sets rather than discrete or continuous probability distributions. The two tasks used for the empirical evaluation in the paper are: a) patch identification (are two blocks of data extracted from the same original dataset?) and b) model configuration assessment (is one configuration of a learning algorithm going to produce a more accurate model for a particular dataset than another one?). On the first task, the paper compares to models built using Dataset2Vec embeddings as well as DSS. On the second task, the paper compares to handcrafted features as well as DSS. In both tasks, the proposed method produces more accurate predictors than DSS, etc. The paper also has some theoretical results regarding the universality of the proposed architecture and its robustness w.r.t. Lipschitz-bounded transformations. ",
    "This paper proposes a novel set/distribution representation architecture DIDA, which leverages pairwise embedding of the set\u2019s elements. The method can be used to represent discrete and continuous distribution representation. The authors also provide the theoretical proofs of the universality of the invariant layers, the local consistency. The experiments show that the architecture improves some dataset representation tasks",
    "This paper studies ways of adding edges to graphs to improve the result of spectral embedding / clustering. It refines existing embeddings using by measuring edges' effect on Laplacian eigenvalues, and adjusting such edges to reduce the distortions. The performance of the algorithm is justified using developments of worst-case efficient algorithms for Laplacian matrices, and experimentally, the algorithm converges quickly when starting with nearest neighbor graphs, and leads to significant increases in accuracy.",
    "The paper proposes a graph learning method for spectral embedding and associated problems such as clustering and dimension reduction. What differentiates the method from much the existing literature is that it focuses approximating an optimal densification of a very sparse initial graph rather than on sparsification of an initial graph, as is more common. The method is based on iteratively identifying edges to add to the graph so as to best improve the corresponding spectral embedding, so called \"spectrally critical\" edges. The authors motivate spectral criticality in relation to the partial derivatives of an objective function inspired by the log-likelihood of a Gaussian graphical model. In particular, those with the highest partial derivatives will tend to be those which, through their addition to the graph, lead to the greatest increase in this objective. The authors go on to discuss a close connection between spectral criticality and distance distortion when comparing the spectral embedding and the original input space. Since the initial graph is very sparse it can be efficiently determined, and the relatively small number of additional edges which need to be added by the proposed method to obtain a high quality embedding means that the entire procedure can be implemented efficiently.",
    "and significance: Learning a graph from data is an important, yet less studied, problem. The proposed algorithm (GRASPEL) is based on a graphical Lasso formulation with the precision matrix restricted to be a graph Laplacian. The algorithm starts with a sparse kNN graph, and recursively adds critical edges (identification of these critical edges based on Lasso and spectral perturbation analysis is the main contribution of the paper). ",
    "This paper proposes a method for combining intrinsic motivation on a state space with goal-conditioned reinforcement learning (GCRL), where goals are defined in some \u201cperceptual space,\u201d such as text or images, which describe the current state. The authors assume access to a renderer that maps states to perceptual goals, but do not assume that the renderer is differentiable. The authors propose to train an intrinsically motivated latent-conditioned policy, using similar techniques as past work in which a policy maximizes the mutual information between a latent variable and the current state. The goal-conditioned policy is then trained to effectively imitate the latent-conditioned policy by maximizing the same reward as the latent-conditioned policy, conditioned on only the rendered version of the final state reached by the latent-conditioned policy. The authors demonstrate that the overall method outperforms past GCRL methods on a variety of tasks (Atari, MuJoCo manipulation and locomotion, and toy tasks).",
    "This paper proposes an unsupervised learning objective for learning perceptual goal-conditioned policies. The goal is to enable unsupervised discovery of high-level behaviors in tandem with a perceptual-goal conditioned policy that can achieve these behaviors. The learning proceeds by training one policy to exhibit diverse behaviors; the states induced by these behaviors are then rendered and used as target goal states for a separate goal-conditioned policy.",
    "This paper proposes a new solution to the problem of learning goal-conditioned policies without hand-crafted rewards. Prior work in this domain learn an embedding space to compute reward between current state and goal. In contrast, this paper utilizes unsupervised skill discovery from [1] to obtain a discriminator that identifies which states belong to a particular skill. Then, the final state of a given skill's execution is used as a goal input to a goal-conditioned policy, which is rewarded if it generates states that the discriminator identifies with this skill. The paper aims to validate the benefit of such a reward over other embedding-distance based reward functions on a variety of environments.",
    "In many real world applications for RL such as medicine, there are limits on the number of policies from which we can simulate data. This paper proposes an approach that adaptively decides when to update the simulation policy, based on the difference between it and the current learned policy. Experiments on a medical treatment environment and Atari show that the approach obtains similar performance to on-policy RL with fewer changes of the simulation policy.",
    "In the RL context, this paper aims at designing a generic solution for reducing the number of policy switches during training (called switching cost) while maintaining the performance. This study is done in the context of deep reinforcement learning. A few generic baselines solutions are provided as well as a more complex solution that empirically outperforms the baselines.",
    "This paper studies RL with low switching cost under the deep RL setting. It points out several naive algorithms like switching after a certain number of steps and then propose a new heuristic. This heuristic learns a new policy offline using the experience replay the behavior collected and switches the behavior policy once the similarity of the feature embeddings of the current state by these two policies becomes large. The paper also makes an attempt to provide a theoretical justification for a better understanding of the heuristic. This method might outperform the naive algorithms by some margin, if any. It would be a more interesting manuscript if some stronger results could be provided from the perspective of any of theory, experiments, or applications.",
    "This paper proposes homotopy SGD (H-SGD) which solves a sequence of unconstrained problems with a homotopy map and homotopy parameter. The authors analyze the algorithm for solving nonconvex problems satisfying PL condition. The analysis works with a generic homotopy map and homotopy parameter satisfying certain conditions (given in Sec 3.1). The authors show linear convergence to a neighborhood of the minimizer. The theoretical results are validated with experiments with clear explanations.",
    "This paper proposed a Homotopy-Stochastic Gradient Descent (H-SGD) algorithm by applying homotopy strategy to explore the nice local structures of problems. H-SGD can gradually approximate to the target objective function and enjoys a global linear convergence to reach a neighborhood of a minimizer. As verified by the author, the assumption of this paper is weaker than its predecessors, Karimi et al., 2016; Vaswani et al., 2019. Further, the numerical experiments verified the effectiveness of H-SGD on regression and classification tasks.",
    "1. It seems to me the proposed Homotopy-SGD is not a practical algorithm, as in each iteration the algorithm has to solve a nontrivial (possibly nonconvex) subproblem. In other words, each subproblem can be as difficult as the original problem. This leads to an essential question that what is the practical motivation of this algorithm?",
    "This paper proposes a way of reconstructing a surface from sparse point clouds via a \"meta learning\" approach. Specifically, the authors view each shape in a collection as a \"domain\", and predicting the SDF values of points in R^3 to reconstruct a given shape (the reconstructed surface is the isosurface of the SDF field) as the \"task\" for that domain. Then, they use a network to predict a distribution over \"task-specific\" latent vectors that characterizes the reconstruction task for a given shape. Given a latent-vector sampled for one shape, they pass it to a decoder that predicts the SDF value at any point in R^3 for that shape.",
    "This paper introduces a meta-learning approach for the neural implicit representation of 3D shapes. The main idea, in my understanding, is to consider the points in the input point cloud as few-shot examples of the object so that each of them can be encoded in a way to best approximate the entire object information. The experiments show that the network can reconstruct the entire shape well even with a very small number of the input points, such as 50 and 100. For better reconstruction, the authors also proposed to use some implicit function regularizations, which are introduced in a previous work (Gropp et al., 2020).",
    "This paper tackles the task of point cloud completion, aiming to infer an implicit occupancy representation given a sparse input point cloud. Following recent practices, the approach represents the shape via a latent-variable conditioned occupancy function $f_{\\phi}(x, h)$ that infers occupancy of a point $x$ given latent $h$. The central task addressed here is to be able to infer a posterior distribution over the latent variable given some observed points $D$ i.e. $p_{\\theta}(h|D)$.",
    "This paper studies the use of channel suppression in improving robustness to adversarial examples. The authors make a convincing illustration in section 3 on how adversarial examples tend to activate more channels compared to natural examples, and adversarial training is not effective in reducing them. This provides a convincing motivation to their design of the Channel-wise Activation Suppression (CAS) module. Their CAS module is also effective in improving adversarial robustness when used in conjunction with different adversarial defense methods, including adversarial training, TRADES, and MART. ",
    "This paper investigates the adversarial robustness from the activation perspective. Specifically, the authors analyzed the difference in the magnitude and distribution of activation between adversarial examples and clean examples: the activation magnitudes of adversarial examples are higher and the activation channels are more uniform by adversarial examples. Based on the above interesting findings, the authors claim that different channels of intermediate layers contribute differently to the class prediction and propose a Channel-wise Activation Suppressing (CAS) method to suppress redundant activations, which can improve the DNN robustness. ",
    "The authors studied the behavior of adversarial examples from the channel view of activations, which is very novel. They focused on the magnitude and frequency of activations and found that state-of-the-art adversarial defense (adversarial training) only addressed the magnitude issue but the frequency distribution issue remains. This provided a novel perspective for us to understand why state-of-the-art adversarial training method works to a certain extent but not so good. Then, the authors proposed a Channel-wise Activation Suppressing (CAS) to address the frequency distribution to further improve the adversarial robustness. CAS is generic, effective, and can be easily incorporated into many existing defense methods. ",
    "This paper studies the optimization and generalization properties of a two-layer linear network. The considered setting is over-parameterized linear regression where the input dimension is D, number of samples is n<D, and the target dimension is m. The hidden width is h. The paper has two main results. The first result is exponential convergence of gradient flow to global minimum, where the convergence rate depends on the (m+n-1)-th singular value of an \"imbalance\" matrix. The second result shows that the solution found is close to the minimum L2 norm solution if certain orthogonality assumption is approximately satisfied at initially; then it was shown that if the width h is sufficiently large, then under a random initialization scheme, the solution found is close to the minimum L2 norm solution with a distance $1/\\sqrt{h}$.",
    "This paper analyzes the convergence of gradient descent optimizing overparametrized linear nn, and proves a exponential convergence rate. Moreover, the paper proposes the distance of the optimizer to the smallest norm solution, which is justified in other papers such as Montanari, etc. as the generalizable solution. Thus the solution that SGD outputs has good generalization as well.",
    "This paper proves the convergence rate of gradient flow for training two-layer linear networks. In particular, this paper discusses the connection between initialization, optimization, generalization, and overparameterization. The results show that gradient flow can converge to the global minimum at a rate depending on the level of imbalance of the initialization. Moreover, the authors show that random initialization and overparameterization can implicitly constrain the gradient flow trajectory to converge to a point lying in a low-dimensional manifold, thus guarantees good generalization ability.",
    "The paper shows that the kernel derived from deep fully-connected networks on the sphere have the same approximation properties as their two-layer counterpart for ReLU activations. This implies the limitations of the kernel framework for studying the benefits of such deep networks. The authors derive the asymptotic eigenvalue decay of dot-product kernels from differentiability properties of the kernel function.",
    "This paper analyzed the expressive power of kernels by studying the reproducing kernel Hilbert space (RKHS) associated with the kernels. Specifically, the authors analyzed the eigenvalue decays in terms of the power series expansions of the kernel function around some points, which is related to the RKHS of the kernel. This analysis can be used to recover some previous results. Besides, using this analysis, the authors have shown several interesting results, including that NTK (which corresponds to fully-connected ReLU networks with infinite width, small learning rate, and proper initialization) with any depth has the same RKHS. The main result also has other corollaries about other kinds of kernels, e.g., Laplace kernel and infinitely differentiable kernels. Experiments were done to validate the theoretical results on synthetic datasets and MNIST/Fashion-MNIST.",
    "Recently, there are a large number of deep learning theory papers related to the property of neural tangent kernel. This paper shows that for ReLU, the kernels derived from deep fully-connected networks have the same approx. properties as their shallow two-layer counterpart. This highlights the limitation of the kernel framework for understanding the benefits of deep networks from such perspective.",
    "The authors propose a deterministic policy-gradient algorithm that extends the TD3 algorithm (Fujimoto 2018). The main claim is that it reduces overestimation issues in a more effective way. Two Q-critics are maintained with separate parameters, but updated using the same transitions. Then a convex combination of these critics is used in the deterministic policy gradient update. The mixture parameter is learned on a slower time-scale to minimize this convex combination over states (instead of taking the minimum of the 2 critics per batch as in TD3). Another contribution in the paper is the \u201cUnbiased\u201d variant of the algorithm (UAD3), which addresses the off-policy nature of the replay mechanism of the AD3 algorithm described above. My understanding is that this is simply a version of the algorithm that does not use any replay mechanism and samples the state iid from the on-policy distribution, so it isn\u2019t a novel idea in itself.",
    "This paper proposes new value-based deep reinforcement learning algorithms (AD3 and UAD3) to address the overestimation bias issue of Q learning. The main contributions of this paper are three folds: 1) The authors propose a weighted sum of two state-action value functions that are trained separately. Then, it is used to update the policy. 2) The mixing weights are updated by the two-step separation method. 3) The original method (AD3) is integrated with the idea of unbiased DRL (Zhang and Huang, 2020). ",
    "The paper presents an approach to mitigate the overestimation issue, which is quite common in RL algorithms whenever computing boostrap target is needed. The key idea is to introduce a weight parameter between two Q values and adopt a dual problem formulation to learn this weight and the policy parameters. The authors propose a two-step method to estimate these parameters and present some experiments to show the proposed algorithm's performance.",
    "The authors proposed inverse reinforcement learning (IRL) algorithm based on Monte Carlo expectation-maximization (MCEM) that maximizes the predictive distribution of trajectories given the reward distribution parameter (eq (1)). In my understanding, the knowledge of the environment dynamics is assumed. The authors tried to validate the proposed idea on objectworld (Levine et al., 2011)",
    "The authors propose an approach to model-based inverse reinforcement learning which estimates a Gaussian mixture model over reward-function parameters. The method uses MCEM and samples reward functions from a current estimate of the GMM, updates them via a gradient-descent based maximum likelihood approach and then updates the GMM to fit the updated parameters. The authors evaluate the approach on objectworld.",
    "The paper proposes a novel method for inverse reinforcement learning: inferring a (distribution over) reward functions from a set of expert demonstrations. Prior work has either learned a point-estimate, notably maximum entropy IRL, or used Bayesian methods to learn a probability distribution over reward functions. Maximum entropy IRL has scaled to complex environments with unknown dynamics and non-linear rewards (with methods such as AIRL), but do not learn a probability distribution. By contrast, Bayesian IRL is more theoretically principled, but has not scaled to complex environments or non-linear rewards. This paper performs maximum likelihood estimation of a parameter for a *generative model* over probability distributions, using a Monte-Carlo expectation-maximization (MCEM) method. It therefore still outputs a probability distribution like Bayesian IRL, but is able to learn non-linear rewards unlike prior Bayesian methods.",
    "of the paper: The paper gives a theoretical justification of self-training. It proposes a new notion of \"expansion\" - the amount of data distribution in the neighbor of an example. Here the neighbor means adding perturbations to the example, or augmentations of the example. When the label distribution satisfies nice expansion properties and that classes are properly separated according to the neighbors, the paper proves distributional guarantees of self-training. Combining with generalization bounds of DNNs, the paper also derives finite sample bounds for DNNs. The paper also verifies the expansion assumption via experiments using a GAN.",
    "This work provides a unified framework to analyze the self-training, semi-supervised algorithms. The key assumptions are 1) the \u201cexpansion\u201d assumption which characterizes the low-probability data subset must expand to a neighborhood with large probability; and 2) the neighborhoods of samples from different classes have small overlap.  Then the authors established the upper bound of the prediction error on the population when minimizing the self-training and input-consistency based loss on the population. They also extend their results to a finite-sample setting and semi-supervised setting as well.  ",
    "This paper provides a theoretical analysis of self-training for semi-supervised learning, unsupervised domain adaptation, and unsupervised learning. The authors propose a novel assumption that they dub _expansion_ to effect this analysis. The expansion assumption requires that the neighborhood of small sets have a class conditional distribution that is large. Under this assumption, the authors show population results for an algorithm that performs self-training under the objective that enforces input consistency. ",
    "This paper proposes a VAE based hierarchical model for video prediction. The model employs recurrent model to predict intermediate representations (in the form of label maps) and these representations are mapped to pixel level information, i.e., videos. The paper presents an interesting idea of using representations that do not use any domain knowledge. The authors demonstrate the value of modeling temporal evolution of these representations which enables long term video prediction.",
    "The paper extends video-to-video translation model of (Wang\u201918) to video prediction by first generating a sequence of segmentation masks and then translating them into videos. Variational video prediction is used to generate a sequence of segmentation masks. The model produces impressive high-resolution and long-horizon results, and is extensively evaluated on Kitti, Cityscapes, and dancing data, outperforming some previously proposed methods.",
    "This paper proposes a hierarchical framework for long-term video prediction. The structure is firstly predicted in the form of semantic map. It lies in a categorical structure space which is easier to predict. Then the authors translate the predicted semantic map to a real video sequence in a frame-by-frame manner. The proposed model is \"surprisingly successful\" for long-term video prediction, as claimed by the authors (thousands frames). ",
    "This work proposes a new graph neural network architecture with modified rules for message passing, Iterated Graph Neural Network System (IGNNS). The paper then provides a theoretical analysis of the proposed architecture by connecting it with Iterated Function System (IFS), an important research field in fractal geometry. This paper further demonstrates empirically that the proposed architecture outperforms related models on citation network datasets.",
    "This paper proposes a new framework of GNN which can deal with undirected and directed graphs in a unified way. The authors argue that the size of the symbol space for a message passing path with length n is 2^n, while previous architectures only have constant size. Motivated by this observation, the authors borrow ideas from Iterated Function System to augment the symbol space. ",
    "The paper proposes a new definition of GNNs designed to cope with bi-directional message-passing processes.  To do so, a new symbols space, different from the one adopted by Bidirectional GCN,  is considered, together with an iterated function system. These lead to an architecture composed of 4 steps: an input layer that acts as a classic FC layer; an IFS layer that applies the iterated function system considering the adjacency matrix; a layer to concatenate or sum the expected values of each iteration; and an output layer that combines the results using the functions of the IFS and a new learnable weight matrix.",
    "The paper investigates graph generation using adversarial technics. They introduce an algorithm named GG-GAN, based on Wassertain GAN, in order to accurately generates new graphs in hopefully the same distribution as a given dataset. GG-GAN generates points in an euclidian space that is then turned into a graph using a similarity function on the space. This approach is justified by Theorem 1. The authors show that their method successfully generate graphs within the same scope as the input dataset, and show that GG-GAN generates much more new graphs that current state of the art approach.",
    "In general, this paper deals with an interesting and essential problem to generate geometric graphs under several standards. The whole algorithm seems easy to implement or reproduce. It seems with minor modifications to traditional autoregressor based generative graph models, the proposed framework can effectively model isomorphism as well as delivers certain novelty. The idea of the paper is with novelty and some theorems can support the observations.",
    "The work proposes to use WGAN architecture to learn latent space for generating new graphs with similar properties to the original ones. The authors show that their model is capable to control a probability of each new generated graph. Moreover it\u2019s equivariant function which ensures that isomorphic graphs have the same probability to be generated. These properties are desirable  if we want to generate efficiently new graphs with properties similar to the graphs in the training set.",
    "The paper proposes an approach to explainable supervised learning by extracting sets of rules for two individual layers within a neural network. The authors build their work on recent published work for patttern-based rule mining [0] to efficently find so-called robust rules. The authors evaluate the approach for image processing tasks with convolutional neural networks on MNIST, ImageNet and Oxford Flower by comparing generated rules against activation maps and prototypes.",
    "This paper proposes to extract interpretable rules from a learned neural network. The authors claim that they are the first to propose rules connecting 1) multiple neurons together, and 2) do this at a dataset level. Their approach relies on using minimum description length and well known principles from the data mining community (e.g., downward closure lemma of apriori algorithm). The authors claim that experiments conducted on image data shows that their approach leads to more faithful, interpretable rules than other approaches such as prototyping or model distillation.",
    "The authors propose a method to explore how neurons interact within a neural network and derive rules of interactions that can help interpret the inner workings of the neural network and open up the black box. The algorithm, EXPLAINN, identifies rules between successive layers where each rule represents a set of neurons that are activate simultaneously and conditionally based on the previous layer. Minimum Description Length principle is used to derive an objective that minimizes the number of bits used to encode the rules. The rule sets are identified using a greedy heuristic and improved until convergence of the objective. The algorithm is then evaluated to demonstrate the interpretation of images with MNIST, GoogLeNet and VGG-S. ",
    "The paper proposes a theoretical framework for analyzing the error of reinforcement learning algorithms in a fixed dataset policy optimization (FDPO) setting.  In such settings, data has been collected by a single policy that may not be optimal and the learner puts together a model or value function that will have explicit or implicit uncertainty in areas where the data is not dense enough.  The authors provide bounds connecting the uncertainty to the loss.  They then show that explicitly pessimistic algorithms that fill in the uncertainty with the worst case can minimize the worst case error.  Similarly, proximal algorithms that attempt to adhere to the collection policy (as often the case in model-free batch RL) have improved error compared to a naive approach but not as good as an explicitly pessimistic approach.",
    "The message of this paper is that naive policy evaluations common in current (deep) RL algorithms, can lead to a dangerous overestimation of the value function. This overestimation of the value function can then lead to policy improvements with poor theoretical guarantees. To combat overestimation, the authors propose to penalize state-action pairs that are rarely visited. As an easier to implement alternative, and closer to existing algorithms in the literature, the authors also study another penalty term that penalizes deviation from the data generating policy. The authors show on a numerical example that the more principled penalty term that depends on visitation counts is better performing, and that the proximal penalty term only yields minor improvements over imitation learning (i.e. returning the data generating policy).",
    "This paper attempts to unify prior work on fixed-dataset (aka \"batch\" or \"offline\") reinforcement learning. Specifically, it emphasizes the importance of pessimism to account for faulty over-estimation from finite datasets. The paper shows that naive algorithms (with no pessimism) can recover the optimal policy with enough data, but do so more efficiently. The pessimistic algorithms are divided into \"uncertainty-aware\" and \"proximal\" algorithms where the uncertainty-aware algorithms are shown to be more principled, but most prior work falls into the computationally easier proximal family of algorithms that is closer to imitation learning. These insights are proven both theoretically and with some small experiments.",
    "This paper presents a memory-efficient asynchronous leapfrog integrator for numerically solving neural ODEs, referred to as MALI. The method comes with a constant memory guarantee (like the adjoint method) and also guarantees reverse-time accuracy (like the adaptive checkpoint adjoint (ACA) method). The authors also give a rigorous theoretical analysis of MALI, and also discuss a \"damped\" version with an increased stability region. The method is evaluated on a variety of tasks which includes classification, dynamical modelling and generative modelling.",
    "There are typically two methods for estimating the gradients with respect to the loss for neural ODEs. The naive method directly backpropagates through the steps of the ODE solver leading to accurate gradients but very large memory cost. The adjoint method in contrast does not store the entire trajectory in memory, but has reverse trajectory errors (i.e. the numerical solution in the reverse direction will not be the inverse of the numerical solution in the forward direction). In this paper, the authors propose a method that is both reverse accurate and has low memory cost.",
    "This paper proposes a new algorithm for solving neural ODEs. Each numerical solver step of the neural ODE is implemented as an invertible neural network via a variant of the asynchronous leafprog integrator. While still computing an accurate gradient, this allows memory savings by discarding intermediate data from the numerical integration steps since it can be reconstructed using the inverse. A theoretical stability analysis is provided. The experimental results show that the algorithm achieves similar performance to previous methods (e.g. ACA) while using less memory. ",
    "The paper provides a set of comparisons among different scene generation methods. It assesses ability of the models to fit the training set (seen conditionings), generalize to unseen conditionings of seen object combinations, and generalize to unseen conditionings composed of unseen object combinations. It finds that these models fit the training distribution with a moderate success, display decent generalization to unseen fine-grained conditionings, and have significant space for improvement when it comes to generating images from unseen coarse",
    "This paper studies the problem of scene conditional image generation with a focus on the evaluation of existing works towards unseen complex scene generation on the COCO-Stuff dataset. Specifically, it evaluates the model performances from three aspects, namely, image generation from seen conditionings, unseen fine-grained conditionings, and unseen coarse conditionings. For each evaluation, it computes the precision, recall, conditional consistency, F1-score, object accuracy, FID and diversity score for both object-wise and scene-wise measures. ",
    "Problem: There has been a plethora of work on image synthesis from a given layout of objects or label maps. However, it is not clear what has led to those results because there are no fixed backbone, optimization, training data, and evaluation protocol in each of them. This paper introduces a methodology to study three approaches (G2im, LostGAN, OC-GAN) that input a layout of objects to synthesize a new image.",
    "The paper presents a theoretical analysis to compare expressive power of Graph-Neural Networks (GNNs) w.r.t a class of simpler graph modles called  Graph-Augmented MLPs (GA-MLPs).   GNNs, especially deeper ones can be more difficult to train, and GA-MLPs have a simpler structure, significantly easier to train, and have been shown to have competitive performance on a number of tasks.  The paper dives deep into several problems (graph-isomorphism, node-classification, and community detection) and through innovative analysis shows that GNNs at least theoretically can have significant advantages for some of the problems. ",
    "The paper compares graph neural networks (GNNs) with graph-augmented multi-layer perceptrons (GA-MLPs) where GA-MLPs are MLPs over nodes with additional node features computed over the graph. The paper contains theoretical results and experimental results for graph isomorphism testing and for node level functions. In the overflow of papers studying the expressivity of GNNs, the originality comes from the study of GA-MLPs and from the comparison for node level functions.",
    "The paper studies a variant of Graph Neural Networks (GNNs) namely, Graph Augmented MLPs (GA-MLPs). Unlike in GNNs where nodes send messages to neighbors, and aggregate received messages via non-linear MLPs,  GA-MLPs rely on a single augmented embedding computed once and then applying an MLP to the new embeddings. The augmented embeddings can be obtained by applying linear transformations of the form A, A^2, \u2026, A^k to the input representations, thereby capturing larger neighborhoods. The main goal of the paper is to demonstrate a fundamental weakness when using GA-MLPs for solving graph problems as compared to GNNs. Along these line the paper the main results can be characterized as follows:",
    "The paper proposes an original idea to use distillation to speed up modern distributed RL settings, when data collection is done on CPUs with the learning happening on accelerated hardware, e.g. GPU. More specifically, the authors propose to use a transformer for the learner and distil the policy into LSTM actors. With this, they achieve much faster wallclock time compared to the Transformer for Actors setup, however, losing in sample-efficiency.",
    "The paper proposes a method for \"actor-latency constrained\" settings: Recently, transformers have been shown to be powerful models in RL which, in particular, exhibited better sample complexity in settings in which long-term credit assignment in partial observability was required (e.g. the T-maze). However, they are computationally expensive. Consequently, the authors propose to train transformers on the learner, supported by hardware acceleration, but also train a smaller LSTM agent which can be efficiently executed on the actors. ",
    "The paper proposes a solution to actor-latency constrained settings in RL by using policy distillation to compress a large \u201clearner model\u201d towards a more tractable \u201cactor model\u201d. In particular, it proposes to exploit the superior sample efficiency of transformer models while utilising an LSTM-based actor during execution. The proposed procedure, called Actor-Learner Distillation (ALD), provides comparable performance to transformers in terms of sample efficiency, yet produces a wall-clock run-time that's on par with LSTM agents.",
    "The paper addresses the problem of multi-domain few-shot image classification (where unseen classes and examples come from diverse data sources), and proposes a Universal Representation Transformer (URT) layer, which learns to transform a universal representation into task-adapted representations. The method proposed builds on top of SUR [Dvornik et al 2020], where a universal representation is extracted from the outputs of a collection of pre-trained and domain-specific backbones and a selection procedure infers how to weight each backbone for a given task at hand. While SUR inferred those weights by optimising a loss on the support set (the few examples provided in a task), the authors in this paper introduce an attention-based layer (inspired by Vaswani et al Transformer) that learns to weight the appropriate backbones for each task. This layer has the main advantage that it can be learned across few-shot tasks from many domains so it can support transfer across these tasks.",
    "Few-shot learning on meta-dataset is challenging due to the domain gap between train and validation. In order to bridge this gap, the authors present a model that learns to combine domain-specific representations to generalize to new domains. This combination is done with a transformer model that pays attention to the features extracted from domain-specific backbones. The authors demonstrate empirically that their model attains comparable performance to previous state-of-the-art at higher efficiency and include ablation results to test their model components.",
    "The paper presents a method for tackling multi-domain few-shot image classification problem where it obtains a task-adapted representation by weighing representations from pretrained domain-specific backbones according to the support set at hand. The desirable property of this framework is that the model can leverage information from other domains to make predictions. The effectiveness of Universal Representations have been discussed in the past work - SUR [1], and this work builds on top of it and introduces a learnable component (self-attention), and showed the improvement both quantitatively and qualitatively.",
    "The paper introduces a non-parametric approach, STAM, for unsupervised progressive learning (UPL), a variant of continual unsupervised learning with a single-stream requirement. STAM is developed for visual tasks. It comprises several components: (1) online clustering of hierarchical visual features (2) novelty detection (3) dual-memory for prototypical features. Experiments show STAM performs better than GEM, MAS in specific scenarios. ",
    "The authors propose an approach (architecture + algorithms) to unsupervised progressive learning in a non-stationary environment (the number of classes grows gradually) by keeping centroids at several hierarchies, using a combination of techniques from online clustering, via computing and updating centroids, with novelty detection, and dropping (forgetting those deemed outliers).  A variety of experiments are performed on several image datasets (MNIST, EMNIST, SVHN, CIFAR-10) with comparisons to other adapted methods. They evaluate performance in a supervised setting where they describe how they learn centroid to label(s) mappings.",
    "This paper presents an \"Unsupervised progressive learning\" (UPL) problem, where a model is exposed to data in an non-iid manner, and each training example is presented once. Simple to continual learning, but a little more explicit in the connections to the way biological agents learn. They present a model that uses clustering and long-term memory (buffered) and compare on a few UPL tasks with additional supervision signal (classification) or unsupervised (clustering).",
    "The authors consider the decentralized optimization problem and explain the generalization gap using the consensus distance. They show that when the consensus distance does not grow too large, the performance of centralized training can be reached and sometimes surpassed. The conducted experiments are extensive and the delivered message is pretty clear -- Critical consensus distance exists in the initial training phase and ensures good optimization and generalization, while a non-negligible consensus distance at middle phases can improve generalization over centralized training.",
    "This paper studies decentralized gradient methods for training deep networks. It focuses on the so-called \"critical consensus distance\" and how disagreement during different stages of training ultimately effects optimization (training loss) and learning (generalization error). Theory is provided for the case of synchronous symmetric averaging methods, and the paper is complemented with detailed experiments on CIFAR and tiny-ImageNet.",
    "This paper studies the problem of decentralized training where several computing units are used simultaneously to process the data, and computing units are assumed to be connected over a network. The main focus is to better understand the role of consensus, or lack there of, into the generalization abilities of decentralized training. The authors describe an upper bound for dissimilarity of local variables that guarantees the performance of decentralized training is as good as centralized one. Moreover, some heuristic guidelines are proposed to control consensus during training process. Some numerical evidence is also provided.",
    "This work concerns the metric learning between sequences using RNNs. The paper notices the similarity between a dynamical system and an RNN. Then it demonstrates that learning a pair of siamese RNNs is similar to learning synchronization between two subsystems of a dynamical system. Finally, the paper proposes to introduce coupling between the two RNNs in order to improve synchronization.",
    "Drawing inspiration from dynamic systems, the paper proposes a novel architecture that couple sequences. Such a system has easiness to bring two instances arbitrarily close and authors have shown the superiority of the approach over an action recognition dataset; but the results seem to far from state of the art on the dataset (see questions section). The authors also recognize that currently such systems need to calculate each pairs (can't be cached due to coupling) at inference time, which is slow. ",
    "I liked the formulation and motivation of the paper, explaining the sequence metric learning problem  and drawing parallel between synchronized trajectories produced by dynamical systems and the distance between similar sequences processed by a siamese style recurrent neural network. The authors propose modification the siamese recurrent network setting called classical Gated Recurrent Unit architecture (CGRU). The premise being two identical sub-networks, two identical dynamical systems which can theoretically achieve complete synchronization if a coupling is introduced between them. The authors describe how this model is able to simultaneously learn a similarity metric and the synchronization of unaligned multi-variate sequences in a weakly supervised way with the coupling demonstrating performance of the siamese Gated Recurrent Unit (SGRU) architecture on UCI activity recognition dataset (mobile data).",
    "This work analyzes the effect of co-distillation for distributed training under moderate batch sizes. Using distillation-like techniques to improve synchronous SGD training is an interesting direction. And the paper carefully analyzed this setting while using the same amount of compute, which is not done by prior work to my knowledge. In addition, the writing is good and easy to follow.",
    "The paper studies the concept of codistillation in data parallel distributed training. In this setting, the standard minibatch SGD algorithm requires exchange of models in every update of every node. Recent work in distributed training has studied \"local SGD\", where models are exchanged at frequent (usually periodic) intervals after a bunch of local updates. This paper studies an alternative, called \"codistillation\". The idea is that at a given node, say node $i$, the local model updates are regularized by the most recent models at nodes $\\{j, j \\neq i\\}$ through an appropriately modified loss term. Specifically, the loss term bias the model at node $i$ towards having similar classification outcomes on the training data as the (most recent) local estimate of the model at nodes $\\{j, j \\neq i\\}.",
    "This paper aims to have a closer look at the role of codistillation for distributed training. Authors provided an answer with their empirical observations. That is, codistillation acts as a regularizer, since the distance between the learned model and the initialization is smaller than sync SGD without codistillation. Then, the authors claim that the codistillation may over-regularize and study how to modify the training configurations to avoid it. There are further discussions on the overfitting and robustness to hyper-parameters in sec 4 and sec 5. ",
    "This paper studies the relations between the heavy tail phenomenon of SGD and the \u2018flatness\u2019 of the local minimum found by SGD and the ratio of the step size $\\eta$ to the batch size $b$ for the quadratic and convex problem. They show that depending on the curvature, the step size, and the batch size, the iterates can converge to a heavy-tailed random variable.  They conduct experiments on both synthetic data and fully connected neural networks, and illustrate that the results would also apply to more general settings and hence provide new insights about the behavior of SGD in deep learning. ",
    "The main theme of this work is to study conditions under which SGD iterations result in random variables with heavy-tail random distributions. Specifically they focus on the step size, batch size and problem dimension. First they show theoretical results showing how the tail-index of the distribution generated by SGD depends on the chosen step size, batch size and problem dimension.",
    "This paper gives a theoretical study of the tail behavior of the SGD in a quadratic optimization problem and explores its relationship with the curvature, step size and batch size. To prove their results, the authors approximate the SGD recursion by a linear stochastic recursion and analyze the statistical properties by the tools from implicit renew theory. Under this setting, they show that the law of the SGD iterates converge to a heavy-tailed stationary distribution depending on the Hessian structure of the loss function at the minimum and choices of the step size and batch size. They take a further step to clarify the relationship and study the moment bounds and convergence rate. ",
    " The article analyzes GCNs from spectral viewpoint, and discusses the performance of GCNs with respect to spectral filtering. The paper shows by experimentation, that the performance of GCNs mainly depend on low frequencies (lower end of the spectrum/eigen-pairs). It then shows that an MLP with low frequency information (Eigen-pairs) performs very well in graph tasks. Aspects such as smoothness and high frequency ablations are also studied.",
    "This paper aims to study how GCN will behave under spectral perturbations/manipulations. The empirical numerical analysis on three benchmark datasets (cora, citeseer, pubmed) show that most of the necessary information is contained in the low-frequency domain. Based on that, the author propose to expand the node feature matrix with the eigenvectors corresponding to low-frequency domain and apply MLP on this new feature matrix. Experimental results show that the proposed method outperforms vanilla GCN and achieve comparable results on pubmed with other baselines.",
    "The work presents an interesting analysis of GCN models under spectral manipulations and relates the performance of GCNs through bandpass filtering. The authors demonstrate that GCNs mainly rely more on low-frequencies rather than high-frequencies which is contrary to what is observed in signal processing. For this, the authors use band-pass filters which allow only a portion of the spectrum to be utilized by the GCN model. The major findings are as follows:",
    "Graph neural networks (GNNs) have become de facto methods for integrating the input graph structure and node features to learn effective node representations. However, in some domains (such as brain signals, particle reconstruction, etc.), there is access to only node features (but not the underlying graph structure). Motivated by the fact that GNNs tend to perform poorly in the absence of the graph structure, the paper",
    "This paper proposes to tackle jointly learning graph structures and GNN parameters without accessing the original graph structure. Specifically, the proposed method adopts a self-supervised auxiliary task, i.e., parallel training using the supervision of node labels and a self-supervised task using de-noised auto-encoding. The latent graph structure is generated through a fully-parameterized adjacency matrix or a KNN construction subsequent to passing node features to an MLP. Experimental results and corresponding analyses demonstrate the effectiveness of the proposed model.",
    "This paper considers the problem of nodes classification with few labeled data and missing graph structures. The proposed solution is expected to infer unobserved graph structure as well as the parameters of the classification model. The main contribution of this paper is proposing adding a denoise autoencoder layer which provides more supervision to the learning. The model compares favorably with other states of art models in several benchmark graph data sets.",
    "The authors propose a novelty detection module to help unsupervised class-incremental learning. The novelty detection relies on the percentage of accuracy drop during a model update when treating incoming data as a new class. If the model maintains high accuracy, then the module treats the incoming data as familiar, thereby choosing one of the existing classes as the correct label. The paper investigates the effectiveness of the proposed method on MNIST, SVHN, CIFAR-10, and CIFAR-100.",
    "This article proposes a method for predicting whether a batch of data is of the same class as one of the classes already seen by a classifier or whether it contains data from another class. The idea is to then be able to incorporate this batch to the previous training set, in an unsupervised learning context. It is assumed that each batch contains data from only one class. Experiments are there to show the interest of this method for anomaly detection or incremental learning.",
    "This paper proposes to tackle the problem of unsupervised class-incremental learning, where the training data is composed of a sequence of \"exposures\". Each exposure is comprised of a set of images that pertains to a single class, where the class label is unknown while the boundaries between exposures are known. The key difficulty in such unsupervised class-incremental learning is to determine whether an arriving exposure belongs to what the classification model $L$ has learnt previously or is a novel one, thus relating to the problem of novelty detection. The proposed method address the novelty detection by an interesting idea: they always treat the current exposure as a novel class and use it to train the copy of classification model $\\hat{L}$ together with the training exemplars of previously-learnt classes, if the current exposure actually belongs to one of the previous-learnt classes, the confusion occurs to make the classification accuracy significantly decrease (over a threshold) on that specific class, where the accuracy is computed based on the validation exemplars. Moreover, a technique of introducing class-imbalance into such confusion-based novelty detection is proposed and helps to boost the robustness of novelty detection. ",
    "The paper addresses how to learn policies for tasks in which constraints are specified in natural language. Towards this, the paper proposes a model that encodes the different types of natural language constraints into intermediate representations that model both spatial and temporal information between states. Then, they use this as input along with the observation to produce an action at each time step for a safe trajectory. ",
    "The paper proposed an algorithm to learn a policy when provided with natural language constraints. The paper defined a navigation task called Hazard World, in which an agent navigation on the map to collect items. The authors defined three types of constraints to restrict agents to visit certain states: 1. budgetary constraints, 2. relational constraints and 3. sequential constraints. The three constraints are described in natural language. The authors proposed a two-step solution. In step one, the algorithm learns a mapping between a natural language constraint to an intermediate representation. In step two the algorithm takes the intermediate representation to learn a policy that satisfy the constraints.",
    "This paper presents a new test environment, Hazard World, for learning the safe reinforcement learning agents with given natural language constraints. In this problem, the goal of the agent is to find an optimal policy that maximizes the cumulative rewards while satisfying the constraints given in natural language. The authors introduce the model that contains the following two separate components; constraint interpreter for encoding the language constraints and policy network for learning the RL agent. Finally, they report the results of their proposed algorithm and compare it with the baselines.",
    "This paper proposes the few-shot edge detection task, which is similar to few-shot segmentation but for the dual task of detecting semantic edges. For the task, the authors construct datasets and experimental settings constructed from existing edge detection dataset (BSD) and a few shot segmentation dataset (FSS). For the proposed method, the authors:",
    "This paper introduces a novel problem of \"few-shot semantic edge detection\" where semantic boundaries are to be learned/detected with a few labeled samples. In order to remedy the issue of label sparsity within the few-shot scenario, the authors have leveraged the use of the segmentation process which provides the semantic information to the edge detector. They have also incorporated a meta-learning approach, namely Multi-Split Matching Regularization (MSMR), to avoid the overfitting when high-dimensional embeddings are used for feature matching.",
    "This paper works on few-shot semantic edge detection. Instead of dealing with the problem in a single stage, the authors decompose the problem into two stages.  First, a few-shot segmentation stage, where the foreground and the background probability are estimated via attention with the foreground and the background prototype (averaged feature vector on the foreground and the background region). Second, the feature maps from the encoder are masked by the attention map and sent to the decoder to generate the final edge-map.",
    "This work proposes to explain graph neural networks from a causal effect view. The proposed method, Causal Screening, iteratively adds edges into the explanatory subgraph. The goal is to maximize the $do(\\cdot)$ calculus, which tries to select an edge such that the prediction probability when feeding into GNNs is close to the original prediction. Experimental results show that the proposed method can outperform other comparing methods.",
    "The paper proposes a procedure for identifying a subgraph $\\mathcal{G}_K$ of a given size $K$ (measured by the number of edges) whose output through the GNN function $f$ is as close as possible to that of the full graph $\\mathcal{G}$. The proposed method is a greedy approach which starts from an empty graph and gradually adds the next edge by minimizing the difference between the outputs using mutual information. Furthermore, to reduce the computational complexity, a node clustering is done on the graph and the attribution is applied first on the edges between $C$ identified clusters and then transferred to all edges.",
    "The paper introduces a novel method called Causal screening which takes a graph and the prediction made by a GNN, and returns an explanatory subgraph. The method aims to explain GNN models. To be precise, it starts from an empty set as the explanatory subgraph, and incrementally adds the edges, testing them for the individual causal effect.",
    "The paper proposes a novel generalisation measure, i.e., measurement that indicates how well the network generalises, based on pruning. The idea is to measure the fraction of the weights that can be pruned (either randomly, or based on the norms) without hurting the training loss of the model. The paper provides thorough discussion of the related methods and motivates the measure in multiple ways. Further, the authors show empirical evidence for the correlation of the pruning robustness to the generalisation ability of networks, based on the paper by Jiang et al., 2019 and dataset (updated with additional models) provided in the paper.",
    "In order to understand why deep networks generalize well, this paper proposes \"prunability\" as an empirical measure that can be predictive of the generalization. Prunability is roughly the smallest _fraction_ (i.e., $\\in [0,1]$) of parameters that can be retained, while zeroing out everything else, without increasing the model's training loss by too much. The authors experimentally demonstrate the predictive ability of this measure in three ways.",
    "In the present work, the authors tackle the highly debated (and sometimes confusing) problem of finding a good simplicity/complexity measure able to predict generalization performance of deep networks. A novel measure called 'prunability' is introduced and compared with some of the many alternatives in the literature. This property measures how networks are able to retain low training loss when a fraction of the weights is set to zero, and is clearly related to common training practices (e.g. dropout) that seems to yield better generalization performance in practice. The experimental settings and the evaluation methods for this new metric are inspired by recent extensive studies on deep networks performance. The authors are able to show that prunability is in fact associated with good generalization and seems able to capture some non-trivial phenomena (double-descent), but they also find it to be inferior to pre-existing (margin based) measures. Moreover, the close relationship to perturbation robustness and flatness measures is investigated, but the results are not fully conclusive.",
    "This paper tackles the problem of long horizon visual planning, with the aim of of being able to plan actions to reach distant goals. This is a well studied problem, and like prior work this method considers the setting where the agent is given an offline dataset of interaction, which it learns from to be able to reach new goals (specified by a goal image). The method first does unsupervised representation learning, where it learns a discrete representation of images (using contrastive predictive coding (CPC) with a discrete latent variable using Gumbel Softmax). Using a set of discrete latent variable, it then builds a set of graphs which connects these discrete states based on the collected experience, and derives a planning procedure to find a path in the graph which reaches the goal. ",
    "This paper presents a method that combines learning discrete representations together with planning using graph search to solve long horizon tasks from vision. The approach works by generating data via random exploration and trains a representation encoder on this data. This network extracts objects from the observations and passes them through a CNN and shared encoder to generate one-hot encodings; these encodings are concatenated to generate the discrete representation. The encoder is trained via a contrastive learning objective with a similarity matrix that encourages nearby states to share similar encodings, thereby encouraging spatial and temporal abstractions. Next, these representations are combined together with an abstract planner to generate a sequence of waypoints to the goal. This is done by creating a graph of transitions from the collected exploratory data and search within this graph \u2014 this is executed for each encoding at a time with the assumption that the task can be solved by moving each object independently of the others. Finally, a low-level controller is used for reaching the waypoints and final goal, this is done via MPC on an action-conditional predictive model that generates future observations given the current state and goal. The approach is tested on two simple planar planning tasks where the agent has to solve k-object arrangement and open a room with a key respectively.",
    "This work presents Discrete Object-factorized Representation Planning (DORP), which learns a discrete representation from videos with an enforced temporal consistency. This representation can then be planned over through a sequence of small alterations to the discrete embedding, which are then executed via MPC. DORB is demonstrated to solve long-horizon tasks and learn representations that consider objects and their properties. ",
    "This paper basically proposed to learn the quantization bits (precision) in each layer. Specially, weights are constructed with binary representation as $W_s = \\[W_s^1,...,W_s^b\\]$. During training, $W_s^i$ is relaxed to $ \\in \\[0, 2\\]$. And a group sparsity is imposed to all $W_s^i$ for all weights in a layer, leading to certain $W_s^i \\to 0$, thus cancelling the bit allocation in $i$-th. Experimental results is promising.",
    "This paper introduces a new method to quantize neural networks in a differentiable manner. Proposed method applies the group lasso on the bit-planes of the weight parameters to let certain LSBs in each layer to be zero-ed out. STE is used to train the binary representation of each bit-plane and the sign of weights during the training. Results demonstrate that the proposed method can achieve higher accuracy and compression ratio compared to previous studies.",
    "Quantization of weights in DNNs is a very effective way to reduce the computational and storage costs which can enable deployment of deep learning at the edge. However, determining suitable layer-wise bit-widths while training is a difficult task due to the discrete nature of the optimization problem. This paper proposes to utilize bit-level sparsity as a proxy for bit-width and employ regularization techniques to formulate the problem so that precision can be reduced while training the model.",
    "The paper identifies the gradient vanishing issue in the robustness of binary quantized networks. Therefore, it proposes to use temperature scaling approach in the attack generation. It has two methods for the temperature scale: (1) singular values of the input-output Jacobian and (2) maximizing the norm of the Hessian of the loss.",
    "**Update**: Thanks to the authors for addressing my comments. As it was pointed out by the authors, temperature rescaling is mostly applicable to non-linear loss functions. For linear loss functions, temperature scaling only linear rescales the gradients. The difference between the proposed PGD++ attack and PGD with linear DLR loss is small (see the author's response to AR4). The improvements are most significant for FGSM but FGSM is not recommended for the robustness evaluation. Given the limited technical novelty and small improvements for linear loss functions, my score remains unchanged.",
    "This work starts by questioning the apparent robustness of quantized networks and demonstrates that such robustness is more so a failure of the attack algorithm in picking up the gradient signal. The authors address this by tuning a scalar multiplier applied to the network logits, which doesn\u2019t modify the model\u2019s decision boundary. Through analyzing the Jacobian, two approaches are proposed to determine the scalar $\\beta$ without tuning it by performing the attack. This approach is quite effective on quantized networks and even provides significant improvement on floating-point networks combining with existing attacks like FGSM and PGD. The proposed modification might seem trivial at first, but it constitutes an important factor the community hasn\u2019t taken notice of, to the best of my knowledge.",
    "The authors propose ProtoryNet,  a prototype-based model for paragraph classification that associates each sentence in the paragraph with a relevant prototypical sentence from the training data. The idea is interesting and the ability to decompose sentiment scores over each sentence + find prototypes for each helps to build user understanding of the model prediction. Thank you to the authors for the submission.",
    "this paper presents an RNN sequence classifying model that generates a prototype for each sentence in a paragraph. The generated prototypes help explain the model's prediction. The method embeds each sentence, matches to prototypes, then runs through an LSTM before making a prediction. Experiments found improved accuracy compared to a previous model that generates only one prototype for a paragraph. A user evaluation also found improvement in interpretability.",
    "This paper presents ProtoryNet, a framework for text data that classifies and explains the prototypes' results.   The key concept, that is the novelty of the work, is that this framework is based on sentence prototypes, called prototype trajectory in the paper. In particular, instead of working at the entity of the text level, the text is split into sentences and each sentence is analyzed by itself.  The structure of the framework is composed of a layer that encodes a text's sequences, followed by a prototype layer in which is computed the similarity among each sentence and the prototype trajectories. At this point, the sentences are represented in one-hot encoding: for each sentence, there is a bunch of zero and then a one for the most similar sentence prototype. This representation is used for the classification of the sentence, done using an LSTM structure. In this setting, the interpretation is given by exploiting the prototypes matched for the text under analysis. ",
    "Authors demonstrated that one can encode the data likelihood function of an HMM using a specialized RNN architecture. Unlike previous work where neurons from different layers were multiplied together, the new encoding strictly followed the classical architecture restrictions of a neural network , i.e. each layer was a weighted sum of the previous layer. Empirically, author showed that the parameter learned by applying gradient descent on the likelihood function is similar to the one that is obtained using the EM algorithm. In addition, authors demonstrated that such formulation enables an application in studying Alzheimer's disease Symptom Progression.",
    "This paper introduces a novel architecture of recurrent neural network that mimics the working of a standard HMM. In particular, the proposed HMRNN learns model-parameters, which are statistically similar solutions to those of a standard HMM, within a general neural network learning framework. While it is shown the proposed network similarly to the HMM, there are many issues that should be considered critically.   ",
    "The authors describe an RNN architecture, the HMRNN, which models the log-likelihood in an HMM.  The authors provide theoretical results showing that the HMRNN objective function does, indeed, correspond to the log-likelihood of an HMM.  Synthetic results are presented which compare the learned parameters between the HMRNN and an HMM trained using the Baum-Welch algorithm.  Finally, HMRNN training is augmented and compared to an HMM trained using the Baum-Welch algorithm for the task of Alzheimer's progression prediction.",
    "This manuscript presents a novel dimensionality reduction method, called Factorized Linear Discriminant Analysis. The method starts from a real problem in neurobiology, and tries to link expression levels of neural genes to phenotypes. In particular, the main goal of the proposed technique is to find linear projections of the genes expression which vary maximally with one phenotypical aspect and minimally with the others. The approach is evaluated using a synthetic example and a real case study involving Drosophila T4/T5 cells.",
    "This manuscript describes a generalization of ANOVA that is intended to be used in the interpretation of single-cell RNA-seq data. The method requires specification of an orthogonal, discrete categorization of cells, nominally by phenotype.  The method then linearly factorizes the observed gene expression values into features and their interactions, relative to the phenotypic categories.  The factors can then be used to help interpret the categories, especially in conjunction with a regularizer to reduce the number of genes involved in the factors.",
    "The paper studies a very important problem in gene data analysis. The proposed method is technically sound. The method is intuitive in its idea and easy to implement. The results are interpretable. And according to the experimental evaluations, the proposed method is consistent to existing biological observations and could further identify unknown genetic targets. Therefore, it, potentially, has insightful scientific implications. ",
    "The paper presents a new saliency map interpretability method for the task of image classification. It considers the saliency map as a random variable and computes the posterior distribution over it. The likelihood measures the predictions of the classifier for an image and its perturbed counterpart. The prior encodes positive correlation among adjacent pixels. Variational approximation is used to approximate the posterior.  ",
    "This paper proposed a method for generating saliency maps for image classifiers that are stochastic (instead of deterministic). The probabilistic model assumes a saliency map random variable that generates the data with a classifier. The inference is done by variational methods. The paper presents several qualitative examples and a comparison to previous work using the pixel perturbation benchmark.",
    "This paper proposes a new interpretability method for image classification networks. It considers a saliency map as a random variable and aims to calculate the posterior distribution over the saliency map.  The likelihood function and the prior distribution are then designed to make the posterior distribution over the saliency map explain the behavior of the classifier\u2019s prediction. Quantitative evaluation on the perturbation benchmark as well as qualitative result show the effectiveness of the proposed method over baselines. ",
    "This paper introduces a novel technique for debiasing pretrained contextual embedding models. Their approach trains a 2 layer fully-connected neural network which takes as input the output from the pretrained model and outputs a new, \"debiased\" representation. This model is trained by minimizing the InfoNCE between the representation produced of original sentence and the representation of that same sentence with some tokens replaced with differently-biased tokens (e.g. \"his\" -> \"hers\"). This paper also introduces a regularizer which minimizes the CLUB between the generated representation and a word embedding for a biased token. ",
    "This paper studied a debiasing method to remove social bias in pretrained NLP models. The authors proposed to train a neural network which takes the sentence representations of a pretrained NLP model as input and outputs the unbiased representations. The neural network is trained by maximizing the mutual information between a sentence and its \u201ccounterpart sentence\u201d, which is automatically generated by replacing sensitive words by other values (e.g. replacing \u201che\u201d with \u201cshe\u201d). Moreover, the network can be further trained by minimizing the mutual information between the sentence representation and its sensitive word representation. The experiments show that the proposed method can effectively reduce bias while achieving better downstream task performance of the pretrained model.",
    "The paper builds on recent working attempts to debais sentence encoders by considering modified sentences. Sentences are selected that, for example, contain\u00a0gender cueing words, and then swap those words with a predetermined 'opposite' (i.e. man<->woman). The core novelty in the work is to train a lightweight modification the encoding of the sentence and its swap to (a) reduce the distance between the two embeddings, using a contrastive learning objective and (b) reduce the mutual information between cueing words and the new embeddings. Evaluated on a WHEAT style task, modified for sentences, the method performs significantly\u00a0better than existing recent work.\u00a0",
    "This paper proposes an improved sample-wise randomized smoothing technique, where the noise level is tuned for different samples, for certification of robustness. Further, it also proposes a pretrain-to-finetune methodology for training networks which are then certified via sample-wise randomized smoothing. The authors show in experiments on CIFAR and MNIST that combining their training methodology and certification methodology can sometimes improve the average certified when compared to state-of-the-art randomized smoothing techniques Smooth-Adv (Salman et. al, 2019).",
    "This paper suggests an extension of randomized smoothing, wherein the degree of smoothing is optimized both at training and test-time on each individual sample. At training time, the model is first \"pre-trained\" using a range of smoothing parameters (variance of the Gaussian perturbations), and then \"fine-tuned\" by selecting the variance on each sample which maximizes the verified radius. At test time, we can again select the smoothing parameter to maximize robustness.",
    "This paper considers the problem of provably defense to adversarial perturbations using randomized smoothing. The authors propose sample-wise randomized smoothing -- assigning different noise levels to different samples. They also propose to first pretrain a model and then adjust the noise for higher performance based on the model\u2019s outputs. Experiments show that proposed approach improves the performance of randomized smoothing with same noise level for small perturbations. ",
    "This paper proposes a Tomographic auto-encoder (TAE) for unsupervised recovery of corrupted data. More specifically, TAE takes a Bayesian approach to recover the posterior distribution of a clean image conditioned on an observed corrupted image and thus effectively modeling uncertainty in data recovery. The paper argues that a naive application of VAE is not effective due to the latent variable collapse, and proposes an alternative model where hierarchical latent variable models are used for both prior and variational posterior. Some tricks are introduced to facilitate the stochastic gradient variational inference. ",
    "Practical datasets often come with corruptions, such as missing items or noisy observations, thus needs models enable to recover the corrupted data automatically. This paper presents the tomographic auto-encoder (TVAE), which conducts inference over the data space $x$. Because the prior regularization acts over the data space, TVAE is enforced to generate diverse samples from the corrupted observations. Empirically, the paper demonstrates that TVAE can indeed generate diverse samples and can achieve superior test ELBO compared to the previous baselines.",
    "This paper proposes a novel approach to handle the recovery of dirty data in fully unsupervised scenarios. The corrupted data considers both missing data and noisy samples. They derive a VAE model with a novel reduced entropy condition inference method that results in richer posteriors. This is a very challenging problem, since the model cannot use clean examples as part of their training procedure.",
    "This paper proposes MAGNA, a multi-hop self-attention mechanism for attention based graph neural networks. The proposed method increases the receptive field at each layer, requiring less layers to achieve a large receptive field. Also, with the proposed method the attention coefficient between two nodes is not just a function of the two nodes but also of their neighbourhood. The proposed MAGNA method is an extension of GAT networks that introduces a diffusion step on the computed attention coefficients, following a similar approach (Diffusion-GCNs) that has been used for GCNs.",
    "The authors propose a novel attention-based GNN called MAGNA. The main contribution consists in considerably increasing the receptive field by considering a multi-hop neighborhood instead of the standard one hop. The technical challenge consists in obtaining attention scores for all relevant nodes in an efficient way. MAGNA solves this by using a diffusion-based technique combined with a geometric distribution. The authors show that the latter further allows for approximations, and also give interesting theoretical insights (e.g., show a relation to page rank). ",
    "     Conventional Graph Neural Networks (GNNs) learn node representations that encode information from multiple hops away by iteratively aggregating information through their immediate neighbors. Self-Attention modules have been adopted to GNNs to selectively aggregate information coming through the immediate neighbors at different propagation stages. However, current self-attention mechanisms are limited to only attend over the nodes' immediate neighbors and not directly over their neighbors that are multiple hops away. Here in this work, the authors intend to address this issue and propose a means to obtain attention scores over indirectly connected neighbors. ",
    "This paper describes a dataset consisting of ~14k multiple-choice questions drawn from many different fields across the humanities and science as well as professional disciplines such as law and medicine. It presents results for GPT-3 models (LMs trained on text corpora with document context) of different scales, as well as for the UnifiedQA model (seq2seq model trained on various QA datasets). Performance of these models is well below their performance on other benchmarks: not above chance for the smaller GPT-3 models, and under 50% average accuracy for the best models.",
    "This paper focuses on coming up with 57 different tasks and measure the performance of these large scale transformer models such as GPT3 on these different tasks. The main claims of this paper are to demonstrate these large-scale models still struggle to use the knowledge it has learned during the pretraining phase and these models struggle to on calculation-intensive tasks. Further one of the more important contributions of this work includes the massive multi-task dataset that comprises 57 different subjects.",
    "The paper proposes a benchmark for NLP models. The purpose of this test is to measure the model's knowledge in 57 topics covered by approx 15000 tasks in total, each formulated as a closed-form question in zero-shot and few-shot settings. Most of the tasks were taken from different human examination sets. Then, the paper provides results of experiments with the latest (GPT-3 and T5 based) models along with some quantitative and qualitative observations.",
    "This work explores a pretraining strategy (similar to https://arxiv.org/abs/1606.03622) to the problem of table question answering. More specifically a synchronous context-free grammar (SCFG) is first learned from training data (with manual alignment of entities/phrases). Then the SCFG is used to generate more full supervision data for Roberta model pretraining. The training objective is a combination of two parts: SQL Semantic Precision (SSP) predicts elements in SQL given the question on the synthetic data, and masked-language modeling (MLM) on the natural (training) data.",
    "The paper provides a interesting direction in pre-training for table semantic parsing. In particular, it proposes to first collect a collection of pseudo question-SQL pairs in an automatic way, based on tables from WikiTables tables and tables and databases in the training sets  SPIDER and WIKISQL. After that, masked language modeling and a newly introduced task called SSP, which is, given a natural language sentence and table headers, to predict whether a column appears in the SQL query and what operation is triggered. Experiments on Spider and WikiSQL show that the model achieves new state-of-the-art.",
    "This paper presents a general-purpose pre-training approach for jointly encoding utterances and relational tables in the task of table semantic parsing, where a natural language utterance is transduced into an executable query (e.g., SQL) over relational database tables. A core challenge in table semantic parsing is to understand the compositional semantics in utterances, and further ground salient entities and relations in the utterance onto the corresponding tabular schema (e.g., columns, cells). To improve understanding and grounding of compositional utterances, the authors propose fine-tuning a pre-trained masked language model (RoBERTa) using linearized table headers paired with synthetic utterances generated from a synchronous context free grammar, via an objective that encourages the model to discover the syntactic roles of columns mentioned in the input utterance. Experiments over four datasets demonstrated strong results when the this newly proposed pre-training objective is combined with classical masked language modeling objective.",
    "This paper provides a theoretical analysis of the inner workings of multi-task learning methods, based on a random matrix analysis applied to Gaussian mixture data model. The analysis is based on MTL LS-SVM with data from a Gaussian mixture model, where the bias of MTL LS-SVM is shown and a simple method is proposed to correct it. Experiments are conducted on a synthetic dataset and image classification task, where superior performance is shown in addition to the theoretical guarantees.",
    "The paper provides interesting theoretical insights in multi-task learning using common and specific parameters modeling framework and based on least-squares SVM. Especially, it is theoretically established that the standard MTL LS-SVM is biased. Thereon a method derived from the analysis is proposed to correct the bias and allows to achieve enhanced performances. Empirical evaluations highlight the effectiveness of the method.",
    "The paper considers the multitask least-square SVM problem. Such a problem consists of k SVM tasks, each being a binary classification problem. The normal vector of the separating hyperplane in each task is \u201cclose\u201d to each other, reflecting the commonality of the tasks. For an input data point, the problem asks to predict the classification of the input data point for a given task. This problem has a standard optimization formulation.",
    "This paper addresses an important symmetry in meta-learning.  Namely, the context data consists of a set of datapoints in arbitrary order.  The model should thus be permutation equivariant to their order.  At the same time, the data itself may have its own symmetries, e.g. rotation, which the network should likewise be equivariant to.  The authors follow a theory-driven approach, proving in Thm 2 that a function with these two types of symmetries may be factored and represented by a composition of functions reflecting each symmetry individually.  They then design a Neural Process (NP) model, EquivCNP, which reflects this result.  Other works have used permutation equivariance and translation equivariance in NPs, but this is the first to incorporate other symmetry groups. ",
    "The paper provides an extension of convolution conditional neural processes CNPs to more general Lie group equivariant CNPs. The development of the theory seems sufficiently clear to someone more familiar with the field. However, for newer readers, it seems important to be familiar with background concepts and prior work. This is not a penalizing point but rather just an observation.",
    "This paper presents EquivCNP which extends Conditional Neural Processes (CNP) to incorporate symmetries of the data, e.g. rotation and scaling. The approach utilizes a combination of LieConv (Finzi et al., 2020)  and DeepSet (Zaheer et al., 2017) to achieve the equivariance in the data space and permutation invariance across the samples in a dataset. They provide empirical results on a 1D regression task with synthetic and 2D image completion tasks using digital clock digits dataset which they constructed.",
    "This paper introduces a new optimization method for text generation that improves upon directly optimizing MLE. It frames text generation learning as an off-policy reinforcement learning (RL) problem using demonstrations (the training examples). The authors also discuss why off-policy learning is more suitable for text generation than on-policy learning. After simplifications and approximations, the proposed optimization objective comes down to a form that is similar to MLE, but upweighs training examples that are more likely under the learned policy $\\pi_\\theta$ (\"easy\" examples) and having higher estimated rewards (considering the future).",
    "This paper proposes a method to train generative models of text using reinforcement learning from off-policy demonstrations. This helps solve the problems of exposure bias and mismatched objectives in standard learning schemes such as maximum likelihood estimation and policy gradient optimization on metrics like BLEU. In the proposed method (GOLD), the authors use policy gradient combined with importance weighting to train the model using just the off-policy demonstrations, i.e. human-written text. They experiment with three different reward formulations, and demonstrate improvements over MLE baselines on tasks like summarization and machine translation. ",
    "This paper formalizes training of conditional text generation models as an off-policy RL objective, specifically, in the limit case where samples are only obtained from the training data. The motivation behind this is that MLE objective optimizes recall -i.e. increasing the prob of all correct sequences that could be generated by humans as an output to a certain input context. While for certain tasks such as MT or summarization it is often sufficient to focus training to generate 1 single correct Translation or summary (see cons: for comments on the effect of this on sample diversity).  Therefore explorations in traditional PG by generating examples from an auto-reg model is unnecessary in this context. Therefore, using importance sampling, PG objective \\E_{x \\sim \\pi_\\theta} is modified to \\E_{x \\sim \\pi_{data}} with the incorporation of the importance ratio and given a uniform sample probability of the training examples. As shown in eq(4), The gradient updates from this loss are identical to the standard MLE loss reweighted by the global reward and the current model probability of the training example, enforcing the model's current belief of the training data. This aligns with the previous intuition of enhancing precision on the expense of recall. Given this formulization this work experiments with three types of rewards: a constant reward and 2 MLE based rewards.    ",
    "The paper proposes a strategy for training feed-forward networks in a more memory-efficient manner by employing local as opposed to end-to-end supervision. End-to-end/global (E2E) supervision as the dominant paradigm in training deep networks considers a loss function at the very end of the network for backpropagation of the resulting gradients, whereas local supervision injects supervisory signals (such as the same E2E objective, e.g. classification) at intermediate layers in the network. The benefit of such intermediate supervision is the ability to train larger networks in smaller chunks piece by piece, where each individual training is more memory efficient due to reduced need to store activations (and weights and biases) in GPU memory. As a drawback, however, it had been shown earlier that such local training is less optimal than global training in terms of the achievable generalization performance. The authors propose a new training strategy that aims at combining the memory efficiency of local supervision and piecewise training with the error performance of global training. Considering a given intermediate layer, the paper motivates to maximize the mutual information between the activations in this layer and the input signal to retain relevant information, while minimizing the mutual information of the activations and a nuisance variable, where the nuisance is defined as having no mutual information with the target variable (e.g. the classification prediction). The authors argue that this local supervision allows to train the features at the intermediate layer such that they carry relevant information from the input to the target variable without resorting to direct supervision with the target variable. Direct computation of the nuisance variable is infeasible and the authors propose a bounded approximation. ",
    "The paper analyzes the pitfalls of locally supervised learning from the point of view of information propagation and proposes a new auxiliary loss that can facilitate locally supervised learning. The proposed loss, \"infopro loss\", is then relaxed to a tractable upper bound, which is then used instead. To implement the loss, mutual information is approximated with a decoder, as well as a classifier. The authors further introduce now contrastive learning fits in the framework as a lower bound maximization process regarding mutual information. The experimental results on standard datasets demonstrate the efficacy of the proposed method.",
    "This paper analyzed the reason why locally supervised training led to performance degradation. And based on the analysis, the author proposed the information propagation loss (can be understood as the combination of a classification loss and a reconstruction loss) aiming to prevent information collapse. Equipped with the proposed method, 40% memory footprint can be reduced demonstrated by their experiments, which is surprising. ",
    "In this paper, the authors propose to sample nodes of a given graph multiple times to form a set of K sub-graphs. GNNs are then applied on each sampled graph for learning node representations. For each node, all representations are combined for the downstream tasks. The idea of doing multiple sampling is to increase the chance that nodes with different neighborhoods can be more different in the set of sampled graphs, than only considering the original single graph. In contrast, nodes with same neighborhood will remain the same over all sampled graphs. This mechanism helps discriminate node representations better.",
    "The paper presents a method that should increase the expressive power of GNN. This method includes sampling subgraphs out of the input graph using a novel diverse sampling method and calculating the output of each node by using a shared GNN on each sampled graph and summing over the outputs. The empirical evidence presented shows that this method outperforms other GNN architectures such as GCN and GAT on several node classification tasks.",
    "This paper claims that existing GNNs often suffers from the limited capability of the aggregation function. This paper proposes a new framework of a diverse sampling of the graph to solve this problem. Specifically, this paper first samples several different graphs and use GNN on each graph to generate features, and finally use a type of injective multi-set aggregation function to obtain the final representation. The experimental results show that adding this module to GCN and GAT can further boost node-based multi-class classification performance. ",
    "The authors explored the robustness of video machine learning models to bit-level corruption. They investigated previous methods such as Out-Of-Distribution (OOD) detection and adversarial training and found that they are not effective enough to defense against the bit-level corruption.  Accordingly, this paper proposed a new framework, Bit-corruption Augmented Training (BAT), which utilizes the knowledge about corruption by bit-level data augmentation at the training stage. Also, the authors argue that the proposed method outperforms the previous methods in handling the bit-level corrupted dataset.",
    "The authors evaluate the effect of bit-level corruption, including network packet losses and bit corruptions, on video models such as action recognition and multi-object tracking. They found that the model performances drop significantly under severe corruption levels. To overcome this issue, they propose a defense method named Bit-corruption Augmented Training (BAT) to enhance the robustness of the model by embedding corrupted video samples in the training process. Results show that BAT is able to improve the model robustness over other methods such as Out-Of-Distribution (OOD) detection and Adversarial Training (AT). ",
    "This work investigates the problem of building robust video prediction models in the presence of signal corruption. The problem itself is not widely studied and experimental work like this one certainly opens some possibilities. The solution on the other hand is surprisingly simple and easy to implement. It serves the purpose of introducing the problem to a wider audience, and shed some light in different types of remedies. ",
    "In this paper, the authors propose learning node embeddings of time varying graphs. They extend the ideas from Skip Gram Negative Sampling (SGNS) to time varying graphs. They extend the relationship between SGNS and Matrix Factorization to a tensor setting. The key contribution seems to be learning a static embedding for each node and an embedding for a time step. These embeddings are combined to learn a time-aware node embedding. Experiments on multiple datasets show that the proposed method outperforms related benchmarks. ",
    "In this paper, the authors studied the problem of time-varying graph embedding problems. The authors generalized skip-gram based graph embedding method to time-varying graphs. The authors show that the method can be used to factorize time-varying graphs as high-order tensors via negative sampling. The authors carried out experiments on several time-resolved proximity networks with comparison to several state-of-art baselines.",
    "The paper proposes an implicit tensor factorization approach for learning time-varying node representations over dynamic networks.  The core method lifts the well-known skip gram based embedding approach from matrix to higher order tensors to support temporal dimensions. The authors claim that such tensor based treatment allows to disentangle the role of node and time. Negative sampling method ( similar to noise contrastive estimation) is extended the higher order tensor setting and incorporated in the cross entropy objective for training. In the experiments, the authors consider five variants of face-to-face proximity data that contains temporal interactions and focuses on tasks of node classification (predicting outcome of SIR epidemic process) and link prediction (in the form of event reconstruction). The proposed method has been compared against two discrete time graph representation learning model and a recently proposed tensor based method. The authors claim that the provided method shows comparable performance with requirement to train lesser number of parameters. Also, the authors provide qualitative analysis in terms of embedding visualizations and goodness of fit plots. ",
    "The authors propose a self-supervised learning task to enhance the reasoning capabilities of machine learning models on mathematical formulas and to perform conjecturing in higher order logic. The task consists in masking out specific portions of mathematical statements and predict them from the surrounding parts. The task can (i) be used during training, to provide supervisory signal to the machine learning model and to increase the effective size of the otherwise small training dataset, and (ii) be used during testing, to evaluate the reasoning capabilities of the learnt models by masking out the mathematical statements at different level of granularities. The authors perform an extensive experimental analysis and provide evidence on the utility of using self-supervised learning in the context of theorem proving.",
    "This paper proposes a skip-tree training task. The authors show that self-supervised language models (the Transformer architecture to be exact) trained on the proposed skip-tree training task for mathematic theorem proving enable mathematical reasoning capabilities. Moreover, no fine-tuning is required to achieve the reported reasoning capabilities. They compare the mathematical reasoning abilities of the skip-tree training task with skip-sequence and show an impressive performance improvement. Another interesting result is studying whether any useful (novel) conjectures can be generated by the model.",
    "This paper extends the idea of language-model style self-supervised learning approach to training logical reasoning models from unlabeled mathematical expressions. The main idea is to develop a skip-tree proxy task (self-supervision) for training the encoder-decoder architecture.  The skip-tree method masks out a complete sub-tree in the input and linearizes it into a sequence in the form of S-expression. The model is required to predict the masked subtree at the decoder end. The paper also proposes several new reasoning tasks for evaluating the model performance. Experimental results show that models learned from this task significantly outperform those trained on the skip-sequence task. Furthermore, the model also exhibits good conjecturing ability in generating quite reasonable amount of new theorems that are provable and useful, which is quite encouraging and impressive.",
    "The paper introduces and analyses the possibility that the effectiveness of PGD-based adversarial attacks might be reduced by imbalanced gradients between the terms of the margin losses commonly used. As a remedy, it also proposed a new scheme for PGD attack, where for the first half of the iterations a single-term loss is optimized, before falling back on the the usual margin loss. The authors test the hypothesis of imbalanced gradients, introducing a new metric, GIR, and the newly proposed attack in two versions, MD and MDMT, on several defenses based on adversarial training.",
    "This paper explores constructing adversarial examples in classification, in order to create better robustness metrics for general classifiers. An attack is defined as an epsilon-perturbation of the learned parameters which create a model whose performance is much degraded. The premise of this paper is to use gradient imbalance as a way of creating perturbation targets, which are claimed (and shown numerically) to better fool networks that are trained to withstand more traditional attacks, and can be used to create more robust models in general.",
    "This work highlights the existence of imbalanced gradients as a phenomenon that may hinder optimization of gradient-based adversarial attacks and, thus, give a false sense of robustness. Imbalanced gradients may occur as the attack objective consists of the difference of two terms (typically, the outputs of the network on two different classes). When the gradients of these two terms have opposite directions, the attack optimization may get easily stuck in a suboptimal local optimum, thus decreasing the attack effectiveness.",
    "This paper proposes a model for verifying semantic equivalence  between symbolic linear algebra expressions. Expressions are represented by trees and equivalence is proven by a sequence of axioms applied to the first expression. The proposed model encodes the expression/program trees as nodes on a graph connected by edges representing one of a set of axioms being applied to one of the elements in the first expression to yield a node in the second expression. The output of the model is a path, a sequence of edges, on this constructed graph that correspond to a sequence of axioms applied to the first expression to arrive at the second.",
    "The authors introduce a new synthetic dataset of equational proofs over the basic axioms of linear algebra.  The dataset consists of triples `(t1, t2, rewrites)` where `rewrites` is a sequence of rewrite instructions that can transform `t1` into `t2`, though some of their models emit one rewrite at a time and observe the result of applying the rewrite instruction to `t1`.  They develop a GNN for the task called pe-graph2axiom and show that it beats two baselines.  Finally, they show that their trained system can solve 15 problems from two Khan Academy modules that can be expressed in their fragment.  The appendix refers to supplementary material including code and data, but no supplementary material was submitted.",
    "This paper proposes a synthetic dataset of algebraic expressions with various kinds of symbols (e.g. scalars, vectors, matrices), and applies graph-to-sequence networks (with attentions) for predicting a sequence of rewrite rules (i.e. axioms) as an equivalent proof between two expressions. The prediction can be validated by a simple checker so that any false positives can be eliminated.",
    "The paper is a nice read. It builds on a line of research on multi-modal video understanding that utilises transformers where these works: 1) fix one of the transformer models (e.g. BERT) and 2) utilise tokens and thus do not train the approach in an end-to-end fashion. This typical trend is due to the memory requirements for training a multi-modal transformer end-to-end.",
    "In this work, the authors present a method for learning audiovisual (AV) representations from videos using a Transformer-based model architecture. Since both video processing and Transformer-based model are memory-intensive, a parameter-reducing scheme is proposed, which facililates training the model end-to-end. The AV representations are learned by training the network to solve two self-supervised pertaining tasks, and subsequently evaluated on various audio/visual downstream tasks. An ablation analysis is performed to demonstrate the efficacy of the various contributions.",
    "This paper studies modeling and training choices when designing a single model based on ConvNets and transformers for audio-visual representation learning. It proposes ablations for which weights/layers to share across modalities, when/where to fuse/join both modalities, and other modeling details (that matter). It also completes pre-training with 3 InfoNCE (audio-audio, visual-visual, audio-visual) with a binary classification loss about if two pairs of audio-visual are from the same or different videos. As strategies for negative sampling in audio and videos are different, it proposes to sample negatives that are similar in the ConvNets' embeddings. The models are pretrained on Kinetics-700 and AudioSet and evaluated on UCF101, ESC-50, and Kinectics-Sounds.",
    "The paper proposes a new learning paradigm that combines both few-shot learning(FSL)  and continual learning (CL) to provide a more realistic learning environment rather than the traditional train-test-retrain approach in FSL. Two environments are proposed, along with a novel dataset. The evaluation seems to be thorough, with strong baselines (conventional approaches adapted to the proposed setting). A novel approach is proposed based on augmenting ProtoNets with contextual memory and is shown to have consistently strong performance compared to the baselines on both tasks.",
    "The paper presented a new setting of online contextualized few shot learning to mimic human learning. This setting combines continual learning and few shot learning, and additionally considers context switch. Specifically, a learning method is presented with a sequence of samples that might come with labels. The method is then tasked to classify the current input into known categories, or recognize the input as belonging to a \u201cnew\u201d category, while at the same time updating the model for known and new categories. Two new datasets (hand-written characters and indoor images) were constructed to support the learning setting. An extension of Prototypical Network (Snell et al.) was explored for this new setting. The results were compared against several baselines and were quite promising. ",
    "This work aims to make a realistic learning setting by combining few-shot learning and continual learning in the online setting. Similar to few-shot learning, the model needs to adapt to new classes with a few samples (at least in the beginning). Similar to continual learning, the model needs to learn new classes over time while being tested on the older classes as well. When encountering a new class, the model is expected to recognize that. Similar to the online setting, model evaluation happens on each trial, after which the model can be updated with that data (labeled or unlabeled). This new paradigm is called Online Contextualize Few-Shot Learning.",
    "This work empirically evaluates the sliding-window strategy for training GNNs with temporal graphs. One may cast the temporal nature of the graph data in an online setting, under which the change of the graph structure as well as the variation of the classes cause distribution shift. The authors conduct a series of experiments to show that the sliding-window strategy is as effective as using the entire historical data for training.",
    "This paper proposes a paradigm which speeds up the training time of GNNs while not compromising too much performance. The method adopts a layerwise training procedure. In particular, the authors inject a loss function at each layer while storing and fixing the feed-forward values of its previous layer. The training is then carried out along all layers parallelly, which allows the updating of paradigms to be decoupled and is not applicable in previous works. A further improvement (lazy-update) by not updating the feed-forward values of each layer is used to reduce the training time.",
    "This work studies the problem of online or incremental learning in temporal graphs (dynamic networks), and more precisely, whether past data can be discarded/ignored without losing predictive accuracy under the assumption that there is the presence of a distribution shift. This question has been essentially investigated over the years in various contexts, e.g., relational learning and classification in dynamic or time-evolving networks. It is also completely obvious that forgetting older data, especially under the assumption of a distribution shift, makes sense and is the correct thing to do. This is exactly what has been done in time-series forecasting for decades. The problem formulation is unclear and can be more precisely defined and motivated appropriately. This needs to be fixed. Are the class labels of a node changing over time, so if a node has label A at time t, then at time t+1 it could have label B, etc. This doesn\u2019t seem true, as it seems the class labels of the nodes are \u201cstatic\u201d, which is unrealistic in many cases. How are the graph snapshots created? How was the timespan selected? What does every time step represent (1 hour, 5 minutes, etc.)?  Also, are the node features changing over time? This doesn\u2019t seem true, but if this is the case, then it is unclear why this would be the case in practice (it would be great to provide some motivation for this, or an example application or problem where this may be true). There are many assumptions that make this problem unrealistic. Furthermore, there have even been works that study the dynamic node classification problem previously, see [1-2] below. ",
    "This paper proposes a new method for learning representations of images with the goal of improving generalization in RL. The key idea is to regularize the learned feature space by forcing embeddings of states followed by the same action (or sequence of actions) to be more similar than embeddings of states followed by different actions. The method is evaluated on the Procgen and achieves superior performance relative to Rainbow, a standard RL algorithm.",
    "This paper tackles the problem of representation learning from visualized input. The paper presents \"cross-state self-constraint(CSSC)\", a technique for regularizing the representation feature space by favoring representation similarity (scalar product between representations) between representations when the agent behaves similarly. The approach is tested with deep RL on the OpenAI ProcGen benchmark.",
    "The authors modify the Rainbow loss through an additional loss based on a cross-state similarity. The notion of similarity is called in the paper \"cross-state self-constraint\" - CSSC. The CSSC loss looks very simple and can be applied with other RL algorithms. The loss is defined in terms of an embedding e of the visual input into a 1-dim space. Given three states x_p, x_q, and x_r, their similarity is defined as the scalar product of e(x_p) and e(x_q) minus the scalar product of e(x_q) and e(x_r). It would be useful if the authors include pseudocode how the loss is exactly computed for a given batch of samples. My understanding of the description is that for a given batch the authors generate triples with the same action set and then take as an auxiliary loss the weighted sum of the logarithms of sigmoids of similarities of these triples.",
    "This paper studies the problem of designing adversarial attacks (on GNN models) that perturb the feature to maximize the misclassified instances. Assuming that the activations are activated independently at random, the paper shows that the attack design can be reduced to the influence maximization problem under the threshold model. The paper identifies several conditions on the threshold that can make the influence maximization problem submodular, thereby making it easy to optimize.  Experiments have been shown that the proposed attack method has higher performance compared to the existing ones.",
    "Paper summary: The paper studies the problem of attacking GNNs in a restricted black-box setup, i.e., by perturbing the features of a small set of nodes, with no access to model parameters and model predictions. The authors draw a connection between the restricted attack problem and the influence maximization problem, and then propose several approximation techniques to solve the reformulated attack problem. Experimental results on attacking three GNN models demonstrate the effectiveness of the proposed attack. ",
    "This paper introduces a novel connection between adversarial attack on graph neural networks in a restricted black-box setup via node feature perturbation, on the one hand, and the influence maximization problem under the linear threshold model on the same graph, on the other hand. An analysis shows that the objective function of the corresponding IM problem is submodular under assumption, hence the problem admits greedy approximation algorithms as effective black-box attack strategies. Experiments show such attacks are effective compared to baselines in degrading the performance of GNNs in terms of mis-classification rate.",
    "This paper attempts to exploit the low-rankness of the adjacency matrix of the DAG in Bayesian network structure learning. The overall framework is similar to NOTEARS, except that the adjacency matrix W is decomposed into low rank components W = UV'. To justify the approach, the paper also includes lower and upper bounds of the rank of DAGs, albeit mostly theoretical and not applicable to real experiments. ",
    "The paper develops several useful lower and upper bounds on the rank of DAGs \u2014 specifically minimum and maximum rank of all weighted matrices that induce the same DAG \u2014 in terms of various graphical properties like head-tail vertex cover, number of non-root and non-leaf vertices. The paper also bounds the rank of DAG in terms of the rank of its skeleton and moral graph. The paper proposes learning low-rank linear or non-linear structural equation models (SEMs) by adding simple norm constraints or matrix factorization to existing SEM learning methods. Through experiments on synthetic and real world data the authors demonstrate that when the underlying SEM is low-rank, exploiting this low-rank assumption in the learning process can lead to better performance. The authors also demonstrate that the rank can be estimated using the obtained bounds from a validation set.",
    "The paper provides a new approch for learning a (possibly densely-connced) low-rank DAG models in the high dimensional settings. In particular, this paper provides how to exploit the property of the low-rank for recovering a underlying causal structure. Futher shown is that under what circumstance the low-rank assumption holds and heuristically confirms that thgrough simulation settings. Lastly, the proposed approach is compared against the state-of-the-art DAG learning algorithms that requirs the assumption of a sparse graph.",
    "This paper shows how the complex autoML pipeline for neural networks can be trained in an end-to-end manner by combining existing methods. By using backpropagatable discrete sampling methods (Gumbel softmax), input transformed by data augmentation is seamlessly embedded in full backpropagation flow. And a differentiable architecture search algorithm is used, which also incorporates architecture search in full backpropagation flow. On top of this differentiable procedure, an alternating optimization is introduced to train network parameters and hyperparameters.",
    "Some of the choices that have to be made when training a neural net based image model are: type of data augmentation, architecture of the neural network, and other hyperparameters such as regularization and optimization hyperparameters (e.g. learning rate). Optimizing all of these is a challenging problem, NAS deals with architecture but ignores the others. More general hyperparameter optimization techniques such as Bayesian Optimization struggle with the dimensionality of the architecture parameters. And optimizing them independently might lead to local minima, and/or be slow.",
    "This paper focuses on achieving automated \"from data to model\" including different components in modeling, namely data augmentation, Neural Architecture Search, Hyper Parameter Optimization. The proposed approach first use data augmentation to select the data argumentation transformation. It tries to select examples which incurs higher training loss for the model to address hard examples. Then use the DAG for neural architecture search. Given the data and architecture, it then alternatively update the model parameter and hyper parameter. The overall proposed framework is end-to-end. Experiment on ImageNet shows slight performance improvement over existing approaches. The authors also conduct ablation study to show the effectiveness of jointly modeling the three components (data augmentation, neural architecture search, hyper-parameter optimization).",
    "This paper extends Prior networks models, previously introduced for classification, to regression problems.  Prior networks are neural networks whose main target is to \"modelling uncertainty in classification tasks by emulating an ensemble using a single model\".  Standard Prior networks models output the parameters of a Dirichlet probability distribution. This Dirichlet probability distribution then defines a distribution over categorical probability distributions over the different classes. This hierarchical approach allows to better capture uncertainty. The presented approach extends this framework to regression tasks. So, instead of returning the parameters of a Dirichlet distribution, it returns the parameters of a Normal-Wishart distribution, which then defines a probability distribution over Normal distributions, and, in turn, each Normal distribution defines a probability distribution over the value of the target variable.  ",
    "Prior Networks (Malinin & Gales, 2018) use Dirichlet prior over categorical predictive distributions to distill ensembles for classification tasks. This paper extends Prior Networks to the regression setting by using a Normal-Wishart prior in order to attempt to match the predictive diversity. The authors define the model and loss terms including analytical derivation and evaluate their proposed approach with synthetic data, UCI datasets and monocular depth estimation. ",
    "This paper addresses interpretable uncertainty quantification for data driven models. In particular, the authors focus on a sub-class of methods known as Prior Networks and attempt to extend these methods to regression tasks as existing approaches address classification only. The author contribution is thus clearly stated and positioned w.r.t. prior arts and tackle a non-trivial issue.",
    "The paper develops a semi-online Bayesian approach to meta-learning, where tasks arrive sequentially and learning within any task is performed in batch mode (hence my terminology semi-online). It suggests a sequential between-task Bayesian update, eq. 5, and proposed three approximations to aid computation. The basic setup is motivated within the recently introduced MAML framework where the learning takes place by adapting a within-task parameter to effectively set up learning within each individual task, allowing the learner to transfer information between tasks, while remaining adaptive to a specific novel task. The authors phrase this idea in the Bayesian language of posterior distributions, that are updated both within and between tasks. The posterior formed after learning t tasks, serves as a prior for learning a new task. The authors suggest 3 approximation schemes, a Laplace approximation, a Hessian approximation, and a variational approximation. Finally, a set of experiments are presented comparing performance to 2 baselines, namely TOE (train of everything) and TFS (train from scratch). A particularly interesting application is to 5 standard sets of images, testing for catastrophic forgetting of previous tasks and the transferability of  information across tasks in the face of distributional shift.",
    "The paper proposes an Bayesian approach to online meta-learning. This is done by lifting (approximate) sequential Bayesian inference from the model parameters to the meta-parameters. Two approaches are proposed to do this: (i) Laplace Approximation (LA), thereby extending Ritter et al\u2019s method from online learning to online meta-learning; and (ii) VI, thereby extending Nguyen et al\u2019s Variational Continual Learning (VCL) method in a similar way. Experiments are performed by converting existing meta-learning benchmarks into online settings in two ways, which they call \u201csequential tasks\u201d and \u201csequential datasets\u201d respectively. The experimental results show resistance to catastrophic forgetting in both of these experimental settings. ",
    "This work proposes a Bayesian approach to meta-learning from sequential data. Two algorithms are proposed. The first is based on the Laplace approximation to the model posterior which is made tractable by using K-FAC approximation of the Hessian. The second approaches uses a variational approximation for the posterior, where meta-learning corresponds to learning the variational prior. The experiments present results of the proposed method in sequential Omniglot and a pentathlon task involving different datasets.",
    "The paper has a fully theoretical flair while proposing a novel and seemingly efficient procedure to recursively compute the higher-order (i.e. more than 1-hop) neighbourhood of a node that are used for learning discriminative graph embedding. The paper contributes with the model above (RNP-GNN) and by providing a proof of its representational power and a general theorem supplying an information theoretic lower bound on the complexity of GNNs that can count induced substructures.",
    "The goal of the paper is to show that GNN's (without exponential computational complexity) can be constructed with the ability to count subgraphs. To this effect, the authors propose a principled neighborhood pooling strategy and theoretically characterize their expressive power - with respect to other models proposed earlier. More specifically, the authors propose a recursive neighborhood pooling strategy which characterizes graphs based on the counts of subgraphs . Furthermore, they show that if the tuple of recursion parameters are chosen well, their proposed model can capture all induced subgraphs (universality) of sizes smaller than the first value in the tuple of recursion parameters plus 1 - and show a relationship to the reconstruction conjecture (Kelly et al. 1957). The authors also provide a bound on the number of iterations required to learn the expressive representations.",
    "The proposed paper seeks a theoretical possibility of counting the subgraph by a graph neural network. To this end, the authors proposed a recursive neighborhood pooling graph neural network and proved the express power of the model. The universal approximation results on a subgraph have been shown as well. Analysis of computational complexity shows the algorithm is much efficient than the known class of models that can count substructures.",
    "This paper studies Lyapunov chaos in learning algorithms for matrix games. It appears to extend earlier work by Cheung and Piliouras to more general-sum settings with the conclusion that in these more common settings the learning algorithms considered exhibit chaos. The paper also presents an interesting notion of matrix domination which is a necessary and sufficient condition for chaos, and also a linear programming approach for the purpose of identifying chaotic games.",
    "This paper studies the chaos phenomena of learning in general normal-form games beyond zero-sum and coordination games. Building upon the previous works by Cheung & Piliouras, the authors apply the canonical decomposition of a general bimatrix game to a sum of a zero-sum game and a coordination game. The authors further devise two new techniques: matrix domination and linear program to help analyze the game dynamics.",
    "This paper provides tools for classifying the payoff dynamics in general-sum n-player games as Lyapunov chaotic assuming three common algorithms are used: multiplicative weights update (FTRL with entropy regularizer), optimistic MWU, and FTRL with L2 regularizer. Previous work (Cheung & Piliouras) showed that the existence of Lyapunov chaos in the dual space is indicated by the sign of a function C of the game. This work shows that this function can be decomposed into a sum: C of the zero-sum part + C of the coordination part. They also show how to use trivial matrices (which don't affect C) to further reduce parts of the game in a way that eases the analysis. As part of their analysis, they prove that the set of bi-matrix games exhibiting chaos has positive Lebesgue measure and discuss how the relative strength of the zero-sum and coordination parts determines the ultimate sign of C.",
    "The paper provides a new family of adaptive optimization algorithms by designing the proximal function of the adaptive algorithms to minimize marginal regret bound. The paper shows that the regret bound is better than existing algorithms in a sense. The paper also presents simulation study on a variety of domains that compare the proposed algorithms with other commonly used algorithms.",
    "This paper proposes a new class of adaptive algorithms inspired by finding an optimal proximal function of adaptive algorithms. They provide a theoretical analysis of the new method showing that it would potentially improve the regret bound of current algorithms. Finally, the proposed method is empirically matched with or superior to other popular algorithms on different tasks. ",
    "This paper introduces a new online convex optimization algorithm that operates in via the reduction to online linear optimization in which the regret is bounded by $\\sum_{t=1}^T \\langle g_t, x_t - u\\rangle$ where $g_t$ is the gradient of the t^th loss at $x_t$. The algorithm is based on online mirror descent with non-decreasing quadratic regularizers $x^\\top H_t x$, using the update $x_{t+1} = argmin_x \\langle g_t, x \\rangle + (x-x_t)^\\top H_t(x-x_t)$ (or, equivalently using the terminology in the paper, $argmin \\langle g_t, x_t\\rangle /\\sqrt(t) + (x-x_t)^\\top H_t(x-x_t)$ where we replace $H_t$ by $H_t/\\sqrt{t}$. The analysis is restricted to diagonal $H_t$, for which we can break the regret into a sum of $d$ 1-dimensional problems, so it suffices to do the analysis in the scalar case. The idea is to break out the standard analysis of mirror descent regret as the sum over all t of $D^2(H_t - H_{t-1}) + g_t^2 H_t^{-1}$, where $D$ is the $\\ell_\\infty$ diameter of the domain, and then choose $H_t$ to minimize each of these terms greedily subject to the non-decreasing condition. A regret bound is provided for this algorithm that achieves worst-case $\\sqrt{T}$ regret, but in cases in which the gradients are small, the regret is much better. By employing this strategy on a per-coordinate basis one can obtain an adagrad-esque regret bound.",
    "The paper proposes an Expected Quadratic Utility Maximization (EQUM) framework for policy grandient Mean-Variance control. The authors claim that current state-of-the-art methods suffer either suffer from computational issues or cannot control risk at desiderable level, hence they propose their approach as a possible solution. They provide different interpretation for the EQUM: standard objective with a regularization, variance minimization with a constraint on expected return and a return targeting optimization. A policy gradient algorithm for EQUM is proposed together with its Actor-Critic extension.",
    "The paper proposes a policy gradient style RL algorithm that optimizes an expected quadratic utility, a commonly used objective of risk management in finance and economics. The key idea here is based on the observation that when using the quadratic utility function, the use of mean-variance RL methods can be shown to optimize the utility of the agent. To this effect, the paper considers the use of expected quadratic utility maximization in the policy gradient. The quadratic utility can be naturally modeled using mean and variance. The paper implements two variations -- policy gradient and actor-critic with EQUM framework. ",
    "In this paper the author proposed a new mean-variance algorithm whose policy gradient algorithm is more simpler than other SOTA methods and it has an unbiased gradient. Instead of formulating the problem as an traditional mean variance constrained problem, the authors utilized quadratic utility theory and formulate the problem as variance minimization problem with a mean reward equality constraint. Then by reformulating the problem with the penalized problem and opening up the variance formulation, they showed that this mean-variance formulation does indeed have an unbiased policy gradient, that does not require advanced techniques such as double sampling or frenchel duality. To demonstrate the effectiveness of this method on balancing risk and return, they also evaluate their methods on several risk-sensitive RL benchmarks (such as portfolio optimization) and compared with a wide range of risk-sensitive RL methods.",
    "This paper pinpoints the key issues of Auxiliary Learning: (1). how to design useful auxiliary tasks, (2) how to combine auxiliary tasks into a single coherent loss. Motived by the issues, this paper proposes a novel Auxiliary Learning frame work, named AuxiLearn. The paper is globally well organized and clearly written. ",
    "This paper studies a variant of multi-task learning, auxiliary learning, where one main task dominates, and other tasks are used to learn a good representation. To achieve this goal, the authors propose a learning-to-learn algorithm. In particular, the auxiliary losses are represented by a vector and then transformed to a new loss term via linear or nonlinear function $h$. They also made two more contributions. First, an approach of new auxiliary task generation is proposed. Second, an implicit differentiation based optimization method is proposed to find the solution. Both theoretical analysis and empirical studies demonstrate the superiority of their proposed model.",
    "The paper proposes AuxiLearn, a framework that can be used to combine losses from multiple auxiliary tasks (if present) into a single combined, loss function that does not require expensive grid search over possible linear combination. It uses an implicit differentiation-based approach to train a (deep) non-linear network that weighs the various auxiliary losses to optimize the generalization capabilities of the network. In the absence of such pre-defined tasks, a variation of the approach, using teacher-student networks, helps create relevant tasks to improve the performance of the network. Experiments across tasks such as classification (both few-shot and with limited labels) and segmentation show that the approach helps improve the performance of the model on the main task.",
    "The paper proposes a technique for assessing the uncertainty of a Transformer-based NMT model on a given input $x$. The technique relies on computing a variance-like estimate over a collection of translation candidates for $x$, where these candidates are obtained by perturbing the decoding mechanism through the use of dropout at test time. Experiments compare this technique with other ways of measuring the \"epistemic uncertainty\" of the NMT model. In limited training data conditions, the proposed measure is better aligned with the actual performance of the model than competing measures, and in particular is better able to detect Out-of-Domain translation requests.",
    "The paper proposed a Baysian method for detecting out of distribution (OOD) in machine translation. To this end, the paper introduces BLEU variance (BLEUVar) that is computed based on a number of samples from Transformer with MC Dropout. The advantage of BLEUVar is that it doesn\u2019t require reference, instead it\u2019s computed based on pairwise comparison of the decoded sentences.",
    "This paper describes a method for estimating a neural machine translation (NMT) system's uncertainty about its translation of a sentence that has two parts: (1) use MC Dropout as a proxy for integrating out parameters; (2) two uncertainty metrics (probability of translation summing over randomly-sampled parameters and variance in BLEU using randomly-sampled parameters). The baseline method is just to use the probability of the 1-best translation under the MLE parameters. The method is evaluated by measuring the BLEU score of a test set retaining only the most-certain fraction of the sentences.",
    "Generating a pruned network falls into two broad categories: 1) spend some extra time and effort to train or fine-tune the pruned model after first training a dense version, or 2) cut out that extra time and effort by generating a sparse network \"from scratch.\"  While approach (1) has historically given the best accuracy, recent advances (such as the lottery ticket hypothesis) suggest that there are sparse networks hidden in the initialization that don't need to first be trained, if only we could divine the structure of those models.  Approach (2) seeks to do just this: determine the connectivity as close to initialization possible.  However, even the best results taking this second path fall short when compared to the accuracy of the former path - why is this?  The submission pokes at three recent techniques to pull out some commonalities that are *not* shared with (1), suggesting possible issues that need to be overcome to improve accuracy, and proposes a set of experiments and comparisons that should be part of any new technique that claims to discover a good sparse mask at initialization.",
    "The paper provides an extensive empirical analysis of Pruning-at-Initialization (PaI) techniques and compares it against two pruning methods after (or during) training. This comparison sheds some light on why pruning at initialization is inherently hard. Furthermore, the comparison among PaI methods with various ablations shows some inherent properties that are common to PaI methods and the benefits/drawbacks of certain methods. With these experiments, certain conclusions are reached among them an important one is that PaI methods only determine what is the fraction of weights to be pruned in each layer rather than which weights to prune.",
    "A recent trend of 'pruning at initialization' in neural network pruning has left me baffled. It's counter-intuitive that neural networks can be pruned at initialisation, improving results for the training done thereafter. Nitpicking semantics, one could hardly even call this a pruning technique, since there is no a-priori knowledge of the dataset distilled in the network. Perhaps it's more aptly referred to as a method of sparse initialisation methods.",
    "The paper claims to be the first paper that simultaneously handles Byzantine threats while ensuring privacy in a federated learning setup. One of their main claims is that this is the first algorithm that provides dimension independent robustness guarantees against byzantine threats (I have some concerns regarding this claim). The algorithm first divides all the machines into shards. Within each shard there is secure aggregation. Finally, the outputs of each shard is robustly aggregated such that the error isn't dimension dependent.",
    "The paper considers robustness to poisoning and backdoor attacks in the context of federated learning. It proposes a defence based  on splitting the clients into shards, averaging their updates via secure aggregation and then using a robust mean estimation on top to ensure robustness. The authors point out that controlling the number of shards is a way to trade-off privacy vs robustness, thus potentially dealing with both malicious clients and an honest, but curious server. The paper provides some theoretical justification for the algorithm, as well as an experimental evaluation where its performance is tested against multiple attacks and compared to other existing methods.",
    "The authors consider federated learning setting and how to defend the overall learning task against malicious clients and a semi-honest centralized server. Though there are known ways to prevent attacks, they suffer from a large error in the estimator and also do not preserve privacy of updates since the server sees them in the clear in order to adjust for error. This paper proposes a sharding technique and use of the estimator method whose error does not depend on the number of dimensions as previous work.",
    "This paper focuses on model-based black box optimization problems in the offline setting. These are settings where access to ground truth is expensive, and instead the optimizer has access only to a trained model of the ground truth based on limited data. While optimizing on this surrogate space, a good optimizer often needs to account for model uncertainty and accuracy degradation. The main aim of the paper is to provide a test bed for algorithms that try to solve this challenge. ",
    "This paper studies the evaluation of offline black-box optimization algorithms. The community currently lacks a standardized benchmark to compare the performance of methods. This paper presents a new suite of offline model-based optimization tasks and standardized evaluation procedures for the community. The evaluation criterion for the quality of a benchmark is the realism and diversity of the tasks, with special consideration for high-dimensional design space and the objective function's sensitivity. The paper then evaluates several algorithms on the benchmark. ",
    "This paper proposes a benchmark suite of offline model-based optimization problems. This benchmark includes diverse and realistic tasks derived from real-world problems in biology, material science, and robotics contains a wide variety of domains, and it covers both continuous and discrete, low and high dimensional design spaces. The authors provide a comprehensive evaluation of existing methods under identical assumptions and get several interesting takeaways from",
    "This paper focuses on providing a more generalize multimodal ELBO to encompass previous PoE and MoE as special cases and combines their benefits. To this end, the authors first define the new ELBO L_{MoPoE} which is an interesting extension of PoE and MoE. Different from PoE (product of experts) and MoE (mixture of experts), MoPoE (mixture of product of experts) explores a more general way by mixing more experts where each expert is the product of a subset of all modalities\u2019 posterior. In this way, as illustrated by the author, PoE and MoE can be seen as specific cases of MoPoE easily. The proposed model achieves competitive results compared with PoE and MoE.",
    "The paper combines ideas from two previous works (MVAE and MMVAE) to propose a new multimodal formulation of the ELBO for VAEs. The approximate posterior consists of a mixture of subsets, with each subset a product of approximate posteriors for each modality. This generalizes previous works, and the authors show that their objective yields a lower bound on the full data log-likelihood. They also compare their approach with MVAE and MMVAE on three multimodal datasets, showing benefits in classification accuracy, coherence, and log-likelihood. Although the proposed method is not superior in all cases, it generally achieves a reasonable trade-off across performance metrics.",
    "This paper formulates a multimodal ELBO as a mixture of product of experts. This allows them to use one encoder per mode while still allowing inference over any subset of modes without needing a new encoder for each subset. The idea is simple and appears to improve on baselines derived from a mixture or a product of experts.",
    "The goal of this paper is to enable the introduction of prior expert knowledge in Bayesian optimization. This is performed by defining a prior distribution for the optimal value, which is included in the pseudo-posterior used to select new points by Expected Improvement. The number of iterations it takes to overcome a potentially wrong prior information is controlled by a parameter, whose sensitivity is studied. Extensive experiments are conducted on toy examples as well are more realistic hyper-parameter test cases.",
    "This paper incorporates a prior distribution given by experts into Bayesian optimization (BO), to leverage useful human knowledge to accelerate BO. The algorithm uses an intuitive approach to combine the prior with the probabilistic surrogate model of BO to derive a pseudo-posterior, which naturally leads the EI acquisition function. As the BO progresses, the prior information is gradually overwhelmed by the observed data, which ensures the asymptotically correct behaviour.",
    "The paper presents a novel method to incorporate experts' knowledge into BO. This is done through introducing  Prior-guided Bayesian Optimization (PrBO). Different experiments where conducted to compare PrBO vs different baselines and to show the effect of the user provided priors in the cases where it is well-specified or mis-specified. The design of PrBO enables it to guide the search in the early iterations and as optimization progresses, more emphasis is given to the model and the effect of the prior is washed out.",
    "The paper introduces the first way (to the best of authors knowledge) of building generative models with binary weights. Also the case with binary activations is considered. The authors consider two SOTA generative models (flow++ and RVAE) and develop technique to binarize all weights (and possibly activcations) in residual layers. They show that residual layers can be binarized with relatively small drop in performance and further binarization of remaining blocks in computational graph leads to significant degradation. Binary modification of weight normalization is suggested although no ablation is study is performed so it is unclear how crucial is BWN for robust learning. The training process itself is pretty standard way of training binary DNNs - they use STE + truncation of real-valued weights counter-parts.",
    "The authors propose to binarize weights and activations of generative VAE and Flow++ models. As Weight Normalization is commonly used in these models, the authors notice that Euclidean norm of binary [-1;1] vector is a square root of it\u2019s length, such that Weight Normalization can be reduced to affine scaling. They propose to call this scaling Binary Weight Normalization, and evaluate it on CIFAR and ImageNet datasets.",
    "This paper describes a method to binarize weights and activations of variational autoencoders and flow-based networks.  This is an important issue as these methods are valuable to solving unsupervised problems, but are rapidly growing in size, necessitating large and expensive computing systems. And, the literature of low and binary precision hasn\u2019t considered these use-cases to date.",
    "The paper extends current adversarial learning approaches beyond imperceptible L_p norm perturbations. The proposed approach can handle many models of natural variation, such as a change in brightness. The main idea behind the approach is to use unsupervised approaches such as GANs to model the natural variation. Given this model of natural variation, the paper replaces the adversarial learning objective of finding the worst example in an L_p norm ball around a data point to finding the worst example based on the model of natural variation. This is expensive, so the paper also proposes more computationally efficient approaches based on data augmentation. The experimental results demonstrate that the proposed approach performs well on a variety of tasks.",
    "This paper proposes a model-based framework for improving the robustness of image classifiers to average-case corruptions of varying severity. The proposed framework can be thought of as adversarial training where the perturbation is replaced by a function that transforms the image according to a specific corruption. A nuisance parameter controls the instantiation and severity of the corruption that is applied to the input. The paper compares baselines to different versions of this general model-based framework with experiments on several datasets.",
    "This paper proposes a \u201cparadigm shift\u201d for augmenting datasets when training CNN-based image classifiers. On one side, traditional augmentations include blur, Gaussian noise, color distortions. On the other side, methods like adversarial training consider augmentations under norm bounds in the image space. The proposed method, instead, uses models of natural variation to augment the images. Increased out-of-domain accuracy is shown on ImageNet-C and several slices of the CURE-TSR dataset. ",
    "The paper studies the non-convex optimization problem of training CNNs with ReLU activations under different choices for the CNN architecture, and shows how these can be framed as convex problems with a poly time complexity w.r.t. relevant variables. The derived convex problems provide valuable insights on how the CNN architecture induces different weight regularizers by giving them in explicit form -- these show a rich connection between the architecture and regularizer.",
    "[Summary] This paper focuses on training convolutional neural networks (CNNs) by using convex optimization techniques. By taking the dual of the nonconvex training problems, (and the dual of its dual), the main contribution of the paper is to show the strong duality between the convex problem and its original nonconvex training problems. This result has been proved for multi-layer CNNs with one ReLU layer and three-layer CNNs with two ReLU layers.",
    "The paper considers several types of CNN and proposes convex reformulations for non-convex problems of training these networks. As a result a polynomial complexity is shown for the training problem. The results are also interpreted as implicit regularization induced by the choice of the architecture. Finally, numerical experiments are made to support the theoretical findings and show that in the predicted regime, SGD for the original problem converges to the global minimizer given by the convex reformulation.",
    "This is a well-written paper that discusses how to learn disentangled representations for the learning from demonstrations (LfD) task in robotics. It is shown that using weak-supervision on top of unsupervised learning frameworks (that use the variational autoencoder for instance) can work well in this case. These disentangled factors of variation in the data are shown to correspond well to the 'abstract concepts' of the human demonstrations. This is shown in the example of the PR2 robot dabbing demonstrations, including visual data as well robot trajectories. ",
    "Under the context of learning\u00a0from demonstrations, the paper studies the problem of leaning interpretable low dimensional representations\u00a0from high dimensional multimodal inputs using\u00a0weak supervision. Paper argues that since robots and humans have different levels of abstractions and mechanisms, observation+action spaces between them are greatly misaligned which\u00a0complicates learning by directly observing humans. However, the underlying concepts essential for tasks\u00a0lie in a much lower-dimensional manifold. Learning this\u00a0manifold\u00a0effectively and in an interpretable way, especially using weak supervision, can significantly change how robots\u00a0can acquire skills from demonstrations and generalize them to new unseen scenarios. Towards this end, the paper proposes to learn probabilistic\u00a0generative models capturing high-level notions from demonstrations using variational inference. The strength of the paper is in demonstrating that conditional latent variable models can learn disentangled\u00a0low dimensional represented using weak supervision;\u00a0which authors effectively demonstrated\u00a0using real-world\u00a0experiments. My main reservations are in terms\u00a0of the technical novelty of the paper and the narrow scope of experimental evaluation.",
    "This paper presents a way to learn from demonstrations with weak or no labels. The premise behind this paper is that even when humans provide labels during a demonstration, those labels often do not fully describe the data (e.g., the human may say \"soft\" when \"fast\" would also apply). This paper presents a technique that uses latent variables to model the uncertainty over a group of class labels that could describe the task (e.g., slow, soft, left-of-object). The variables are modeled such that the observation is conditionally independent of the human provided labels given the latent variables. This allows the human provided labels to be decoupled (or disentangled as the paper calls it) from the observations. By doing so, it is possible to have only partial labels (weak labels). This model was applied to a task where a human would teleoperate a robot arm and apply a dabbing motion in relation to an object in the scene. The operator would provide only one of several possible applicable labels for each demonstration. The results show that the models using the weak labeling out-performed models with no labeling.",
    "This paper studies fine-tuning BERT-like pretrained language models (PLMs) on low resource target tasks. The authors hypothesize that the general-purpose knowledge obtained by the PLMs from pre-training might be irrelevant and redundant for a given target task. When fine-tuned onto a low resource target task, overfitting is likely to happen. To this end, a fine-tuning framework based on variational information bottleneck (VIB) is proposed to address these challenges. Specifically, the sentence representation will be mapped to a latent Gaussian variable  which compresses information in the sentence and also suppress irrelevant and redundant features, and a reconstructed version of the representation is used for task prediction. Empirical evaluations on sever datasets demonstrates the effectiveness of the method over previous research.",
    "This work applies information bottleneck as a way to compress the pre-trained representation so that only meaningful features are employed for the target task. It is applied for the number of GLUE tasks especially focusing on low resource settings and show consistent gains over previously known strong baselines, e.g., Mixout and L2-of-difference. This work also demonstrates that the learned model has generalization capacity so that the tuned model works on out-of-domain data.",
    "The paper proposes a method to avoid overfitting while finetuning the large pretrained models for downstream tasks on small scale datasets. It has been shown that many SOTA models usually overfit w.r.t. spurious correlations in the data and as a result fail miserably when tested for generalization on the out of domain datasets. The proposed method tries to maximally filter out task-irrelevant information in the feature vectors by minimizing the mutual information between the original features and the bottleneck features while simultaneously optimizing for performance. Experiments on several datasets show improved performance on both in-domain and out-of-domain datasets.",
    "1. This is the first work that attempts to reconstruct 3D shape from 2D image in an unsupervised way using GANs. The idea is neat: Use networks to predict four 3D parameters and use GAN to generate / synthesize the images corresponding to a set of parameters. Then these synthesized images can be used as pseudo ground truth to train the 3D parameter network.",
    "This paper studies an interesting inverse-graphics problem. It proposed a novel method to learn 3D shape reconstruction using pre-trained 2D image generative adversarial networks. Given an image containing one single object of interest, it first predicts the graphics code (e.g., viewpoint, lighting, depth, and albedo) by minimizing the reconstruction error using a differentiable renderer. The next step is to render many pseudo samples by randomization in the viewpoint and lighting space, while keeping the predicted depth and albedo fixed. A pre-trained 2D image GAN is further used to project the pseudo samples to the learned data manifold through GAN-Inversion. Finally, these projected samples are added to the set for the next round optimization. Experimental evaluations have been conducted on several categories including face, car, building, and horse.",
    "This paper proposes an iterative method that jointly estimates viewpoints, light directions, depth, and albedo from single images, by projecting intermediate renderings to the nautral image manifold. Intuitively, the method works by generating, with pre-trained GANs, multiple views of the same object under different lightings, and then inferring 3D shapes from those variants. The key idea is to use pre-trained 2D GANs to make such data generation photorealistic. The authors also demonstrate 3D edits, such as 3D rotation and relighting, that one can perform after running their model.",
    "The majority of feature extraction backbone is shared among different agents and the classifiers of experts are trained with both classification loss and proposed distribution-aware diversity loss. For the second stage, an expert assignment module is trained to re-weight the expert decisions. The whole paper is generally well-organized. However, there are some technical issues authors should further address:",
    "This paper proposes a Routing Diverse Experts (RIDE) framework to solve the long-tailed classification problem. It has 1) a shared low-level feature extractor and multiple expert classifiers, 2) a distribution-aware diversity loss to encourage experts learning different classification strategies, 3) an expert routing module that dynamically selects a subset of experts for each test instance to make a joint decision. This paper firstly increases the performances on all three splits (many-/med-/few-shot), while most of the existing methods have to sacrifice the head for tail improvements.",
    "This paper proposes a method termed RoutIng Diverse Experts (RIDE) for reducing both the bias and the variance of a long-tailed classifier. Specifically, RIDE consists of three crucial components: 1) a shared architecture for multiple experts; 2) a distribution-aware diversity loss that encourages more diverse decisions for classes with fewer training instances; 3) an expert routing module that dynamically assigns more ambiguous instances to additional experts. Experiments are conducted on three long-tailed benchmark datasets, i.e., CIFAR100-LT, ImageNet-LT, and iNaturalist. Satisfactory classification results of long-tailed visual recognition are observed.",
    "The paper discusses various baseline scoring mechanisms used for filter pruning that are norm-based and finds that none of the scoring mechanisms are particularly effective at pruning filters from CNNs. Moreover, all methods seem to perform very similar to each other. These conclusions are based on a theoretical (and experimental) analysis of the various scoring mechanisms under the assumption that trained filter weights follow a Gaussian-like distribution, which reveals that in this case the scoring mechanisms are insufficient to reliably discern the importance of filters since the resulting scores are very similar. The Gaussian-like assumption, which is termed \"Convolution Weight Distribution Assumption\" (CWDA), is validated through a large range of experiments on different architectures and data sets.",
    "The goal of the paper is to bring into attention that many norm-based pruning criteria used for structured pruning are very similar, in that their ranking of the redundant filters is highly correlated. The key ingredient is the CWDA assumption that filters in a particular convolutional layer are iid and approximately follow a Gaussian distribution, which is shown based on extensive statistical hypothesis testing. Based on this assumption, they prove that these pruning criteria are roughly the same. ",
    "This paper analyzes the current limitations of existing magnitude-based pruning methods. First, the paper focuses on the similarities between three methods and then focuses on the redundancy in large networks. The paper also analyzes the weight distribution for a well-trained network and propose CDWA as a way to prove this distribution.  My main concern with this paper is the contribution to the field. ",
    "This paper proposes GraphCodeBERT as a Transformer-based pretrained model for programming language that incorporates data flow information in the graph representation of variables in the code. The data flow graph encodes the structure of variables based on \u201cwhere-the-value-comes-from\u201d from the AST parse. The pretrained model is jointly trained on the code, the natural language comment of the code, and the data flow graph of the code. In addition to the Masked Language Modeling objective, two new pretraining objectives are proposed including predicting the edge of the data flow graph and predicting the alignment of variables between data flow graph and code. The graph-guided masked attention is used such that the attention can only occur if two variables have an edge in the data flow graph or there is an alignment between data flow graph and code. The experiments show that GraphCodeBERT can deliver improvements on Natural Language Code Search, Code Clone Detection, Code Translation, and Code Refinement.",
    "The authors present Graph Code BERT, the first language model that leverages data flow to learn code representation. They use three objective functions: Masked Language Modeling, Edge Prediction, and Node Alignment. They claim their structure-aware pre-training can help improving performance on code-related downstream tasks, including code search, clone detection, code translation, and code refinement.",
    "This work address the pretraining over code and text. It proposes to leverage data flow as additional inputs, and add two structure aware pre-training tasks besides the masked token prediction task. The pretrained model is evaluated on four different tasks and outperforms the CodeBERT baselines as well as other pretrained models. Further analysis confirmed the benefits from the additional tasks and data flow input. ",
    "The paper presents a novel approach to improve the accuracy of regression models that are learned from a skew dataset. The proposed approach consists of two parts, namely, (i) adversarial network for forcing output distributions and (ii) regularization based on an adversarial autoencoder. Experiments suggest that the proposed approach increases the accuracy of the regression model for all the four datasets considered in the paper.",
    "This paper proposed to learn a regression model using \"skewed data\", which is defined as the subset of training samples with true target above certain threshold. The model consists of two components. First, the input x was mapped to its latent space through encoder R_enc. The latent representation was further mapped to the predicted output through regressor network R_post. The predictive distribution was forced to match the true target distribution p(y) through an adversarial network. Second, the latent space representations were also forced to match the true target distribution p(y). Experimental results on synthetic benchmark data showed the proposed approach performed better than naively applying regression model on the skewed data.",
    "This paper proposed a semi-supervised learning approach to improve the regression model trained on output-skewed data. The key assumption is that, though the training outputs can be skewed, it is easy to estimate the true distribution of the output. The proposed model that combines an AAE that generates the output distribution, and an adversarial model that enforces the distribution of the predicted output to resemble the true distribution of the output. On several real datasets, the ablation study shows the proposed model can improve the regression accuracy.",
    "This paper proposes an architecture that addresses transferability of compositionality. The proposed architecture consists of three components: a network that transforms the input X into a series of hidden representations {H_1, H_2, ... H_K}, a network that reconstructs the input X from this series of hidden representations, and a prediction network that generates a prediction from the hidden representations. The authors propose several datasets meant to address transferability of compositional generalisation, and show that their architecture significantly improves standard DNN architectures as well as humans on these datasets.",
    "The paper introduces a \u201ctransferability of compositionality\u201d problem and proposes an approach to alleviate it. The said problem may arise when one trains neural models to produce \u201ccompositional\u201d representations of the input. In the paper \u201ccompositional representations\u201d consist of multiple vectors which are supposed to correspond to semantically meaningful aspects of the input, for example different objects in the case of images or different parts of compound words in the case of linguistic inputs. The transferability problem arises when there is a difference between training and test distributions, namely when certain combinations of objects have different probabilities in training & testing. The proposed solution at inference time is to project object representations to the manifold of individual object representations. The manifold is estimated by saving representations of individual object representations from the training time. ",
    "This paper studies \"compositionality\" and in particular the way in which it \"transfers\" on test data. They run simple baselines on three experiments (overlapped MNIST, colored MNIST and concatenated month names) and find that the baselines do not learn compositional representation. They proposed the use of an *auxiliary reconstruction network and a regularized optimization* which improves on these baselines. ",
    "The paper studies poisoning attacks on RL agents, in which the attacker influences the agent's learning process by changing the feedback obtained from the environment. The focus is put on attacking policy-based deep RL agents, without necessarily having access to the underlying MDP model of the environment. The paper proposes a new poisoning algorithm, called Vulnerability-Aware Adversarial Critic Poison, and experimentally demonstrates its effectiveness on 5 different RL environments.   ",
    "The paper studies poisoning attacks against online reinforcement learning agents. The attacker has the power of manipulating the training data, i.e., state-action-reward trajectories, in order to achieve some attack goal. The attack can be completely black-box, meaning that the proposed method allows an attack setting where the attacker has no knowledge of the RL algorithm used by the victim agent or the environment. In this scenario, the authors proposed that the attacker can imitate the learning procedure of the victim, and then based on the imitated policy; the attacker designs how to poison the training data. The attack is formulated as a bi-level optimization, where the lower level involves the imitated learning procedure. Due to the intractability of sequential optimization, the original formulation is simplified so that only the attack only solves the attack on the current training data. This procedure is repeated in every episode to achieve sequential attacks. Experiments on a variety of tasks demonstrate the superiority of the proposed attack.",
    "This paper proposes a poisoning algorithm named Vulnerability-Aware Adversarial Critic Poison (VA2C-P) to attack policy-based deep reinforcement learning agents. The poisoning attack is formulated as a sequential bilevel optimisation problem (Problem Q), where the attacker either minimises the expected total rewards of the learner (non-targeted poisoning), or forces the learner to learn a target policy (targeted poisoning). To solve Problem Q, VA2C-P mainly makes two decision: (1) when to attack: a new metric named stability radius is proposed to decide the attack timing, (2) how to attack: a mechanism of adversarial critic is designed to solve a relaxed version of Problem Q by only considering the loss of the immediate next iteration.",
    "The paper presents an online algorithm for dynamic tensor rematerialization.  Theoretically, it shows the same asymptotic order on the memory budget and tensor operations as of the optimal static approach.  By simulation, it shows the performance matches optimal static checkpointing in a few models.  A PyTorch prototype is implemented, which shows benefits of reducing memory footprint and increased batch size comparing with basic PyTorch models without checkpointing.",
    "Contributions: a) analyzes multiple heuristics for which tensors to evict where compute overhead of rematerialization is minimal overall, b) suggested approach is just-in-time, and thus does not require any static analysis of the network. That is, unlike prior work in this area, it covers any network type with no prior knowledge, c) offers a good formal analysis of proposed heuristic in terms of its components: staleness, memory capacity and recursive replay cost - their formalization covers previously published heuristics as well.  Experimental framework is sound. And some encouraging results are shown delivering memory capacity saving of 30% to 90% with training slowdown of 2x or less.",
    "This paper proposed a simple yet effective greedy algorithm with a new heuristics on checkpointing deep learning models so that people could train large model with restricted GPU memory budgets. The proposed method operates in an online setting and do not need static analysis of computation graph, thus could be used for both static and dynamic models. In a restricted model setting of linear forward network and equal space and time cost for each node, the author proves the proposed method could reach the same bound on tensor operation and memory budget with previous static checkpointing methods. The author also establish a theorem on tensor operation numbers between the proposed dynamical method and an optimal static checkpointing algorithm. In experiment, the author compared the proposed method with static techniques including the optimal Checkmate tool of Jain et al. (2020), showing the proposed method gives competitive performance without static model analysis in prior. The author also compared the proposed heuristics with prior arts on several static and dynamic models. Finally, the author described a prototype of PyTorch implementation of the proposed method. ",
    "The paper addresses the problem of \"hallucinated\" content in conditional neural generation for two specific tasks: machine translation and summarization. It proposes a new task for faithfulness assessment, which classifies each token as either hallucinated or not. The classifier uses a pre-trained LM (either XLM-R or ROBERTa) and is fine-tuned on synthetic classification data created using both 'noisified' real data and a pretrained LM (BART). Experiments on either summarization and MT system outputs labeled for hallucinations show relatively encouraging classification results (e.g., F1 of 0.46 to 0.66 for MT, and 0.56 to 0.66 for summarization).",
    "This paper proposes hallucination detection at the token level, which predicts if each token in the generation output is hallucinated or faithful to the source input. In contrast, previous studies usually work on the sentence level. To create synthetic training data, a denoising pre-trained LM is first used to generate (potentially) unfaithful counterparts T\u2019 of the references T. Then, token-level labels are obtained by comparing T and T\u2019 via edit distance. Finally, a standard classification model is trained on the token-level labels by concatenating the source S, true and unfaithful targets T (T\u2019).",
    "This paper presents a method to detect hallucinated tokens in generations from neural machine translation and summarization. Given a source input S and its output G generated by a sequence generation model, this paper formalizes the task of detecting hallucinated tokens as a labeling problem on the output G. In order to train the labeler, the method synthetically generates supervision data by using a BART model. The BART model receives a text with noises ([MASK] tokens) and tries to predict [MASK] tokens. In this way, the method obtains a pseudo hallucinated text T' from a text T, and assigns hallucination labels by estimating edit operations between T and T'. The labeler is trained by fine-tuning pre-trained cross-lingual (for MT) and mono-lingual (for summarization) language models. In training, the labeler receives a source text S, true target text T, and pseudo hallucinated text T' separated by [SEP] tokens and tries to reproduce the hallucination labels on T'. Receiving a source text S and its output G, the labeler predicts hallucination labels on G during the inference time.",
    "This paper proposes an interesting method that adopts NAS to search multiple class-aware generator architectures for cGAN instead of class-agnostic type. A search space containing both normal and class-modulated convolutions are introduced to simplify the process of re-training. Besides, this paper design a mixed-architecture optimization to specifically address the computational burden issue under the setting of a multi-net search. The search results also give some insights about constructing cGAN models.",
    "This paper proposes a framework NAS-caGAN that adopts RL-based NAS to search the optimal class-aware generator architecture by directly optimizing the Inception Score (IS) using the  REINFORCE algorithm, and leverages the mixed-architecture optimization to mitigate the training data sparsity of each category. The authors design a Class-Modulated Convolution to allow for the weight-sharing among different searched architectures. The proposed NAS-caGAN outperforms the model that employs searched class-agnostic architecture on CIFAR 10 and achieves better results compared with cproj (Miyato & Koyama, 2018) on CIFAR 100. ",
    "This paper proposes an interesting idea that adopts NAS to find a distinct architecture for each class based on cGAN framework. Within the framework, the paper also proposes an operator, Class-Modulated convolution (CMconv), to allow the training data to be shared among different architectures, so as to balance the training data across classes. The proposed method leverages a Markov Decision Process (MDP) in the search algorithm, and learns the sampling policy for NAS. Comprehensive experiments demonstrate the class-aware NAS can outperform class-agnostic NAS.",
    "The present paper introduces a new approach, deep orthogonal networks for unconfounded treatments (DONUT), that allows to estimate (average) treatment effects exploiting an orthogonality property implied by the classical unconfoundedness assumption. The authors propose a regularization framework based on the orthogonality constraint and prove that a resulting estimator is doubly robust, asymptotically normal and with efficient variance. They supply multiple simulations to demonstrate their theoretical claims and to show state-of-the-art performance of their estimator.",
    "The authors propose a regularized framework for estimating the average treatment effect. They assume unconfoudedness and show that it implies a specific orthogonality constraint. The main idea is to use this orthogonality constraint during estimation of the model parameters as a regularizer. On the theoretical side, the authors provide sufficient conditions under which the regularization yields an asymptotically normal estimator for the average causal effect. Based on the regularization framework, an estimator for average causal effect via feedforward neural nets is developed.",
    "This paper proposes a novel regularization term for designing loss functions to estimate outcome and propensity score models, where the end goal is to estimate ATE.  The regularizer is derived from the assumption of conditional independence of potential outcomes and treatment given covariates (i.e. the no hidden confounding assumption).  The authors observe that this assumption implies that residuals of potential outcomes and treatments are orthogonal.  The authors derive a loss function which yields this orthogonality at the optimum.",
    "This paper studies the effect of training BN parameters on training deep neural networks. The conclusion is striking: learning only BN parameters is enough when increasing the depth of the network. Authors have done extensive experiments to understand the effect of increasing the depth and width of the network. To stress the important role of BN parameters, the same number of parameters are chosen randomly and trained. Yet, it is observed BN parameters can obtain far better accuracy. Furthermore, an interesting observation is conducted on the distribution of BN parameters: when training only these parameters, a sparsity pattern is observed on the optimal parameters. While learning all parameters does not reach such a sparse pattern for BN parameters. The sparsity pattern indicates that an efficient network only needs to have a particular ground-truth connection between different units and the choice of weights is not important. This shows that random features imposed by neurons can create a very interesting function class when they are connected in a proper way. ",
    "The authors explore the representational power of BatchNorm's affine parameters (scale $\\gamma$ and bias $\\beta$). For that, they freeze the randomly-initialized parameters of different versions of ResNet and VGG, and only train the affine transformations. They also compare the expressiveness of BatchNorm coefficients with respect to the same amount of neural net parameters.  The main conclusions of this work are that BatchNorm coefficients have a greater discriminative power than the rest of network parameters. Moreover, in random networks, $\\gamma$ seems to disable non-useful features, disabling more than 25% of the channels, and in non-random networks it may prevent overshooting. They also show how these coefficients interact with networks of different depth and width, concluding that deeper random networks achieve better performance than wider random networks with the same amount of BatchNorm parameters.",
    "This paper studies the expressive power of batchnorm parameters by training only these parameters while fixing other randomly initialized parameters. With experiments on different datasets and models, the authors show that batchnorm parameters are consistently more expressive than other parameters. The authors also try to explain such phenomenon by examining the values of parameters and activations, showing that training BN only can lead to sparse values. ",
    "This paper proposes a method to adapt a pre-trained model to a target domain, without the need to access samples from the source domain - on which the model was originally trained. The idea is to adapt layer normalization parameters at test time, by learning affine transformations. This is applied in tandem with the re-collection of the domain statistics.",
    "This paper tackles an interesting problem setting \u2014 fully test-time adaptation with only target data. The proposed method is to minimize the test-time entropy, and the loss is used to update the feature modulation layer only. The proposed method compares favorably with the state of the arts, on the ImageNet-C benchmark and unsupervised domain adaptation tasks.",
    "Presents Test-time Entropy (TENT) minimization, an algorithm for adapting deep models at test time to distributionally shifted data, without requiring access to source training data. At test time, the algorithm updates batch-norm parameters (that control channel-wise normalization and transformation) to minimize predictive entropy over target data. This simple approach is found to lead to state of the art performance on various corruption benchmarks for image classification, and competitive performance on simple DIGITS recognition-based domain adaptation shifts. ",
    "This paper presents an approach to uncertainty modeling in recurrent neural networks through a discrete hidden state. The training of this discrete model is done using a reparameterizable approximation (in particular, using the Gumbel-Softmax trick). The authors show the utility of this method on a variety of problems, including showing effective out of distribution detection and improved calibration in classification tasks.",
    "This work proposes a novel method to estimate uncertainties in recurrent neural networks. The proposed model explicitly computes a probability distribution over a set of discrete hidden states given the current hidden state in an RNN. Leveraging the Gumbel softmax trick, the proposed method performs MC gradient estimation. A temperature parameter is also learned to control the concentration of state transition distribution. To estimate uncertainty of a given input, the proposed model is run multiple times to draw samples for estimating the mean and variance. Experiments are conducted in a variety of sequential prediction problems, including a reinforcement learning task, demonstrating the effectiveness of the proposed uncertainty estimation method.",
    "This paper proposes a method to quantify the uncertainty for RNN. Different from  the traditional Bayesian RNN, the proposed method is more efficient. At each  time, based on the current hidden state and memory, it generates a probability  distribution over the state transition paths on the transition probability by  using the Gumbel softmax function. The next state is computed based on the weighted average of the sampled states and its uncertainty can be  qualified by the sample variance. The hyper-parameter tau of the Gumbel function  is learnt from data to better capture the inherent uncertainty in the data.",
    "The paper focuses on the topic of differentially private deep learning. Specifically, based on the deep residual learning, they first see it as an ODE. Then, to reduce the reversibility of the ODE, they modify the model as an SDE. By discretizing the SDE, they get a perturbed version of residual learning and use this to design DP-algorithms. The first strategy is directly followed the SDE while the second strategy is with an addition multiplicative noise of the additive noise. Finally, they show that their methods to defend membership inference attack both theoretically and practically. ",
    "The paper presents a method for training ResNets with differential privacy. Rather than the usual methods based on noisy gradient descent, the authors propose adding noise at each layer of the network during both training and testing. The authors prove differential privacy guarantees for two strategies of this type (one with additive and one with multiplicative noise). They also show some evidence that the noise can help generalization, by showing that the Rademacher complexity of a continuous linearized version of the model is lower when noise is added.",
    "This paper studies an important problem and proposes the novel residual perturbation to protect privacy while maintaining the ResNet models\u2019 utility.  Two SDE models are provided to inject noises with abundant theoretical proof are provided. Experimental results demonstrate the performance of privacy protection and classification accuracy on benchmark datasets. My major concern is about the utility enhancement and the DP guarantee (see cons below). Hope the authors can address my concern in the rebuttal period.",
    "The paper proposed the Length-Adaptive Transformer. The model can be trained once and directly applied to different inference scenarios. To achieve this goal, the author proposed the LengthDrop method, which randomly samples the length at each layer. In addition, the author used the sandwich rule to train the model. At each step, the sandwich rule will train the largest model, the smallest model, and another bunch of randomly sampled models. In the inference phase, the paper proposed to search for the best length configuration that balances the accuracy and latency tradeoff via evolutionary search. Moreover, to generalize the model to token annotation tasks, the author proposed the Drop-and-Restore process, in which the tokens that have been dropped are used again in the final layer. Experiments show that Length-Adaptive Transformer is able to outperfom the baseline models when evaluated at the same latency level.",
    "This work introduces a method, called LengthDrop, to train a Length-Adaptive Transformer that supports adaptive model architecture based on different latency constraints. In order to make the model robust to variable input lengths, the method stochastically reduces the length of a sequence at each layer during training. Once the model is trained, the method uses an evolutionary search to find subnetworks that maximize model accuracy under a latency budget. ",
    "The work targets an interesting direction of improving the efficiency of Transformers by reducing the sequence length. The main contributions of the work are (1) proposing LengthDrop as the way to achieve length reduction; (2) utilizing techniques developed in NAS, namely one-shot NAS, to enable proper training and allow adaptive drop ratio search after training. All these ideas are very reasonable and interesting. Empirically, the authors show that the proposed method is able to match or even outperform BERT-base model with 1/3 - 1/2 FLOPs during inference (not training).",
    "of the paper: The main objective of the paper is to improve the expressiveness of the GNN by exploring powerful aggregators. The requirements to build more powerful aggregators are analysed. It is closely related to finding strategy for preserving the rank of hidden features, and implies that basic aggregators correspond to a special case of low-rank transformations.",
    "The authors propose two new layers for GNNs. CombConv and ExpandingConv are motivated by the insight that a GNN is only as expressive as the rank of the matrix that represents the coefficients of the aggregation function. To arrive at this statement, the authors formalize all GNNs as being composed of three steps: 1) generation of aggregation coefficients, 2) actual aggregation of the neighbourhood, and 3) feature extraction from the aggregation. Furthermore, it is shown that current approaches have very low distinguishing strength and that CombConv and ExpandingConv, by their construction, yield higher expressive power. ",
    "\tThis paper explores the representation power of graph neural networks. Unlike recent work on choosing among simple aggregation functions or combinations thereof, the authors here recognize that these aggregators are the bottleneck in the representation power and generalize simple aggregator functions commonly used in literature to an aggregation coefficient matrix. The paper supports this construction theoretically and also proposes two aggregators that satisfy the rank-preservation requirement for more expressive (distinguishing) GNNs.",
    "The paper presents a disentanglement metric to measure the intrinsic properties of a generative model with respect to the factor of variation in the dataset. Toward this, the paper first assumes disentangled factors reside in different manifolds. These different manifolds are the sub-manifolds of some manifold M for a given disentangled generative model. The paper considers the fact that in an entangled model the sub-manifolds are not homeomorphic and thus similarity across submanifolds can be measured to evaluate a model\u2019s disentanglement. As such, disentanglement is related to the topological similarity.  For measuring topological similarity, the paper then introduces Wasserstein Relative Living Times. The proposed metric is used to evaluate standard disentanglement methods and datasets demonstrating the importance. ",
    "Introduces unsupervised disentangling metric that measures homeomorphic similarity between submanifolds conditioned on a given factor, and homeomorphic dissimilarity on submanifolds conditioned on different factors. The paper also includes a supervised variant which can directly assess topological similarity of submanifolds with label-spaces. The paper also introduces a novel variation of RLTs that  employs wasserstein distance instead of euclidean distance. ",
    "The paper proposes a novel metric for evaluating disentanglement by taking a manifold-topological perspective on the representations learnt. The key insight is that for a disentangled representation, when we fix a certain factor of variation at different values the topology of the conditional sub-manifolds should be similar. Using this insight the paper proposes a metric for disentangling which does not require annotations of the factors of variation and is more general than previous such tests.",
    "The paper's motivation is based on protecting private data and preventing its being scraped and used to train models. Even though motivation is clear and very important, the problem is the same as the works in crafting adversarial samples (i.e., the ones under data poisoning and adversarial attacks parts of the related work). The key difference is to apply Projected Gradient Descent (Mandry et al. 2018) in the reverse direction iteratively to *minimize* the loss function.  Furthermore, the performance evaluation will be the margin between models trained on completely clean data and sample-wise/class-wise adversarially corrupted data (in contrast to fooling a pretrained network in adversarial attack benchmarks). ",
    "The authors proposed the idea of using invisible noise to make personal data unusable to authorized deep learning models. To achieve this goal, the authors proposed the idea of error-minimizing noise crafted by a min-min optimization method. The error-minimizing noise is then added to training examples to make them unlearnable to deep learning models. The idea is very well motivated and explained. The experiments not only confirm the exceptional effectiveness of the proposed method but also show its flexibility.",
    "The authors studied the problem of data protection from a new perspective. They proposed one kind of error-minimizing noise to make the data (added noise) unlearnable. The noise is imperceptible to human eyes, and thus does not affect normal data utility. The idea is very interesting and inspiring. The authors conducted a series of solid experiments to validate the effectiveness of the proposed noise, and tested it on a real world task of face recognition. ",
    "The paper extends MuZero for nondeterministic domains (NDMZ). Compared to MuZero NDMZ also learns a function that determines who is to act (player 1,2 or chance) and a distribution of chance outcomes. This makes it possible to employ MCTS search adjusted to handle nondeterministic nodes on top of a tree constructed by NDMZ's neural nets.",
    "This paper proposes NDMZ, which extends the previous MuZero algorithm to stochastic two-layer zero-sum games of perfect information. NDMZ formalize chance as a player (chance player) and introduces two additional quantities: the player identity policy and the chance player policy. NDMZ also introduce new node classes to MCTS, which allows it to accommodate chance.",
    "This paper introduces NDMZ, short for nondeterministic MuZero, a deep reinforcement learning algorithm for model-based RL that doesn't use the rules of the game to perform search. The paper's contribution is mostly focused on describing how to construct the algorithm, and experimental results are provided at the end. A good analogy is that of a player that must play a (physical) board game by not only making decisions, but also acting out the game: producing random events, such as die rolls, and moving pieces on the board. ",
    "This paper introduces a novel option-learning policy gradient method, HO2. The method learns a parameterized joint distribution over options and actions and uses a soft-continuation based approach to interrupt or \"switch\" between options before option termination. The method introduces a new meta-parameter which enforces a hard limit on the number of \"switches\" that can occur, significantly reducing the variance of the option-learning method and replacing softer loss penalization based approaches. The paper demonstrates the performance of the proposed algorithm on a handful of 3D virtualized environments as well as on robotic simulation tasks.",
    "The paper considers the Hierarchical Reinforcement Learning setting, Options in particular, and proposes an algorithm that allows to learn both the high-level and low-level (option) policies at once, from off-policy samples. An original aspect of the algorithm is that it is easy to constrain the learned policies on how often they terminate an option and start a new one. This prevents the agent from learning tiny options that immediately terminate. It is unclear whether it can also be used to prevent the agent from learning a single big option that does everything.",
    "This paper studies an important area in RL, hierarchical RL, which improves data efficiency by incorporating abstractions. In this paper, the authors proposes an efficient option learning algorithm, which utilizes a TD(0) type objective and constrains the learned policy being not too far away from the past policy. In terms of different abstractions, the paper studies action abstraction through a mixture policy, and temporal abstraction through explicitly limiting the maximum number of switches between options. ",
    "This paper proposes a modified bellman equation for reinforcement learning that optimizes the maximum expected single step reward along a trajectory, instead of the maximum cumulative reward. This formulation is applied to the generation of molecules with optimized properties of interest. A recently published molecule generation algorithm, that constructs molecules step wise via the (predicted) chemical reactions of building blocks, is modified with this new bellman formulation, and shows modest improvements in optimizing for some HIV activity targets.",
    "Motivated by the de novo drug design, this submission proposed a new objective in reinforcement learning, i.e., to maximize the expected maximum rather than the accumulated reward along trajectories. The authors defined the corresponding Bellman operator, and then proved its theoretical properties, including monotonicity and contraction. In the experiments, the authors first showed on a simulated grid that when compared with Q-learning, the proposed Max-Q algorithm can achieve higher maximum rewards along trajectories. Finally, the authors tested on de novo drug design task, by modifying the TD target in the previous PGFS algorithm. The new variant achieved better performance across different metrics.",
    "This paper proposes a max reward instead of cumulative reward objective for reinforcement learning. This objective is primarily motivated by applications like chemical synthesis where the goal is for the RL agent to generate the most desirable state possible. The paper then defines the corresponding varaint of the Bellman operator (the max-Bellman operator) and proves tabular convergence guarantees by a contraction argument. Some experiments in a gridworld and simulated chemical synthesis indicate that this objective modification can improve prior algorithms. ",
    "The paper proposes a few-shot meta-learning method for recommender system that uses a new feature's meta-information and observed samples for the features to predict the network weights for predicting the feature value from other features. The paper focuses on the cold-start problem where few samples with a new feature observed is available. The method outperforms a wide range of baselines on MovieLens-1M, a medical synthetic dataset, and a e-learning dataset.",
    "The paper proposes Contextual HyperNetworks (CHNs) as an auxiliary model to generate parameters from existing data, and observations and other metadata associated with new feature to address cold start problem of new feature. Besides, it doesn\u2019t need either re-train or fine-tune at prediction time. The CHN is applied to P-VAE and some experimental results are provided to demonstrate its effectiveness in some application, i.e., recommender system, e-learning and healthcare tasks.",
    "This submission focuses on the cold start problem of new entities (new items in a recommender system, new treatments in a medical application, etc.). It combines the strengths of the *relations* between a new entity and the existing entities, and the *content* features of the new entity, by fusing the two kinds of information into a neural network that outputs the estimated representation of the new entity. The proposed method outperforms several intuitive na\u00efve strategies as well as MAML.",
    "The authors present a new method for Bayesian deep learning motivated by the difficulty of posterior inference in the \"overparameterized\" regime of deep neural network models. The proposed method provides a principled strategy for selecting a subset of the neural network's parameters (forming a so-called \"subnetwork\") for which a full-covariance approximate posterior can be computed. The authors use the well-studied Laplace approximation with the generalized Gauss-Newton Hessian approximation for the covariance. An empirical analysis is presented which attempts to assess the efficacy of the proposed method in prediction accuracy and uncertainty quantification.",
    "The paper proposes to approximate the posterior distribution of a Bayesian neural network by an approximation that consists of a deterministic component. The authors select a sub network and infer approximate posterior distributions over the weights in the sub network. All other weights are estimated via MAP point estimation.  A sufficiently small sub-network allows high fidelity posterior approximations that do not make restrictive mean field assumptions to be tractable.",
    "The authors focus on the important problem of scalable approximate inference in Bayesian NNs. More specifically, they propose a method for scalable BNNs via a (full-covariance Gaussian) Laplace approximation on a (Wasserstein-based) pruned subnetwork within a deterministically-trained model. They include a theoretical analysis for a simple generalized linear model, and experiments on 1D regression, tabular regression, and larger-scale image classification with CIFAR-10 (using the dataset shift setup from Ovadia et al., (2019)). From the experiments, they show that their method generally outperforms comparable methods (including deep ensembles) on metric performance and on the ability to capture in-between uncertainty.",
    "The paper proposes a framework of jointly learning a state and action embedding using the model of the environment, eventually using those embeddings to learn a parameterized control policy using standard policy gradient (PG) methods. Joint learning of state and action embeddings allows us to capture the interactions between actions in different states. The framework proposes to learn an internal (embedding) policy, a state embedding, an inverse function on action embeddings, combining all the parts to form an overall policy. The paper theoretically shows that optimizing the internal policy leads to an optimal overall policy. ",
    "The paper proposes a method to jointly learn: (a) a latent state embedding; (b) a latent action embedding; (c) a state transition model; and (d) an RL policy.  The latent models should allow for better generalization over states and actions, and therefore result in improved learning, particularly for discrete action domains. The method shows improved performance over vanilla policy gradient on a grid-world task, a slot machine task, a recommender system, and half-cheetah locomotion.",
    "Learning on environments with large state-action spaces can be difficult. This paper addresses this issue by learning a joint state-action embedding and learn an internal policy(\\pi_i) on this embedded state-action space instead of the original state-action space. There are three parts of learning, 1. learning the embedding model that learns mapping from state to state embedding, 2. learning the internal policy, and 3. learning the mapping from action embedding to action space. The authors justify this approach by showing that the overall policy (\\pi_o) can be expressed in terms of the internal policy (\\pi_i). Furthermore, there is equivalence between the internal state-action-value function and overall state-action-value function and the authors show that updating \\pi_i is equivalent to updating \\pi_o. ",
    "Learning representations using self-supervision requires domain expertise to identify diverse transformations of the data samples that label preserving. This can be expensive and hard to obtain in many data modalities. The paper proposes to automate this by learning to generate transformations tailed to each modality and sample. Specifically, an adversarial strategy is applied to learning transformations that are close to the original view in the input space but hard to classify for the self-supervision encoder.",
    "The paper presents a generative model to automatically generate data that is needed for contrastive learning, with a focus on the SimCLR framework, while the method itself is general. Experiments were conducted across multiple modalities, including image, speech and wearable sensor data. The results demonstrate the effectiveness of the proposed model as compared to data augmentation methods relying on human domain knowledge. ",
    "The paper proposes a method for automatic generation of data views for contrastive self-supervised learning of representations. The method consists of learning an adversarial perturbation model that aims to maximize the distance between the original image and its perturbed views in the space of learned representations. To avoid collapse to a completely information-destroying perturbation model, authors propose to limit the perturbation strength in terms of the $l_p$ norm of the added noise. Authors apply their method on various image, speech and wearable sensor datasets where the proposed approach provides an improvement over other methods.",
    "This paper introduces a taxonomy of OODs and proposed an integrated approach to detect different types of OODs. Their taxonomy classifies OOD on the nature of their uncertainty and they show that no single state-of-the-art approach detects all these OOD types. Motivated by this observation, they combine multiple existing OOD detection methods to detect various types of OODs. ",
    "This paper introduces a novel taxonomy for OOD outliers. The authors analyze current OOD detection approaches and uncover their limitations. They propose to fuse several existing approaches into a combined one and extensively evaluate it on various data sets (CIFAR,10, SVNH, MNIST, STL10, ImageNet, etc.). The proposed integrated OOD detection approach clearly shows superior performance.",
    "The authors explore the different kinds of outliers and show that the methods previously proposed detect different kinds of OOD and not a single one can detect them all. The authors propose an interesting study of the different kind of outlier on synthetic data which  illustrates well the different characteristics of the outlier types. The authors then propose to combine different methods to increase the OOD detection rate. Experiments are conducted on 3 images classification datasets using different deep neural networks. For each dataset, samples from other databases are introduced as outliers and must be detected. The combination method yield better detection rates than baseline methods in almost all configurations. ",
    "The paper claims that high quality of generated samples and SOTA bpds are achievable by VAEs if the model is deep enough (deep in terms of the number of stochastic layers). The authors explain the architecture that resemblances the U-net architecture, and explain its building blocks. Interestingly, they are able to learn VAEs with up to 78 stochastic layers, and achieve SOTA bpds on CIFAR-10, ImageNet-32, ImageNet-64, FFHQ-256 (5-bit), and setting a great result on FFHQ-1024 (8bit).",
    "the paper puts forward an idea that deep-enough VAE should perform at least as well as autoregressive models. Authors explore this in the context of image generation, and construct VAE model that is a generalisation of typical autoregressive architectures. They use several tricks to ensure stable training of very deep VAEs and show that final performance exceeds all autoregressive models. This experimentally supports their claim that very deep VAEs encompass autoregressive models.",
    "This paper shows that deep hierarchical VAEs can outperform state-of-the-art autoregressive models on images. The authors first argue that autoregressive models are special cases of hierarchical VAEs and that hierarchical VAEs are universal approximators. They introduce a simple top-down (LVAE) architecture that scales past 70 layers. Furthermore, the model can be trained without using freebits or KL annealing -- although additional tricks are required (gradient skipping and prior warmup). They demonstrate that likelihood performance is correlated with depth and report state-of-the-art performances on multiple image datasets.",
    "This paper adopts semi-hard negative mining, a sampling strategy widely used for metric learning, for contrastive self-supervised learning. Specifically, the paper chooses the negative samples in the range of $[w_l, w_u]$ percentiles (close, but not too close) in terms of the normalized feature distance. As the initial representation is not informative, the paper anneals down the percentile range. This sampling strategy improves the contrastive learning methods (IR, CMC, MoCO).",
    "This is an interesting paper that discusses the negative sample mining in visual representation learning. The authors discuss the theory and method to conditionally select the negative samples based on the dot product of representations in noise constructive estimation (NCE). Their theory shows that the NCE with negative examples sampling from a conditional distribution q is lower bounded with mutual information, and the object has higher bias and lower variance. The authors also provide the method to construct the conditional distribution by picking a ring surface where the dot product of representations is bounded within percentiles of data.",
    "Inspired by the effectiveness of hard negative mining in deep metric learning, this papers focuses on the problem of negative mining in unsupervised learning under the contrastive setting. One of the problems in this scenario is that naively selecting difficult negatives may yield an objective that no longer bounds mutual information, which is the basis for many contrastive objectives such as the Noise Contrastive Estimator. To address this problem, this paper formally defines a family of conditional distributions where negatives can be drawn from (negatives are chosen conditional on the current instance), while maintaining a lower bound on the NCE and on mutual information, resulting in a new estimator dubbed Conditional NCE. It also shows that, even though it\u2019s a looser bound than NCE, it also has lower variance, which may lead to better local optima. Finally, within this family of conditional distributions, the paper proposes the Ring model, which takes inspiration from semi-hard negative mining approaches, and that can be applied to state-of-the-art contrastive algorithms in order to sample harder negatives, resulting in better representations.",
    "This work introduces CAFE, a novel training algorithm to leak training data in a federated learning setup. Extending from \"deep leakage from gradient\" fake images are optimised with respect to the difference observed from the client gradients (i.e. with the real images) and the one observed with the current version of the fake image. However, DLG does not work when the mini-batch size increases due to a messy gradient representation. In this work, the authors propose to keep track of the batch index. Indeed, it may happen that the server decides of the batch index corresponding to the training data that will be used by the client during the local training. Within such conditions, a malicious server can easily store fake images corresponding to specific indices and therefore optimise correctly each fake images w.r.t the corresponding real image. ",
    "This paper studies the data leakage issue in the federated learning. More precisely, when the servers have access to model parameters and gradients. It can recover the input data via gradient matching, and the authors claim that their method performs well even with large training batch sizes, e.g. over 40. Finally, the author also studies the possibility of attacking during learning, where they suggest that multiple updates of fake data helps. However, their contribution seems incremental, gradient matching is used in previous literature [zhu et al 2019], and their main modification is extra two regularization terms: total variation and internal representation regularization, and a data index alignment technique (whose exact meaning is unclear in the paper).",
    "The submission considers the problem of reconstructing private data from gradients in a Federated Learning system, which has been recently shown to a threat in distributed learning systems. Two types of federated learning systems are considered. Vertical federated learning (VFL) refers to the case where different agents hold different features of the same data points while  Horizontal federated learning (HFL) refers to the case where different agents how all the features of different subsets of the data.",
    "This paper presents a method for dynamic relational inference for multi-agent trajectory prediction. The method extends the neural relational inference (NRI) (Kipf et al., 2018) by changing the static relations between agents to dynamic relations. This equates to inferring time-varying latent variables $z_t^{ij}$ as opposed to learning time-independent latent variables $z^{ij}$. The paper conducts experiments on physics simulations and basketball trajectories to show the superiority of the proposed method against different variants of NRI.",
    "The authors propose a novel Relational Inference system that learns to predict the graph structure underlying the data as well as the updated state of the system. Relational reasoning has received considerable attention in recent year. Predicting the graph structure underlying a system from data in a dynamic way is an great next step, which could help alleviate some of the scalability issue currently afflicting these methods.",
    "This paper builds on Kipf et al. (2018)\u2019s Neural Relational Inference. In particular, this work introduces a latent variable model which treats the interactions (i.e. relations) between different agents as dynamic and time-varying. As in NRI, the interaction variable between any two agents is conditioned on the history of those agents\u2019 states. An agent\u2019s future state is conditioned on its history of states as well as its interaction variables with other agents.",
    "This work explores a popular problem, i.e., collaborative filtering, in an inductive setting, which is very important for real-world recommender systems. To address the challenges in the inductive settings, i.e., learning accurate representations for users who do not occur in the training data, the authors propose to construct a relational graph between users in the training data and new users based on a standard matrix factorization model and then use an attentive message passing framework to inductively compute user-specific representations. Besides, the authors prove the expressive and generalization capabilities of the proposed framework. Extensive experiments are conducted to demonstrate the effectiveness of the proposed framework both in transductive and inductive settings, as well as the scalability.",
    "This paper proposed an inductive collaborative filtering method, called IRCF. The goal is to possess expressiveness (against feature-driven methods) as well as generalization (against one-hot encoding based methods). In IRCF, there are a matrix factorization model for support users and a relation model for query users. The former is trained with transductive learning to obtain support users embeddings and item embeddings. The relation model then generates query user embeddings as weighted sum of support user embeddings by examining relational graph between support and query users.",
    "This work proposed an inductive recommendation framework on user-item relation graphs. Such a framework relies on the user-item relations without the requirement of side-information and perceives certain flexibility in terms of the parametrization for user/item representations. The authors also provided theoretical analysis to highlight some mathematical insights out of this framework. The proposed method is evaluated on three real-world datasets and compared with several baselines.",
    "Disentangled representation (DR) of data is useful in downstream tasks. However, VAE-based DR fundamentally suffers from a trade-off between high-quality reconstruction images and disentangling. To overcome this point, the paper approaches VAE from the multi-stage modeling (so-called MS-VAE). The proposed method starts from the other standard DR method which learns low-quality image(Y) and then, improves the quality of the image via training additional encoded representation(Z). The widely-used techniques in style transfer (FILM and AdaIN) are used to adopt 'Z' into 'Y' for a high-quality reconstructed image. The authors evaluated the proposed method through FID(high-quality image) and MIG(disentanglement). At the similar scale of complexity, the proposed method obtained high FID score and low MIG score than the baselines.",
    "This article introduces a method for learning high-quality generative model with disentangled latent representation by splitting the learning process into two steps. The first step consists in learning a generative model on the data using a method with strong disentanglement constraints, producing a low-quality generation. As a second step, a conditional generative model is trained to turn this low-quality sample into an high quality one. This intermediate generation acts as an observed variable, and thus separates the latent spaces of the two models, effectively preventing disruptive interference in the learning of the \"independent factors\" on the one hand and the \"dependent factors\" on the other, as has been previously observed as a difficulty in the literature. The authors provide detailed empirical analysis of the performance of the model.",
    "The paper studies the problem of learning disentangled representations while maintaining good data reconstruction. As common modeling, the latent representation is decomposed into disentangled representation C and correlated representation Z. Then a hierachical generative process is proposed, where the first stage is to reconstruct a preliminary version of the data given the disentangled representation C, and the second step is to reconstruct a full version of the data given C and correlated representation Z. The two stages are learned separately, with the first stage using the previous \u03b2-TCVAE model to learn C, and the second stage using the Feature-wise Linear Modulation (FiLM) technique.",
    "The paper discusses three mutual information (MI) objectives for representation learning in RL, referred to as forward, state, and inverse. The forward MI objective models latent dependencies given the action. The state MI objective models latent dependencies alone. And the inverse MI objective models dependencies between actions and future states (empowerment). The paper shows that of these three common objectives, only the forward objective is sufficient for learning the optimal policy / value function. This is demonstrated using simple examples and experiments on a simple game environment.",
    "of the work: This work studies which mutual-information representation learning objectives (1. forward information, 2. state-only transition information, 3. inverse information) are sufficient for control in terms of representing the optimal policy, in the context of reinforcement learning (RL). As a result, they find a representation that maximizes 1 is sufficient for optimal control under any reward function, but 2 and 3 fails to provide that guarantee in some MDP cases. They provide both proof and interesting counter examples to justify the findings. Besides, they conduct some empirical studies on a video game (i.e. Catcher) and show that the sufficiency of a representation can have a substantial impact on the performance of an RL agent that uses that representation. ",
    "This paper studies which commonly-used mutual information objectives for learning state representations are sufficient for reinforcement learning. In particular, they provide counterexamples to show that state-only and inverse MI objectives are not Q*-sufficient, while proving that forward MI is Q*-sufficient. They validate their findings empirically with experiments in a simple RL domain.",
    "This paper showed that a two-layer vector-output ReLU neural network training problem is equivalent to a finite-dimensional convex copositive program. Based on this connection, the authors gave the first algorithm that finds the global min of the network training problem, which has running time polynomial in the number of samples but exponential in the data matrix. For CNN, the running time is only exponential in the filter size, which is usually a constant. The authors also described circumstances in which the global min can be efficiently found by soft-thresholded SVD; provided a copositive relaxation that is exact for certain cases. The effectiveness of the proposed algorithms is verified in experiments.",
    "The draft is a vector extension of [1] on studying how to approximately solve the global optima of a two-layered Relu network. The key of the analysis is to enumerate all possible sign patterns of the ReLU unit generating from specific data. Once we have the enumeration, we can also enumerate the linear area separated by ReLU, and the whole optimization problem will become a non-convex quadratic optimization problem. The non-convex quadratic can be approximately solved with its convex dual (or exactly under some conditions), or we can relax it to a copositive program (which might still be NP-hard to solve). With some assumption on the data, the sign pattern of the ReLU is a singleton, then we will have efficient algorithms to exactly recover the global optima of the two-layered network.",
    "The paper proposes a convex formulation for shallow neural networks with one hidden layer and vectorial outputs. This is an extension on a line of previous works (Ergen & Pilanci, 2020a) and (Ergen & Pilanci, 2020b) where similar results have been established for the case of scalar outputs. A Frank-Wolfe algorithm for finding the global optimum of the resulting convex program is proposed and evaluated on smaller datasets. ",
    "This paper proposes to combine the neuro-symbolic concept learner for visual reasoning from language (NS-CL; Mao et al., 2019) with recent unsupervised approaches to learning object-centric representations such as MONet (Burgess et al., 2019) and Slot-Attention (Locatello et al., 2020). While NS-CL normally relies on pre-trained object-detectors (in a supervised fashion) to extract visual representations, the proposed combination (dubbed LORL) use MONet or Slot Attention for this. By additionally back-propagating error signals from language-driven visual reasoning tasks obtained via NS-CL into MONet/Slot-Attention, it is shown how LORL is better able at learning object-centric representations and perform instance segmentation. ",
    "The paper proposes a framework for object-centric representation learning with additional language supervision such as e.g. questions and answers, denoted as Language-mediated, Object-centric Representation Learning (LORL). The authors combine two ideas from prior work, the unsupervised object-centric representation learning and the neural-symbolic concept learning, in one architecture. The model obtains object representations by learning to reconstruct the input image (as in MONet and Slot Attention). The learned representations are used as input to the neural-symbolic program executor, which learns to answer questions about objects. The entire model is trained in three stages: first the reconstruction objective, then the QA objective, and, finally, jointly. Experiments on two datasets demonstrate that the obtained object segmentations have better quality that those of the original unsupervised models. The learned representations are also shown to be effective in several other down-stream tasks.",
    "This paper proposed an interesting idea that uses language to learn the concept and aid downstream tasks such as segmentation and referential expression interpretation. The authors combine the unsupervised segmentation method (MONet and Slot Attention) with neural symbolic concept learning (NS-CL). By joint training these two objectives, the authors show improvements in the object segmentation and several downstream tasks. ",
    "The work utilizes relational background knowledge contained in logical rules to conduct multi-relational reasoning for knowledge graph (KG) completion. This is different from the superficial vector triangle linkage used in embedding models. It solves the KG completion task through rule-based reasoning rather than using rules to obtain better embeddings. Experiments on FB15K, WN18, and a new dataset FB15K-R demonstrate the effectiveness of the proposed model EM-RBR. ",
    "The paper seek to improve KG representation (e.g. for link prediction and question answering) by combining logical reasoning (logical rule templates) with statistical methods (TransE). Rules are mined from the KG using AMIE and recursive backward steps are taken, using the mined rules, to determine if a fact is true.",
    "The paper proposes a framework (EM-RBR) for doing Knowledge Base (KB) completion. Instead of the direct triple score from an embedding based method, EM-RBR allows the triple score to be calculated as a composition of the scores of the rules mined from the KB. EM-RBR uses a BFS type algorithm that recursively searches for reasoning paths connecting the triple while also updating the score.  The authors show that EM-RBR when used as an addendum to a translation-based embedding method (such as TrasnE, TransH) is able to outperform them. They show their results on FB15k and WN18. ",
    "This paper proposes a new type of recurrent neural network architecture called schema / object-file factorization (SCOFF). This model contains multiple weight-sharing GRU cells. The input information is fed into each GRU cells through an attention layer. The output information is fetched from these GRU cells and mixed with another attention layer. The model is tested on several intuitive physics benchmarks and basic reinforcement learning environment. This model demonstrates superior performance than other modular RNN architectures such as RIM on specific tasks.",
    "The authors propose SCOFF, a novel architectural motif, one with memory, which, as they describe, can serve as a drop-in for an LSTM or GRU within any architecture. It is inspired by the notion that when modeling a structured, dynamic environment (such as one with objects moving around), one must keep track of both declarative knowledge and procedural knowledge. They propose that these two types of knowledge be factored, creating an architecture consisting of \"object files\" (OF) whose evolution is governed by input, all objects, and  \"schemata\" which can be selectively applied to each OF.",
    "The motivation and the proposal for splitting the schema from the procedural (representational) block makes sense. This is a good idea. A the authors build on top of RIMs, which have shown reasonable ways to model dynamical systems. However the paper itself needs to be improved and we need to evaluate the model more before publication. ",
    "This paper introduces the Visio-Linguistic Neural Module Network (VilNMN) consisting of a pipeline of dialogue and video understanding neural modules. Motivated by Hu et al. (2017), Kottur et al (2017), this paper extends the NMNs on video tasks for interpretable neural models. The model explicitly resolves entity references (dialog understanding) and detects actions from videos (video understanding) for response generation. Experiments show that NMNs achieve competitive results on AVSD (video-dialog) and TGIF-QA (video-QA) benchmarks. ",
    "This paper studies the language grounding aspect of video-language problems. It proposes a Neural Module Network (NMN) for explicit reasoning of visually-grounded object/action entities and their relationships. The proposed method is demonstrated to be somewhat effective in the audio-visual dialogue task and has been shown superior to existing works on video QA. Overall, the paper is motivated clearly and is delivered with good clarity. The followings need to be clarified.",
    "The paper studies the application of neural module network to video-grounded language tasks. They propose a method dubbed Visio-Linguistic Neural Module Network (VilNMN) to retrieve spatio-temporal information in a video through a linguistic-based parsed program. In particular, VilNMN first extracts entity references and their corresponding actions in linguistic cues. This information is then being used to locate relevant information in the visual cue to arrive at the correct answer. The proposed method is evaluated on two large scales benchmarks AVSD and TGIF-QA, demonstrating competitive performance with state-of-the-art methods.",
    "The paper suggests two techniques to improve the calculation of empirically figuring out a Nash equilibrium using an iterative application of best-response dynamics. One method learns the best-response to the previously used strategy. The other uses that technique to model the opponent, and then best-responds to the modeled opponent. The experiments show a faster reaching to NE than without these changes.",
    "The paper proposes two new methods in the Policy-Space Response Oracle framework. These approaches permit to reuse past knowledge in order to reduce the amount of data required for the RL training. The first algorithm Mixed-Oracles transfers the previous iteration of Deep RL, instead of the second one, Mixed-Opponents, transfers existing strategy action-value estimates.",
    "The paper focuses on resolving the computational and sample efficiency challenges with current PSRO style approaches. To this end it proposes two different modifications to the standard PSRO setup: 1) Mixed Oracles, and 2) Mixed Opponents. These approaches allow avoiding resetting learning after each outer loop epoch and reduce the stochasticity of dynamics during training. Thee efficacy is demonstrated on relatively simple games but using Deep RL policies where the proposed approaches are at least on par with standard PSRO approach in terms of final performance while drastically improving the sample efficiency.",
    "In this paper the authors tackle the problem of alignment between input tokens and output acoustic features. The key contribution of this paper is replacing the attention mechanism of the Tacotron 2 with an explicit representation of token durations. The attention mechanism is vulnerable to issues such as pauses, repetitions, and skips, and hence using durations directly takes care of such issues. The challenge lies in obtaining the durations. The authors propose different methods toward that end. ",
    "In this paper, the authors introduce a text-to-speech model based on Tacotron 2, called Non-Attentive Tacotron. Instead of an attention mechanism, a duration predictor is utilized to improve robustness, which is evaluated by two metrics, unaligned duration ratio (UDR) and word deletion rate(WDR). The authors propose semi-supervised and unsupervised duration modeling with a fine-grained variational auto-encoder (FVAE).",
    "This paper presents an approach based on the Tacotron model for speech synthesis, where the attention mechanism is replaced by a duration predictor. It also presents a short study on semi-supervised and unsupervised training. The paper also introduces two metrics to evaluate the robustness of the model. The experiments shows that the proposed model is on par with the Tacotron baselines in terms on MOS score and better in terms of the new metrics.",
    "This paper presents SBEVNet, a neural network architecture to estimate the bird's-eye view (BEV) layout of an urban driving scene. Given an image captured by a stereo camera, SBEVNet performs an inverse perspective mapping (IPM) to obtain an initial feature volume, which is further processed to generate the BEV layout. The system is trained end-to-end in a supervised learning setup.",
    "The paper proposes an end-to-end network for layout estimation from stereo images. The approach is built off previous stereo matching networks, which built and process a 3D disparity volume. The stereo estimate is used to project image features into a birds-eye-view representation which is processed using a U-net which predicts a semantic scene layout. The approach is evaluated on the KITTI and Carla generated datasets.",
    "The paper proposed to estimate the semantic layout in the bird eye's view from a pair of stereo images. The main novelty/contribution lies in how to organize and exploit the information from the stereo images. The proposed framework builds upon inverse perspective mapping, and projected stereo feature volume. The performance was evaluated on the KITTI and CARLA datasets. Given a pair of stereo images, there are various options to exploit the image information, where this paper provides a framework by exploiting the stereo information in the bird eye's view. ",
    "    The authors propose a new gating based recurrent graph attention networks for multi-relational graphs to capture long-range neighbor dependencies. The authors provide an interesting analysis of current gated GNN models (in the appendix + Figure 3) in light of their ability to capture long-range dependencies in graphs. Experimental results are reported for node classification with two synthetic datasets and two real-world datasets.  ",
    "This paper proposes a new GNN model (GR-GAT) for multi-relational graphs. The proposed method has better ability of capturing the long-range information. Essentially, the proposed GR-GAT is modified from GAT so that it can apply to the multi-relational graphs. Since the modifications are common and frequently used techniques, the novelty of this work is not enough. Also, why these modifications can help to capture long-range information is not well explained in this paper. Overall, this work is ok but not good enough for ICLR.",
    "This paper presents a graph attention architecture that captures long-range interactions. The novelties in the architectures are (1) vector-based parameterization of edge type in modeling message, (2) slight modification of graph attention (Section 3.2), and (3) GRU-based node update function. The experiments are primarily on synthetic tasks. However, it is unclear if modeling such long-range interaction is useful in real tasks. The paper fails to demonstrate convincing results on the real tasks of entity classification in knowledge graphs.",
    "This paper provides an interesting pos-hoc explanation method to identify relevant features in an input that may inform a trained neural model's prediction. The task is to identify a binary mask over input image/text such that the masked input yields almost similar prediction as original input. The author formulates this as an SMT solver task, but instead of making sure that the output prediction is similar (which involve multiple time consuming pass over potentially huge networks), they make sure that high influential neurons in first layer of the network are still activated. This provides a less time consuming way to evaluate invariance of masked input.",
    "This paper addresses the question of identifying which input features are most important for a neural network's decision. To do so, it frames the problem as an SMT problem that seeks to select the best input features, without changing the state of the first layer too much. The paper shows experiments, primarily on image classification, and also examples of how the approach may be applied to text classification.",
    "This paper presents a method to encode the minimal input feature discovery problem -- finding the minimal set of features in a input that is necessary for a prediction -- into a form that can is amenable to satisfiability modulo theory (SMT) solvers.  In particular they first use the integrated gradients methods to score first-layer neurons on the degree to which they influence the prediction.  Then, they produce and solve an SMT problem that finds the minimal mask that changes these influential neurons.  They demonstrate their approach on several problems.",
    "This paper tackles the task of pose prediction and takes a render-and-compare approach. However, instead of rendering pixel colors, the key insight is to render features -- each mesh vertex is associated with 3D (learned) features which are encouraged to match computed 2D image features. This 'neural mesh' representation allows pose inference via SGD as one can optimize for pose s.t. the rendered features best match the image features, and is also robust to foreground occlusion. The paper demonstrates results on ObjectNet3d and PASCAL3D+ where the proposed approach is shown to be more robust to occlusion and also better at precise pose estimation.",
    "The paper presents a novel approach for 3d pose estimation by combining render-and-compare (analysis-by-synthesis) and contrastive feature learning. The key idea is to render and compare learned latent features instead of synthesized RGB colors to optimize 6D pose parameters. The proposed method learns latent feature vectors on a template mesh as well as target images via backbone neural networks such that matched regions have similar features while latent features are as distinctive as possible. The paper evaluates the novel formulation on  PASCAL3D+, the occluded PASCAL3D+, and ObjectNet3D dataset, demonstrating the render-and compare optimization with the proposed approach is more robust to appearance change and partial occlusions.",
    "The authors propose a novel 3D neural mesh model of objects that is generative. They demonstrate that standard deep learning approaches to 3D pose estimation are highly sensitive to partial occlusion. Since their method works in a render and compare manner, it enables the method to be more robust to artifacts in general and partial occlusion in particular. They also achieve a highly competitive 3D pose estimation performance on popular dataset. They go on to show that even very crude prototypical approximation of the object geometry using a cuboid. ",
    "This paper addresses an interesting problem in retrieval system - compatible features learning. Given the old feature extractor and a new dataset, the objective is to learn a new feature extractor, so that the features extracted by two (old and new) feature extractors are comparable to each other. In the proposed setting, the old dataset (including its statistics), old classifier, and the parameters of the old model are not available.",
    "This paper deals with an interesting problem of feature compatible learning that the features produced by new model should be compatible with old features. The proposed method uses nearest class\u2013mean classifier instead of linear classifier. Random walk is applied to refine the class means. The proposed method is compared with several baseline methods and shows good performance.",
    "This work proposes a new problem setting by adding extra constraints to the Feature Compatible Learning problem. The new constraints avoid using old training data and the old model\u2019s parameter when learning a new model. The paper gives a baseline method and its variants for the problem by generating pseudo classifiers to regularize a new model\u2019s learning. The experiments show that the proposed method can satisfy the empirical criterion about success.",
    "This paper studies the gradient norm as a measure of generalization in deep learning. The authors first an approximation to the gradient norm (GN) that is the norm of the gradients for only fully connected layers (AGN). Then they empirically evaluate the correlation between AGN and GN as well as GN and the generalization error. In Section 2.1, the authors conclude that AGN is highly correlated with GN and both are correlated with generalization error. In Section 3, the authors conclude that the correlation between AGN and generalization error is not consistent in a wider family of models. In Section 4, authors propose to use AGN for model selection and conclude that AGN is not good for model selection unless the hyperparameter for mixing AGN with another metric is optimal.",
    "The paper empirically investigates the sum of gradient norms as a measure to determine the generalization abilities of a neural network. The approach is inspired by the theoretical work of Li, et al. 2020 which showed that the generalization gap can be upper bounded by a function of the sum of the full gradient norms of the training path. ",
    "In this paper, they provide the empirical studies  to understand the effectiveness and efficiency of the use of the gradient norm (induced by [the Li et al., 2020]) as the model selection criterion. To speed up the calculation process the of the gradient norm, they first propose an approximate gradient norm (AGN) based on the depth-wise, sample-wise and epoch-wise accelerations.  Their empirical studies find that the use of AGN can select the models with lower generalization error, but fails for bandit-based or population-based algorithms, and fails to predict the generalization performance of models based on different architectures.  In conclusion, they do not recommend using (approxiamte) gradient norm for model selection in practice.",
    "The paper introduces a new method to retrieve entity by auto regressively generating unique entity name as a sequence of word pieces, instead of pinpointing the ID representing an entity. This method stands out in novelty compared to existing various entity retrieval methods, which always assigns a single ID to each entity. Practically, the proposed method has two nice properties: (1) When the entity vocabulary is very large, this approach requires less parameter space and memory compared to other methods (as shown clearly in Table 4) (2) The model can address novel entities, which was unseen during the training. The paper is clearly written and extensively evaluated on three relevant tasks, entity disambiguation, entity linking, and entity retrieval.",
    "This paper proposes to tackle the entity linking task using a sequence-to-sequence neural model, trained by producing unique entity names, in autoregressive fashion. The paper makes a case that this approach can scale better with larger entity vocabularies than previous methods with dedicated entity representations both in terms of memory as well as computation costs. The model is studied under a number of tasks including entity disambiguation, entity linking and document retrieval for question answering.",
    "The paper proposed to use autoregressive approach to solve entity-based problems. They proposed a uniform framework and showed that their model achieved the state of the art performance on 3 different types of tasks (~20 datasets). The GENRE model also significantly reduced the memory usage compared to previous models that stored a big memory table. It's also capable of linking novel entities at inference time. This paper is clearly written. The experiment results are convincing.",
    "In this submission a routing problem is studied. In the considered model with each edge of the given graph a congestion function is associated that specifies the congestion depending on the current load of the edge. Then cars have to be routed through the network where each car has a source and a destination and one aims at choosing a path from the source to the destination with the smallest total congestion. However, the congestion functions of the edges are a priori unknown and hence one cannot trivially use a shortest path algorithm. Instead one gains information about the congestion functions only by routing the cars. When a car is routed one observes for each edge on its path the current congestion up to some random additive term. These observations can then be used for future routing decisions.",
    "This work introduces an interesting generalization of stochastic combinatorial semi-bandits for routing in a static graph. The main differences are: (1) the expected loss of an edge e is f_e(x^t_e) where the flow x^t_e is revealed at the beginning of each round (for each edge) and f_e is an unknown Lipschitz function (with known Lipschitz constant); (2) the regret is dynamic, computed against the sequence of optimal paths. When f_e is a constant function for each edge, then we recover a version of the stochastic combinatorial semi-bandit.",
    "The paper uses the bandit learning framework to study the online learning problem for routing in a city network . After each routing decision, the learning agent observes the actual delay on each edge, which is given by the congestion function on the given flow plus a random noise, and the reward is the total delay on all edges. The paper proposes a learning algorithm similar to the UCB approach, provide the regret bound result, and conduct simulations on the New York City network to verify performance of the algorithm. ",
    "This paper proposes an improvement to how tokens are selected for masking in pre-training large masked language models (BERT and family). Specifically, it stipulates that purely random choice of words (or word pieces) makes the MLM task insufficiently hard. It then goes on to propose a data-driven approach for selecting n-grams to mask together. The approach, based on an extension of pointwise mutual information for n-grams, is shown to outperform random token and random spans masking strategies on performance of downstream tasks.",
    "This paper presents a masking strategy for training masked language models (MLM). The proposed strategy builds on previous approaches that mask semantically coherent spans of tokens (such as entire words, named entities, or spans) rather than randomly masking individual tokens. Specifically, the proposed method computes the PMI of spans (and the generalization for spans of size >2) over the pretraining corpus, and randomly masks from among the 800K spans (lengths 2-5) with the highest PMI. Masking based on PMI removes the ability for the model to rely on highly local signals to fill in the mask and instead focus on learning higher level semantics. They motivate this hypothesis with an experiment demonstrating that as the size of the WordPiece vocabulary decreases (and words are more frequently split into multiple tokens rather than being their own token), the transfer performance of the resulting MLM decreases. However, using whole-word masking with this same vocabulary size recovers much of the original performance, indicating that allowing the model to rely on these strong local signals harms the transfer quality of the resulting model.",
    "The paper proposes a variant on the MLM training objective which uses PMI in order to determine which spans to mask. The idea is related to recently-proposed Whole Word Masking and Entity-based masking, but the authors argue the PMI-based approach is more principled. The method is straightforward--it involves computing PMIs for ngrams (in this case, up to length 5) over the training corpus, and then preferring to mask entire collocational phrases rather than single words during training. The intuition is that masking single words allows models to exploit simple collocations, thus optimizing their training objective without learning longer-range dependencies or higher level semantic features of the sentences, and this makes training less efficient than it could be. One contribution of the paper is a variant on the PMI metric that performs better for longer phrases by reducing the scores of phrases that happen to contain high-PMI subphrases, e.g. \"George Washington is\" should not have a high score despite the fact that \"George Washington\" does have a high score.",
    "This paper investigates the effect of partial conditioning on amortized inference in variational auto-encoders, focusing specifically on sequential data sources where it is common practice to have a posterior that is factorized in such a way that conditioning is partial (usually only conditioning on past signals in the sequence). Given a true posterior that is conditioned on the entire observed datapoint, the authors discuss the effect of having an approximate posterior that is only conditioned on part of the input. As the approximate posterior cannot adapt to the part of the input that is left out of the conditioning, the evidence lower bound becomes less tight, due to the larger KL divergence between the approximate posterior and the true posterior. The authors compare this to the work by Cramer et al. [1], where the distinction was made between having a restricted family of possible distributions for the approximate posterior (approximation gap) and the gap between an amortized approximate posterior with an inference network shared for all datapoints and a non-amortized approximate posterior that is optimized for each datapoint separately (amortisation gap). They argue that partial conditioning leads to a third type of gap which is distinct of the aforementioned inference gaps. Through an example with discrete observations the authors derive that when the true posterior is conditioned on the full data, and the approximate posterior is only partially conditioned, the optimal approximate posterior is something akin to a product of true posteriors over the unconditioned information, and not a mixture where the left out information is marginalized out. Through a 1D example they show that this could lead to overly sharp posteriors that have high densities in regions where the true posterior has very low density. ",
    "The paper considers the problem of Bayesian inference with partially conditioned variational posterior. Namely, this work describes the phenomena of ill-behaved variational posterior for the case of partially observed data. The paper's main theoretical finding is that the partially conditioned variational posterior behaves like a product of experts, resulting in a degenerate solution. Speaking intuitively, the true posterior can be seen as a mixture of distributions: the sum over the unobservable variable. At the same time, the optimal variational posterior mixes as a product of distributions. Clearly, the product of densities hardly depicts features of the mixture since a near-zero value of a single member is enough for zeroing out the product's density.",
    "The paper reviews the issue of partial conditioning of the amortized posterior in sequential latent variable models, typically state-space models trained with a VAE-style loss, but where the posterior used is the filtering rather than smoothing posterior. The author show that training a model with posterior with missing information can lead to a gap in estimating both the posterior and the corresponding model. They show the benefits of using the correct posteriors in simple examples.",
    "The paper analyses generalization properties of distributed kernel ridge regression (DKRR) with random features and communications. It studies optimal learning rates of the generalization bounds both in expectation and in probability. In the case of DKRR with random features, the optimal learning rate in expectation is shown to achieve by relaxing the requirement on the number of partitions from $O(1)$ (Li et al., 2019a) to $O(|D|^{0.5})$ (Theorem 1). Within the same setup of random features, the number of partitions is relaxed to $O(|D|^{0.25})$ guaranteeing optimal generalization performance in probability (Theorem 2). The latter bound $O(|D|^{0.25})$ on partition count is much smaller then $O(|D|^{0.5})$. However, as proved in Theorem 3, allowing multiple communication rounds in DKRR-RF, up to $O(|D|^{0.5})$ partitions can be handled depending on the number of communication rounds. In other words, it can exploit more partitions at the cost of more communication rounds.",
    "The paper investigates an algorithm for distributed learning with random Fourier features. The main idea is to sample M random Fourier features and split the data into m chunks. Each chunk is processed on a separate machine that outputs a linear hypothesis using the sampled M random features. The hypotheses coming from different machines are then aggregated on the master machine via importance weighting. In particular, each hypothesis is assigned importance weight proportional to its data chunk size (see Eq. 3). The regularization parameter is fixed across different machines. The main contribution of the work is a consistency bound. In comparison to a previous bound on the divide & conquer algorithm (Li et al., arXiv 2019), this one does not require a constant number of machines (in my understanding of the related work section).",
    "This paper studies the statistical properties of distributed kernel ridge regression together with random features (DKRR-RF), and obtain optimal generalization bounds under the basic setting in the attainable cases.  Numerical results are given for the studied new algorithms. The algorithms and the derived results are new and interesting to me. However, the presentations as well as the citations need some major revision before the publication. ",
    "Motivated by exploring the ranking correlations of the existing RandomNAS in NASBench-201, this paper proposes EPS to improve the search efficiency and keep good ranking correlations by evolving the proxy search space (PS) in RandomNAS. Specially, EPS contains three stages: 1) training the supernet in PS, 2) validating the architectures among the PS and 3) evolving the PS by tournament selection with the aging mechanism. Furthermore, a model-size-based regularization is introduced in the selection stage. Experiments on some popular benchmarks demonstrate the effectiveness of the method.",
    "This paper claims that random search-based NAS methods show a low ranking correlation among top-20% candidate architectures in the search phase. To address this issue, this paper proposes to introduce a proxy search space consisting of good architectures and evolve it using evolutionary algorithms. This paper also proposes a simple size regularization to help the NAS algorithm escape from the small architecture traps. The experimental results show that the proposed approach achieves competitive performance with baseline methods.",
    "This paper proposes Evolving the Proxy Search Space (EPS) as a new RandomNAS-based approach. The goal is to find an effective proxy search space (PS) that is only a small subset of GS to dramatically improve RandomNAS\u2019s search efficiency while at the same time keeping a good correlation for the top-performing architectures. EPS runs in three stages iteratively: Training the supernet by randomly sampling from a PS; Validating the architectures among the PS on a subset of the validation dataset in the training interval; Evolving the PS by a tournament selection evolutionary algorithm with the aging mechanism.",
    "This work seeks to efficiently learn new tasks by combining meta-RL and imitation learning (IL). Such a combination is a natural thing to try, as both lines of work improve sample complexity of learning a new task: meta-RL by leveraging experience on prior related tasks, and IL by leveraging demonstrations. Demonstrations also form a natural way of specifying a new task to the agent.",
    "This work proposes PERIL, a method for combined Meta Imitation Learning and Meta Reinforcement Learning using context-based meta-learning. Given a set of demonstrations, a latent variable representing the desired task is inferred, and trajectories are generated conditioned on the inferred latent variable.  The data from the expert demonstrations and trajectories are used for meta-learning updates.",
    "This paper introduces PERIL, a meta RL method that combines demonstration trajectories and trajectories collected by the policy, in order to adapt to a new task. To this end, the authors combine ideas from metaRL (specifically from PEARL (Rakelly et al. 2019) and Humplik et al (2019)) where a set encoder is used to encode trajectories to a latent vector describing the task, with imitation learning techniques by (a) training this encoder also with demonstrations (b) initialising the latent vector at test time by feeding demonstrations through the encoder, and (c) having additional losses inspired by metaIL techniques. The motivation is that using demonstrations allows us to learn tasks that are difficult otherwise, for example because the rewards (at test time) are sparse. ",
    "This paper is concerned with the question of generalization of convolutional neural networks. For that, the authors study a simple toy model, where each data point consists of several patterns. All patterns are assumed to be orthogonal to each other. Those images should be learned with a 3-layer neural network. The contributions of this paper are as follows:",
    "This paper studied a simplified image classification task with orthogonal non-overlapping patches and is learned by a 3-layer CNN. The authors observed pattern statics inductive bias (PSI) in experiments. They proved that if a learning algorithm satisfies PSI, the sample complexity is nearly quadratic in the filter dimension; while the VC dimension of the network is at least exponential in the filter dimension. The authors also verified PSI in some task based on MNIST that has non-orthogonal patches.",
    "In this manuscript the authors derive theoretical analysis for the generalization guarantees of a na\u00efve CNN (3-layers) where the task is a simplified binary classification task, under the assumption that the images contain orthogonal patches (a na\u00efve assumption). They define a statistical phenomenon that holds in SGD in the proposed setting and call it Pattern Statistics Inductive Bias (PSI). Informally, this means that the magnitude of the dot-product between the learned pattern detectors and their detected patterns is correlated with the distribution of the patterns in the data.   They prove that if a learning algorithm  satisfies PSI then its sample complexity is O(d^2 log (d)), where d is the dimension of the filter. According to their empirical derivation SGD satisfies this property. In contrast there exist learning algorithms that have exponential sample complexity. ",
    "This submission considers contrastive learning approach to representation learning under topic modeling assumptions. It proves that the proposed procedure can recover a representation of documents that reveals their underlying topic posterior information in case of linear models. It is experimentally demonstrated that the proposed procedure performs well in a document classification task with very few training examples in a semi-supervised setting.",
    "This paper tries to learn a document level representation from document level contrastive estimation. The training task is try to predict where two half of a document are from the same document. The author proved the contrastive estimation reveals topic posterior information given the topic modeling assumptions. And in experiments, linear models can get relatively good performance. ",
    "This paper presents a new contrastive learning algorithm for document representation. The main idea is to generate pseudo labeled two texts, whether the texts are coming from the same document. To learn the discriminating function between the two texts, the learning algorithm minimizes the cross-entropy loss function between them. With the function, the authors suggest the embedding function for a document with selected landmark documents. The authors also show the learned function can be represented by combining the topic posterior distribution and topic likelihood distribution. Experiments show that the suggested learning algorithm can identify hidden topics from a synthetic dataset. And the authors also show the usefulness of the representation in semi-supervised learning by classification performance and visualization.",
    "The paper tries to minimize the difference of the PMI between related and unrelated pairs of multimodal data but arrives at a very different objective with many approximations. It can be plugged into existing VAE based methods and improve learning performance and data efficiency. My major concern is about the derivation and the connection between motivation and the final objective.",
    " The paper proposes a contrastive objective that (1) minimizes the distance between \"related\" samples while (2) maximizing the distance between randomly paired samples. Existing multimodal VAEs optimize (1) via different multimodal ELBOs. The novelty lies in the optimization of (2) which can further benefit from unimodal samples for which no \"related\" samples of the other modality are available---this can be viewed as a semi-supervised approach for weakly-supervised multimodal data.  For the estimation of (2), the paper experiments with two different estimators, IWAE and CUBO.",
    "This work presents a generative model for multimodal learning. The paper maximizes or minimizes the pointwise mutual information between data from two modalities considering a novel random variable relatedness to dictates if data are related or not.  This is realized by casting multimodal learning as max-margin optimization with the contrastive loss for the objective. For the optimization, the paper considers the IWAE estimator. As per the experiments, the paper considers MNIST-SVHN and CUB Image-Captions dataset and perform evaluations across four metrics. Using the experiments, the paper demonstrates that the proposed approach improves multimodal learning, data-efficient learning, and label propagation. ",
    "The authors highlight an important problem in VAE - the prior-hole problem - which is that the approximate posterior and the simple gaussian prior do not match in spite of the KL term in the ELBO which makes sampling an issue - leading to the prior putting probability mass on latents that are not decoded to high probability mass regions in data manifold. Prior approaches have overcome this problem by increasing the expressivity of the prior through autoregressive models, and/or using hierarchical latents, EBMs with MCMC sampling. This paper proposes a very simple two stage method - (1) train a regular VAE, (2) train a binary classifier in NCE style to distinguish samples from prior and approx. posterior; use the re-weighting term from the NCE score to sample from a better re-weighted prior - either through langevin dynamics or re-sampling. The authors combine this approach with the use of hierarchical latents and produce really good performing generative models on a host of benchmarks with good looking samples.",
    "Authors approach the \"hole problem\" of variational autoencoders where the aggregate posterior fails to match the prior, causing some areas of the prior distribution to be left out. Consequently, the decoder is not trained properly to operate in such regions, and the whole generate models is then subject to suboptimal performance. To attack this problem authors introduce two changes:",
    "The goal of the paper is to model the marginal over latents in VAEs in such a way to minimize the mismatch with the aggregated posterior. The paper proposes a new class of marginal distributions over the latent space that is a product of two experts: the first expert is a non-trainable probability distribution, and the second expert is an unnormalized probability distribution parameterized using neural networks. Since training a product of experts requires to apply an approximate inference (e.g., MCMC sampling), the authors propose to use the likelihood ratio trick. Eventually, a VAE is trained in two stages. First, they assume the marginal over z's to be simply the non-trainable distribution, and the VAE is trained. At the second stage, they propose to train the second expert (i.e., the binary classifier that distinguishes z ~ q(z) and z ~ p(z)) in order to obtain the final NCP that better matches the aggregated posterior. Further, the idea is extended to hierarchical VAEs, and a separate binary classifier is trained per each stochastic level.",
    "This work considers a regularized IRL setup, where instead of the entropy regularization used in maximum entropy IRL, an arbitrary convex regularizer $\\Omega$ is used. The work presents a number of theoretical results for this general setting, and it is shown that when $\\Omega$ is Tsallis entropy, the $RL \\cdot IRL$ is equivalent to minimizing a Bregman divergence defined based on the Tsallis entropy and the expert state-action distribution. A practical algorithm is presented for IRL with the Tsallis entropy. A number of experiments are performed to obtain understanding of various components.",
    "This paper proposes a new method for regularized inverse RL. The paper builds upon work by Geist et al. who studied regularized MDPs with convex policy regularizers. The Shannon entropy is a special case of such a policy regularizer. The paper extends the analysis of Geist et al. for regularized IRL and devises tractable solutions to regularized IRL that only depend on the analytic knowledge of the regularizer. The paper further proposes regularized adversarial IRL (RAIRL), an extension of AIRL by Fu et al., as an algorithm for IRL in regularized MDPs. The algorithm is validated on a number of domains.",
    "This paper shows a formulation of regularized Markov Decision Processes (MDPs), which is slightly different from that of Geist et al. (2019). Then, the authors propose a novel inverse reinforcement learning under regularized MDPs. One of the contributions is that policy regularization considered here is more general than that of Yang et al. (2019). ",
    "In this paper, the authors present a study of different aspects of language-specific model capacity for massively multilingual machine translation. To this end, language-specific behaviour is achieved via a combination of conditional computation to decide whether to use language-specific parameters or not and statically assigning experts for each languages. The language specific sub-layers are incorporated throughout the network. The training objective allow budgetary constraints on the amount of language-specific parameters. The paper does a systematic analysis on the role of language specific parameters using the proposed architecture. Based on the analysis, recommendations on design of multilingual NMT architectures are proposed and their efficacy validated experimentally. The study sheds light on the amount of language specific parameter sharing, their distribution in the network, impact of language, etc. ",
    "The work proposes a hybrid architecture that has: (1) language-specific (LS) components; (2) as well as the components that are shared across all the languages -- a trade-off between specificity and generality.  A key conclusion of the work is that the best architectures typically are. the ones that have ~10-30% language-specific capacity. ",
    "In this work, the authors present a conditional language-specific routing (CLSR) scheme for transformer-based multilingual NMT systems. They introduce a CLSR layer after every transformer encoder and decoder layer; each such layer is made up of hard gating functions conditioned on token representations that will either select a language-specific projection layer or a shared projection layer. Further, a budget is imposed on the language-specific capacity measured by aggregating the number of gates that allow for language-specific computations; this budget constraint forces the network to identify the sub-layers that will benefit most from being language-specific.",
    "This paper propose a computationally efficient Wasserstein distributional normalization algorithm for accurate classification of noisy labels. An explicit upper bound for the Wasserstein-2 distance is derived and such a bound can be used as an estimator to determine if a network is over-parameterized. Empirical results on CIFAR-10/100 and Clothing1M suggest that the propose algorithm outperforms other SOTA approaches. ",
    "The paper is a contribution that aims at solving the label noise problem. In this setting, the labels are possibly corrupted, this yielding a potentially significant underperformance of a (neural network) classifier when minimizing the empirical risk. This problem is ubiquitous and important in real life scenarii. The paper builds on the idea of small loss criteria, which favors learning on certain samples in the beginning of the learning process, and gradually incorporate uncertain samples along iterations. The paper proposes a novel type of distributional normalization based on Wasserstein distance. It projects uncertain samples on a Wasserstein ball defined wrt. the certain samples. This process is done with a particle based stochastic dynamics, based on a Ornstein-Ulenbeck process. A theoretical Analysis is given, along with results on classical datasets in the symmetric noise setting, open noise and a real world dataset (clothing 1M), for which it achieves very good performances compared to state of the art competing methods. ",
    "The paper introduces a novel objective function by imposing geometric constraints on the logits of uncertain samples. The authors' approach is to map the distribution logits of uncertain samples onto the 2-Wasserstein ball centered on the measure of certain samples. To overcome the dilemma of selecting the ball radius, the authors propose a surrogate objective, namely Wasserstein Normalization. An SDE grad flow is proposed for solving the Wasserstein normalization. The paper also keeps the Gaussian parameters as moving average during training in light of batch normalization. The paper both theoretically and empirically validate their method.",
    "The paper proposes a new conformalized procedure for computing uncertainty sets in classification tasks. The key feature of the method is that the size of the uncertainty sets are regularized via a penalty on the size. The issue of large uncertainty sets produced by conformalized procedures is an interesting one, which the paper does well to highlight. The proposed solution of using an additive regularizer is reasonable, and appears to be effective for sensible choices of the hyper-parameters. However, the paper has some significant weaknesses.",
    "In this paper, the authors propose a regularized conformal score for use in a conformal prediction framework. This regularizer is motivated by the instabilities of top-p variations on conformal scores (cf. Romano et. al., 2020) and the resulting high-variance in output conformal prediction set sizes. The proposed regularizer smooths top-p scores with top-k scores, which empirically results in more robust predictive sets. The authors also perform a large-scale evaluation on ImageNet with modern architectures, which serves as a helpful benchmark for conformal prediction algorithms.",
    " Prediction sets are used to quantify the uncertainty of classification. The naive approach which include the labels until a pre-specified coverage probability is satisfied often leads to large prediction sets. Adaptive Prediction Sets (APS) can output prediction sets with desired coverage but set sizes are still not satisfyingly small and the results are unstable, especially when many probability estimations fall into the tail of the distribution. ",
    "This work introduces a new Wasserstein-2 barycenter computation method. The authors first derive the dual formulation of the Wasserstein-2 barycenter problem, and then parametrize the convex potentials by ICNNs. The congruent and conjugacy conditions are enforced by regularization terms, respectively. They then show that the algorithm can find a good barycenter if the objective function is properly minimized.",
    "The paper derives the barycenter mapping problem as an optimization over *congruent* convex functions---each convex potential corresponding to a component distribution.  Congruency is a property on the set of optimal potential functions that ties them together.  However, this optimization is quite challenging and so the paper derives an principled objective function that includes two regularization terms.  The first regularization term encourages congruency of the set of convex functions and can be seen as a variational bound on an ideal congruency regularization.  The second regularization term encourages the pairs of convex functions to be conjugate.  The paper proves that the optimal solution of this objective is the true potentials and thus no bias is introduced.  The proposed approach is demonstrated on the tasks of generative modeling (2-256 dimensions), posterior inference, and color pallete barycenters (3D)",
    "The paper considers the Wasserstein Barycenter problems in the continuous setting. In particular, the authors propose an algorithm to compute the Wasserstein-2 barycenter when only samples from the marginals are accessible. Some theoretical analysis of this method is presented. Several numerical examples are carried out to compare this method with two other recently proposed methods.",
    "The authors consider a binary classification task. As a model the authors use a deep fully-connected neural network and train it to separate the submanifolds, representing different classes. They assume that sub-manifolds belong to the unit sphere. Also, the authors restrict their analysis to a one-dimensional case. The main claim is that by increasing depth we can improve model generalization of a network, trained by SGD.",
    "The paper studies the conditions for a deep fully-connected network to separate low-dimensional data classes. A binary classification setting is considered, where the two classes are modelled as two different manifolds. The manifolds are assumed to be one-dimensional for the ease of analysis. It is shown that the network depth should be sufficiently large so as to adapt to the geometrical properties of data (e.g. the manifold curvature); the network width should increase polynomially with the network depth; and the number of data samples should also scale at a polynomial rate with the network depth. The authors show that if these conditions are met, with high probability a randomly initialized network converges to a classifier that separates the two class manifolds. The proof technique relies on conditioning the network parameters of the l-th layer on the parameters of the previous layers using a Martingale model, which gives sharp concentration guarantees. ",
    "The paper under review studies the question of whether gradient descent can solve the problem of calibrating a deep neural network for separating two submanifolds of the sphere. The problem studied in the paper is very interesting and as been the subject of recent increasing interest in the machine learning community. The contribution is restricted to a simple set up and addresses the question in the finite sample regime. The framework of the analysis hinges on the Neural Tangent Kernel approximation of Jacot et al. ",
    "This study presents a deep reinforcement learning method, Advantage-Weighted Regression (AWR). The policy update of AWR is constrained as in a similar manner as REPS (Peters et al., 2010). Although the benefit of AWR is not clear in the reinforcement learning tasks, AWR exhibits its advantages in the context of imitation learning and off-policy learning with static datasets. ",
    "This paper focuses on developing an RL learning algorithm that is simple and can significantly improve performance over existing algorithms. The paper presents the algorithm AWR, which is an extension of the algorithm reward weighted regression. The primary extensions of RWR are using the advantage function instead of the q function and the ability to use experience replay. Experiments on common environments are conducted to evaluate the performance of AWR and compare it to other algorithms. There are ablation experiments to justify the choice of some of the extensions. ",
    "This paper presents a reinforcement learning algorithm that applies advantage-weighted regression. In each iteration, it samples trajectories from a mixture of previous policies, estimates the value function and then computes the advantage value to estimate the policy. The idea is very similar to the work published in \u201cNeumann, Gerhard and Peters, Jan R, Fitted Q-iteration by advantage weighted regression, Advances in neural information processing systems, 2009\u201d, starting from reward-weighted regression and further developing to advantage weighted regression.  The difference in this paper is to add a constraint on the policy search, requiring the policy to be similar to the sampling policy. However, this constraint has also been studied in the paper \"Christian Wirth and Johannes Furnkranz and Gerhard Neumann, Model-Free Preference-based Reinforcement Learning, AAAI 2017\" (It seems not in reference). Overall, it may enhance this paper if it has more technical novelty when developing a new algorithm.",
    "The paper proposes using a sinusoidal regularizer for neural network quantization. The regularizer \u201cWaveQ\u201d (sin^2) pushes floating-point parameters towards quantized values. Because the period of the function is highly related to the required bit-width, it can be used to determine the bit-width while keeping good characteristics - continuous and trainable. The authors provide experiments on both CNN and Transformers. The proposed method is widely adaptable and easy-to-use with quite promising results.",
    "This paper proposed a regularization term to control the bit-width and encourage the DNN weights moving to the quantization intervals. The key in such regularization is the Sinusoidal function, where the penalty is maximized in the middle of quantization levels and minimized at the quantization points. The sinusoidal period is regarded as the continuous representation of the bit-width.",
    "When training quantized neural networks, one typically first fixes the desired bitwidth $b$ (of weights and activations). While training, one maintains and updates full-bitwidth weights during backprop and \"cheats\" by using $b$-quantized versions of these full-precision weights during forward propagation. The quantization scheme used may vary.",
    "The paper proposes a GAN process for training neural machine translation models. The noise generator in this approach uses a switching-aligned-words technique where they randomly switch a word in the source sentence with its translation in the target sentence. They use fast-align to get alignments between source and target sentences. The experiments show that the noisy sentence pair generator performs best with the proposed switch and align approach in comparison with other (more random) methods. ",
    "This paper describes a method for data augmentation and/or regularization for machine translation that works by running a word aligner on the parallel data, and then with some probability \\gamma, replacing a source token with its corresponding target token or vice versa. A proposed variant also mixes the embeddings of the two words. Small improvements are shown over simpler noising strategies such as replacing words with placeholder tokens or with random words from the vocabulary.",
    "The paper proposes a data augmentation technique where source sentences are perturbed by replacing (or mixing) source words with their aligned counterparts from the target language (while the target sentences remain as is). Alignments can be either obtained from an unsupervised aligner like fast-align or from the attention distribution of an NMT model. Perturbations are aimed to be semantically invariant to preserve the meaning of the source sentence. In addition to simply replacing the source word with the aligned word, authors also try out inputting a weighted combination of both the source word and the target word and refer to this method as \u201cmixing\u201d. Empirical observations suggest that simply replacing the source word with the aligned target yields better results.",
    "The paper is to measure each client\u2019s contribution to training the federated learning model. In particular, the contribution is measured by the distance between the local model and the global model in each iteration. The targeting problem is interesting, and the use of attention-based model divergence is also an interesting idea to measure the contribution. However, the paper lacks strict theoretical discussion to prove the proposed solution is a reasonable one rather than a heuristic method. Moreover, the experiment is too weak to support the claims. The paper\u2019s technique contribution and originality are also limited. ",
    "The paper proposes a low computational complexity method for weighting contributions of clients in a federated learning setting. The main contributions are to compare the weighting method with Shapley values and their sensitivity to low data volume and quality. The paper is based on the FedAtt paper that calculates weights based on the Euclidean distance between the server model and each client and for each layer.",
    "The paper proposes a new contribution measurement approach for federated learning. The basic idea is that the agent with a larger model update has a larger contribution. Specifically, based on FedAtt [1], the impact of a client is computed as the local updates plus the impact of the previous round times a decay rate. The experiments on a dataset show that the proposed approach can have a similar contribution measurement compared with Shapley Value.",
    "The paper considers the problem of robustly learning fixed structure Bayesian networks in nearly-linear time. Previous work by Cheng et al. gives a runtime of O(Nd^2/eps). The paper improves this to O(Nd). The algorithm works by directly relating the problem to robust mean estimation, and then leveraging the algorithm of Dong et al. for robust mean estimation which works in nearly-linear time. The authors have to modify the runtime analysis of the algorithm of Dong et al. to work in time linear in the sparsity, rather than dimension.",
    "The paper studies the problem of robust learning of fixed-structure Bayesian networks under the eps-adversarial corruptions model. Fixed-structure means a known structure of the underlying Bayesian network. Robust learning is an important area of research and this particular question has been studied in prior work. The main contribution of this work is in improving the running time of the algorithm. On a d-node Bayes net, let m denote the total number of parental configurations possible. Prior work of Cheng et al showed a robust learning algorithm using O(m/eps^2) samples and runs in time O(md^2/eps^2).",
    "This paper studies the problem of learning Bayes nets using adversarially corrupted data. The model is that $N$ samples are made from a Bayes net on d nodes, out of which an unknown $\\varepsilon$ fraction are changed arbitrarily. The structure of the Bayes net is already given, but it remains to learn the probability distribution.",
    "In this paper, the authors propose to replace commonly-used shooting-based methods for action sequence planning in learned latent-space dynamics models by a collocation-based method. They argue that shooting-based methods exhibit problematic behavior especially for sparse-reward and long-horizon tasks, as shooting methods do not allow for planning trajectories which (slightly) violate the learned dynamics. The authors propose a collocation method based on Levenberg-Marquard optimization with a scheduled Lagrange multiplier which outperforms two shooting methods (CEM and gradient-based) on a set of robotic tasks.",
    "This paper introduces a vision-based motion planning approach using collocation. Many existing approaches to vision-based control rely on computationally expensive planning approaches using shooting to perform model-based control, which is often only useful in simple control tasks. Collocation approaches are effective in settings with difficult path constraints, and thus exploited by this work to dramatically improve model-based reinforcement learning.",
    "The paper studies the problem of planning in domains with sparse rewards where observations are in the form of images. It focuses on solving this problem using model-based RL with emphasis on better trajectory optimization. The proposed solution uses latent models to extract latent representations of the planning problem that is optimized using the Levenberg-Marquardt algorithm (over a horizon). The experimental results show improvements over a) zeroth-order CEM optimization, b)  PlaNet (Hafner et al., 2019) and c)  gradient-based method that optimizes the objective in Eq. 1.",
    "The work propose a theory suggesting that the cold posterior phenomena arises solely due the the curated nature of image benchmarks. A generative model is proposed where multiple annotators label datapoints, and only unanimously labeled datapoints are accepted into a dataset. This theory is studied under a toy-problem using VI and a relabelled version of the CIFAR-10 test set with SGLD. ",
    "This paper addresses the perplexing issue of cold posterior having better predictive performance than the ideal Bayesian posterior in Bayesian deep learning (Wenzel et al., 2020), and offers a possible explanation in terms of a mis-specified likelihood function that deviates from the true generative process of the data. By considering the data curation process and augmenting the likelihood model accordingly, the effect of cold posterior is shown to diminish significantly, and the ideal posterior is again optimal. Empirical results on both a toy problem and image classification support the theory.",
    "The authors propose the idea that cold posteriors in Bayesian neural networks could be caused by the likelihood instead of the prior. They argue theoretically that the curation process of popular benchmark data sets would lead to a different weighting of the likelihood in the posterior. They show in some experiments that the cold posterior effect can be reduced when accounting for this.",
    "Traditional NTM is done with a large encoder and large autoregressive (AR) decoder. Due to the sequential nature of the AR decoder, inference can be slow due to lack of parallelism (unless done at very large batch sizes). Non-Autoregressive (NAR) models have been proposed to alleviate this problem, but all NAR approaches trade off some translation quality for speed gains. In this paper, the authors claim that an alternative to NAR is to speed up standard AR decoding by reallocating network weights and layers to the (easily parallelizable) encoder, and making the decoder a single layer. They claim that this matches the speed of NAR models while keeping the performance of traditional AR models, making it a better choice in the design space than any NAR models. Comparisons are made to CMLM and DisCo NAR models to justify these claims with experimental evidence.",
    "The authors advocate for fair comparison between autoregressive (AR) and non-autoregressive models (NAR) in non-autoregressive machine translation (NAT) research. They highlight three main aspects where the comparison has not been fair so far in the literature - suboptimal layer allocation, insufficient speed measurement, and lack of knowledge distillation. They perform extensive comparisons between AR and NAR models in these 3 aspects and report interesting results. ",
    "The paper proposes deep encoder and shallow decoder models for auto-regressive NMT. They compare rigorously to NAR models. They also study three factors: layer allocation, speed measurement and knowledge distillation. They include that with a 12E-D1 model they obtain significant speed-up and can outperform the standard 6-6 AR model and almost always beat the NAR model in terms of quality. They also show that NAR models need deep decoders because they need to handle reordering.",
    "The paper under review studies the epoch wise double descent phenomena empirically. The epoch wise double descent phenomena is the observation that the risk of a large neural network trained with SGD first decreases, then increases, and finally decreases again as a function of the epochs or SGD steps. In addition, it proposes a quantity called ``optimization variance (OV)'', and it demonstrate that OV correlates with the test error. Based on this observation, it proposes to early stop when the OV reaches a minimum.",
    "Having a stopping rule without the validation set is intriguing, especially for datasets with a low number of samples. The authors propose a rule that doesn't require the validation dataset, i.e. it is solely based on training data. It introduces the notion of optimization variance which is different from the variance of gradients. ",
    "The paper studies the trajectory of the test error as a function of training time focusing on Epoch-Wise Double-Descent.  Similar to \"Rethinking Bias-Variance Trade-off for Generalization of Neural Networks\" by Yang et. al., the paper shows that if one decomposes the test error to bias and variance terms, Double Descent occurs as a function of train time as a result of unimodality of the variance term (while the bias term decreases monotonically).  The paper also introduces a quantity they name optimization variance (OV) and that correlates with the test error (while being only a function of the train set) and can be useful for early stopping.",
    "This paper investigates the adversarial robustness of model agnostic meta-learning (MAML). Adversarial robustness can be added to MAML in two places, meta-update stage and and fine-tune stage. It shows that robustifying the meta-update stage via fast attack generation method is sufficient to achieve fast robustness adaptation without losing generalization and computation efficiency in general. The paper also demonstrates that unlabeled data can help using contrastive representation learning to improve generalization and robustness. ",
    "It is an interesting paper empirically addressing adversarial robustness of model agnostic meta learning (MAML). The paper investigates where to incorporate robust regularization in MAML in order to improve adversarial robustness, and based on that *efficient* robust MAML methods are proposed. Interestingly, contrastive learning is incorporated and derive a more robust MAML model. ",
    "This paper explores a way to promote the adversarial robustness in Model-agnostic meta-learning (MAML). It conducts extensive experiments to show regularizing adversarial robustness at meta-update level is sufficient to offer fast and effective robustness adaptation on few-shot test tasks. However, it lacks the theoretical analysis for this conclusion. Also, the experiments only are conducted on few-shot image classification task on miniImageNet dataset. This makes this conclusion lack sufficient credibility.",
    "Meta-gradient descent is an approach to step-size adaptation in which the step-size is adapted by considering how it influences the loss function over time. Intuitively, one can think of the trajectory of parameters $(w_s)_{s=1}^t$ as being a function of the step-size $\\eta$, and try to control the loss indirectly through the step-size's influence on the weight trajectory. This paper provides guarantees for this class of algorithms when applied to a quadradic loss function. It is shown that the meta-objective $\\ell_t(\\eta)=\\frac{1}{2}w_t(\\eta)^\\top H w_t(\\eta)$ contains no bad local solutions, but can suffer from vanishing/exploding gradients. It is then shown that this can be remedied simply considering the logarithm of this meta-objective, but that this too will have issues with numerical stability if approached with back-propagation. Finally, results related to the generalization ability of these methods are presented.",
    "This paper considers algorithms that attempt to learn learning rates for gradient descent by gradient descent. Analysis is provided for a few specific quadratic losses showing that the gradient with respect to the learning rate may explode or vanish, and taking the logarithm is suggested to mitigate this. Further results suggest that implementing the gradient of the log comes with interesting numerical difficulties as *intermediate results* might explode or vanish even if the final answer does not.",
    "This paper presents novel theoretical results on learning a step size for vanilla GD and SGD by unrolling the optimization steps and back-propagating, taking into account the simple problem minimizing quadratic functions and mean-square errors. The authors could demonstrate the occurrence of already-detected phenomena for learned optimizers, such as gradient explosion/vanishing and over-fitting, in the particular studied case. A few experiments illustrate what the developed theory predicts. ",
    "In this paper, a graph view-consistent learning framework (GVCLN) is proposed. Specifically, two view learners are used to give predictions for the input. Then, a consistency loss is employed to force the two viewers giving the same predictions. Moreover, a co-training scheme is proposed to alleviate the label sparsity problem.",
    "This paper proposes a view-consistent framework to address the issues of expensive labels. In particular, this work first uses graph neural networks and graph attention networks to construct two different latent features of the same data. Then, it uses the same classification neural networks to produce the node classification outcomes. Finally, it uses the classification outcome to construct a so-called \"view loss\". In addition, it uses an incremental strategy to gradually included pseudo labels until some termination conditions are satisfied. ",
    "This paper adopts a multi-view learning approach for graph representation learning where some labels are assumed to be available. It uses graph convolution network (GCN) and graph attention network (GAT) to create two different views of the same graph and then define a loss function to force the output due to the two views to be consistent. The low label rate scenario is considered and pseudo labels are created to define an additional loss function to better enforce consistency. Three datasets are used for performance evaluation.",
    "This submission explores the question of identifying conserved quantities in Hamiltonian dynamics for physical systems by attempting to learn canonical transformations. The approach closely resembles previous work on \"Hamiltonian neural networks\" but the loss is augmented with a term enforcing the invariance of the dynamics under the transformation and with a term that ensures the resulting transformed coordinates satisfy the constraints of the algebraic relations that emerge from the Poisson bracket. Together these two additions allow the authors to train a network that performs a change of coordinates which is subsequently optimized to bring it closer to a canonical transformation. Perhaps the main observation is that some of the cyclic coordinates identified by the network have a clear relation to the underlying conserved quantities. ",
    ".** The authors propose using a neural network to learn a canonical transformation of the data coordinates before learning a Hamiltonian. This is a novel contribution in that previous work has shown how to learn Hamiltonians with neural networks but it has not shown how to learn the proper canonical transformation. In the course of learning this canonical transformation, they show how to project out other symmetries (linear and angular momentum) and hence improve upon HNNs while also learning these other symmetries to a good approximation.",
    "This paper presents the results of a NN trained to learn symmetries in physics, specifically, to learn and preserve quantities that are preserved (e.g., energy, angular momentum). The input is a sequence generated from a Hamiltonian dynamics. Results of experiments on 2 and 3 body problems and a harmonic oscillator are presented. The training networks are small, shallow feedforward networks. There is some customization of the training networks to incorporate \"cyclic\" coordinates. Results indicated empirical conservation up to small error of physically conserved quantities. The paper is fairly easy to read, with much relevant background provided.",
    "The paper proposes a GNN model by incorporating gradient boosting. In the proposed BGNN, the input feature on the graph is learned by the gradient boosting model. The processed feature then becomes a new feature for a GNN model following the gradient boosting. Several experiments demonstrate the improvement of the performance for a tabular feature and graph-structured datasets. The running time of Res-GNN/BGNN is shown to have a significant reduction as compared to the plain GNN methods.",
    "This paper aims to learn from graphs with tabular node features. Existing methods are only designed to handle either tabular data, such as gradient boosting decision tree (GBDT), or graph-structured data, such as graph neural networks (GNNs). This paper naturally extends GBDT to deal with graph-structured data and train it together with GNN in end-to-end fashion.",
    "Review: This paper proposes a fusion of GBDT and graph neural network that works on graphs with heterogeneous tabular features. Previous approaches are computationally heavy and do not consider graph-structured data and suffer from lack of relational bias imposed in GNNs. The proposed method is a new ensemble tree method which alternates between functional gradient step in GBDT (which train on the current latent features) and SGD training of graph neural network (to generate the latent features which are fed into the subsequent trees).",
    "In this paper, the authors study the theoretical properties of meta-learning. In particular, the train-validation split to tackle the linear centroid meta-learning problem is investigated using statistical asymptotic theory. First, the authors proved that the train-validation method has statistical consistency, while the train-train method has a statistical bias to the centroid. Under the noise-free setting, however, both methods have statistical consistency. Furthermore, the train-train method is superior to the train-validation method in the sense of the asymptotic MSE. Based on the asymptotic analysis the optimal ratio of the data splitting for the train-validation method was also derived. The theoretical findings are confirmed by some numerical experiments. ",
    "In meta-learning, a common practice is to do a train/validation split of the data within each that, so that optimization of meta-parameters is performed on validation, not training, losses. In this paper, the author argue that this split is important for correcting model misspecification, but if the model is correctly specified, not doing a split might actually lead to better learning rates. They provide theoretical justification under a simple linear model, and some experiments on synthetic and real data.",
    "The authors verify the importance of train-validation split in meta-learning theoretically, which is commonly used in the meta-learning paradigms. By analyzing the linear centroid meta-learning problem, the authors show that the splitting method converges to the optimal prior as expected, whereas the non-splitting method does not in general, without structural assumptions on the data. The authors validate the theories empirically through both simulations and real meta-learning tasks.",
    "This paper proposes momentum of memorization as a way to distinguish hard examples needed for efficient learning from noisy examples which decrease classification accuracy. The method finds confident, hard examples and updates them dynamically during model training. This is done by iteratively selecting examples with labels that agree with model predictions and then training on only the confident data. Results show improved accuracy on standard image classification datasets with both synthetic and real world label noise.",
    "This paper propose a novel and effective method called Me-Momentum to cope with noisy labels. The algorithm borrows the idea of momentum from physics and tries to identify hard examples. The authors alternately update the hard examples and improve the classifier to achieve the robustness to noisy labels. Experiments and comparisons with recent state-of-art methods are provided to verify the effectiveness of Me-Momentum. ",
    "The authors introduce an interesting approach to handling hard \"confident\" samples in learning with label noises. At the heart of the proposed approach is an interactive method that jointly refines the classifier and the samples. The confident samples are initialized by utilizing the memorization effect of deep networks. Then, a classifier is learned from such samples. ",
    "First, the paper identifies k-Nearest Neighbor (kNN) and radius Nearest Neighbor (rNN) to be naturally effective baseline certified defenses against data poisoning attack. It is easy to see that kNN and rNN are resistant to poison attacks, since to flip the prediction of a test example, one would need to insert/delete enough examples to change the majority vote. Second, the paper proposes a joint certificate that further improves certified accuracy for rNN. Specifically, it uses the fact that for any given poison removal budget, it can only decrease the vote for a single label. Even though the idea is simple, the experimental result is quite impressive significantly outperforming the previous more sophisticated certified defense methods.",
    "The paper studies robustness of k-NN and r-NN against data poisoning attacks. The main message of the paper is that k-NN and r-NN are automatically resilient against attacks. Furthermore, by grouping test examples based their predicted labels. Data points with different predictions are grouped together, and then better certification guarantee can be derived. Experimental results demonstrate that k-NN and r-NN are indeed self-robust against data poisoning attacks.",
    "This paper studies to train a certifiable robust model against data poisoning attacks using nearest neighbors. The paper studies the voting mechanism in the nearest neighbor models, and presents a relationship between the poisoning instances and the difference between the majority votes and the second majority votes. Such a relationship will result in a guarantee on the lower bound of a training model's accuracy, which is referred to as Certified Accuracy (CA). The theoretical results are neat. The experiments are conducted on MNIST and CIFAR, and results show better CA than previous approaches of DPA and Bagging.",
    "In this paper, the authors study an important problem on how the choice of batch size (i.e., the number of sampled nodes) affects the training efficiency and accuracy of graph neural networks (GNN). Focusing on the layer-wise and graph-wise sampling for training, the authors theoretically characterize the impact of batch sizes on the efficiency (measured by a product of computation time and variance) of the algorithms. Especially, in order to better capture the randomness of two-consecutive layers, the authors investigate a different estimator rather than the one truly used in the training of GNN. The resulting theory suggests a choice of the batch size to be n/\\hat d, where n is the total number of nodes and \\hat d is the average degree of the graph. The authors empirically show that compared to the training of NN, the training of GNN requires a much larger batch size to achieve an efficient training. In addition, the experiments show that the best batch size is much smaller than the full batch that is widely adopted in the training of GNN.",
    "In this paper, the authors studied the problem of batch size selection in graph neural networks. Since scaling up the batch size is the most efficient way to increase parallelism, this topic seems to be very important for making full use of modern computer architectures like GPUs or TPUs. The authors conduct a detailed analysis on the impact of batch size in graph neural networks. After a series of discussions, the authors conclude that an ideal batch size should be n/d where n is the total number of nodes and d is the average node degree. The authors suggested that this batch size should be able to give the best convergence/generalization performance for graph neural networks. Overall, the paper is properly written. In terms of presentation, the structure is clear and the idea is easy to understand.",
    "The goal of the paper is to propose a principled strategy to select batch size for training graph neural networks with SGD. Training (using GNNs) real world graphs with a large number of nodes/ edges may not always fit in CPU /GPU memory, hence constructing mini-batches is important. Specifically, the authors propose a strategy for the task of node classification - where they aim to select batch size based on number of nodes and average degree in a graph and show that their proposed guidelines have benefits in terms of training time as well as accuracy. The authors propose a metric - pseudo precision rate which is dependent on the computation cost and the variance of the gradients and derive a lower bound for this metric which factors into account the batch size.",
    "This paper introduces RED, a new methodology to produce reliable confidence scores to detect missclassification errors in neural networks. The idea is to combine kernels based on both input and output spaces (as in RIO) to define a (sparse) GP that estimates the residual between the correctness of the original prediction and the maximum class probability. The authors show enhanced performance against other related methods and the ability of RED to detect OOD and adversarial data through the variance of the confidence score. ",
    "In this paper, their goal is to improve calibration and accuracy by augmenting a classification model with a GP. They base their model off RIO (ICLR 2020) which targets regression problems and tries to predict the residual between predicted value and true value. They propose a model, RED, which instead tries to predict the residual between the predicted confidence score for the true class and 1 \u2014 the true class target confidence score using a GP. They show strong improvements over the methods they compare to for 125 UCI datasets and CIFAR-10 dataset.",
    "This paper solves an interesting problem of predicting uncertainty in NN without re-raining/modifying the existing NN. The authors propose a framework to calculate a confidence score for detecting misclassification errors by calibrating the NN classifier\u2019s confidence scores and estimates uncertainty around the calibrated scores using Gaussian processes. This framework is called RED (Residual i/o Error Detection). ",
    "Many Information Retrieval systems rely on two components: a retriever that identifies a small set of \"support\" documents from a large corpus, followed by a reader that re-scores these support documents more finely. For retrievers, metrics like BM25 were once common but they are increasingly replaced by machine learned components. However, most datasets do not provide direct supervision information for the retriever.",
    "The paper targets an important problem in open-domain QA - the training of the retriever for the purpose of determining a segment that may contain the answer. In the most traditional setting, the retriever is just a traditional IR system such as BM25. In some existing work, the retriever has been trained to locate the documents containing the answer (e.g. inverse cloze task, or DPR). This paper goes in the same direction. The difference is that it uses the attention weights as relevance signals to train the retriever, instead of the inclusion of the answer in the passage.",
    "The authors propose a training technique for information retrieval models in the context of (open domain) question answering. Assuming the existence of some reader model, the idea is to use internal information of that model as a training signal for a retriever. Specifically, they use the attention activations over the input documents as synthetic labels for the retriever.",
    "The paper proposes a constrained reinforcement learning (RL) formulation relying on constraints written in a formal language. The proposed formulation is based on constrained Markov decision processes where the constraint is represented as a deterministic finite automaton that rejects any trajectory violating the constraint. The proposed solution relies on transforming the automaton's sparse binary cost into an approximate dense cost and augmenting that with the reward objective. The paper presents a series of results from simulations in Safety Gym, MuJoCo, and Atari environments.",
    "The paper builds on the constrained MDP framework (Altman, 1999), by considering the special-case where the cost functions are defined in terms of states from a parser of a formal language. In the experiments the work uses deterministic finite automata (DFA) but in principle other more expressive classes could be used. Using a formal language to specify constraints may simplify model checking (although this is left to future work). ",
    "The authors propose to use formal languages, specifically DFAs, as a mechanism to specify constraints in a constrained MDP setting. This has the benefit of being able to rely on a large body of existing work on identification, safety verification, etc. The strategy relies on decomposing the constraint into a translation, recogniser & cost assignment function that connect the MDP to the DFA. The mentioned cost can then be combined with existing solution for solving cMDPs, such as reward shaping and Lagrangian methods. The key observation is that adding the recogniser state to the observations of the policy can result in significant gains in both performance and constraint satisfaction. A range of results are presented across different environment suites and hyper parameters.",
    "The authors presented in this submission a nice novel idea of building a tree ensemble in a cascading style so that any positive predictions are decided and explained by the first tree predicting them positively. The reviewer finds this idea very interesting and clearly elaborated in this paper. However, more theoretical and empirical justification is crucially necessary in order to make the claims in the submission convincing. The issues listed here are some questions that the reviewer believes should have been discussed or answered in the paper.",
    "This paper introduces the Cascading Decision Tree, a novel variant of decision trees with permits to extract short explanations for a class of interest. The idea is to realize a cascade of small decision trees: at a certain level, the tree is built using all points except the positive ones correctly classified by trees in previous levels. The method has been tested using three standard datasets and a novel application.",
    "This paper introduces a new type of classification model called the \"cascading decision tree.\" The cascading decision tree is a rule-based classifier designed to have an overlapping hierarchical structure between its nodes to produce succinct explanations. The paper introduces these models, presents an induction algorithm to learn them from data, and includes an empirical evaluation on three UCI datasets as well as a propietary dataset. The submission includes code.",
    "This paper analyzed the influence of neural network width on the network performances while fixing the total number of parameters. Specifically, the authors introduced several ways to change the model width without increasing the number of parameters, and showed experimentally that for widened networks with a random static mask on weights to keep the number of parameters, increasing the width can improve the performances of the models until the network become very sparse and hard to train. They author theoretically showed that for a not so sparse one-hidden-layer neural network, increasing width decreases the distance to the Gaussian Process kernel corresponding to the infinith-width limit, which partially supports their experimental findings.",
    "In this paper, the authors analyze the enhancements brought by widening networks with the number of parameters fixed. From the experimental side, they conduct various experiments to compare the methods of widening the networks and demonstrate different ratios of widening different networks on diverse datasets. From the theoretical side, the authors relate the training dynamics of neural networks to kernel-based learning, in  the infinite-width limit. As a consequence, the authors claim that wider networks indeed improve the performance of algorithms under certain conditions.",
    "This manuscript provides an intriguing discussion on the different roles that the width and parameter size could play in a neural network. While these two aspects are traditionally treated as -if not identical- correlated, the authors managed to develop a couple of configurations to decouple and analyze both separately. Especially the wide and sparse approach could be a new way to design neural networks that are supposed to be small and expressive at the same time. ",
    "This paper presents an approach to jointly pre-train language models and representations for knowledge graphs. In particular, natural language texts (English Wikipedia) are used to train context representations, while knowledge graphs (Wikidata) train entity representations (and both depend on each other). Experiments show that the approach outperforms baseline methods on several natural language understanding tasks: few-shot relation classification, knowledge graph question answering, and entity classification. ",
    "This work proposes a method for joint pre-training of knowledge graph and text data which embeds KG entities and relations into shared latent semantic space as entity embeddings from text. The proposed model JAKET consists of two main parts: a language module and a knowledge module. The model is pre-trained on a collection of tasks: entity category prediction, relation type prediction, masked token prediction and masked entity prediction. The proposed framework enables fine-tuning on knowledge graphs which are unseen during pre-training.",
    "This paper proposed a new language modeling pretraining method that leverages the knowledge graph information. Specifically, the paper replaces the entity embedding in one hidden layer of BERT context embedding, with the corresponding graph attention embedding that is obtained from the knowledge graph. The pretraining tasks contain not only the language related tasks (like predicting masked tokens), but also the knowledge graph tasks like entity classification or relation type prediction. Experiments on few-shot learning tasks, question answering and entity classification show better performance over other pretraining counterparts. ",
    "This paper proposes to model the generation order as latent variables for sequence generation tasks, by optimizing the ELBO involving a proposed process of Variational Order Inference (VOI). To alleviate the difficulty of optimizing discrete latent variables, the authors propose to cast it as a one-step Markov Decision problem and optimize it using the policy gradient. The authors also introduce the recent developed Gumbel-matching techniques to derive the close-form of the posterior distribution.",
    "This paper aims to decode both content and ordering of language models and proposes Variational Order Inference (VOI). The authors introduce a latent sequence variable z = (z_1, .. ,z_n) in which z_t is defined as the absolute position of the value generated. The authors model the posterior distribution of z as a Gumbel-Matching distribution which is relaxed as a Gumbel-Sinkorn distribution. To training the encoder and decoder networks, the ELBO is maximized using the policy gradient with baseline. The experimental results on Django and MS-COCO 2017 dataset show the proposed VOI outperforms the Transformer-InDIGO, as well as suggests that learned orders depend on content and best-first generation order.",
    "This paper designed a new generative model by capturing the auto-regressive order as latent variables for sequence generation task. Based on combinatorical optimization techniques, the authors derived an policy gradient algorithm to optimize the variational lower bound. Empirical results on image caption and code generation showed that this method is superior than both fixed-order generation and previous adaptive-order method transformer-InDIGO. The authors further analyzed the learned orders on global and local level on COCO2017 dataset, demonstrating that the arrangement tend to follows the best-first strategy.",
    "This paper studies the convergence of stochastic training methods for graph neural networks. Here, this paper views GNN as a compositional optimization problem. Then, to reduce the variance incurred by the neighbor sampling, this paper uses SPIDER to reduce the variance to accelerate the convergence speed. It provides theoretical convergence analysis for SPIDER used on GNNs, showing that the proposed method has a better convergence rate compared with the traditional gradient descent method. At last, this paper conducts experiments to verify the proposed algorithm. ",
    "Node sampling is a crucial point in making GCNs efficient. While several sampling methods have been proposed previously, the theorectical convergence analysis is still lacking. This paper finds that the convergence speed is related to not only the function approximation error but also the layer-gradient error. Based on this finding, the authors suggest to take historical hidden features and historical gradients to do doubly variance reduction. Experiments are done on 5 datasets for 7 baseline sampling-based GCNs.",
    "This paper presents a novel variance reduction method which can adapt to any sampling-based GCN methods (inductive GCNs). The paper draws the idea from VRGCN that integrates the historical latent representations of nodes computed with full Laplacian to approximate the that computed with sampled sparse Laplacian. The variance reduction is implemented on both node embedding approximation, as well as layer-wise gradient computation in back-propagation. The resulting algorithms lead to faster convergence rate.",
    "This paper proposed a single image-based manipulation method (DeepSIM) using conditional a generative model. The authors addressed this problem by proposing to learn the mapping between a set of primitive representation, which consists of edges and segmentation masks, and an image. They also adopted a thin-plate-splines (TPS) transformation as augmentation which enables the model to robustly manipulate an image by editing primitives.",
    "This work proposes a method to design conditional generative models based on a single image. In particular, while some recent models have enabled one to sample (unconditionally) images from a generative model learned from a single image (like SinGAN), this work explores a way of conditioning the generation on a primitive, which can be user-specified. As a result, one can produce realistic modifications to a given image by modifying - or sketching - some primitive.",
    "This paper provides an augmentation method to enable single image training. The network learns to map between a primitive representation of the image (e.g. edges and segmentation) to the image itself. During manipulation, the generator allows for making general image changes by modifying the primitive input representation and mapping it through the network.",
    "Given two input graphs G1,G2 the maximum common subgraph detection problem asks to find an induced subgraph of both G1 and G2, with as many vertices as possible. In the recent years, there have been papers that introduce different heuristics for guiding the search of this subgraph within branch & bound algorithms. The main contribution of this paper is a combination of graph neural network embeddings and RL to guide the search more efficiently.  The function used to guide the deep Q-network is given in Equation (3). The paper performs a set of experiments on synthetic and real world pairs of graphs, where it is shown that it performs well in practice. The supplementary material provides more details on the experiments. ",
    "The motivation of this paper is clear and interesting, as it\u2019s important to explore the maximum common subgraph in biochemical domain. In this paper, the authors conduct a lot of experiments to demonstrate the effectiveness of the proposed method. Despite of this, the presentation of this paper requires improvement because many important details are missing, which makes it hard to follow. The time-complexity analysis might also be crucial to demonstrate the superiority of the proposed method over other baselines in terms of searching time. ",
    "The paper deals with the problem of Maximum Common Subgraph (MCS) detection, following a learning-based approach. In particular, it introduces GLSEARCH, a model that leverages representations learned by GNNs in a reinforcement learning framework to allow for efficient search. The proposed model has been experimentally evaluated on both artificial and real-world graphs, and its performance has been compared against traditional and learning-based baselines.",
    "This paper introduces a supervised neural network predicting a wireframe structure from a 3D point cloud. The network takes a raw unordered 3D point cloud as input, processes it using FCGF architecture, and predicts three types of information: vertex existence in each patch, vertex location, and edge existence for each pair of vertices. In the experiments, the network is evaluated with two datasets, a subset of the ABC dataset and a set of 3D models from Google 3D warehouse. Also, it is compared with the baseline methods using four evaluation metrics, which are created to assess the accuracy of the predicted vertices, edges, and the overall wireframe graph structure. The results demonstrate the outperformance of the proposed method quantitatively and qualitatively.",
    "This paper presents a deep architecture to extract a wireframe model from a 3D point cloud. This is a problem of high interest, and the author claim that the approach they present is the first one to address this task, which is true to the best of my knowledge. Since both the approach and the evaluation are sound, this alone seem to warrant publication. There are however several weaknesses in the paper, and my accept recommendation is conditional to clear answer on each of them:",
    "This paper introduces PC2WF, a neural network that turns 3D point clouds into a wireframe model. PC2WF encodes each point into a feature vector and uses them to predict the candidate corners. After that, line proposals are generated by connecting pairs of corners, and the point features along each line are pooled into its confidence value. By pruning the proposed lines, PC2WF generates the final wireframe represesntation.",
    "This paper studies gradient-based stochastic optimization algorithms which incorporate (estimates of) the noise statistics in the adaptive stepsize design. Starting from the standard analysis of SGD with adaptive steps (Thm 1) the authors show in Cor 1 how, using a second-moment-dependent learning rate, one can \u201caccelerate\u201d (see comment later) the convergence of SGD. Next, the authors show (Thm 3) that one can recover a similar result by estimating the second moment using an exponential moving average.",
    "This paper studies the problem of stochastic optimization where the gradient noise process is non-stationary. Based on a general convergence results based on a general sequence for the second moments of the stochastic gradient norms and a general stepsize sequence, the authors propose to use an online estimation procedure for the gradient norm second moments, in order to mimic the behavior of the ``idealized'' stepsize sequence. Finite-time convergence rates are established for the algorithms with adaptive stepsize, leading to an acceleration effect in certain regimes for the non-stationarity.",
    "The objective of the paper is to provide a theoretical justification for the value of using adaptive learning steps. The paper presents two results. The first is essentially of theoretical interest, and assumes that the noise level indicators defined in Eq. (1) [but which are difficult to understand at this level of the paper] are known. The second is more practical: it shows that a variant of the RMSprop algorithm achieves the same results as the \"theoretical\" algorithm.",
    "This paper proposes to integrate word alignment obtained from SMT into an NMT system. This is an exciting topic not only because it can help interpretability, but also because the same mechanism could be used e.g. for imposing a specific terminology in translations, something that was relatively easy to do with SMT but is much harder to achieve with NMT. The proposed method involves computing word-word alignment using existing SMT models (GIZA and FastAlign in the experiments) and integrating that information in the decoder of a transformer-based NMT model. Experiments on English-Romanian and English Korean show small improvement over a standard baseline.",
    "This work proposes to incorporate word alignment information as a word substitution model. Basic idea is to jointly train a separate encoder using a cross entropy loss which predicts a source input sequence with words substituted by aligned target words. The learned representation is combined with a Transformer either by simple summation, gating or joint attention mechanism. Experimental results on Romanian/English and Korean/English tasks show very marginal gains over the baseline Transformer.",
    "The paper presents a strategy to integrate prior word alignments into NMT models. It is not clear the motivation for this in the NMT context, especially why the prior alignments are crucial information that is necessary to be given a-priori to the Transformer. Besides this, the description of the method and the discussion of related work is given, SMT methods are briefly mentioned but the usage of the idea in previous work, also SMT literature is necessary.",
    "The paper describes a new benchmark for evaluating reinforcement learning techniques (MDP-playground). It can be seen as a toolbox allowing to generate different MDPs with different characteristics. Each MDP will then be used to probe a particular ability of learning algorithms, resulting in a comparison of methods over multiple dimensions. Proposed dimensions are reward sparsity, stochasticity, delayed reward, etc....  In addition to this toolbox, the authors also evaluate some of the classical algorithms in the domain. ",
    "This paper proposes a suite of benchmark tasks designed to test (and possibly debug) reinforcement learning algorithms. Deemed the MDP Playground, these environments are applicable to both discrete and continuous RL agents and allow tuning of various dimensions of complexity - reward delays, reward sparsity, stochasticity, etc. The authors demonstrate their framework by evaluating the performance of many well-known RL agents across a variety of these playground environments. Additionally they conduct similar experiments on Atari and Mujoco tasks and observe similar trends in agent performance when injecting noise, reward delays, and varying action max values. Finally, the MDP Playground is very quick to run and facilitates fast experimentation.",
    "This paper presents \"MDP Playground\", a family of procedurally generated MDPs that can be used to benchmark certain dimension of difficulty considered by the authors to be challenging to current RL algorithms.  The paper presents the effects of the various perturbations to the MDP on state-of-the-art learning algorithms and discusses particular dimension of interest in the paper.  A full and exhaustive analysis of results is presented in the appendix.  The \"MDP Playground\" is slated to be open-sourced so that the community can benchmark against it.",
    "The manuscript discusses the side-effects (or drawbacks) of Isotonic regression and proposes an alternative approach for calibration in regression problems. The authors demonstrate the limitiation of Isotonoc regression such as nonsmooth PDFs and truncation of support under some constructions of the calibration dataset (line 2 in page 4) on a simple linear regression problem (last paragraph before section 4). On the light of these observations, they propose quantile regression (QR) which does not require an additional dataset.",
    "The paper discusses a new calibration mechanism for regression models which produce better model prediction and uncertainty estimates. In Section 3, the paper first discusses some properties and drawbacks of the approach based on isotonic regression in Kuleshov et al., 2018 which uses a post-hoc calibration dataset after model fitting for calibration. Section 4 discusses a new approach based on regularization to achieve implicit regression calibration during model training instead of using a post-hoc processing approach. Section 5 is devoted to experimental results supporting the theory outlined in Sections 3 and 4.",
    "The authors consider the problem of learning quantile calibrated regressions model. A probabilistic regression model is a model that, given an input, outputs a distribution over possible scalar values. A quantile calibrated model is one is such that, for all quantiles $p$, the probability over $X, Y$ that the model predicts $Y$ is in the $p$th quantile is equal to $p$. Machine learning models are not usually calibrated after standard training, so the authors consider a regularization approach to improve the calibration of the model during training.",
    "This paper describes a Deep Variational Bayes Filter (DBVF) for Deep-Learning based SLAM in 3D environments. It builds upon similar work for 2D environments in [Mirchev et. al. 19], and learns a full 3D RGBD occupancy map and a sequence of 6 DoF poses (localization) using raw stereoscopic camera data. Differentiable ray-casting and an attention model is described to access the learnt global map to give a local map and an expected observation - using an emission model from the current pose and local map. A transition model describing the evolution of the dynamics of the agent is also learnt. A variational approximation of the actual posterior (of the sequence of poses and the map, given the sequence of observations) is learnt by optimizing the standard ELBO equation from Variational Bayes. Such deep generative models, once learnt (in an unsupervised way) for an environment, allows one to hallucinate a sequence of poses and observations, given the learnt map and control inputs. This allows downstream robotic control tasks like environment exploration and path planning to be integrated into the model. Experiments on a simulated dataset with a flying drone in a subway and living room environments demonstrate good SLAM performance (that approach traditional methods): bird's eye view projections of the 6 DoF poses and the emitted maps closely match the ground truth poses and the occupancy grid. This is a well-written paper that represents a good step up from [Mirchev et. al. 19] to formulate a DVBF with realistic RGBD data streams. The authors mention that the computational times for this method is still far from conventional SLAM techniques - an actual quantification of the time taken during inference would be useful.",
    "This paper addresses the problem of dense RGB-D SLAM. The key idea is to formulate the problem as a deep state-space model and infer the state of the latent variables (i.e. pose and geometry) using variational inference. The experiments demonstrate that the method performs well in a challenging quadcopter dataset. However, the advantages of the approach are not demonstrated. ",
    "This paper presents a novel learning-based visual-inertial odometry algorithm. The algorithm simultaneously reconstructs the world map as well as the states of the agent from the stereo RGBD sensors.  The world is modeled as an occupancy grid with color. A graphical model with attention mechanism and ray casting is used to model how the world and the agent state renders the RGBD sensor data. ELBO is used to optimize the model. The technical details look sound to me.",
    "This paper is studying the problem of learning to interpret manuals / textual information about the task, with the goal of faster learning and generalization in RL. Unlike recent prior work (Narasimhan et al 2018, Zhong et al 2020) where the entities in the environment are already partly grounded to text (e.g. by representing them as their textual description), the agent here needs to learn the mapping between entities and corresponding text. In order to study this problem, the authors use a new environment and dataset of natural language descriptions, as well as propose a self-attention model that matches entities to relevant sentences. The proposed model performed comparable to a partly grounded policy (as in Narasimhan et al 2018).",
    "The paper considers the task of training an agent to act following a manual expressed in natural language. The manual describes the roles and the behaviors of the entities in the environment. Each entity can be the goal, the message or the enemy and it can also be either fleeing, chasing or not moving. The agent has to bring the message to the goal while avoiding the enemy. A model called EMMA is proposed to change entity representations based on the manual, thereby making the agent aware of the entities\u2019 roles. It is shown that EMMA is more effective than simple baselines.",
    "Natural language grounding is an interesting research direction and has attracted many researchers in recent years. Previous work mainly considered grounding the text to image objects. This paper considers collaboratively to learn \u201centity\u201d representations and natural language explanations with a reinforcement learning framework. Specifically, a multi-modal attention network is proposed to model the interaction between the entity representation and the text descriptions. The entire framework is trained over multiple games in a multi-task manner. Experiments are conducted on a newly designed benchmark. The proposed RL framework achieves reasonable performance in domain games (training & test are from the same games) and also has a strong zero-shot generalization to unseen games and \"entities\" (thanks to the parameter sharing and multi-task learning). Besides, the newly released dataset may facilitate future research in natural language grounding.",
    "This paper presents AVEC, a new critic loss for model-free actor-critic Reinforcement Learning algorithms. The AVEC loss can be used with any actor-critic algorithm, with PPO, TRPO and SAC being evaluated in the paper. The loss builds on the mean-squared-error, and adds a term that minimizes $E_s [f_{\\\\phi}(s) - \\\\hat{V}^{\\\\pi_{\\\\theta_k}}(s) ]$. The addition of that extra term is motivated by recent research on the stability of actor-critic algorithms, and the benefits obtained by the AVEC loss are empirically demonstrated in numerous environments, with AVEC+PPO, AVEC+SAC and AVEC+TRPO.",
    "The paper explores an alternative loss function for fitting critic in Reinforcement Learning. Instead of using the standard mean squared loss between critic predictions and value estimates, the authors propose to use a loss function that also incorporates a variance term. The authors dub the approach AVEC. The authors combine their approach with popular RL algorithms such as SAC and PPO and evaluated on the standard benchmarks for continuous control.",
    "The paper proposes a simple and elegant idea for changing the value function objectives in deep RL and demonstrates reasonable empirical evidence of it's potential usefulness.  The authors also provide a clearly articulated intuitive motivation and provide experiments to support the proposal.  The idea complements several other algorithms and is therefore quite widely applicable (and easy to try). The analysis of the experiments is also quite interesting and clearly presented. ",
    "This paper aims to empirically explore the depth dependence of overparameterized networks. The authors study fully-connected networks trained on a synthetic dataset consisting of random Gaussian inputs, with the label a simple function of the input. In one case, for \"local\" labels, the label is the parity of a product of a subset of the components. In the other case, for \"global\" labels, the label is a sum of such products of subsets with coverage over all the components. Broadly, the authors find that deeper MLPs are better able to learn the local labels, but shallower MLPs are better able to learn the global labels. Finally, the authors compare these results to the infinite width NTK and show that the NTK does not at all capture the behavior of the finite networks.",
    "This paper analyzes overparametrized networks evaluating how depth and width affect the generalization performance of the network. A set of experiments is designed in which labels are determined either by local or global interactions among the features, and generalization is observed for different values of width and depth of the network. NTK is also considered as a limit case of a network with infinite width.",
    "Recent theoretical study on the training of neural networks has introduced an important kernel function called neural tangent kernel. This paper studies the training of deep ReLU networks and compares it with the training directly using NTK by conducting experiments on synthetic data. Based on the experimental results, the authors conclude that deeper networks perform better on certain datasets whose labels are more \u201clocal\u201d, while shallower networks are better at more \u201cglobal\u201d labels. Moreover, the authors observed that finite-width networks have better generalization than NTK. ",
    "This paper studies the benefit of few-shot learning for sample complexity, when all the tasks (both source and target task) share the same underline representation. Under some assumptions on the data and tasks, this paper improves the previous result based on the iid task assumption and shows that they can utilize all source data. The considered models include linear model (both low dimensional and high dimensional representation) and two-layer neural network.",
    "The paper aims at justifying the success of few shot learning methods that work based on finding a shared representation among a number of tasks. A serious theoretical challenge is that, even if we assume such a representation exists (and belongs to a predefined class of functions with controlled capacity), we would still need to assume something that connects the source tasks with the target task. Previous work has considered \"i.i.d. tasks\", however, the obtained bounds were not natural in the sense that we don't have the usual decrease in the error as we increase the size of the training set of the source tasks. Under a different set of assumptions, the authors show that, in a sense, one can \"fully\" exploit the training data from the source tasks. ",
    "This paper presents some new theoretical insights into a two-layer (linear or non-linear) network based meta-learning framework for dimension reduction and few-shot linear regression. In the considered problem setting, the hidden layer for feature extraction is assumed to be shared across the training and test tasks, and the output layer is optimized in a task-specific way with quadratic loss. For well-specified low-dimensional linear representation learning models, statistical analysis shows that when the tasks are sufficiently divergent, the excess risk of the target task estimator has a near-optimal rate of convergence, up to a near-optimal statistical error of meta-training. The corresponding results for well-specified high-dimensional linear representation and neural networks have also been derived under additional regularization conditions.",
    "The present paper proposes to consider features derived from PCA for the purposes of adversarial attack and defense. They argue that, based on these features, they can verify larger neighborhoods and provide stronger attacks. The neighborhoods are based on the ERAN verifier and the attacks are in comparison to a recent attack called AutoZoom. Defense performance is measured in number of images in the neighborhood, and attack performance in terms of L2 distance.",
    "The authors study the problem of adversarial robustness, aiming to find regions of the input space for which a classifier is robust. Instead of the standard approach of defining a neighborhood around each data point based on some $\\ell_p$-norm, they use PCA to identify directions along which the model is robust or brittle. They then use these methods to identify large regions of input space for which models are robust and, in a complementary direction, to craft imperceptible adversarial examples with few model queries.",
    "The overall quality of the paper is good. This paper proposed a feature perturbation procedure, as a comparison to the commonly used perturbation to the original input data. Given access to a feature mapping and a black-box classifier, the proposed procedure is able to select the most robust/weak features. This then can be used for two important tasks: to determine a robust neighborhood for a data point using the robust features and to design adversarial examples using the weak features. For the first task, the feature-based robust neighborhood proposed by this paper is shown by experiments to contain far more points than the traditional input-based neighborhood. For the second task, the feature-based adversarial examples require less query to the black-box classifier and have less distortion from the original data points compared with other competitive methods, and thus are more human-imperceptible. These characteristics make the procedure appealing.",
    "In this paper, the authors present a new multi-task reinforcement learning (RL) algorithm. Since In general, the relationships between tasks is unknown a-priori, directly applying classical multi-task learning approaches that assume all tasks are related, could suffer from negative transfer. The authors propose to cluster tasks into disjoint groups: The proposed algorithm iterates through steps of assigning tasks to specific policies and training each policy only based on the respective assigned tasks (clusters). In the experiments, the authors compare their algorithm with two single-task learning baselines (SP: a single policy for all tasks and PPT: a policy per task) and a recent multi-task RL algorithm of Eramo et al. 2020 on Pendulum, Bipedal Walker, and Atari problems.",
    "This paper proposes a multi-task RL algorithm that leverages unsupervised task clustering. The authors propose to initialize a number of policies, cluster each task based on its performance on different policies, and train each policy with data coming from tasks within the cluster. The paper shows that such kind of an EM style clustering can lead to better performance than single-task training and be more sample efficient more training each task independently on both tabular settings, continuous control experiments, and Atari. ",
    "The authors propose to approach multi-task RL problems in which tasks may differ considerably in transition functions/dynamics and reward functions as well as in the action space through task clustering. Specifically, tasks are modeled as belonging to separate task clusters defined by the return obtainable by individual policies i. All policies are evaluated on a single task and the relative cumulative discounted rewards over some iterations determines the assignment of tasks to policies. Simulations show the advantage in terms of number of training iterations on several tasks compared to a selection to other related algorithms. ",
    "This paper proposes a self-supervised encoder-discriminator based framework for embedding the multivariate time series into a compact fixed dimensional representation. The approach dubbed Temporal Neighborhood Coding (TNC) leverages the concept of a neighborhood in time (with stationary properties), and learns time series representations by ensuring the distribution of neighboring signals is distinguishable from the distribution of non-neighboring signals, in the encoding space. Empirical evidence is provided that such embedding of time series results in clusters of higher quality, as well that use of such obtained representations for supervised tasks outperforms few competitor (unsupervised) approaches. ",
    "The authors propose a novel unsupervised encoding scheme for time series. Utilizing a statistical test for non-stationarity, the authors derive a Temporal Neighborhood Coding (TNC) scheme and combine it with ideas from Positive-Unlabeled (PU) learning to learn informative hidden representations of time series windows. The representations are evaluated in terms of how well they can be clustered and how much they influence classification performance on three data sets. The supreme performance was demonstrated when comparing to the state of the art methods and a $k$NN (for classification) baseline. Furthermore, the authors illustrate how the learnt representations remain interpretable as long as the encoding network is reasonably small. ",
    "The paper proposes an unsupervised representation (embedding) learning method for time-series. While unsupervised representation learning has been extensively studied and shown good performance in fields like NLP and vision, it is relatively new to the time-series community. This paper, in contrast to recent work (CPC and Triplet-Loss), has the following differences:",
    "This paper presents a method of composing stacked neural network blocks by linearly combining module \"template\" weights.  The work extends \"isometric networks\", in which each block in the stack has the same operational structure, by parameterizing each block using a mixture of the weights from a bank of K blocks (\"templates\").  In multitask learning experiments, the mixtures naturally learn to share common components between tasks, while learning task-specific components where needed.  Further experiments describe behavior of the system applied to transfer learning and domain adaptation scenarios.",
    "The authors propose a method to design network architectures as a combination of network components. Their idea consists in imposing an architecture that is a sequence of identical network blocks, and learn a series of templates, which provide an instantiation of model weights for one such network block. Model weights are then estimated for a specific task as a linear combination of a set of template weights. ",
    "This paper considers \u201cmodular multi-task learning\u201d where parameters in each layer/task are generated as a (layer/task-specific) linear (mixture) combination of a common pool of parameters. Exploring this idea, several observations are made: (1) single task isometric model performance on ImageNet can be improved, (2) Multi-task learning is supported and parameter sharing (selecting same mixture components) emerges in early layers, with specialisation emerging in later layers. With multi-domain learning, the opposite effect is achieved with domain-wise specificity arising in earlier layers, and sharing in later layers. (3) Parameter-efficient transfer learning is supported by fine-tuning the task-specific weights for new tasks. (4) Parameter-efficient domain adaptation is supported by optimising the task-specific weights for new domains. ",
    "The paper considers Gaussian VAEs and their tendency to suffer from posterior collapse. In particular, the authors analyse the impact of the usually fixed covariance $\\sigma_x$ of the decoder Gaussian on the learned encoder variance. They show that the former can be seen as a regulariser for the latter and therefore impacts the \"smoothness\" of the encoder. The authors hypothesize that a large value of $\\sigma_x$ causes posterior collapse as a consequence.",
    "This paper studies the Gaussian VAE and figures out that the decoder variance regularizes the VAE and affects the model smoothness, and an inappropriate estimation of this parameter would raise posterior collapse, which is supported by theoretical analysis and empirical demonstrations. Hence, this paper then proposes an ELBO with adaptive decoder variance to avoid oversmoothing the model. Overall, the idea is interesting and provides some new insights for our community. The major concerns regarding this paper are listed as below.",
    "This paper analyses the \"posterior collapse\" phenomenon observed in training latent variable models (in particular Variational Auto-Encoders), and propose a new training objective to remedy the problem. The theoretical analysis of the authors suggests that the posterior collapse is induced by an inappropriate choice of variance in the decoder distribution. The new objective they propose, the AR-ELBO, jointly optimises this variance along with the usual network parameters. The authors demonstrate that their objective yields relatively good results on image modelling, compared to other standard VAE methods.",
    "This paper proposed a deep generative model based on the non i.i.d. VAE framework in an unsupervised version. The model which combines a mixture prior in the local latent space with global latent space has three advantages: First, the latent space can capture interpretable features. Second, the model performs domain alignment. Third, the model can discriminate among their global posterior representations. Although this paper has mild improvement on the basic VAE structure, the model displays a good interpretability power, and the setup of the latent variables are illustrated reasonably in the paper.",
    "This article introduces a VAE-based method for separating local variation factors from global variation factors in the data in an unsupervised manner. It achieves so by designing a graphical model with a mix of example-local and batch-shared variables, and training it using the ELBO. The article provide an detailed experimental analysis on MNIST and CelebA, and experimental evidence that all parts of the model (notably the discrete d variable) are relevant.",
    "This paper presents a novel deep generative model based on noni.i.d. variational autoencoders that captures global dependencies among observations in a fully unsupervised fashion. The proposed model combines a mixture model in the local or data-dependent space and a global Gaussian latent variable, which captures interpretable disentangled representations with no user-defined regularization in the evidence lower bound. The proposed model is being evaluated in two tasks: (1) disentanglement, and (2) domain alignment.",
    "This paper proposes to improve upon unsupervised representation learning for various downstream vision tasks by leveraging human motion and attention (gaze) information. The authors collect a large spatio-temporal dataset with gaze and body motion labels for this task. They train a network to jointly predict the visual focus of attention in scenes and body motion besides visual instance recognition via an NCE loss to learn good visual representations. They show large improvements in accuracy of many different visual recognition downstream tasks with their approach versus the SOTA MOCO approach, which uses visual information only.",
    "The main aim of the paper is to make use of human interaction/motion to learn a visual  representation that can be re-used for classic visual tasks such as depth estimation. The authors claim that by encoding interaction and attention cues in the self-supervised representation, the method can outperform visual-only state-of-the-art methods. To study the interaction element, the authors attach sensors like Inertial Movement Units (IMUs) to the limbs of subjects and monitor their reaction to visual events in daily life. The paper also introduces a new dataset of 4260 minutes of human interactions by 35 participants which include synchronized streams of images, body part movements, and gaze information.",
    "The paper uses a combination of visual, human gaze and human motion sensors to build representations that perform better on downstream tasks such as action recognition, physics prediction and depth estimation than representations extracted from solely visual input. The paper announces the release a new data set of aligned visual images, eye gaze fixations and IMU motion readings from test subjects walking around an environment. Representations are computed using three different forms of information simultaneously. Given a visual input, the system tries to predict the location of eye gaze in image frame coordinates, whether each of 6 groups of motion detectors are active or not (head, torso, legs, etc.) and the result of a more traditional auxiliary visual pretext task. In this work, the paper uses \u201cinstance discrimination\u201d where representations of augmented versions of a specific image are pushed close together in latent space and far away from augmentations of other images. Tests on diverse benchmarks show that the gaze and motion prediction improve over visual pretext tasks alone and that there is a small benefit to using both together, but it is not additive. The paper also shows the benefit of gaze and motion is present for two different visual auxiliary tasks.",
    "This work investigates the intriguing phenomenon where pretraining on one task hurts the finetuning performance of another. Besides being interesting in general, this phenomenon has practical relevance as pretraining becomes increasingly popular with large-scale models. Here, the authors present a clean case for \u201cnegative pretraining effect\u201d on images, and propose three ways to mitigate it.",
    "This paper conducts an empirical study to examine the well-known negative transfer phenomenon (termed as a negative pretraining effect in this work) in neural networks. In particular, a network trained on a sequence of tasks performs inferior to a network trained from scratch on the intended target task. The main idea of the paper is to study this phenomenon by formulating and intervening on different constituents of the sequential learning process - (1) changing the learning rate across tasks, (2) number and type of tasks encountered in the learning process, and (3) resetting the model biases when going from one task to another. The paper conducts experiments on four visual classification datasets (CIFAR-10, FashionMNIST, MNIST, SVHN) and report their findings for sequential training of ResNet-18 architecture. They show that increasing the learning rate after training on the first task can alleviate the negative pretraining effect. They further showcase how different task discretization and resetting model biases help to reduce the effect. ",
    "The authors study what they call a negative pretraining effect = models pretrained on task 1 and tuned on task 2 sometimes underperform compared to just training on task 2 from scratch. This is an important factor in many forms of life long learning, multi-task learning and curriculum learning. They investigate 3 potential remedies / setups: a) using different learning rates for task 1 and task 2, b) changing from task 1 to task 2 more smoothly, and c) resetting network biases at different stages of the process. The perform with a single ResNet18 architecture on MNIST, Fashion MNIST, SVHN and CIFAR-10.",
    "This paper aims to improve adversarial robustness of the classifiers in a different perspective than the existing works. Usually, the networks are trained using adversarial examples to improve robustness (adversarial training). This work extend this line of thought and make an input robust to adversarial attacks. Instead of updating the network, they make updates to the input to gain robustness. In other words, this work explore the existence of safe spots near the input samples that are robust against adversarial attacks. Results on CIFAR-10 and ImageNet reveals that there exists such safe spots which are resistant to adversarial perturbations and improve adversarial robustness when combined with adversarial training (the authors term it as safe-spot aware adversarial training). Based on this approach, the authors also propose out-of-distribution detection method that outperforms previous works.",
    "This paper proposes a new adversarial framework where the defender could preemptively modify classifier inputs to find safe spots that are robust to adversarial attacks. They then introduce a novel bi-level optimization algorithm that can find safe spots on over 90% of the correctly classified images for adversarially trained classifiers on CIFAR-10 and ImageNet datasets and show that they can be used to improve both the empirical and certified robustness on smoothed classifiers. Besides, they propose a new training scheme based on their conjecture about safe spots for out-of-distribution detection which achieves state-of-the-art results on near-distribution outliers. ",
    "The authors argue that there are some safe \"spots\" in the data space that are less prone to adversarial attacks. The authors propose a technique to identify such \"safe spots\". They then leverage them for robust training and observe higher robust accuracy than baseline. Finally, they leverage this observation to identify out of distribution data. ",
    "This paper introduces a new convolutional approach to directly process raw spatiotemporal (ST) point cloud data. The proposed point spatio-temporal (PST) convolution operates on \"point tubes\" and decouples space and time through a shared spatial convolution at each timestep, followed by a temporal convolution. It also introduces a transposed PST to enable point-wise predictions in an encoder-decoder framework (PSTNet). The presented experiments demonstrate the effectiveness of these convolutions by using PSTNet for action recognition and semantic segmentation on point cloud sequences, showing improvement over relevant recent work.",
    "The paper introduces point spatio-temporal convolutions, which are used for the feature extraction of point cloud sequences. A trainable kernel is used which is applied locally as a continuous convolution. An important aspect is that the temporal dimension is processed separately, with an additional convolution, instead of simply using a 4D convolution. The authors claim that in this way the network will achieve a better understanding of the dynamics of the input.",
    "This paper aims to process the point cloud data in a convolution manner. The authors propose the PST convolution and deconvolution operations to handle the different tasks such as the classification and segmentation on point cloud. The extensive experiments verify the effectiveness of the proposed method and achieve state-of-the-art results on multiple benchmark datasets. Overall, the paper is well-written and organized. ",
    "AdaSpeech is a paper on practical TTS custom voice adaptation with the aim of reducing the amount of adapted parameters per voice to allow cloud serving of a large number of custom voices while maintaining high adaptation quality and similarity. The novel piece that enables this is the conditioning of layernorm in the model on the speaker embedding. The grammar reads slightly awkwardly in places, but the paper is understandable and well structured. Descriptions of the model, experiments, and analysis of results are well done.",
    "The authors propose an interesting text-to-speech adaptation method for high quality and efficient customization of new voice. The proposed method consists of two-stage modeling : multi-phonetic-level acoustic condition modeling and conditional layer normalization. In the first stage modeling, the authors proposed a new phoneme-level acoustic condition modeling in addition to the speaker and utterance-level approaches. In the second stage modeling, they employ conditional layer normalization for efficient adaptation.",
    "In this paper, the authors present AdaSpeech, a TTS system that can adapt to a custom voice with a high quality output and a low number of additional parameters. The model is based on the TTS model in FastSpeech 2, with several additional components. The authors show that AdaSpeech has improved results over other baselines. They also provide an interesting ablation study.",
    "This paper proposes effective gradient flow (EGF), which is a layer-wise normalized gradient flow. Compared to (unnormalized) gradient flow, the paper shows that the proposed EGF is (slightly) better correlated with metrics like test loss and test accuracy (see Table 1). Given that this claim is supported with experimental results, the paper would become much stronger if a larger number and a more diverse set of data-sets were used (in addition to CIFAR-10 and CIFAR-100, which are two very similar image-data-sets) as to show that the claim holds more generally. Apart from that, given that the correlations are (only) about 0.4 in Table 1, it seems that only some aspects are explained by EGF. ",
    "Recently, initialization has been found critical to the model accuracy attained by sparse training [1]. In this paper, the authors studies the impact of factors other than initialization on the model accuracy attained by sparse training relative to dense training (under the same model parameter count). At the core of this paper, the authors argue that the effective gradient flow (grad norm from only activate model weight dimensions) is an effective indicator on the model accuracy attained by sparse training. Firstly, the authors show that the effective gradient flow attains higher correlation with model accuracy than the norm of full gradient (including gradients on sparsified weight dimensions) in sparse training. Secondly, the paper empirically demonstrate that in sparse training, 1) weight decay and data augmentation can hurt model accuracy, 2) batch normalization plays significantly role for model accuracy in sparse training and 3) non-saturating activations boost the magnitude of effective gradient flow and consequently improve model accuracy. ",
    "This paper looks at how choices in optimization affect how well you can train sparse networks. The authors come up with a new measure of effective gradient flow, which is important for good performance. They also compare sparse vs. dense networks across various optimizers, hyperparameters and activation functions, and find that batch norm and certain activation functions are beneficial for sparse networks",
    "The manuscript proposes a unified model which combines label propagation algorithm (LPA) and graph convolution network (GCN). The main idea is to optimize edge weights (after making edge weights trainable) by maximizing the intra-class feature influence. Introducing the theorems on the relationship between feature and label influence, and LPA\u2019s prediction, the authors propose the unified objective function (a summation of the GCN loss and LPA loss) which combines both methods.   ",
    "This paper addresses the problem that edges in a graph could be noisy, containing erroneous edges. With the assumption of GCN that \u2018labels/features are correlated over the edges of the graph\u2019, it is desired that weights of inter-class edges are large, and those of intra-class edges are small. Hence, these noisy edges could impair GCN\u2019s performance.",
    "This paper aims to combine the label propagation and graph convolutional network with the modeling of their latent relationships. In the developed model, the node label is utilized to infer the edge weights between different nodes. From the evaluation results in Section 4, the performance improvement between the proposed method GCN-LPA and GDC is marginal, which can hardly demonstrate the advantage of the unified model (with GCN and LPA) over the graph diffusion network (without the restriction of information aggregation over neighboring nodes).",
    "This paper studied a novel perspective on generalization error bounds, by introducing the \"label generating function \"(LGF). Several new complexity measures (correlated Rademacher complexity, co-complexity, invariance co-complexity, dissociation co-complexity, Rademacher smoothness) were proposed. The properties of the measures and generalization error bound with respect to these complexity measures are studied.  ",
    "The paper provides an interesting perspective to view generalization error for the machine learning model. In particular, it proposes to investigate the constraint on the label generating function space. They propose a concept of co-complexity analogous to the entropy-ish concept which measures complexities between two function spaces. This co-complexity can be decomposed into two parts which measure the categorization ability of the classifier in generator and extent level in classifier for the invariance transformation in the generator.",
    "This paper aims to propose a new complexity measure, called co-complexity, to control classifiers' generalization gap. This new measure acts like a joint-entropy and leads to tighter bounds on the generalization error in this setting. The main idea is to extend the classical complexity measure of Barlett & Mendelson (2003) by introducing a new function space: the generator space is defined as the function space of all possible LGFs satisfying ad hoc constraints. Thus, the authors claimed to be able to measure the extent to which the classifier's function space obeys the invariance transformations in the data and measure the extent to which the classifier can differentiate between separate categories in the data.",
    "This paper proposes BRECQ which is a new Post Training Quantization (PTQ) method. The goal of the paper is to push the limit of PTQ to low bit precision (INT2). They try to address this by considering both inter and intra-layer sensitivity to find the best update to the model parameters so that the output from a block is minimally changed/perturbed. Furthermore, the authors also consider mixed precision quantization setting.",
    "This paper explores the post-training inference quantization. Based on second-order quantization error analysis, it proposes to reconstruct quantized model in a block level to achieve SOTA accuracy for INT2 weight quantization, which distinguish this paper from previous reported layer-wise reconstruction approach. The proposed approach is intuitive and supported by extensive experiments across a wide range of image classification and object detection tasks.",
    "I couldn't follow the method described in the paper. The authors are basically trying to address post-training quantization by perturbing the the weights of a trained DNN. The goal is to perturb the weights so that the quantized DNN will behave similar to the original full-precision DNN. The authors draw a link between this optimization problem and optimizing for the \"reconstruction\" of the output activations of a block (see Equation 7). The technique BRECQ, shown in Algorithm 1, is basically to optimize the perturbation of the weights for the right hand side of Equation 7 for each block of a DNN.",
    "\tThis paper discussed how data properties (e.g., label noise, label imbalance, data size) affects calibration error. The author designed experiments on varying computer vision datasets (i.e., cifar10, cifar100, eurosat and iNaturalist) qualitatively: 1) calibration error for various individual classes under class-imbalance situation; 2) calibration error for different scale of label noise; 3) calibration error under non-uniform noise; 4) calibration error under various scale of dataset size; 5) Calibration error under different combinations of data augmentations. The experimental results show that poor calibration performance accompanies with large noisy label rate, large imbalance ratio and small dataset size. For the reason of small dataset size causing poor calibration error, this paper provided the theoretical proof. ",
    "This work is an empirical survey of the calibration problem with convnets. The authors use several existing benchmark datasets and create synthetic class-imbalance for datasets that are initially balanced. They then extend the well-known results on higher prediction error of minority class, to its calibration error. The work investigates several existing methods that alleviate prediction error in imbalanced datasets and examine their effect on calibration error. At last, the effect of dataset size and data augmentation on calibration error is reported. Later on, the effect of random label noise is also examined. The observations, although not surprising, have not been reported before ",
    "In this work, authors demonstrate that dataset properties can significantly affect calibration and suggest that calibration should be measured during dataset curation. In the field of applied AI to real-life problem, we face all the time decision-makings on what is the most effective strategy in the pipeline (eg. sampling, noise, labeling) and this paper present some evidence for those decisions.",
    "The paper investigates emergent gesture-based communication in Embodied Multi-Agent Populations. A noticeable feature of the paper is that it investigates emergent communication in the case of non-uniform distribution of intents and costly communication (i.e. agents are penalized for effort). The authors find that in certain scenarios, these conditions may lead to communication generalization of learned communication strategies to new, previously unseen agents.",
    "The paper deals with agents that communicate non-verbally via actuating their joints in a 3D environment. The authors show that the agents should be able to learn protocols that can generalize to novel partners. Furthermore, the authors find that the current training approaches are brittle, and they propose and evaluate approaches to address this challenge.",
    "The authors study the zero-shot emergent non-verbal communication in this paper. Different from most papers on emergent communication. this paper uses the motion of three-joint agents. The agents meet partners that they have never seen in the training phase, presenting the challenge of the universal protocol. To make a universal protocol possible, the authors study intents sampled from Zipf distribution and energy regulation. The authors conducted experiments on tasks with 2, 5, 10 intents. The results show that providing latent energy feature is essential for zero-shot coordination. To achieve better than chance accuracy on tasks with 10 intents, a torque curriculum is needed. ",
    "In this paper, the authors propose a technique for uncertainty estimation in regression with neural networks. The basic idea is to use an auxiliary \"meta model\" that (in the authors' best performing setting) has access to the base model and is trained jointly with it. The purpose of the meta model is to predict the error characteristics of the base model, which of course naturally leads to error bars. In order to account for the fact that the models errors on the train set are unlikely to be representative, the authors make use of a validation set on which the meta model is trained further. ",
    "In this work, the authors present a meta-modeling approach to provide predictions with uncertainty estimates in a sequential task. They develop a white box, black box, and joint modeling method that allows them to apply their method to a variety of scenarios. These methods differ based on the amount of information provided to a meta-learner which has the goal of predicting errors $\\hat{z} \\in \\mathbb{R}^{D \\times M} $. The authors also incorporate the ability to make asymmetric uncertainty bounds. They apply this method and many baeslines to two datasets: MITV and SPE9PR.",
    "This paper describes a method to generate symmetric and asymmetric uncertainty estimates. The method is proposed to work for the non-stationarity processes found in real-world applications. The paper introduces a meta-modelling concept as an approach to achieve high-quality uncertainty quantification in deep neural networks for sequential regression tasks. The paper also introduces metrics for evaluating the proposed approach. A proposed meta-modelling approach is related to the work of Chen et al. (2019) which is mainly used for classification task in a non-sequential setting, however, the proposed method is mainly for the sequential setting. ",
    "The paper introduces a novel unbalanced Gromov-Wasserstein type problem. The Gromov-Wasserstein distance is very useful in practice for comparing probability distributions that do not lie in the same metric spaces. It has recently found several successful applications in ML for computational chemistry, graphs comparisons or NLP. Following previous works on unbalanced optimal transport (i.e. soft constraints over marginals enforcement of the coupling matrix), and the rationale that disposing of unbalanced versions of transport problems can alleviate in some ways presence of outliers or noise in the distributions, the authors propose two \u2018unbalanced\u2019 variants of the Gromov-Wasserstein (GW) problem, that allow comparison of metric spaces with arbitrary positive measures up to isometries (I.e. rigid transformations). ",
    "The authors consider the Gromov Wasserstein (GW) problem for metric measure spaces having different masses (i.e., Unbalanced GW). Similar to the ideas of unbalanced optimal transport (UOT), they proposed to use a quadratic divergence to relax the marginal constraints (instead of divergence as in UOT). When divergence is KL, the authors derive a GPU-friendly algorithm for the UGW  which relies on the unbalanced Sinkhorn algorithm. Additionally, the authors also propose a variant of UGW, namely Conic Gromov-Wasserstein (CGW) to address the different masses of metric measure spaces. The authors propose that CGW has nice properties (Theorem 1). However, there is no algorithm to solve the CGW yet.",
    "In the paper, the authors propose two versions of Gromov-Wasserstein distance when the weights of measures do not need to sum up to one. The first version, named Unbalanced Gromov-Wasserstein (UGW), is a direct application of unbalanced optimal transport (UOT) to the setting of Gromov-Wassertstein. The second version, named Conic Gromov-Wasserstein (CGW), is an extension of the conic formulation of UOT to the setting of Gromov-Wasserstein. The authors also show that CGW is a distance in the metric-measure spaces and is an lower bound of the UGW. Finally, the authors also provide some experiments with their proposed divergences.",
    "The submission deals with eliminating neurons in a network where either a) all the input connections xor b) all the output connections have been pruned. When this is the case, the unpruned a) output or b) input connections are unused and can also be pruned: and the freed parameter budget used for other more useful connections. This is shown to improve the accuracy of pruned networks at a given sparsity ratio, especially for very high levels of sparsity.",
    "The paper proposes to remove dead neurons and their connected parameters through a very simple check while reviving pruned (salient) parameters up to the prespecified sparsity level, such that the sparse network obtained could perform better. The main (and perhaps the single major) contribution of this work is in its demonstration that such a simple method is indeed effective for different pruning methods on various network architectures and datasets. The proposed method (AAP) can perhaps be considered as a generic post-processing step that could be equipped to any pruning method leaving dead neurons.",
    "This work proposes a novel pruning method, called all-alive pruning (AAP), which is a general technique to remove dead connections from pruned neural networks. AAP is broadly applicable to various saliency-based pruning methods and model architectures. AAP equipped with existing pruning methods consistently improves the accuracy of original methods on three benchmark datasets.",
    "In this paper, the authors propose an image attribute editing method by manipulating the GAN latent vector. Specifically, this paper uses a pre-trained GAN to synthesize images, a pre-trained regressor to get the image attributes, and trains a network T to find meaningful latent-space directions. It then edits image attributes by modifying the input latent vector, described as z' = z + T(z)\u03b5. The experimental results show that the proposed method performs better than other selected methods to some degree.",
    "This paper presents a new approach for the semantic image editing task by allowing the controllable transformation on the latent space. Authors proposed to integrate an attribute regression network for training the transformation functions. The local transformation T is learned from a simple MLP conditioned on the latent vector z. Two outputs of the regression module for the original latent vector z and the transformed one z+T*epsilon are used to minimize the cross-entropy loss. Experiments validate the effectiveness of the proposed method in terms of manipulation quality.",
    "The paper proposes a new simple, yet powerful and alternative method of editing the semantic attributes of images generated using pre-trained GAN models as well as a pre-trained regressors. The approach allows for the manipulation of single or multiple various image attributes, while preserving the identity of the original image in contrast to the baseline method of Shen et. al 2019. The method focuses on the manipulation of the latent space, in contrast to the popular image space editing methods. ",
    "The paper proposes an improvement to sequence generative adversarial networks (GAN) to cope with the common training issues of GANs. For the sake, the paper combines Gumbel-Softmax based GAN, relativistic discrimination  function with  the matching of mean representations of true and generated samples in a latent feature space. This feature statistics alignment allows to leak information from the discriminator to the generator as the used features are extracted from the discriminator network. Experimental evaluations on synthetic and real datasets show the improvement achieved by the proposed method over existing sequence generation networks.",
    "The paper addresses the task of improving GANs for sequence generation and proposed a method based on the relativistic discriminator. The proposed method employs a Feature Statistics Alignment (FSA) paradigm to reduce the gap between real and generated data distributions. It relies on the relativistic discriminator for \"coarse\" differences and FSA for \"fine-grained\" differences between real and generated data distributions. It is evaluated on synthetic and real datasets, and it significantly outperforms the baselines. It also outperforms baselines on human evaluation based on the acceptance, grammaticality, and meaningfulness of the generated sentences. ",
    "This paper proposes a new GAN-based text generation method that incorporates feature statistics alignment and gumbel-softmax for reparameterization to deal with mode collapse and unstable training. For feature statistics alignment, the authors design two methods such as mean square and mean distance alignments. They evaluate the proposed method on a synthetic dataset, MS COCO caption, and EMNLP2017 WMT news dataset, comparing them with RL-based and non RL-based models. With extensive experiments including ablation studies, the proposed method show promising results.",
    "This paper proposes an extension to DQN, more generally applicable to value-based deep RL systems, that encodes the return using a thermometer encoding with exponentially-sized bins. This enables returns of vastly differing magnitudes to be learned without hurting performance. The authors propose an algorithm for learning these encode returns, including the use of a variance scaling term to speed up learning.",
    "This work describes and addresses the issue of _reward progressivity_ in reinforcement learning, where as the task progresses the scale of the reward changes. The authors argue that reward progressivity harms Q-learning when training signals arising from large rewards interfere with those arising from smaller rewards. They propose a form of reward decomposition with an analogous modification to the Q-network output, which together help to ensure that training losses from small and large rewards are similarly scaled. The authors present a handful of experimental results demonstrating that their proposed method outperforms two other reward re-scaling baselines when reward progressivity is an issue and maintains good performance in more standard tasks.",
    "In this paper the authors propose a new RL method, spectral DQN, in which rewards are decomposed into different frequencies. This decomposition allow for the training loss to better balanced on certain tasks - in particular those with progressive rewards. The new method is shown to perform well on specially constructed tasks with extreme reward progressively, as well as on a selection of standard Atari tasks.",
    "Broadly, this work is an attempt to understand how neural networks can form generalizable representations while being severely overparameterized. This work proposes an information theoretic measure, called the \"usable information\", and use it to quantify the amount of relevant information in different layers of a neural network during training. The key idea is that, in order for the information represented in one layer to be \"usable\" by the next layer, it should be decodable by a simple transformation (affine + element-wise nonlinearity).",
    "The paper studies how initialization and the implicit regularization of SGD affect the training dynamics of neural networks in terms of minimality and sufficiency of learned representations. The main findings are that 1) SGD with random initialization learns almost minimal and sufficient representations and 2) SGD with an initialization that contains information about irrelevant factors fails to converge to minimal representations, increasing the chance of overfitting. These findings are interesting, useful for understanding neural networks, relevant to the ICLR community, but lack evidence of generality.",
    "The authors contribute to the recent research on whether neural network training (in particular, SGD) favors minimal representations, in which irrelevant information is not represented by deeper layers. They do so by implementing a simple neuroscience-inspired task, in which the network is asked to make a decision by combining color and target information. Importantly, the network's output is conditionally independent of the color information, given the direction decision, so the color information is in some sense irrelevant at the later stages. Using this, the authors quantify the 'relevant' and 'irrelevant' information in different layers of the neural network during training. Interestingly, the authors show that minimal representation are uncovered only if the network is started with random initial weights. Information is quantified using a simple decoder network.",
    "This paper studies the nonconvex strongly-concave min-max optimization problem. It improves the analysis of an existing method SREDA to make it allow larger step size and less initialization computation. Besides, it extends the algorithm to the case where the objective function is non-differentiable. The authors claimed it is the first zeroth-order variance-reduced method for the min-max problem. Experiments are conducted to demonstrate the improved algorithm is better than existing methods.",
    "The paper proposes a SREDA-Boost, which builds upon SREDA for nonconvex-strongly-concave minimax problem. The SREDA-Boost algorithm is less restrictive to initialization and has an accuracy-independent and larger step size. Thus it can run substantially faster than SREDA. The main contribution to the first-order optimization story is a new analytical framework that builds upon the previous analysis in SREDA and overcomes the dependence of highly accurate initialization via bounding the tracking error and gradient estimation error separately. It also proposes a zeroth-order variance reduction algorithm for the same optimization problem, which has the largest possible step size so far and also improves the complexity of the state-of-the-art in some cases. Various experiments have validated the superiority. The theoretical analysis and empirical results look good to me.",
    "The paper proposes a variant SREDA-Boost of the variance reduction method SEDRA for solving nonconvex-strongly-concave min-max problem. The first contribution of the paper is to relax the conditions on the initialization  of SEDRA and moreover enable larger stepsizes ($\\epsilon$-independent stepsizes). As SEDRA is already optimal, such modification does not improve the theoretical convergence rate, but it is beneficial from the practical perspective. The second contribution is to adapt the method to zero order oracle, achieving the state-of-the-art convergence rate. ",
    "This paper studies one-shot 2D object detections. The major conclusion is that when keeping the number of training images fixed, increasing the number of training categories can significantly increase the one-shot performance.  This paper demonstrated this conclusion empirically by doing controlled experiments on COCO, Objects365, and LIVS.   Inspired by this observation, this paper improves the state-of-the-art one-shot detection performance on COCO from 22.0 to 27.5 AP50 by training on LIVS.  Other two related conclusions in this paper: - PASCAL VOC is not suitable for evaluating one-shot object detection algorithms. The reason may be that the number of instances per image is low(2.9 ins/img on average). The algorithm only needs to recognize foreground objects rather than objects of target categories.  - Only when the training data is challenging enough, increasing the model size and training time can help improve one-shot performance.   ",
    "- The paper considers the problem of one-shot object detection, meaning, the model is asked to detect unseen categories, based on only one provided a template.  - The main discovery made by the authors is that, to generalise better, the model should be trained with data from as many categories as possible, given the same budget on number of samples for training.  - Architecture-wise, a Siamese Faster R-CNN is adapted. ",
    "This paper studies the effect of category number in the one-shot object detection task. In the testing of one-shot detection, there exists a performance gap between the base (training) classes and held-out classes. It is claimed that this performance gap can be largely closed by increasing the number of categories used for training. And the number of categories is more crucial than the number of samples per category. Experiments are conducted on VOC, COCO, Object365, and LVIS using a Siamese-style detector to verify the claims.",
    "This paper shows that the key to reduce the generalization gap between base classes and novel classes is to increase the number of training categories, instead of training samples. The authors did many experiments on four existing datasets (PASCAL, COCO, Objects365, and LVIS) with Siamese Faster R-CNN to verify this point. Experiments show that with more categories in the training set, the generalization gap will be nearly closed. Finally, the author proposes that future data sets should focus on the diversity of categories.",
    "This paper presents a method for 3D scene reconstruction from a single image using implicit surface representations such as occupancy or SDF. The authors propose to incorporate loss functions on the spatial gradients to provide dense supervision in the 3D space in the case where 3D labels may be incomplete (e.g. open 3D meshes) or not well-defined everywhere. Experiments are performed on ShapeNet and ScanNet show that the proposed method can achieve competitive performance on single-image scene reconstruction tasks.",
    "This paper describes novel loss functions for learning to predict an implicit 3D scene representation from a single image.  They argue that when working with real scan data of scenes (rather than single objects) it is difficult to generate accurate occupancy or signed distance function (SDF) ground truth as would be required for supervised learning.  Instead, they propose to only use occupancy or SDF supervision near the surfaces of objects; elsewhere, they rely on constraints on the gradient of the occupancy or SDF adapted from Gropp et al. 2020.  They perform a thorough evaluation on several benchmark datasets and compare against state-of-the-art competing methods.  They show that they outperform competing methods, even though in some cases their method has access to less supervisory data.    They also perform an ablation study to show the importance of various parts of the loss function.  ",
    "This paper presents a new method to learn implicit 3D scene reconstructions from single image input. The main improvement is a closed-form Differentiable Gradient Sampling.  By taking spatial gradient into  consideration, the proposed method can apply back-propagation of the  loss on spatial gradients to feature maps and allow the training for the case of without dense 3D supervision.   ",
    "In this paper, the authors propose a new method for single view 3D reconstruction.  A conditional (image feature prior) implicit representation framework is proposed to reconstruct 3D scene from a single view. In this paper, the authors propose that feature gradient is essential for watertight reconstruction and propose a differentiable gradient sampling method for the formulation. Experiments have been performed on both synthetic and real datasets. Superior results have been presented.",
    "This work studies the problem of efficient pretraining of large-scale models for language and vision representations, namely the issue of significant memory requirements for models with billions to trillions of parameters. Authors propose two modifications: first, to reduce the memory load and improve convergence at the initial stage of training, they suggest to train a multilayer model with shared parameters and then unshare them. Second, to maximize GPU utilization with offloading, authors develop a method for granular CPU offloading, which keeps larger chunks of the model in GPU memory. When combined, the proposed methods allow the authors to train a 10 trillion parameter model on 512 GPUs.",
    "The authors propose to train very large neural language models via a \"Sharing-Delinking\" paradigm. The proposed method first trains a model with weights shared across layers. In this way, the model appears to be smaller and it can fit into fewer GPUs. At some point, the authors delink the weights, and continue training the model in the conventional way.  The authors also propose a granular CPU offloading mechanism to save CPU memory.",
    "The paper proposes a technique called Pseudo-to-Real (P2R) for reducing the computational and time requirements of training massive (or Giant) models with trillions of parameters. The key idea of P2R is a two phase training approach for Giant models. The first phase involves training a smaller version of the model (a.k.a., Pseudo-Giant) which is obtained by making all layers share parameters. The second phase involves training the Giant model after initializing with Pseudo-Giant weights. The paper further proposes Granular CPU offloading which is to offload some but not all model parameters to CPU memory to reduce GPU memory consumption. Finally, the paper provides some evaluation results to demonstrate P2G.",
    "The paper proposed an interesting strategy to reduce the training time for large scale language models consisting of stacking layers with identical structures. Users first trained the models with shared parameters across the layers, then relax the tie constraints so that parameters at different layers are updated differently.  The paper showed some empirical evidence that the proposed strategy converged faster given a limited training time budget and demonstrated the feasibility of training a 10T model.",
    "This paper derives a Fenchel duality formulation of the maximum likelihood loss of F1-EBMs, which turns the optimization into a min-max problem on probability measures over the sample space. A dual algorithm with mean-field dynamics is proposed to solve this problem. Using the dual aogrithm they also draw a connection between maximum-likelihood training and score matching. Simple numerical experiments on two-layer ReLU network show that the algorithm converges much faster than the original MLE. ",
    "The authors formulated the Fenchel dual problems to maximum likelihood and score matching training applied to energy-based models defined by shallow neural networks. The authors then proposed practical algorithms based on the Hahn decomposition and compared this to various predecessor algorithms. An interesting part is that the learning dynamics can interpolate between maximum likelihood and score matching. There are also rich results in the Appendix. ",
    "Two approaches exist for learning a Gibbs measure: either by MLE (minimizing the KL divergence) or by score matching (maximizing the Hyvarinen score). With the same goal to minimizing the KL divergence, the author proposes an alternative training approach by augmenting an auxiliary $\\gamma$ measure and thereby optimizing a more tractable dual problem. The author claims that this new training method has a quicker convergence rate than the primary problem.  ",
    "This paper studies the training of Energy Based Models (EBM). The \u201cstandard\u201d technique is maximum likelihood maximization of the observed dataset. While theoretically sound, there are practical difficulties in simulating the MCMC dynamics due to large basins in the energy landscape. For this reason a class of alternative methods, like Score matching, have been explored in the literature. Score matching, however, is deemed to suffer in statistical power.  This work explores how, leveraging known results about Fenchel dualities, it is possible to connect the two training modalities (Maximum Likelihood and Score based) on a continuum, and proposes a practical algorithm based on such considerations. The authors consider for their theoretical analysis of the expressiveness of the models,  shallow neural networks in the lazy and kernel regime (spaces F_1 and F_2 respectively).  Section 2.1 introduces the two considered spaces, referring to the works of Chizat and Bach.   An energy based model is defined at the beginning of section 2.2 by means of the Radon Nikodym derivative. Training an EBM model via maximum likelihood corresponds to maximizing eq. (2), that, when considering networks in F_1, can be rewritten as the expression (3). At the end of Section 2.2. score matching is rigorously defined and the relationship between theoretical and empirical implementations (Hyvarinen) is clarified.  Section 3 is the core of the paper. If Assumption 1 holds (growth conditions), then Thm 1 states that eq. (3) is the Fenchel dual of (5). As (5) is a static functional, the authors propose to use results from Chizat and Santambrogio to rewrite it as the dynamical system (eq. (6))  together with the definitions in (7). Importantly, this formulation contains \\alpha, a free parameter >0, that determines relative time-scales over which functions \\gamma and \\nu are updated. System (6) is still \u201calgorithmically\u201d unsolvable. The authors then propose to use the two following approximations: first, the mean field technique known as propagation of chaos, is used to switch from (6)  to the system (8), where gamma is substituted by neural network  parameters and \\nu by and SDE. Then the continuous time system (8) is discretized using Euler-Maruyama. Algorithm 1 is the result of the process.  Section 4 explores how, in the infinite alpha regime, the dynamical system (6) is equivalent to score matching. By means of eq. (11) and proposition (3) the technical analysis is performed. Intuitively, parameters are updated infinitely faster than the samples.  Section 5 explores the implementation of Algorithm 1 on a synthetic dataset. The authors consider two cases (the two teacher neurons aligned to 164 and 78 degrees respectively). Comparison of the primal and dual (alpha<<1, alpha>>1) shows that the dual performs much better than the primal.  The conclusions stress the theoretical contribution based on Fenchel duality and propose as future work the exploration of convergence rates of (6) and (10) and numerical investigation of the restarting probability p_R. In addition, the authors suggest that \u201cporting\u201d the presented work to deeper network architectures (e.g. to work on realistic dataset, such as images) is straightforward from the practical point of view, and unpractical from the theoretical point of view. ",
    "This paper presents tight lower bounds on differentially private ERM, a well-studied topic in the DP literature. It obtains tight bounds for both the constrained and unconstrained settings. The exact quantitative improvements are stated precisely in the abstract, and I won't repeat them here. The improvements are not staggering, but they are tight, and are presumably the final word on this topic.   ",
    "The paper describes some lower bounds for differentially private empirical risk minimization (DP ERM). The main results are:  * An $\\Omega(\\sqrt{p \\log(1/\\delta)}/\\epsilon n)$ lower bound for unconstrtained ERM under approximate differential privacy. This improves on prior work of Bassily et al. in the presence of the $\\log(1/\\delta)$ term, and in the optimization being unconstrained.  * An $\\Omega(p/\\varepsilon n)$ lower bound for pure differential privacy.  The proofs use now standard techniques from the literature: fingerprinting codes for approximate DP and a packing argument for pure DP.",
    "## Summary of Contributions  This paper studies the unconstrained empirical risk minimization (ERM) under differential privacy (DP). In this setting, there is a loss function $\\ell: \\mathbb{R}^p \\times \\mathcal{X} \\to \\mathbb{R}$ and we are given $x_1, \\dots, x_n \\in \\mathcal{X}$; the goal is to output $\\theta$ that minimizes the empirical loss $L(\\theta; X) := \\frac{1}{n} \\sum_{i=1}^n \\ell(\\theta; x_i)$. The goal is to minimize the excess empirical loss $\\mathbb{E}[L(\\theta; X) - \\min_{\\theta^* \\in \\mathbb{R}^p} L(\\theta^*; X)]$. We want our algorithm to satisfies $(\\epsilon, \\delta)$-DP. Recall that the case $\\delta > 0$ is referred to as *approximate-DP* whereas the case $\\delta = 0$ is referred ti as *pure-DP*. Here we assume that $\\ell$ is 1-Lipchitz; the results easily extends to $C$-Lipchitz functions with an extra multiplicative factor of $C$ in the excess empirical loss.  The main contributions of the paper are: 1. In the approximate-DP setting, the authors show a lower bound of $\\Omega\\left(\\frac{\\sqrt{p \\log(1/\\delta)}}{\\epsilon n}\\right)$. This improves upon the best known bound of $\\Omega\\left(\\frac{\\sqrt{p}}{\\epsilon n \\log p}\\right)$ in the unconstrained case from [Asi et al., 2021] and $\\Omega\\left(\\frac{\\sqrt{p}}{\\epsilon n}\\right)$ in the constrained case [Bassily et al., FOCS 2014]. The new lower bound also matches the known upper bound in both cases [Bassily et al., FOCS 2014]. 2. In the pure-DP setting, the authors show a lower bound of $\\Omega\\left(\\frac{p}{\\epsilon n}\\right)$.  To prove 1., the authors reduce from the 1-way marginal problem (similar to previous work). Recall that in 1-way marginal, we are given $x_1, \\dots, x_n \\in \\\\{-1, 1\\\\}^p$ and the goal is to approximate $\\frac{1}{n} \\sum_{i=1}^n x_i$; a lower bound of $\\Omega(\\frac{\\sqrt{p \\log(1/\\delta)}}{\\epsilon n})$ is known for the problem [Bun et al., STOC 2014]. The authors use an $\\\\ell_1$-distance loss function, i.e., $\\\\ell(\\\\theta; x_i) = ||\\\\theta - x_i||\\_1$. Notice that here the optimal solution is $\\\\theta^*\\_j = sign(\\sum\\_{i} z\\_{i, j})$. This in spirit is very similar to 1-way marginal but not exactly the same. Specifically, if $\\sum_{i} z_{i, j}$ is roughly around zero, then taking $\\theta_j = -1$ or $\\theta_j = 1$ does *not* effect the loss too much. Therefore, a direct \"blackbox\" reduction from 1-way marginal does not seem to work. To overcome this, the authors observe that actually in the construction of [Bun et al., STOC 2014] most of the coordinates' means are not close to zero (formalized as \"biased mean\" property in the current paper) and thus the hard instance gives the desired lower bound for DP ERM.  To prove 2., the authors use a standard packing-style construction together with the $\\\\ell_2$-distance loss function",
    "This paper studies differentially private empirical risk minimisation (ERM) in the unconstrained setting. It gives tight lower bounds for approximate DP ERM for general loss functions, which also implies the same lower bound for the constrained case, which is an improvement over a classic lower bound by Bassily et al 2014. It also gives a lower bound for unconstrained pure DP ERM that recovers the result in the constrained case.",
    "This paper proposes a method to solve Wasserstein gradient flows based on the JKO scheme using variational formulations of functional objectives, such as the KL divergence or the generalized entropy (non-linear diffusion). Relying on known reformulations of the JKO scheme as optimization over convex functions, the paper departs from recent related methods in expressing certain objectives as f-divergences, and in turn using the dual formulation of these divergences to circumvent the need to do explicit density computation in these. The resulting method involves parametrizing two types of operators as neural networks (one of them as an input-convex neural network), and solving a mini-max objective. The paper presents experiments on simple PDEs (mostly in 1D or 2D) with known solutions. ",
    "This paper studies the implementation of some Wasserstein Gradient Flows (WGF) in discrete time but without discretizing the space. The methods proposed are based on the JKO operator to discretize WGF in time. The implementation of the JKO can be challenging. The strategy of the authors is to first reparametrize the JKO as a minimization over a space of functions (instead of measures) via pushforward. Then, when the objective function is a f-divergence, the objective inside the JKO admit a variational representation and can be expressed as a sup. Conclusion: each JKO is written as a min max over a space of functions. To solve it, they parametrize the functions by neural networks and alternatively maximize and minimize the problem using Adam. An important feature is that the objective in the min max can be approximated with samples of the current distribution (its density doesn't appear, only integrals wrt to the current distribution). ",
    "This paper proposes a variational formulation of each JKO step for optimizing functionals on measures. Different from existing recent works on emulating JKO steps by training pushforward neural networks (either directly or as gradients of convex functions), the variational formulation involves another inner maximization of a function, without needing density access that typically requires cubic time complexity due to computing the log determinants of the pushforwards. Experiments are done to demonstrate the practicality of the algorithm. ",
    "The paper proposes a method to compute Wasserstein Gradient Flows (WGFs) via neural networks and the JKO scheme. In contrast to prior works, to compute WGFs of functionals involving f-divergences, the authors use variational approximations rather than direct computations. It is claimed to work faster and perform better.",
    "The paper presents an approach, called MetaBu, for learning a meta-feature embedding from an existing meta-feature space into a latent space, which is aims at being rank preserving regarding different hyper-parameter configurations. The special kind of embedding and its property of aiming at being performance preserving in the context of AutoML is the main contribution of the paper, in my opinion. The quality of the learned meta-features is assessed through different experiments such as capturing to what degree the embedding is indeed performance preserving and how well AutoML tools perform when initialized with the corresponding meta-features. Moreover, the authors provide a sensitivity analysis of relevant hyper-parameters of MetaBu and demonstrate how to gain insights from the learned embeddings.",
    "In this paper, the authors address the AutoML problem, which aims to automatically select the best ML algorithm and its hyperparameter configuration for a dataset, and propose an approach to this problem that learns meta-features of the dataset. The proposed method, MetaBu, learns new meta-features by optimal transport according to the space of distributions of hyperparameter configurations. Meta-features in MetaBu is known only once and induce a topology in a set of data sets. Experiments on the OpenML CC-18 benchmark have shown that MetaBu meta-features can improve the performance of the state-of-the-art AutoML systems AutoSklearn and Probabilistic Matrix Factorization. Furthermore, the examination of MetaBu meta-features provides hints on when an ML algorithm will work. Finally, a topology based on MetaBu meta-features can estimate the intrinsic dimension of the OpenML benchmark for a given ML algorithm or pipeline. ",
    "This paper tackles the AutoML problem. It proposes to learn a linear combination of manually designed meta-features, which aligns meta-features with the space of hyper-parameter configurations via an Optimal Transport procedure. Experiments on OpenML benchmark demonstrate the power of the proposed method on boosting AutoML systems.",
    "This paper focuses on the AutoML problem for tabular data and proposes a meta-learning based novel solution. They consider the optimal transport to define distances between two datasets, utilizing the Wasserstein-Gromov distance between the distribution of the top performing hyperparameters for the respective datasets. Given this distance, they propose learning a linear transformation of existing dataset meta-features such that the Euclidean distance between a pair of datasets in this transformed space is proportional to their Wasserstein-Gromov distance. This method is termed Metabu.  The empirical evaluation compares Metabu to existing meta-learning schemes on (i) their ability to capture the desired Wasserstein-Gromov distance, (ii) their ability to find better hyperparameters via sampling without an underlying optimizer, and (iii) their ability to find better seed hyperparameters for hyperparameter optimizers. The results on the OpenML CC-18 suite with 3 machine learning models indicate that Metabu significantly improves upon existing meta-learning schemes. The paper also demonstrates how the learned linear transformation of existing dataset meta-features allow us understand the importance of different existing dataset meta-features and how these vary between machine learning models.  ",
    "This paper proposes a customisation strategy named \"Split-Max\" for federated learning. The authors identify the heterogeneity of devices and data in FL scenarios. They present the importance of considering devices' budgets and dynamics when dispatching training models. Split-max can adjust the model size according to the devices' budget while maintaining good accuracy and robustness.  Split-max works in steps. First, multiple base models from different initialisations are trained to improve diversity. These base models are randomly given to clients to extract generalisable features. Then, base models are aggregated to the server. Secondly, to provide devices with models with different robustness, it trains two similar models together to capture both the standard-training accuracy and adversarial-training accuracy. Then layer-wise mixing is conducted to achieve both standard accuracy and adversarial accuracy.   Experiments show that Split-Mix achieves better accuracy than naive approaches. Moreover, with customisation, the models are smaller and more robust under budget constraints.",
    "Split-Mix is a Federated Learning strategy aimed at easing the problems that arise when a heterogeneous pool of devices/clients (i.e. some with more compute/memory capabilities than others, different data distributions) collaboratively train a global model. Split-Mix trains a model that can later on be customized in terms of model size and robustness. As the name suggests, Split-Mix has two stages: During `split`, a large model is split into smaller base models. Base models are constructed by discarding channels but maintaining the the number and type of layers in the network. During `mix`, the server samples a fraction of the base models (depending on a given client's compute capabilities) and fuses them into a single one that is send to a client to train. All base models are trained on all clients (should these meet the compute requirements of a sub-model) in a federated manner. This means that the more capable devices, train all base models. This is envisioned to happen in a parallel fashion in a given device. Once FL training is completed, a customized model can be deployed to a device/client in hardware-aware and robustness-ware fashion. The Authors refer to this as _in-situ customization_ ",
    "This paper presents a new federated learning approach named Split-Mix FL that allows clients to train customized models efficiently while considering heterogeneity in data and computation resources. The key idea is threefold: 1) the global model is first split into several sub-networks called base models that each have different sizes, thus requiring a different amount of computational resources; 2) Each selected client trains a random subset of base models, under its computational resource constraints; 3) updated base models are aggregated at the server-side and distributed again. Furthermore, the proposed approach can train both accurate and robust models in a joint fashion, where all but batch-norm layers are shared for efficiency. Experimental results on multiple datasets (CIFAR10, Digits, DomainNet) demonstrate the effectiveness of the proposed approach compared to FedAvg and HeteroFL.",
    "The paper proposes a new federated learning scheme that is suitable for devices with heterogeneous resources. The proposal, namely Split-Mix, trains multiple models of different sizes and adversarial robustness levels, tailored to the budget of each device. Empirical results demonstrate the efficacy of the method against the main competitor.",
    "This paper constructs methods named CurvatureEG+ (and Adaptive EG+ and CEG+), built upon a recently proposed EG+ [Diakonikolas et al., 2021], a variant of EG, that works under the weak MVI condition. Most importantly, the CurvatureEG+ (and Adaptive EG+/CEG+) works for a range (of the weak MVI) larger than that of EG+. The corresponding nonconvex-nonconcave setting includes non-trivial problems illustrated in the paper, where the proposed method converges, while other existing methods reach limit cycles. Unlike EG+, the CurvatureEG+ can handle both constrained and composite cases. A stochastic variant is also studied. Although the experiments consider toyish problems, they seem interesting.",
    "This paper focuses on variants of ExtraGradient (EG) by considering different options for the two step-sizes of the method: one for the extrapolation step and the second for the iterate update.  Building on the analysis of (Diakonikolas et al. 2021),  the paper relaxes the setup therein by allowing a larger range of values for the $\\rho$ parameter (see Fig. 2) of weak Minty Variational Inequality (MVI) which parameter controls the degree of nonconvexity.  In particular, it provides the following contributions: *(i)* Primarily it defines Alg.1 where the step size for the iterate update is adaptive and shows the main convergence result (Thm  3.1.) that under some assumptions (Asm 1), Alg. 1 converges on weak MVI problem. *(ii)* It then considers a non-adaptive variant of Alg. 1, dubbed CEG+, which can be seen as a generalization of the EG+ method of (Diakonikolas et al. 2021), and complements the result of the latter by showing that the convergence result is tight on weak MVI; *(iii)* extends CEG+ by using an adaptive scheme for the first step size (for the extrapolation) which uses Lipschitz constant backtracking, and Alg.1 for the latter step size (for the iterate update), dubbed CurvatureEG+, which method is shown to empirically converge on some toy-examples on which CEG+ does not; *(iv)* finally, for the stochastic setup the authors consider one of the step-sizes to be diminishing and the other can be constant, and show that this variant converges on weak MVI problems. ",
    "This paper proposed CEG+ and CurvatureEG+, which extend extragradient method to a proximal variant (regarding the operator $A$), and apply it in nonconvex-nonconcave minimax optimization with Weak MVI condition in both deterministic and stochastic cases, and proved their complexities, which has the same order as those in literature (e.g., Diaonikolas et al., 2021). The authors also studied the lower bound in the simpler case when $A\\equiv 0$, showing a difference compared to EG+ in (Diaonikolas et al., 2021).  In the deterministic case, it proposed an adaptive stepsize strategy to allow larger range of the MVI parameter $\\rho$, and further a curvature-based strategy to avoid the lower bound requirement of $\\rho$. The authors also executes several experiments, showing that CurvatureEG+ can avoid cycling in the experiments.",
    "This work extends the extragradient algorithm in Diakonikolas et al. (2021) from unconstrainted and unregularized inclusion problems that satisfy weak Minty inequality (MVI) to their constrained and regularized counterparts. Compared with the original extragradient algorithm, the extended algorithm is proved to converge with a larger range of stepsize choices and MVI-related constant $\\rho$ (implying a larger set of applicable problems) in both deterministic and stochastic inclusion problems. The range of $\\rho$ is also proved tight by providing a lower bound of $\\rho$. The extended algorithm also generalizes the celebrated forward-backward-forward (FBF) algorithm in Tseng (2000). Finally, an improvement of this extended algorithm is proposed using Lipschitz constant backtracking. ",
    "The paper presents a new neural-bandit algorithm with shallow exploration and provides a regret bound for the proposed method. The existing approaches have introduced deep neural networks based bandit algorithms to learn reward functions, in which exploration takes place over the entire network parameter space, which can be inefficient for large-size networks which are typical in NTK based approaches. The authors address this by taking an existing approach that decouples the deep neural network feature representation learning from most of the exploration of the network parameters by only exploring over the final layer of the network.   Despite the fact that this idea of shallow exploration has been proposed previously, there has not been a theoretical analysis with a regret bound. The authors analyze a UCB version of this approach, then build from techniques from both deep neural contextual bandits and linear contextual bandits to prove an O(\\sqrt(T)) regret bound. Finally, the authors present experimental results to show that their algorithm work well in practice.",
    "This paper studies neural contextual bandits and proposes an algorithm that transforms the raw feature vector using the last hidden layer of a deep ReLU neural network, and uses an UCB approach to explore in the last linear layer. Compared with existing neural contextual bandit algorithms, the proposed algorithm attains computation efficiency. Regret guarantees and empirical results are provided to demonstrate the effectiveness of the proposed algorithms",
    "This paper study a novel contextual bandit algorithm: Neural-LinUCB. As in (Riquelme et al 2019), the idea of this algorithm is based on decoupling deep representation learning and exploration. A deep neural network learns the mapping between the context $x_{t,a_t}$, while a linear bandit, OFUL (Abbasi-Yadkori 2011), chooses the arm to play. In contrast to (Riquelme et al 2019), a regret upper bound of the algorithm a regret upper bound of the algorithm is stated in Corollary 4.6. The proposed algorithm is also an improvement over NeuralUCB (Zhou et al 2020) for two reasons: the computational cost of the exploration is lesser, since the exploration is only done in the last layer of weights, and the regret upper bound is tighter. Indeed, in contrast to (Zhou et al 2020) it does not depend on the dimension of the tangent kernel matrix, which can be in O(KT). Experiments, done on four contextual bandit problems, show that Neura-lLinUCB outperforms LinUCB and performs as well as NeuralUCB and NeuralTS. ",
    "Authors tackle the setting of contextual bandits, using deep representation learning combined with an upper confidence bound algorithm. The main contribution of this work is to provide a regret bound for the setup which decouples the representation learning from the UCB search, by searching only over the last layer of the network. The setting had been studied before, but only empirically, and using Thompson sampling rather than UCB. Authors validate their results empirically on several domains from the UCI data repo, as well as on MNIST, comparing against state of the art baselines. ",
    "The paper proposed a data-driven method for optimal action space selection in a reinforcement learning problem. Given a set of training state, action pair, the proposed approach first filters out the set of indispensable action set and then rank the other action set according to their cumulative reward values. To further improve the efficiency, a Monte Carlo sampling method is proposed for cut-off cardinality computation for action space. An action update rule is devised by computing optimal step size. Finally, a case study on a cloud environment is illustrated to select the optimal set of resources (#vCPUs and Memory size) to optimize the CPU utilization rate. The case study demonstrates that the Monte Carlo sampling based algorithm reduces action search space by 81% and then it creates a list of ranked action set. It is shown that a large action space does not necessarily lead to better performance for an RL agent. ",
    "The paper addresses the problem of action set selection, i.e. identifying which actions should be available to a RL agent, during training. The set of available actions can influence the RL agent's performance or even hinder it to reach its goal. A method to evaluate action sets is introduced and a case study is performed on a resource tuning example on cloud infrastructure.",
    "This paper focuses on Reinforcement Learning (RL). RL methods often entail a potentially large action space exploration to find a good policy. This work proposes a method to reduce such action space exploration. The method separates actions into two categories: dispensable (the action can be ignored) and indispensable (the action must be taken). Dispensable actions are also ranked according to their importance with respect to the final policy. The method is data driven and operates by looking at the global reward returns obtained when a certain action is removed from the action space. The method is evaluated on a case study simulating cloud infrastructure workload optimisation, i.e. the task of reducing high CPU utilisation by allocating more resources.",
    "This paper empirically considered the impact of training action space for reinforcement learning in a case study. Understanding the impact of training action space is a valid and important problem. An empirical study of this problem appears to be the main contribution of this paper.",
    "Let $X$ be an instance space, $Y$ a set of labels, $D$ some underlying (hidden) distribution over $X \\times Y$. This work studies a new method for converting the output of a probabilistic predictor (e.g. a deep net) to a good prediction set: that is a mapping from $C: X \\to 2^Y$, such that for most samples $(x,y) \\sim D$, $C(x)$ contains $y$. Formally, the authors study this problem in the PAC setting with covariate shift. The learner is given access to the score function, a labeled sample from the source distribution $P$ over $X \\times Y$, and unlabeled samples from a target distribution $Q$ over $X \\times Y$ whose marginal over $X$ may be shifted from the source. The goal is to output a prediction set which is as small as possible while still retaining PAC guarantees with respect to the shifted target distribution. This is a well-motivated model in practice. Probabilistic outputs of modern neural nets can be difficult to interpret, and small prediction sets may be useful in settings where one wishes to avoid or check more carefully a few marked outputs (e.g. a problematic medical diagnosis).  Assuming known, bounded importance weights, the authors provide an algorithm satisfying the PAC guarantee by maximizing a cutoff value for the score function that performs well over an empirical sample. They ensure their guarantee holds over the target rather than source distribution by rejection sampling to simulate the target distribution. The authors also extend this to settings where the importance weights are unknown but can be estimated from unlabeled samples. Finally, the authors provide experimental evidence over a couple common settings of covariate shift. They show that their algorithm outperforms baseline methods in the literature in the sense that it maintains PAC guarantees while outputting a smaller prediction set  in expectation. ",
    "This paper is concerned with learning prediction sets (in a PAC sense) under the covariate shift assumption, given a model $f(x,y)$. The form of the sets is restricted to $C_\\tau(x) := \\{y : f(x,y) \\ge \\tau\\},$ and the problem is set up as learning a $\\tau$, using a  labelled source dataset $S_m \\sim P^{\\otimes n}$ and an unlabelled target dataset $T_n \\sim Q^{\\otimes n}$ such that with high probability over $S_m, T_n,$ $Q(Y \\in C_\\tau(X)) \\ge 1-\\varepsilon,$ where $\\varepsilon$ is a given target coverage level. It is desired that $\\tau$ is as large as possible to minimise the size of the prediction sets learned.  The main scheme is presented modularly. The paper first describes how finding the maximum $\\tau$ whilst ensuring that the number of points in $S_m$ it captures is large enough (as specified by using a Binomial tail inverse) gives valid sets when $Q = P$. Next, it is argued that when $Q$ is absolutely continuous with respect to $P$, and the derivative $w(x) = \\frac{\\mathrm{d}Q}{\\mathrm{d}P}(x)$ is upper bounded and known, then one can importance sample the set $S_m$ to generate a sample from $Q$, which can then plug into the previous procedure. This step fundamentally uses the covariate shift assumption, and, to my understanding, is folklore. The following, then, constitute the main technical contributions.  Next, the assumption of exact knowledge of $w$ is relaxed, and it is argued that if instead for each $x_i \\in S_m,$ bounds $\\underline{w}_i \\le w(x_i) \\le \\overline{w}_i$ are available, then one can produce a worst-case estimate of the coverage of $C_\\tau$ for any $\\tau$ (by taking points that were missed to have high weights, and points covered to have low weights), and if this pessimistic coverage also satisfies the constraint. So, for each $\\tau$, the worst $w_\\tau$ can be produced, which can then feed into the importance sampling procedure above.  Then, it is pointed out that such a confidence bound on the $w_i$s can be learned using a probabilistic classifier $s(\\cdot|x)$ to separate data from $S_m$ and $T_n$, which leads to the main proposed algorithm. While it is roughly justified in the appendix that an accurate estimate can be obtained under smoothness assumptions with an appropriately fine gridding of the space (and a consequently huge sample complexity), the concrete proposal is to replace this step with a heuristic method for fitting bounds on the weights, and then plugging these into the above strategy. Note that this is not implemented as a direct optimisation over $\\tau$ - instead a set $\\mathcal{T}$ of possible values is pre-selected, and the procedure is executed for each $\\tau$ (the algorithm recommends an increasing order on the same).  Finally, the paper presents experiments in the DomainNet dataset, and in the ImageNet dataset, where the shift in the latter corresponds to adversarial perturbations. The principal baselines are the weighted split conformal inference (WSCI) method, which in my opinion is an appropriate choice, and the \"PS-C\" method, which simply uses a prediction set that has $1-\\varepsilon/b$ coverage on the source data, where $b$ is an estimated upper bound on $w$. The proposed method is ablatively presented, and it is seen that on just the DomainNet data, the method PS-R (which simply takes $(1-s)/s$ as an estimate of $w$) is both reliable and performs well, while the PS-M method, which further integrates samples in bins tends to be slightly optimistic on this dataset. Conversely, in the adversarially perturbed dataset, PS-R produces trivial prediction sets (since presumably this shift goes entirely outside the source domain's support), while PS-M performs well. The proposed method, PS-W, which further uses upper and lower bounds on $w$s after integrating them over bins, tends to be pessimistic (error-rates of $0.06-0.07$ are observed when only $0.1$ is demanded), but is not too much worse than either of these methods, and is effective in both types of shifts.",
    "The paper presents algorithms for PAC prediction sets under the assumption of covariate shift. Using estimated/known importance weights that encode the shift, the method optimizes for the smallest subset of labels such that with high probability the error of this prediction set is low. A rejection sampling based strategy is then shown to satisfy the PAC constraints. The methodology is extended to the case where the importance weights are uncertain (due to estimation error). It is shown that the robust variant can be solved using the extreme case weights and the rejection sampling based algorithm. Simulations show the efficacy of the method.",
    "This paper proposes a new method to construct approximately correct (PAC) prediction sets for uncertainty quantification in the presence of covariate shift. It is a natural and interesting extension of the previous works [Park et al. 2020a, 2021] on PAC prediction sets. The building blocks this paper took from these previous works are the optimization problem in Equation (1) and the Clopper-Pearson confidence intervals for the Binomial distribution in Section 2.2. The extension is based on a rejection sampling Clopper-Pearson bound given in Section 3.2.  The authors propose an algorithm with and without access to the true important weights. The algorithm is evaluated in the settings of \u201crate shift\u201d and \u201csupport shift\u201d on the DomainNet and ImageNet datasets. The experiments show that the algorithm gives the smallest prediction sets among approaches that always satisfy the PAC constraint. ",
    "The paper considers a popular approach to semi-supervised learning based on iterative pseudo-labeling the unlabelled data and refining the model parameters thereafter. The paper is supported theoretically for the case of the Gaussian mixture model establishing a generalization error bound based on the KL divergence between the pseudo-labeled and true data distributions. The paper is also supported empirically for binary classification examples coming from CIFAR10 and MNIST datasets ",
    "This paper considers one common semi-supervised learning algorithm, pseudo labeling, and studies this problem from theoretical point of view. Specifically, it derives an information theoretic upper bound on generalization error in each iterative update of pseudo labeling. They separate the bound into two main parts: one depends on the mutual information between the data samples and model parameters, and the other depends on the KL distance between the underlying data distribution and pseudo labeled samples from previous iteration. Their main conclusion is that as the number of labeled and unlabeled samples grows, the first term vanishes, but the second term does not necessarily vanish.   In the rest of the paper, the authors rely on the simple example of binary Gaussian Mixture Model to give a more understandable and sensible calculation of the their upper bound. Namely, they calculate the KL distance and mutual information terms in the main theorem and study the behavior of generalization error for this model. The conclusion they made is that the iterative pseudo labeling can decrease the generalization error for only the first few iterations and after than has no effect on reducing the generalization error. ",
    "The paper considers the problem of semi-supervised learning where pseudo-labeling is used to iteratively assign labels for unlabelled data batches to enlarge the labelled dataset for subsequent re-training of the classification model. The paper first adapts the recent results of Bu et al (2020) and Wu et al (2020) to this set-up and provides a general information-theoretic upper bound for the generalization error of such a learning algorithm. The paper then specializes its set-up to a binary classification problem with Gaussian class conditionals and presents its corresponding generalization bound. Additional experiments are performed on the more practical datasets with deep neural network classifiers. ",
    "This paper provides a generalization error bound for iterative semi-supervised learning (SSL) algorithms using information-theoretic principles (see Theorem 1). To provide more intuitions, the authors first work with a simple model, i.e., the binary Gaussian mixture model (bGMM). It is shown in bGMM that when the class conditional variances are not too large, the upper bound on the generalization error decreases monotonically with the number of iterations, but quickly saturates. The theoretical results on the simple model are corroborated by experiments on MNIST and CIFAR datasets, where similar phenomena are observed, i.e., the generalization error improves after several pseudo-labelling iterations, but saturates afterwards.",
    "This paper proposes a method for exploration called Generative Planning method (GPM), which generates a multi-step action sequence such that the exploration is more temporally consistent and \"intentional\" compared to regular single-step action noise exploration. The multi-step action sequence is output by a generator with an RNN structure, and the generator is optimized by maximizing the plan value function. The authors show that their method GPM performs better than some other methods in several continuous control tasks and present some interesting qualitative results (e.g. state trajectory) showing that the exploration is more effective.",
    "This paper presents a method called generative planning method (GPM) to improve exploration in RL. GPM performs exploration by learning a planner (a map from state to a sequence of action, aka a \u201cplan\u201d)) and performing MPC with a special rule for whether or not to use the latest plan or keep the old plan. The planner is an auto-regressive model (specifically, a stochastic RNN) and is trained to maximize an auto-regressive Q-function. Each time step, the plan from the previous time step is shifted forward by one time step and compared to the newly generated plan. The plans are compared using their predicted Q-values, and the policy switches plans with some probability that increases monotonically with Q(new plan) - Q(old plan). The exact likelihood is determined by a hyperparameter, l_commit_target, that, intuitively, sets a soft target for how long a plan is typically kept. The authors compare GPM to a variety of action-repeat-based exploration methods, from epsilon greedy policies to policies with learned action repeat counts (DAR & TAAC) and find that it is competitive with or outperforms these methods on various low-dimensional robot domains, as well as the image-based CARLA environment. The authors also visualize the trajectories and qualitatively show that GPM improves exploration.",
    "A generative planning method is proposed, which sits somewhere between model-free and model-based methods. No explicit model is learned. However, an action plan is generated using a recurrent action-plan generator, paired with a similarly recurrent critic.  At each environment step, a new action plan is generated, and  the current action plan can be abandoned in favor of the new action plan if the estimated benefit is large enough. The method builds on SAC.  Overall the benefits of the temporally extended action plans are: (a) temporally-coordinated exploration; (b) more effective than action-repeat; (c) some degree of interpretability given that an action-sequence plan represents then intent of a policy in a given state.",
    "This paper proposes a method called Generative Planning (GPM), which aims to improve exploration for model-free RL. GPM learns a recurrent model to generate short term plans at each time step, and only decides to switch to the new plan if it is a lot better than the old plan. This encourages temporally extended explorations, and also does it in an adaptive manner. Experiments on a set of continuous control benchmarks show that GPM is able to converge faster than prior approaches, explore more effectively, and generate interpretable short-term plans. ",
    "This paper summarizes the theoretical guarantee for the existing LRMC and LRTC algorithms, and provides the theoretical analysis for a new proposed Multi-Mode Nonlinear deep tensor factorization. The analytical results show that when n2 is larger than n1, the nonlinear DMF provides a tighter generalization bound than MF. Similar analysis has been extended to two-mode matrix factorization and multi-mode  tensor factorization. Experimental results in synthetic data and real data show better results of the proposed algorithm as compared to other algorithms in completion tasks. ",
    "To bridge the gap between deep learning and tensor decomposition, this paper presents two novel approaches named as two mode non-linear deep matrix factorization and multi-mode nonlinear deep tensor factorization (extension of two mode model to multi-mode scenario). The main contribution of the methods lie in full exploration of non-linearity of data in matrix and tensor factorization. To better motivate the proposed models, the authors provide theoretical analysis for why and when nonlinear deep matrix factorization outperforms linear deep matrix factorization in matrix completion. The experimental evaluation demonstrates that in some datasets, the proposed models outperform the existing models on matrix and tensor completion tasks.",
    "This paper studies the nonlinear low-rank completion of matrices and tensors. Specifically, it first presents the theoretical results showing why nonlinear deep matrix factorization is better than the ordinary matrix factorization model. Then, it proposes a model named two-mode nonlinear deep matrix factorization to make full use of the nonlinearity of the nearly square matrices. The authors also extend this method to tensor factorization by further factorizing the factor matrices in the Tucker decomposition using the deep factorization method. Impressive results are obtained using both synthetic and real-world datasets.",
    "The paper provides a multi-mode framework for the deep learning based tensor decomposition, which could be useful for dealing with nonlinear high-dimensional data sets. In particular, it extends the deep matrix factorization (DMF) method and proposes a multi-mode deep matrix factorization method for matrix completion with convergence guarantee. Based on this, it also develops a multi-mode nonlinear deep tensor factorization method with convergence guarantee. The proposed models are solved by various optimization algorithms. Numerical experiments on synthetic and real data sets of the matrix/tensor form have shown that the proposed methods outperform other state of the arts. ",
    "The paper works on a novel problem of interpreting and explaining structured output models. The paper utilizes an energy based model to account for correlations between structured outputs and learns an interpretability block which given as input an image learns to mask it such that the energy based model would assign a similar score to the ground truth output and input as well as the ground truth output and perturbed input. In essence, the energy based model is a proxy for the actual deep neural network performing the structured prediction task. Results on a couple of datasets demonstrate that the work does better than baselines like LIME which do not utilize the correlations in the outputs modeled by the energy based model.  ",
    "The paper proposes a technique for identifying what input variables are most relevant for determining the value of a single, given output variable in structured-output (MAP) inference.  The idea is to learn an energy model that predicts which input variables are relevant to a particular structured prediction (x, y).  The authors propose to implement the energy model using a neural network followed by a Gumbel-softmax activation, and to train it by maximizing a structured hinge loss.  The proposed approach is evaluated on three datasets and compared to standard attribution techniques (LIME, SHAP, L2X).",
    "The authors propose an energy-based training method for achieving model interpretability, which performs instance-wise feature selection. The proposed model adopts a similar approach of one of the pre-existing interpretable methods by calculating feature-level importance score with regard to each instance. The authors validate their method on synthetic and public datasets.",
    "This paper propose a method for interpreting structured output model. The key idea is to find an \"interpretation\" which explains an \"target\" output random variable based on subset of rest of the output variables. The training objective is on finding a small subset which keeps the target output random variable invariant. The proposed methodology is applied to explain a synthetic energy function and structured prediction energy networks. ",
    "This paper considers a generalization of the policy gradient method to optimize for arbitrary utility functions with weightings that depend on the entire CDF (rather than the expected reward). This generalization has two aspects: (1) a utility function on top of the trajectory reward and (2) a weighting function for the CDF of the trajectory reward with respect to which the expectation is performed.  The paper derives an expression for the policy gradient and also generalizes the standard variance reduction baselines. Inspired by the PPO loss, the authors then propose a clipped version of the policy gradient calling it C3PO and evaluate this on some benchmarks from the OpenAI Safety Gym, where it is found that the conservative weightings can offer improvements over the standard formulation.",
    "Risk objectives have long been investigated in reinforcement learning (RL). Most of the focus has been on classic risk measures, like exponential utility, value-at-risk (VaR), conditional value-at-risk (CVaR), leaving out, however, the cumulative prospect theory (CPT) developed by Tversky and Nobel Prize Kahneman in 1992, which has not yet been considered.  The advantage of CPT is to better model human decision-making, still allowing a wide class of risk measures, based on the utility $u$ and weighting $\\omega$.  Hence, the authors consider a new risk-aware objective. Following some derivation, they compute a sample-based estimation of the gradient of this new objective w.r.t. the policy parameters.  The authors propose a PPO-like algorithm (called C3PO), which incorporates the new, risk-aware, gradient estimator.  They perform an empirical analysis on some tasks of \"Safety Gym\", showing that proper risk-awareness helps increase the performance of classic PPO.",
    "The paper presents an alternate approach for distributional DRL via proposing an objective inspired from Cumulative Prospect Theory (CPT, Tversky and Kahneman, 1992). They use this distributional objective in conjunction with policy gradient methodology to propose a distribution policy gradient method for risk-sensitive RL. Under their approach, the distribution of the returns is optimized to maximize some chosen function of its CDF. They experiment with different such possible distributional objectives (risk profiles) on the OpenAI Safety Gym environments and show that their approach performs better than PPO. ",
    "The article propose a policy gradient method for optimizing a CDF based criterion, inspired by CPT.  By varying the weighting function inside the objective, it is possible to change the risk-aversion of the agent. The authors derives the policy gradient for the aforementioned objective and propose an estimation technique for it. Then, they propose an algorithm which extends PPO for optimizing their objective. Empirical analysis is carried on to evaluate the approach on some modified Safety Gym environments, in which a fixed negative rewards corresponded to adverse events. The authors evaluate different objectives obtained by employing a Wang weighting function, with different values of the parameter $\\eta$. They show that optimizing a cautious (or risk-averse) objective allow to obtain better results in terms of average reward w.r.t. optimizing an aggressive (or risk-seeking) one. By further exploring the parameter space, the author demonstrate that some risk-averse values of the parameters allow to outperform also the risk-neutral version of PPO w.r.t. the average reward objective.",
    "This paper tackles learning a flexible distribution approximator to approximate the output of a high-dimensional and computationally intensive stochastic simulator.  The contributions of this paper then reduce into three main components:   1 - Definition of a spatiotemporal neural process that can succinctly model a more richly structured latent process.  2 - Definition of a new acquisition function and using a neural process in an active learning setting.  3 - Application to epidemiological simulators to \u201ccompile\u201d estimation.  The method appears to work, validated on a toy-ish SEIR model, and a more sophisticated pre-existing epidemiological model.   ",
    "This study proposes a new method for learning surrogate models of stochastic simulators. The new method, Interactive Neural Process (INP), builds on Neural processes and leverages the spatiotemporal structure of the problems at hand to reduce the complexity of the inference task. On a few problems in epidemiology -- a low dimensional SEIR problem (2 parameters, 100-dimensional output), and a complex spatiotemporal LEAM-US problem --, the approach is shown to appropriately learn the surrogate in few iterations.",
    "The authors proposed a novel active learning framework integrated with the neural process. The neural process is used to mimic the simulator dynamics which is later used for Bayesian active learning. They also proposed a new acquisition function utilizing the latent from the neural process. The experimental results show that INP works better to accelerate stochastic simulation than GP, and the proposed LIG leads to faster convergence compared with alternatives.  ",
    "The manuscript entitled, \"Accelerating Stochastic Simulation with Interactive Neural Processes\", presents a novel approach to the problem of statistical emulation for mechanistic models of epidemic disease transmission.  To this end, structured neural processes are developed to exploit and respect the temporal and spatio-temporal character of these models.  An active learning strategy is developed to train these neural processes to minimise the computational costs of generating training instances of disease simulator outputs.  The methodology developed is applied to two SEIR compartmental model examples: a minimal one with a single homogenous population and a maximal one with many age and space delimited cohorts.",
    "In this paper, the authors propose a method that applies DP-SGD to NLP tasks. DP-SGD protects the privacy of the model training against that the individual information about the training samples is detected or inferred. The method is applied to the fine-tuning phase of the pre-trained language models (e.g. bert, gpt), thus it achieves good performances for many applications. To adapt DP-SGD to NLP models, this paper proposes ghost clipping that allows clipping in DP-SGD to run without instantiating per-example gradients for any layer in the model.",
    "This paper adapts the widely used DP learning algorithm, DP-SGD, to language models. It achieves to fine-tune the dataset while protecting the private information in the dataset. In this paper, the authors conduct some empirical studies on language models and find some useful conclusions (e.g. fine-tuning on a part of parameters with DP is enough). The authors verify the model on sentence classification, table-to-text generation, and dialog generation tasks, using various pre-trained language models (e.g. GPT, Bert).",
    "The paper propose a faster algorithm to learn approximate differentially private NLP models. Pretrained NLP models are often very large. Practical procedure involves fine-tuning NLP model on private data, which may leak private information. To avoid leakage, DP-SGD (and DP-AGAGRAD, DP-ADAM) uses norm clipping on each sample\u2019s gradient, and then add isotropic noise to aggregated gradients for samples in a batch. Then the normal update steps of SGD, ADAGRAD, or ADAM are performed. This will ensure privacy under differential privacy definition. However, this procedure requires computing per-sample gradient and keep them in the memory so that the norm of the gradient can be calculated, and the per-sample gradient clipping can be performed. This will introduce memory overhead proportional to the batch_size$\\times$#params, which is impossible for very large NLP models.   This paper propose GhostClipping method to save the memory, without the need of per-sample gradient instantiated. The idea is compute the partial sum of gradient element-wise square using two small matrices of the size of $T\\times T$, where $T$ is sequence length (<=1024 in practice), and aggregate them to obtain the per-sample norm (just a scale for each). And then it performs a second back-propagation to compute aggregation on the clipped gradient. It will uses almost the same memory as standard SGD (or ADAM), with one forward pass and two backward passes.   This paper also introduce two additional techniques to improve, one is choose a larger batch size, and the other is to introduce multi-task finetuning (fine-tuning includes masked prediction task on the target dataset). These two are important in boost the performance of the final models.   The paper evaluates on text classification, data-to-text generation, and dialog generation tasks. The results shows it gains prior DP methods.     ",
    "This paper investigated the problem of privately fine-tuning large language models for downstream NLP tasks, including sentence classification and language generation. The authors showed that by appropriately selecting hyper-parameters (including batch size, learning rate, training epochs, and clipping norm) and making the fine-tuning task aligned with pretraining tasks, directly fine-tuning large language models with DP-SGD yields strong performance, and provided an empirical guideline for setting a good training configuration. The authors also proposed ghost clipping trick for further memory saving when fine-tuning large language models. Finally the authors showed through experiments that low dimensional updates do not necessarily lead to better performance.",
    "This paper proposes a transform-and-control policy to optimize the robotic agents' designs. Contributions include: - A novel perspective on agent design: rather than formulating agent design as a bi-level optimization, this paper embeds both design generation and control into a single decision-making process such that both design and control are optimized by the same RL algorithm. - In this formulation, the training experience from different designs is shared to improve sample efficiency. - Joint-specialized MLP on top of the GNN policy that further finetunes the control of individual joints.",
    "The paper poses the problem of morphology design for robots as RL training of one joint GNN policy. Their policy first generates the robot's morphology and then evaluates the design with a common behavior policy that conditions on it. The authors also introduce a technique called JSMPL to allow asymmetric morphologies. Experiments in the Mujoco simulator demonstrate a large improvement over evolutionary methods in terms of sample efficiency and final performance (although the latter is less clear, as neither method has clearly converged). Ablation studies show that the GNN architecture is essential, but are less clear about the impact of JSMPL. ",
    "The paper proposes an algorithm for simultaneous agent design and policy optimization. The choice of the body structure is treated as another action available to the agent. Therefore, the policy is parameterized by graph neural networks (GNNs), and it outputs i) the skeleton structure, ii) node attributes such as bone length, size, motor strength, and iii) motor control commands. Thanks to the parameterization via GNNs, the policy can be trained with PPO. Experiments show that the proposed method outperforms prior approaches, which mainly employ evolutionary methods for optimization, whereas the proposed method leverages more sample efficient policy gradient algorithms.",
    "The paper introduced a reinforcement learning algorithm that simultaneously optimizes the design as well as the controller of a simulated robot to perform locomotion tasks. The core idea is to train a conditioned policy that performs the task in three stages: 1) morphology design of the robot, 2) design parameter adjustment, and 3) controlling of the robot to perform the task. By integrating the design process into the policy learning framework, they are able to design novel and effective agents to complete a variety of tasks. To support the proposed algorithm, graph neural networks is heavily used to support different morphologies. They further propose a joint-specific architecture to improve flexibility of the network, which improves the performance of the algorithm.",
    "The paper proposes a novel coordinate-based network architecture which proposes to process each of the input coordinates independently in the first layer instead of together in a fully connected layer. This input style results in a speed-up in terms of evaluation of the network, and thus faster training and inference in tasks where coordinate-based MLPs are used, without incurring a significant degradation in terms of the quality of the signal fit. These benefits are demonstrated for the tasks of image representation, video representation, and 3D shape representation.",
    "This paper proposes a new architecture for implicit neural representations, called CoordX, which splits each dimension of the input signal into separate branches (e.g. the x and y coordinates of pixel locations in an image) and processes each of these separately before fusing them. The authors achieve this by projecting each of these branches into a hidden feature and then using shared fully connected layers to process these. Each branch is then fused by an outer product which then reconstructs the entire input grid (e.g. for an image of size H x W, 2 branches take in H locations and W locations respectively which are then combined into H x W features by the fusion operation). The fused layers are processed by a few more MLP layers to output the predicted features. In addition, the authors propose a method for effectively subsampling the grid during training as well as different splitting strategies for the branches.  The authors perform experiments on various data modalities, including images, videos, 3D shapes and NerF scenes.  The main contributions of the paper in my eyes are then: - Introducing a new architecture for implicit neural representations that in certain cases can improve training/inference speed without incurring a decrease in reconstruction - Experiments on various data modalities showing the strengths/weaknesses of the method ",
    "Summary: This paper proposes a modification to INR models on multidimensional coordinate grids where a subset of the earlier layers operate on the decomposed coordinate grid. In this setup, the grid (which is assumed to be regularly sampled to permit this decomposition) is broken into its constituent components, (e.g. x and y instead of (x,y)), passed through a single linear layer unique to that component, then through a stack of shared layers, followed by an outer product to return to the joint (x,y) space, and at least one layer that operates on the joint space. This approach lightly reduces parametric efficiency but strongly improves compute efficiency (both in terms of FLOPS, memory usage, and actual observed runtime) for common implicit neural representation tasks, including fitting images, videos, shapes, and volumetric rendering via radiance fields. ",
    "The paper proposes an interesting tweak to the network architecture to accelerate CoortMLP. The idea is to split the input coordinates along the dimensions and then share weights before fusion.  The authors analyze the theoretical upper bound (as far as the MAC ops are concerned) and show about 2X speedup on actual machines.",
    "This paper proposes a novel unsupervised scene decomposition model that infers object shapes, appearances and 3D poses. The benefits over existing models are the structured, 3D object representations which allows to manipulate objects in the scenes such as moving and replacing objects. This paper also shows that the inferred object representations can be used in a visual reasoning task.",
    "The paper aims to decompose a scene into objects and infer the representations of 3D occupancy, color, and pose for each object from a single image of the scene without supervision. To this end, the paper proposes an autoencoding solution by combining the Slot Attention encoder with the GIRAFFE decoder. Each object is represented as a Neural Radiance Field (NeRF) additionally parameterized by the latent variables inferred from the encoder. The decoder then compositionally renders the objects. The experiments show that the proposed model (1) achieves competitive 2D segmentation performance on CLEVR6, (2) supports object-wise scene manipulation, and (3) outperforms non-object-centric methods on CATER snitch localization when combined with a powerful transformer.",
    "This paper proposes a model which is able to segment 3D scenes into objects by a combination of slot-attention (For inference) and a mixture of object NeRF functions which mix together (in 3D) to compose a scene. The method receives a single input image (with the camera coordinates though these are fixed) and extracts a set of slots - one slot for each object. These slots are decoded using a NeRF renderer: one part (the shape) generates the density, one (the appearance) generates the colours and one (the pose) transforms the points of the object to the appropriate pose in scene space. Results are demonstrated on CLEVR data as well as CATER (which is visually very similar) and some downstream tasks.",
    "This paper proposes a model to infer structured 3D object representations from a 2D scene in an unsupervised fashion so as to represent the visual scene in an object-centric way. Specifically, the inference part adopts a similar mechanism as Slot Attention to derive object slot latent code, and then maps slot latent code to 3D object representations with MLP. The rendering part takes the idea from 3D neural rendering where a shared NeRF function is used to represent all objects excluding the background. Rendering is performed by querying NeRF with 3D location, 2D view direction as well as object latent to get object color value and occupancy value. Object rendering is composed into scene rendering according to location derived at the inference stage and weighted by occupancy value.  To sum up, the paper interprets a 2D visual scene with 3D object-centric representation. With the existing 2D object-centric scene segmentation method and 3D neural rendering approach, it achieves comparable segmentation performance and derives manipulable object representation.",
    "The paper sheds an exciting light on the problem of producing a meaningful evaluation of GNN explanation methods (at least a subset of them). The idea is to introduce a deconfounder D to capture the effect of OOD explanations. The authors make an interesting example for a well-known synthetic dataset where the weight of the explanation in the ground truth is lower than a clear non-valid explanation when evaluated using the model to explain. The introduction of the deconfounder D creates a spurious path between the graph variable and the explainer variable. To mitigate this effect, then, they introduce a front-door adjustment to the causal graph. The front door adjustment requires a graph generator and authors use a novel Conditional-VGAE to generate graphs that will also cover the OOD case. The paper finally presents some experiments showing the evaluation method in action.",
    "In this paper, the authors use a causal view to investigate the OOD effect on the explanation evaluation of GNNs. They find the confounder between the extracted subgraphs and the model prediction, which makes the evaluation less reliable. To solve this problem, the authors proposed a deconfounding evaluation method based on the front-door adjustment from causal discovery. To generate a reliable surrogate subgraph, they proposed a generative model, which contains three losses for training. The experimental results show the effectiveness of the proposed method (DSE).",
    "This paper has done an excellent work of finding the out-of-distribution between the subgraph and graph as the confounder. Further, this paper proposes a conditional variational graph auto-encoder in assessing the causal effects of subgraph on the prediction. They also introduce a surrogate variable to denote this out-of-distribution effect. Through adversarial training, the effects of the proposed model is correctly verified.  ",
    "This paper presents a novel explainer-agnostic method to adjust the biases of feature importance scores of feature attribution for GNNs. The paper first describes the feature importance scores of the GNN feature attribution framework have biases due to the out-of-distribution (OOD) problem. The subgraph important scores are calculated by inputting a subgraph instead of data graphs, but subgraph patterns can fall into regions outside the distribution of training data graphs. To address this problem, the paper proposed a method to generate surrogate graphs within the data graph distribution by CVGAE to make a front-door adjustment for deconfounding these biases by distribution shift. Experiments using several state-of-the-art GNN explainers shows demonstrated the effectiveness of the proposed framework. ",
    "This paper investigates if using large, pretrained models in an active learning setup helps achieve better performance with lesser data when compared to using randomly sampled data. In order to conduct this investigation the authors study the empirical performance of large pre-trained models on some image datasets and a text dataset. In both cases large pre-trained model is finetuned on a small amount of seed data and then an active learning procedure is used (in this paper the AL procedure is an uncertainty sampling procedure) to collect more data. The datasets are chosen to illustrate several conceptual issues (i) distinguishing causal from spurious correlations (ii) measuring robustness to distribution shifts (iii) role of data imbalance.   Experiments are performed to show that using an active learning procedure indeed helps improve performance using only a small amount of actively labeled training dataset.  The paper is well written and the results are convincing and insightful. ",
    "The authors describe interesting empirical observations regarding using uncertainty sampling to select examples to fine-tune models that use pretrained embeddings and provide some hypotheses regarding the reasons for these performance improvements. Specifically, (1) from a methodological perspective, they propose using uncertainty sampling (i.e., least confident selection) to select examples for fine-tuning image/NLP pretrained models and (2) from an empirical perspective, they use Waterbirds/Treeperson/iWildCam2020-WILDS for image classification and Amazon-WILDS for review star prediction based on text and compare with random sampling \u2014 noting that these are settings where there is known covariate shift between train/test with semantic meaning to induce interpretable spurious associations (e.g., background in images). The proposed method works overall, especially on the image datasets, and they also dig into the types of examples selected \u2014 noting that they align with expected \u2018difficult\u2019 examples (depending on the setting).",
    "The authors set out to investigate if active learning is an emergent property of pre-training. That is if running active learning with pre-trained models gives better result than using the same models without pre-training. They run several experiments on different text and image datasets first showing that active learning performs better than random sampling on pre-trained models and secondly that pre-trained models perform better than un-pretrained ones for active learning.",
    "This paper investigates the active learning performance of pre-trained models vs their non-pre-trained counterparts on both vision and NLP tasks. Specifically, the investigation focuses on datasets with spurious correlation, domain shift, and label imbalance. Empirical results generally show that the pre-trained models with the uncertainty acquisition function performs much better than the random baseline and their un-pre-trained counterparts. ",
    "Automated program repair benefits from knowledge of its many properties, which includes its inherent (parse-)tree structure and graphical properties such as data-flow. This work proposes a graph-based encoder coupled with a tree-edit decoder, and optionally pretrained on a tree-based objective comparable to masked language modeling. The resulting model efficiently leverages relatively few parameters to achieve near-SOTA performance on a benchmark compiled from real-world bug fixes.",
    "This paper presents a model over sequential structural tree edits, used for program repair based on ASTs. The model itself uses a graph encode and decoder to predict the sequential tree edits. The authors also introduce a method for pretraining the model on existing (non program repair) code data: they delete subtrees of arbitrary size from the code, and predict their reconstruction. The resulting model performs comparably to several other state of the art code repair models on the Patches in the Wild Java repair dataset, but with fewer parameters than several of the best-performing pre-trained models (CodeBERT, CodeT5). ",
    "The paper proposes a new approach to abstract syntax tree-based automatic program repair. The novel technique called deleted-subtree reconstruction is based on dropping parts of the syntax tree and training the model to grow them back. The method is evaluated against edit-based and sequence-based approaches, where it outperforms only the edit-based ones.",
    "The paper presents GRAPHIX, a graph edit model for program repair. The work is directly related to Hoppity (Dinella et. al. 2020) which proposed using a sequence of graph edit for program repair. GRAPHIX employs multi-head graph encoder which improves upon Hoppity in terms of accuracy and complexity. Notably GRAPHIX is able to learn longer edit sequence and thus work on more program repair samples. The work has also proposed a pre-training task to improve model performance. Empirically the authors evaluated GRAPHIX on the *Patches in the Wild* Java bug-fix benchmark. It outperforms various baselines without pre-training. With pre-training, GRAPHIX-P stays roughly on par despite having much smaller model.",
    "This paper tackles an important problem in federated adversarial training: robustness accuracy significantly drops at the later stage of training. The authors first raise their assumption for the cause of this phenomenon: Adversarial training amplifies the heterogeneity of data distributions across different clients, and overfitted local robustness can not well generalized to other clients. Based on this assumption, the authors proposed \\alpha-weighted federated adversarial training, which essentially up-weights the model trained on benign distributions and down-weights those on harsh distributions when averaging them up at the cloud center. Results show the proposed method outperforms previous state-of-the-arts under different adversarial training and federated learning settings. ",
    "This work studied the limitation of conventional Federated Adversarial Training approach, and proposed an \\alpha-weighted relaxation for Adversarial Training in the federated learning setting. Then it proposed a novel \\alpha-Weighted Federated Adversarial Training for minimizing a lower bound of the inner-maximization in Federated Adversarial Training. The performance of the proposed \\alpha-Weighted Federated Adversarial Training were validated for both IID and Non-IID federated learning settings.",
    "This paper introduces the alpha Weighted Federated Adversarial Training algorithm. The key of the idea is that in the aggregate step, the center prefers the local machine that yields smaller lost. Some theoretical results are delivered with numerical experiments. The paper claims that the alpha-weighted mechanism is tailored for the inner-maximization of Federated Adversarial Training, which is the rationale of the whole work.",
    "The authors explore the adversarial robustness of federated learning. They claim that the inner-maximization optimization of AT can exacerbate the data heterogeneity among local clients. They propose an algorithm, $\\alpha$--WFAT, which relaxes the inner-maximization of Adversarial Training into a lower bound friendly to Federated Learning.. The authors also experimentally establish that federated learning models are most susceptible to attacks when clients are using non-IID training sets. The experiments are performed over the CIFAR-10 , SVHN and CIFAR-100datasets.",
    "In contrast to previous works on lifelong machine learning (LML) that put their focus on the supervised learning settings, this paper concentrates on the scenario that only a limited amount of data is available. The proposed method MAKO is mounted on the top of supervised LML model, without introducing additional knowledge based overhead, for better leveraging the unlabeled data. Labeling new data can be realized by using the data programming method which is supervised by the labeled data. The target of this paper is to design a SSL LML framework that minimizes the performance between using partially labeled data, and the upper-bound performance using fully labeled data. Several experiments on standard image classification data sets including MNIST, CIFAR-10 and CIFAR-100 are used to evaluate the the effectiveness of MAKO. ",
    "This paper propose a wrapper tool that mounts on top of supervised Lifelong Machine Learning (LML) frameworks, leveraging a well-known method data programming. The contributions of this paper can be summarized in three aspects. 1)  Adapting automatic label generation by semi-supervised learning/data programming to LML in some special scenario. 2) Implementing a LML wrapper that can accomplish some tasks under some restrictions. 3) Through detailed experimental results prove the superiority of its method.",
    "This paper proposes  data programming method, named Mako,  for semi-supervised continual learning. Mako automatically generates labels for unlabeled data with a set of weak labeling functions, each of the functions is trained on subset of training set with bootstrapping. Experimental on several datasets demonstrate the effectiveness of the proposed methods. ",
    "This paper presents an interesting idea of using data programming techniques to enable continual semi-supervised learning with limited labeled data. It proposes a stage-wise pipeline where probabilistic pseudo labels are first produced by a Snuba based Data Programming framework, then calibrates them by the temperature scaling, and finally inputs into the mounted Lifelong Machine Learning (LML) tools. Experiments show that the proposed framework achieves similar performance to fully supervised methods.",
    "The authors propose an attack that could break 4 adversarial detection methods published recently. Traditionally, attacks against detection methods have attempted to maximize the loss for both classification and detection simultaneously. However, using a toy example the authors show that this is suboptimal, as it may not find the worst-case adversaries. The authors propose to minimize the loss (targeted attack setting) iteratively by optimizing either only for the classification pipeline or the detection pipeline at a time.  The attack first considers the classification loss and further tries to fool the detection pipeline until the classification prediction remains incorrect. The authors also propose a variant of the attack by considering gradient steps for the classification pipeline to be orthogonal to the gradients of the detection pipeline and vice versa. Finally, the paper shows that these two proposed attacks completely circumvent four recent adversarial detection methods.",
    "This paper considers the problem of finding adversarial examples that simultaneously defeat a detector of adversarial examples. An argument is made that existing attacks often achieve one goal at the expense of another. This argument motivates the proposal of two attack techniques. These are evaluated against four existing detection-based defence methods, with successful results.",
    "This paper targets on attacking the defensive mechanism of adversarial examples detection. It proposes a new optimization algorithm to simultaneously meet two different requirements. It verifies its effectiveness on several state-of-the-art adversarial example detection methods.",
    "This paper proposes two techniques for generating adversarial examples: Selective Projected Gradient Descent (SPGD) and Orthogonal Projected Gradient Descent (OPGD). In order to fool both the victim model $f$ and a detector $g$, SPGD selectively optimise either $f$ or $g$ depending on whether the modified input is misclassified as the target class, while OPGD further orthogonalizes the gradients. Evaluation on four previously unbroken, state-of-the-art defence methods demonstrate the effectiveness of the proposed attacks.",
    "This paper studies valuation problems from cooperative game theory. There are $n$ agents and a valuation function $F: [n] \\to R$ where $F(S)$ is the collective payoff of the coalition $S \\subseteq [n]$. The goal is to use this function $F$ to define an importance vector $\\phi(F) \\in R^n$. Examples include the Shapley value and Banzhaf index.  The authors introduce a probabilistic treatment of this problem, where they use $F$ to define a probability distribution $p$ where $p(S)$ is the probability that coalition $S$ forms. They then phrase the problem of defining an importance vector $\\phi(F)$ as a decoupling problem. Under $p$, the $n$ agents may be correlated in a complicated way, but to assign each of them an individual importance value, one must decouple their interactions, or simplify their correlations. The goal is then to find a product distribution $q$ that is as close to $p$ as possible under the KL divergence. Specifically, the authors define $q$ to be an $n$ independent Bernoulli distribution, where the probability that agent $i$ participates in the coalition is denoted $x_i$. The authors show how to optimize the probabilities $x_1, \\dots, x_n$ using coordinate ascent. Finally, they define the importance score of player $i$ as $\\log(x_i/(1-x_i))$ (ignoring a temperature $T$ term for simplicity). The authors show that the resulting importance vector satisfies many of the game-theoretic axioms that the Shapley value and Banzhaf index satisfy, like the null player, marginalism, and symmetric axioms.  In the experiments, the authors look at small instances with $n = 25$ where it is actually possible to compute the gradients exactly (as opposed to an approximate sampling method). The applications they look at are for data valuation and feature attribution in the context of machine learning. For these tasks, they show that their proposed approach performs about the same as the Shapley value and Banzhaf index, and sometimes a bit better.",
    "Valuation criteria based on game-theory (e.g. Shapely value) have been used in the ML literature for analyzing feature importance and for data subset selection. These criteria serve as solution concepts for cooperative games and have been adapted by some works in ML for subset valuation problems.    The present paper presents a probabilistic treatment of cooperative games, and shows that two classical valuation criteria can be seen as a one-step factored approximation to maximum entropy solution to the game. They then propose a new valuation criterion \"Variational Index\" that uses a multi-step factored approximation and show it satisfies some common axioms for cooperative games. The paper also has experimental results on the proposed criterion.  ",
    "The paper studies valuation problems for cooperative games. It proposes a new valuation measure called Variational Index. The idea is to create a coalition probability distribution based on a maximum entropy criterion. Player valuations are then derived by creating decoupled surrogates of this distribution. The authors then present a gradient ascent algorithm to compute this decoupling. Classical valuation criteria like the Shapley value and the Banzhaf index can be recovered as special cases or modifications of the algorithms iterates.",
    "This paper proposes an energy-based perspective on cooperative games that permits a gradient-based calculation of Shapley/Banzhaf values, as well as the definition of a new alternative value - the variational index. A quick summary of the paper's key ideas is:  - For a given cooperative game $F$, we can seek an entropy maximizing distribution over coalitions $p(S)$ that satisfies a constraint on the mean coalition value $\\mu$ - Solving the entropy maximization problem via its Lagrangian yields the Boltzmann distribution $p(S) \\propto \\exp(F(S)/T)$, where the temperature $T$ has a one-to-one correspondence with the mean coalition value $\\mu$ (this result is in the appendix). This distribution gives more probability mass to coalitions that achieve higher values - We can seek a simpler alternative to $p(S)$ by doing mean-field variational inference, i.e., finding a factorized surrogate $q(S)$ where each player's participation is determined by independent Bernoulli RVs. The result will intuitively assign higher probabilities to players that belong to high-value coalitions, so these probabilities can serve a function similar to Shapley/Banzhaf values - The VI approach suggests a KL divergence minimization (or ELBO maximization) objective for learning $q(S)$, which is parameterized by $x \\in [0, 1]^n$. Doing gradient descent on this objective yields a relatively simple update rule, where we repeatedly set $x_i^+ = \\sigma(\\nabla_i f_{mt}(x) / T)$ for $i = 1, \\ldots, n$ - The authors define the \"variational index\" as a function of the solution to the KL divergence minimization problem: $s^* = T\\sigma^{-1}(x^*)$ - The authors find that the Banzhaf value can be found using a single-step update to a particular initialization of the KL divergence minimization problem (luckily the temperature $T$ is not important for single-step updates). Similarly, they find that the Shapley value is the average of the single-step update applied to different initializations (again, the temperature doesn't matter). Finally, the authors point out that any single-step update applied to a symmetric initialization will be a probabilistic value (a class of solution concepts in cooperative game theory, of which Shapley/Banzhaf values are special cases) - Lastly, the authors suggest a practical sampling-based approach to calculating the necessary gradients, which are just as difficult to calculate as the Shapley/Banzhaf values because they require calculating the value for every coalition $S \\subseteq N$  The experiments compare the variational index to Shapley and Banzhaf values in data and feature removal tasks, finding that it performs quite favorably in the settings examined.",
    "This paper uses out-of-sample prediction error as a measurement of epistemic uncertainty. Using this definition, it develops an estimator: direct epistemic uncertainty prediction.  The idea is to have a main predictor to learn the task, and an error predictor to predict the generalization error. Empirical studies show that their proposed estimator produces better estimation on downstream tasks such as sequential model optimization and reinforcement learning. ",
    "Given some supervised task, this paper redefines the uncertainty of a solution as its generalisation risk. The authors then propose to learn a secondary function to estimate the generalisation risk of the first. This is done by using held-out points as training data for the secondary model. In turn, this held out used to estimate the primary model error comes from a k-fold split.  The inputs to the secondary model are the data points being evaluated, estimates of the predictive variance of the primary model, density estimates from a generative model and whether the point has been observed by the primary model.  The authors posit that the advantage of their method is that it can capture uncertainty due to model selection bias, something omitted by existing work, which focuses on the variance of the learnt estimator. The authors provide a diverse range of experiments: OOD rejection in image classification, active learning for drug discovery, function optimisation and exploration in reinforcement learning. ",
    "This paper proposes a new approach for computing epistemic uncertainty. The proposed approach, DEUP, builds a new model (in addition to the original model) which predicts epistemic uncertainty, defined as generalization error minus aleatory uncertainty. I highlight some features of DEUP below: - DEUP works with a hold-out dataset that is used for training the error predictor.  - In case there does not exist a hold-out set or in interactive settings (like RL or active learning), DEUP is extended to be used in a cross-validation setting and the features used to fit the error predictor is extended to include data density estimates and model variance. DEUP is evaluated on different settings including OOD data, sequential model optimization and RL.",
    "This paper proposes a method to estimate the epistemic uncertainty (uncertainty due to lack of knowledge/data) at a new model input. The paper takes an indirect approach towards this goal by a) first estimate the generalization error at the new input, b) next estimate the aleatoric error (inherent uncertainty in the data distribution / irreducible error), and c) subtract aleatoric error estimate from the total generalization error estimate to obtain the epistemic uncertainty estimate.  The authors claim that this method captures both the uncertainty due to lack of data, as well as model misspecification in the process - while other/existing methods focus mostly on the variance of the posterior distribution (or its approximation) as a measure of epistemic uncertainty (and thereby implicitly assume the model is well specified.)  Estimating the total generalization error itself is performed with a second neural network model, which uses residuals obtained from the primary model as its labels. Estimating aleatoric error either assumes the presence of an Oracle or   The authors apply their technique on both static (fixed data set) as well as interactive (active learning) settings, though mostly focused on the mean squared error loss function.",
    "This paper proposes a block coordinate descent algorithm for rotation learning. The algorithm is based on Lemma 1 and Theorem 1. The rotation matrix on SO(n) is decomposed into diverse simple Givens rotation matrices. Then the optimized variable is converted into these Givens rotation matrices so that the rotation matrix is always on SO(3) and the projection is not required anymore. The authors also discuss how to select the coordinate, including random strategy, greedy strategy, and steepest strategy. Different from the existing work, it considers multiple Given rotations matrices in one step. ",
    "Current rotation learning methods are trying to minimize quantization distortion for fixed embeddings, which are not applicable to an end-to-end training scenario where embeddings are getting updated constantly. Therefore, this paper tries to address this issue to fully enable end-to-end training of Product Quantization (PQ) based embedding index with retrieval models, by using mathematical studies of the decomposition of orthogonal group. They proposed a family of block Givens coordinate descent algorithms to learn rotation matrices that are provably convergent on any convex objectives by leveraging geometric intuitions from Lie group theory. Authors claimed that their algorithms are much more parallelizable, reducing runtime by orders of magnitude on modern GPUs, and converge more stably according to experimental studies in comparison to the state-of-the-art SVD method.   Their main contributions can be summarized as follows:  - Changing the landscape of learning rotation matrix in approximate nearest neighbor (ANN) search from SVD based to iterative Givens rotation-based, to be applicable to end-to-end neural network training.  - Proposing a family of Givens coordinate block descent algorithm with complexity analysis and convergence proof.  - Proves that for the fixed embedding, their algorithm shows similar convergence result as the existing rotation matrix learning algorithms. Therefore, their proposed algorithm is able to learn the rotation matrix more effectively for the end-to-end training.",
    "This paper proposes to learn rotation matrix by Givens coordinate descent algorithms in the context of minimizing the quantization distortion for efficient storage. The proposed family of Givens coordinate descent algorithms are based on geometric intuitions of the special orthogonal group and are provably convergent on any convex objectives. The experiments show that the proposed algorithms are much time efficient and lead to performance improvement in an end-to-end training of embedding indexes.",
    "The paper address rotation matrix learning during product quantization in modern ANN embedding search systems. The main contribution is addressing rotation matrix learning via gradient descent of small rotation updates. The approach relies on the decomposition of any small rotation matrix into a product of Given rotations, so that partial derivatives can be obtained in parallel, but the product causes the computation of the rotation matrix itself to be slow, in O(n^2) matrix multiplications, hence the need to select a subset of coordinates and do coordinate descent. Experiments on product quantization show a marginal improvement in results over existing approaches OPQ and Cayley.",
    "This paper targets the problem of abstract reasoning, with a special focus on the task of learning visual analogies. The authors propose a multi-stage neural network (Neural Structure Mapping, NSM) for decomposing the problem into vision relationship recognition and concept inference. They tested their model on an existing RPM (Raven's Progressive Matrices) based visual analogy benchmark that contains different systematic generalization tests and outperformed existing models. The authors made further discussion on these experimental results to support their proposals on model designs.",
    "A model called Neural Structure Mapping (NSM) is introduced to solve the task of abstract visual analogy making. The NSM model consists of a visual relationship encoder and an analogy inference engine. The visual relationship encoder extracts the visual domain elements, including object, attribute, and relation, while the analogy inference engine is a neural modular architecture that constructs the model layout based on the relation and predicts the final answer. On the dataset proposed by Hill et. al., the NSM shows better performance than other baselines.",
    "This paper tackles the problem of analogical reasoning. In particular, it presents a framework for learning the Raven Progressive Matrices (RPM) task, an abstract analogy task.  In the RPM task, a sequence of three images from a source domain are given. There is some relationship that holds for the sequence, e.g. the third image is the union of the first two. Then, given an incomplete sequence of two images from the target domain, the third image must be chosen from a list of four possible candidates.  The proposed Neural Structure Mapping (NPM) system consists of two pieces. The first piece is the Visual Relationship Encoder. Given the source sequence of images, the encoder predicts the type of relationship exhibited in the sequence. This information is passed to the second piece, the Analogy Inference Engine. The architecture of the engine is assembled dynamically, according to the predicted relationship. The assembled network takes the target sequence and the candidate matrices as input and selects the completion of the sequence from among the candidates.  The encoder is trained with the ground truth relationship labels. The engine is trained using the ground truth candidate labels.   The paper presents an experiment to test systematic generalization, in which particular attributes are held out during train time. The NSM system is found to achieve better performance.  In contrast to Hill 2019, which presents the model with semantically-contrasting alternative candidates at train time, NSM achieves good performance even when the alternative candidates are not necessarily semantically related.  ",
    "This paper proposes a new architecture for learning visual analogies, based on Gentner\u2019s Structure Mapping Theory for how humans might draw analogies. Gentner\u2019s theory proposes representing the relationships between objects explicitly, so that this relational structure can be reused in new domains (and suggests that this commonality in structure is what permits analogies to be made between perceptually dissimilar objects). The authors propose a neural network model architecture and test it on the Raven\u2019s Progressive Matrices dataset. The proposed architecture first splits a series of \u2018source\u2019 visual scenes into objects, attributes and the relationships between those scenes, before feeding just the relationship head into a second network. The second network then switches between two different architectures (depending on the relation fed in). The architecture in the second network (whichever is chosen) receives the \u2018source\u2019 relationship and two \u2018target\u2019 scenes before trying to predict which of a set of 4 candidate  \u2018target\u2019 scenes completes the visual analogy between source and target. The authors test their architecture on the generalisation splits in the RPM dataset and compare test accuracy results to the baseline models used by Hill et al, 2019. The authors show that their model (which builds in additional architectural structure) performs better at a subset of tests than more general architectures.",
    "Recently several works have proposed semi-supervised learning methods to leverage unlabeled biological sequences for learning their general-purpose representations. In this work, the authors proposed the Self-GenomeNet, a novel contrastive learning method for nucleotides based on the reverse-complement (RC) context prediction. First, given a sequence, they divide it into two subsequences and transform one into its RC. Then, the model is trained to distinguish their representations from those of other random nucleotide sequences. The authors claimed that the proposed method considerably outperforms previous self-supervised baseline models on three benchmark datasets in both self-supervised and semi-supervised evaluation ",
    "This paper presents a self-supervised learning approach using contrastive loss for representation learning of genomic sequences. The contrastive loss has been used for self-supervised learning in the NLP and computer vision domains and the paper presents its application for genomics. Self-supervised contrastive learning tries to maximize the agreement between augmented views of a sample. Therefore, Self-GenomeNet splits a sequence into two subsequences, and the learned representation of subsequence 1 is compared to subsequence 2 and its revers compliment (positive samples) as well as other sequences (negative samples). The described method has two considerations specific to the genomics tasks - (1) it handles variable sequences (2) it incorporates reverse complement information of the sequences. The method is applied on two prediction tasks and one transfer learning task using sequences from viral, bacterial, and human genomes. Its performance is compared to the supervised model, generative language model, and self-supervised learning models - CPC and Contrastive-sc. The results show improved classification performance over the baseline for both supervised retraining and semi-supervised training settings. ",
    "This submission introduces self-genomenet, a self-supervised training method for learning from DNA sequences. The self-supervision is done by predicting the end of a sequence from its start (both broken into smaller subsequences), through a contrastive loss against other random sequences. The predicted part is also reverse-complemented (RC), making the network learn the expected reverse-complement invariance of the prediction function. The method is extensively tested on several learning tasks, where it shows good performances.",
    "The authors proposed a self-supervised learning method for nucleotide-level genomic data utilizing reverse-complement of genomic sequences. The proposed method achieved a considerable performance improvement. In addition, the authors proposed an architecture called Self-GenomeNet that handles varying-length genome sequences.",
    "This paper proposes to make the geometric neurons of Melnyk et al.'21 to be steerable so that objects undergoing arbitrary rotations can be classified with higher accuracy. This is done in multiple stages. First, the neurons of Melnyk et al. are trained to convergence with a hyperspherical output layer. Then, the frozen weights are transformed such that the input of a *steerable neuron* can be written as a linear combinations of the rotated versions of itself. The experiments act as a sanity check while demonstrating the validity of the algorithm on a simple human pose dataset.",
    "The paper proposes a method for constructing steerable spherical neurons, building on the recent Geometric Neurons developed in Melnyk et al 2021. The main technical result in the paper is a steerability constraint for a geometric neuron, as given by eq. (13) in the paper. This constraint is used in an implementation whereby a steerable model is constructed and is then use for two tasks. The first task involves the use of steerable spherical neutrons for the classification of 3D Tetris objects seen under rotations, and the second is a similar experiment applied to 3D skeleton data. The results demonstrate a very large performance boost when using the steerable versions. The second experiment builds on this idea to construct a version that adapts a possibly imperfect initial rotation estimate, using the representation. This second experiment is in the spirit of demonstrating equivariance under 3D rotations with perturbations.",
    "## Summary and contributions. Authors propose 3D \"spherical neurons\" leading to rotationally equivariant layers. They do so by building on the spherical and geometric neurons introduced in Melnyk et al. (2021), which leverages the conformal space (for $\\mathbb{R}^n$) to perform operations. The authors then solve for the steerability constraint for this neuron and empirically show that the proposed approach overperforms Melnyk et al. (2021) on rotated 3D data. ",
    "The paper aims to derive a steerability constraint for spherical neurons (3D point classifiers with spherical decision boundary). The steerability constraint enables test-time optimization of a pre-trained classifier to make predictions equivariant to 3D rotation perturbations applied to the input. When input rotation perturbations are unknown, the authors propose a method to recover the unknown rotations and therefore make rotation-invariant predictions. The experiments on a few small scale datasets verifies some of the claims.",
    "As the title suggests, the paper is a comparison of recent continual learning methods that prevent catastrophic forgetting and their effectiveness in some text classification tasks using popular pretrained language models such as BERT, RoBERTa, etc. The paper divides continual learning methods into three categories: (1) rehearsal-based, (2) regularization-based, and (3) dynamic architecture. The experimental results show that rehearsal based methods are superior to the other two, and also that BERT is generally better than other candidates. The paper then proposes a new probing techniques to find out what makes rehearsal-based method better and what's happening inside BERT. The paper finds that the last layer has the biggest catastrophic forgetting and lower layer is less impacted.",
    " This paper conducts an empirical study on the catastrophic forgetting of pretrained language models. On two continual learning settings (class incremental and task incremental), the paper evaluates multiple pre-trained models on different data sets, to see how severe the catastrophic forgetting issue is for these pre-trained models. Then the paper also tests the effectiveness of multiple continual learning methods on such pre-trained models and draws some conclusions. ",
    "The authors perform a comprehensive study of how pretrained language models work in the continual learning setting. The authors study 5 relevant pretrained language models (masked and unmasked) and somewhere between 3 and 6 continual learning strategies depending on where in the paper they are counted. In addition to a thorough everything-by-everything evaluation, the authors hone in on the details of how the different models and CL approaches are reflected in the transformer layers. The authors find that the different language models studied perform relatively differently, both qualitatively and quantitatively, and these insights may provide useful for directing future improvements.",
    "This paper explores the continual learning performance when combining different PLMs and common continual learning methods with 3 challenging NLP classification tasks.  To benchmark these combinations the methods are evaluated in task-incremental and class-incremental learning settings over various NLP end-tasks, which covers common learning settings in continual learning and NLP. There is also a layer-wise performance analysis to identify which layers keep or forget task relevant information during training.  Overall the paper shows that forms of replay outperform other methods like regularization.",
    "The paper tackles the problem of adversarial attacks in federated learning settings. The main proposal is a defensive technique to address the \u201cbyzantine generals\u201d problem in federated learning: how to ensure that the general ML model is not affected by \u201cpoisonous\u201d attempts made by corrupted clients. The proposed technique is experimentally validated on four datasets, outperforms previous defensive methods, and the evaluation also considers adaptive adversaries with increasing degrees of knowledge.   Overall, the presentation of the paper is very good. The quality of the English text is good. Figures are appropriate, Tables require some editing. The topic addressed by the manuscript is trendy and in-line with ICLR\u2019s scope. The references should be improved The contribution is significant  STRENGTHS: + Adaptive adversary  + Trendy subject (federated learning) + Evaluation on multiple datasets + Technically sound  WEAKNESSES - Unclear assumptions and threat model. - Problem or Feature space attacks? - Lack of a concrete use-case - Tradeoff? ",
    "The authors propose TESSERACT, an aggregation scheme that is robust to the directed deviation attack (proposed in Fang et. al. 2020). ",
    "This submission with the title \"Tesseract: Gradient Flip Score to Secure Federated Learning against Model Poisoning Attacks \" discusses defenses against data poisoning in federated learning. The authors propose a novel defense against the recently popularized attack \"Tesseract: Gradient Flip Score to Secure Federated Learning against Model Poisoning Attacks \" by Yang et al. This attack reduces model availability by sending malicious updates from compromised client that maximize sign flips in the global model gradient.  This defense then proposes a measure of change in gradient direction that can be evaluated for each local update and used to dynamically down-weight clients with a large number of flips in direction. ",
    "This paper studied a very important topic in the field of federated learning: how to efficiently resist untargeted model poisoning attacks. In order to defend against such a poisoning attack, the authors developed TESSERACT, an aggregation algorithm that assigns reputation scores to participating clients based on their behavior in the training phase and weights the client's contribution. Extensive case studies have verified the effectiveness of the algorithm. In particular, the experimental results show that TESSERACT provides robustness against even a white-box version of the attack. ",
    "This paper considers the problem of estimating an expectation over covariates of some functional of an unknown regression function. The authors propose two estimators, one based on neural networks and one based on random forests. In contrast to many (all?) previous estimators which were derived for specific functionals, these estimators are applicable to general functionals. They employ a (new?) debiasing technique. Moreover, they use a novel multi-task architecture based on the observation that it suffices to estimate the regression function as a function of the Riesz representer. The paper demonstrates improved accuracies compared to prior work and good coverage on semi-synthetic tasks derived from two data sets.",
    "The authors address the problem of estimating the average value of a moment function that depends on an unknown regression function, which is commonly used in causal inference.  By the Riesz representation theorem, the authors design a loss function where the Riesz representer turns out to be the minimizer of the proposed loss.  The authors propose both a Neural Network method (RieszNet) and a random forest method (ForestRiesz), i.e. a multi-tasking Neural Network method where the loss function is a combination of the Riesz representer and regression loss, and a random forest method that leans representation of both the regression function and the Riesz function.  The authors conduct experiments of estimating the average treatment effect and average marginal effects, and show that the proposed RieszNet and ForestRiesz beat the state-of-the-art methods.   ",
    "This paper shows novel methods based on the recent findings on the Riesz representation in econometrics and machine learning, such as Chernozhukov et al. (2021). While the proposed applications make sense and are persuasive, the contributions of this paper are a bit limited. Although the authors support the soundness of the proposed algorithms in experiments, the experiments are a bit simple and may not be sufficient for the justification. ",
    "The authors study the nonparametric estimation of an important class of (causal) estimands that includes the average treatment effect (ATE) in experiments and observational studies under unconfoundedness. The main innovation is the \"automatic\" nature of the procedures, one based on deep learning and one on random forests. While previous work has developed hand-tailored constructions for the ATE (a traditional problem in statistics), the authors show that existing constructions can be generalized considerably based on recent advances in semi- and nonparametric statistics based on Riesz representers. The key challenge this work addresses is the fact that the Riesz representer is typically unknown.  The main proposed method based on deep learning, RieszNet, may be seen as a generalization of the DragonNet procedure by Shi et al. (2019) from the ATE to more general estimands. Even in the case of the ATE, DragonNet and RieszNet are not the same and RieszNet outperforms DragonNet in simulations: RieszNet directly targets the inverse propensities, while DragonNet estimates the propensities and then plugs in their inverse.",
    "This paper establishes the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning (MARL) problems with average reward. It focuses on the practical setting where the rewards and actions of each agent are only known to itself, and the knowledge of joint actions of the agents is not assumed. The established finite-sample complexity matches that of the state-of-the-art single-agent actor-critic algorithms.",
    "This paper considers cooperative multi-agent reinforcement learning (MARL) for average reward MDPs with fully decentralized actor-critic methods. In particular, the authors make some progress on top of existing works in this direction, and in particular (Zhang et al., 2018). More precisely, the authors remove the assumption in (Zhang et al., 2018) that the joint actions are observable to all agents, and propose to modify the actor updates with mini-batch TD sharing to accommodate the scenario where each agent only observes its own action. The authors then establish a finite-sample bound for the proposed algorithm in terms of convergence to stationary points under linear value function approximation. Numerical experiments are also provided to showcase the benefits of the modifications over the algorithm in (Zhang et al., 2018). ",
    "This paper studies the cooperative average reward fully decentralized multi-agent reinforcement learning (MARL) problems, where the agents interact with their neighbors over a communication network. It proposes a consensus-based actor-critic algorithm and shows its convergence to the stationary point. The convergence rate and sample complexity of this algorithm are provided and comparison with existing algorithm is shown in the numerical experiments. ",
    "This paper studies a networked MARL problem based on the model in [Zhang et al 2018], where each agent can observe the global state, take local action and observe local rewards. The key difference in setting from [Zhang et al 2018] is that [Zhang et al 2018] assume the global action can be observed, but in this paper, only local action is known to each agent. To deal with this, an additional consensus loop is added to estimate the average TD error, which can be used to estimate the advantage function. Further, compared to [Zhang et al 2018], a finite time error bound is provided.  ",
    "This paper aims to provide theoretical understanding for contrastive learning where \"similar pairs\" of points $x$ and $x^+$ are encouraged to have similar representations through an InfoNCE inspired objective function. Some prior works show the benefit of learned representations for linearly classifying downstream classes, by making conditional independence like assumption on the similar pairs or positive samples, i.e. $x$ and $x^+$ are (approximately) conditionally independent given downstream label $y$. This work argues that these assumptions are quite strong for contrastive learning with data augmentations, and aims to show guarantees under the following weaker and more realistic assumption: support of augmentation distribution of different inputs from the same class overlap to form a \"connected graph\" of inputs within a class, whereas support of augmentations of inputs from different classes do not overlap. Lower and upper bounds using this and some other assumptions, connecting the downstream performance of representation function to the contrastive loss. Some simulation experiments are presented to support some aspects of the theoretical analysis.  Using the insights from the analysis, the paper proposes an \"Average Confusion Ratio (ACR)\" metric that can be used to predict the ranking of downstream performances of different augmentations **using only unlabeled data**. Experimental evidence is provided on CIFAR and STL datasets to verify the efficacy of this metric for some practical augmentations.    While there are some interesting aspects in the paper (especially the ACR metric), the theoretical analysis seems to have raised many questions and concerns that I have summarized below (details in main review).   - **Soundness of assumptions**: Assumption 4.6, which is crucial, seems questionable and may not be coherent or appropriate to make in this setting. More on this in point (W2) of main review  - **Deeper dive into theoretical results**: There is a lack of discussion about the (non-)vacuousness of the bounds in the main results Theorem 4.2 and 4.8, that puts the interpretation and significance of the result in question. More on this and related issues in point (W2) of main review.  - **Comparison to prior work**: The work of HaoChen et al. in particular is not adequately compared to, especially since some of the points being addressed here are covered through a different kind of analysis in that paper. More on this in point (W3) of main review.",
    "The authors provided a new understanding of contrastive learning from the perspective of data augmentation for intra-class samples. In particular, the authors proposed to understand the role of data augmentation as to create certain ``chaos'' between intra-class samples so to encourage the clustering of intra-class samples and also the learning of class-separated representations. Additionally, a new metric ARC is proposed to evaluate the downstream performance. The conclusion is validated via both synthetic and real-world datasets. ",
    "The current leading theory of what contrastive losses are doing and why they work interprets contrastive learning as balancing alignment with uniformity, as proposed in [2].  This paper seeks to augment that understanding of contrastive learning using a new perspective, focusing on the role of data augmentation.  It is well-known that contrastive learning techniques are highly sensitive to the data augmentation schemes used, most notably discussed in [1].  In this work, the authors interpret augmentation as a way to connect different intra-class images together.  Then, the contrastive loss is seen as a way to gradually cluster intra-class samples together by aligning augmented views, producing representations that are class-separated even in feature space.  On top of introducing a new lens with which to understand contrastive learning, the authors also provide proofs on performance guarantees, as well as a new evaluation metric.  The metric is inspired by their augmentation-oriented understanding, and was also found to align well with downstream performance.  The authors provide a scenario where alignment and uniformity are satisfied, but fails to translate well to downstream classification accuracy.  This suggests to them that the instance discrimination task alone cannot guarantee the learning of class-discriminative features that would enable better downstream classification, and directs their attention to the other important component of contrastive-learning to help explain the story: augmentation.  They then build off the analytical work of [3] to prove guarantees for the downstream performance with a relaxed assumption.   [1] Chen et al., A Simple Framework for Contrastive Learning of Visual Representations, 2021.  [2] Wang and Isola., Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere, 2020.  [3] Saunshi et al., A theoretical analysis of contrastive unsupervised representation learning, 2019. ",
    "The paper proposes a new theory for understanding contrastive representation learning. The novelty is the focus on the interplay between alignment and augmentation. Prior work has identified alignment as one of the factors of contrastive learning, but have not investigated how different types of augmentations may affect the learned embeddings. This work adds that missing piece. The results intuitively make sense, showing that proper amount of augmentation (that connects samples of the same class) has positive effect on downstream classification. Empirically, the authors verify that too weak or too strong augmentation harms performance. Based on observations, the authors define a metric on ratio of positive pairs among nearest (embedding) neighbors, and found the change of this metric throughout training positively correlate with performance.",
    "The paper proposes an approach called VoiceFixer which is aimed at restoring degraded speech signals. The paper considers a variety of speech degradations - additive noise, reverberations, clipping and limited bandwidth. The paper describes a two stage approach in which the first stage aims to produce restored mel-spectrogram and then a vocoder is used to synthesize the  speech from the restored mel-spectrogram. Experiments are done using the VCTK dataset and experiments are done using single distortions as well as combinations of all 4 distortions. ",
    "This paper proposes a general speech restoration (GSR) task that tries to remove multiple distortions in a single model. In addition, it also presents a generative framework called VoiceFixer consisting of analysis and synthesis stages to address the general speech restoration task. In VoiceFixer, the authors employ a ResNet for modeling the analysis stage and a TFGAN-based neural vocoder for synthesis stage. They report that their baseline GSR and VoiceFixer surpass the single speech restoration (SSR) models with more improved results by the latter. Their idea was well described and the experiments are systematical and extensive. The results are consistent and clear.  The contribution of this paper is to incorporate a variety of speech restoration tasks including speech denoising, super-resolution, dereverberation, declipping, etc. in a single unified task called GSR. Another is the proposal of a well-performing generative speech restoration framework called VoiceFixer. ",
    "This paper introduces a unified view of several speech restoration problems including denoising, decliping, dereverberation and audio super-resolution. In order to solve the problem of the general speech restoration task, the authors propose a U-Net architecture which is trained on all of these tasks simultaneously during training time. The authors conduct extensive experiments for the general speech restoration task as well as the individual tasks where they compare the proposed models with more specialized models bounded to each distortion. The experimental results show that the proposed VoiceFixer combination of the model and the analysis-synthesis procedure are capable of effectively removing the speech distortions and in some cases outperform previous approaches in the literature.",
    "The paper proposes a single system to deal with the speech enhancement tasks of denoising, dereverb, bandwidth extension (BWE) and declipping. The system is a two-stage system composed of an analysis module producing mel-band masks and a synthesis module using a vocoder. Both modules reuse existing architectures. Results comparing the proposed system to author-derived counterparts of it and to some existing systems for specific tasks show improvement for the proposed system in some cases, while achieving similar performance as existing systems in other cases. Data and code for reproducibility are provided.",
    "For multivariate time series forecasting, this paper proposes to use a tensor network to model the variable space and improve the quality of the variable space by designing the series-variable encoder. Under the variable space, this paper also proposes an N-order residual connection approach and the skip-connection layer for processing the long-term data. The proposed model MVSRTN achieves good results on some datasets. However, this paper has not well explored MVSRTN, and the results are not very competitive. In addition, there are many typos in the paper.",
    "The paper proposes a deep learning architecture for time series forecasting called MVSRTN. The model is composed of 3 blocks with skip-connections in-between them: a 1) \"Series-Variable Encoder\", 2) an \"N-Order Residual Tensor Network\", as the authors call it, and 3) the output layer. Out of these, 1) is essentially a 1D CNN combined with (causal and non-causal) self-attention, and 2) seems to be a tensor network built from taking the tensor product of the sequence entries, and then contracting that by a TT-rank-constrained weight tensor. The computation of the tensor network output is formulated as a recursion across time-steps, and motivated by residual networks, an identity mapping with respect to the hidden state at the previous time-stamp is added to the recursive formulation. Then, by the analogy with higher-order solvers for ODEs, a \"higher-order residual connection\" is introduced. The model is applied to four time series forecasting datasets, where some improvements are achieved, and an ablation study is included to show how the various model blocks contribute to the performance.",
    "This paper proposed the MVSRTN architecture for multivariate time series modeling. The MVSRTN consists of an encoder to extract latent variables and residual tensor network (TN) blocks to capture the interactions in the latent space.  The main contribution of the model is the TN block part. In particular, the authors used tensor-products to fully represent the latent variable space (Eq 2). Then, they proposed an N-order residual TN block to alleviate potential gradient problems of high-order TNs in long-term time series. They conducted experiments on four multivariate time series data for prediction. Moreover, an ablation study shows the effectiveness of the proposed residual TN blocks.  Combining ResNet and TN is an interesting direction. However, I think this paper did not present this problem sufficiently and some notations are confusing. ",
    "The paper considers the problem of forecasting of multivariate time series. The authors propose an architecture for such forecasting that incorporates several layers, including a residual tensor network layer. The idea is to tensorize (via outer products/Kronecker products) the features passed on from the encoder layer and then handle these very large tensorized features with a tensor network. The point of the tensorization is to better incorporate the effect of combinations of variables from different time steps. Experiments are done on four benchmark datasets.",
    "This paper formulated the graph neural network as a stochastic compositional optimization problem and then developed a new optimization algorithm to train GNN. However, there are some errors. It is not ready for publication.",
    "This paper proposed an improved variant of the Stochastic Compositional Optimization (SCO) framework to train GNNs, replacing all nodes' moving averages with a sparse representation. The proposed algorithm only requires a fixed-size buffer, regardless of the graph size, solving the memory issue of SCO algorithms and making it practically applicable to large graphs. The paper showed that the proposed algorithm preserves the convergence rate of the original SCO algorithm and experimentally validated that the algorithm could outperform the traditional Adam SGD for GNN training with a small memory overhead.",
    "This paper studies neighbor sampling techniques for training GNNs. Previous work has observed that sampling-based GNN training can be formulated as a Stochastic Compositional Optimization (SCO) problem. The authors argue that naive implementation of existing SCO algorithms incurs huge memory cost for training GNNs. This paper propose a Sparse Stochastic Compositional (SpSC) gradient method, which only stores the data for nodes sampled in the past few iterations. Convergence analysis on SpSC is provided and empirical results show that SpSC has better performance than naive SCO. ",
    "This paper studies the problem of training GNNs on large-scale graphs. Specifically, it proposes to use sparse moving average for sampling-based GNN training strategies. The convergence rate of the proposed approach has been proved under several assumptions. The authors conduct experiments on several large-scale datasets to show the effectiveness and efficiency of the proposal.",
    "Min-wise hashing (MinHash) is a fundamental and popular algorithm in machine learning. This paper proposes Circulant MinHash (C-MinHash) to approximate the Jaccard similarity in massive binary data. Compared with MinHash, C-MinHash only requires two (or maybe one in practice) random permutations in a circulant manner for approximation. The authors also systematically demonstrate that the C-MinHash can provide a smaller estimation variance than MinHash. Extensive experiments validate the effectiveness of C-MinHash.   ",
    "The paper designs an improved version of the classical MinHash data structure for calculating the Jaccard similarity between two binary strings.  The classical MinHash data structure generates K hash values for a binary string by generating K independent random permutations of the binary string and taking the index of the first \u201c1\u201d in the permuted string as the hash value in each random permutation. The estimator is then the percentage of equal hash values out of K hash values for the two binary strings. This is an unbiased estimator.  This paper\u2019s algorithm, called C-MinHash, first applies a random permutation to the binary string. For the K hash values, instead of using K independent random permutations, the new algorithm uses the same permutation but shifted by 1, 2, \u2026, K positions. The estimator is the same as that of the MinHash and can be easily shown to be unbiased. The paper then shows that this simple scheme, with only two independent random permutations, yields a smaller variance than that of MinHash. ",
    "This paper proposes C-MINHASH to improve vanilla MINHASH. Instead of using K random permutations to generate K hash values, C-MINHASH requires only two permutations. Theoretically, C-MINHASH provides unbiased estimate, and its variance is smaller than MINHASH. Extensive empirical experiments verify the theoretical analysis. ",
    "This paper proposes an effective approach for MinHash by permutating data vectors. It first randomly shuffles the data to break structures exhibited in the original data and then performs permutation K-times to obtain K hash values. Besides, this paper proposes an approach that performs only one permutation to compute hash values. This paper shows the theoretical approximation error of the proposed approach. By using text and image datasets, it shows that experimental results follow the results of the theoretical analysis.",
    "This paper proposes a method to produce image classifiers which are adversarially robust against multiple $\\ell_p$ threat models\u2014in particular, against $\\ell_1$, $\\ell_2$, and $\\ell_\\infty$ attacks. The method involves training against $\\ell_1$ and $\\ell_\\infty$ attacks with the hypothesis that this will additionally give robustness for $\\ell_p$ threat models with $1 \\leq p \\leq \\infty$. This hypothesis is supported by prior results that proved that affine classifiers robust to $\\ell_1$ and $\\ell_\\infty$ threat models are also be robust to other $\\ell_p$ threat models. The authors test their method on CIFAR-10 and ImageNet for both training classifiers from scratch and for fine-tuning robust models trained on one $\\ell_p$ threat model to the other $\\ell_p$ threat models.",
    "The paper tackles the problem of robustness against multiple perturbations and proposes extreme norms adversarial training (E-AT) that adaptively alternates between $\\ell_1$ and $\\ell_\\infty$-norm. Furthermore, the paper fine-tunes Gowal et al. (2020) to improve its multi-norm robustness. Finally, the experiments are conducted on CIFAR-10 and ImageNet with APGD for training, showing the proposed method's effectiveness.",
    "This paper addresses the problem of multiple perturbation adversarial robustness for attacks subsumed within $\\ell_p$ regions for $p\\in{1,2,\\infty}$. The main contribution of this work is to show how a model robust to a particular attack type (typically $\\ell_\\infty$) can be fine-tuned (at low cost) to be robust against multiple (or alternate) perturbation types. The authors build on prior formalization about the geometry of $\\ell_p$ balls (by Croce et. al.) to empirically demonstrate its effect. The results are convincing and evaluated against AutoAttack which is",
    "This paper mainly studies the problem of defending multiple norm adversarial perturbations. The authors propose extreme norms adversarial training (E-AT), which leverages different geometry of the $\\ell_{p}$-balls to conduct adversarial training by adaptively alternating between the $\\ell_{1}$ norm and $\\ell_{\\infty}$ norm. They also show that using E-AT fine-tune could turn $\\ell_{p}$ robust model into a model that is robust against the union of $\\ell_{p}$ adversarial perturbations. The authors also provide some theoretical proof for their method. ",
    "The paper propose a simple method for safe multi-task learning where there is no negative transfer or \"negative sharing\" among tasks. It jointly trains shared encoder, task-specific (private) encoders, gate, and decoder. The gate computes importance for each output of shared and task specific encoder and combine the outputs with simple convex combination. ",
    "This paper presents a multi-task learning approach that avoids negative sharing in training deep neural networks.  A novel network architecture is proposed, which consists of a public encoder shared by all the tasks, private encoder for each task, and a gate for each task to combine encoded features from public and private encoders. Their experiment results indicate the proposed approach is effective on image recognition related tasks.",
    "This paper focuses on the negative sharing problem in multi-task learning, which has not been studied sufficiently in existing work. The authors propose the Safe Multi-Task Learning (SMTL) model and several of its variants to avoid negative sharing and achieve safe multi-task learning. Both theoretical analysis and comprehensive experimental results are provided to demonstrate the effectiveness of the proposed method.",
    "This paper aims to solve the negative sharing problem, which is defined as that a multi-task learning model has inferior performance than single-task learning on some tasks, for multi-task learning. To address negative sharing, Safe Multi-Task Learning (SMTL) model is proposed. The model combines hard-sharing model and single-task learning together and is expected to achieve performance that not inferior than single-task learning. ",
    "The paper works in a computational model where various architectures of energy-based-models are viewed as computational models for accepting languages. EBM's assign a weight to each string. The sum of weights is called the partition function and this needs to be computed (or at best approximated) if the energy is to be thought of as a probability measure. The paper shows that expressive EBM's are turning complete, and uses that to show that the partition function may be uncomputable. And that is even in the case the energy of a sequence could be computed in poly-time. The paper then shows some corollaries and variations of this result, showing that model selection is undecidable as well. The paper concludes by suggesting scenarios where the partition function is computable but this naturally comes at the expense of the expressivity of the model.",
    "This theoretical work highlights uncomputability issues arising with energy-based sequence models. It is shown that an EC-complete family (a certain computational model capturing neural networks and transformers that is essentially equivalent to weighted Turing machines) cannot approximate the partition function of energy-based sequence models (EBMs) even given an unlimited amount of time and space. A consequence is the impossibility of model selection for EBMs. This paper also rules out popular estimators such as rejection and important sampling. This work concludes with a discussion of restricted EBMs that avoid such uncomputability issues. ",
    "This paper studies \"efficiently computable (EC) energy-based sequence models (EBMs)\" which are simply sets of strings equipped with nonnegative weights that can be computed by a poly-time Turing machine (upon normalization, the weights induce a probability distribution over the strings). In practice, it is common for these weights to be computed by neural networks. In fact, certain neural sequence model families like RNNs and Transformers are expressive enough to be Turing-complete. In this paper, the authors find that the expressivity of such sequence model families, so-called \"EC-complete parametric families\", comes at a significant cost in terms of *computability/decidability* of various primitives for inference. For instance, they show that if one could actually take in any vector of parameters specifying a model in such a family and output the corresponding partition function (sum of the weights of all strings) even approximately in expectation, then would be able to decide the halting problem (Theorem 2, 4). They also exhibit a single efficiently computable EBM for which proving (within ZFC) that the partition function is one of two possible values would either disprove Godel's second incompleteness theorem or disprove consistency of ZFC (Theorem 3); this can be extended to show that *asymptotic* estimates like rejection sampling and importance sampling will also fail (Theorems 5, 6). Along similar lines, they can reduce from the halting problem to other tasks like deciding whether two given parameter vectors give rise to the same EBM (\"parameter identifiability\", Theorem 7), or deciding which of two given parameter vectors gives rise to an EBM which is distributionally closer to some other given EBM (\"model selection\", Theorem 8).  In terms of techniques, the reductions from the halting problem are all based on a simple weight function that is tiny unless if the string corresponds to a valid accepting trace of an input-free Turing machine M. The point is that the weight for any string x can be computed by M simply by simulating M on x, but the partition function is large iff M halts. The ZFC results follow by taking M which enumerates all provable propositions under ZF and halts iff it proves 1 = 0.",
    "The paper studies the trade-off between expressiveness and computability (of the partition function) for energy-based sequence models. The theoretical results show that the high expressively of unrestricted energy based models comes at the cost of un-computability and in-approximability of the partition function. These negative results further show that rejection and importance sampling are not a panacea either.",
    "The paper proposes a new slice-based approach to efficiently compute the Wasserstein distance between two distributions $\\nu$ and $\\mu$. The method termed ASWD (augmented sliced Wasserstein Distance) first  projects the samples from $\\nu$ and $\\mu$ onto a higher dimensional space using a non linear injective mapping function and then uses the classical random linear projections onto 1D to compute the sliced Wasserstein Distance. Overall, the procedure amounts to applied a spatial Radon Transform to perform the slicing. Theoretical results establish conditions  under which ASWD is a metric. A numerical algorithm is given along with the design of the injective mapping using NN. Empirical evaluations on simulation datasets and on generative modeling highlight the potential of the proposed method over existing approaches.",
    "This manuscript introduces the concept of augmented sliced Wasserstein distances. The main idea is to extend the sliced Wasserstein distance based on mapping samples to higher -dimensional hypersurfaces. The proposed distance is shown to be a metric. Moreover, given that the optimal choice of the nonlinear maps is rather computationally intensive to obtain, an approximation based on neural networks is proposed. Several experiments are shown where a better performance is obtained with respect to existing methods.",
    "This paper introduces the augmented sliced Wasserstein distance (ASWD), a new variety of sliced Wasserstein distance (SWD), that allows comparing two probability distributions by combining a nonlinear embedding of the sample data points to a higher-dimensional space with a slicing scheme to calculate 1D Wasserstein distances between uniformly projection directions. The authors introduce the spatial Radon transform, which includes the standard Radon transform and the special case of polynomial generalized Random transform (introduced in Kolouri et al. 2019). They further prove that ASWD is a valid metric if and only if the mapping is injective. Several experiments are conducted on generative modelling (CIFAR10, CelebA,  MNIST, color transferring).",
    "This paper proposes a variant of sliced Wasserstein distance, named augmented sliced Wasserstein distance. ASWD maps input data points to hypersurfaces using neural networks, then calculates SWD on the hypersurfaces. ASWD alleviates the low efficiency problem of SWD for high-dimensional data. Various tasks including flow, generative modeling, and barycenters show the advantage of AWSD against some existing methods.",
    "This paper introduces a learned centralized exploration reward for multi-agent settings. The exploration reward is factorized into an on/off gate (dubbed \u2018switching control\u2019) and a scale function. Some mathematical derivations are included (sketched in the main text, with details in the appendices) to provide theoretical guarantees on how the exploration reward changes the solutions the training procedure might find. Evaluations on gridworld environments that target specific difficulties of multi-agent exploration show promising results. Some maps from the SMAC benchmark are also included, and again show good results.",
    "This paper proposes a method, Learnable Intrinsic-reward Generation Selection (LIGS) to improve coordinated exploration. LIGS incorporates an extra agent, called Generator to learn what state to give what intrinsic reward for each agent. The intrinsic reward is potential-based, so it preserves the optimality. Experimental results on several domains show its advantages over several MARL methods. ",
    "The paper describes a novel reinforcement learning algorithm for multi-agent system (MARL) that employs a generator of intrinsic reward and a switching control system that helps to regulate intrinsic control. Crucially, the intrinsic reward is learned to better fit the particular task being learned. The paper claims that the proposed algorithm helps with exploration as well as preservation of known policies. The paper has a strong theoretical background with a section that illustrates the properties of convergence and optimality. The experimental results appear to justify the approach with superior performance with respect to the baselines. The paper deals with an emerging and interesting area of RL and proposes a new mechanism for co-ordinated RL agents.  ",
    "The paper focuses on learning intrinsic rewards for multi-agent reinforcement learning, which is an important problem. Different from previous works on this topic, the authors propose to train an agent with a learnable gating function that incentives other agents. Theoretical analysis and empirical evaluation are provided to prove the effectiveness of the proposed method.",
    "The paper proposes a simple attention-based model for conversational and multi-hop QA tasks. The model use BERT-like pre-trained LM ETC separately encodes questions and paragraph (i.e., a collection of sentences). Besides the encodings on sentence-level, the final context encodings also contain extra paragraph embeddings, which are a weighted sum of sentences\u2019 encodings using a simple dot product attention. For the QA interaction, the models use a hard attention mechanism to select an entry representing either a sentence or a paragraph.  The experiments on two extractive QA datasets HYBRIDQA and QASPER show the model performs worse than the MATE model on HYBRIDQA but marginally better than other baselines on QASPER. On multi-hop QA and conversational QA tasks, the model performs marginally better than baselines on *expanded dataset*, but authors do not provide results on original datasets. ",
    "This paper introduces DocHopper, a new model for complex question answering over long documents (e.g., multi-hop QA over multiple paragraphs, conversational QA, reasoning over scientific documents). DocHopper is based on ETC (Ainslie et al., 2020) and DocHopper extends the existing hierarchical attentions from ETC with a new approach to update query representations in latent space. Their model does not jointly encode a question and context and does not require re-encoding of queries as in prior work, which leads to their effectiveness at inference time. They evaluate DocHopper on four different datasets: ShARC, QASPER, HotpotQA, and HybridQA. The proposed method achieves strong performance on those datasets, reducing the computational cost at the inference time. ",
    "The paper proposes an iterative approach for multi-hop question answering. At high-level the proposed model breaks a question into multiple sub-questions and then adds information relevant to each sub-question to the query vector for the next step retrieval. At each iteration an ETC encoder is used to encode the document and a sub-question; the vector corresponding to sub-question is then updated iteratively by contextualizing it over sentences and paragraphs in the document and is used to extract the final answer using a subsequent BERT reader. Evaluation results show improvements on 3 of 4 datasets. ",
    "This paper provides a novel MRC model (DocHopper) for multi-hop QA over long structured documents. In multi-hop QA, the evidence necessary to answer a user's question is spread across different parts of the long document. Previous approaches find the evidence by iteratively updating the user's query. The problems in these previous approaches are 1) computational efficiency and 2) ineffective modeling strategy for figuring out the relations of the evidence. DocHopper resolves these problems with a hierarchical attention mechanism. Hierarchical attention mechanism provides two types of embedding vectors for a single paragraph: 1) local sentence vectors and 2) global context vector of the paragraph. DocHopper computes the similarities between the query vectors and these sentence/paragraph vectors and selects the proper evidence. Since the sentence/paragraph vectors can be pre-computed, the only inference time required for this method is the time for question embedding, and this brings drastic improvement in the computational efficiency. This paper uses four types of datasets for evaluation: 1) conversational QA (ShARC), 2) TableQA (HybridQA), 3) QA on academic paper (QASPER), and 4) multi-hop factual QA (HotpotQA), and shows the QA performance and computational efficiency of their model.",
    "The paper proposes a label refinement approach. Starting from an initial set of labels, k-means clustering is used to refine the labels. The approach is described in the context of dubbing/voice casting. The method tries to obtain voice characteristics which can be further used for dubbing/voice-casting. Experiments are shown on video game datasets MassEffect and Skyrim and they primarily investigate how different parameters of k-means (# of clusters) and distance measure affect the label refinement. ",
    "The paper tackles a voice similarity system task for voice casting problem. The authors trained voice embedding network using voice character label and cluster the embedding features and used these clusters to train final voice embedding network. The introduction is well-written, however, the proposed method is known or marginal improvements from the existing technical skill in machine learning community (pseudo labeling with embedding feature clustering).",
    "This paper addresses the task of finding similar-sound voices with application to voice-dubbing (e.g. finding an actor to record dialog in English, translated from original French dialog, such that the English speaker sounds similar to the original French speaker). The paper proposes a method called \"label refining\". This method is based on p-vectors, a prior representation found to model similarity between characters. The method uses 1) non-expert \"initial labels\" to train a p-vector system 2) use k-means to cluster the resulting p-vectors and 3) use the groups learned by k-means to re-group the labels (the \"refined labels\"). To evaluate the method, English-French pairs of voice data from the video games Mass-Effect 3 and Skyrim are used. Performance is measured using clustering measures v-measure and purity-K, as well as accuracy on the test set (which it seems the ground-truth labels are mapping to the correct dubbing speaker). The method achieves a higher accuracy of 0.70 over a state-of-the-art system that achieves 0.69. A second experiment is performed using Skyrim data as a subsidiary corpus used to cluster, with the goal of \"bringing out vocal characteristics\" from the initial labels, which shifts the optimal K towards 2, which the paper claims is because the new representations start to model gender.",
    "The paper presents a \"label-refining\" technique, which helps users pick voices to provide a better user experience in dubbed video games. The idea is that a voice talent's voice in the target language should match the character's voice characteristics in the source language. The method seems to work by attaching labels to data-driven clusters, and refining these using a second corpus, on which the labels' value for discrimination is measured.",
    "This work is aimed at distributed \"privacy preserving\" training of neural networks for image processing tasks like deblocking, denoising, deraining, and deblurring. \"One of the most important contribution\" [pg 2] is breaking down the neural network model into task-specific convolutional head and tails (trained on \"clients\"), and a common shared (across tasks) Transformer based feature backbone, which is trained on the server. The heads/tails and the transformer backbone are trained in an alternate manner by assuming the other model to be fixed.    The proposed is similar to the method \"Splitfed\" (Thapa et al., 2020) but is extended for different tasks (as described above).  Experimental results demonstrate:  (i) successful training of the neural network models with the proposed method. (ii) better/comparable performance to prior works on distributed/privacy-preserving methods. (iii) better performance using the Vit backbone as compared to CNN backbones, and also with the proposed multi-task vs. single-task setting.",
    "In this work, the authors present a multi-task distributed learning framework called TAViT. The task-specific head CNN and the tail CNN are distributed to clients with their data connected to a standard Transformer body placed in the server. With an alternating training scheme, the heads and tails on client sides are trained by task-specific learning, while the body is trained by task-agnostic learning. Experiments on four different image processing tasks show the success of task-agnostic learning of the Transformer body and its synergistic improvement with the task-specific heads and tails.",
    "The paper presents an architecture for image processing tasks that splits up a network into three subsequent parts: head, body, and tail. Head and tail parts are CNN-based and can be trained on multiple client devices using federated learning (FedAvg), while the body part of the architecture is transformer-based and is trained on a central server. Head and tail parts are trained for specific tasks, while the body part is trained in a task-agnostic manner by selecting clients from each task for loss optimization. Experimental results show benchmark and convergence results that are comparable or favorable to non-distributed models, as well as comparison results to purely FL and SL approaches with a very small nr of clients.",
    "This paper presents a new distributed learning framework exploiting the vision transformer for various image processing applications. It gives impressive quantitative and qualitative results on multiple image restoration tasks meanwhile keeping privacy. Specifically, it employs a task-agnostic vision transformer to learn universal representation at the server, and several CNN-based task-specific heads and tails to handle different image restoration tasks at the client side. It also gives a training strategy to learn this model.",
    "This paper targets the very important problem of reward-hacking that occurs when the objectives optimized by intelligent agents are misaligned with respect to the tru objectives of the algorithm designer. The paper presents an empirical study across a range of different settings including a simple driving simulator, covid modeling, and a single atari game. The experiments show evidence of reward hacking as a function of modeling power of the agent and the size of the state-space. The paper concludes with some ideas and initial directions on how to potentially mitigate reward hacking. ",
    "This paper studies reward hacking, a common but understudied phenomenon, across a set of environments. Reward hacking emerges in several tasks, meaning that the resulting policy has a high proxy reward but a low true reward. A key finding is that reward hacking increases with agent capabilities so that increasing capability lowers the true reward. This holds across several ways of increasing capabilities (model size, training steps, action space, etc). The authors also find \u2018phase transitions\u2019 where a small increase in capability results in qualitatively new reward hacking behavior, a phenomenon that may require novel monitoring strategies. One such strategy is anomaly detection, for which the authors introduce a benchmark and baselines. ",
    "This paper provides a systematic study of \u201creward hacking\u201d in the environments with the misspecified rewards. The authors conduct a set of experiments with 4 environments, several types of reward misspecification in each of them and several agents of different expressivity (model capacity). They notice that often the agents that are more capable end up obtaining high proxy reward, but low real reward. Besides, often the transition to the low real reward happens very quickly and authors call this phenomenon \u201cphase transition\u201d. Finally, they propose a baseline for anomaly detection to identify this phase transition.",
    "This paper investigates the phenomenon of reward hacking as a function of agent capabilities. They introduce four diverse RL environments with nine misspecified rewards and demonstrate that more capable agents are better at exploiting the misspecification. They find instances of phase transitions where a small increase in agent capability produces a large change in behavior that sharply decreases the true reward.  To mitigate the reward hacking problem, they propose to set up an anomaly detection task, given a trusted model with moderate performance on the true reward, where the anomaly detector's task is to identify whether policies from a different model are satisfactory for the true reward. They provide several baseline anomaly detectors and show how they perform on different tasks. ",
    "The paper proposes a novel f-divergence Thermodynamic Variational Objective (f-TVO) framework for VI, that extends the TVO towards, a more general, family of f-divergences. The authors propose to use a $\\chi$-deformed exponential distribution, which casts the f-TVO objective as integral along the $\\chi$-path between p(x,z) and q(z|x) (rather than the geometric path in TVOs) under $\\chi$-geometry. The authors propose different variants of f-TVO, that vary between the type of the f-divergance used, as well as how this integral is approximated (K-partitioned ) left-Riemann sum (related to ELBO), right-Riemann sum (related to EUBO) or a 'zig-zag' that alternates between the two. Besides theoretical justifications, results from two sets of experiments show that, in general, the proposed f-TVO perform comparable to or slightly better than the f-VI counterparts, but without clear conclusion wrt the choice of the f-divergence.",
    "The paper presents a new bound as the objective for variational inference. The bound combines the recent progress of thermodynamic variational object which gives a tighter bound than the conventional ELBO, and the f-divergence which induces more possible distribution metrics. Experiments show its better performance on some Bayesian inference tasks.",
    "This paper proposed an $f$-divergence TVO, which includes some existing works e.g., RVB, CUBO, ELBO into a unified framework. This paper's main idea is to transform $f$-divergence into a generalized $\\chi$-exponenetial family and integral TVO along the $\\chi$-path. The paper provides some theoretical analysis and the optimization methods of the suggested framework and supports the proposed $f$-TVO with numerical results. ",
    "This paper proposed new variational inference that combines f-divergence variational inference and the thermodynamic variational objective. The authors introduced several new concepts of exponential families to extend TVO. Finally, the authors provided the estimator of the gradient of the objective function based on the reparametrization trick.",
    "This paper presents a deep reinforcement algorithm, Ensemble Deep Deterministic Policy Gradients (ED2), for continuous control tasks. The algorithm is empirically derived and is claimed to represent SotA performance on several tasks and while providing more stable results. These claims are justified based primarily on the (reward and stability) results on 4 MuJoCo environments.  ",
    "This paper has two main contributions: it introduces an ensemble-based actor-critic method, and it answers some pertinent questions in policy optimization by focusing on its different components. The ensemble is different from multi-actor learners that interact with multiple environments simultaneously, violating the standard RL setup. Instead, the learner of this paper maintains multiple actors and critics but uses only a single actor at a time to interact with the environment. All actors and critics are trained on a common replay buffer. The base method is the streamlined off-policy (SOP) method, which unlike soft actor-critic (SAC) doesn\u2019t use an entropy bonus. Additionally, no exploration noise is added, resulting in their Ensemble Deep Deterministic (ED2) method.  The proposed algorithm ED2 is shown to be superior and more stable in performance according to different measures compared to existing methods. It is also revealed that actor initialization affects performance less than critic initialization. ED2 uses deterministic actors, and its exploration comes from sampling among the actors. Such a form of exploration is also shown to be superior to UCB-style exploration. ",
    "The paper presents an empirical study evaluating the commonly accepted design choice in off-policy Deep RL algorithms in continuous control settings. The use of additive exploration noise, initialization choices, update frequency, and precision for retraining are tested empirically highlighting some interesting results. The paper also introduces ED2 - an ensemble method utilizing the design choices from the study which is demonstrated to achieve SOTA results on Mujoco benchmarks.",
    "This paper conducted an experimental study over a range of tricks that are often exploited to facilitate ensemble deep reinforcement learning. The experiment results show several interesting findings. For example, it was found that commonly used additive action noise may not be necessary for effective exploration. Meanwhile, experiments show that the initialization of critics perhaps has a higher impact on learning performance than the initialization methods adopted for actors. These findings can be quite important to guide future design of more effective ensemble reinforce learning algorithms.",
    "    This paper studies the problem of fair supervised learning under the Equalized Loss (EL) fairness notion, which is formulated as a non-convex constrained optimization problem. The authors introduce two algorithms that find the global (sub-)optimal solution by solving a sequence of convex (constrained) optimizations. Empirically, the algorithms perform well.",
    "The authors consider minimization of convex losses constrained by either bounded loss on each group, or bounded difference of losses over two groups. The second formulation is non-convex, whereas the first formulation is convex.   When the losses are strictly convex on both the demographic groups, so that their optima are distinct (I think this is the condition they need, but they use a more restrictive condition in the paper), they can find the \"EL\" fair predictor by solving a sequence of convex constrained optimizations, by exploiting a monotonicity property. They next give a more computationally efficient approximate algorithm for finding the EL fair predictor. ",
    "The authors study fair prediction subject to Equalized Loss (EL), and they introduce a variety of approaches for exactly and approximately solving the problem of finding the globally optimal predictor that satisfies EL. First, they show how to solve a sequence of convex constrained optimization problems in order to solve the larger non-convex problem. Next, they show how to approximately solve this problem more efficiently by using unconstrained convex optimization. Lastly, they evaluate both of their approaches on two datasets.",
    "This paper studies supervised learning models with fairness constraints. They specifically consider equalized loss fairness constraint.  When a traditional (convex) loss minimization problem is cast with additional fairness constraints, the corresponding problem is non-convex. They provide algorithms to efficiently solve this problem up to global optimality. They demonstrate the performance of their algorithms on real-world data. ",
    "This paper revisits the problem of neural network's systematic generalization ability from the perspective of meaningful learning, or more specifically, semantic linking. Based on this view, they propose two data augmentation methods from either the inductive learning perspective or deductive learning perspective. They train different model variants with such augmented data. The empirical results on SCAN, GEO, and ADV show that models can behave systematically. They further group some data augmentation methods on the machine translation task and semantic parsing task into the inductive or the deductive category, and show these augmentation methods can bring benefit in real data. ",
    "The paper introduces an interesting idea of improving the systematic generalization ability via meaningful learning. Through providing augmented data for inductive learning and deductive learning, the sequence-to-sequence model can be more generalizable to compositions of new concepts. It tests on real data to provide evidence of the efficacy. ",
    "This paper considers the problem of learning novel words from a few examples. The authors name their approach as \"meaningful learning,\" which, at a high level, means that we should relate the new word with existing words. The concrete technique they proposed is to use domain-specific rules to generate new data that contains novel words based on the existing examples.",
    "This paperintroduce semantic linking for systematic generalization through the analysis of inductive and deductive learning from a meaningful learning perspective. They show that both prior knowledge and semantic linking play a key role in systematic generalization, which is in line with the so-called 'meaningful learning theory'. Interesting results are attained from SCAN to real data.",
    "This paper proposes a novel 3D point cloud representation learning framework. At the core of this method, is a lifting scheme inspired by wavelet decomposition. The proposed method roughly splits the input data in half at each stage, producing a down-sampled approximation C and detail d. Then C is further processed by the next layer, forming a multiscale pyramid. In summary, the contribution of this paper is:  1. Proposed to use the lifting scheme in point cloud processing, using graph convolution networks and transformers as backbone.  2. Evaluated the method against state-of-the-art baselines and showed that the proposed scheme performs well. ",
    "This paper proposes a new 3D shape representation learning method using multi-scale wavelet decomposition. In particular, the authors introduce a neural network architecture that decomposed 3D shapes into sub-bands components at multiple scales. In particular, starting from a pointcloud the proposed model learns to decompose it into coarse (high frequency) and detail (low frequency) components using an adaptive lifting scheme, similar to the original lifting scheme introduced for defining second-generation wavelets. Subsequently, two transformer models are used to refine the coarse and approximate geometry of the 3D shape. The proposed model achieves state-of-the-art results on the shape classification task on the ModelNet40 and the ScanObjectNN dataset and on the part segmentation task on the ShapeNet Part dataset. The concept of using such an adaptive lifting scheme seems to facilitate learning and to the best of my knowledge is novel for the case of shape representation learning.",
    "This paper presents a novel framework for 3D shape representation learning, which is based on multi-scale wavelet decomposition. This is very different from existing works. A novel transformer-based neural network, AWT-Net, is also proposed.",
    "The paper presents a new deep neural network architecture for 3D point cloud representation learning, based on wavelet decomposition. In particular, the authors propose a data-driven adaptive lifting scheme that introduces non-linearity into wavelet. The original linear operators update(U) and predict(P) in wavelet decomposition are replaced by non-linear graph convolutional networks (GCN). Equipped with wavelet transform and Transformers, the proposed network aims to captures and refines the holistic and complementary geometry of 3D shapes to supplement neighboring local information. Experimental results on standard benchmarks (i.e., shape classification and part segmentation) show that it achieves state-of- the-arts or competitive performance.",
    "This paper proposes a simple yet effective method, cocktail fine-tuning, for the natural language generation tasks. Their results show that cocktail fine-tuning can handle both In-domain data and Out-of-domain data effectively by combing adapter-finetuning and full-finetuning through knowledge distillation and overall has comparable performance compared to their ensembles. It also provides theoretical analysis on multi-class logistic regression to explain why it works.",
    "This paper proposes an ensemble model between a full fine-tuning model and a parameter-efficient fine-tuning model to improve the out-of-distribution (OOD) performance of a full fine-tuning model. The proposed method is inspired by the observation that full fine-tuning model achieves good in-distribution (ID) performance while parameter-efficient finetuning model achieves better OOD performance. There are two ensembling methods presented in the paper: linear interpolation between the predictions of the two models; and distill from the predictions of a parameter-efficient model with ID training data. Improved OOD performance is observed with this ensemble method.",
    "This paper presents interesting an idea of combining lightweight fine-tuning and full fine-tuning to achieve the best of both approaches, i.e. perform best on out-of-domain and in-domain data. The authors proposed two approaches: a simple ensemble method and a so-called cocktail fine-tuning that combines two fine-tuning methods in one single model. They evaluated their tasks in three datasets: WebNLG, XSUM and OpenQA and obtained mixed results. The authors also provided good analyses for more insights. ",
    "The present paper first discusses the trade-off between performance for out-of-domain data and in-domain data with respect to whether the model is fully fine-tuned or lightweight fine-tuned on NLG tasks. Second, it argues that such a trade-off is not necessary if one can make use of both of these two fine-tuning schema in a clever way. To this end, it proposes cocktail fine-tuning, which augments full fine-tuning via distillation from a lightweight model and which achieves equal performance as an ensemble of the two fine-tuning schema. At length, this paper also explains the behavior of the cocktail fine-tuning through a toy model. ",
    "In this work, the authors propose the WARM method to help conduct iterative and interactive weakly-supervised learning. Active learning is used here to refine the labeling functions by focusing on data points that are once labeled. The authors further incorporated gradient propagation to alternatively update the LF parameters and the DP model. Experimental results show that the WARM method can improve the quality of training data.",
    "This paper proposes WARM, an active learning approach to weakly/programmatically supervised learning.  In the WARM approach, which bases off of the data programming/Snorkel paradigm for weak supervision, users write labeling functions (LFs) to programmatically label training data; these labeling functions are then modeled by the Snorkel framework for weak supervision and used to train downstream models.  In the WARM setup, these LFs are assumed to be, or cast as, differentiable.  The paper then proposes an active learning approach to sampling labeled data points to tune the parameters of these LFs, and validates this approach on several medical datasets.",
    "This paper proposes an algorithm for choosing a small set of labels to improve labeling function model performance both directly and for downstream tasks. Additionally, the authors provide a general method to convert standard labeling functions to \"soft\" labeling functions which are differentiable with respect to some parameters (e.g. a threshold). If the labeling functions are differentiable, this paper provides a method to update the labeling function parameters. Finally, experimental results show that the method introduced outperforms other active labeling approaches for weak supervision.",
    "The paper gives a method to iteratively and interactively improve the label model in weak supervision. The approach consists of two steps, first is standard weak supervision way of weighted combination of labelling functions to generate labels. Novelty and improvement mainly comes from the second step, where true label for most uncertain data point is queried using which the parameters of the labelling functions are improved, which in turn lead to a more accurate weak supervision model. A key requirement and assumption in this paper's setup is that labelling functions are given by some learnable parameters ( i.e. they can be differentiated w.r.t. their parameters), which allows parameters updates using the true labels acquired. Empirical results on various real world datasets in medical domain show that in some cases this approach can yield a more accurate model in comparison to pure active learning approach and some recent baselines which combine weak supervision with active learning. These results also show that the paper's approach can get accuracy comparable to fully supervised model as well.  ",
    "This paper proposes a novel ERM-based method for classification task with group annotated training data. The goal is to be group distributionally robust while enhancing the minority performance. The authors make an improvement to an existing method named Group-DRO by modifying the focus on the group with the highest regularized loss to focus on the group that leads to the largest decrease in average training loss. They analyze the convergence and present detailed comparisons with Group-DRO.",
    "The paper gives a new algorithm for the setup where the test distribution is different from the train distribution. The setup includes multiple groups whose information is present during the training time but not during test time and the relative proportion of these groups change during test. The most commonly used method group-DRO does distributionally robust optimization or finds a classifier which performs well on the group with worst loss. This paper proposes to focus instead on the group which leads to maximum decrease in the loss while training instead of the group which has the maximum loss. The paper present several synthetic toy cases where their approach could be useful and concludes with experiments on a variety of benchmarks for this setup and shows improved results.",
    "The paper proposes a new method for robust ML under distribution shifts. Past work has looked at formulations that minimize the worst group error. This paper adds a new twist on it and instead argues for focusing on the group that leads to the greatest decrease in average training error for all the groups. This intuition is combined into an algorithm and the paper proves that though their proposed algorithm doesn't minimize a specific loss function, it still finds first-order-stationary points. The results are shown on several synthetic datasets as well as on the WILDS Robust ML benchmark that show the superior performance of the proposed algorithm over several baselines.    Main Contributions:   1). The paper proposes a new approach for robust ML under distribution shifts that performs gradient descent not on the group with worst error but on the group which decreases the average error of all other groups.  2). Results are shown on synthetic and real-world datasets which show the superior performance of the proposed method in achieving group robustness. ",
    "The paper provides an efficient method to generalize to all groups in the presence of sub-population shifts and domain adaptation. The paper conducts extensive simulations to derive insights and also numerical experiments on the benchmark dataset to demonstrate the performance. The proposed method is intuitive, easily implemented, and has good performance.",
    "In previous studies, Shapley value has been widely used to explain model predictions, in which previous studies generally characterized importance for each feature instance separately. While some works have explored the effect of combinatorial features on prediction, no works have explored how features interact to influence each other, such as whether feature A is redundant if feature B is present.   In order to achieve this goal, this paper offers an intuitive solution. The degree of feature interaction is estimated using a matrix called a bivariate Shapley explanation map. The j-th column and i-th row of the matrix represents how feature i influences the prediction if feature j has been included. Item ij can be seen as a revised Shapley value: rather than summing up the marginal contributions of all coalitions, it only considers them when feature j appears. They then propose four different types of interactions based on this definition: least/most influential features, directional/mutual redundancy. The experimental results indicate that the proposed method can efficiently discover these four types of feature interactions. ",
    "This paper attempts to alleviate the shortcomings of existing local-feature-interaction explainers that assume symmetrical feature interactions by proposing a bivariate feature-explanation map that can capture asymmetrical (directional) feature interactions; this analysis provides evidence of mutual and directional redundancy, offering a comprehensive understanding of the features most influential for a given prediction. This proposed approach can also be instantiated using any univariate feature-based explanation method. Empirical results on image, text, and tabular data show the ability of the proposed method to accurately identify mutual and directional redundancies.",
    "This work proposed to study the directional feature interactions to explain deep models. The proposed method is a graph-based explainer and the data can be considered as graphs. Then it studies the Bivariate Shapley values to consider the directional feature interactions. Experiments on several datasets show very promising results. ",
    "In this paper, the authors generalize the univariate Shapley method to bivariate Shapley method. The authors first build a directly graph based on the asymmetric bivariate Shapley value (adding feature j to all sets contained feature i). Then several graph algorithms are applied to analyze the directly graph to derive (1) univariate feature importance available in univariate approach and (2) relations like mutually redundancy only available in bivariate approaches. Experiments on several datasets with comparison to existing methods demonstrated the superiority of the proposed method.",
    "POETREE aims to construct an interpretable model for a policy over a time series using decision trees. The healthcare domain is particularly targeted. As opposed to other works, the model directly maps observations of a POMDP to actions. POETREE creates a decision tree from time series data. The decision tree can be conditioned on the history, allowing the tree to be different at different time steps, allowing for example the tree to model that an exam done previously that is no longer informative is no longer likely. Each tree is a soft-probabilistic model first grown incrementally by developing, optimized globally (as it is differentiable), then pruned. Finally, the tree is simplified for interpretability by limiting each condition to a single variable. POETREE is then empirically evaluated and compared to baselines in terms of distribution modeling, interpretability and policy learning.",
    "  The authors argued that many methods failed the merits of interpretability in some important areas, e.g. clinical decision-making. Thus, this paper proposed a (soft) tree-based method for synthetic clinical datasets in the matter of interpretability. The authors model the clinical decision process as a partially observable Markov Decision Process (POMDP), which naturally fits the assumption of medical diagnosis.",
    "This paper proposes a novel approach for learning and representing human decision-making policies from observed behavioral data. The proposed approach emphasizes interpretability as a primary aim, while nevertheless seeking to maintain reasonable modeling accuracy. The decision tree model proposed extends canonical decision tree approaches to the probabilistic setting, allow for optimization of leaf-specific parameters via stochastic gradient descent. The proposed approach is evaluated both in terms of its interpretability (subjective measurements from a panel of licensed physicians) as well as its accuracy in recapitulating actions conditioned patient observations. The utility of the approach is demonstrated on both synthetic and real-world datasets.",
    "This paper proposes a new method to learn (stationary) interpretable policies using soft decision trees in partially observed settings. The soft decision tree structure is extended to allow for recursion over time, and account for policy decisions based on history of collected data. An algorithm is presented to optimize the parameters of the soft decision tree as well as the structure/topology of the tree. The algorithm mainly proceeds by splitting nodes and locally optimizing the parameters of the the associated probability representation of the soft node, and recursively split (if local optimization does not improve validation performance) and fixed as leaf otherwise. A global update step is then used after topology is fixed followed by pruning low probability paths in the trees. Experimental validation on surveys with clinicians demonstrate reasonable interpretability and improved prediction performance on imitating clinician policy. ",
    "This paper target the task of automatically determining the best augmentation method to obtain improved accuracy. While the previous related studies focus on the image-level augmentation and ignore the semantic information of the augmented images, the proposed algorithm augments the grid-wise patches of the given input with the preserved semantic information. To overcome the enlarged number of combinations to consider all the patches, the algorithm utilizes the MARL algorithm with the unified reward function. By MARL algorithm, the number of parameters can be reduced and the training speed can be much improved, compared to the previous auto-augmentation methods. Through the image classification and fine-grained image recognition tasks, the proposed algorithm was validated, and it shows the state-of-the-art performance among the compared methods.",
    "This paper proposes an automatic data augmentation approach. Different from existing works, they proposed to augment patches in the image rather than the whole image. The approach is formulated as a multi-agent reinforcement learning problem. They empirically show the effectiveness of their approach across several image classification datasets.",
    "This paper proposed a fine-grained automated data augmentation approach, Patch AutoAugment (PAA), which tries to increase diversity in local regions by divide an image into a grid of patches and search for the joint optimal augmentation policies for the patches. The proposed PAA considers the task as a multi-agent reinforcement learning problem,  and adopt a multi-agent reinforcement learning algorithm to automatically search for the optimal augmentation policies by considering the contextual relationship between the patches. They verify the proposed method on many classification and fine-grained recognition dataset(CIFAR10, CIFAR-100, ImageNet, CUB-200-2011, Stanford Cars and FGVC-Aircraft). The experiments show a good result and visualization results provide some insights that the PAA  help the target network to localize more class-related cues. ",
    "  The paper proposes an evolution of the traditional   pipeline of image data augmentation used to reduce ML   model overfitting.    Instead of applying transformations such as shear,   rotate, CutOut, etc. at the image level, the proposed   technique divides the images into a fixed grid and   applies a potentially different transformation to each   cell. The problem of selecting a transform for each cell   is cast as a multi-agent RL (MARL) task, and the agents   learn as the main network trains within a (multi-agent)   Advantage Actor Critic framework.    The agents use a shared reward mechanism, with the reward   defined as the difference between the loss on the   augmented sample and the original loss.    The regular grid is fixed for a dataset and   hyperparameters like the magnitude of the augmentations   follow a fixed schedule; the agents only pick _which_   augmentation to apply on a patch.    Experiments performed on CIFAR-{10,100}, ImageNet,   CUB-200-2011, Stanford Cars, and FGVC-Aircraft show   relatively small but very consistent improvements in   terms of image classification accuracy. Different design   choices (MARL vs. single-agent vs. random, grid size,   etc.) are ablated and discussed in detail. ",
    "The work presents a causal perspective of adversarial attacks on image-based machine learning models by studying a causal graph of the adversarial data creation process and highlighting how such a process makes the learned models vulnerable. It argues that the main reason for adversarial vulnerability is the reliance of models on spurious correlations between labels and style. Accordingly, it proposes a method to learn models for which the conditional distribution of label given style and image does not vary much when attacked. Empirically, the method is shown to be more robust than two baselines on three datasets.",
    "This paper presents a causal perspective on addressing adversarially vulnerability. It first constructs a causal graph, which then inspires the design of the distribution alignment method for reducing the gap between adversarial and natural data. Extensive experiments on CIFAR10, CIFAR100, and MNIST demonstrate the robustness of the proposed method against various attack methods.",
    "The paper shows a causal perspective to the adversarial robustness problem. It creates a graph over content and style variable sets. It identifies the spurious correlation between style and label as the main reason for adversarial examples, and then proposes a method to remove it from the trained model. Experiments on three datasets show that the proposed method is better than two baselines. ",
    "This paper proposes a causal graph to model the generation process of adversarial attacks. Based on the proposed causal graph, the authors identify the origin of adversarial vulnerability as the spurious correlation between style variable and class label. Under the adversarial distribution, such spurious correlation can be maliciously used to mislead a victim model. In this light, the authors propose a method to align the adversarial distribution and the natural distribution to prevent a model from learning spurious correlation. The proposed method is empirically validated on prevailing datasets under several attacks.",
    "This paper introduces a model for continual learning based on the decomposition of linear filters into low-rank components, called atoms. Specifically, the authors decompose convolutional filters shaped (c,c',k,k) into two components: i) alpha, shaped (c,c',m) and D, shaped (m,k,k). The former is learned on the first task and then frozen, whereas for D every task has its own and they are do not conflict during optimization. On top of that, the authors envision two different ensembling schemes that improve performances. i) First, in task-incremental settings, they retrieve atoms from the task of interest and from similar tasks as well (based on SVD decomposition of D matrices and Grassman distance) and ensemble them. ii) Furthermore, in class-incremental settings, they explicitly setup multiple atoms per task, building a task ensemble. During inference, all ensembles are queried and their predictive variance is used to \"discover\" the relevant task, for which a prediction is carried out. Experiments are carried out on 3 datasets in both task-incremental and class-incremental learning settings. ",
    "The paper proposes a continual learning algorithm that enforces the convolutional filter in each layer to a low-rank filter subspace defined by a small set of filter atoms. For each task, each convolutional layer is defined by a new filter subspace but subspace coefficients are shared among the tasks. The algorithm is validated on multiple benchmark datasets. ",
    "The paper, motivated by the task subspace modeling literature, enforced a low-rank filter structure to each CNN layer across time in continual learning. It not only ensures that the knowledge of the past tasks is not lost but also saves a lot of computing memory. Meanwhile, the paper proposes novel intra-task ensembles and inter-task ensembles for class-incremental settings and task-incremental settings, respectively. ",
    "This paper tackles the continual learning via enforcing a low-rank filter structure to each CNN layer.  They first perform atom-coefficient filter decomposition and then learn each task with a new filter subspace, so that the method only needs to save the new filters for each task. The contribution of this paper includes the low-rank filter scheme and the designed intra-task and inter-task model ensemble performing on the filters. The proposed method also achieves SOTA performance on several datasets with tiny size of model memory. ",
    "In this paper, the authors analyze the underestimation issue of stein variational gradient descent (SVGD), and propose the maximum mean discrepancy (MMD) descent. From the perspective of the decomposition of the gradient term (driving force and repulsive force), this paper suggested to use another driving force term instead of the original one in SVGD. But the new driving force makes MMD-descent impractical since it depends on an intractable integral of the desired distribution $p$. In addition, the paper identify the log derivative driving force as the problematic term in SVGD, and propose a modified SVGD with particle resampling. They also argue that the proportional asymptotic limit is more relevant to understanding the variance collapse phenomenon. The theoretical dimensional analysis of SVGD on Gaussian also suggested another modified (damped) SVGD.",
    "This paper provides an understanding of the variance collapse phenomenon of SVGD. The paper first (1) introduces the reader to the most important concepts and phenomena, then (2) gives an explanation for why this problem occurs, thanks to a comparison with an accurate (yet computationally intensive) algorithm they call MMD-descent. Finally (3) the paper shows how to fix SVGD with damping. The paper provides experiments and theory, nicely combined.",
    "This work studies the variance collapse phenomenon of SVGD. By comparing to MMD-descend, the authors argue that the driving force of SVGD suffers from a bias caused by reusing data, and thus tends to underestimate the variance of the target distribution. Theory are developed in the setting of estimating standard Gaussian with a proposal limit (i.e., $d/n \\to \\gamma$), and explains the understanding in the overparameterized/high-dim setting (i.e., $\\gamma > 1$). Experiments are also conducted to verify the understanding. Finally, motivated by the understanding, new algorithm is proposed to fix the issue of SVGD by damping the driving force term in SVGD.",
    "This paper analyzed the curse-of-dimensionality problem of the vanilla SVGD with Euclidean distance kernel in a qualitative and quantitative way. Specifically, the author first built a connection of SVGD to MMD-descent, where they share identical repulsive forces with different driving forces (if Euclidean distance kernel is adopted). Then, the author argued that the variance collapse problem is rooted in (1) high variance and (2) the deterministic bias of the driving force, which were confirmed by sampling from the isotropic Gaussian. Quantitatively, the author analyzed the stationary variance of MMD-descent and SVGD with isotropic Gaussian under the proportional limit, which confirms the curse-of-dimensionality problem of SVGD. ",
    "This submission empirically studies the efficacy of adversarial training for mitigating the effect of label noise in training data. Their findings are as follows: 1) \"Smoothing effect\" of adversarial training: \ta) on a 2-dimensional synthetic binary classification dataset where two points are incorrectly labeled, they show that vanilla training yields a classifier that memorizes the bad labels by forming \"clusters\" around the incorrectly labeled points, whereas adversarial training does not yield such clusters \tb) for CIFAR injected with 20/40% random label noise, they ran vanilla and adversarial training on the noisy data and found that if you look at the distribution over labels within the neighborhood of a random incorrectly labeled point, on average the entropy of that distribution is higher for the classifier obtained by adversarial training than by vanilla training 2) For vanilla training on CIFAR (also MNIST) injected with label noise, the gap between accuracy on the correctly labeled training data and the incorrectly labeled data closed over the course of training, whereas this gap does not close or seems to close much more slowly for adversarial training. 3) Over these same noisy datasets, adversarial training seems to mitigate the impact of noisy training data on (clean) test accuracy, unlike vanilla training for which generalization degrades as label noise increases 4) They consider a quantity they call the \"geometry value\" of a data point (x,y), which corresponds to the number of PGD steps needed to find a differently labeled point in the neighborhood of x. This quantity was originally introduced by [Zhang et al. 2021b], and in the present paper they find that: \ta) compared to loss(x,y), it appears to be a more effective way to effective way to distinguish correctly labeled data from incorrectly labeled training data, as well rare data from typical data 5) They propose a \"robust annotator\" for labeling unlabeled data that has possibly been subject to adversarial perturbations. The algorithm repeatedly alternates between 1) identifying training data points with high loss and low geometry value and re-labeling them according to the current classifier and 2) running a step of adversarial training. It appears to do slightly better than a PGD-based annotator baseline when trained over CIFAR injected with label noise. They also note that the geometry value can provide some kind of \"confidence score\" to go along with the label annotations.",
    "This paper studies the connection between noisy labels (NL) and adversarial training (AT). The contribution of this paper is two-fold. The first one is to adopt the number of PGD attack steps as a criterion for sample selection to correct noisy labels. The second one is that adversarial training can serve as a way to correct noisy labels. These two contributions indicate that adversarial training can be applied to more general model robustness problems.  ",
    "This paper focuses on understanding adversarial training in the presence of label noise by conducting empirical studies. Based on their observations, the authors propose to use _PGD step number_ of adversarial training as a new measure for sample selection to correct noisy labels. Moreover, they present two use-cases, namely 1. a _robust annotator_ algorithm to label unlabeled instances, and 2. PGD step number as a _confidence score_ for the labeling of unlabeled instances. Empirical observations are primarily made on CIFAR-10 images.",
    "This paper studies the adversarial training in the context of label noises. Specifically, it is discovered that adversarial training can prevent the model from overfitting to the label noises, leading to a more smooth landscape. In addition, the authors point out that the number of PGD step sizes can be considered as a useful metric to distinguish instances with correct or incorrect labels.",
    "Present a method to measure the expected robustness of a neural network model, by determining  the probability that a random input perturbation might cause misclassification, providing formal guarantees regarding the expected frequency of errors that a trained model will encounter after deployment. The method can be applied black-box. Applied the approach to compare the robustness of different models, and measure how a model\u2019s robustness is affected by the magnitude of input perturbation. ",
    "The paper presents a statistical method - Robustness Measurement and Assessment (RoMA) to measure the expected robustness of a neural network model. The robustness is defined as the probability that a random input perturbation causes an incorrect prediction. The presented approach is a blackbox approach. Different output labels are observed to exhibit different robustness values.   The basic premise of the paper is that the adversarial perturbations are not naturally normal, but a transformation (Box-Cox) can be applied to make them a normal distribution before applying statistical estimation techniques (Anderson-Darling test + z score). ",
    "This paper proposes RoMA, a robustness evaluation framework based on local sampling and probability computation.  The main contributions are: 1. Proposal of the ($\\epsilon$,$\\delta$) local robustness score for assessing the probability of random local samples that have different predictions than a given data input with a $\\delta$-confined top-1 confidence.  2. Use of Box-Cox transformation for input data to improve statistical estimation.  3. The method can be implemented in a model-agnostic fashion. ",
    "Summary:  The paper introduces a statistical method to measure the robustness of deep neural networks. The novel  part of the method is that it's designed to measure the probability of random points near an input being  adversarial, instead of probability of adversarial examples existing in the vicinity of an input. To measure it,  the authors proposes to use Box-cox transformation to transform distribution of confidence scores to normal,  then calculate the probability based on it.  ",
    "This paper presents HCM, an approach for chunking a sequence of data into a hierarchical representation. More specifically, HCM learns a tree with atomic units (ie the low-level inputs, in this case integers representing things like text characters or quantized pixel values) as the leaves and increasingly complex groupings of them higher up the tree.   HCM learns by iteratively parsing the provided data (ie stream of tokens), in each pass computing marginals for the current set of chunks as well as transition frequencies between them. After updating its marginals and transition frequencies, the two chunks with highest joint probability are combined into one. The process continues until all pairs of chunks pass an independence test.   I believe the main contribution of this paper is in that it presents an idea for interpretable grouping based on the principle of grouping by proximity from cognitive science, and a largely qualitative proof of concept for it.",
    "The paper proposes a graph-learning model (HCM) for learning hierarchical chunks from sequential data. The paper first proposes an idealised HCM method, for which the paper provides learning guarantees via a proof by induction, and an online approximation to this idealised method, which is more computationally feasible and which is used to perform experiments in temporal, visual, visuotemporal and language sequential data domains. The paper demonstrates that the online method learns interpretable chunks at multiple levels of abstraction and demonstrates positive (and negative) transfer to other hierarchically structured environments with similar (and different) structures.",
    "This paper proposes a method for learning representations of non- i.i.d. data in terms of hierarchical sets of chunks, inspired by cognitive theories of grouping by proximity. These sets are assembled over time from the initial set of primitive data points by finding correlations between temporally/spatially sequential primitives/chunks and appending to the set. The authors show that this learning method is tractable, has convergence w.r.t. hierarchically-decomposable problems, and learns intuitively and practically reasonable chunk sets.",
    "This paper proposes a non neural system of parsing natural language text by chunking sequences to form hierarchical structures. The algorithm strongly resembles classical parsing algorithms. Decisions about when to chunk a phrase into a constituent are based on chi^2 tests of independence, where a pair of chunks that are considered to be dependent are joined into a single constituent. They test this chunking algorithm on natural language data against an RNN,  concluding that the classical parsing algorithm is more sample efficient in achieving a low KL-divergence from the true sequence data. They also provide some examples of how this algorithm can be applied to temporal image data or video.",
    "This work studies the question to what extend a reparametrization of an optimization problem, i.e. representing the original parameters w to optimize for as a function of some other parameters theta, can accelerate the convergences of the gradient flow / gradient descent for nonconvex optimization problems. It studies the dynamics of the flow via eigenvectors of a matrix M formed as the expectation over the outer product of the gradient of the loss with itself to reveal 'slow' and 'fast' modes of the evolution. It subsequently derives sufficient conditions for the reparametrization (which is chosen to be linear but time varying) to balance the decay on all modes. After discussing an efficient approximation of the theoretically derived scheme, numerical results demonstrate the effectiveness of the proposed reparametrization in two exemplary applications.  ",
    "This paper proposes a reparameterization of non-linear non-convex optimization problems. This reparameterization amounts to a linear map (i.e., \"optimization params = linear operation of a different set of parameters). These linear maps are interpreted as a graph convolution network. The experimental results are validated on \"Kuramoto models\" and \"persistent homology models\".",
    "The authors derive a neural reparameterization of non-convex optimization problems in order to accelerate their convergence. They do this by deriving how the slowest components of the optimization variables can have their convergence rate improved by preconditioning with a NTK-based matrix. They make connections between this approach and Group Convolutional Networks. Experimentally, they show this approach improves upon baseline gradient-based optimization on a two datasets. ",
    "This work proposed a neural reparametrization scheme to accelerate a large class of nonconvex nonlinear optimization problems. The proposed method is grounded on analysis that the dynamics of gradient \ufb02ow are related to the condition number of the system. More specifically, by reparametrizing the optimization problem with a graph convolutional network (GNN), the proposed method can modify the condition number and obtain convergence speed up, the acceleration is demonstrated on optimizing synchronization problems and persistent homology of point-clouds.",
    "In this work auhors proposed an ensemble of multiple SVM classifiers setup in a hierarchical way (somewhat similar to neural networks). Each SVM is trained is a small patch or window from the input imagery and some classifiers can be eliminated from contributing to the predictions. Results show better performance by the model in the small data regime compared with larger convolutional neural networks trained from scratch.",
    "The paper describes the use of SVM classifiers trained independently using local receptive fields of images, outputting class probabilities for each pixel that are organized in channels. New independent SVM classifiers are trained over the class probabilities and their results are combined using voting to perform the final prediction. The authors report experiments on two datasets, comparing with versions of ResNet trained from scratch, in which SVMNet shows better results than ResNet when using fewer training examples, For one of the datasets, the ResNet could not converge, while SVMNet obtained up to 80%.",
    "The paper argues that one of the major drawbacks for deep convolutional neural networks (DCNNs) is the need for large annotated training sets. To address this drawback, the paper proposes a new architecture, SVMnet, which is designed to achieve relatively high accuracy  (compared to DCNNs) in settings of small training sets.  The SVMnet architecture is composed of one or more stacked \"SVM layers\". Each SVM layer is composed of a set of independent svm classifiers, where the input to each svm is a patch in the image and the output is a probability estimate for the image class. For example, given a grayscale h X w input image, an SVMnet with 5x5 kernels and stride of 5 would have a 2d \u201carray\u201d of h/5 X w/5 svms, each one trains on a patch of 5x5 pixels whichis flattened to a vector of 25 features. Each svm i is then trained directly to predict the class of the image, based on the 5x5 window, thus resulting in a probability vector for the 5x5 patch. From the validation step, we also obtain the average accuracy of each svm i, denoted by Ai, from which we can compute its weight when aggravating the predictions from all svms. In general each svm layer will have k X l svms, and thh output of the svm layer can be formulated either as a 2d array of k X l predictions or a 3d array of k X l X c of probabilities for each class (where c is the number of classes). When stacking a second SVM layer, the input to that layer is then the k X l X c probability map which is treated as a feature map. Finally, the predictions from the last SVM layer are tallied to produce a majority vote for the image. When training on images with multiple channels, for example RGB images, the channels are flattened to one vector, for example: a 3x5x5 patch would be flattened to a 75 dimensional feature vector.   To demonstrate the applicability of the proposed method, the paper compares SVMnet to ResNet on 3 publicly available datasets and claims to achieve superior performance to resnet in settings of limited training data as well as faster training time. ",
    "One of the weakness of traditional DCNNs is it needs large clean-labeled dataset. In this paper, the author proposes SVMNET, a deep learning architecture which includes a layered structure of Support Vector Machine (SVM) ensembles. The result shows that the SVMNET outperforms other deep convolutional neural networks such as ResNet-50 with less training time for cases in which the number of labeled training samples is small.  ",
    "The paper considers the problem of distributed training for graph learning tasks, under a setting where data privacy is significant for each individual machine and communication to/from a central parameter server is expensive. To preserve privacy each machine has only access to a distinct partition of the overall graph. The central server has access to the full graph. In the LLCG algorithm that the paper proposes, each machine trains on its local graph partition for some time before sending the parameters to the server. The server averages the received parameter, but additionally also does its own training using the full graph available to it. Theoretically the authors show that the proposed method avoids an error gap in the gradient norm that would exist if server correction is not performed. Experimental results show the proposed scheme performing similarly to GGS albeit with much lower communication costs.  ",
    "Training GNNs is challenging due to high communication costs or large memory overheads. This paper proposes a communication-efficient distributed GNN training technique named Learn Locally, Correct Globally (LLCG) to periodically model averaging on the server using locally trained models.  It also applies global server corrections to refine the locally learned models and solve the irreducible performance degradation caused by ignoring node dependency. This paper provides the convergence analysis and shows the proposed method can address the residual error. The experimental results show significant improvement compared to existing methods.",
    "This paper deals with the problem of distributed training of GNNs. Existing methods are either communication-intensive (sampling) or do not achieve good performance (averaging).  The authors propose a novel method, dubbed \"LLCG: Learn Locally Correct Globally\". Essentially, this method captures the idea of transmitting only local averages but adds a centralized step on the server to account for global structural information lost in the subgraph partition.  The authors further provide theoretical convergence guarantees. They both show that just averaging leads to an insurmountable residual error that explains the poor performance of averaging methods, as well as prove that this residual error disappears when adding the global correction step.",
    "This paper proposes a distributed training technique for GNN. This technique includes local computations done in parallel by several machines and a correction phase done by a centralized server. A theoretical analysis is given for this technique, showing that the server correction phase reduces some irreducible error that happens due to splitting the graph and doing a local computation on each subgraph. Several experiments are made on real datasets which show the merits of this technique over previous techniques in terms of performance, communication steps, and size.",
    "This work focuses on anytime pixel-level recognition (e.g., semantic segmentation). They propose to add intermediate exists in the architecture for anytime inference. They also consider spatial confidence adaptivity in their network, where they only execute subsequent layers on a small set of non-confidence pixels and obtain the features of other positions via interpolation. They apply the method to semantic segmentation and human pose estimation and demonstrate a reduction in FLOPs and good anytime performance for both tasks.   "
]