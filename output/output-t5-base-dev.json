[
    ". federated learning ( FL ) Kairouz et al. ( 2019 ) ; Konen et al. ( 2016 ) is a rapidly evolving application of distributed optimization to large-scale learning or estimation scenarios. Federated learning ( FL ) Kairouz et al. ( 2019 ) ; Konen et al. ( 2016 ). While FL offers significant practical privacy improvements, it lacks a",
    ". federated learning ( FL ) Kairouz et al. ( 2019 ) ; Konen et al. ( 2016 ) is a rapidly evolving application of distributed optimization to large-scale learning or estimation scenarios. Federated learning ( FL ) Kairouz et al. ( 2019 ) ; Konen et al. ( 2016 ). While FL offers significant practical privacy improvements, it lacks a",
    ". federated learning ( FL ) Kairouz et al. ( 2019 ) ; Konen et al. ( 2016 ) is a rapidly evolving application of distributed optimization to large-scale learning or estimation scenarios. Federated learning ( FL ) Kairouz et al. ( 2019 ) ; Konen et al. ( 2016 ). While FL offers significant practical privacy improvements, it lacks a",
    "... SAN-based neural machine translation ( NMT ) models are iteratively optimized to model language knowledge on the whole training dataset. However, SANs gradually model language knowledge on the batch-level datasets. However, SANs gradually model language knowledge on the whole training dataset. To address this issue, recent studies explored the prior knowledge which has the stringer ability to model the fluency of translation in traditional SMT ( Koehn et al",
    "... SAN-based neural machine translation ( NMT ) models are iteratively optimized to model language knowledge on the whole training dataset. However, SANs gradually model language knowledge on the batch-level datasets. However, SANs gradually model language knowledge on the whole training dataset. To address this issue, recent studies explored the prior knowledge which has the stringer ability to model the fluency of translation in traditional SMT ( Koehn et al",
    "... SAN-based neural machine translation ( NMT ) models are iteratively optimized to model language knowledge on the whole training dataset. However, SANs gradually model language knowledge on the batch-level datasets. However, SANs gradually model language knowledge on the whole training dataset. To address this issue, recent studies explored the prior knowledge which has the stringer ability to model the fluency of translation in traditional SMT ( Koehn et al",
    ".....................................................",
    ".....................................................",
    ".....................................................",
    ". In this paper, we propose a simple yet effective framework consisting of multi- ple VAEs. The framework is based on the assumption that entangled representations are unique in their own ways. Despite this trade-off, models with the same architecture and hyperparameter setting can sometimes learn entangled representations. To address this challenge, 9 we propose a simple yet effective VAE ensemble framework consisting of multi- ple VAEs. We show both theoretically",
    ". In this paper, we propose a simple yet effective framework consisting of multi- ple VAEs. The framework is based on the assumption that entangled representations are unique in their own ways. Despite this trade-off, models with the same architecture and hyperparameter setting can sometimes learn entangled representations. To address this challenge, 9 we propose a simple yet effective VAE ensemble framework consisting of multi- ple VAEs. We show both theoretically",
    ". In this paper, we propose a simple yet effective framework consisting of multi- ple VAEs. The framework is based on the assumption that entangled representations are unique in their own ways. Despite this trade-off, models with the same architecture and hyperparameter setting can sometimes learn entangled representations. To address this challenge, 9 we propose a simple yet effective VAE ensemble framework consisting of multi- ple VAEs. We show both theoretically",
    "a feature extractor ( BYU-DML, 2019 ) to represent the dataset itself. In this work we use a GNN for node prediction, which predicts the machine learning pipeline for an unseen dataset. Specifically, we use a graph attention network ( GAT ) ( Velikovi et al., 2018 ) with neighborhood aggregation. The advantage of using a GNN for node prediction, which predicts",
    "a feature extractor ( BYU-DML, 2019 ) to represent the dataset itself. In this work we use a GNN for node prediction, which predicts the machine learning pipeline for an unseen dataset. Specifically, we use a graph attention network ( GAT ) ( Velikovi et al., 2018 ) with neighborhood aggregation. The advantage of using a GNN for node prediction, which predicts",
    "a feature extractor ( BYU-DML, 2019 ) to represent the dataset itself. In this work we use a GNN for node prediction, which predicts the machine learning pipeline for an unseen dataset. Specifically, we use a graph attention network ( GAT ) ( Velikovi et al., 2018 ) with neighborhood aggregation. The advantage of using a GNN for node prediction, which predicts",
    "gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. We argue that gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. In this paper, we argue that gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. In this paper, we argue that gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. In this paper, we argue that gradient descent is one of the reasons that make",
    "gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. We argue that gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. In this paper, we argue that gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. In this paper, we argue that gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. In this paper, we argue that gradient descent is one of the reasons that make",
    "gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. We argue that gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. In this paper, we argue that gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. In this paper, we argue that gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. In this paper, we argue that gradient descent is one of the reasons that make",
    ".. However, such a margin can not guarantee to be tight enough for alignment learning. In this paper, we propose a new approach that explicitly learns KG-invariant and principled entity representations. In this sense, the model not only pursues the closeness of aligned entities on geometric distance, but also aligns the neural ontologies of two KGs to eliminate the discrepancy in feature distribution and underlying ontology knowledge. In",
    ".. However, such a margin can not guarantee to be tight enough for alignment learning. In this paper, we propose a new approach that explicitly learns KG-invariant and principled entity representations. In this sense, the model not only pursues the closeness of aligned entities on geometric distance, but also aligns the neural ontologies of two KGs to eliminate the discrepancy in feature distribution and underlying ontology knowledge. In",
    ".. However, such a margin can not guarantee to be tight enough for alignment learning. In this paper, we propose a new approach that explicitly learns KG-invariant and principled entity representations. In this sense, the model not only pursues the closeness of aligned entities on geometric distance, but also aligns the neural ontologies of two KGs to eliminate the discrepancy in feature distribution and underlying ontology knowledge. In",
    ". For the first challenge, many recent works focus on designing CNNs with improved hardware efficiency. For the second challenge, many recent works focus on designing CNNs with improved hardware efficiency. As such, a generic NAS would treat the camera as given, and only optimize the masks. Likewise, existing phase mask designs for lensless cameras treat the CNNs as given, and only optimize the masks. As such, a generic NAS would treat the camera as given,",
    ". For the first challenge, many recent works focus on designing CNNs with improved hardware efficiency. For the second challenge, many recent works focus on designing CNNs with improved hardware efficiency. As such, a generic NAS would treat the camera as given, and only optimize the masks. Likewise, existing phase mask designs for lensless cameras treat the CNNs as given, and only optimize the masks. As such, a generic NAS would treat the camera as given,",
    ". For the first challenge, many recent works focus on designing CNNs with improved hardware efficiency. For the second challenge, many recent works focus on designing CNNs with improved hardware efficiency. As such, a generic NAS would treat the camera as given, and only optimize the masks. Likewise, existing phase mask designs for lensless cameras treat the CNNs as given, and only optimize the masks. As such, a generic NAS would treat the camera as given,",
    "2018 ; ; Graving et al., 2019 ). Individuals in animal societies can be described with semantic embeddings. These embeddings are interpretable, and are useful for accomplishing downstream tasks. In temporal settings where the interaction matrices change over time, there is no straightforward extension of this algorithm. For example, the interaction matrices at different time points can be factorized individually. For example, the interaction matrice",
    "2018 ; ; Graving et al., 2019 ). Individuals in animal societies can be described with semantic embeddings. These embeddings are interpretable, and are useful for accomplishing downstream tasks. In temporal settings where the interaction matrices change over time, there is no straightforward extension of this algorithm. For example, the interaction matrices at different time points can be factorized individually. For example, the interaction matrice",
    "2018 ; ; Graving et al., 2019 ). Individuals in animal societies can be described with semantic embeddings. These embeddings are interpretable, and are useful for accomplishing downstream tasks. In temporal settings where the interaction matrices change over time, there is no straightforward extension of this algorithm. For example, the interaction matrices at different time points can be factorized individually. For example, the interaction matrice",
    ". In contrast, deep learning techniques yield significantly higher quality reconstructions. This in turn enables fewer measurements further reducing image acquisition times. While large datasets have been harvested and carefully curated by tech companies in areas such as vision and NLP, this is not feasible in many scientific applications including MRI.",
    ". In contrast, deep learning techniques yield significantly higher quality reconstructions. This in turn enables fewer measurements further reducing image acquisition times. While large datasets have been harvested and carefully curated by tech companies in areas such as vision and NLP, this is not feasible in many scientific applications including MRI.",
    ". In contrast, deep learning techniques yield significantly higher quality reconstructions. This in turn enables fewer measurements further reducing image acquisition times. While large datasets have been harvested and carefully curated by tech companies in areas such as vision and NLP, this is not feasible in many scientific applications including MRI.",
    "ordered data. Experimental results on facial age estimation, aesthetic score regression, and historical color image classification show that the proposed algorithm can cluster ordered data effectively. In order learning, the pairwise ordering relationship between objects is learned from training data. The rank of a test object is estimated by comparing it with reference objects with known ranks. However, some objects can not be easily compared. For instance, in facial age estimation, face photos are ranked according to the ages.",
    "ordered data. Experimental results on facial age estimation, aesthetic score regression, and historical color image classification show that the proposed algorithm can cluster ordered data effectively. In order learning, the pairwise ordering relationship between objects is learned from training data. The rank of a test object is estimated by comparing it with reference objects with known ranks. However, some objects can not be easily compared. For instance, in facial age estimation, face photos are ranked according to the ages.",
    "ordered data. Experimental results on facial age estimation, aesthetic score regression, and historical color image classification show that the proposed algorithm can cluster ordered data effectively. In order learning, the pairwise ordering relationship between objects is learned from training data. The rank of a test object is estimated by comparing it with reference objects with known ranks. However, some objects can not be easily compared. For instance, in facial age estimation, face photos are ranked according to the ages.",
    ". However, the sample efficiency issue remains an open challenge ( Osband et al., 2019 ). To address the above challenge, many exploration methods have been investigated and demonstrated to be effective on hard-exploration environments. One approach is to use intrinsic rewards based on uncertainty, e.g., assigning higher rewards to novel states ( Ostrovski et al., 2016 ; Guo et al., 2016 ; Zheng",
    ". However, the sample efficiency issue remains an open challenge ( Osband et al., 2019 ). To address the above challenge, many exploration methods have been investigated and demonstrated to be effective on hard-exploration environments. One approach is to use intrinsic rewards based on uncertainty, e.g., assigning higher rewards to novel states ( Ostrovski et al., 2016 ; Guo et al., 2016 ; Zheng",
    ". However, the sample efficiency issue remains an open challenge ( Osband et al., 2019 ). To address the above challenge, many exploration methods have been investigated and demonstrated to be effective on hard-exploration environments. One approach is to use intrinsic rewards based on uncertainty, e.g., assigning higher rewards to novel states ( Ostrovski et al., 2016 ; Guo et al., 2016 ; Zheng",
    "images from some training classes, ZSL aims to classify new images from unseen classes with zero training image available. However, learning to align the representation leads to overfitting on seen classes. In this paper, we propose \u201c Isometric Propagation Network ( IPN ) \u201d which learns to dynamically interact between the visual space and the semantic space. In each step, the attention scores generated in each space are distributed. In this paper, we show how IPN",
    "images from some training classes, ZSL aims to classify new images from unseen classes with zero training image available. However, learning to align the representation leads to overfitting on seen classes. In this paper, we propose \u201c Isometric Propagation Network ( IPN ) \u201d which learns to dynamically interact between the visual space and the semantic space. In each step, the attention scores generated in each space are distributed. In this paper, we show how IPN",
    "images from some training classes, ZSL aims to classify new images from unseen classes with zero training image available. However, learning to align the representation leads to overfitting on seen classes. In this paper, we propose \u201c Isometric Propagation Network ( IPN ) \u201d which learns to dynamically interact between the visual space and the semantic space. In each step, the attention scores generated in each space are distributed. In this paper, we show how IPN",
    "). However, learning multiple tasks using a single set of parameters can be challenging in many ways. Moreover, achieving state-of-the-art performance on natural language understanding benchmarks still relies on fine-tuning a single model for every single task. In this paper, we propose a new Transformer architecture, the HyperGrid Transformer. HyperGrid Transformers rely on a hypernetwork-based module that performs gridwise decomposable hyper projection",
    "). However, learning multiple tasks using a single set of parameters can be challenging in many ways. Moreover, achieving state-of-the-art performance on natural language understanding benchmarks still relies on fine-tuning a single model for every single task. In this paper, we propose a new Transformer architecture, the HyperGrid Transformer. HyperGrid Transformers rely on a hypernetwork-based module that performs gridwise decomposable hyper projection",
    "). However, learning multiple tasks using a single set of parameters can be challenging in many ways. Moreover, achieving state-of-the-art performance on natural language understanding benchmarks still relies on fine-tuning a single model for every single task. In this paper, we propose a new Transformer architecture, the HyperGrid Transformer. HyperGrid Transformers rely on a hypernetwork-based module that performs gridwise decomposable hyper projection",
    ". Using the results of sensitivity analysis, we further propose an algorithm to improve the overall performance of the task of \u201c learning to steer \u201d. In this work, we quantify the influence of varying-quality images on the task of \u201c learning to steer \u201d. The results show that our approach is able to enhance the learning outcomes up to 48 %. The results show that our approach is able to enhance the learning outcomes up to 48 %.",
    ". Using the results of sensitivity analysis, we further propose an algorithm to improve the overall performance of the task of \u201c learning to steer \u201d. In this work, we quantify the influence of varying-quality images on the task of \u201c learning to steer \u201d. The results show that our approach is able to enhance the learning outcomes up to 48 %. The results show that our approach is able to enhance the learning outcomes up to 48 %.",
    ". Using the results of sensitivity analysis, we further propose an algorithm to improve the overall performance of the task of \u201c learning to steer \u201d. In this work, we quantify the influence of varying-quality images on the task of \u201c learning to steer \u201d. The results show that our approach is able to enhance the learning outcomes up to 48 %. The results show that our approach is able to enhance the learning outcomes up to 48 %.",
    ". We then fix any violations of the inequality constraints via a differentiable correction procedure based on gradient descent. Together, this process enables feasibility with respect to all constraints. Further, this process is fully differentiable and can be incorporated into standard deep learning methods.",
    ". We then fix any violations of the inequality constraints via a differentiable correction procedure based on gradient descent. Together, this process enables feasibility with respect to all constraints. Further, this process is fully differentiable and can be incorporated into standard deep learning methods.",
    ". We then fix any violations of the inequality constraints via a differentiable correction procedure based on gradient descent. Together, this process enables feasibility with respect to all constraints. Further, this process is fully differentiable and can be incorporated into standard deep learning methods.",
    ". In contrast, regularization-based approaches typically select unimportant weights through training with a penalty term. The latter focuses on directly proposing certain theoretically sound importance criterion so that we can prune the unimportant weights once for all. Thus, the pruning process is typically one-shot. In contrast, regularization-based approaches typically select unimportant weights through training with a penalty term Han et al. ( 2015 ) ; Wen et al",
    ". In contrast, regularization-based approaches typically select unimportant weights through training with a penalty term. The latter focuses on directly proposing certain theoretically sound importance criterion so that we can prune the unimportant weights once for all. Thus, the pruning process is typically one-shot. In contrast, regularization-based approaches typically select unimportant weights through training with a penalty term Han et al. ( 2015 ) ; Wen et al",
    ". In contrast, regularization-based approaches typically select unimportant weights through training with a penalty term. The latter focuses on directly proposing certain theoretically sound importance criterion so that we can prune the unimportant weights once for all. Thus, the pruning process is typically one-shot. In contrast, regularization-based approaches typically select unimportant weights through training with a penalty term Han et al. ( 2015 ) ; Wen et al",
    "; and models can be given [ e.g., 45 ] ; and models can be given [ e.g., 45 ]. This in turn makes it difficult for practitioners to decide which form of MBRL is best for a given problem ( if any ). The aim of this paper is to assess the strengths and weaknesses of recent advances in MBRL methods.",
    "; and models can be given [ e.g., 45 ] ; and models can be given [ e.g., 45 ]. This in turn makes it difficult for practitioners to decide which form of MBRL is best for a given problem ( if any ). The aim of this paper is to assess the strengths and weaknesses of recent advances in MBRL methods.",
    "; and models can be given [ e.g., 45 ] ; and models can be given [ e.g., 45 ]. This in turn makes it difficult for practitioners to decide which form of MBRL is best for a given problem ( if any ). The aim of this paper is to assess the strengths and weaknesses of recent advances in MBRL methods.",
    ". In contrast, policy-free planning focuses on implicit planning ( also called model-free planning ). Both VINs and GVINs lift the assumption that the environment is a grid-world and allow planning on irregular discrete state spaces. Both approaches require the graph specifying the underlying Markov decision process ( MDP ) to be known in advance and are inapplicable if it is too large to be stored in memory. In addition, both approaches require the graph specifying",
    ". In contrast, policy-free planning focuses on implicit planning ( also called model-free planning ). Both VINs and GVINs lift the assumption that the environment is a grid-world and allow planning on irregular discrete state spaces. Both approaches require the graph specifying the underlying Markov decision process ( MDP ) to be known in advance and are inapplicable if it is too large to be stored in memory. In addition, both approaches require the graph specifying",
    ". In contrast, policy-free planning focuses on implicit planning ( also called model-free planning ). Both VINs and GVINs lift the assumption that the environment is a grid-world and allow planning on irregular discrete state spaces. Both approaches require the graph specifying the underlying Markov decision process ( MDP ) to be known in advance and are inapplicable if it is too large to be stored in memory. In addition, both approaches require the graph specifying",
    "the training objective of overparameterized neural networks is non-convex and contains multiple global minima with different generalization properties. In this work, we use empirical tools to analyze the inductive bias in a challenging and novel setting which is not addressed in previous theoretical works. Specifically, we use the NTK approximation of neural networks which reduces to a convex optimization problem. However, the NTK approximation is limited and does not accurately model neural networks as they are",
    "the training objective of overparameterized neural networks is non-convex and contains multiple global minima with different generalization properties. In this work, we use empirical tools to analyze the inductive bias in a challenging and novel setting which is not addressed in previous theoretical works. Specifically, we use the NTK approximation of neural networks which reduces to a convex optimization problem. However, the NTK approximation is limited and does not accurately model neural networks as they are",
    "the training objective of overparameterized neural networks is non-convex and contains multiple global minima with different generalization properties. In this work, we use empirical tools to analyze the inductive bias in a challenging and novel setting which is not addressed in previous theoretical works. Specifically, we use the NTK approximation of neural networks which reduces to a convex optimization problem. However, the NTK approximation is limited and does not accurately model neural networks as they are",
    "choosing the route with the highest return. ( C2 ) The second one is how can an RL agent effectively learn from sparse and delayed rewards. ( C1 ) The first one is how can an agent effectively learn from sparse and delayed rewards? ( C2 ) The second one is how to retrieve relevant past experiences that help to learn faster and improve sample efficiency. ( C3 ) In many real-world applications, an RL agent only has access to sparse and delayed rewards",
    "choosing the route with the highest return. ( C2 ) The second one is how can an RL agent effectively learn from sparse and delayed rewards. ( C1 ) The first one is how can an agent effectively learn from sparse and delayed rewards? ( C2 ) The second one is how to retrieve relevant past experiences that help to learn faster and improve sample efficiency. ( C3 ) In many real-world applications, an RL agent only has access to sparse and delayed rewards",
    "choosing the route with the highest return. ( C2 ) The second one is how can an RL agent effectively learn from sparse and delayed rewards. ( C1 ) The first one is how can an agent effectively learn from sparse and delayed rewards? ( C2 ) The second one is how to retrieve relevant past experiences that help to learn faster and improve sample efficiency. ( C3 ) In many real-world applications, an RL agent only has access to sparse and delayed rewards",
    ". Moreover, each level can be associated with a level identifier ( e.g. an index, a random number generator seed, etc. ) used by the PCG algorithm to generate a specific level. This allows for a clean notion of train-test split and testing on held-out levels. Unlike singleton environments, such as those in the Arcade Learning Environment benchmark ( Bellemare et al., 2013 ), PCG",
    ". Moreover, each level can be associated with a level identifier ( e.g. an index, a random number generator seed, etc. ) used by the PCG algorithm to generate a specific level. This allows for a clean notion of train-test split and testing on held-out levels. Unlike singleton environments, such as those in the Arcade Learning Environment benchmark ( Bellemare et al., 2013 ), PCG",
    ". Moreover, each level can be associated with a level identifier ( e.g. an index, a random number generator seed, etc. ) used by the PCG algorithm to generate a specific level. This allows for a clean notion of train-test split and testing on held-out levels. Unlike singleton environments, such as those in the Arcade Learning Environment benchmark ( Bellemare et al., 2013 ), PCG",
    ", 2018 ; Liu et al., 2019 ; Kornblith et al., 2019 ). Multitask learning and pretraining have transformed machine learning by allowing downstream tasks to benefit from statistical regularities from data-rich related tasks. In our work, we focus on improving generalization for a single task, the primary task, and the other tasks, and the auxiliary tasks. For that purpose, we introduce a framework which decompos",
    ", 2018 ; Liu et al., 2019 ; Kornblith et al., 2019 ). Multitask learning and pretraining have transformed machine learning by allowing downstream tasks to benefit from statistical regularities from data-rich related tasks. In our work, we focus on improving generalization for a single task, the primary task, and the other tasks, and the auxiliary tasks. For that purpose, we introduce a framework which decompos",
    ", 2018 ; Liu et al., 2019 ; Kornblith et al., 2019 ). Multitask learning and pretraining have transformed machine learning by allowing downstream tasks to benefit from statistical regularities from data-rich related tasks. In our work, we focus on improving generalization for a single task, the primary task, and the other tasks, and the auxiliary tasks. For that purpose, we introduce a framework which decompos",
    "an embodied agent situated in a 3D game environment that can learn the names of entirely unfamiliar objects in a single exposure. Moreover, the agent is reasonably robust to a degree of variation in the number of objects involved in a given fast-mapping task at test time. Moreover, the agent exhibits above-chance success when executing instructions such as \u201c put the dax in the box \u201d that depend on both slow-learned and fast-mapped word meanings.",
    "an embodied agent situated in a 3D game environment that can learn the names of entirely unfamiliar objects in a single exposure. Moreover, the agent is reasonably robust to a degree of variation in the number of objects involved in a given fast-mapping task at test time. Moreover, the agent exhibits above-chance success when executing instructions such as \u201c put the dax in the box \u201d that depend on both slow-learned and fast-mapped word meanings.",
    "an embodied agent situated in a 3D game environment that can learn the names of entirely unfamiliar objects in a single exposure. Moreover, the agent is reasonably robust to a degree of variation in the number of objects involved in a given fast-mapping task at test time. Moreover, the agent exhibits above-chance success when executing instructions such as \u201c put the dax in the box \u201d that depend on both slow-learned and fast-mapped word meanings.",
    ". Few-Shot Learning ( FSL ) aims to reduce this burden by defining a distribution over tasks. This distribution consists of a few labeled data points ( support set ) and a set of target data ( query set ) belonging to the same set of classes. However, many deep learning methods are not designed to cope with these more challenging settings. Figure 1 shows that several state-of-the-art FSL methods underperform when tested under three CI regimes",
    ". Few-Shot Learning ( FSL ) aims to reduce this burden by defining a distribution over tasks. This distribution consists of a few labeled data points ( support set ) and a set of target data ( query set ) belonging to the same set of classes. However, many deep learning methods are not designed to cope with these more challenging settings. Figure 1 shows that several state-of-the-art FSL methods underperform when tested under three CI regimes",
    ". Few-Shot Learning ( FSL ) aims to reduce this burden by defining a distribution over tasks. This distribution consists of a few labeled data points ( support set ) and a set of target data ( query set ) belonging to the same set of classes. However, many deep learning methods are not designed to cope with these more challenging settings. Figure 1 shows that several state-of-the-art FSL methods underperform when tested under three CI regimes",
    ". Moreover, interactions among GC parameters at different layers pose a bias on the flow of topological information. Therefore, existing graph neural networks are limited by ( i ) the necessity to select an appropriate convolution operator, and ( ii ) the limitation of expressiveness. In this paper, we propose the Polynomial Graph Convolution ( PGC ) layer that independently considers neighbouring nodes for each node.",
    ". Moreover, interactions among GC parameters at different layers pose a bias on the flow of topological information. Therefore, existing graph neural networks are limited by ( i ) the necessity to select an appropriate convolution operator, and ( ii ) the limitation of expressiveness. In this paper, we propose the Polynomial Graph Convolution ( PGC ) layer that independently considers neighbouring nodes for each node.",
    ". Moreover, interactions among GC parameters at different layers pose a bias on the flow of topological information. Therefore, existing graph neural networks are limited by ( i ) the necessity to select an appropriate convolution operator, and ( ii ) the limitation of expressiveness. In this paper, we propose the Polynomial Graph Convolution ( PGC ) layer that independently considers neighbouring nodes for each node.",
    ". Scene Graphs ( SGs ) in both computer vision and computer graphics are an interpretable and structural representation of scenes. A scene graph summarizes entities in the scene and plausible relationships among them. Synthetic data has been used for a variety of tasks such as image classification, object detection, object detection, object detection, 3D keypoint extraction, 3D reconstruction, etc. Synthetic data is a viable alternative to this problem since annotations are essentially free.",
    ". Scene Graphs ( SGs ) in both computer vision and computer graphics are an interpretable and structural representation of scenes. A scene graph summarizes entities in the scene and plausible relationships among them. Synthetic data has been used for a variety of tasks such as image classification, object detection, object detection, object detection, 3D keypoint extraction, 3D reconstruction, etc. Synthetic data is a viable alternative to this problem since annotations are essentially free.",
    ". Scene Graphs ( SGs ) in both computer vision and computer graphics are an interpretable and structural representation of scenes. A scene graph summarizes entities in the scene and plausible relationships among them. Synthetic data has been used for a variety of tasks such as image classification, object detection, object detection, object detection, 3D keypoint extraction, 3D reconstruction, etc. Synthetic data is a viable alternative to this problem since annotations are essentially free.",
    "20-40. Compared to Soft-Actor-Critic ( SAC ), which is model-free and uses a UTD of 1, MBPO achieves much higher sample efficiency. In this paper, we introduce a simple model-free algorithm called Randomized Ensemble Double Q learning ( REDQ ). The results indicate, that at least for the OpenAI MuJoCo benchmark, simple model-free algorithms can attain such high sample efficiency.",
    "20-40. Compared to Soft-Actor-Critic ( SAC ), which is model-free and uses a UTD of 1, MBPO achieves much higher sample efficiency. In this paper, we introduce a simple model-free algorithm called Randomized Ensemble Double Q learning ( REDQ ). The results indicate, that at least for the OpenAI MuJoCo benchmark, simple model-free algorithms can attain such high sample efficiency.",
    "20-40. Compared to Soft-Actor-Critic ( SAC ), which is model-free and uses a UTD of 1, MBPO achieves much higher sample efficiency. In this paper, we introduce a simple model-free algorithm called Randomized Ensemble Double Q learning ( REDQ ). The results indicate, that at least for the OpenAI MuJoCo benchmark, simple model-free algorithms can attain such high sample efficiency.",
    "the state of the art : DSS and DATASET2VEC architectures. On both tasks, DIDA outperforms the state of the art : DSS and DATASET2VEC architectures. On the one hand, they inherit the NN properties of universal approximation. On the other hand, they achieve invariance under permutation of the features. On both tasks, DIDA outperforms the state of the art : DSS and",
    "the state of the art : DSS and DATASET2VEC architectures. On both tasks, DIDA outperforms the state of the art : DSS and DATASET2VEC architectures. On the one hand, they inherit the NN properties of universal approximation. On the other hand, they achieve invariance under permutation of the features. On both tasks, DIDA outperforms the state of the art : DSS and",
    "the state of the art : DSS and DATASET2VEC architectures. On both tasks, DIDA outperforms the state of the art : DSS and DATASET2VEC architectures. On the one hand, they inherit the NN properties of universal approximation. On the other hand, they achieve invariance under permutation of the features. On both tasks, DIDA outperforms the state of the art : DSS and",
    "; ( Rabbat et al., 2017 ; Dong et al., 2019 ; Kalofolias & Perraudin, 2019 ). Graph learning is playing increasingly important roles in many machine learning and data mining applications. However, how to learn meaningful graphs from large data set at scale still remains a challenging problem. For example, ( Egilmez et al., 2017 ) addresses the graph learning problem by restrict",
    "; ( Rabbat et al., 2017 ; Dong et al., 2019 ; Kalofolias & Perraudin, 2019 ). Graph learning is playing increasingly important roles in many machine learning and data mining applications. However, how to learn meaningful graphs from large data set at scale still remains a challenging problem. For example, ( Egilmez et al., 2017 ) addresses the graph learning problem by restrict",
    "; ( Rabbat et al., 2017 ; Dong et al., 2019 ; Kalofolias & Perraudin, 2019 ). Graph learning is playing increasingly important roles in many machine learning and data mining applications. However, how to learn meaningful graphs from large data set at scale still remains a challenging problem. For example, ( Egilmez et al., 2017 ) addresses the graph learning problem by restrict",
    "). In this paper, we present a novel approach to reward learning ( RL ). We argue that these approaches may limit the repertoires of behaviors and impose manual learning. In this paper, we present a novel approach to reward learning ( RL ) based on a non-parametric reward function in original or embedding space as above.",
    "). In this paper, we present a novel approach to reward learning ( RL ). We argue that these approaches may limit the repertoires of behaviors and impose manual learning. In this paper, we present a novel approach to reward learning ( RL ) based on a non-parametric reward function in original or embedding space as above.",
    "). In this paper, we present a novel approach to reward learning ( RL ). We argue that these approaches may limit the repertoires of behaviors and impose manual learning. In this paper, we present a novel approach to reward learning ( RL ) based on a non-parametric reward function in original or embedding space as above.",
    "a low switching cost. In some real-world RL applications such as robotics, education, and dialogue system, changing the deployed policy frequently may cause high costs and risks. Ideally, we need this criterion to have the following four properties : 1. Low switching cost : This is the purpose of this criterion. An algorithm equipped with this criterion should have low switching cost. 2. High Reward : Since the deployed policy determines the",
    "a low switching cost. In some real-world RL applications such as robotics, education, and dialogue system, changing the deployed policy frequently may cause high costs and risks. Ideally, we need this criterion to have the following four properties : 1. Low switching cost : This is the purpose of this criterion. An algorithm equipped with this criterion should have low switching cost. 2. High Reward : Since the deployed policy determines the",
    "a low switching cost. In some real-world RL applications such as robotics, education, and dialogue system, changing the deployed policy frequently may cause high costs and risks. Ideally, we need this criterion to have the following four properties : 1. Low switching cost : This is the purpose of this criterion. An algorithm equipped with this criterion should have low switching cost. 2. High Reward : Since the deployed policy determines the",
    "fj ( w ) : = 1N N j=1 fj ( w ). This paper focuses on the theoretical development and analysis of a stochastic optimization algorithm, called Homotopy-Stochastic Gradient Descent ( H-SGD ). In particular, we assume that we only have access to noisy function values and gradients of the objective function in equation 1 via a stochastic first-order iterative algorithm.",
    "fj ( w ) : = 1N N j=1 fj ( w ). This paper focuses on the theoretical development and analysis of a stochastic optimization algorithm, called Homotopy-Stochastic Gradient Descent ( H-SGD ). In particular, we assume that we only have access to noisy function values and gradients of the objective function in equation 1 via a stochastic first-order iterative algorithm.",
    "fj ( w ) : = 1N N j=1 fj ( w ). This paper focuses on the theoretical development and analysis of a stochastic optimization algorithm, called Homotopy-Stochastic Gradient Descent ( H-SGD ). In particular, we assume that we only have access to noisy function values and gradients of the objective function in equation 1 via a stochastic first-order iterative algorithm.",
    "a novel method that enables state-of-the-art shape completion of previously unseen objects from sparse observations. In this paper we introduce a novel methodology that enables state-of-the-art shape completion of previously unseen objects from sparse observations. In popular Bayesian variants of meta-learning ( Edwards & Storkey, 2017 ; Eslami et al., 2018 ; Garnelo et al.,",
    "a novel method that enables state-of-the-art shape completion of previously unseen objects from sparse observations. In this paper we introduce a novel methodology that enables state-of-the-art shape completion of previously unseen objects from sparse observations. In popular Bayesian variants of meta-learning ( Edwards & Storkey, 2017 ; Eslami et al., 2018 ; Garnelo et al.,",
    "a novel method that enables state-of-the-art shape completion of previously unseen objects from sparse observations. In this paper we introduce a novel methodology that enables state-of-the-art shape completion of previously unseen objects from sparse observations. In popular Bayesian variants of meta-learning ( Edwards & Storkey, 2017 ; Eslami et al., 2018 ; Garnelo et al.,",
    ". Deep neural networks ( DNNs ) have become standard models for solving real-world complex problems ( He et al., 2016 ). Adversarial examples can transfer across different models ( or attacks ), raising safety concerns in autonomous driving ( Eykholt et al., 2018 ). Adversarial examples have been found to be vulnerable to adversarial examples ( or attacks ), raising safety concerns in autonomous driving ( Eykholt",
    ". Deep neural networks ( DNNs ) have become standard models for solving real-world complex problems ( He et al., 2016 ). Adversarial examples can transfer across different models ( or attacks ), raising safety concerns in autonomous driving ( Eykholt et al., 2018 ). Adversarial examples have been found to be vulnerable to adversarial examples ( or attacks ), raising safety concerns in autonomous driving ( Eykholt",
    ". Deep neural networks ( DNNs ) have become standard models for solving real-world complex problems ( He et al., 2016 ). Adversarial examples can transfer across different models ( or attacks ), raising safety concerns in autonomous driving ( Eykholt et al., 2018 ). Adversarial examples have been found to be vulnerable to adversarial examples ( or attacks ), raising safety concerns in autonomous driving ( Eykholt",
    ". Neural networks have shown excellent empirical performance in many application domains such as vision ( Krizhevsky et al., 2012 ; Rawat & Wang, 2017 ). However, such analysis, however, leads to bounds on the network width that significantly exceed practical values ( Buchanan et al., 2020 ). This motivates the following questions : \u2022 Is the kernel regime, which requires impractical bounds on the network width",
    ". Neural networks have shown excellent empirical performance in many application domains such as vision ( Krizhevsky et al., 2012 ; Rawat & Wang, 2017 ). However, such analysis, however, leads to bounds on the network width that significantly exceed practical values ( Buchanan et al., 2020 ). This motivates the following questions : \u2022 Is the kernel regime, which requires impractical bounds on the network width",
    ". Neural networks have shown excellent empirical performance in many application domains such as vision ( Krizhevsky et al., 2012 ; Rawat & Wang, 2017 ). However, such analysis, however, leads to bounds on the network width that significantly exceed practical values ( Buchanan et al., 2020 ). This motivates the following questions : \u2022 Is the kernel regime, which requires impractical bounds on the network width",
    "; Daniely, 2017 ; Daniely et al., 2019b ; Du et al., 2019a ; b ; Zou et al., 2019b ). Several recent studies have focused on shallow networks with only two layers. However, many recent results on gradient-based optimization of certain over-parameterized networks have been shown to be equivalent to kernel methods with an architecture-specific kernel ( NTK ).",
    "; Daniely, 2017 ; Daniely et al., 2019b ; Du et al., 2019a ; b ; Zou et al., 2019b ). Several recent studies have focused on shallow networks with only two layers. However, many recent results on gradient-based optimization of certain over-parameterized networks have been shown to be equivalent to kernel methods with an architecture-specific kernel ( NTK ).",
    "; Daniely, 2017 ; Daniely et al., 2019b ; Du et al., 2019a ; b ; Zou et al., 2019b ). Several recent studies have focused on shallow networks with only two layers. However, many recent results on gradient-based optimization of certain over-parameterized networks have been shown to be equivalent to kernel methods with an architecture-specific kernel ( NTK ).",
    "overestimation bias. This bias accumulates at every step via bootstrapping of temporal difference learning. When the overestimation bias is harmful to a certain task, it will cause instability, divergence and suboptimal policy updates. DDQN not only yields more accurate value estimates, but leads to much higher scores on several games Van Hasselt et al. ( 2016 ). DDQN not only yields more accurate value estimates, but",
    "overestimation bias. This bias accumulates at every step via bootstrapping of temporal difference learning. When the overestimation bias is harmful to a certain task, it will cause instability, divergence and suboptimal policy updates. DDQN not only yields more accurate value estimates, but leads to much higher scores on several games Van Hasselt et al. ( 2016 ). DDQN not only yields more accurate value estimates, but",
    "overestimation bias. This bias accumulates at every step via bootstrapping of temporal difference learning. When the overestimation bias is harmful to a certain task, it will cause instability, divergence and suboptimal policy updates. DDQN not only yields more accurate value estimates, but leads to much higher scores on several games Van Hasselt et al. ( 2016 ). DDQN not only yields more accurate value estimates, but",
    "an inverse problem that expert demonstrations determine a reward function over a Markov decision process ( MDP ) if the model dynamics are known Russell ( 1998 ) ; Ng et al. ( 2000 ). To overcome these limitations, two classes of probabilistic approaches for the IRL problem are proposed. BIRL solves for the distribution of reward functions without an assumption that experts behave optimally. MaxEnt employs the principle of maximum entropy to resolve the ambigu",
    "an inverse problem that expert demonstrations determine a reward function over a Markov decision process ( MDP ) if the model dynamics are known Russell ( 1998 ) ; Ng et al. ( 2000 ). To overcome these limitations, two classes of probabilistic approaches for the IRL problem are proposed. BIRL solves for the distribution of reward functions without an assumption that experts behave optimally. MaxEnt employs the principle of maximum entropy to resolve the ambigu",
    "an inverse problem that expert demonstrations determine a reward function over a Markov decision process ( MDP ) if the model dynamics are known Russell ( 1998 ) ; Ng et al. ( 2000 ). To overcome these limitations, two classes of probabilistic approaches for the IRL problem are proposed. BIRL solves for the distribution of reward functions without an assumption that experts behave optimally. MaxEnt employs the principle of maximum entropy to resolve the ambigu",
    ". Recent work in supervised learning with deep networks leverages unlabeled data as well as labeled data from the same distribution or a related distribution. Recent work in semi-supervised learning ( Chapelle et al., 2010 ; Doersch et al., 2015 ; Ganin et al., 2016 ; Tzeng et al., 2017 ; Shu et al., 2018 ; Zhang et al.",
    ". Recent work in supervised learning with deep networks leverages unlabeled data as well as labeled data from the same distribution or a related distribution. Recent work in semi-supervised learning ( Chapelle et al., 2010 ; Doersch et al., 2015 ; Ganin et al., 2016 ; Tzeng et al., 2017 ; Shu et al., 2018 ; Zhang et al.",
    ". Recent work in supervised learning with deep networks leverages unlabeled data as well as labeled data from the same distribution or a related distribution. Recent work in semi-supervised learning ( Chapelle et al., 2010 ; Doersch et al., 2015 ; Ganin et al., 2016 ; Tzeng et al., 2017 ; Shu et al., 2018 ; Zhang et al.",
    "; ; Denton & Fergus, 2018 ; Castrejon et al., 2019 ). Video prediction aims to generate future frames conditioned on a short video clip. Despite their success in short-term forecasting, none of these approaches have been successful in synthesizing convincing long-term future. Therefore, many hierarchical modeling approaches are proposed. These approaches first generate a sequence using a low-dimensional structure space instead of directly",
    "; ; Denton & Fergus, 2018 ; Castrejon et al., 2019 ). Video prediction aims to generate future frames conditioned on a short video clip. Despite their success in short-term forecasting, none of these approaches have been successful in synthesizing convincing long-term future. Therefore, many hierarchical modeling approaches are proposed. These approaches first generate a sequence using a low-dimensional structure space instead of directly",
    "; ; Denton & Fergus, 2018 ; Castrejon et al., 2019 ). Video prediction aims to generate future frames conditioned on a short video clip. Despite their success in short-term forecasting, none of these approaches have been successful in synthesizing convincing long-term future. Therefore, many hierarchical modeling approaches are proposed. These approaches first generate a sequence using a low-dimensional structure space instead of directly",
    ",, DGI ( Velikovi et al., 2019 ), GCNII ( Ming Chen et al., 2020 ), GCNII ( Ming Chen et al., 2020 ) and GEN ( Li et al., 2020 ). We note that the above direction based model does not consider the bidirectional mixed passing of messages. But in real life, message passing is interactive",
    ",, DGI ( Velikovi et al., 2019 ), GCNII ( Ming Chen et al., 2020 ), GCNII ( Ming Chen et al., 2020 ) and GEN ( Li et al., 2020 ). We note that the above direction based model does not consider the bidirectional mixed passing of messages. But in real life, message passing is interactive",
    ",, DGI ( Velikovi et al., 2019 ), GCNII ( Ming Chen et al., 2020 ), GCNII ( Ming Chen et al., 2020 ) and GEN ( Li et al., 2020 ). We note that the above direction based model does not consider the bidirectional mixed passing of messages. But in real life, message passing is interactive",
    ". ( 1 ) Expressive power : g should be able to model local and global dependencies between nodes and graph edges. ( 3 ) Scalability : g should be able to synthesize graphs with tens of thousands of vertices. ( 4 ) Novelty : g should produce graphs that are similar to ( but not necessarily in ) the training set. ( 1 ) is important since there exist exponentially many ways to represent the",
    ". ( 1 ) Expressive power : g should be able to model local and global dependencies between nodes and graph edges. ( 3 ) Scalability : g should be able to synthesize graphs with tens of thousands of vertices. ( 4 ) Novelty : g should produce graphs that are similar to ( but not necessarily in ) the training set. ( 1 ) is important since there exist exponentially many ways to represent the",
    ". ( 1 ) Expressive power : g should be able to model local and global dependencies between nodes and graph edges. ( 3 ) Scalability : g should be able to synthesize graphs with tens of thousands of vertices. ( 4 ) Novelty : g should produce graphs that are similar to ( but not necessarily in ) the training set. ( 1 ) is important since there exist exponentially many ways to represent the",
    "a new method that explains how the neurons in a neural network interact. In particular, we consider the activations of neurons X and Y over a given dataset. A rule thus represents that neurons X are typically active when neurons Y are. In particular, we propose to characterize these in terms of rules X  Y, where X and Y are sets of neurons in different layers of the network. Our rules are easily interpretable, show the effects of fine",
    "a new method that explains how the neurons in a neural network interact. In particular, we consider the activations of neurons X and Y over a given dataset. A rule thus represents that neurons X are typically active when neurons Y are. In particular, we propose to characterize these in terms of rules X  Y, where X and Y are sets of neurons in different layers of the network. Our rules are easily interpretable, show the effects of fine",
    "a new method that explains how the neurons in a neural network interact. In particular, we consider the activations of neurons X and Y over a given dataset. A rule thus represents that neurons X are typically active when neurons Y are. In particular, we propose to characterize these in terms of rules X  Y, where X and Y are sets of neurons in different layers of the network. Our rules are easily interpretable, show the effects of fine",
    "a dataset of transitions from an environment is used to find a policy with high return. We study worst-case guarantees on the expected return of fixed-dataset policy optimization ( FDPO ). This theoretical framework is validated by experiments on a tabular gridworld, and deep learning experiments on four MinAtar environments. Our main contribution is a theoretical justification of the pessimism principle in FDPO. We further demonstrate how this bound may be used to derive principle",
    "a dataset of transitions from an environment is used to find a policy with high return. We study worst-case guarantees on the expected return of fixed-dataset policy optimization ( FDPO ). This theoretical framework is validated by experiments on a tabular gridworld, and deep learning experiments on four MinAtar environments. Our main contribution is a theoretical justification of the pessimism principle in FDPO. We further demonstrate how this bound may be used to derive principle",
    "a dataset of transitions from an environment is used to find a policy with high return. We study worst-case guarantees on the expected return of fixed-dataset policy optimization ( FDPO ). This theoretical framework is validated by experiments on a tabular gridworld, and deep learning experiments on four MinAtar environments. Our main contribution is a theoretical justification of the pessimism principle in FDPO. We further demonstrate how this bound may be used to derive principle",
    "based on the asynchronous leapfrog ( ALF ) solver ; for time series modeling, MALI significantly outperforms the adjoint method ; for time series modeling, MALI significantly outperforms the adjoint method ; and for continuous generative models, MALI achieves new state-of-the-art performance. In this project, we provide a pypi package : https : //jzkay12.github. io",
    "based on the asynchronous leapfrog ( ALF ) solver ; for time series modeling, MALI significantly outperforms the adjoint method ; for time series modeling, MALI significantly outperforms the adjoint method ; and for continuous generative models, MALI achieves new state-of-the-art performance. In this project, we provide a pypi package : https : //jzkay12.github. io",
    "based on the asynchronous leapfrog ( ALF ) solver ; for time series modeling, MALI significantly outperforms the adjoint method ; for time series modeling, MALI significantly outperforms the adjoint method ; and for continuous generative models, MALI achieves new state-of-the-art performance. In this project, we provide a pypi package : https : //jzkay12.github. io",
    "2018 ; Miyato et al., 2018 ; Miyato et al., 2018 ; Brock et al., 2019 ). Despite recent advances in generative models ( Goodfellow et al., 2014 ; van den Oord et al., 2016b ; Vondrick et al., 2016 ; Miyato et al., 2018 ; Brock e",
    "2018 ; Miyato et al., 2018 ; Miyato et al., 2018 ; Brock et al., 2019 ). Despite recent advances in generative models ( Goodfellow et al., 2014 ; van den Oord et al., 2016b ; Vondrick et al., 2016 ; Miyato et al., 2018 ; Brock e",
    "2018 ; Miyato et al., 2018 ; Miyato et al., 2018 ; Brock et al., 2019 ). Despite recent advances in generative models ( Goodfellow et al., 2014 ; van den Oord et al., 2016b ; Vondrick et al., 2016 ; Miyato et al., 2018 ; Brock e",
    "augmented node features. In this work, we will refer to such models as Graph-Augmented MLPs ( GA-MLPs ). These models have achieved competitive performances on various tasks, and moreover enjoy better scalability since the augmented node features can be computed during preprocessing ( Rossi et al., 2020 ). In this work, we will examine what advantages GNNs have over baselines and whether they can be simplified",
    "augmented node features. In this work, we will refer to such models as Graph-Augmented MLPs ( GA-MLPs ). These models have achieved competitive performances on various tasks, and moreover enjoy better scalability since the augmented node features can be computed during preprocessing ( Rossi et al., 2020 ). In this work, we will examine what advantages GNNs have over baselines and whether they can be simplified",
    "augmented node features. In this work, we will refer to such models as Graph-Augmented MLPs ( GA-MLPs ). These models have achieved competitive performances on various tasks, and moreover enjoy better scalability since the augmented node features can be computed during preprocessing ( Rossi et al., 2020 ). In this work, we will examine what advantages GNNs have over baselines and whether they can be simplified",
    ". In reinforcement learning, the agent must act while it is learning.. with a large model capacity, the bottleneck in experiment run-times becomes actor inference.. with a large model capacity, the bottleneck in experiment run-times becomes actor inference. with a large model capacity, the bottleneck in experiment run-times becomes actor inference. with a large model capacity, the bottleneck in experiment run-times becomes actor inference.",
    ". In reinforcement learning, the agent must act while it is learning.. with a large model capacity, the bottleneck in experiment run-times becomes actor inference.. with a large model capacity, the bottleneck in experiment run-times becomes actor inference. with a large model capacity, the bottleneck in experiment run-times becomes actor inference. with a large model capacity, the bottleneck in experiment run-times becomes actor inference.",
    ". In reinforcement learning, the agent must act while it is learning.. with a large model capacity, the bottleneck in experiment run-times becomes actor inference.. with a large model capacity, the bottleneck in experiment run-times becomes actor inference. with a large model capacity, the bottleneck in experiment run-times becomes actor inference. with a large model capacity, the bottleneck in experiment run-times becomes actor inference.",
    ". This research direction is well captured by the problem of multi-domain few-shot classification. In this setting, training and test data spans a number of different domains. A promising direction to address this challenge is developing methods that are capable of performing transfer learning across the collective data of many tasks. This research direction is well captured by the problem of multi-domain few-shot classification. In this setting, training and test data span a number of different domains, each represented by a different source",
    ". This research direction is well captured by the problem of multi-domain few-shot classification. In this setting, training and test data spans a number of different domains. A promising direction to address this challenge is developing methods that are capable of performing transfer learning across the collective data of many tasks. This research direction is well captured by the problem of multi-domain few-shot classification. In this setting, training and test data span a number of different domains, each represented by a different source",
    ". This research direction is well captured by the problem of multi-domain few-shot classification. In this setting, training and test data spans a number of different domains. A promising direction to address this challenge is developing methods that are capable of performing transfer learning across the collective data of many tasks. This research direction is well captured by the problem of multi-domain few-shot classification. In this setting, training and test data span a number of different domains, each represented by a different source",
    "Lt the set of class labels the agent has seen up to time t. In the UPL context, the agent observes a sequence ( or stream ) of unlabeled data vectors  xt  tN with xt  Rn. Each vector xt is associated with a class k ( xt ) and the vectors of class k follow a distribution Fk. We assume that the distribution Fk associated with class",
    "Lt the set of class labels the agent has seen up to time t. In the UPL context, the agent observes a sequence ( or stream ) of unlabeled data vectors  xt  tN with xt  Rn. Each vector xt is associated with a class k ( xt ) and the vectors of class k follow a distribution Fk. We assume that the distribution Fk associated with class",
    "Lt the set of class labels the agent has seen up to time t. In the UPL context, the agent observes a sequence ( or stream ) of unlabeled data vectors  xt  tN with xt  Rn. Each vector xt is associated with a class k ( xt ) and the vectors of class k follow a distribution Fk. We assume that the distribution Fk associated with class",
    ". Communication overhead is sensitive to the hardware of the training systems, causing the bottleneck in efficient deep learning training. This phenomenon is poorly understood even in relatively straightforward i.i.d. data distribution scenarios. In this work, we theoretically identify the consensus distance, i.e. the consensus distance, i.e. the consensus distance, i.e. the consensus distance, i.e. the consensus distance, i.e",
    ". Communication overhead is sensitive to the hardware of the training systems, causing the bottleneck in efficient deep learning training. This phenomenon is poorly understood even in relatively straightforward i.i.d. data distribution scenarios. In this work, we theoretically identify the consensus distance, i.e. the consensus distance, i.e. the consensus distance, i.e. the consensus distance, i.e. the consensus distance, i.e",
    ". Communication overhead is sensitive to the hardware of the training systems, causing the bottleneck in efficient deep learning training. This phenomenon is poorly understood even in relatively straightforward i.i.d. data distribution scenarios. In this work, we theoretically identify the consensus distance, i.e. the consensus distance, i.e. the consensus distance, i.e. the consensus distance, i.e. the consensus distance, i.e",
    ". Metric learning aims at learning an essential component for numerous machine learning algorithms used for classification or clustering : a similarity metric. However, sequence metric learning aims at learning an essential component for numerous machine learning algorithms used for classification or clustering. Recent work mitigates these drawbacks notably with virtual metric learning ( Perrot & Habrard, 2015 ; Su & Wu, 2019 ) and soft versions of DTW.",
    ". Metric learning aims at learning an essential component for numerous machine learning algorithms used for classification or clustering : a similarity metric. However, sequence metric learning aims at learning an essential component for numerous machine learning algorithms used for classification or clustering. Recent work mitigates these drawbacks notably with virtual metric learning ( Perrot & Habrard, 2015 ; Su & Wu, 2019 ) and soft versions of DTW.",
    ". Metric learning aims at learning an essential component for numerous machine learning algorithms used for classification or clustering : a similarity metric. However, sequence metric learning aims at learning an essential component for numerous machine learning algorithms used for classification or clustering. Recent work mitigates these drawbacks notably with virtual metric learning ( Perrot & Habrard, 2015 ; Su & Wu, 2019 ) and soft versions of DTW.",
    "synchronize at each step using an optimizer such as SGD or Adam ( Kingma & Ba, 2015 ). By scaling the training of neural network models, it is possible to increase the learning rate in proportion to the number of workers. However, the linear learning rate scaling strategy leads to performance degradation for very large batch sizes ( Goyal et al., 2017 ).",
    "synchronize at each step using an optimizer such as SGD or Adam ( Kingma & Ba, 2015 ). By scaling the training of neural network models, it is possible to increase the learning rate in proportion to the number of workers. However, the linear learning rate scaling strategy leads to performance degradation for very large batch sizes ( Goyal et al., 2017 ).",
    "synchronize at each step using an optimizer such as SGD or Adam ( Kingma & Ba, 2015 ). By scaling the training of neural network models, it is possible to increase the learning rate in proportion to the number of workers. However, the linear learning rate scaling strategy leads to performance degradation for very large batch sizes ( Goyal et al., 2017 ).",
    "f ( x ) : = f ( x, S ) : = ( 1/n ) n i=1 f ( i ) ( x ) ( 1.2 ) where f ( i ) denotes the cost induced by the data point zi. The stochastic gradient descent ( SGD ) algorithm has been one of the most popular algorithms for addressing this problem. The stochastic gradient descent ( SGD",
    "f ( x ) : = f ( x, S ) : = ( 1/n ) n i=1 f ( i ) ( x ) ( 1.2 ) where f ( i ) denotes the cost induced by the data point zi. The stochastic gradient descent ( SGD ) algorithm has been one of the most popular algorithms for addressing this problem. The stochastic gradient descent ( SGD",
    "f ( x ) : = f ( x, S ) : = ( 1/n ) n i=1 f ( i ) ( x ) ( 1.2 ) where f ( i ) denotes the cost induced by the data point zi. The stochastic gradient descent ( SGD ) algorithm has been one of the most popular algorithms for addressing this problem. The stochastic gradient descent ( SGD",
    "high-frequencies of the graph Laplacian have a minor impact on the classification performances. Thus, the principles that allow GCNs to obtain good performances remain unclear. In contrast, our work actually suggests that, in the setting of community detection, graph Laplacian high-frequencies have a minor impact on the classification performances. Thus, the principles of GSP are very appealing because they allow to use the dense literature of harmonic analysis, on graphs.",
    "high-frequencies of the graph Laplacian have a minor impact on the classification performances. Thus, the principles that allow GCNs to obtain good performances remain unclear. In contrast, our work actually suggests that, in the setting of community detection, graph Laplacian high-frequencies have a minor impact on the classification performances. Thus, the principles of GSP are very appealing because they allow to use the dense literature of harmonic analysis, on graphs.",
    "high-frequencies of the graph Laplacian have a minor impact on the classification performances. Thus, the principles that allow GCNs to obtain good performances remain unclear. In contrast, our work actually suggests that, in the setting of community detection, graph Laplacian high-frequencies have a minor impact on the classification performances. Thus, the principles of GSP are very appealing because they allow to use the dense literature of harmonic analysis, on graphs.",
    "... a self-supervised task. by masking some input features and training a separate GNN. The task is generic and can be combined with several existing latent graph learning approaches.. a self-supervised task based on the hypothesis Work was done when authors were at Borealis AI. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 )..",
    "... a self-supervised task. by masking some input features and training a separate GNN. The task is generic and can be combined with several existing latent graph learning approaches.. a self-supervised task based on the hypothesis Work was done when authors were at Borealis AI. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 )..",
    "... a self-supervised task. by masking some input features and training a separate GNN. The task is generic and can be combined with several existing latent graph learning approaches.. a self-supervised task based on the hypothesis Work was done when authors were at Borealis AI. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 )..",
    "a novel unsupervised class-incremental learning problem has been introduced. it is motivated by the desire to simulate how children \u2019 s play behaviors support their ability to learn object models. the agent must conduct two procedures successfully. the first step is novelty detection : to identify whether an exposure corresponds to a class that has been learned. the second step is to identify its label such that the exposure can be leveraged to update the model. Otherwise, the novelty detection mistakes will result in label noise that distor",
    "a novel unsupervised class-incremental learning problem has been introduced. it is motivated by the desire to simulate how children \u2019 s play behaviors support their ability to learn object models. the agent must conduct two procedures successfully. the first step is novelty detection : to identify whether an exposure corresponds to a class that has been learned. the second step is to identify its label such that the exposure can be leveraged to update the model. Otherwise, the novelty detection mistakes will result in label noise that distor",
    "a novel unsupervised class-incremental learning problem has been introduced. it is motivated by the desire to simulate how children \u2019 s play behaviors support their ability to learn object models. the agent must conduct two procedures successfully. the first step is novelty detection : to identify whether an exposure corresponds to a class that has been learned. the second step is to identify its label such that the exposure can be leveraged to update the model. Otherwise, the novelty detection mistakes will result in label noise that distor",
    ". In this paper, we consider the use of natural language to specify constraints ( orthogonal to rewards ) on learning. In particular, a cleaning robot must be careful to not knock the television over, even if the television lies on the optimal path to cleaning the house. In this paper, we consider the use of natural language to specify constraints ( which are orthogonal to rewards ) on learning. We consider the use of natural language to specify constraints ( which are orthogonal to rewards )",
    ". In this paper, we consider the use of natural language to specify constraints ( orthogonal to rewards ) on learning. In particular, a cleaning robot must be careful to not knock the television over, even if the television lies on the optimal path to cleaning the house. In this paper, we consider the use of natural language to specify constraints ( which are orthogonal to rewards ) on learning. We consider the use of natural language to specify constraints ( which are orthogonal to rewards )",
    ". In this paper, we consider the use of natural language to specify constraints ( orthogonal to rewards ) on learning. In particular, a cleaning robot must be careful to not knock the television over, even if the television lies on the optimal path to cleaning the house. In this paper, we consider the use of natural language to specify constraints ( which are orthogonal to rewards ) on learning. We consider the use of natural language to specify constraints ( which are orthogonal to rewards )",
    ". In recent years, there have been significant improvements on semantic edge detection. Moreover, it is possible to train deep neural networks without massive amounts of annotated data. Recently, few-shot learning has been applied to computer vision tasks requiring highly laborious and expensive data labeling such as semantic segmentation ( Dong & Xing, 2018 ; Wang et al., 2019 ). Moreover, few-shot learning is used to train machines to learn previously uns",
    ". In recent years, there have been significant improvements on semantic edge detection. Moreover, it is possible to train deep neural networks without massive amounts of annotated data. Recently, few-shot learning has been applied to computer vision tasks requiring highly laborious and expensive data labeling such as semantic segmentation ( Dong & Xing, 2018 ; Wang et al., 2019 ). Moreover, few-shot learning is used to train machines to learn previously uns",
    ". In recent years, there have been significant improvements on semantic edge detection. Moreover, it is possible to train deep neural networks without massive amounts of annotated data. Recently, few-shot learning has been applied to computer vision tasks requiring highly laborious and expensive data labeling such as semantic segmentation ( Dong & Xing, 2018 ; Wang et al., 2019 ). Moreover, few-shot learning is used to train machines to learn previously uns",
    "; and ( 2 ) approximating the decision boundary via structure perturbations or structure masking ( Ying et al., 2019 ). In the running example, consider the example in Figure 1, where SA ( Baldassarre & Azizpour, 2019 ) and GNNExplainer ( Ying et al., 2019 ) are used. In the running example, consider the example in Figure 1, where SA ( Bal",
    "; and ( 2 ) approximating the decision boundary via structure perturbations or structure masking ( Ying et al., 2019 ). In the running example, consider the example in Figure 1, where SA ( Baldassarre & Azizpour, 2019 ) and GNNExplainer ( Ying et al., 2019 ) are used. In the running example, consider the example in Figure 1, where SA ( Bal",
    "; and ( 2 ) approximating the decision boundary via structure perturbations or structure masking ( Ying et al., 2019 ). In the running example, consider the example in Figure 1, where SA ( Baldassarre & Azizpour, 2019 ) and GNNExplainer ( Ying et al., 2019 ) are used. In the running example, consider the example in Figure 1, where SA ( Bal",
    "based on the size of the original network. This has proved non-trivial, as many measures grow with the size of the model. By understanding which factors drive generalization in neural networks we may further be able to develop more efficient and performant network architectures and training methods. While these models are already being successfully used in many applications, improving our understanding of how neural networks perform on unseen data is crucial for safety-critical use cases.",
    "based on the size of the original network. This has proved non-trivial, as many measures grow with the size of the model. By understanding which factors drive generalization in neural networks we may further be able to develop more efficient and performant network architectures and training methods. While these models are already being successfully used in many applications, improving our understanding of how neural networks perform on unseen data is crucial for safety-critical use cases.",
    "based on the size of the original network. This has proved non-trivial, as many measures grow with the size of the model. By understanding which factors drive generalization in neural networks we may further be able to develop more efficient and performant network architectures and training methods. While these models are already being successfully used in many applications, improving our understanding of how neural networks perform on unseen data is crucial for safety-critical use cases.",
    ". In this paper, we aim to learn discrete representations for high-level abstract planning from video interaction data, combined with a learned short-horizon controller. First, the relationship between the optimization objective and the true task objective is not well-defined. Second, the learning is in continuous latent space which is unstructured and difficult to combine with high-level abstract planning. In this paper, we aim to learn discrete representations for high-level abstract planning from video interaction data.",
    ". In this paper, we aim to learn discrete representations for high-level abstract planning from video interaction data, combined with a learned short-horizon controller. First, the relationship between the optimization objective and the true task objective is not well-defined. Second, the learning is in continuous latent space which is unstructured and difficult to combine with high-level abstract planning. In this paper, we aim to learn discrete representations for high-level abstract planning from video interaction data.",
    ". In this paper, we aim to learn discrete representations for high-level abstract planning from video interaction data, combined with a learned short-horizon controller. First, the relationship between the optimization objective and the true task objective is not well-defined. Second, the learning is in continuous latent space which is unstructured and difficult to combine with high-level abstract planning. In this paper, we aim to learn discrete representations for high-level abstract planning from video interaction data.",
    ". In addition, it can better utilize fixed-point processing units in mobile and edge devices to run much faster and more efficiently. To co-optimize the performance and model size, some previous pruning and factorization techniques relax the representation of model size as a differentiable regularization term R ( W ). For example, group Lasso ( Han et al., 2015b ; Wen et al., 2016 ) and DeepHoyer ( Yang e",
    ". In addition, it can better utilize fixed-point processing units in mobile and edge devices to run much faster and more efficiently. To co-optimize the performance and model size, some previous pruning and factorization techniques relax the representation of model size as a differentiable regularization term R ( W ). For example, group Lasso ( Han et al., 2015b ; Wen et al., 2016 ) and DeepHoyer ( Yang e",
    ". In addition, it can better utilize fixed-point processing units in mobile and edge devices to run much faster and more efficiently. To co-optimize the performance and model size, some previous pruning and factorization techniques relax the representation of model size as a differentiable regularization term R ( W ). For example, group Lasso ( Han et al., 2015b ; Wen et al., 2016 ) and DeepHoyer ( Yang e",
    "parameter quantized networks are vulnerable against gradient based adversarial attacks. In this work, we systematically study the robustness properties of parameter quantized networks ( BNNs ) against gradient based adversarial attacks. We first discuss the conditions to ensure informative gradients and then resort to a temperature scaling approach ( Guo et al. ( 2017 ) ) ( which scales the logits before applying softmax cross-entropy ). Our results show that, even with",
    "parameter quantized networks are vulnerable against gradient based adversarial attacks. In this work, we systematically study the robustness properties of parameter quantized networks ( BNNs ) against gradient based adversarial attacks. We first discuss the conditions to ensure informative gradients and then resort to a temperature scaling approach ( Guo et al. ( 2017 ) ) ( which scales the logits before applying softmax cross-entropy ). Our results show that, even with",
    "parameter quantized networks are vulnerable against gradient based adversarial attacks. In this work, we systematically study the robustness properties of parameter quantized networks ( BNNs ) against gradient based adversarial attacks. We first discuss the conditions to ensure informative gradients and then resort to a temperature scaling approach ( Guo et al. ( 2017 ) ) ( which scales the logits before applying softmax cross-entropy ). Our results show that, even with",
    ".. Recurrent neural networks ( DNNs ) have been widely adopted in natural language processing. However, the memory mechanism obstructs the interpretation of model decisions. In fact, the attention weights are not always intelligible. In fact, the prototype-based approaches may not be feasible in real-world applications. In fact, the prototype-based approaches may not be feasible in real-world applications. In fact, the prototype-based approaches may be",
    ".. Recurrent neural networks ( DNNs ) have been widely adopted in natural language processing. However, the memory mechanism obstructs the interpretation of model decisions. In fact, the attention weights are not always intelligible. In fact, the prototype-based approaches may not be feasible in real-world applications. In fact, the prototype-based approaches may not be feasible in real-world applications. In fact, the prototype-based approaches may be",
    ".. Recurrent neural networks ( DNNs ) have been widely adopted in natural language processing. However, the memory mechanism obstructs the interpretation of model decisions. In fact, the attention weights are not always intelligible. In fact, the prototype-based approaches may not be feasible in real-world applications. In fact, the prototype-based approaches may not be feasible in real-world applications. In fact, the prototype-based approaches may be",
    ", 2019 ). Hidden Markov models ( HMMs ) are commonly used for modeling disease progression. HMMs allow researchers to conceptualize complex ( and noisy ) clinical measurements as originating from a smaller set of latent health states. HMRNNs mimic the computation of hidden Markov models while allowing for substantial modularity with other predictive networks. In this paper, we introduce Hidden Markov Recurrent Neural Networks ( HMRNNs ) - neural networks that mimic the",
    ", 2019 ). Hidden Markov models ( HMMs ) are commonly used for modeling disease progression. HMMs allow researchers to conceptualize complex ( and noisy ) clinical measurements as originating from a smaller set of latent health states. HMRNNs mimic the computation of hidden Markov models while allowing for substantial modularity with other predictive networks. In this paper, we introduce Hidden Markov Recurrent Neural Networks ( HMRNNs ) - neural networks that mimic the",
    ", 2019 ). Hidden Markov models ( HMMs ) are commonly used for modeling disease progression. HMMs allow researchers to conceptualize complex ( and noisy ) clinical measurements as originating from a smaller set of latent health states. HMRNNs mimic the computation of hidden Markov models while allowing for substantial modularity with other predictive networks. In this paper, we introduce Hidden Markov Recurrent Neural Networks ( HMRNNs ) - neural networks that mimic the",
    "... phenotypes....... We propose a supervised learning approach that factorizes the gene expression data into components corresponding to individual phenotypes..................",
    "... phenotypes....... We propose a supervised learning approach that factorizes the gene expression data into components corresponding to individual phenotypes..................",
    "... phenotypes....... We propose a supervised learning approach that factorizes the gene expression data into components corresponding to individual phenotypes..................",
    ". Saliency maps, also called relevance maps, have been widely used for interpretability methods in classification tasks. The saliency map, also called relevance maps, has been widely used for interpretability methods in classification tasks. The saliency map, also called saliency maps, has been widely used for interpretability methods in classification tasks. The saliency map, also called saliency maps, has been widely used for interpretability methods in classification tasks.",
    ". Saliency maps, also called relevance maps, have been widely used for interpretability methods in classification tasks. The saliency map, also called relevance maps, has been widely used for interpretability methods in classification tasks. The saliency map, also called saliency maps, has been widely used for interpretability methods in classification tasks. The saliency map, also called saliency maps, has been widely used for interpretability methods in classification tasks.",
    ". Saliency maps, also called relevance maps, have been widely used for interpretability methods in classification tasks. The saliency map, also called relevance maps, has been widely used for interpretability methods in classification tasks. The saliency map, also called saliency maps, has been widely used for interpretability methods in classification tasks. The saliency map, also called saliency maps, has been widely used for interpretability methods in classification tasks.",
    ". Text encoders, which map raw-text data into low-dimensional embeddings, have become the mainstream to extract the sentence-level text representations. However, the fairness of pretrained text encoders has not received significant research attention. To quantitatively measure the bias degree of pretrained text encoders, prior work proposed several statistical tests ( Caliskan et al., 2017 ; Chaloner & Maldonado, 2019 ).",
    ". Text encoders, which map raw-text data into low-dimensional embeddings, have become the mainstream to extract the sentence-level text representations. However, the fairness of pretrained text encoders has not received significant research attention. To quantitatively measure the bias degree of pretrained text encoders, prior work proposed several statistical tests ( Caliskan et al., 2017 ; Chaloner & Maldonado, 2019 ).",
    ". Text encoders, which map raw-text data into low-dimensional embeddings, have become the mainstream to extract the sentence-level text representations. However, the fairness of pretrained text encoders has not received significant research attention. To quantitatively measure the bias degree of pretrained text encoders, prior work proposed several statistical tests ( Caliskan et al., 2017 ; Chaloner & Maldonado, 2019 ).",
    "; Athalye et al., 2018 ). The vulnerability of neural networks to adversarial examples has attracted considerable attention in safety-critical scenarios. Recently, Cohen et al. ( 2019 ) utilized a randomized smoothing technique to build robust smoothed classifiers with provable l2-robustness.",
    "; Athalye et al., 2018 ). The vulnerability of neural networks to adversarial examples has attracted considerable attention in safety-critical scenarios. Recently, Cohen et al. ( 2019 ) utilized a randomized smoothing technique to build robust smoothed classifiers with provable l2-robustness.",
    "; Athalye et al., 2018 ). The vulnerability of neural networks to adversarial examples has attracted considerable attention in safety-critical scenarios. Recently, Cohen et al. ( 2019 ) utilized a randomized smoothing technique to build robust smoothed classifiers with provable l2-robustness.",
    "automated data cleaning and recovery without any example of clean data or prior signal assumptions. In this paper, we introduce a novel variational framework to perform automated data cleaning and recovery without any example of clean data or prior signal assumptions. The TAE extends this concept to the reconstruction of data manifolds. In this paper, we introduce a novel variational framework to perform automated data cleaning and recovery without any example of clean data or prior signal assumptions. The TAE extends this concept to the reconstruction of data man",
    "automated data cleaning and recovery without any example of clean data or prior signal assumptions. In this paper, we introduce a novel variational framework to perform automated data cleaning and recovery without any example of clean data or prior signal assumptions. The TAE extends this concept to the reconstruction of data manifolds. In this paper, we introduce a novel variational framework to perform automated data cleaning and recovery without any example of clean data or prior signal assumptions. The TAE extends this concept to the reconstruction of data man",
    "automated data cleaning and recovery without any example of clean data or prior signal assumptions. In this paper, we introduce a novel variational framework to perform automated data cleaning and recovery without any example of clean data or prior signal assumptions. The TAE extends this concept to the reconstruction of data manifolds. In this paper, we introduce a novel variational framework to perform automated data cleaning and recovery without any example of clean data or prior signal assumptions. The TAE extends this concept to the reconstruction of data man",
    ",, 2019b ; Wang et al., 2019a ; Liu et al., 2019b ; Oono & Suzuki, 2020 ). Recently, the self-attention mechanism ( Velikovi et al., 2018 ; Wang et al., 2019a ; Liu et al., 2019b ; Wang et al., 2019a ; Liu",
    ",, 2019b ; Wang et al., 2019a ; Liu et al., 2019b ; Oono & Suzuki, 2020 ). Recently, the self-attention mechanism ( Velikovi et al., 2018 ; Wang et al., 2019a ; Liu et al., 2019b ; Wang et al., 2019a ; Liu",
    ",, 2019b ; Wang et al., 2019a ; Liu et al., 2019b ; Oono & Suzuki, 2020 ). Recently, the self-attention mechanism ( Velikovi et al., 2018 ; Wang et al., 2019a ; Liu et al., 2019b ; Wang et al., 2019a ; Liu",
    "performance is essentially human-level for language understanding as a whole. This suggests a disconnect between our benchmarks and the actual capabilities of these models. To bridge the gap between the wide-ranging knowledge that models see during pretraining and the existing measures of success, we introduce a new benchmark for assessing models across a diverse set of subjects that humans learn. We design the benchmark to measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the benchmark more",
    "performance is essentially human-level for language understanding as a whole. This suggests a disconnect between our benchmarks and the actual capabilities of these models. To bridge the gap between the wide-ranging knowledge that models see during pretraining and the existing measures of success, we introduce a new benchmark for assessing models across a diverse set of subjects that humans learn. We design the benchmark to measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the benchmark more",
    "performance is essentially human-level for language understanding as a whole. This suggests a disconnect between our benchmarks and the actual capabilities of these models. To bridge the gap between the wide-ranging knowledge that models see during pretraining and the existing measures of success, we introduce a new benchmark for assessing models across a diverse set of subjects that humans learn. We design the benchmark to measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the benchmark more",
    ". These advances have shifted the focus from building domain-specific semantic parsers ( LMs ) to cross-domain semantic parsing. As such tasks requires generalization to new databases/tables and more complex programs, we hypothesize that current pretrained language models are not sufficient for such tasks. Second, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a wide range of natural language processing tasks.",
    ". These advances have shifted the focus from building domain-specific semantic parsers ( LMs ) to cross-domain semantic parsing. As such tasks requires generalization to new databases/tables and more complex programs, we hypothesize that current pretrained language models are not sufficient for such tasks. Second, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a wide range of natural language processing tasks.",
    ". These advances have shifted the focus from building domain-specific semantic parsers ( LMs ) to cross-domain semantic parsing. As such tasks requires generalization to new databases/tables and more complex programs, we hypothesize that current pretrained language models are not sufficient for such tasks. Second, language models pre-trained using unstructured text data such as Wikipedia and Book Corpus are exposed to a wide range of natural language processing tasks.",
    "a deterministic limit involving simple ( small-dimensional ) statistics of the data. This article provides theoretical insights into the inner workings of multi-task and transfer learning methods. By a random matrix analysis applied to a Gaussian mixture data model, the performance of MTL LS-SVM is shown to converge, as n, p, to a deterministic limit involving simple ( small-dimensional ) statistics of the data. The latter result is",
    "a deterministic limit involving simple ( small-dimensional ) statistics of the data. This article provides theoretical insights into the inner workings of multi-task and transfer learning methods. By a random matrix analysis applied to a Gaussian mixture data model, the performance of MTL LS-SVM is shown to converge, as n, p, to a deterministic limit involving simple ( small-dimensional ) statistics of the data. The latter result is",
    "a deterministic limit involving simple ( small-dimensional ) statistics of the data. This article provides theoretical insights into the inner workings of multi-task and transfer learning methods. By a random matrix analysis applied to a Gaussian mixture data model, the performance of MTL LS-SVM is shown to converge, as n, p, to a deterministic limit involving simple ( small-dimensional ) statistics of the data. The latter result is",
    "). Inductive bias, or learning to learn, provides a way to select an inductive bias from data. In particular, meta-learning, or learning to learn, provides a way to select an inductive bias from data. In this study, we are interested in deep neural networks. In particular, a convolutional neural network, which play a significant role in the recent achievements of deep neural networks, has translation equivariance that preserves the",
    "). Inductive bias, or learning to learn, provides a way to select an inductive bias from data. In particular, meta-learning, or learning to learn, provides a way to select an inductive bias from data. In this study, we are interested in deep neural networks. In particular, a convolutional neural network, which play a significant role in the recent achievements of deep neural networks, has translation equivariance that preserves the",
    "). Inductive bias, or learning to learn, provides a way to select an inductive bias from data. In particular, meta-learning, or learning to learn, provides a way to select an inductive bias from data. In this study, we are interested in deep neural networks. In particular, a convolutional neural network, which play a significant role in the recent achievements of deep neural networks, has translation equivariance that preserves the",
    ". Second, the training loss is negative log-likelihood, whereas the evaluation is based on human judgment of the output quality. This is known as the exposure bias problem ( Husz\u00e1r et al., 2016 ; Bengio et al., 2015 ). Third, the training loss is negative log-likelihood, whereas the evaluation is based on human judgment of the output quality. In this paper, we aim to bridge",
    ". Second, the training loss is negative log-likelihood, whereas the evaluation is based on human judgment of the output quality. This is known as the exposure bias problem ( Husz\u00e1r et al., 2016 ; Bengio et al., 2015 ). Third, the training loss is negative log-likelihood, whereas the evaluation is based on human judgment of the output quality. In this paper, we aim to bridge",
    ". Second, the training loss is negative log-likelihood, whereas the evaluation is based on human judgment of the output quality. This is known as the exposure bias problem ( Husz\u00e1r et al., 2016 ; Bengio et al., 2015 ). Third, the training loss is negative log-likelihood, whereas the evaluation is based on human judgment of the output quality. In this paper, we aim to bridge",
    "gradients are propagated backward layer-by-layer to update the weights. Although being effective, this procedure may suffer from memory and computation inefficiencies. First, the entire computational graph and the activations of most, if not all, layers need to be stored. Second, E2E training is a sequential process that impedes model parallelization. The local supervised learning paradigm ( L\u00f6we et al., 2020 ; Belilovsky et",
    "gradients are propagated backward layer-by-layer to update the weights. Although being effective, this procedure may suffer from memory and computation inefficiencies. First, the entire computational graph and the activations of most, if not all, layers need to be stored. Second, E2E training is a sequential process that impedes model parallelization. The local supervised learning paradigm ( L\u00f6we et al., 2020 ; Belilovsky et",
    "gradients are propagated backward layer-by-layer to update the weights. Although being effective, this procedure may suffer from memory and computation inefficiencies. First, the entire computational graph and the activations of most, if not all, layers need to be stored. Second, E2E training is a sequential process that impedes model parallelization. The local supervised learning paradigm ( L\u00f6we et al., 2020 ; Belilovsky et",
    ".. GIN.. a graph isomorphism network ( GIN )..., 2018a )..., 2017 ).  . ..a ).a ).a ). Moreover,.......",
    ".. GIN.. a graph isomorphism network ( GIN )..., 2018a )..., 2017 ).  . ..a ).a ).a ). Moreover,.......",
    ".. GIN.. a graph isomorphism network ( GIN )..., 2018a )..., 2017 ).  . ..a ).a ).a ). Moreover,.......",
    ". In the real world, videos are susceptible to corruptions beyond the pixels, such as corrupted bit-level network and file corruptions ( Fig. 1 ). Recent work in computer vision has studied the robustness of machine learning ( ML ) models to pixel-level corruptions. In the real world, videos are susceptible to corruptions beyond the pixels, such as corrupted bit-level network and file corruptions ( Fig. 1 ).",
    ". In the real world, videos are susceptible to corruptions beyond the pixels, such as corrupted bit-level network and file corruptions ( Fig. 1 ). Recent work in computer vision has studied the robustness of machine learning ( ML ) models to pixel-level corruptions. In the real world, videos are susceptible to corruptions beyond the pixels, such as corrupted bit-level network and file corruptions ( Fig. 1 ).",
    ". In the real world, videos are susceptible to corruptions beyond the pixels, such as corrupted bit-level network and file corruptions ( Fig. 1 ). Recent work in computer vision has studied the robustness of machine learning ( ML ) models to pixel-level corruptions. In the real world, videos are susceptible to corruptions beyond the pixels, such as corrupted bit-level network and file corruptions ( Fig. 1 ).",
    ". Node and graph embeddings map nodes into low-dimensional vectors that can be used to solve downstream tasks such as edge prediction, network reconstruction and node classification. The manual and automatic collection of time-resolved proximity graphs for contact tracing purposes presents an opportunity for quick identification of possible infection clusters and infection chains. The use of wearable proximity sensors for collecting time-resolved proximity graphs for contact tracing purposes has been largely discussed in the literature.",
    ". Node and graph embeddings map nodes into low-dimensional vectors that can be used to solve downstream tasks such as edge prediction, network reconstruction and node classification. The manual and automatic collection of time-resolved proximity graphs for contact tracing purposes presents an opportunity for quick identification of possible infection clusters and infection chains. The use of wearable proximity sensors for collecting time-resolved proximity graphs for contact tracing purposes has been largely discussed in the literature.",
    ". Node and graph embeddings map nodes into low-dimensional vectors that can be used to solve downstream tasks such as edge prediction, network reconstruction and node classification. The manual and automatic collection of time-resolved proximity graphs for contact tracing purposes presents an opportunity for quick identification of possible infection clusters and infection chains. The use of wearable proximity sensors for collecting time-resolved proximity graphs for contact tracing purposes has been largely discussed in the literature.",
    "self-supervised language modeling applied to mathematical formulas enables logical reasoning. This is a major departure from prior work in deep learning for mathematics. These approaches require labeled data, which is hard to come by and typically very limited in size. In contrast, our language modeling approach to mathematics allows us to train on unlabeled mathematical expressions. We start with the HOList dataset ( Bansal et al., 2019 ).",
    "self-supervised language modeling applied to mathematical formulas enables logical reasoning. This is a major departure from prior work in deep learning for mathematics. These approaches require labeled data, which is hard to come by and typically very limited in size. In contrast, our language modeling approach to mathematics allows us to train on unlabeled mathematical expressions. We start with the HOList dataset ( Bansal et al., 2019 ).",
    "self-supervised language modeling applied to mathematical formulas enables logical reasoning. This is a major departure from prior work in deep learning for mathematics. These approaches require labeled data, which is hard to come by and typically very limited in size. In contrast, our language modeling approach to mathematics allows us to train on unlabeled mathematical expressions. We start with the HOList dataset ( Bansal et al., 2019 ).",
    "robustness may still be overestimated even when there are no obfuscated gradients. In this work, we identify a new situation called Imbalanced Gradients that exists in several state-of-the-art defense models. Imbalanced gradients is a new type of gradient masking effect where the gradient of one loss term dominates that of other terms. Imbalanced gradients is a new type of gradient masking effect where the gradient of one loss",
    "robustness may still be overestimated even when there are no obfuscated gradients. In this work, we identify a new situation called Imbalanced Gradients that exists in several state-of-the-art defense models. Imbalanced gradients is a new type of gradient masking effect where the gradient of one loss term dominates that of other terms. Imbalanced gradients is a new type of gradient masking effect where the gradient of one loss",
    "robustness may still be overestimated even when there are no obfuscated gradients. In this work, we identify a new situation called Imbalanced Gradients that exists in several state-of-the-art defense models. Imbalanced gradients is a new type of gradient masking effect where the gradient of one loss term dominates that of other terms. Imbalanced gradients is a new type of gradient masking effect where the gradient of one loss",
    "the first graph-to-sequence deep learning system to generate proofs of semantic equivalence between two program pairs. We generate expressions which include scalars, vectors and matrices, and 16 distinct operators combining them. We demonstrate our system on expressions from a rich multi-type symbolic language for linear algebra. In this work we target the problem of automatically computing whether two input programs are semantically equivalent ( Kaplan, 1969 ), under",
    "the first graph-to-sequence deep learning system to generate proofs of semantic equivalence between two program pairs. We generate expressions which include scalars, vectors and matrices, and 16 distinct operators combining them. We demonstrate our system on expressions from a rich multi-type symbolic language for linear algebra. In this work we target the problem of automatically computing whether two input programs are semantically equivalent ( Kaplan, 1969 ), under",
    "the first graph-to-sequence deep learning system to generate proofs of semantic equivalence between two program pairs. We generate expressions which include scalars, vectors and matrices, and 16 distinct operators combining them. We demonstrate our system on expressions from a rich multi-type symbolic language for linear algebra. In this work we target the problem of automatically computing whether two input programs are semantically equivalent ( Kaplan, 1969 ), under",
    "2018 ). Currently, existing approaches learn localized representations from short videos, capturing only short-term dependencies in data. However, existing approaches learn localized representations from short videos, capturing only short-term dependencies in data. However, existing approaches learn localized representations from short videos, capturing only short-term dependencies in data.",
    "2018 ). Currently, existing approaches learn localized representations from short videos, capturing only short-term dependencies in data. However, existing approaches learn localized representations from short videos, capturing only short-term dependencies in data. However, existing approaches learn localized representations from short videos, capturing only short-term dependencies in data.",
    "2018 ). Currently, existing approaches learn localized representations from short videos, capturing only short-term dependencies in data. However, existing approaches learn localized representations from short videos, capturing only short-term dependencies in data. However, existing approaches learn localized representations from short videos, capturing only short-term dependencies in data.",
    ".. We propose a novel paradigm, online contextualized few-shot learning, that approximates the naturalistic conditions that humans and artificial agents encounter as they wander within a physical environment. In this article, we propose a novel paradigm, online contextualized few-shot learning, that approximates these naturalistic conditions. Furthermore, we develop deep-learning architectures well suited for this setting.",
    ".. We propose a novel paradigm, online contextualized few-shot learning, that approximates the naturalistic conditions that humans and artificial agents encounter as they wander within a physical environment. In this article, we propose a novel paradigm, online contextualized few-shot learning, that approximates these naturalistic conditions. Furthermore, we develop deep-learning architectures well suited for this setting.",
    ".. We propose a novel paradigm, online contextualized few-shot learning, that approximates the naturalistic conditions that humans and artificial agents encounter as they wander within a physical environment. In this article, we propose a novel paradigm, online contextualized few-shot learning, that approximates these naturalistic conditions. Furthermore, we develop deep-learning architectures well suited for this setting.",
    ". Second, as new vertices and edges appear ( and disappear ) over time, so can new classes. Third, as new vertices and edges appear ( and disappear ) over time, so can new classes. Fourth, as new vertices and edges appear ( and disappear ) over time, so can new classes. Fourth, as new vertices and edges appear ( and disappear ) over time, so can new classes. Fifth",
    ". Second, as new vertices and edges appear ( and disappear ) over time, so can new classes. Third, as new vertices and edges appear ( and disappear ) over time, so can new classes. Fourth, as new vertices and edges appear ( and disappear ) over time, so can new classes. Fourth, as new vertices and edges appear ( and disappear ) over time, so can new classes. Fifth",
    ". Second, as new vertices and edges appear ( and disappear ) over time, so can new classes. Third, as new vertices and edges appear ( and disappear ) over time, so can new classes. Fourth, as new vertices and edges appear ( and disappear ) over time, so can new classes. Fourth, as new vertices and edges appear ( and disappear ) over time, so can new classes. Fifth",
    ". For example, an agent might pay more attention to the change of irrelevant background rather than noticing the obstacles or enemies ( Song et al. ( 2019 ) ). For example, an agent might pay more attention to the change of irrelevant background rather than noticing the change of irrelevant background. For example, an agent might pay more attention to the change of irrelevant background rather than noticing the obstacles or enemies ( Song et al. ( 2019 ) ). However,",
    ". For example, an agent might pay more attention to the change of irrelevant background rather than noticing the obstacles or enemies ( Song et al. ( 2019 ) ). For example, an agent might pay more attention to the change of irrelevant background rather than noticing the change of irrelevant background. For example, an agent might pay more attention to the change of irrelevant background rather than noticing the obstacles or enemies ( Song et al. ( 2019 ) ). However,",
    ". For example, an agent might pay more attention to the change of irrelevant background rather than noticing the obstacles or enemies ( Song et al. ( 2019 ) ). For example, an agent might pay more attention to the change of irrelevant background rather than noticing the change of irrelevant background. For example, an agent might pay more attention to the change of irrelevant background rather than noticing the obstacles or enemies ( Song et al. ( 2019 ) ). However,",
    "a greedy adversarial attack strategy can significantly degrade GNN performance under adversarial attacks. In particular, Ma et al. ( 2020 ) examine an extremely restricted nearblack-box attack scenario where the attacker has access to neither model parameters nor model predictions. In addition, the research about adversarial attacks on GNNs in turn helps us better understand the intrinsic properties of existing GNN models.",
    "a greedy adversarial attack strategy can significantly degrade GNN performance under adversarial attacks. In particular, Ma et al. ( 2020 ) examine an extremely restricted nearblack-box attack scenario where the attacker has access to neither model parameters nor model predictions. In addition, the research about adversarial attacks on GNNs in turn helps us better understand the intrinsic properties of existing GNN models.",
    "a greedy adversarial attack strategy can significantly degrade GNN performance under adversarial attacks. In particular, Ma et al. ( 2020 ) examine an extremely restricted nearblack-box attack scenario where the attacker has access to neither model parameters nor model predictions. In addition, the research about adversarial attacks on GNNs in turn helps us better understand the intrinsic properties of existing GNN models.",
    ". The latter employ a score function to evaluate candidate causal structures relative to data and seek to locate the causal structure with the optimal score. Due to the combinatorial nature of the acyclicity constraint ( Chickering, 2002 ; Spirtes et al., 2000 ), score-based methods rely on local heuristics to perform the search. This change of perspective allows using deep learning techniques to model causal mechanisms with non-linear data.",
    ". The latter employ a score function to evaluate candidate causal structures relative to data and seek to locate the causal structure with the optimal score. Due to the combinatorial nature of the acyclicity constraint ( Chickering, 2002 ; Spirtes et al., 2000 ), score-based methods rely on local heuristics to perform the search. This change of perspective allows using deep learning techniques to model causal mechanisms with non-linear data.",
    ". The latter employ a score function to evaluate candidate causal structures relative to data and seek to locate the causal structure with the optimal score. Due to the combinatorial nature of the acyclicity constraint ( Chickering, 2002 ; Spirtes et al., 2000 ), score-based methods rely on local heuristics to perform the search. This change of perspective allows using deep learning techniques to model causal mechanisms with non-linear data.",
    ". ( 2020 ) and Wang et al. ( 2020 ).. ( 2020 ) investigated the joint optimization between NAS and HPO via differentiable architecture and hyper-parameter search spaces. In contrast, Wang et al. ( 2020 ) investigated the joint optimization between NAS and HPO via differentiable architecture and hyper-parameter search spaces. In contrast, Wang et al. ( 2020 ) investigated the joint optimization between",
    ". ( 2020 ) and Wang et al. ( 2020 ).. ( 2020 ) investigated the joint optimization between NAS and HPO via differentiable architecture and hyper-parameter search spaces. In contrast, Wang et al. ( 2020 ) investigated the joint optimization between NAS and HPO via differentiable architecture and hyper-parameter search spaces. In contrast, Wang et al. ( 2020 ) investigated the joint optimization between",
    ". ( 2020 ) and Wang et al. ( 2020 ).. ( 2020 ) investigated the joint optimization between NAS and HPO via differentiable architecture and hyper-parameter search spaces. In contrast, Wang et al. ( 2020 ) investigated the joint optimization between NAS and HPO via differentiable architecture and hyper-parameter search spaces. In contrast, Wang et al. ( 2020 ) investigated the joint optimization between",
    ", 2014 ; ; Gal & Ghahramani, 2016 ). Ensemble methods have become the standard approach to addressing a wide range of machine learning tasks. Ensemble methods have been proposed as an approach to modelling uncertainty in classification tasks. Prior Networks ( Malinin & Gales, 2018 ; 2019 ; Malinin, 2019 ; Sensoy et al., 2018 ) have been proposed as an approach to modelling uncertainty in classification tasks",
    ", 2014 ; ; Gal & Ghahramani, 2016 ). Ensemble methods have become the standard approach to addressing a wide range of machine learning tasks. Ensemble methods have been proposed as an approach to modelling uncertainty in classification tasks. Prior Networks ( Malinin & Gales, 2018 ; 2019 ; Malinin, 2019 ; Sensoy et al., 2018 ) have been proposed as an approach to modelling uncertainty in classification tasks",
    ", 2014 ; ; Gal & Ghahramani, 2016 ). Ensemble methods have become the standard approach to addressing a wide range of machine learning tasks. Ensemble methods have been proposed as an approach to modelling uncertainty in classification tasks. Prior Networks ( Malinin & Gales, 2018 ; 2019 ; Malinin, 2019 ; Sensoy et al., 2018 ) have been proposed as an approach to modelling uncertainty in classification tasks",
    ". Neural networks are known to suffer catastrophic forgetting when trained on sequential datasets. This work introduces a Bayesian online meta-learning framework to tackle the catastrophic forgetting and the sequential few-shot tasks problems. Our framework incorporates MAML into a Bayesian online learning algorithm with Laplace approximation or variational inference. The experimental evaluations demonstrate that our framework can effectively prevent catastrophic forgetting and is capable of online meta-learning in various few-shot classification settings.",
    ". Neural networks are known to suffer catastrophic forgetting when trained on sequential datasets. This work introduces a Bayesian online meta-learning framework to tackle the catastrophic forgetting and the sequential few-shot tasks problems. Our framework incorporates MAML into a Bayesian online learning algorithm with Laplace approximation or variational inference. The experimental evaluations demonstrate that our framework can effectively prevent catastrophic forgetting and is capable of online meta-learning in various few-shot classification settings.",
    ". Neural networks are known to suffer catastrophic forgetting when trained on sequential datasets. This work introduces a Bayesian online meta-learning framework to tackle the catastrophic forgetting and the sequential few-shot tasks problems. Our framework incorporates MAML into a Bayesian online learning algorithm with Laplace approximation or variational inference. The experimental evaluations demonstrate that our framework can effectively prevent catastrophic forgetting and is capable of online meta-learning in various few-shot classification settings.",
    ", 2017 ; Hamilton et al., 2017 ). Graph Neural Networks ( GNNs ) are powerful tools for graph representation learning ( Scarselli et al., 2008 ; Hamilton et al., 2017 ). However, their expressive power has been shown to be limited. For example, their discriminative power corresponds to the one-dimensional Weisfeiler-Leman ( 1-WL ) graph isomorphis",
    ", 2017 ; Hamilton et al., 2017 ). Graph Neural Networks ( GNNs ) are powerful tools for graph representation learning ( Scarselli et al., 2008 ; Hamilton et al., 2017 ). However, their expressive power has been shown to be limited. For example, their discriminative power corresponds to the one-dimensional Weisfeiler-Leman ( 1-WL ) graph isomorphis",
    ", 2017 ; Hamilton et al., 2017 ). Graph Neural Networks ( GNNs ) are powerful tools for graph representation learning ( Scarselli et al., 2008 ; Hamilton et al., 2017 ). However, their expressive power has been shown to be limited. For example, their discriminative power corresponds to the one-dimensional Weisfeiler-Leman ( 1-WL ) graph isomorphis",
    "Lyapunov chaos. When the starting point of a dynamical system is slightly perturbed, the resulting trajectories and final outcomes diverge quickly. In this paper, we characterize general normal games where popular learning algorithms exhibit chaotic behaviors. As round-offs are inevitable, we surely want to avoid chaotic learning that does not fulfill our primary goals in building predictable and reproducible learning.",
    "Lyapunov chaos. When the starting point of a dynamical system is slightly perturbed, the resulting trajectories and final outcomes diverge quickly. In this paper, we characterize general normal games where popular learning algorithms exhibit chaotic behaviors. As round-offs are inevitable, we surely want to avoid chaotic learning that does not fulfill our primary goals in building predictable and reproducible learning.",
    "Lyapunov chaos. When the starting point of a dynamical system is slightly perturbed, the resulting trajectories and final outcomes diverge quickly. In this paper, we characterize general normal games where popular learning algorithms exhibit chaotic behaviors. As round-offs are inevitable, we surely want to avoid chaotic learning that does not fulfill our primary goals in building predictable and reproducible learning.",
    "AMSGrad. However, this algorithm had convergence issues in the presence of high frequency noises. Therefore, many new algorithms were proposed to boost the convergence speed of optimization algorithms. However, many of these algorithms had convergence issues in the presence of high frequency noises. For example, RMSProp ( Tieleman & Hinton, 1964 ) and Adam ( Kingma & Ba, 2015 ) changed the global average design in AdaGrad to the exponential moving average",
    "AMSGrad. However, this algorithm had convergence issues in the presence of high frequency noises. Therefore, many new algorithms were proposed to boost the convergence speed of optimization algorithms. However, many of these algorithms had convergence issues in the presence of high frequency noises. For example, RMSProp ( Tieleman & Hinton, 1964 ) and Adam ( Kingma & Ba, 2015 ) changed the global average design in AdaGrad to the exponential moving average",
    "AMSGrad. However, this algorithm had convergence issues in the presence of high frequency noises. Therefore, many new algorithms were proposed to boost the convergence speed of optimization algorithms. However, many of these algorithms had convergence issues in the presence of high frequency noises. For example, RMSProp ( Tieleman & Hinton, 1964 ) and Adam ( Kingma & Ba, 2015 ) changed the global average design in AdaGrad to the exponential moving average",
    ". In this paper, we focus on the mean-variance trade-off. In this paper, we focus on the mean-variance trade-off. Xie et al. ( 2018 ) proposed a method based on the Legendre-Fenchel duality ( Boyd & Vandenberghe, 2004 ). This method is based on the Legendre-Fenchel duality ( Boyd & Vandenberghe, 2004 )",
    ". In this paper, we focus on the mean-variance trade-off. In this paper, we focus on the mean-variance trade-off. Xie et al. ( 2018 ) proposed a method based on the Legendre-Fenchel duality ( Boyd & Vandenberghe, 2004 ). This method is based on the Legendre-Fenchel duality ( Boyd & Vandenberghe, 2004 )",
    ". In this paper, we focus on the mean-variance trade-off. In this paper, we focus on the mean-variance trade-off. Xie et al. ( 2018 ) proposed a method based on the Legendre-Fenchel duality ( Boyd & Vandenberghe, 2004 ). This method is based on the Legendre-Fenchel duality ( Boyd & Vandenberghe, 2004 )",
    ". In the low data regime, learning with auxiliary tasks can significantly improve. For example, learning to segment an image into objects can be more accurate when the model is simultaneously trained to predict other properties of the image. In some domains, it may be easy to design beneficial auxiliary tasks and collect supervised data. For example, for point cloud classification, few self-supervised tasks have been proposed. However, their benefits so far are limited ( Achituve et al.",
    ". In the low data regime, learning with auxiliary tasks can significantly improve. For example, learning to segment an image into objects can be more accurate when the model is simultaneously trained to predict other properties of the image. In some domains, it may be easy to design beneficial auxiliary tasks and collect supervised data. For example, for point cloud classification, few self-supervised tasks have been proposed. However, their benefits so far are limited ( Achituve et al.",
    ". In the low data regime, learning with auxiliary tasks can significantly improve. For example, learning to segment an image into objects can be more accurate when the model is simultaneously trained to predict other properties of the image. In some domains, it may be easy to design beneficial auxiliary tasks and collect supervised data. For example, for point cloud classification, few self-supervised tasks have been proposed. However, their benefits so far are limited ( Achituve et al.",
    "). Statistical machine translation ( SMT, ( Brown et al., 1993 ; Och, 2003 ), has largely been replaced in recent years following the emergence of Neural Machine Translation ( NMT, ( Kalchbrenner & Blunsom, 2013 ) ). This field, known as Bayesian Deep Learning ( BDL, ( Neal, 2012 ; Gal, 2016 ), is concerned with the",
    "). Statistical machine translation ( SMT, ( Brown et al., 1993 ; Och, 2003 ), has largely been replaced in recent years following the emergence of Neural Machine Translation ( NMT, ( Kalchbrenner & Blunsom, 2013 ) ). This field, known as Bayesian Deep Learning ( BDL, ( Neal, 2012 ; Gal, 2016 ), is concerned with the",
    "). Statistical machine translation ( SMT, ( Brown et al., 1993 ; Och, 2003 ), has largely been replaced in recent years following the emergence of Neural Machine Translation ( NMT, ( Kalchbrenner & Blunsom, 2013 ) ). This field, known as Bayesian Deep Learning ( BDL, ( Neal, 2012 ; Gal, 2016 ), is concerned with the",
    ". As the computational demands of training have exploded, researchers have begun to investigate the possibility that neural networks can be pruned early in training or even before training. This work raises the prospect that it may be possible to prune early in training without affecting final accuracy. However, this work does not suggest a way to find these subnetworks without first training the full network.",
    ". As the computational demands of training have exploded, researchers have begun to investigate the possibility that neural networks can be pruned early in training or even before training. This work raises the prospect that it may be possible to prune early in training without affecting final accuracy. However, this work does not suggest a way to find these subnetworks without first training the full network.",
    ". As the computational demands of training have exploded, researchers have begun to investigate the possibility that neural networks can be pruned early in training or even before training. This work raises the prospect that it may be possible to prune early in training without affecting final accuracy. However, this work does not suggest a way to find these subnetworks without first training the full network.",
    ". This kind of attack is well-studied by Bhagoji et al. ( 2019 ) ; Yin et al., 2018 ; Fu et al., 2019 ; Pillutla et al., 2019 ). These protocols replace trivial averaging with well-designed Byzantine-robust mean estimators. These estimators suppress the influence of the malicious updates and output a mean estimation as accurate as possible",
    ". This kind of attack is well-studied by Bhagoji et al. ( 2019 ) ; Yin et al., 2018 ; Fu et al., 2019 ; Pillutla et al., 2019 ). These protocols replace trivial averaging with well-designed Byzantine-robust mean estimators. These estimators suppress the influence of the malicious updates and output a mean estimation as accurate as possible",
    ". This kind of attack is well-studied by Bhagoji et al. ( 2019 ) ; Yin et al., 2018 ; Fu et al., 2019 ; Pillutla et al., 2019 ). These protocols replace trivial averaging with well-designed Byzantine-robust mean estimators. These estimators suppress the influence of the malicious updates and output a mean estimation as accurate as possible",
    ". This is the setting of data-driven offline model-based optimization. Although online black-box optimization has been studied extensively, the offline MBO problem has received comparatively little attention. This is partly due to the fact that methods for online design optimization can not be easily applied in the offline MBO setting. However, there is no commonly adopted set of benchmarks for offline MBO.",
    ". This is the setting of data-driven offline model-based optimization. Although online black-box optimization has been studied extensively, the offline MBO problem has received comparatively little attention. This is partly due to the fact that methods for online design optimization can not be easily applied in the offline MBO setting. However, there is no commonly adopted set of benchmarks for offline MBO.",
    ". This is the setting of data-driven offline model-based optimization. Although online black-box optimization has been studied extensively, the offline MBO problem has received comparatively little attention. This is partly due to the fact that methods for online design optimization can not be easily applied in the offline MBO setting. However, there is no commonly adopted set of benchmarks for offline MBO.",
    ". In particular, self-supervised, generative models are suitable for learning the joint distribution of multiple data types without supervision. In particular, multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across modalities. Furthermore, to handle missing modalities, naively, it requires 2M different encoders to handle all combinations for M data types. In addition, to handle missing modalities, it requires 2M",
    ". In particular, self-supervised, generative models are suitable for learning the joint distribution of multiple data types without supervision. In particular, multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across modalities. Furthermore, to handle missing modalities, naively, it requires 2M different encoders to handle all combinations for M data types. In addition, to handle missing modalities, it requires 2M",
    ". In particular, self-supervised, generative models are suitable for learning the joint distribution of multiple data types without supervision. In particular, multimodal generative models need to represent both modality-specific and shared factors and generate semantically coherent samples across modalities. Furthermore, to handle missing modalities, naively, it requires 2M different encoders to handle all combinations for M data types. In addition, to handle missing modalities, it requires 2M",
    ", 2018 ; Nardi et al., 2016 ). Bayesian Optimization ( BO ) is a data-efficient method for the joint optimization of design choices that gained great popularity in recent years. Nevertheless, domain experts often have substantial prior knowledge that standard BO can not incorporate. Nevertheless, users often know which ranges of hyperparameters tend to work best, and are able to specify a probability distribution pbest ( x ) to quantify these",
    ", 2018 ; Nardi et al., 2016 ). Bayesian Optimization ( BO ) is a data-efficient method for the joint optimization of design choices that gained great popularity in recent years. Nevertheless, domain experts often have substantial prior knowledge that standard BO can not incorporate. Nevertheless, users often know which ranges of hyperparameters tend to work best, and are able to specify a probability distribution pbest ( x ) to quantify these",
    ", 2018 ; Nardi et al., 2016 ). Bayesian Optimization ( BO ) is a data-efficient method for the joint optimization of design choices that gained great popularity in recent years. Nevertheless, domain experts often have substantial prior knowledge that standard BO can not incorporate. Nevertheless, users often know which ranges of hyperparameters tend to work best, and are able to specify a probability distribution pbest ( x ) to quantify these",
    "binarization for brevity. As machine learning models continue to grow in number of parameters, there is an effort to try and reduce the ever-increasing memory and computational requirements that these models incur. In this work we focus on non-autoregressive models with explicit densities. VAE models tend to have deep hierarchies of latent layers, and have demonstrated good performance relative to comparable modelling approaches ( Ranganath et al., 2016 ; Kingm",
    "binarization for brevity. As machine learning models continue to grow in number of parameters, there is an effort to try and reduce the ever-increasing memory and computational requirements that these models incur. In this work we focus on non-autoregressive models with explicit densities. VAE models tend to have deep hierarchies of latent layers, and have demonstrated good performance relative to comparable modelling approaches ( Ranganath et al., 2016 ; Kingm",
    "binarization for brevity. As machine learning models continue to grow in number of parameters, there is an effort to try and reduce the ever-increasing memory and computational requirements that these models incur. In this work we focus on non-autoregressive models with explicit densities. VAE models tend to have deep hierarchies of latent layers, and have demonstrated good performance relative to comparable modelling approaches ( Ranganath et al., 2016 ; Kingm",
    ", 2019a ). Despite this progress, it is now well-known that DL is fragile to unbounded shifts in the data-distribution due to a wide range of natural phenomena. For example, in image classification, such shifts include changes due to lighting, blurring, or weather conditions ( Pei et al., 2018 ). Indeed, DL is fragile to unbounded shifts in the data-distribution",
    ", 2019a ). Despite this progress, it is now well-known that DL is fragile to unbounded shifts in the data-distribution due to a wide range of natural phenomena. For example, in image classification, such shifts include changes due to lighting, blurring, or weather conditions ( Pei et al., 2018 ). Indeed, DL is fragile to unbounded shifts in the data-distribution",
    ", 2019a ). Despite this progress, it is now well-known that DL is fragile to unbounded shifts in the data-distribution due to a wide range of natural phenomena. For example, in image classification, such shifts include changes due to lighting, blurring, or weather conditions ( Pei et al., 2018 ). Indeed, DL is fragile to unbounded shifts in the data-distribution",
    ". We introduce equivalent finite dimensional convex formulations that can be used to globally optimize CNN architectures. Remarkably, our results characterize the role of network architecture in terms of equivalent convex regularizers. Remarkably, we prove that the proposed methods are polynomial time with respect to all problem parameters. Among these studies, Parhi & Nowak ( 2019 ) ; Ergen & Pilanci ( 2020b ; c ; d",
    ". We introduce equivalent finite dimensional convex formulations that can be used to globally optimize CNN architectures. Remarkably, our results characterize the role of network architecture in terms of equivalent convex regularizers. Remarkably, we prove that the proposed methods are polynomial time with respect to all problem parameters. Among these studies, Parhi & Nowak ( 2019 ) ; Ergen & Pilanci ( 2020b ; c ; d",
    ". We introduce equivalent finite dimensional convex formulations that can be used to globally optimize CNN architectures. Remarkably, our results characterize the role of network architecture in terms of equivalent convex regularizers. Remarkably, we prove that the proposed methods are polynomial time with respect to all problem parameters. Among these studies, Parhi & Nowak ( 2019 ) ; Ergen & Pilanci ( 2020b ; c ; d",
    ". In this context, we need to be able to ground the specifications and symbols used by the operator in the actions and observations of the robot agent. Often the actions and the observations of a robot agent can be high-dimensional. However, the concepts we need to be able to ground lie on a much-lower-dimensional manifold embedded in the high-dimensional data space. For example, the concept of pressing softly against a surface manifests itself in a data stream associated",
    ". In this context, we need to be able to ground the specifications and symbols used by the operator in the actions and observations of the robot agent. Often the actions and the observations of a robot agent can be high-dimensional. However, the concepts we need to be able to ground lie on a much-lower-dimensional manifold embedded in the high-dimensional data space. For example, the concept of pressing softly against a surface manifests itself in a data stream associated",
    ". In this context, we need to be able to ground the specifications and symbols used by the operator in the actions and observations of the robot agent. Often the actions and the observations of a robot agent can be high-dimensional. However, the concepts we need to be able to ground lie on a much-lower-dimensional manifold embedded in the high-dimensional data space. For example, the concept of pressing softly against a surface manifests itself in a data stream associated",
    "overfitting on statistically spurious correlations between irrelevant information and target labels. In particular, the task-universal nature of large-scale pretrained sentence representations means that much of the information in these representations is irrelevant to a given target task. In this paper, we propose a fine-tuning method that uses the Variational Information Bottleneck ( VIB ) principle. VIB addresses the problem of overfitting by adding a regularization term to the training loss that directly suppress",
    "overfitting on statistically spurious correlations between irrelevant information and target labels. In particular, the task-universal nature of large-scale pretrained sentence representations means that much of the information in these representations is irrelevant to a given target task. In this paper, we propose a fine-tuning method that uses the Variational Information Bottleneck ( VIB ) principle. VIB addresses the problem of overfitting by adding a regularization term to the training loss that directly suppress",
    "overfitting on statistically spurious correlations between irrelevant information and target labels. In particular, the task-universal nature of large-scale pretrained sentence representations means that much of the information in these representations is irrelevant to a given target task. In this paper, we propose a fine-tuning method that uses the Variational Information Bottleneck ( VIB ) principle. VIB addresses the problem of overfitting by adding a regularization term to the training loss that directly suppress",
    ".......... Despite their impressive results, these methods often assume object shapes are symmetric ( symmetry assumption ). Despite their impressive results, these methods often assume object shapes are symmetric ( symmetry assumption ). However, these methods often assume object shapes are symmetric ( symmetry assumption ). However, these methods often assume object shapes are symmetric (",
    ".......... Despite their impressive results, these methods often assume object shapes are symmetric ( symmetry assumption ). Despite their impressive results, these methods often assume object shapes are symmetric ( symmetry assumption ). However, these methods often assume object shapes are symmetric ( symmetry assumption ). However, these methods often assume object shapes are symmetric (",
    ".......... Despite their impressive results, these methods often assume object shapes are symmetric ( symmetry assumption ). Despite their impressive results, these methods often assume object shapes are symmetric ( symmetry assumption ). However, these methods often assume object shapes are symmetric ( symmetry assumption ). However, these methods often assume object shapes are symmetric (",
    "the head-tail model bias gap remains large. We propose a new long-tailed classifier called RoutIng Diverse Experts ( RIDE ). It reduces the model variance with multiple experts, reduces the computational cost with a dynamic expert routing module. RIDE outperforms the state-of-the-art by 5 % to 7 % on CIFAR100-LT, ImageNet-LT and iNaturalist 2018 benchmarks.",
    "the head-tail model bias gap remains large. We propose a new long-tailed classifier called RoutIng Diverse Experts ( RIDE ). It reduces the model variance with multiple experts, reduces the computational cost with a dynamic expert routing module. RIDE outperforms the state-of-the-art by 5 % to 7 % on CIFAR100-LT, ImageNet-LT and iNaturalist 2018 benchmarks.",
    "the head-tail model bias gap remains large. We propose a new long-tailed classifier called RoutIng Diverse Experts ( RIDE ). It reduces the model variance with multiple experts, reduces the computational cost with a dynamic expert routing module. RIDE outperforms the state-of-the-art by 5 % to 7 % on CIFAR100-LT, ImageNet-LT and iNaturalist 2018 benchmarks.",
    "1 and  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  1 and  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  1 and  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  2 pruning can be seen as the criteria which use absolute Importance Score",
    "1 and  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  1 and  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  1 and  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  2 pruning can be seen as the criteria which use absolute Importance Score",
    "1 and  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  1 and  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  1 and  2 pruning can be seen as the criteria which use absolute Importance Score of filters.  2 pruning can be seen as the criteria which use absolute Importance Score",
    "GraphCodeBERT is a pre-trained model for programming language that considers the inherent structure of code. Instead of taking syntactic-level structure of code, GraphCodeBERT takes the semantic structure of code into account. GraphCodeBERT provides a way to understand the semantic of the variable v by leveraging dependency relation between variables. GraphCodeBERT provides a way to understand the semantic of the variable v by leveraging dependency relation between variables. GraphCodeBER",
    "GraphCodeBERT is a pre-trained model for programming language that considers the inherent structure of code. Instead of taking syntactic-level structure of code, GraphCodeBERT takes the semantic structure of code into account. GraphCodeBERT provides a way to understand the semantic of the variable v by leveraging dependency relation between variables. GraphCodeBERT provides a way to understand the semantic of the variable v by leveraging dependency relation between variables. GraphCodeBER",
    "GraphCodeBERT is a pre-trained model for programming language that considers the inherent structure of code. Instead of taking syntactic-level structure of code, GraphCodeBERT takes the semantic structure of code into account. GraphCodeBERT provides a way to understand the semantic of the variable v by leveraging dependency relation between variables. GraphCodeBERT provides a way to understand the semantic of the variable v by leveraging dependency relation between variables. GraphCodeBER",
    ". In particular, pharmaceutical development is often affected by this problem. When data from the literature are used to train a regression model, the predictions from the regression model may differ from the true distribution. In this work, we propose a new approach to improve the accuracy of a regression model that is trained using skewed data. We assume the presence of enough unlabeled data which follow the true distribution. We assume the presence of enough unlabeled data which follow the true distribution.",
    ". In particular, pharmaceutical development is often affected by this problem. When data from the literature are used to train a regression model, the predictions from the regression model may differ from the true distribution. In this work, we propose a new approach to improve the accuracy of a regression model that is trained using skewed data. We assume the presence of enough unlabeled data which follow the true distribution. We assume the presence of enough unlabeled data which follow the true distribution.",
    ". In particular, pharmaceutical development is often affected by this problem. When data from the literature are used to train a regression model, the predictions from the regression model may differ from the true distribution. In this work, we propose a new approach to improve the accuracy of a regression model that is trained using skewed data. We assume the presence of enough unlabeled data which follow the true distribution. We assume the presence of enough unlabeled data which follow the true distribution.",
    ". In the language domain, a compound word is a combination of multiple words. In the image domain, an object is a combination of many parts or properties. In the language domain, a compound word is a combination of multiple words. In the language domain, a compound word is a combination of multiple words. In the digit example, the representation of one digit is overlapped. In the language domain, a compound word is a compound word",
    ". In the language domain, a compound word is a combination of multiple words. In the image domain, an object is a combination of many parts or properties. In the language domain, a compound word is a combination of multiple words. In the language domain, a compound word is a combination of multiple words. In the digit example, the representation of one digit is overlapped. In the language domain, a compound word is a compound word",
    ". In the language domain, a compound word is a combination of multiple words. In the image domain, an object is a combination of many parts or properties. In the language domain, a compound word is a combination of multiple words. In the language domain, a compound word is a combination of multiple words. In the digit example, the representation of one digit is overlapped. In the language domain, a compound word is a compound word",
    "how to poison RL agents and how to characterize the vulnerability of deep RL algorithms. In this paper, we focus on poisoning attacks, which occur during the training and influence the learned policy. Since training RL is known to be very sample-consuming, one might have to constantly interact with the environment to collect data. Therefore, understanding poisoning mechanisms and characterizing the vulnerability of deep RL algorithms are crucial to provide guidance for defense methods. Challenge I \u2013 Future Data Unavailable in Online RL",
    "how to poison RL agents and how to characterize the vulnerability of deep RL algorithms. In this paper, we focus on poisoning attacks, which occur during the training and influence the learned policy. Since training RL is known to be very sample-consuming, one might have to constantly interact with the environment to collect data. Therefore, understanding poisoning mechanisms and characterizing the vulnerability of deep RL algorithms are crucial to provide guidance for defense methods. Challenge I \u2013 Future Data Unavailable in Online RL",
    "how to poison RL agents and how to characterize the vulnerability of deep RL algorithms. In this paper, we focus on poisoning attacks, which occur during the training and influence the learned policy. Since training RL is known to be very sample-consuming, one might have to constantly interact with the environment to collect data. Therefore, understanding poisoning mechanisms and characterizing the vulnerability of deep RL algorithms are crucial to provide guidance for defense methods. Challenge I \u2013 Future Data Unavailable in Online RL",
    "O ( N ) tensor operations. DTR closely matches the performance of optimal static planning in simulated experiments. We present Dynamic Tensor Rematerialization ( DTR ), a greedy online algorithm for heuristically checkpointing arbitrary DL models. DTR collects lightweight metadata on tensors and operators as a model is trained and uses it as a tensor-level cache.",
    "O ( N ) tensor operations. DTR closely matches the performance of optimal static planning in simulated experiments. We present Dynamic Tensor Rematerialization ( DTR ), a greedy online algorithm for heuristically checkpointing arbitrary DL models. DTR collects lightweight metadata on tensors and operators as a model is trained and uses it as a tensor-level cache.",
    "O ( N ) tensor operations. DTR closely matches the performance of optimal static planning in simulated experiments. We present Dynamic Tensor Rematerialization ( DTR ), a greedy online algorithm for heuristically checkpointing arbitrary DL models. DTR collects lightweight metadata on tensors and operators as a model is trained and uses it as a tensor-level cache.",
    "the faithfulness of machine outputs in conditional sequence generation tasks. This risk of generating unfaithful content impedes the safe deployment of neural sequence generation models. In this paper, we focus on the faithfulness of machine outputs in conditional sequence generation tasks. We aim to automatically identify and quantify content in the output that is not faithful to the input text. This risk of generating unfaithful content impedes the safe deployment of neural sequence generation models in a deployed system at run-time",
    "the faithfulness of machine outputs in conditional sequence generation tasks. This risk of generating unfaithful content impedes the safe deployment of neural sequence generation models. In this paper, we focus on the faithfulness of machine outputs in conditional sequence generation tasks. We aim to automatically identify and quantify content in the output that is not faithful to the input text. This risk of generating unfaithful content impedes the safe deployment of neural sequence generation models in a deployed system at run-time",
    "the faithfulness of machine outputs in conditional sequence generation tasks. This risk of generating unfaithful content impedes the safe deployment of neural sequence generation models. In this paper, we focus on the faithfulness of machine outputs in conditional sequence generation tasks. We aim to automatically identify and quantify content in the output that is not faithful to the input text. This risk of generating unfaithful content impedes the safe deployment of neural sequence generation models in a deployed system at run-time",
    "class-aware generators. As the number of classes grows, there are three main issues we have to consider. First, we present a carefully designed search space that is both flexible and safe. We refer to safety as the ability to assign a distinct generator architecture to each class. Second, the search space will grow exponentially as the number of classes grows. Third, searching and re-training each generator one by one may be impractical when the number of generators is large.",
    "class-aware generators. As the number of classes grows, there are three main issues we have to consider. First, we present a carefully designed search space that is both flexible and safe. We refer to safety as the ability to assign a distinct generator architecture to each class. Second, the search space will grow exponentially as the number of classes grows. Third, searching and re-training each generator one by one may be impractical when the number of generators is large.",
    "class-aware generators. As the number of classes grows, there are three main issues we have to consider. First, we present a carefully designed search space that is both flexible and safe. We refer to safety as the ability to assign a distinct generator architecture to each class. Second, the search space will grow exponentially as the number of classes grows. Third, searching and re-training each generator one by one may be impractical when the number of generators is large.",
    ". Unlike RCTs, observational studies adopt observed data to estimate the causal effect. For instance, in order to control an epidemic, it is relevant for individual decision-makers to estimate the causal effect of an intervention. In this paper, we estimate the average causal effect of a treatment from observational data. Unlike RCTs, observational studies adopt observed data to estimate the causal effect. However, this is challenging, since we do not know what the outcome would have been",
    ". Unlike RCTs, observational studies adopt observed data to estimate the causal effect. For instance, in order to control an epidemic, it is relevant for individual decision-makers to estimate the causal effect of an intervention. In this paper, we estimate the average causal effect of a treatment from observational data. Unlike RCTs, observational studies adopt observed data to estimate the causal effect. However, this is challenging, since we do not know what the outcome would have been",
    ". Unlike RCTs, observational studies adopt observed data to estimate the causal effect. For instance, in order to control an epidemic, it is relevant for individual decision-makers to estimate the causal effect of an intervention. In this paper, we estimate the average causal effect of a treatment from observational data. Unlike RCTs, observational studies adopt observed data to estimate the causal effect. However, this is challenging, since we do not know what the outcome would have been",
    ". BatchNorm is ubiquitous in deep convolutional neural networks ( CNNs ) for computer vision. These affine parameters are present by default in numerous models that researchers and practitioners train every day. One fact we do know about  and  in BatchNorm is that their presence has a meaningful effect on the performance of ResNets. 1He et al. ( 2016 ) find better accuracy when using BatchNorm before activation rather than after in ResNets. that, were",
    ". BatchNorm is ubiquitous in deep convolutional neural networks ( CNNs ) for computer vision. These affine parameters are present by default in numerous models that researchers and practitioners train every day. One fact we do know about  and  in BatchNorm is that their presence has a meaningful effect on the performance of ResNets. 1He et al. ( 2016 ) find better accuracy when using BatchNorm before activation rather than after in ResNets. that, were",
    ". BatchNorm is ubiquitous in deep convolutional neural networks ( CNNs ) for computer vision. These affine parameters are present by default in numerous models that researchers and practitioners train every day. One fact we do know about  and  in BatchNorm is that their presence has a meaningful effect on the performance of ResNets. 1He et al. ( 2016 ) find better accuracy when using BatchNorm before activation rather than after in ResNets. that, were",
    ". It might not be computationally practical to ( re- ) process source data during testing. 3. Accuracy. A model might be too inaccurate without adaptation to serve its purpose. To adapt during testing we minimize the test entropy of model predictions. Entropy is related to error, as more confident predictions are all-in-all more correct ( Figure 1 ). Entropy is related to shifts due to corruption, as more corruption results in more errors.",
    ". It might not be computationally practical to ( re- ) process source data during testing. 3. Accuracy. A model might be too inaccurate without adaptation to serve its purpose. To adapt during testing we minimize the test entropy of model predictions. Entropy is related to error, as more confident predictions are all-in-all more correct ( Figure 1 ). Entropy is related to shifts due to corruption, as more corruption results in more errors.",
    ". It might not be computationally practical to ( re- ) process source data during testing. 3. Accuracy. A model might be too inaccurate without adaptation to serve its purpose. To adapt during testing we minimize the test entropy of model predictions. Entropy is related to error, as more confident predictions are all-in-all more correct ( Figure 1 ). Entropy is related to shifts due to corruption, as more corruption results in more errors.",
    ". Moreover, when monitoring medical time-series data, hospital staff should be alerted when there is a low-confidence prediction concerning a patient \u2019 s health status. In this paper, we propose an orthogonal approach to quantify the uncertainty in recurrent neural networks ( RNNs ). At each time step, based on the current hidden ( and cell ) state, the model computes a probability distribution over a finite set of states.",
    ". Moreover, when monitoring medical time-series data, hospital staff should be alerted when there is a low-confidence prediction concerning a patient \u2019 s health status. In this paper, we propose an orthogonal approach to quantify the uncertainty in recurrent neural networks ( RNNs ). At each time step, based on the current hidden ( and cell ) state, the model computes a probability distribution over a finite set of states.",
    ". Moreover, when monitoring medical time-series data, hospital staff should be alerted when there is a low-confidence prediction concerning a patient \u2019 s health status. In this paper, we propose an orthogonal approach to quantify the uncertainty in recurrent neural networks ( RNNs ). At each time step, based on the current hidden ( and cell ) state, the model computes a probability distribution over a finite set of states.",
    "; the model extraction attack can learn a model that matches the target model, given the adversary only black-box access to the target model ; the attribute inference attack can infer certain features of a given input from the output of a target model, given the adversary only black-box access to the target model, which makes training DNs exposed to data privacy leakage ( Fredrikson et al., 2015a ; Shokri et al., 2017 ;",
    "; the model extraction attack can learn a model that matches the target model, given the adversary only black-box access to the target model ; the attribute inference attack can infer certain features of a given input from the output of a target model, given the adversary only black-box access to the target model, which makes training DNs exposed to data privacy leakage ( Fredrikson et al., 2015a ; Shokri et al., 2017 ;",
    "; the model extraction attack can learn a model that matches the target model, given the adversary only black-box access to the target model ; the attribute inference attack can infer certain features of a given input from the output of a target model, given the adversary only black-box access to the target model, which makes training DNs exposed to data privacy leakage ( Fredrikson et al., 2015a ; Shokri et al., 2017 ;",
    ". However, excessive computational overhead during inference has hindered its use in real applications. In this paper, we develop a framework based on PoWER-BERT such that we can train a transformer to cope with a diverse set of computational budgets in the inference time. In this paper, we propose to train a transformer while reducing the sequence length with a random proportion at each layer.",
    ". However, excessive computational overhead during inference has hindered its use in real applications. In this paper, we develop a framework based on PoWER-BERT such that we can train a transformer to cope with a diverse set of computational budgets in the inference time. In this paper, we propose to train a transformer while reducing the sequence length with a random proportion at each layer.",
    ". However, excessive computational overhead during inference has hindered its use in real applications. In this paper, we develop a framework based on PoWER-BERT such that we can train a transformer to cope with a diverse set of computational budgets in the inference time. In this paper, we propose to train a transformer while reducing the sequence length with a random proportion at each layer.",
    "2017 ; 2019 ; Maron et al., 2019 ; Morris et al., 2019 ; Chen et al., 2019 ; Li et al., 2020b ; Vignac et al., 2020b ). Expressive power of GNNs measures their abilities to represent different graph structures. The expressiveness analysis measured by the WL test assumes that aggregators are injective, which is usually unre",
    "2017 ; 2019 ; Maron et al., 2019 ; Morris et al., 2019 ; Chen et al., 2019 ; Li et al., 2020b ; Vignac et al., 2020b ). Expressive power of GNNs measures their abilities to represent different graph structures. The expressiveness analysis measured by the WL test assumes that aggregators are injective, which is usually unre",
    "2017 ; 2019 ; Maron et al., 2019 ; Morris et al., 2019 ; Chen et al., 2019 ; Li et al., 2020b ; Vignac et al., 2020b ). Expressive power of GNNs measures their abilities to represent different graph structures. The expressiveness analysis measured by the WL test assumes that aggregators are injective, which is usually unre",
    ". As a result, evaluation has often resorted to qualitative inspection for comparisons between models. In particular, reliance on training and tuning external models presents a tendency to be sensitive to additional hyperparameters and introduces partiality for models with particular training objectives ( Chen et al., 2016 ; Lin et al., 2018b ; Burgess et al., 2018b ; Karras et al., 2019 )",
    ". As a result, evaluation has often resorted to qualitative inspection for comparisons between models. In particular, reliance on training and tuning external models presents a tendency to be sensitive to additional hyperparameters and introduces partiality for models with particular training objectives ( Chen et al., 2016 ; Lin et al., 2018b ; Burgess et al., 2018b ; Karras et al., 2019 )",
    ". As a result, evaluation has often resorted to qualitative inspection for comparisons between models. In particular, reliance on training and tuning external models presents a tendency to be sensitive to additional hyperparameters and introduces partiality for models with particular training objectives ( Chen et al., 2016 ; Lin et al., 2018b ; Burgess et al., 2018b ; Karras et al., 2019 )",
    "unlearnable examples. In other words, DNNs trained on unlearnable examples will have a performance equivalent to random guessing on normal test examples. In this paper, we introduce unlearnable examples, which aims at making training examples unusable for Deep Neural Networks ( DNNs ). In other words, DNNs trained on unlearnable examples will have a performance equivalent to random guessing on normal test examples.",
    "unlearnable examples. In other words, DNNs trained on unlearnable examples will have a performance equivalent to random guessing on normal test examples. In this paper, we introduce unlearnable examples, which aims at making training examples unusable for Deep Neural Networks ( DNNs ). In other words, DNNs trained on unlearnable examples will have a performance equivalent to random guessing on normal test examples.",
    "unlearnable examples. In other words, DNNs trained on unlearnable examples will have a performance equivalent to random guessing on normal test examples. In this paper, we introduce unlearnable examples, which aims at making training examples unusable for Deep Neural Networks ( DNNs ). In other words, DNNs trained on unlearnable examples will have a performance equivalent to random guessing on normal test examples.",
    "the player identity policy and the chance player policy. This paper presents Nondeterministic MuZero ( NDMZ ), an extension of MuZero to stochastic, two-player, zero-sum games of perfect information. In it, we formalize the element of chance as a player in the game, determine a policy for the chance player via interaction with the environment. Finally, we introduce new node classes to the Monte Carlo Tree Search, allowing the",
    "the player identity policy and the chance player policy. This paper presents Nondeterministic MuZero ( NDMZ ), an extension of MuZero to stochastic, two-player, zero-sum games of perfect information. In it, we formalize the element of chance as a player in the game, determine a policy for the chance player via interaction with the environment. Finally, we introduce new node classes to the Monte Carlo Tree Search, allowing the",
    "the player identity policy and the chance player policy. This paper presents Nondeterministic MuZero ( NDMZ ), an extension of MuZero to stochastic, two-player, zero-sum games of perfect information. In it, we formalize the element of chance as a player in the game, determine a policy for the chance player via interaction with the environment. Finally, we introduce new node classes to the Monte Carlo Tree Search, allowing the",
    ". In this paper, we present a method for data-efficient, robust off-policy learning of options to partially combat the previously mentioned challenges in option learning. The algorithm updates the policy via critic-weighted maximum-likelihood ( similar to Abdolmaleki et al. ( 2018a ) ; Wulfmeier et al. ( 2020 ). In addition, we evaluate against current methods for option learning to demonstrate the importance of off",
    ". In this paper, we present a method for data-efficient, robust off-policy learning of options to partially combat the previously mentioned challenges in option learning. The algorithm updates the policy via critic-weighted maximum-likelihood ( similar to Abdolmaleki et al. ( 2018a ) ; Wulfmeier et al. ( 2020 ). In addition, we evaluate against current methods for option learning to demonstrate the importance of off",
    ". In this paper, we present a method for data-efficient, robust off-policy learning of options to partially combat the previously mentioned challenges in option learning. The algorithm updates the policy via critic-weighted maximum-likelihood ( similar to Abdolmaleki et al. ( 2018a ) ; Wulfmeier et al. ( 2020 ). In addition, we evaluate against current methods for option learning to demonstrate the importance of off",
    "( s, a ) = E  ( s, a ) [ R (  ) | ( s0, a0 ) = ( s, a0 ) ]. In the de novo drug design pipeline, molecule generation tries to maximize a given reward function. In this paper, we argue that optimizing for only the largest reward in an episode is also an important goal.",
    "( s, a ) = E  ( s, a ) [ R (  ) | ( s0, a0 ) = ( s, a0 ) ]. In the de novo drug design pipeline, molecule generation tries to maximize a given reward function. In this paper, we argue that optimizing for only the largest reward in an episode is also an important goal.",
    "( s, a ) = E  ( s, a ) [ R (  ) | ( s0, a0 ) = ( s, a0 ) ]. In the de novo drug design pipeline, molecule generation tries to maximize a given reward function. In this paper, we argue that optimizing for only the largest reward in an episode is also an important goal.",
    "the cold-start problem, which is prevalent not only in recommender systems but also in applications where high quality data is sparse. This presents a key challenge : the adaptation of a deep learning model to accurately predict the new feature values in the low-data regime. We wish to extend these ideas to the challenge of extending deep learning models in this low-data regime.",
    "the cold-start problem, which is prevalent not only in recommender systems but also in applications where high quality data is sparse. This presents a key challenge : the adaptation of a deep learning model to accurately predict the new feature values in the low-data regime. We wish to extend these ideas to the challenge of extending deep learning models in this low-data regime.",
    "the cold-start problem, which is prevalent not only in recommender systems but also in applications where high quality data is sparse. This presents a key challenge : the adaptation of a deep learning model to accurately predict the new feature values in the low-data regime. We wish to extend these ideas to the challenge of extending deep learning models in this low-data regime.",
    ", 2019 ). Deep neural networks ( DNNs ) still suffer from critical shortcomings that make them unfit for important applications. Despite recent successes in the field of Bayesian deep learning ( Blundell et al., 2015 ; Gal & Ghahramani, 2016 ), their accuracy is well-preserved by a small subnetwork. In addition, recent work by Izmailov et al. ( 2019 )",
    ", 2019 ). Deep neural networks ( DNNs ) still suffer from critical shortcomings that make them unfit for important applications. Despite recent successes in the field of Bayesian deep learning ( Blundell et al., 2015 ; Gal & Ghahramani, 2016 ), their accuracy is well-preserved by a small subnetwork. In addition, recent work by Izmailov et al. ( 2019 )",
    ", 2019 ). Deep neural networks ( DNNs ) still suffer from critical shortcomings that make them unfit for important applications. Despite recent successes in the field of Bayesian deep learning ( Blundell et al., 2015 ; Gal & Ghahramani, 2016 ), their accuracy is well-preserved by a small subnetwork. In addition, recent work by Izmailov et al. ( 2019 )",
    ". Moreover, many real-world domains suffer from large state-action spaces. In this work, we investigate efficient training of reinforcement learning agents in the presence of large state-action spaces. In this work, we propose to jointly learn embeddings for states or actions that can be directly used by an RL agent. This approach aims to improve the applicability of RL to real-world domains. For instance, resource management in computing clusters ( Mao et",
    ". Moreover, many real-world domains suffer from large state-action spaces. In this work, we investigate efficient training of reinforcement learning agents in the presence of large state-action spaces. In this work, we propose to jointly learn embeddings for states or actions that can be directly used by an RL agent. This approach aims to improve the applicability of RL to real-world domains. For instance, resource management in computing clusters ( Mao et",
    ". Moreover, many real-world domains suffer from large state-action spaces. In this work, we investigate efficient training of reinforcement learning agents in the presence of large state-action spaces. In this work, we propose to jointly learn embeddings for states or actions that can be directly used by an RL agent. This approach aims to improve the applicability of RL to real-world domains. For instance, resource management in computing clusters ( Mao et",
    "; Chen et al., 2019 ). Views refer to human-defined data transformations, which target capabilities or invariances thought to be useful for transfer tasks. In contrastive learning, models are trained to maximize the mutual information between different views of an image. We present a general method for learning diverse and useful views for contrastive learning. Rather than searching through possible compositions of existing view functions ( Cubuk et al., 2018 ; Lim e",
    "; Chen et al., 2019 ). Views refer to human-defined data transformations, which target capabilities or invariances thought to be useful for transfer tasks. In contrastive learning, models are trained to maximize the mutual information between different views of an image. We present a general method for learning diverse and useful views for contrastive learning. Rather than searching through possible compositions of existing view functions ( Cubuk et al., 2018 ; Lim e",
    "; Chen et al., 2019 ). Views refer to human-defined data transformations, which target capabilities or invariances thought to be useful for transfer tasks. In contrastive learning, models are trained to maximize the mutual information between different views of an image. We present a general method for learning diverse and useful views for contrastive learning. Rather than searching through possible compositions of existing view functions ( Cubuk et al., 2018 ; Lim e",
    "overconfident incorrect predictions on inputs which are outside the training distribution. The responsible deployment of deep neural networks in high-assurance applications necessitates detection of out-of-distribution ( OOD ) data so that DNNs can abstain from making decisions on those inputs. In this paper, we present a new approach for the detection of out-of-distribution ( OOD ) data.",
    "overconfident incorrect predictions on inputs which are outside the training distribution. The responsible deployment of deep neural networks in high-assurance applications necessitates detection of out-of-distribution ( OOD ) data so that DNNs can abstain from making decisions on those inputs. In this paper, we present a new approach for the detection of out-of-distribution ( OOD ) data.",
    "overconfident incorrect predictions on inputs which are outside the training distribution. The responsible deployment of deep neural networks in high-assurance applications necessitates detection of out-of-distribution ( OOD ) data so that DNNs can abstain from making decisions on those inputs. In this paper, we present a new approach for the detection of out-of-distribution ( OOD ) data.",
    "a hierarchical VAE that, for the first time, generates samples quickly and outperforms the PixelCNN in loglikelihood. Qualitative studies suggest this is because autoregressive models have historically outperformed VAEs in loglikelihood on all natural image benchmarks. In this paper, we present a hierarchical VAE that, for the first time, generates samples quickly and outperforms the PixelCNN in loglikel",
    "a hierarchical VAE that, for the first time, generates samples quickly and outperforms the PixelCNN in loglikelihood. Qualitative studies suggest this is because autoregressive models have historically outperformed VAEs in loglikelihood on all natural image benchmarks. In this paper, we present a hierarchical VAE that, for the first time, generates samples quickly and outperforms the PixelCNN in loglikel",
    "a hierarchical VAE that, for the first time, generates samples quickly and outperforms the PixelCNN in loglikelihood. Qualitative studies suggest this is because autoregressive models have historically outperformed VAEs in loglikelihood on all natural image benchmarks. In this paper, we present a hierarchical VAE that, for the first time, generates samples quickly and outperforms the PixelCNN in loglikel",
    "; Chen et al., 2019 ; Misra et al., 2020a ; b ; Grill et al., 2020a ; c ; Grill et al., 2020b ; d ; Grill et al., 2020a ; d ; Grill et al., 2020b ; d ; Chen et al., 2020b ; d ; Grill",
    "; Chen et al., 2019 ; Misra et al., 2020a ; b ; Grill et al., 2020a ; c ; Grill et al., 2020b ; d ; Grill et al., 2020a ; d ; Grill et al., 2020b ; d ; Chen et al., 2020b ; d ; Grill",
    "; Chen et al., 2019 ; Misra et al., 2020a ; b ; Grill et al., 2020a ; c ; Grill et al., 2020b ; d ; Grill et al., 2020a ; d ; Grill et al., 2020b ; d ; Chen et al., 2020b ; d ; Grill",
    ". This setting is called feature-partitioned or vertical FL ( VFL ). Unlike the HFL setting, in many learning scenarios, multiple workers handle data about the same set of subjects but their data share many common features. This setting is also referred to as feature-partitioned or vertical FL ( VFL ). In this context, FL raises new challenges including the heterogeneity of data and the privacy of data.",
    ". This setting is called feature-partitioned or vertical FL ( VFL ). Unlike the HFL setting, in many learning scenarios, multiple workers handle data about the same set of subjects but their data share many common features. This setting is also referred to as feature-partitioned or vertical FL ( VFL ). In this context, FL raises new challenges including the heterogeneity of data and the privacy of data.",
    ". This setting is called feature-partitioned or vertical FL ( VFL ). Unlike the HFL setting, in many learning scenarios, multiple workers handle data about the same set of subjects but their data share many common features. This setting is also referred to as feature-partitioned or vertical FL ( VFL ). In this context, FL raises new challenges including the heterogeneity of data and the privacy of data.",
    "DYNAMIC RELATIONAL INFERENCE IN MULTI-AGENT TRAJECTORIES Anonymous authors Paper under double-blind review ABSTRACT Unsupervised learning of interactions from multi-agent trajectories has broad applications in physics, vision and robotics. However, existing neural relational inference works are limited to static relations. In this paper, we propose DYnamic multi-Agent Relational Inference ( DYARI ) model,",
    "DYNAMIC RELATIONAL INFERENCE IN MULTI-AGENT TRAJECTORIES Anonymous authors Paper under double-blind review ABSTRACT Unsupervised learning of interactions from multi-agent trajectories has broad applications in physics, vision and robotics. However, existing neural relational inference works are limited to static relations. In this paper, we propose DYnamic multi-Agent Relational Inference ( DYARI ) model,",
    "DYNAMIC RELATIONAL INFERENCE IN MULTI-AGENT TRAJECTORIES Anonymous authors Paper under double-blind review ABSTRACT Unsupervised learning of interactions from multi-agent trajectories has broad applications in physics, vision and robotics. However, existing neural relational inference works are limited to static relations. In this paper, we propose DYnamic multi-Agent Relational Inference ( DYARI ) model,",
    ", 2004 ; Srebro et al., 2004 ; Zheng et al., 2016b ). As information explosion has become one major factor affecting human life in the decade, recommender systems play an increasingly indispensable part in day-to-day activities. First of all, recommendation models need to meet two important requirements in order for desirable effectiveness and practical utility. First, recommendation models need to meet two important requirements in order for desirable effectiveness and practical utility.",
    ", 2004 ; Srebro et al., 2004 ; Zheng et al., 2016b ). As information explosion has become one major factor affecting human life in the decade, recommender systems play an increasingly indispensable part in day-to-day activities. First of all, recommendation models need to meet two important requirements in order for desirable effectiveness and practical utility. First, recommendation models need to meet two important requirements in order for desirable effectiveness and practical utility.",
    ", 2004 ; Srebro et al., 2004 ; Zheng et al., 2016b ). As information explosion has become one major factor affecting human life in the decade, recommender systems play an increasingly indispensable part in day-to-day activities. First of all, recommendation models need to meet two important requirements in order for desirable effectiveness and practical utility. First, recommendation models need to meet two important requirements in order for desirable effectiveness and practical utility.",
    ". disentanglement by penalizing the ( aggregate ) posterior to encourage statistical independence of the latent factors. This approach introduces a trade-off between disentangled representation learning and reconstruction quality since the model does not have enough capacity to learn correlated latent variables that capture detail information present in most image data. To overcome this trade-off, we present a novel multi-stage modelling approach where the disentangled factors are first learned using a preexisting disentangled representation learning method.",
    ". disentanglement by penalizing the ( aggregate ) posterior to encourage statistical independence of the latent factors. This approach introduces a trade-off between disentangled representation learning and reconstruction quality since the model does not have enough capacity to learn correlated latent variables that capture detail information present in most image data. To overcome this trade-off, we present a novel multi-stage modelling approach where the disentangled factors are first learned using a preexisting disentangled representation learning method.",
    ". disentanglement by penalizing the ( aggregate ) posterior to encourage statistical independence of the latent factors. This approach introduces a trade-off between disentangled representation learning and reconstruction quality since the model does not have enough capacity to learn correlated latent variables that capture detail information present in most image data. To overcome this trade-off, we present a novel multi-stage modelling approach where the disentangled factors are first learned using a preexisting disentangled representation learning method.",
    "an autonomous vehicle would not be able to navigate safely if its state representation did not contain information about the color of the stoplight in front of it. In this paper we focus on analyzing representations learned by maximizing the mutual information ( MI ) between random variables. Correspondence to rakelly @ eecs.berkeley.edu 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). the MI objective to learn representations of visual inputs",
    "an autonomous vehicle would not be able to navigate safely if its state representation did not contain information about the color of the stoplight in front of it. In this paper we focus on analyzing representations learned by maximizing the mutual information ( MI ) between random variables. Correspondence to rakelly @ eecs.berkeley.edu 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). the MI objective to learn representations of visual inputs",
    "an autonomous vehicle would not be able to navigate safely if its state representation did not contain information about the color of the stoplight in front of it. In this paper we focus on analyzing representations learned by maximizing the mutual information ( MI ) between random variables. Correspondence to rakelly @ eecs.berkeley.edu 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). the MI objective to learn representations of visual inputs",
    ". In particular, we introduce a relaxation to parameterize the neural network training problem. Thus, we find an intimate, novel connection between neural network training and copositive programs. In particular, we introduce a relaxation to parameterize the neural network training problem. Thus, we find an intimate, novel connection between neural network training and copositive programs. In this paper, we describe algorithms which can provably find the global minimum of the neural network training problem in polynomial time",
    ". In particular, we introduce a relaxation to parameterize the neural network training problem. Thus, we find an intimate, novel connection between neural network training and copositive programs. In particular, we introduce a relaxation to parameterize the neural network training problem. Thus, we find an intimate, novel connection between neural network training and copositive programs. In this paper, we describe algorithms which can provably find the global minimum of the neural network training problem in polynomial time",
    ". In particular, we introduce a relaxation to parameterize the neural network training problem. Thus, we find an intimate, novel connection between neural network training and copositive programs. In particular, we introduce a relaxation to parameterize the neural network training problem. Thus, we find an intimate, novel connection between neural network training and copositive programs. In this paper, we describe algorithms which can provably find the global minimum of the neural network training problem in polynomial time",
    "object-based attention that disentangles the motion and location of objects from their visual appearance features. From language, we can learn to associate concepts, such as black, pan, and legs, with the referred object \u2019 s visual appearance features. Further, language provides cues about how an input scene should be segmented into individual objects. In this paper, we propose a computational learning paradigm, Language-mediated, Object-centric Representation Learning (",
    "object-based attention that disentangles the motion and location of objects from their visual appearance features. From language, we can learn to associate concepts, such as black, pan, and legs, with the referred object \u2019 s visual appearance features. Further, language provides cues about how an input scene should be segmented into individual objects. In this paper, we propose a computational learning paradigm, Language-mediated, Object-centric Representation Learning (",
    "object-based attention that disentangles the motion and location of objects from their visual appearance features. From language, we can learn to associate concepts, such as black, pan, and legs, with the referred object \u2019 s visual appearance features. Further, language provides cues about how an input scene should be segmented into individual objects. In this paper, we propose a computational learning paradigm, Language-mediated, Object-centric Representation Learning (",
    "FB15k, WN18 and our new dataset where our model perform futher than those state-of-the-arts. In this paper, we propose a general framework, named EM-RBR. EM-RBR aims to utilize relational background knowledge contained in rules to conduct multi-relation reasoning link prediction. In this way, we can find the most reasonable explanation for a given triplet to obtain higher prediction accuracy.",
    "FB15k, WN18 and our new dataset where our model perform futher than those state-of-the-arts. In this paper, we propose a general framework, named EM-RBR. EM-RBR aims to utilize relational background knowledge contained in rules to conduct multi-relation reasoning link prediction. In this way, we can find the most reasonable explanation for a given triplet to obtain higher prediction accuracy.",
    "FB15k, WN18 and our new dataset where our model perform futher than those state-of-the-arts. In this paper, we propose a general framework, named EM-RBR. EM-RBR aims to utilize relational background knowledge contained in rules to conduct multi-relation reasoning link prediction. In this way, we can find the most reasonable explanation for a given triplet to obtain higher prediction accuracy.",
    "the wicker chair in one \u2019 s living room is not just a chair. The fly buzzing in your left ear is the same fly that landed on the table. To model a complex, structured visual environment, multiple OFs must be maintained in parallel. Figure 1 : Two successive frames of PacMan. Figure 2 : Two successive frames of PacMan. Figure 3 : Two successive frames of PacMan. Figure 4 : Two successive frames of PacMan.",
    "the wicker chair in one \u2019 s living room is not just a chair. The fly buzzing in your left ear is the same fly that landed on the table. To model a complex, structured visual environment, multiple OFs must be maintained in parallel. Figure 1 : Two successive frames of PacMan. Figure 2 : Two successive frames of PacMan. Figure 3 : Two successive frames of PacMan. Figure 4 : Two successive frames of PacMan.",
    "the wicker chair in one \u2019 s living room is not just a chair. The fly buzzing in your left ear is the same fly that landed on the table. To model a complex, structured visual environment, multiple OFs must be maintained in parallel. Figure 1 : Two successive frames of PacMan. Figure 2 : Two successive frames of PacMan. Figure 3 : Two successive frames of PacMan. Figure 4 : Two successive frames of PacMan.",
    "the information retrieval process in video-grounded language tasks. These tasks extend the complexity of traditional visual tasks with the additional visual temporal variance. Recently Jang et al. ( 2017 ) ; Lei et al. ( 2018 ) further develop video-grounded language research into the dialogue domain. Our experiments show that VilNMN can achieve promising performance on two video-grounded language tasks : video QA and video-grounded dialogues.",
    "the information retrieval process in video-grounded language tasks. These tasks extend the complexity of traditional visual tasks with the additional visual temporal variance. Recently Jang et al. ( 2017 ) ; Lei et al. ( 2018 ) further develop video-grounded language research into the dialogue domain. Our experiments show that VilNMN can achieve promising performance on two video-grounded language tasks : video QA and video-grounded dialogues.",
    "the information retrieval process in video-grounded language tasks. These tasks extend the complexity of traditional visual tasks with the additional visual temporal variance. Recently Jang et al. ( 2017 ) ; Lei et al. ( 2018 ) further develop video-grounded language research into the dialogue domain. Our experiments show that VilNMN can achieve promising performance on two video-grounded language tasks : video QA and video-grounded dialogues.",
    ". In ( single-agent ) reinforcement learning ( RL ), an agent repeatedly interacts with an environment until it achieves mastery. In ( multiagent ) reinforcement learning ( RL ), an agent repeatedly interacts with an environment until it achieves mastery. In ( multiagent ) reinforcement learning ( RL ), an agent repeatedly interacts with an environment until it achieves mastery. In ( multiagent ) reinforcement learning ( RL",
    ". In ( single-agent ) reinforcement learning ( RL ), an agent repeatedly interacts with an environment until it achieves mastery. In ( multiagent ) reinforcement learning ( RL ), an agent repeatedly interacts with an environment until it achieves mastery. In ( multiagent ) reinforcement learning ( RL ), an agent repeatedly interacts with an environment until it achieves mastery. In ( multiagent ) reinforcement learning ( RL",
    ". In ( single-agent ) reinforcement learning ( RL ), an agent repeatedly interacts with an environment until it achieves mastery. In ( multiagent ) reinforcement learning ( RL ), an agent repeatedly interacts with an environment until it achieves mastery. In ( multiagent ) reinforcement learning ( RL ), an agent repeatedly interacts with an environment until it achieves mastery. In ( multiagent ) reinforcement learning ( RL",
    ". Non-Attentive Tacotron based on the Tacotron 2 text-to-speech model. The attention mechanism is replaced with an explicit duration predictor. This improves robustness significantly as measured by unaligned duration ratio and word deletion rate. This paper presents Non-Attentive Tacotron based on the Tacotron 2 text-to-speech model. The attention mechanism is replaced with an explicit duration predictor. This improves robustness",
    ". Non-Attentive Tacotron based on the Tacotron 2 text-to-speech model. The attention mechanism is replaced with an explicit duration predictor. This improves robustness significantly as measured by unaligned duration ratio and word deletion rate. This paper presents Non-Attentive Tacotron based on the Tacotron 2 text-to-speech model. The attention mechanism is replaced with an explicit duration predictor. This improves robustness",
    ". Non-Attentive Tacotron based on the Tacotron 2 text-to-speech model. The attention mechanism is replaced with an explicit duration predictor. This improves robustness significantly as measured by unaligned duration ratio and word deletion rate. This paper presents Non-Attentive Tacotron based on the Tacotron 2 text-to-speech model. The attention mechanism is replaced with an explicit duration predictor. This improves robustness",
    ". It is also hard and computationally expensive to get accurate depth and point clouds from cameras. In this paper, we show that explicit depth estimation is actually neither sufficient nor necessary for good layout estimation. Explicitly estimating accurate depth is also not necessary because many areas in the 3D space can be occluded partially, e.g. behind a tree trunk. In this paper, we show that explicit depth estimation is actually neither sufficient nor necessary for good layout estimation.",
    ". It is also hard and computationally expensive to get accurate depth and point clouds from cameras. In this paper, we show that explicit depth estimation is actually neither sufficient nor necessary for good layout estimation. Explicitly estimating accurate depth is also not necessary because many areas in the 3D space can be occluded partially, e.g. behind a tree trunk. In this paper, we show that explicit depth estimation is actually neither sufficient nor necessary for good layout estimation.",
    ". It is also hard and computationally expensive to get accurate depth and point clouds from cameras. In this paper, we show that explicit depth estimation is actually neither sufficient nor necessary for good layout estimation. Explicitly estimating accurate depth is also not necessary because many areas in the 3D space can be occluded partially, e.g. behind a tree trunk. In this paper, we show that explicit depth estimation is actually neither sufficient nor necessary for good layout estimation.",
    "focus on learning long-range patterns in multi-relational graphs using graph neural networks ( GNNs ). In this work, we focus on learning long-range patterns in multi-relational graphs using graph neural networks ( GNNs ). In relational GNNs, such as the Relational Graph Convolutional Network ( RGCN ) ( RGCN ) ( RGCN ) ( RGCN ) ( RGCN ) ( RG",
    "focus on learning long-range patterns in multi-relational graphs using graph neural networks ( GNNs ). In this work, we focus on learning long-range patterns in multi-relational graphs using graph neural networks ( GNNs ). In relational GNNs, such as the Relational Graph Convolutional Network ( RGCN ) ( RGCN ) ( RGCN ) ( RGCN ) ( RGCN ) ( RG",
    "focus on learning long-range patterns in multi-relational graphs using graph neural networks ( GNNs ). In this work, we focus on learning long-range patterns in multi-relational graphs using graph neural networks ( GNNs ). In relational GNNs, such as the Relational Graph Convolutional Network ( RGCN ) ( RGCN ) ( RGCN ) ( RGCN ) ( RGCN ) ( RG",
    ". In this work, we present a new application of SMT solvers for explaining neural network decisions. Model explanation can be viewed as identifying a minimal set of features in a given input that is critical to a model \u2019 s prediction. Second, we can not generate reliable explanations based on final model prediction. Thus, we present a new application of SMT solvers for explaining neural network decisions.",
    ". In this work, we present a new application of SMT solvers for explaining neural network decisions. Model explanation can be viewed as identifying a minimal set of features in a given input that is critical to a model \u2019 s prediction. Second, we can not generate reliable explanations based on final model prediction. Thus, we present a new application of SMT solvers for explaining neural network decisions.",
    ". In this work, we present a new application of SMT solvers for explaining neural network decisions. Model explanation can be viewed as identifying a minimal set of features in a given input that is critical to a model \u2019 s prediction. Second, we can not generate reliable explanations based on final model prediction. Thus, we present a new application of SMT solvers for explaining neural network decisions.",
    ". Object pose estimation is a fundamental task in computer vision with a multitude of real-world applications. However, current 3D pose estimation approaches are not robust to partial occlusion and when objects are viewed from a previously unseen pose. This lack of robustness can have serious consequences in real-world applications and therefore needs to be addressed by the research community.",
    ". Object pose estimation is a fundamental task in computer vision with a multitude of real-world applications. However, current 3D pose estimation approaches are not robust to partial occlusion and when objects are viewed from a previously unseen pose. This lack of robustness can have serious consequences in real-world applications and therefore needs to be addressed by the research community.",
    ". Object pose estimation is a fundamental task in computer vision with a multitude of real-world applications. However, current 3D pose estimation approaches are not robust to partial occlusion and when objects are viewed from a previously unseen pose. This lack of robustness can have serious consequences in real-world applications and therefore needs to be addressed by the research community.",
    "a random walk algorithm. Non-Inherent Feature Compatible Learning... expensive.. expensive... expensive. In this work, we introduce an approach for feature compatible learning without inheriting old classifier and training data..   . ..... expensive....",
    "a random walk algorithm. Non-Inherent Feature Compatible Learning... expensive.. expensive... expensive. In this work, we introduce an approach for feature compatible learning without inheriting old classifier and training data..   . ..... expensive....",
    "a random walk algorithm. Non-Inherent Feature Compatible Learning... expensive.. expensive... expensive. In this work, we introduce an approach for feature compatible learning without inheriting old classifier and training data..   . ..... expensive....",
    "). These studies initialize the analysis from the learning dynamics \u2019 perspectives and then extend to the upper bound estimation of generalization errors ( Mou et al., 2017 ). This work studies the use of generalization performance measures ( Li et al., 2020 ; Negrea et al., 2019 ) for model selection purposes ( Cawley & Talbot, 2010 ). The generalization gap G is defined as G (  ) = E",
    "). These studies initialize the analysis from the learning dynamics \u2019 perspectives and then extend to the upper bound estimation of generalization errors ( Mou et al., 2017 ). This work studies the use of generalization performance measures ( Li et al., 2020 ; Negrea et al., 2019 ) for model selection purposes ( Cawley & Talbot, 2010 ). The generalization gap G is defined as G (  ) = E",
    "). These studies initialize the analysis from the learning dynamics \u2019 perspectives and then extend to the upper bound estimation of generalization errors ( Mou et al., 2017 ). This work studies the use of generalization performance measures ( Li et al., 2020 ; Negrea et al., 2019 ) for model selection purposes ( Cawley & Talbot, 2010 ). The generalization gap G is defined as G (  ) = E",
    "; Chen et al., 2017 ; Le & Titov, 2018 ).  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.",
    "; Chen et al., 2017 ; Le & Titov, 2018 ).  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.",
    "; Chen et al., 2017 ; Le & Titov, 2018 ).  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.  Work done during internship with Facebook AI Research.",
    "t e ) +  t e, where x t e is the flow on edge e at time t, fe is the congestion function, and te is a noise sample drawn from an unknown distribution. In this paper, we assume that whenever a vehicle traverses an edge, we observe the time spent on the edge. This induces a natural exploration/exploitation trade-off : we may wish to send vehicles on under",
    "t e ) +  t e, where x t e is the flow on edge e at time t, fe is the congestion function, and te is a noise sample drawn from an unknown distribution. In this paper, we assume that whenever a vehicle traverses an edge, we observe the time spent on the edge. This induces a natural exploration/exploitation trade-off : we may wish to send vehicles on under",
    "t e ) +  t e, where x t e is the flow on edge e at time t, fe is the congestion function, and te is a noise sample drawn from an unknown distribution. In this paper, we assume that whenever a vehicle traverses an edge, we observe the time spent on the edge. This induces a natural exploration/exploitation trade-off : we may wish to send vehicles on under",
    ".......... It is the random choice of single tokens that we address in this paper. PMIMasking reaches the performance of prior masking approaches in half the training time. 1 INTRODUCTION.... ........",
    ".......... It is the random choice of single tokens that we address in this paper. PMIMasking reaches the performance of prior masking approaches in half the training time. 1 INTRODUCTION.... ........",
    ".......... It is the random choice of single tokens that we address in this paper. PMIMasking reaches the performance of prior masking approaches in half the training time. 1 INTRODUCTION.... ........",
    "the approximation gap between the ELBO and the log marginal likelihood is the KL divergence from the approximate to the true posterior. The approximation gap is caused by restricting the approximate posterior to a specific parametric form, the variational family. The amortisation gap is caused by the inference network failing to produce the optimal parameters within the family.",
    "the approximation gap between the ELBO and the log marginal likelihood is the KL divergence from the approximate to the true posterior. The approximation gap is caused by restricting the approximate posterior to a specific parametric form, the variational family. The amortisation gap is caused by the inference network failing to produce the optimal parameters within the family.",
    "the approximation gap between the ELBO and the log marginal likelihood is the KL divergence from the approximate to the true posterior. The approximation gap is caused by restricting the approximate posterior to a specific parametric form, the variational family. The amortisation gap is caused by the inference network failing to produce the optimal parameters within the family.",
    "2016 ; Si et al., 2016 ; Rudi et al., 2018 ; Li et al., 2020a ; Avron et al., 2017a ; Yu et al., 2016 ; Rudi et al., 2016 ). Distributed learning ( Zhang et al., 2013 ; 2015 ; Chang et al., 2017b ; Li et al",
    "2016 ; Si et al., 2016 ; Rudi et al., 2018 ; Li et al., 2020a ; Avron et al., 2017a ; Yu et al., 2016 ; Rudi et al., 2016 ). Distributed learning ( Zhang et al., 2013 ; 2015 ; Chang et al., 2017b ; Li et al",
    "2016 ; Si et al., 2016 ; Rudi et al., 2018 ; Li et al., 2020a ; Avron et al., 2017a ; Yu et al., 2016 ; Rudi et al., 2016 ). Distributed learning ( Zhang et al., 2013 ; 2015 ; Chang et al., 2017b ; Li et al",
    ". In this paper, we introduce the concept of Neural Architecture Search ( NAS ). Neural architecture search ( NAS ) has been successfully utilized to discover novel DNN architectures in complex search spaces. Although these searched architectures can deliver high accuracy, they come with tremendous computation and time costs. Therefore, researchers gradually shift their focuses to one-shot NAS. One-shot NAS is more efficient and can deliver satisfying outputs within a few GPU-days.",
    ". In this paper, we introduce the concept of Neural Architecture Search ( NAS ). Neural architecture search ( NAS ) has been successfully utilized to discover novel DNN architectures in complex search spaces. Although these searched architectures can deliver high accuracy, they come with tremendous computation and time costs. Therefore, researchers gradually shift their focuses to one-shot NAS. One-shot NAS is more efficient and can deliver satisfying outputs within a few GPU-days.",
    ". In this paper, we introduce the concept of Neural Architecture Search ( NAS ). Neural architecture search ( NAS ) has been successfully utilized to discover novel DNN architectures in complex search spaces. Although these searched architectures can deliver high accuracy, they come with tremendous computation and time costs. Therefore, researchers gradually shift their focuses to one-shot NAS. One-shot NAS is more efficient and can deliver satisfying outputs within a few GPU-days.",
    "PERIL is a hybrid framework that combines the merits of both RL and IL. It allows for continual policy improvement through further exploration of the task. PERIL is based on a meta-training dataset of tasks. it is based on a meta-training dataset of tasks. PERIL is based on a meta-training dataset of tasks. PERIL is based on a meta-training dataset of tasks. PERIL is based on a",
    "PERIL is a hybrid framework that combines the merits of both RL and IL. It allows for continual policy improvement through further exploration of the task. PERIL is based on a meta-training dataset of tasks. it is based on a meta-training dataset of tasks. PERIL is based on a meta-training dataset of tasks. PERIL is based on a meta-training dataset of tasks. PERIL is based on a",
    "PERIL is a hybrid framework that combines the merits of both RL and IL. It allows for continual policy improvement through further exploration of the task. PERIL is based on a meta-training dataset of tasks. it is based on a meta-training dataset of tasks. PERIL is based on a meta-training dataset of tasks. PERIL is based on a meta-training dataset of tasks. PERIL is based on a",
    ". In this paper, we analyze a simplified pattern recognition task where all patterns in the images are orthogonal and the classification is binary. The architecture is a 3-layer overparameterized convolutional neural network and it is learned using stochastic gradient descent ( SGD ). Empirically, we identify a novel property of the solutions found by SGD. We observe that the statistics of patterns in the images are orthogonal and the classification is binary. In this paper, we",
    ". In this paper, we analyze a simplified pattern recognition task where all patterns in the images are orthogonal and the classification is binary. The architecture is a 3-layer overparameterized convolutional neural network and it is learned using stochastic gradient descent ( SGD ). Empirically, we identify a novel property of the solutions found by SGD. We observe that the statistics of patterns in the images are orthogonal and the classification is binary. In this paper, we",
    ". In this paper, we analyze a simplified pattern recognition task where all patterns in the images are orthogonal and the classification is binary. The architecture is a 3-layer overparameterized convolutional neural network and it is learned using stochastic gradient descent ( SGD ). Empirically, we identify a novel property of the solutions found by SGD. We observe that the statistics of patterns in the images are orthogonal and the classification is binary. In this paper, we",
    "contrastive learning is capable of recovering a representation of documents that reveals their underlying topic posterior information to linear models. Contrastive learning ( also called noise contrastive estimation, or NCE ) is an alternative representation learning approach that tries to capture the latent structure in unlabeled data implicitly. While principled, this approach is not without its drawbacks. In the context of document classification tasks under topic modeling assumptions, we demonstrate empirically that linear classifiers with these representations perform",
    "contrastive learning is capable of recovering a representation of documents that reveals their underlying topic posterior information to linear models. Contrastive learning ( also called noise contrastive estimation, or NCE ) is an alternative representation learning approach that tries to capture the latent structure in unlabeled data implicitly. While principled, this approach is not without its drawbacks. In the context of document classification tasks under topic modeling assumptions, we demonstrate empirically that linear classifiers with these representations perform",
    "contrastive learning is capable of recovering a representation of documents that reveals their underlying topic posterior information to linear models. Contrastive learning ( also called noise contrastive estimation, or NCE ) is an alternative representation learning approach that tries to capture the latent structure in unlabeled data implicitly. While principled, this approach is not without its drawbacks. In the context of document classification tasks under topic modeling assumptions, we demonstrate empirically that linear classifiers with these representations perform",
    "1 INTRODUCTION To comprehensively describe concepts in the real world, humans collect multiple perceptual signals of the same object such as image, sound, text and video. This collection of different media featuring the same underlying concept is characterised as multimodal data. However, the scope of multimodal learning has been limited to leveraging the commonality between \u201c related \u201d and \u201c unrelated \u201d observations within a multimodal dataset. Figure 2 formalises this proposal.",
    "1 INTRODUCTION To comprehensively describe concepts in the real world, humans collect multiple perceptual signals of the same object such as image, sound, text and video. This collection of different media featuring the same underlying concept is characterised as multimodal data. However, the scope of multimodal learning has been limited to leveraging the commonality between \u201c related \u201d and \u201c unrelated \u201d observations within a multimodal dataset. Figure 2 formalises this proposal.",
    "1 INTRODUCTION To comprehensively describe concepts in the real world, humans collect multiple perceptual signals of the same object such as image, sound, text and video. This collection of different media featuring the same underlying concept is characterised as multimodal data. However, the scope of multimodal learning has been limited to leveraging the commonality between \u201c related \u201d and \u201c unrelated \u201d observations within a multimodal dataset. Figure 2 formalises this proposal.",
    "q ( z ) p ( z ) and a reweighting factor r ( z ). Figure 1 INTRODUCTION q ( z ) p ( z ) p ( z ) r ( z ) We propose an EBM prior using the product of a base prior p ( z ) and a reweighting factor r ( z ). Figure 1 INTRODUCTION",
    "q ( z ) p ( z ) and a reweighting factor r ( z ). Figure 1 INTRODUCTION q ( z ) p ( z ) p ( z ) r ( z ) We propose an EBM prior using the product of a base prior p ( z ) and a reweighting factor r ( z ). Figure 1 INTRODUCTION",
    "q ( z ) p ( z ) and a reweighting factor r ( z ). Figure 1 INTRODUCTION q ( z ) p ( z ) p ( z ) r ( z ) We propose an EBM prior using the product of a base prior p ( z ) and a reweighting factor r ( z ). Figure 1 INTRODUCTION",
    "). Inverse Reinforcement Learning ( IRL ) has been successfully applied to many challenging domains including games ( Mnih et al., 2015 ) and robot control ( Haarnoja et al., 2018 ). However, Geist et al. ( 2019 ) recently proposed a theoretical foundation of regularized Markov decision processes ( MDPs ). Here, Geist et al. ( 2019 ) show that",
    "). Inverse Reinforcement Learning ( IRL ) has been successfully applied to many challenging domains including games ( Mnih et al., 2015 ) and robot control ( Haarnoja et al., 2018 ). However, Geist et al. ( 2019 ) recently proposed a theoretical foundation of regularized Markov decision processes ( MDPs ). Here, Geist et al. ( 2019 ) show that",
    "). Inverse Reinforcement Learning ( IRL ) has been successfully applied to many challenging domains including games ( Mnih et al., 2015 ) and robot control ( Haarnoja et al., 2018 ). However, Geist et al. ( 2019 ) recently proposed a theoretical foundation of regularized Markov decision processes ( MDPs ). Here, Geist et al. ( 2019 ) show that",
    "the search space of which parameters to share and at which granularity grows rapidly. This rapid expansion of the search space prevents us from exhaustively exploring the choice of sharing patterns in multilingual models. While the joint training enables positive Work done while Biao Zhang was interning at Google Research.",
    "the search space of which parameters to share and at which granularity grows rapidly. This rapid expansion of the search space prevents us from exhaustively exploring the choice of sharing patterns in multilingual models. While the joint training enables positive Work done while Biao Zhang was interning at Google Research.",
    "the search space of which parameters to share and at which granularity grows rapidly. This rapid expansion of the search space prevents us from exhaustively exploring the choice of sharing patterns in multilingual models. While the joint training enables positive Work done while Biao Zhang was interning at Google Research.",
    "uncertain and certain samples based on small loss criteria. To this end, we impose geometric constraints on uncertain samples by normalizing them into the Wasserstein ball centered on certain samples. Experimental results demonstrate that our proposed WDN outperforms other state-of-the-art methods for accurate classification. In this paper, we split our data into uncertain and certain samples based on small loss criteria. To this end, we impose geometric constraints on uncertain samples by normalizing them into the Wasserstein ball",
    "uncertain and certain samples based on small loss criteria. To this end, we impose geometric constraints on uncertain samples by normalizing them into the Wasserstein ball centered on certain samples. Experimental results demonstrate that our proposed WDN outperforms other state-of-the-art methods for accurate classification. In this paper, we split our data into uncertain and certain samples based on small loss criteria. To this end, we impose geometric constraints on uncertain samples by normalizing them into the Wasserstein ball",
    "uncertain and certain samples based on small loss criteria. To this end, we impose geometric constraints on uncertain samples by normalizing them into the Wasserstein ball centered on certain samples. Experimental results demonstrate that our proposed WDN outperforms other state-of-the-art methods for accurate classification. In this paper, we split our data into uncertain and certain samples based on small loss criteria. To this end, we impose geometric constraints on uncertain samples by normalizing them into the Wasserstein ball",
    ". This paper describes a method for constructing prediction sets from any pre-trained image classifier that are formally guaranteed to contain the true class with a high probability. Our method modifies a conformal predictor ( Vovk et al., 2005 ) given in Romano et al. ( 2020 ) for the purpose of modern image classification. In this paper, we describe a method for constructing prediction sets from any pre-trained image classifier that are",
    ". This paper describes a method for constructing prediction sets from any pre-trained image classifier that are formally guaranteed to contain the true class with a high probability. Our method modifies a conformal predictor ( Vovk et al., 2005 ) given in Romano et al. ( 2020 ) for the purpose of modern image classification. In this paper, we describe a method for constructing prediction sets from any pre-trained image classifier that are",
    ". This paper describes a method for constructing prediction sets from any pre-trained image classifier that are formally guaranteed to contain the true class with a high probability. Our method modifies a conformal predictor ( Vovk et al., 2005 ) given in Romano et al. ( 2020 ) for the purpose of modern image classification. In this paper, we describe a method for constructing prediction sets from any pre-trained image classifier that are",
    ". For continuous distributions, barycenters can be computed. In this paper, we present a method to compute Wasserstein-2 barycenters of continuous distributions. Our algorithm is straightforward without introducing bias ( e.g. Li et al. ( 2020 ) ). Our algorithm is based on a novel regularized dual formulation where the convex potentials are parameterized by input convex neural networks ( Amos et al. (",
    ". For continuous distributions, barycenters can be computed. In this paper, we present a method to compute Wasserstein-2 barycenters of continuous distributions. Our algorithm is straightforward without introducing bias ( e.g. Li et al. ( 2020 ) ). Our algorithm is based on a novel regularized dual formulation where the convex potentials are parameterized by input convex neural networks ( Amos et al. (",
    ". For continuous distributions, barycenters can be computed. In this paper, we present a method to compute Wasserstein-2 barycenters of continuous distributions. Our algorithm is straightforward without introducing bias ( e.g. Li et al. ( 2020 ) ). Our algorithm is based on a novel regularized dual formulation where the convex potentials are parameterized by input convex neural networks ( Amos et al. (",
    "... a certificate of small norm... to unseen data. a certificate of small norm. perfect generalization to unseen data.ization to unseen data....  perfect generalization to unseen data.. ........",
    "... a certificate of small norm... to unseen data. a certificate of small norm. perfect generalization to unseen data.ization to unseen data....  perfect generalization to unseen data.. ........",
    "... a certificate of small norm... to unseen data. a certificate of small norm. perfect generalization to unseen data.ization to unseen data....  perfect generalization to unseen data.. ........",
    "simple, easy to implement, and can readily incorporate fully off-policy data with experience replay. In this work, we propose advantage-weighted regression ( AWR ), a simple off-policy algorithm for model-free RL. AWR achieves competitive results when compared to commonly used on-policy and off-policy RL methods. In this work, we provide a theoretical analysis of AWR, including the capability to incorporate fully off-policy data",
    "simple, easy to implement, and can readily incorporate fully off-policy data with experience replay. In this work, we propose advantage-weighted regression ( AWR ), a simple off-policy algorithm for model-free RL. AWR achieves competitive results when compared to commonly used on-policy and off-policy RL methods. In this work, we provide a theoretical analysis of AWR, including the capability to incorporate fully off-policy data",
    "simple, easy to implement, and can readily incorporate fully off-policy data with experience replay. In this work, we propose advantage-weighted regression ( AWR ), a simple off-policy algorithm for model-free RL. AWR achieves competitive results when compared to commonly used on-policy and off-policy RL methods. In this work, we provide a theoretical analysis of AWR, including the capability to incorporate fully off-policy data",
    "the training loss. ( 1 ) Sinusoidal functions ( sin2 ) have periodic minima. By adjusting the period, the minima can be positioned on quantization levels corresponding to a bitwidth at per-layer granularity. ( 2 ) WaveQ is a differentiable regularization mechanism. By adding our parametric sinusoidal regularizer to the original training objective function, our method automatically yields the bitwidths for each layer along with nearly quantized",
    "the training loss. ( 1 ) Sinusoidal functions ( sin2 ) have periodic minima. By adjusting the period, the minima can be positioned on quantization levels corresponding to a bitwidth at per-layer granularity. ( 2 ) WaveQ is a differentiable regularization mechanism. By adding our parametric sinusoidal regularizer to the original training objective function, our method automatically yields the bitwidths for each layer along with nearly quantized",
    "the training loss. ( 1 ) Sinusoidal functions ( sin2 ) have periodic minima. By adjusting the period, the minima can be positioned on quantization levels corresponding to a bitwidth at per-layer granularity. ( 2 ) WaveQ is a differentiable regularization mechanism. By adding our parametric sinusoidal regularizer to the original training objective function, our method automatically yields the bitwidths for each layer along with nearly quantized",
    "a target-to-target model is trained. The resulting synthetic parallel corpus can be added to existing training data to learn a source-to-target model. This is a special case in Computer Vision research. In this paper, we will focus on data augmentation techniques in neural machine translation ( NMT ) which is special and more difficult than other NLP tasks. For example, if in-domain monolingual training data is available, existing methods such as random swapping two words",
    "a target-to-target model is trained. The resulting synthetic parallel corpus can be added to existing training data to learn a source-to-target model. This is a special case in Computer Vision research. In this paper, we will focus on data augmentation techniques in neural machine translation ( NMT ) which is special and more difficult than other NLP tasks. For example, if in-domain monolingual training data is available, existing methods such as random swapping two words",
    "a target-to-target model is trained. The resulting synthetic parallel corpus can be added to existing training data to learn a source-to-target model. This is a special case in Computer Vision research. In this paper, we will focus on data augmentation techniques in neural machine translation ( NMT ) which is special and more difficult than other NLP tasks. For example, if in-domain monolingual training data is available, existing methods such as random swapping two words",
    "the Shapley Value in game theory. To address this issue, this paper proposes a real-time contribution measurement method. Firstly, the method defines the impact of each agent. Furthermore, we comprehensively consider the current round and the previous round to obtain the contribution rate of each agent. To verify effectiveness of the proposed method, the comparative experiment result shows that the proposed method is more sensitive to both data quantity and data quality under the premise of maintaining real-time. \u2022 We propose",
    "the Shapley Value in game theory. To address this issue, this paper proposes a real-time contribution measurement method. Firstly, the method defines the impact of each agent. Furthermore, we comprehensively consider the current round and the previous round to obtain the contribution rate of each agent. To verify effectiveness of the proposed method, the comparative experiment result shows that the proposed method is more sensitive to both data quantity and data quality under the premise of maintaining real-time. \u2022 We propose",
    "the Shapley Value in game theory. To address this issue, this paper proposes a real-time contribution measurement method. Firstly, the method defines the impact of each agent. Furthermore, we comprehensively consider the current round and the previous round to obtain the contribution rate of each agent. To verify effectiveness of the proposed method, the comparative experiment result shows that the proposed method is more sensitive to both data quantity and data quality under the premise of maintaining real-time. \u2022 We propose",
    "( 2006 ) ; Abbeel et al. ( 2006 ) ; Santhanam et al. ( 2012 ) ; Santhanam et al. ( 2012 ) ; Santhanam et al. ( 2012 ) ; Loh et al. ( 2013 ; 2014 ) ; Bresler ( 2015 ) ). In this paper, we study the problem of learning Bayesian networks where an",
    "( 2006 ) ; Abbeel et al. ( 2006 ) ; Santhanam et al. ( 2012 ) ; Santhanam et al. ( 2012 ) ; Santhanam et al. ( 2012 ) ; Loh et al. ( 2013 ; 2014 ) ; Bresler ( 2015 ) ). In this paper, we study the problem of learning Bayesian networks where an",
    "( 2006 ) ; Abbeel et al. ( 2006 ) ; Santhanam et al. ( 2012 ) ; Santhanam et al. ( 2012 ) ; Santhanam et al. ( 2012 ) ; Loh et al. ( 2013 ; 2014 ) ; Bresler ( 2015 ) ). In this paper, we study the problem of learning Bayesian networks where an",
    ",. In this work, we argue that more powerful planners are necessary for longer-horizon reasoning. As shown in Figure 1, we extend the myopic planning behavior of existing visual planning approaches. With this goal of long-horizon planning, we aim to extend the myopic planning behavior of existing visual planning approaches. As shown in Figure 1, this ability to reason over long horizons enables collocation to explore much more effectively and efficiently.",
    ",. In this work, we argue that more powerful planners are necessary for longer-horizon reasoning. As shown in Figure 1, we extend the myopic planning behavior of existing visual planning approaches. With this goal of long-horizon planning, we aim to extend the myopic planning behavior of existing visual planning approaches. As shown in Figure 1, this ability to reason over long horizons enables collocation to explore much more effectively and efficiently.",
    ",. In this work, we argue that more powerful planners are necessary for longer-horizon reasoning. As shown in Figure 1, we extend the myopic planning behavior of existing visual planning approaches. With this goal of long-horizon planning, we aim to extend the myopic planning behavior of existing visual planning approaches. As shown in Figure 1, this ability to reason over long horizons enables collocation to explore much more effectively and efficiently.",
    "if we take the usual Bayesian viewpoint. In contrast, tempered posteriors directly give performance comparable to a carefully trained finite network. While new priors have been suggested ( Wenzel et al., 2020 ), these results are puzzling if we take the usual Bayesian viewpoint. Here, we consider the possibility that it is predominantly ( but not entirely ) the likelihood, and not the prior that is at fault. In particular, we note",
    "if we take the usual Bayesian viewpoint. In contrast, tempered posteriors directly give performance comparable to a carefully trained finite network. While new priors have been suggested ( Wenzel et al., 2020 ), these results are puzzling if we take the usual Bayesian viewpoint. Here, we consider the possibility that it is predominantly ( but not entirely ) the likelihood, and not the prior that is at fault. In particular, we note",
    "if we take the usual Bayesian viewpoint. In contrast, tempered posteriors directly give performance comparable to a carefully trained finite network. While new priors have been suggested ( Wenzel et al., 2020 ), these results are puzzling if we take the usual Bayesian viewpoint. Here, we consider the possibility that it is predominantly ( but not entirely ) the likelihood, and not the prior that is at fault. In particular, we note",
    ". This property limits parallelization. A flurry of recent work developed ways to ( partially ) parallelize the decoder with non-autoregressive machine translation ( NAR ). Recent work suggests that better speed-quality tradeoffs can be achieved by having different depths in the encoder and the decoder. In this work, we make a formal argument in favor of deep encoder, shallow decoder configurations and empirically demonstrate better speed-quality tradeoffs",
    ". This property limits parallelization. A flurry of recent work developed ways to ( partially ) parallelize the decoder with non-autoregressive machine translation ( NAR ). Recent work suggests that better speed-quality tradeoffs can be achieved by having different depths in the encoder and the decoder. In this work, we make a formal argument in favor of deep encoder, shallow decoder configurations and empirically demonstrate better speed-quality tradeoffs",
    ". This property limits parallelization. A flurry of recent work developed ways to ( partially ) parallelize the decoder with non-autoregressive machine translation ( NAR ). Recent work suggests that better speed-quality tradeoffs can be achieved by having different depths in the encoder and the decoder. In this work, we make a formal argument in favor of deep encoder, shallow decoder configurations and empirically demonstrate better speed-quality tradeoffs",
    ". Model-wise double descent, i.e., as a DNN \u2019 s model complexity increases, its test error first shows a classical U-shaped curve and then enters a second descent, has been observed on many machine learning models. In particular, Yang et al. ( 2020 ) performed bias-variance decomposition for mean squared error ( MSE ) and the cross-entropy ( CE ) loss. In addition",
    ". Model-wise double descent, i.e., as a DNN \u2019 s model complexity increases, its test error first shows a classical U-shaped curve and then enters a second descent, has been observed on many machine learning models. In particular, Yang et al. ( 2020 ) performed bias-variance decomposition for mean squared error ( MSE ) and the cross-entropy ( CE ) loss. In addition",
    ". Model-wise double descent, i.e., as a DNN \u2019 s model complexity increases, its test error first shows a classical U-shaped curve and then enters a second descent, has been observed on many machine learning models. In particular, Yang et al. ( 2020 ) performed bias-variance decomposition for mean squared error ( MSE ) and the cross-entropy ( CE ) loss. In addition",
    "fast generalization adaptation to unseen tasks. Corresponding : Ren Wang ( renwang348117609 @ umich.edu ) Corresponding : Ren Wang ( renwang@umich.edu ) Corresponding : Ren Wang ( renwang@umich.edu ) Corresponding : Ren Wang ( renwang@umich.edu ) Corresponding : Ren Wang ( renwang",
    "fast generalization adaptation to unseen tasks. Corresponding : Ren Wang ( renwang348117609 @ umich.edu ) Corresponding : Ren Wang ( renwang@umich.edu ) Corresponding : Ren Wang ( renwang@umich.edu ) Corresponding : Ren Wang ( renwang@umich.edu ) Corresponding : Ren Wang ( renwang",
    "fast generalization adaptation to unseen tasks. Corresponding : Ren Wang ( renwang348117609 @ umich.edu ) Corresponding : Ren Wang ( renwang@umich.edu ) Corresponding : Ren Wang ( renwang@umich.edu ) Corresponding : Ren Wang ( renwang@umich.edu ) Corresponding : Ren Wang ( renwang",
    "a simple problem of tuning the step size for quadratic loss. We characterize when it is necessary to compute the meta-objective on a separate validation set instead of the original training set. Finally, we verify our results empirically and show that a similar phenomenon appears even for more complicated learned optimizers.",
    "a simple problem of tuning the step size for quadratic loss. We characterize when it is necessary to compute the meta-objective on a separate validation set instead of the original training set. Finally, we verify our results empirically and show that a similar phenomenon appears even for more complicated learned optimizers.",
    "a simple problem of tuning the step size for quadratic loss. We characterize when it is necessary to compute the meta-objective on a separate validation set instead of the original training set. Finally, we verify our results empirically and show that a similar phenomenon appears even for more complicated learned optimizers.",
    ". Graph problems can be divided into three main directions : link prediction ( Zhang et al., 2018a ), graph classification ( Zhang et al., 2018b ) and semi-supervised node classification ( Kipf & Welling, 2016 ). Graph problems can be roughly divided into three directions : link prediction ( Zhang et al., 2018a ), graph classification ( Zhang et al., 2018b )",
    ". Graph problems can be divided into three main directions : link prediction ( Zhang et al., 2018a ), graph classification ( Zhang et al., 2018b ) and semi-supervised node classification ( Kipf & Welling, 2016 ). Graph problems can be roughly divided into three directions : link prediction ( Zhang et al., 2018a ), graph classification ( Zhang et al., 2018b )",
    ". Graph problems can be divided into three main directions : link prediction ( Zhang et al., 2018a ), graph classification ( Zhang et al., 2018b ) and semi-supervised node classification ( Kipf & Welling, 2016 ). Graph problems can be roughly divided into three directions : link prediction ( Zhang et al., 2018a ), graph classification ( Zhang et al., 2018b )",
    "in the context of Hamiltonian Neural Networks ( HNNs ) Greydanus et al. ( 2019 ). We extend this approach by learning and incorporating additional constraints due to further symmetries of the system. 0.6 0.8 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0",
    "in the context of Hamiltonian Neural Networks ( HNNs ) Greydanus et al. ( 2019 ). We extend this approach by learning and incorporating additional constraints due to further symmetries of the system. 0.6 0.8 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0",
    "in the context of Hamiltonian Neural Networks ( HNNs ) Greydanus et al. ( 2019 ). We extend this approach by learning and incorporating additional constraints due to further symmetries of the system. 0.6 0.8 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0",
    ". Graph neural networks ( GNNs ) have shown great success in learning on graph-structured data with various applications in molecular design ( Stokes et al., 2020 ). Yet tabular data with detailed information and rich semantics among nodes in the graph are more natural for many situations and abundant in real-world AI ( Xiao et al., 2019 ). Graph neural networks ( GNNs ) have shown great success in learning on",
    ". Graph neural networks ( GNNs ) have shown great success in learning on graph-structured data with various applications in molecular design ( Stokes et al., 2020 ). Yet tabular data with detailed information and rich semantics among nodes in the graph are more natural for many situations and abundant in real-world AI ( Xiao et al., 2019 ). Graph neural networks ( GNNs ) have shown great success in learning on",
    ". Graph neural networks ( GNNs ) have shown great success in learning on graph-structured data with various applications in molecular design ( Stokes et al., 2020 ). Yet tabular data with detailed information and rich semantics among nodes in the graph are more natural for many situations and abundant in real-world AI ( Xiao et al., 2019 ). Graph neural networks ( GNNs ) have shown great success in learning on",
    ". Meta-learning, also known as \u201c learning to learn \u201d, has recently emerged as a powerful paradigm for learning to adapt to unseen tasks. Meta-learning, also known as \u201c learning to learn \u201d, has recently emerged as a powerful paradigm for learning to adapt to unseen tasks. Meta-learning has been successfully applied to many real problems, including few-shot image classification ( Finn et al., 2017 ; Snell et al.,",
    ". Meta-learning, also known as \u201c learning to learn \u201d, has recently emerged as a powerful paradigm for learning to adapt to unseen tasks. Meta-learning, also known as \u201c learning to learn \u201d, has recently emerged as a powerful paradigm for learning to adapt to unseen tasks. Meta-learning has been successfully applied to many real problems, including few-shot image classification ( Finn et al., 2017 ; Snell et al.,",
    ". Meta-learning, also known as \u201c learning to learn \u201d, has recently emerged as a powerful paradigm for learning to adapt to unseen tasks. Meta-learning, also known as \u201c learning to learn \u201d, has recently emerged as a powerful paradigm for learning to adapt to unseen tasks. Meta-learning has been successfully applied to many real problems, including few-shot image classification ( Finn et al., 2017 ; Snell et al.,",
    "; Liu & Tao, 2016 ; Scott, 2015 ; Natarajan et al., 2013 ; Natarajan et al., 2013 ; Goldberger & Ben-Reuven, 2013 ). Label noise is a common problem in machine learning. Label noise is a common problem in machine learning. Label noise is a common problem in machine learning. However, label noise is not a problem in machine learning.",
    "; Liu & Tao, 2016 ; Scott, 2015 ; Natarajan et al., 2013 ; Natarajan et al., 2013 ; Goldberger & Ben-Reuven, 2013 ). Label noise is a common problem in machine learning. Label noise is a common problem in machine learning. Label noise is a common problem in machine learning. However, label noise is not a problem in machine learning.",
    "; Liu & Tao, 2016 ; Scott, 2015 ; Natarajan et al., 2013 ; Natarajan et al., 2013 ; Goldberger & Ben-Reuven, 2013 ). Label noise is a common problem in machine learning. Label noise is a common problem in machine learning. Label noise is a common problem in machine learning. However, label noise is not a problem in machine learning.",
    ". Unlike adversarial examples ( Szegedy et al., 2014 ; Goodfellow et al., 2014 ; Suciu et al., 2018 ), data poisoning attacks corrupt the model such that it misclassifies many clean testing examples. Unlike adversarial examples ( Szegedy et al., 2014 ; Goodfellow et al., 2014 ; Suciu et al.,",
    ". Unlike adversarial examples ( Szegedy et al., 2014 ; Goodfellow et al., 2014 ; Suciu et al., 2018 ), data poisoning attacks corrupt the model such that it misclassifies many clean testing examples. Unlike adversarial examples ( Szegedy et al., 2014 ; Goodfellow et al., 2014 ; Suciu et al.,",
    ". Unlike adversarial examples ( Szegedy et al., 2014 ; Goodfellow et al., 2014 ; Suciu et al., 2018 ), data poisoning attacks corrupt the model such that it misclassifies many clean testing examples. Unlike adversarial examples ( Szegedy et al., 2014 ; Goodfellow et al., 2014 ; Suciu et al.,",
    "..., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.",
    "..., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.",
    "..., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.., 512 ,.",
    ". However, these scores are unreliable and may even be misleading. A detector can raise a red flag whenever the predictions are suspicious. A human observer can then evaluate such predictions. In a practical setting, such a detector can raise a red flag whenever the predictions are suspicious. In order to construct such a detector, quantitative metrics for measuring predictive reliability are first developed. In order to construct such a detector, a warning threshold is then set based on users \u2019",
    ". However, these scores are unreliable and may even be misleading. A detector can raise a red flag whenever the predictions are suspicious. A human observer can then evaluate such predictions. In a practical setting, such a detector can raise a red flag whenever the predictions are suspicious. In order to construct such a detector, quantitative metrics for measuring predictive reliability are first developed. In order to construct such a detector, a warning threshold is then set based on users \u2019",
    ". However, these scores are unreliable and may even be misleading. A detector can raise a red flag whenever the predictions are suspicious. A human observer can then evaluate such predictions. In a practical setting, such a detector can raise a red flag whenever the predictions are suspicious. In order to construct such a detector, quantitative metrics for measuring predictive reliability are first developed. In order to construct such a detector, a warning threshold is then set based on users \u2019",
    "based on heuristics, or weakly supervised learning. These approaches suffer from the following limitations. First, frequent answers or entities might lead to false positive examples. As an example, the sentence \u201c Ada Lovelace died in 1852 in London \u201d would be considered as a positive example. The sentence \u201c Ada Lovelace died in 1852 in London \u201d would be considered as a false positive example. A third limitation is the lack of training data for the retriever",
    "based on heuristics, or weakly supervised learning. These approaches suffer from the following limitations. First, frequent answers or entities might lead to false positive examples. As an example, the sentence \u201c Ada Lovelace died in 1852 in London \u201d would be considered as a positive example. The sentence \u201c Ada Lovelace died in 1852 in London \u201d would be considered as a false positive example. A third limitation is the lack of training data for the retriever",
    "based on heuristics, or weakly supervised learning. These approaches suffer from the following limitations. First, frequent answers or entities might lead to false positive examples. As an example, the sentence \u201c Ada Lovelace died in 1852 in London \u201d would be considered as a positive example. The sentence \u201c Ada Lovelace died in 1852 in London \u201d would be considered as a false positive example. A third limitation is the lack of training data for the retriever",
    ". In this paper, we propose specifying constraints in formal languages to add useful structure based on expert knowledge. In this paper, we propose specifying CMDP constraints in formal languages to add useful structure based on expert knowledge. In this paper, we propose specifying CMDP constraints in formal languages to add useful structure based on expert knowledge.",
    ". In this paper, we propose specifying constraints in formal languages to add useful structure based on expert knowledge. In this paper, we propose specifying CMDP constraints in formal languages to add useful structure based on expert knowledge. In this paper, we propose specifying CMDP constraints in formal languages to add useful structure based on expert knowledge.",
    ". In this paper, we propose specifying constraints in formal languages to add useful structure based on expert knowledge. In this paper, we propose specifying CMDP constraints in formal languages to add useful structure based on expert knowledge. In this paper, we propose specifying CMDP constraints in formal languages to add useful structure based on expert knowledge.",
    "binary classification is widely used in the medical and scientific domains. However, in order for a model to be useful in real-world applications, it is imperative that users are able to understand and explain the logic underlying model predictions. In this paper, comprehensibility and interpretability are used interchangeably. decision tree models, on the other hand, have transparent decision making steps. A traversal of features on the decision path from the root to the leaf node is presented to users as",
    "binary classification is widely used in the medical and scientific domains. However, in order for a model to be useful in real-world applications, it is imperative that users are able to understand and explain the logic underlying model predictions. In this paper, comprehensibility and interpretability are used interchangeably. decision tree models, on the other hand, have transparent decision making steps. A traversal of features on the decision path from the root to the leaf node is presented to users as",
    "binary classification is widely used in the medical and scientific domains. However, in order for a model to be useful in real-world applications, it is imperative that users are able to understand and explain the logic underlying model predictions. In this paper, comprehensibility and interpretability are used interchangeably. decision tree models, on the other hand, have transparent decision making steps. A traversal of features on the decision path from the root to the leaf node is presented to users as",
    "1 INTRODUCTION Deep neural networks have shown great empirical success in solving a variety of tasks across different application domains. In this paper, we propose and test methods of increasing network width while keeping the number of parameters constant. Suprisingly, we find scenarios under which most of the performance benefits come from increasing the width. \u2022 We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant.",
    "1 INTRODUCTION Deep neural networks have shown great empirical success in solving a variety of tasks across different application domains. In this paper, we propose and test methods of increasing network width while keeping the number of parameters constant. Suprisingly, we find scenarios under which most of the performance benefits come from increasing the width. \u2022 We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant.",
    "1 INTRODUCTION Deep neural networks have shown great empirical success in solving a variety of tasks across different application domains. In this paper, we propose and test methods of increasing network width while keeping the number of parameters constant. Suprisingly, we find scenarios under which most of the performance benefits come from increasing the width. \u2022 We propose three candidate methods ( illustrated in Figure 2 ) for increasing network width while keeping the number of parameters constant.",
    ". Knowledge graphs ( KGs ) represent entities and relations in a structural way. They can also solve the sparsity problem in text modeling. For instance, a language model may require tens of instances of the phrase \u201c labrador is a kind of dog \u201d in its training corpus before it implicitly learns this fact. Knowledge graphs ( KGs ) represent entities and relations in a structural way. They can also solve the sparsity problem in text",
    ". Knowledge graphs ( KGs ) represent entities and relations in a structural way. They can also solve the sparsity problem in text modeling. For instance, a language model may require tens of instances of the phrase \u201c labrador is a kind of dog \u201d in its training corpus before it implicitly learns this fact. Knowledge graphs ( KGs ) represent entities and relations in a structural way. They can also solve the sparsity problem in text",
    ". Knowledge graphs ( KGs ) represent entities and relations in a structural way. They can also solve the sparsity problem in text modeling. For instance, a language model may require tens of instances of the phrase \u201c labrador is a kind of dog \u201d in its training corpus before it implicitly learns this fact. Knowledge graphs ( KGs ) represent entities and relations in a structural way. They can also solve the sparsity problem in text",
    "). However, recent developments in natural language processing have demonstrated the power of the left-to-right autoregressive order. This makes designing algorithms that can leverage autoregressive orders an important research domain. Stern et al., 2019b ; Welleck et al., 2019b ; Stern et al., 2019b ). This could be explained if domainindependent methodology for identifying high-quality autoregressive orders is open question",
    "). However, recent developments in natural language processing have demonstrated the power of the left-to-right autoregressive order. This makes designing algorithms that can leverage autoregressive orders an important research domain. Stern et al., 2019b ; Welleck et al., 2019b ; Stern et al., 2019b ). This could be explained if domainindependent methodology for identifying high-quality autoregressive orders is open question",
    "). However, recent developments in natural language processing have demonstrated the power of the left-to-right autoregressive order. This makes designing algorithms that can leverage autoregressive orders an important research domain. Stern et al., 2019b ; Welleck et al., 2019b ; Stern et al., 2019b ). This could be explained if domainindependent methodology for identifying high-quality autoregressive orders is open question",
    "supervised graph classification ( Kipf & Welling, 2016 ), protein interface prediction ( Fout et al., 2017 ), and knowledge graph ( Fout et al., 2017 ). However, scaling GCNs to large graphs is not straight forward. Third, sampling-based methods are only based on the structure of the graph. Finding the optimal adaptive importance sampling distribution is computationally inadmissible. Fourth, the",
    "supervised graph classification ( Kipf & Welling, 2016 ), protein interface prediction ( Fout et al., 2017 ), and knowledge graph ( Fout et al., 2017 ). However, scaling GCNs to large graphs is not straight forward. Third, sampling-based methods are only based on the structure of the graph. Finding the optimal adaptive importance sampling distribution is computationally inadmissible. Fourth, the",
    "supervised graph classification ( Kipf & Welling, 2016 ), protein interface prediction ( Fout et al., 2017 ), and knowledge graph ( Fout et al., 2017 ). However, scaling GCNs to large graphs is not straight forward. Third, sampling-based methods are only based on the structure of the graph. Finding the optimal adaptive importance sampling distribution is computationally inadmissible. Fourth, the",
    ". At manipulation time, our generator allows for general image changes by modifying the primitive input representation of the image. At manipulation time, our generator allows for making general image changes by modifying the primitive input representation. In this paper, we introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods. In this paper, we demonstrate that simply training a conditional adversarial generator on a single target image is sufficient",
    ". At manipulation time, our generator allows for general image changes by modifying the primitive input representation of the image. At manipulation time, our generator allows for making general image changes by modifying the primitive input representation. In this paper, we introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods. In this paper, we demonstrate that simply training a conditional adversarial generator on a single target image is sufficient",
    ". At manipulation time, our generator allows for general image changes by modifying the primitive input representation of the image. At manipulation time, our generator allows for making general image changes by modifying the primitive input representation. In this paper, we introduce a novel method for training deep conditional generative models from a single image. The objective differs from popular single-image methods. In this paper, we demonstrate that simply training a conditional adversarial generator on a single target image is sufficient",
    "MCSP uses node degree as its heuristic by choosing high-degree nodes to visit first. What is worse, they rely on several heuristics on how to explore the search space. This paper presents GLSEARCH ( Graph Learning to Search ), a general framework for MCS detection combining machine learning and labeled data. GLSEARCH combines machine learning and labeled data.",
    "MCSP uses node degree as its heuristic by choosing high-degree nodes to visit first. What is worse, they rely on several heuristics on how to explore the search space. This paper presents GLSEARCH ( Graph Learning to Search ), a general framework for MCS detection combining machine learning and labeled data. GLSEARCH combines machine learning and labeled data.",
    "MCSP uses node degree as its heuristic by choosing high-degree nodes to visit first. What is worse, they rely on several heuristics on how to explore the search space. This paper presents GLSEARCH ( Graph Learning to Search ), a general framework for MCS detection combining machine learning and labeled data. GLSEARCH combines machine learning and labeled data.",
    "a  smallest common denominator '', the least committal representation that can be reliably generated with low-level signal processing. Specifically, many man-made objects are ( approximately ) polyhedral and can be described by corners, straight edges and/or planar surfaces. Reconstructed wireframes are not only a  compression technique '' to save storage. Their biggest advantage in many applications is that they are easy to manipulate and edit, automatically or",
    "a  smallest common denominator '', the least committal representation that can be reliably generated with low-level signal processing. Specifically, many man-made objects are ( approximately ) polyhedral and can be described by corners, straight edges and/or planar surfaces. Reconstructed wireframes are not only a  compression technique '' to save storage. Their biggest advantage in many applications is that they are easy to manipulate and edit, automatically or",
    "a  smallest common denominator '', the least committal representation that can be reliably generated with low-level signal processing. Specifically, many man-made objects are ( approximately ) polyhedral and can be described by corners, straight edges and/or planar surfaces. Reconstructed wireframes are not only a  compression technique '' to save storage. Their biggest advantage in many applications is that they are easy to manipulate and edit, automatically or",
    "SGD can achieve the minimax optimal convergence rate for both convex and nonconvex optimization problems. However, adaptive gradient methods have become the method of choice for training deep neural networks. We present a different perspective on understanding the benefits of adaptivity by considering it in the context of non-stationary neural networks. We show that adaptive gradient methods can achieve the minimax optimal convergence rate for both convex and nonconvex optimization problems. We also show that adaptive gradient methods can achieve the minimax optimal",
    "SGD can achieve the minimax optimal convergence rate for both convex and nonconvex optimization problems. However, adaptive gradient methods have become the method of choice for training deep neural networks. We present a different perspective on understanding the benefits of adaptivity by considering it in the context of non-stationary neural networks. We show that adaptive gradient methods can achieve the minimax optimal convergence rate for both convex and nonconvex optimization problems. We also show that adaptive gradient methods can achieve the minimax optimal",
    "SGD can achieve the minimax optimal convergence rate for both convex and nonconvex optimization problems. However, adaptive gradient methods have become the method of choice for training deep neural networks. We present a different perspective on understanding the benefits of adaptivity by considering it in the context of non-stationary neural networks. We show that adaptive gradient methods can achieve the minimax optimal convergence rate for both convex and nonconvex optimization problems. We also show that adaptive gradient methods can achieve the minimax optimal",
    "..... The latter is to leverage 1https : //translate.google.com pre-specified translations. The latter is to leverage 1https : //translate.google.com pre-specified translations to guide the MT input. The latter is to leverage 1https : //translate.google.com pre-specified translations to guide the MT input. The latter is to leverage",
    "..... The latter is to leverage 1https : //translate.google.com pre-specified translations. The latter is to leverage 1https : //translate.google.com pre-specified translations to guide the MT input. The latter is to leverage 1https : //translate.google.com pre-specified translations to guide the MT input. The latter is to leverage",
    "..... The latter is to leverage 1https : //translate.google.com pre-specified translations. The latter is to leverage 1https : //translate.google.com pre-specified translations to guide the MT input. The latter is to leverage 1https : //translate.google.com pre-specified translations to guide the MT input. The latter is to leverage",
    ". And yet the underlying assumptions are almost always those of a Markov Decision Process ( MDP ). This is exacerbated by the absence of a unifying benchmark for all of RL. We propose a benchmark which distills difficulties for MDPs that can be generalised across RL problems and allows to control these difficulties for more precise experiments.",
    ". And yet the underlying assumptions are almost always those of a Markov Decision Process ( MDP ). This is exacerbated by the absence of a unifying benchmark for all of RL. We propose a benchmark which distills difficulties for MDPs that can be generalised across RL problems and allows to control these difficulties for more precise experiments.",
    ". And yet the underlying assumptions are almost always those of a Markov Decision Process ( MDP ). This is exacerbated by the absence of a unifying benchmark for all of RL. We propose a benchmark which distills difficulties for MDPs that can be generalised across RL problems and allows to control these difficulties for more precise experiments.",
    ". For supervised machine learning, the notion of calibration is a measure of evaluating how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For example, a binary classifier will be considered perfectly calibrated if, among all predictions with probability score 0.9, 90 % of the true test outputs are correct ( Guo et al., 2017 ). Similarly, consider a probabilistic regression model that produces credible",
    ". For supervised machine learning, the notion of calibration is a measure of evaluating how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For example, a binary classifier will be considered perfectly calibrated if, among all predictions with probability score 0.9, 90 % of the true test outputs are correct ( Guo et al., 2017 ). Similarly, consider a probabilistic regression model that produces credible",
    ". For supervised machine learning, the notion of calibration is a measure of evaluating how well a model \u2019 s confidence in its prediction matches with the correctness of these predictions. For example, a binary classifier will be considered perfectly calibrated if, among all predictions with probability score 0.9, 90 % of the true test outputs are correct ( Guo et al., 2017 ). Similarly, consider a probabilistic regression model that produces credible",
    ". However, they lack a predictive distribution. Thus, we address the problem of learning representations of spatial environments. To that end, we integrate assumptions from multiple-view geometry and rigid-body dynamics commonly used in modern SLAM systems. With that, our model maintains the favourable properties of generative modelling and enables prediction. \u2022 We use the recently published approach of Mirchev et al. ( 2019 ) as a starting point.",
    ". However, they lack a predictive distribution. Thus, we address the problem of learning representations of spatial environments. To that end, we integrate assumptions from multiple-view geometry and rigid-body dynamics commonly used in modern SLAM systems. With that, our model maintains the favourable properties of generative modelling and enables prediction. \u2022 We use the recently published approach of Mirchev et al. ( 2019 ) as a starting point.",
    ". However, they lack a predictive distribution. Thus, we address the problem of learning representations of spatial environments. To that end, we integrate assumptions from multiple-view geometry and rigid-body dynamics commonly used in modern SLAM systems. With that, our model maintains the favourable properties of generative modelling and enables prediction. \u2022 We use the recently published approach of Mirchev et al. ( 2019 ) as a starting point.",
    ". In this paper, we propose a model to learn an effective grounding for entities and dynamics without requiring any prior mapping between text and state observations. To achieve this, we develop a new model called EMMA ( Entity Mapper with Multimodal Attention ). We train the entire model in a multi-task fashion using only scalar reward signals from the environment. This is done using a multi-modal attention mechanism which uses entity representations as queries to attend to specific tokens in",
    ". In this paper, we propose a model to learn an effective grounding for entities and dynamics without requiring any prior mapping between text and state observations. To achieve this, we develop a new model called EMMA ( Entity Mapper with Multimodal Attention ). We train the entire model in a multi-task fashion using only scalar reward signals from the environment. This is done using a multi-modal attention mechanism which uses entity representations as queries to attend to specific tokens in",
    ". In this paper, we propose a model to learn an effective grounding for entities and dynamics without requiring any prior mapping between text and state observations. To achieve this, we develop a new model called EMMA ( Entity Mapper with Multimodal Attention ). We train the entire model in a multi-task fashion using only scalar reward signals from the environment. This is done using a multi-modal attention mechanism which uses entity representations as queries to attend to specific tokens in",
    "). However, new studies ( Tucker et al., 2018 ; Ilyas et al., 2020 ) indicate that \u201c much larger gains could be achieved by instead improving the accuracy of the value function \u201d. These findings leave the reader skeptical about actor-critic algorithms. In Tucker et al. ( 2018 ), the authors argue that \u201c much larger gains could be achieved by instead improving the accuracy of the value function \u201d.",
    "). However, new studies ( Tucker et al., 2018 ; Ilyas et al., 2020 ) indicate that \u201c much larger gains could be achieved by instead improving the accuracy of the value function \u201d. These findings leave the reader skeptical about actor-critic algorithms. In Tucker et al. ( 2018 ), the authors argue that \u201c much larger gains could be achieved by instead improving the accuracy of the value function \u201d.",
    "). However, new studies ( Tucker et al., 2018 ; Ilyas et al., 2020 ) indicate that \u201c much larger gains could be achieved by instead improving the accuracy of the value function \u201d. These findings leave the reader skeptical about actor-critic algorithms. In Tucker et al. ( 2018 ), the authors argue that \u201c much larger gains could be achieved by instead improving the accuracy of the value function \u201d.",
    ". However, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well",
    ". However, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well",
    ". However, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well. As for generalization, we do not have general theory that explains why deep learning works so well",
    "a general representation function class and obtain a similar result. Next, we consider the setting where the common representation may be high-dimensional but is capacity-constrained. Here, we again demonstrate the advantage of representation learning in both high-dimensional linear regression and neural networks. While representation learning has achieved tremendous success in a variety of applications ( Bengio et al., 2013 ), its theoretical studies are limited. While representation learning has achieved tremendous success in a variety of applications, its",
    "a general representation function class and obtain a similar result. Next, we consider the setting where the common representation may be high-dimensional but is capacity-constrained. Here, we again demonstrate the advantage of representation learning in both high-dimensional linear regression and neural networks. While representation learning has achieved tremendous success in a variety of applications ( Bengio et al., 2013 ), its theoretical studies are limited. While representation learning has achieved tremendous success in a variety of applications, its",
    "a general representation function class and obtain a similar result. Next, we consider the setting where the common representation may be high-dimensional but is capacity-constrained. Here, we again demonstrate the advantage of representation learning in both high-dimensional linear regression and neural networks. While representation learning has achieved tremendous success in a variety of applications ( Bengio et al., 2013 ), its theoretical studies are limited. While representation learning has achieved tremendous success in a variety of applications, its",
    ". Feature-defined neighborhoods We propose to analyze network robustness to perturbations of high-level input features. A small perturbation to a feature translates to changes of multiple input entries ( e.g., image pixels ) and as such may produce visible perturbations. To illustrate, consider a neighborhood around Figure 1 ( a ) and Figure 1 ( b ) in which only the background pixels can change their color. To illustrate, consider a neighborhood around Figure 1 (",
    ". Feature-defined neighborhoods We propose to analyze network robustness to perturbations of high-level input features. A small perturbation to a feature translates to changes of multiple input entries ( e.g., image pixels ) and as such may produce visible perturbations. To illustrate, consider a neighborhood around Figure 1 ( a ) and Figure 1 ( b ) in which only the background pixels can change their color. To illustrate, consider a neighborhood around Figure 1 (",
    ". Feature-defined neighborhoods We propose to analyze network robustness to perturbations of high-level input features. A small perturbation to a feature translates to changes of multiple input entries ( e.g., image pixels ) and as such may produce visible perturbations. To illustrate, consider a neighborhood around Figure 1 ( a ) and Figure 1 ( b ) in which only the background pixels can change their color. To illustrate, consider a neighborhood around Figure 1 (",
    ". However, in some cases an incorrect similarity assumption can hurt learning performance. In this paper we provide an easy, straightforward approach to avoid human assumptions on task similarities. This is known as positive transfer ( Lazaric, 2012 ). However, if the tasks are sufficiently similar, negative transfer occurs and reusing a pre-trained policy is disadvantageous. This can even lead to a worse performance than simply starting with a random initialization.",
    ". However, in some cases an incorrect similarity assumption can hurt learning performance. In this paper we provide an easy, straightforward approach to avoid human assumptions on task similarities. This is known as positive transfer ( Lazaric, 2012 ). However, if the tasks are sufficiently similar, negative transfer occurs and reusing a pre-trained policy is disadvantageous. This can even lead to a worse performance than simply starting with a random initialization.",
    ". However, in some cases an incorrect similarity assumption can hurt learning performance. In this paper we provide an easy, straightforward approach to avoid human assumptions on task similarities. This is known as positive transfer ( Lazaric, 2012 ). However, if the tasks are sufficiently similar, negative transfer occurs and reusing a pre-trained policy is disadvantageous. This can even lead to a worse performance than simply starting with a random initialization.",
    "unsupervised representation learning is well studied in domains such as vision ( Donahue & Simonyan, 2019 ; Denton et al., 2017 ) and natural language processing ( Young et al., 2018 ; Mikolov et al., 2013 ). Moreover, it should account for and be able to model dynamic changes that occur within samples. Moreover, the lack of well-defined or available labels that are needed for identifying",
    "unsupervised representation learning is well studied in domains such as vision ( Donahue & Simonyan, 2019 ; Denton et al., 2017 ) and natural language processing ( Young et al., 2018 ; Mikolov et al., 2013 ). Moreover, it should account for and be able to model dynamic changes that occur within samples. Moreover, the lack of well-defined or available labels that are needed for identifying",
    "unsupervised representation learning is well studied in domains such as vision ( Donahue & Simonyan, 2019 ; Denton et al., 2017 ) and natural language processing ( Young et al., 2018 ; Mikolov et al., 2013 ). Moreover, it should account for and be able to model dynamic changes that occur within samples. Moreover, the lack of well-defined or available labels that are needed for identifying",
    "a databank of template blocks and ( b ) vectors of \u201c mixture weights \u201d that are used to generate weights for every layer. This approach can be utilized for a variety of applications from producing compact networks and training multi-task models. The experimental results show that : ( a ) when used for multi-task training, our model organizes its modules where tasks share first few layers. ( b ) when used for multi-task training, our model organizes its modules",
    "a databank of template blocks and ( b ) vectors of \u201c mixture weights \u201d that are used to generate weights for every layer. This approach can be utilized for a variety of applications from producing compact networks and training multi-task models. The experimental results show that : ( a ) when used for multi-task training, our model organizes its modules where tasks share first few layers. ( b ) when used for multi-task training, our model organizes its modules",
    "a databank of template blocks and ( b ) vectors of \u201c mixture weights \u201d that are used to generate weights for every layer. This approach can be utilized for a variety of applications from producing compact networks and training multi-task models. The experimental results show that : ( a ) when used for multi-task training, our model organizes its modules where tasks share first few layers. ( b ) when used for multi-task training, our model organizes its modules",
    "2x  0. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation",
    "2x  0. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation",
    "2x  0. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation data is assumed to follow a Gaussian distribution. In this case, the posterior of the observation",
    ",, a deep probabilistic VAE non i.i.d. model with both local and global latent variable........ ), ,, ( ),,,,,, to perform domain alignment, or to ensure fairness....",
    ",, a deep probabilistic VAE non i.i.d. model with both local and global latent variable........ ), ,, ( ),,,,,, to perform domain alignment, or to ensure fairness....",
    ",, a deep probabilistic VAE non i.i.d. model with both local and global latent variable........ ), ,, ( ),,,,,, to perform domain alignment, or to ensure fairness....",
    "pre-trained using ImageNet or similar datasets. ( 2 ) This method of training is a passive approach in that it does not encode interactions. Moreover, by observing another person interact with the environment, infants can significantly enhance their perception and cognition. ( 3 ) This method of training is a passive approach in that it does not encode interactions. ( 4 ) This method of training is a passive approach in that it does not encode interactions. ( 5 ) This method",
    "pre-trained using ImageNet or similar datasets. ( 2 ) This method of training is a passive approach in that it does not encode interactions. Moreover, by observing another person interact with the environment, infants can significantly enhance their perception and cognition. ( 3 ) This method of training is a passive approach in that it does not encode interactions. ( 4 ) This method of training is a passive approach in that it does not encode interactions. ( 5 ) This method",
    "pre-trained using ImageNet or similar datasets. ( 2 ) This method of training is a passive approach in that it does not encode interactions. Moreover, by observing another person interact with the environment, infants can significantly enhance their perception and cognition. ( 3 ) This method of training is a passive approach in that it does not encode interactions. ( 4 ) This method of training is a passive approach in that it does not encode interactions. ( 5 ) This method",
    "Fig. 1 INTRODUCTION. We formalize the basic ingredients of sequential learning as following a path on a learning manifold as depicted in Fig. 1. We establish experimentally for a variety of task changes and datasets that this final performance can be highly dependent on the way the chosen model is trained. we also provide three ways to remove the negative pretraining effect that can occur for certain task changes in neural network training as depicted in Fig. 2.",
    "Fig. 1 INTRODUCTION. We formalize the basic ingredients of sequential learning as following a path on a learning manifold as depicted in Fig. 1. We establish experimentally for a variety of task changes and datasets that this final performance can be highly dependent on the way the chosen model is trained. we also provide three ways to remove the negative pretraining effect that can occur for certain task changes in neural network training as depicted in Fig. 2.",
    "Fig. 1 INTRODUCTION. We formalize the basic ingredients of sequential learning as following a path on a learning manifold as depicted in Fig. 1. We establish experimentally for a variety of task changes and datasets that this final performance can be highly dependent on the way the chosen model is trained. we also provide three ways to remove the negative pretraining effect that can occur for certain task changes in neural network training as depicted in Fig. 2.",
    "the study of adversarial examples has been an arms race between adversaries, who manipulate inputs to raise network malfunction. in this paper, we approach the adversarial robustness problem from a different perspective. instead of defending networks from already perturbed examples, we assume the situation where the defenders can also influence inputs slightly for their interest. instead of defending networks from already perturbed examples, we assume the situation where the defenders can also influence inputs slightly for their interest",
    "the study of adversarial examples has been an arms race between adversaries, who manipulate inputs to raise network malfunction. in this paper, we approach the adversarial robustness problem from a different perspective. instead of defending networks from already perturbed examples, we assume the situation where the defenders can also influence inputs slightly for their interest. instead of defending networks from already perturbed examples, we assume the situation where the defenders can also influence inputs slightly for their interest",
    "the study of adversarial examples has been an arms race between adversaries, who manipulate inputs to raise network malfunction. in this paper, we approach the adversarial robustness problem from a different perspective. instead of defending networks from already perturbed examples, we assume the situation where the defenders can also influence inputs slightly for their interest. instead of defending networks from already perturbed examples, we assume the situation where the defenders can also influence inputs slightly for their interest",
    "dynamic point clouds are irregular and unordered in the spatial dimension while points are not consistent and even flow in and out over time. Moreover, voxel sequences are irregular and unordered in the spatial dimension while points are not consistent and even flow in and out over time. Moreover, the scales of spatial displacements and temporal differences in point cloud sequences may not be compatible. Moreover, the scales of spatial displacements and temporal differences in point cloud sequences may not",
    "dynamic point clouds are irregular and unordered in the spatial dimension while points are not consistent and even flow in and out over time. Moreover, voxel sequences are irregular and unordered in the spatial dimension while points are not consistent and even flow in and out over time. Moreover, the scales of spatial displacements and temporal differences in point cloud sequences may not be compatible. Moreover, the scales of spatial displacements and temporal differences in point cloud sequences may not",
    "dynamic point clouds are irregular and unordered in the spatial dimension while points are not consistent and even flow in and out over time. Moreover, voxel sequences are irregular and unordered in the spatial dimension while points are not consistent and even flow in and out over time. Moreover, the scales of spatial displacements and temporal differences in point cloud sequences may not be compatible. Moreover, the scales of spatial displacements and temporal differences in point cloud sequences may not",
    ". Custom voice aims to synthesize natural human voice when training with a large amount of high-quality and single-speaker corpora. However, these corpora contain a fixed set of speakers where each speaker still has a certain amount of speech data. Furthermore, there are several distinctive challenges in custom voice : 1 ) The recordings of the custom users are usually of different acoustic conditions from the source speech data ( the data to train the source TTS model )",
    ". Custom voice aims to synthesize natural human voice when training with a large amount of high-quality and single-speaker corpora. However, these corpora contain a fixed set of speakers where each speaker still has a certain amount of speech data. Furthermore, there are several distinctive challenges in custom voice : 1 ) The recordings of the custom users are usually of different acoustic conditions from the source speech data ( the data to train the source TTS model )",
    ". Custom voice aims to synthesize natural human voice when training with a large amount of high-quality and single-speaker corpora. However, these corpora contain a fixed set of speakers where each speaker still has a certain amount of speech data. Furthermore, there are several distinctive challenges in custom voice : 1 ) The recordings of the custom users are usually of different acoustic conditions from the source speech data ( the data to train the source TTS model )",
    "sparse networks to converge to the same performance as dense neural architectures have been elusive. In this paper, we take a broader view of training sparse networks and consider various choices made during training that might disadvantage sparse networks. Moreover, overparameterized deep neural networks have been shown to be more prone to memorization. Moreover, overparameterized deep neural networks have been shown to be more prone to memorization. In this paper, we",
    "sparse networks to converge to the same performance as dense neural architectures have been elusive. In this paper, we take a broader view of training sparse networks and consider various choices made during training that might disadvantage sparse networks. Moreover, overparameterized deep neural networks have been shown to be more prone to memorization. Moreover, overparameterized deep neural networks have been shown to be more prone to memorization. In this paper, we",
    "sparse networks to converge to the same performance as dense neural architectures have been elusive. In this paper, we take a broader view of training sparse networks and consider various choices made during training that might disadvantage sparse networks. Moreover, overparameterized deep neural networks have been shown to be more prone to memorization. Moreover, overparameterized deep neural networks have been shown to be more prone to memorization. In this paper, we",
    ".. ( 1 ) feature/label smoothing where we analyze how the initial feature/label of one node influences the final feature/label of another node. ( 2 ) feature/label influence of how much the initial feature/label of one node influences the final feature/label of another node. ( 3 ) feature/label influence of how much the initial feature/label of one node influences the final feature/label of another node.",
    ".. ( 1 ) feature/label smoothing where we analyze how the initial feature/label of one node influences the final feature/label of another node. ( 2 ) feature/label influence of how much the initial feature/label of one node influences the final feature/label of another node. ( 3 ) feature/label influence of how much the initial feature/label of one node influences the final feature/label of another node.",
    ".. ( 1 ) feature/label smoothing where we analyze how the initial feature/label of one node influences the final feature/label of another node. ( 2 ) feature/label influence of how much the initial feature/label of one node influences the final feature/label of another node. ( 3 ) feature/label influence of how much the initial feature/label of one node influences the final feature/label of another node.",
    "the generalization error of a classifier. In this paper, we work with Rademacher complexity and propose extensions that provide a new perspective on generalization error. From a statistical perspective, the generalization error of a classifier can be understood through convergence bounds on the error function, i.e., the expected deviation of the error function on the test data compared to the training data. Thus, higher Rm ( F ) leads to a greater generalization gap and",
    "the generalization error of a classifier. In this paper, we work with Rademacher complexity and propose extensions that provide a new perspective on generalization error. From a statistical perspective, the generalization error of a classifier can be understood through convergence bounds on the error function, i.e., the expected deviation of the error function on the test data compared to the training data. Thus, higher Rm ( F ) leads to a greater generalization gap and",
    "the generalization error of a classifier. In this paper, we work with Rademacher complexity and propose extensions that provide a new perspective on generalization error. From a statistical perspective, the generalization error of a classifier can be understood through convergence bounds on the error function, i.e., the expected deviation of the error function on the test data compared to the training data. Thus, higher Rm ( F ) leads to a greater generalization gap and",
    ". However, this pipeline requires a full training dataset and many computation resources to perform end-to-end backpropagation. Therefore, there is more demand in industry for quantizing the neural networks without retraining. Although, PTQ is fast and light, it suffers from severe accuracy degeneration when the quantization precision is low. However, PTQ can not further quantize the weights into INT2 because the cross-layer dependency in the Hessian matrix can not",
    ". However, this pipeline requires a full training dataset and many computation resources to perform end-to-end backpropagation. Therefore, there is more demand in industry for quantizing the neural networks without retraining. Although, PTQ is fast and light, it suffers from severe accuracy degeneration when the quantization precision is low. However, PTQ can not further quantize the weights into INT2 because the cross-layer dependency in the Hessian matrix can not",
    ". However, this pipeline requires a full training dataset and many computation resources to perform end-to-end backpropagation. Therefore, there is more demand in industry for quantizing the neural networks without retraining. Although, PTQ is fast and light, it suffers from severe accuracy degeneration when the quantization precision is low. However, PTQ can not further quantize the weights into INT2 because the cross-layer dependency in the Hessian matrix can not",
    "calibration. Calibration is the extent to which model certainty reflects the actual correctness likelihood. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP.",
    "calibration. Calibration is the extent to which model certainty reflects the actual correctness likelihood. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP.",
    "calibration. Calibration is the extent to which model certainty reflects the actual correctness likelihood. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP. Calibration can be important for beam-search in NLP.",
    "agents that learn to communicate via actuating their joints in a 3D environment. We show that under realistic assumptions, a non-uniform distribution of intents and a commonknowledge energy cost, these agents can find protocols that generalize to novel partners. Finally, we propose and evaluate initial training improvements to address these challenges. In this work, we extend this line of work to a new modality, by studying agents that learn to communicate via actuating their joints in a",
    "agents that learn to communicate via actuating their joints in a 3D environment. We show that under realistic assumptions, a non-uniform distribution of intents and a commonknowledge energy cost, these agents can find protocols that generalize to novel partners. Finally, we propose and evaluate initial training improvements to address these challenges. In this work, we extend this line of work to a new modality, by studying agents that learn to communicate via actuating their joints in a",
    "agents that learn to communicate via actuating their joints in a 3D environment. We show that under realistic assumptions, a non-uniform distribution of intents and a commonknowledge energy cost, these agents can find protocols that generalize to novel partners. Finally, we propose and evaluate initial training improvements to address these challenges. In this work, we extend this line of work to a new modality, by studying agents that learn to communicate via actuating their joints in a",
    ".... a meta-modeling concept..... well as a meta-modeling approach. This paper focuses on uncertainty quantification in sequential regression tasks, particularly in the context of deep recurrent networks.... ....... ( 2017 )..",
    ".... a meta-modeling concept..... well as a meta-modeling approach. This paper focuses on uncertainty quantification in sequential regression tasks, particularly in the context of deep recurrent networks.... ....... ( 2017 )..",
    ".... a meta-modeling concept..... well as a meta-modeling approach. This paper focuses on uncertainty quantification in sequential regression tasks, particularly in the context of deep recurrent networks.... ....... ( 2017 )..",
    "xi = ( xi ) i is a finite set of points. For instance, if X = ( xi ) i is a finite set of points, then  =  imixi ( xi is the Dirac mass at xi ) is simply a set of positive weights mi =  ( xi )  0 associated to each point xi. For instance, if",
    "xi = ( xi ) i is a finite set of points. For instance, if X = ( xi ) i is a finite set of points, then  =  imixi ( xi is the Dirac mass at xi ) is simply a set of positive weights mi =  ( xi )  0 associated to each point xi. For instance, if",
    "xi = ( xi ) i is a finite set of points. For instance, if X = ( xi ) i is a finite set of points, then  =  imixi ( xi is the Dirac mass at xi ) is simply a set of positive weights mi =  ( xi )  0 associated to each point xi. For instance, if",
    ". 2 ) The second group enforces sparsity as model regularization. It does not require network retraining. 3 ) The third group develops saliency criteria to prune less important units ( Han et al., 2015 ; Narang et al., 2016 ; Lee et al., 2019 ; Park et al., 2020 ; Evci et al., 2019 ). 4 ) The",
    ". 2 ) The second group enforces sparsity as model regularization. It does not require network retraining. 3 ) The third group develops saliency criteria to prune less important units ( Han et al., 2015 ; Narang et al., 2016 ; Lee et al., 2019 ; Park et al., 2020 ; Evci et al., 2019 ). 4 ) The",
    ". 2 ) The second group enforces sparsity as model regularization. It does not require network retraining. 3 ) The third group develops saliency criteria to prune less important units ( Han et al., 2015 ; Narang et al., 2016 ; Lee et al., 2019 ; Park et al., 2020 ; Evci et al., 2019 ). 4 ) The",
    ". Semantic image editing is the task of transforming a source image to a target image while modifying desired semantic attributes. ( i ) image-space editing methods directly transform one image to another across domains. ( ii ) latent-space editing methods focus on discovering latent variable manipulations that permit continuous semantic image edits. Semantic image editing is useful for various real-world tasks, including artistic visualization, design, photo enhancement, and targeted data augmentation",
    ". Semantic image editing is the task of transforming a source image to a target image while modifying desired semantic attributes. ( i ) image-space editing methods directly transform one image to another across domains. ( ii ) latent-space editing methods focus on discovering latent variable manipulations that permit continuous semantic image edits. Semantic image editing is useful for various real-world tasks, including artistic visualization, design, photo enhancement, and targeted data augmentation",
    ". Semantic image editing is the task of transforming a source image to a target image while modifying desired semantic attributes. ( i ) image-space editing methods directly transform one image to another across domains. ( ii ) latent-space editing methods focus on discovering latent variable manipulations that permit continuous semantic image edits. Semantic image editing is useful for various real-world tasks, including artistic visualization, design, photo enhancement, and targeted data augmentation",
    "accumulative mismatch along with the increment of generated sequence length. Generative Adversarial Networks ( GANs ) ( Goodfellow et al., 2014 ) can serve as an alternative to models trained by MLE. However, GANs still suffer from some intrinsic problems, such as mode dropping, reward sparsity, and training instability.",
    "accumulative mismatch along with the increment of generated sequence length. Generative Adversarial Networks ( GANs ) ( Goodfellow et al., 2014 ) can serve as an alternative to models trained by MLE. However, GANs still suffer from some intrinsic problems, such as mode dropping, reward sparsity, and training instability.",
    "accumulative mismatch along with the increment of generated sequence length. Generative Adversarial Networks ( GANs ) ( Goodfellow et al., 2014 ) can serve as an alternative to models trained by MLE. However, GANs still suffer from some intrinsic problems, such as mode dropping, reward sparsity, and training instability.",
    "progressive. For example, in the Atari game Video Pinball, the player can increase a \u201c bonus multiplier \u201d that increases the score paid per bumper hit. Since the bonus multiplier does not reset until the player dies, the rewards typically increase with time. This property also arises in many games settings. For example, in the Atari game Video Pinball, the player can increase a \u201c bonus multiplier \u201d that increases the score paid per bumper hit. Since the bonus",
    "progressive. For example, in the Atari game Video Pinball, the player can increase a \u201c bonus multiplier \u201d that increases the score paid per bumper hit. Since the bonus multiplier does not reset until the player dies, the rewards typically increase with time. This property also arises in many games settings. For example, in the Atari game Video Pinball, the player can increase a \u201c bonus multiplier \u201d that increases the score paid per bumper hit. Since the bonus",
    "progressive. For example, in the Atari game Video Pinball, the player can increase a \u201c bonus multiplier \u201d that increases the score paid per bumper hit. Since the bonus multiplier does not reset until the player dies, the rewards typically increase with time. This property also arises in many games settings. For example, in the Atari game Video Pinball, the player can increase a \u201c bonus multiplier \u201d that increases the score paid per bumper hit. Since the bonus",
    ". We propose to study a simple task inspired by decision-making tasks in neuroscience. we then extend our findings to standard image classification tasks trained with state-of-the-art models. our neuroscience-inspired task is the checkerboard ( CB ) task ( Chandrasekaran et al., 2017 ; Kleinman et al., 2019 ).",
    ". We propose to study a simple task inspired by decision-making tasks in neuroscience. we then extend our findings to standard image classification tasks trained with state-of-the-art models. our neuroscience-inspired task is the checkerboard ( CB ) task ( Chandrasekaran et al., 2017 ; Kleinman et al., 2019 ).",
    ". We propose to study a simple task inspired by decision-making tasks in neuroscience. we then extend our findings to standard image classification tasks trained with state-of-the-art models. our neuroscience-inspired task is the checkerboard ( CB ) task ( Chandrasekaran et al., 2017 ; Kleinman et al., 2019 ).",
    "n n i=1 F ( x, y ; i ) ( finite-sum case ) ( 1 ) where f ( x, y ) is -strongly concave with respect to y for all x  Rd1. ( 2 ) The objective function  (  ) in eq. ( 2 ) is nonconvex in general, and hence algorithms for solving",
    "n n i=1 F ( x, y ; i ) ( finite-sum case ) ( 1 ) where f ( x, y ) is -strongly concave with respect to y for all x  Rd1. ( 2 ) The objective function  (  ) in eq. ( 2 ) is nonconvex in general, and hence algorithms for solving",
    "n n i=1 F ( x, y ; i ) ( finite-sum case ) ( 1 ) where f ( x, y ) is -strongly concave with respect to y for all x  Rd1. ( 2 ) The objective function  (  ) in eq. ( 2 ) is nonconvex in general, and hence algorithms for solving",
    "; ( 2 ) learning a suitably general visual representation ( metric ) that supports recognition of previously unseen object categories based on ( ideally ) a single example. In this paper, we operationalize this question using an example-based visual search task ( figure 1 ) that has been investigated before using handwritten characters ( Omniglot ; Michaelis et al. ( 2018a ) ) and real-world image datasets ( Zhang et al. (",
    "; ( 2 ) learning a suitably general visual representation ( metric ) that supports recognition of previously unseen object categories based on ( ideally ) a single example. In this paper, we operationalize this question using an example-based visual search task ( figure 1 ) that has been investigated before using handwritten characters ( Omniglot ; Michaelis et al. ( 2018a ) ) and real-world image datasets ( Zhang et al. (",
    "; ( 2 ) learning a suitably general visual representation ( metric ) that supports recognition of previously unseen object categories based on ( ideally ) a single example. In this paper, we operationalize this question using an example-based visual search task ( figure 1 ) that has been investigated before using handwritten characters ( Omniglot ; Michaelis et al. ( 2018a ) ) and real-world image datasets ( Zhang et al. (",
    "; ( 2 ) learning a suitably general visual representation ( metric ) that supports recognition of previously unseen object categories based on ( ideally ) a single example. In this paper, we operationalize this question using an example-based visual search task ( figure 1 ) that has been investigated before using handwritten characters ( Omniglot ; Michaelis et al. ( 2018a ) ) and real-world image datasets ( Zhang et al. (",
    ".. our model performs well when generalizing to unseen images from ShapeNet and ScannetV2.. 3D geometry with a textured mesh ( Kato et al., 2018 ) or point cloud ( Yu et al., 2020 ). However, such representations require supervision signals from every location. In this paper, we demonstrate single view implicit surface reconstructions on real-world scenes.. Ina",
    ".. our model performs well when generalizing to unseen images from ShapeNet and ScannetV2.. 3D geometry with a textured mesh ( Kato et al., 2018 ) or point cloud ( Yu et al., 2020 ). However, such representations require supervision signals from every location. In this paper, we demonstrate single view implicit surface reconstructions on real-world scenes.. Ina",
    ".. our model performs well when generalizing to unseen images from ShapeNet and ScannetV2.. 3D geometry with a textured mesh ( Kato et al., 2018 ) or point cloud ( Yu et al., 2020 ). However, such representations require supervision signals from every location. In this paper, we demonstrate single view implicit surface reconstructions on real-world scenes.. Ina",
    ".. our model performs well when generalizing to unseen images from ShapeNet and ScannetV2.. 3D geometry with a textured mesh ( Kato et al., 2018 ) or point cloud ( Yu et al., 2020 ). However, such representations require supervision signals from every location. In this paper, we demonstrate single view implicit surface reconstructions on real-world scenes.. Ina",
    "the neural scaling law [ 13 ]. These studies have demonstrated the neural scaling law [ 13 ]. Generally there are two tracks of research in large-scale pretraining, dense models and sparse expert models respectively. Dense expert models with large model capacity are capable of fast training owing to the combination of data parallelism and expert parallelism [ 35 ; 14 ; 11 ; 32 ]. Sparse expert models with large model capacity are capable of fast training owing to",
    "the neural scaling law [ 13 ]. These studies have demonstrated the neural scaling law [ 13 ]. Generally there are two tracks of research in large-scale pretraining, dense models and sparse expert models respectively. Dense expert models with large model capacity are capable of fast training owing to the combination of data parallelism and expert parallelism [ 35 ; 14 ; 11 ; 32 ]. Sparse expert models with large model capacity are capable of fast training owing to",
    "the neural scaling law [ 13 ]. These studies have demonstrated the neural scaling law [ 13 ]. Generally there are two tracks of research in large-scale pretraining, dense models and sparse expert models respectively. Dense expert models with large model capacity are capable of fast training owing to the combination of data parallelism and expert parallelism [ 35 ; 14 ; 11 ; 32 ]. Sparse expert models with large model capacity are capable of fast training owing to",
    "the neural scaling law [ 13 ]. These studies have demonstrated the neural scaling law [ 13 ]. Generally there are two tracks of research in large-scale pretraining, dense models and sparse expert models respectively. Dense expert models with large model capacity are capable of fast training owing to the combination of data parallelism and expert parallelism [ 35 ; 14 ; 11 ; 32 ]. Sparse expert models with large model capacity are capable of fast training owing to",
    "the particles in the sample space and the neurons in the parameter space of the energy at a faster rate. In the lazy regime, this dual formulation leads to a training algorithm in which the particles are restarted at every iteration step. These results are illustrated in simple numerical experiments. 1 INTRODUCTION. Energy-based models ( EBMs ) are explicit generative models which consider Gibbs measures defined through an energy function f, with a probability density proportional to exp (",
    "the particles in the sample space and the neurons in the parameter space of the energy at a faster rate. In the lazy regime, this dual formulation leads to a training algorithm in which the particles are restarted at every iteration step. These results are illustrated in simple numerical experiments. 1 INTRODUCTION. Energy-based models ( EBMs ) are explicit generative models which consider Gibbs measures defined through an energy function f, with a probability density proportional to exp (",
    "the particles in the sample space and the neurons in the parameter space of the energy at a faster rate. In the lazy regime, this dual formulation leads to a training algorithm in which the particles are restarted at every iteration step. These results are illustrated in simple numerical experiments. 1 INTRODUCTION. Energy-based models ( EBMs ) are explicit generative models which consider Gibbs measures defined through an energy function f, with a probability density proportional to exp (",
    "the particles in the sample space and the neurons in the parameter space of the energy at a faster rate. In the lazy regime, this dual formulation leads to a training algorithm in which the particles are restarted at every iteration step. These results are illustrated in simple numerical experiments. 1 INTRODUCTION. Energy-based models ( EBMs ) are explicit generative models which consider Gibbs measures defined through an energy function f, with a probability density proportional to exp (",
    "the first ( tight )  ( p n ) lower bound. As for pure-DP, we introduce an auxiliary dimension to simplify the computation brought by  2 loss. As for pure-DP, we achieve the first ( tight )  ( p n ) lower bound. As for pure-DP, we introduce a novel biased mean property instead of linear functions considered by previous papers. As for pure-DP, we introduce an auxiliary dimension to simplify",
    "the first ( tight )  ( p n ) lower bound. As for pure-DP, we introduce an auxiliary dimension to simplify the computation brought by  2 loss. As for pure-DP, we achieve the first ( tight )  ( p n ) lower bound. As for pure-DP, we introduce a novel biased mean property instead of linear functions considered by previous papers. As for pure-DP, we introduce an auxiliary dimension to simplify",
    "the first ( tight )  ( p n ) lower bound. As for pure-DP, we introduce an auxiliary dimension to simplify the computation brought by  2 loss. As for pure-DP, we achieve the first ( tight )  ( p n ) lower bound. As for pure-DP, we introduce a novel biased mean property instead of linear functions considered by previous papers. As for pure-DP, we introduce an auxiliary dimension to simplify",
    "the first ( tight )  ( p n ) lower bound. As for pure-DP, we introduce an auxiliary dimension to simplify the computation brought by  2 loss. As for pure-DP, we achieve the first ( tight )  ( p n ) lower bound. As for pure-DP, we introduce a novel biased mean property instead of linear functions considered by previous papers. As for pure-DP, we introduce an auxiliary dimension to simplify",
    ". The Wasserstein gradient flow is a model of the gradient dynamics over the space of probability densities. It was first discovered by Jordan, Kinderlehrer, and Otto ( JKO ) in their seminal work ( Jordan et al., 1998 ). The Wasserstein gradient flow is a model of the gradient dynamics over the space of probability densities. We aim to develop a scalable method to compute the Wasserstein gradient flow without discretizing the underlying space",
    ". The Wasserstein gradient flow is a model of the gradient dynamics over the space of probability densities. It was first discovered by Jordan, Kinderlehrer, and Otto ( JKO ) in their seminal work ( Jordan et al., 1998 ). The Wasserstein gradient flow is a model of the gradient dynamics over the space of probability densities. We aim to develop a scalable method to compute the Wasserstein gradient flow without discretizing the underlying space",
    ". The Wasserstein gradient flow is a model of the gradient dynamics over the space of probability densities. It was first discovered by Jordan, Kinderlehrer, and Otto ( JKO ) in their seminal work ( Jordan et al., 1998 ). The Wasserstein gradient flow is a model of the gradient dynamics over the space of probability densities. We aim to develop a scalable method to compute the Wasserstein gradient flow without discretizing the underlying space",
    ". The Wasserstein gradient flow is a model of the gradient dynamics over the space of probability densities. It was first discovered by Jordan, Kinderlehrer, and Otto ( JKO ) in their seminal work ( Jordan et al., 1998 ). The Wasserstein gradient flow is a model of the gradient dynamics over the space of probability densities. We aim to develop a scalable method to compute the Wasserstein gradient flow without discretizing the underlying space",
    "; Stern et al., 2010 ; Kotthoff, 2014 ; Bergstra et al., 2002 ; Song et al., 2012 ; Bardenet et al., 2013 ; Feurer et al., 2014 ; 2015 ; Hazan et al. ; 2018 ; Fusi et al., 2018 ; Yang et al., 2019 ).",
    "; Stern et al., 2010 ; Kotthoff, 2014 ; Bergstra et al., 2002 ; Song et al., 2012 ; Bardenet et al., 2013 ; Feurer et al., 2014 ; 2015 ; Hazan et al. ; 2018 ; Fusi et al., 2018 ; Yang et al., 2019 ).",
    "; Stern et al., 2010 ; Kotthoff, 2014 ; Bergstra et al., 2002 ; Song et al., 2012 ; Bardenet et al., 2013 ; Feurer et al., 2014 ; 2015 ; Hazan et al. ; 2018 ; Fusi et al., 2018 ; Yang et al., 2019 ).",
    "; Stern et al., 2010 ; Kotthoff, 2014 ; Bergstra et al., 2002 ; Song et al., 2012 ; Bardenet et al., 2013 ; Feurer et al., 2014 ; 2015 ; Hazan et al. ; 2018 ; Fusi et al., 2018 ; Yang et al., 2019 ).",
    "......,..... In addition, the deployment of models usually has a great amount of dynamics. For example, in a learning task for face recognition, the training datasets from participants can be non-i.i.d. and therefore lead to resource heterogeneity. In addition, the deployment of models usually has dynamics.. For example,",
    "......,..... In addition, the deployment of models usually has a great amount of dynamics. For example, in a learning task for face recognition, the training datasets from participants can be non-i.i.d. and therefore lead to resource heterogeneity. In addition, the deployment of models usually has dynamics.. For example,",
    "......,..... In addition, the deployment of models usually has a great amount of dynamics. For example, in a learning task for face recognition, the training datasets from participants can be non-i.i.d. and therefore lead to resource heterogeneity. In addition, the deployment of models usually has dynamics.. For example,",
    "......,..... In addition, the deployment of models usually has a great amount of dynamics. For example, in a learning task for face recognition, the training datasets from participants can be non-i.i.d. and therefore lead to resource heterogeneity. In addition, the deployment of models usually has dynamics.. For example,",
    ". This is in sharp contrast to minimization problems, where only finding a local solution is intractable. This has been made precise through exponential lower bound of the classical optimization type ( Hirsch & Vavasis, 1987 ) and computational complexity results ( Gidel et al., 2018a ; Daskalakis et al., 2021b ). This is in sharp contrast to minimization problems, where only finding a local solution is intractable",
    ". This is in sharp contrast to minimization problems, where only finding a local solution is intractable. This has been made precise through exponential lower bound of the classical optimization type ( Hirsch & Vavasis, 1987 ) and computational complexity results ( Gidel et al., 2018a ; Daskalakis et al., 2021b ). This is in sharp contrast to minimization problems, where only finding a local solution is intractable",
    ". This is in sharp contrast to minimization problems, where only finding a local solution is intractable. This has been made precise through exponential lower bound of the classical optimization type ( Hirsch & Vavasis, 1987 ) and computational complexity results ( Gidel et al., 2018a ; Daskalakis et al., 2021b ). This is in sharp contrast to minimization problems, where only finding a local solution is intractable",
    ". This is in sharp contrast to minimization problems, where only finding a local solution is intractable. This has been made precise through exponential lower bound of the classical optimization type ( Hirsch & Vavasis, 1987 ) and computational complexity results ( Gidel et al., 2018a ; Daskalakis et al., 2021b ). This is in sharp contrast to minimization problems, where only finding a local solution is intractable",
    "T is the learning time horizon. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the",
    "T is the learning time horizon. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the",
    "T is the learning time horizon. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the",
    "T is the learning time horizon. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the",
    "( s, s\u2032 ) is the reward signal received after transitioning from state s to state s\u2032. The reward function, Ra, is defined ab initio for an efficient goal accomplishment. In many real-life use cases, the agent can not directly sense the effect of its actions on the environment. To address this challenge for RL model training, simulation-based action models play a pivotal role. To address this challenge for RL model training, simulation-based",
    "( s, s\u2032 ) is the reward signal received after transitioning from state s to state s\u2032. The reward function, Ra, is defined ab initio for an efficient goal accomplishment. In many real-life use cases, the agent can not directly sense the effect of its actions on the environment. To address this challenge for RL model training, simulation-based action models play a pivotal role. To address this challenge for RL model training, simulation-based",
    "( s, s\u2032 ) is the reward signal received after transitioning from state s to state s\u2032. The reward function, Ra, is defined ab initio for an efficient goal accomplishment. In many real-life use cases, the agent can not directly sense the effect of its actions on the environment. To address this challenge for RL model training, simulation-based action models play a pivotal role. To address this challenge for RL model training, simulation-based",
    "( s, s\u2032 ) is the reward signal received after transitioning from state s to state s\u2032. The reward function, Ra, is defined ab initio for an efficient goal accomplishment. In many real-life use cases, the agent can not directly sense the effect of its actions on the environment. To address this challenge for RL model training, simulation-based action models play a pivotal role. To address this challenge for RL model training, simulation-based",
    "........................................................",
    "........................................................",
    "........................................................",
    "........................................................",
    "semi-supervised learning ( SSL ) has come to the fore in recent years. It is relatively easy and cheap to obtain large amounts of unlabelled data. However, the number of labelled data examples is usually small. This has been shown to outperform supervised and unsupervised learning under certain conditions. In this paper, we leverage results in Bu et al. ( 2020 ) ; Wu et al. ( 2020 ) to derive an informationtheoretic generalization",
    "semi-supervised learning ( SSL ) has come to the fore in recent years. It is relatively easy and cheap to obtain large amounts of unlabelled data. However, the number of labelled data examples is usually small. This has been shown to outperform supervised and unsupervised learning under certain conditions. In this paper, we leverage results in Bu et al. ( 2020 ) ; Wu et al. ( 2020 ) to derive an informationtheoretic generalization",
    "semi-supervised learning ( SSL ) has come to the fore in recent years. It is relatively easy and cheap to obtain large amounts of unlabelled data. However, the number of labelled data examples is usually small. This has been shown to outperform supervised and unsupervised learning under certain conditions. In this paper, we leverage results in Bu et al. ( 2020 ) ; Wu et al. ( 2020 ) to derive an informationtheoretic generalization",
    "semi-supervised learning ( SSL ) has come to the fore in recent years. It is relatively easy and cheap to obtain large amounts of unlabelled data. However, the number of labelled data examples is usually small. This has been shown to outperform supervised and unsupervised learning under certain conditions. In this paper, we leverage results in Bu et al. ( 2020 ) ; Wu et al. ( 2020 ) to derive an informationtheoretic generalization",
    ", 2019 ; Xie et al., 2019 ). Reinforcement learning ( RL ) has received great success recently ( Mnih et al., 2015 ; Lillicrap et al., 2016 ; Korenkevych et al., 2019 ). Among them, simple action repeat-based temporal persistency has been shown to be very successful ( e.g. Mni",
    ", 2019 ; Xie et al., 2019 ). Reinforcement learning ( RL ) has received great success recently ( Mnih et al., 2015 ; Lillicrap et al., 2016 ; Korenkevych et al., 2019 ). Among them, simple action repeat-based temporal persistency has been shown to be very successful ( e.g. Mni",
    ", 2019 ; Xie et al., 2019 ). Reinforcement learning ( RL ) has received great success recently ( Mnih et al., 2015 ; Lillicrap et al., 2016 ; Korenkevych et al., 2019 ). Among them, simple action repeat-based temporal persistency has been shown to be very successful ( e.g. Mni",
    ", 2019 ; Xie et al., 2019 ). Reinforcement learning ( RL ) has received great success recently ( Mnih et al., 2015 ; Lillicrap et al., 2016 ; Korenkevych et al., 2019 ). Among them, simple action repeat-based temporal persistency has been shown to be very successful ( e.g. Mni",
    ". Low-rank matrix completion ( LRMC ) and low-rank tensor completion ( LRTC ) are pervasive in sciences and engineering. We can use LRMC or LRTC to recover the missing entries of a lowrank matrix or tensor. For example, in collaborative filtering ( e.g. the recommendation problem of Netflix ), the rating matrix is often highly incomplete because each user can only rate a few items. If the missing entries",
    ". Low-rank matrix completion ( LRMC ) and low-rank tensor completion ( LRTC ) are pervasive in sciences and engineering. We can use LRMC or LRTC to recover the missing entries of a lowrank matrix or tensor. For example, in collaborative filtering ( e.g. the recommendation problem of Netflix ), the rating matrix is often highly incomplete because each user can only rate a few items. If the missing entries",
    ". Low-rank matrix completion ( LRMC ) and low-rank tensor completion ( LRTC ) are pervasive in sciences and engineering. We can use LRMC or LRTC to recover the missing entries of a lowrank matrix or tensor. For example, in collaborative filtering ( e.g. the recommendation problem of Netflix ), the rating matrix is often highly incomplete because each user can only rate a few items. If the missing entries",
    ". Low-rank matrix completion ( LRMC ) and low-rank tensor completion ( LRTC ) are pervasive in sciences and engineering. We can use LRMC or LRTC to recover the missing entries of a lowrank matrix or tensor. For example, in collaborative filtering ( e.g. the recommendation problem of Netflix ), the rating matrix is often highly incomplete because each user can only rate a few items. If the missing entries",
    "an arbitrary structured output model is available as a black box and argue how considering the correlations between output variables can improve the explanation performance. In this paper, we assume an arbitrary structured output model is available as a black box and argue how considering the correlations between output variables can improve the explanation performance. The effectiveness of the proposed method is confirmed using a variety of simulated and real data sets.",
    "an arbitrary structured output model is available as a black box and argue how considering the correlations between output variables can improve the explanation performance. In this paper, we assume an arbitrary structured output model is available as a black box and argue how considering the correlations between output variables can improve the explanation performance. The effectiveness of the proposed method is confirmed using a variety of simulated and real data sets.",
    "an arbitrary structured output model is available as a black box and argue how considering the correlations between output variables can improve the explanation performance. In this paper, we assume an arbitrary structured output model is available as a black box and argue how considering the correlations between output variables can improve the explanation performance. The effectiveness of the proposed method is confirmed using a variety of simulated and real data sets.",
    "an arbitrary structured output model is available as a black box and argue how considering the correlations between output variables can improve the explanation performance. In this paper, we assume an arbitrary structured output model is available as a black box and argue how considering the correlations between output variables can improve the explanation performance. The effectiveness of the proposed method is confirmed using a variety of simulated and real data sets.",
    "an asymptotically consistent estimate of the policy gradient for a broad class of CDF-based objectives via sampling. We show that, in all environments tested, the same risk profile can be used to produce stronger overall performance than standard PPO constrained by Lagrangians to maintain the same cost levels. Endowing agents with such perspective could make their decision-making more robust, potentially leading to increased safety, increased trust from humans, and more widespread real-world adoption.",
    "an asymptotically consistent estimate of the policy gradient for a broad class of CDF-based objectives via sampling. We show that, in all environments tested, the same risk profile can be used to produce stronger overall performance than standard PPO constrained by Lagrangians to maintain the same cost levels. Endowing agents with such perspective could make their decision-making more robust, potentially leading to increased safety, increased trust from humans, and more widespread real-world adoption.",
    "an asymptotically consistent estimate of the policy gradient for a broad class of CDF-based objectives via sampling. We show that, in all environments tested, the same risk profile can be used to produce stronger overall performance than standard PPO constrained by Lagrangians to maintain the same cost levels. Endowing agents with such perspective could make their decision-making more robust, potentially leading to increased safety, increased trust from humans, and more widespread real-world adoption.",
    "an asymptotically consistent estimate of the policy gradient for a broad class of CDF-based objectives via sampling. We show that, in all environments tested, the same risk profile can be used to produce stronger overall performance than standard PPO constrained by Lagrangians to maintain the same cost levels. Endowing agents with such perspective could make their decision-making more robust, potentially leading to increased safety, increased trust from humans, and more widespread real-world adoption.",
    ". Moreover, stochastic simulations are computationally expensive. For example, epidemic models require the exploration of a large parameter space ( e.g. characteristics of a virus, policy interventions, people \u2019 s behavior ). Furthermore, stochastic simulations can only approximate specific system dynamics and fail to generalize under different parametrization. Furthermore, stochastic simulations are computationally expensive.",
    ". Moreover, stochastic simulations are computationally expensive. For example, epidemic models require the exploration of a large parameter space ( e.g. characteristics of a virus, policy interventions, people \u2019 s behavior ). Furthermore, stochastic simulations can only approximate specific system dynamics and fail to generalize under different parametrization. Furthermore, stochastic simulations are computationally expensive.",
    ". Moreover, stochastic simulations are computationally expensive. For example, epidemic models require the exploration of a large parameter space ( e.g. characteristics of a virus, policy interventions, people \u2019 s behavior ). Furthermore, stochastic simulations can only approximate specific system dynamics and fail to generalize under different parametrization. Furthermore, stochastic simulations are computationally expensive.",
    ". Moreover, stochastic simulations are computationally expensive. For example, epidemic models require the exploration of a large parameter space ( e.g. characteristics of a virus, policy interventions, people \u2019 s behavior ). Furthermore, stochastic simulations can only approximate specific system dynamics and fail to generalize under different parametrization. Furthermore, stochastic simulations are computationally expensive.",
    "sensitive training examples. In this paper, we address the problem of building performant DP language models for sentence classification and language generation tasks with hundreds of thousands of examples. Our empirical results demonstrate that large pretrained models with hundreds of millions of parameters can be effectively and efficiently fine-tuned. In contrast to the mainstream perception, our empirical results demonstrate that large pretrained models with hundreds of millions of parameters can be effectively and efficiently fine-tuned.",
    "sensitive training examples. In this paper, we address the problem of building performant DP language models for sentence classification and language generation tasks with hundreds of thousands of examples. Our empirical results demonstrate that large pretrained models with hundreds of millions of parameters can be effectively and efficiently fine-tuned. In contrast to the mainstream perception, our empirical results demonstrate that large pretrained models with hundreds of millions of parameters can be effectively and efficiently fine-tuned.",
    "sensitive training examples. In this paper, we address the problem of building performant DP language models for sentence classification and language generation tasks with hundreds of thousands of examples. Our empirical results demonstrate that large pretrained models with hundreds of millions of parameters can be effectively and efficiently fine-tuned. In contrast to the mainstream perception, our empirical results demonstrate that large pretrained models with hundreds of millions of parameters can be effectively and efficiently fine-tuned.",
    "sensitive training examples. In this paper, we address the problem of building performant DP language models for sentence classification and language generation tasks with hundreds of thousands of examples. Our empirical results demonstrate that large pretrained models with hundreds of millions of parameters can be effectively and efficiently fine-tuned. In contrast to the mainstream perception, our empirical results demonstrate that large pretrained models with hundreds of millions of parameters can be effectively and efficiently fine-tuned.",
    "computationally expensive to find its optimal controller. Specifically, we learn a transform-and-control policy, called Transform2Act, that first designs an agent and then controls the designed agent. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s",
    "computationally expensive to find its optimal controller. Specifically, we learn a transform-and-control policy, called Transform2Act, that first designs an agent and then controls the designed agent. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s",
    "computationally expensive to find its optimal controller. Specifically, we learn a transform-and-control policy, called Transform2Act, that first designs an agent and then controls the designed agent. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s",
    "computationally expensive to find its optimal controller. Specifically, we learn a transform-and-control policy, called Transform2Act, that first designs an agent and then controls the designed agent. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s decision-making process. In an episode, we divide the agent \u2019s",
    ". The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. With CoordX, the initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This speedup is up to 2.92x compared to the baseline model for image, video, and 3D shape representation and rendering tasks.",
    ". The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. With CoordX, the initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This speedup is up to 2.92x compared to the baseline model for image, video, and 3D shape representation and rendering tasks.",
    ". The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. With CoordX, the initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This speedup is up to 2.92x compared to the baseline model for image, video, and 3D shape representation and rendering tasks.",
    ". The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. With CoordX, the initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This speedup is up to 2.92x compared to the baseline model for image, video, and 3D shape representation and rendering tasks.",
    "neural networks can learn object-centric representations from low-level perceptual features. In this work, we propose INFERNO, a model which infers a structured representation of objects and their 3D poses from a single image. The implicit functions are localized in the scene according to the objects poses and combined together to generate a 2D output view. In this work, we propose INFERNO, a model which infers a structured representation of objects and their 3D",
    "neural networks can learn object-centric representations from low-level perceptual features. In this work, we propose INFERNO, a model which infers a structured representation of objects and their 3D poses from a single image. The implicit functions are localized in the scene according to the objects poses and combined together to generate a 2D output view. In this work, we propose INFERNO, a model which infers a structured representation of objects and their 3D",
    "neural networks can learn object-centric representations from low-level perceptual features. In this work, we propose INFERNO, a model which infers a structured representation of objects and their 3D poses from a single image. The implicit functions are localized in the scene according to the objects poses and combined together to generate a 2D output view. In this work, we propose INFERNO, a model which infers a structured representation of objects and their 3D",
    "neural networks can learn object-centric representations from low-level perceptual features. In this work, we propose INFERNO, a model which infers a structured representation of objects and their 3D poses from a single image. The implicit functions are localized in the scene according to the objects poses and combined together to generate a 2D output view. In this work, we propose INFERNO, a model which infers a structured representation of objects and their 3D",
    "a distribution shift exists between the full graph and the subgraph, causing the out-of-distribution problem. Furthermore, the OOD effect brings spurious associations between the subgraph importance and model prediction. In this work, we propose Deconfounded Subgraph Evaluation ( DSE ) which assesses the causal effect of an explanatory subgraph on the model prediction. This work aims to provide insight into how predictor models work, answering \u201c Why the target GNN made",
    "a distribution shift exists between the full graph and the subgraph, causing the out-of-distribution problem. Furthermore, the OOD effect brings spurious associations between the subgraph importance and model prediction. In this work, we propose Deconfounded Subgraph Evaluation ( DSE ) which assesses the causal effect of an explanatory subgraph on the model prediction. This work aims to provide insight into how predictor models work, answering \u201c Why the target GNN made",
    "a distribution shift exists between the full graph and the subgraph, causing the out-of-distribution problem. Furthermore, the OOD effect brings spurious associations between the subgraph importance and model prediction. In this work, we propose Deconfounded Subgraph Evaluation ( DSE ) which assesses the causal effect of an explanatory subgraph on the model prediction. This work aims to provide insight into how predictor models work, answering \u201c Why the target GNN made",
    "a distribution shift exists between the full graph and the subgraph, causing the out-of-distribution problem. Furthermore, the OOD effect brings spurious associations between the subgraph importance and model prediction. In this work, we propose Deconfounded Subgraph Evaluation ( DSE ) which assesses the causal effect of an explanatory subgraph on the model prediction. This work aims to provide insight into how predictor models work, answering \u201c Why the target GNN made",
    "the shape of the blue square is not the color of the object. In addition, task ambiguity may arise during distribution shifts. In this paper, we consider whether task ambiguity can be addressed through automated active learning. In particular, task ambiguity can manifest in different ways : For example, the shape of an object may be spuriously correlated with other features predictive of the training labels. In addition, task ambiguity may arise from an underdiverse training set",
    "the shape of the blue square is not the color of the object. In addition, task ambiguity may arise during distribution shifts. In this paper, we consider whether task ambiguity can be addressed through automated active learning. In particular, task ambiguity can manifest in different ways : For example, the shape of an object may be spuriously correlated with other features predictive of the training labels. In addition, task ambiguity may arise from an underdiverse training set",
    "the shape of the blue square is not the color of the object. In addition, task ambiguity may arise during distribution shifts. In this paper, we consider whether task ambiguity can be addressed through automated active learning. In particular, task ambiguity can manifest in different ways : For example, the shape of an object may be spuriously correlated with other features predictive of the training labels. In addition, task ambiguity may arise from an underdiverse training set",
    "the shape of the blue square is not the color of the object. In addition, task ambiguity may arise during distribution shifts. In this paper, we consider whether task ambiguity can be addressed through automated active learning. In particular, task ambiguity can manifest in different ways : For example, the shape of an object may be spuriously correlated with other features predictive of the training labels. In addition, task ambiguity may arise from an underdiverse training set",
    "automated program repair ( Goues et al., 2019 ). In the recent years, advances in machine learning have appealed researchers to move to data-driven approaches for automated program repair. The first line of work regards the bug-fix learning problem as sequence-based code generation and harnesses the power of sequence-to-sequence models with RNN. The second line of work regards the bug-fix learning problem as sequence-based code generation and harnesses the power of",
    "automated program repair ( Goues et al., 2019 ). In the recent years, advances in machine learning have appealed researchers to move to data-driven approaches for automated program repair. The first line of work regards the bug-fix learning problem as sequence-based code generation and harnesses the power of sequence-to-sequence models with RNN. The second line of work regards the bug-fix learning problem as sequence-based code generation and harnesses the power of",
    "automated program repair ( Goues et al., 2019 ). In the recent years, advances in machine learning have appealed researchers to move to data-driven approaches for automated program repair. The first line of work regards the bug-fix learning problem as sequence-based code generation and harnesses the power of sequence-to-sequence models with RNN. The second line of work regards the bug-fix learning problem as sequence-based code generation and harnesses the power of",
    "automated program repair ( Goues et al., 2019 ). In the recent years, advances in machine learning have appealed researchers to move to data-driven approaches for automated program repair. The first line of work regards the bug-fix learning problem as sequence-based code generation and harnesses the power of sequence-to-sequence models with RNN. The second line of work regards the bug-fix learning problem as sequence-based code generation and harnesses the power of",
    "a dynamic schedule on the local training epochs. Hong et al. ( 2021 ) considered the hardware constraint where some clients are not able to participate Adversarial Training. However, the robustness of FAT ( Zizzo et al., 2020 ) will decrease significantly at the later stage of learning compared with the centralized Adversarial Training ( Madry et al., 2018 ) that does not. However, the",
    "a dynamic schedule on the local training epochs. Hong et al. ( 2021 ) considered the hardware constraint where some clients are not able to participate Adversarial Training. However, the robustness of FAT ( Zizzo et al., 2020 ) will decrease significantly at the later stage of learning compared with the centralized Adversarial Training ( Madry et al., 2018 ) that does not. However, the",
    "a dynamic schedule on the local training epochs. Hong et al. ( 2021 ) considered the hardware constraint where some clients are not able to participate Adversarial Training. However, the robustness of FAT ( Zizzo et al., 2020 ) will decrease significantly at the later stage of learning compared with the centralized Adversarial Training ( Madry et al., 2018 ) that does not. However, the",
    "a dynamic schedule on the local training epochs. Hong et al. ( 2021 ) considered the hardware constraint where some clients are not able to participate Adversarial Training. However, the robustness of FAT ( Zizzo et al., 2020 ) will decrease significantly at the later stage of learning compared with the centralized Adversarial Training ( Madry et al., 2018 ) that does not. However, the",
    "lifelong machine learning ( LML ) is defined as continual learning over task sequences. This is the first work integrating semi-supervised LML with lifelong learning. Mako sits atop an existing lifelong learner to turn it into a semi-supervised learner. Mako generates labels for the unlabeled data and then updates the lifelong learner supervised by both sets. This approach builds upon the widely used Snuba algorithm ( Varma & R\u00e9, 2016",
    "lifelong machine learning ( LML ) is defined as continual learning over task sequences. This is the first work integrating semi-supervised LML with lifelong learning. Mako sits atop an existing lifelong learner to turn it into a semi-supervised learner. Mako generates labels for the unlabeled data and then updates the lifelong learner supervised by both sets. This approach builds upon the widely used Snuba algorithm ( Varma & R\u00e9, 2016",
    "lifelong machine learning ( LML ) is defined as continual learning over task sequences. This is the first work integrating semi-supervised LML with lifelong learning. Mako sits atop an existing lifelong learner to turn it into a semi-supervised learner. Mako generates labels for the unlabeled data and then updates the lifelong learner supervised by both sets. This approach builds upon the widely used Snuba algorithm ( Varma & R\u00e9, 2016",
    "lifelong machine learning ( LML ) is defined as continual learning over task sequences. This is the first work integrating semi-supervised LML with lifelong learning. Mako sits atop an existing lifelong learner to turn it into a semi-supervised learner. Mako generates labels for the unlabeled data and then updates the lifelong learner supervised by both sets. This approach builds upon the widely used Snuba algorithm ( Varma & R\u00e9, 2016",
    "a 0 % detection rate. We introduce Selective Projected Gradient Descent and Orthogonal Projected Gradient Descent, improved attack techniques to generate adversarial examples. We find that existing defenses aim to make generating adversarial examples more difficult by requiring additional constraints on inputs for them to be considered successful. We use our technique to evade four stateof-the-art detection defenses, reducing their accuracy to 0 % while maintaining a",
    "a 0 % detection rate. We introduce Selective Projected Gradient Descent and Orthogonal Projected Gradient Descent, improved attack techniques to generate adversarial examples. We find that existing defenses aim to make generating adversarial examples more difficult by requiring additional constraints on inputs for them to be considered successful. We use our technique to evade four stateof-the-art detection defenses, reducing their accuracy to 0 % while maintaining a",
    "a 0 % detection rate. We introduce Selective Projected Gradient Descent and Orthogonal Projected Gradient Descent, improved attack techniques to generate adversarial examples. We find that existing defenses aim to make generating adversarial examples more difficult by requiring additional constraints on inputs for them to be considered successful. We use our technique to evade four stateof-the-art detection defenses, reducing their accuracy to 0 % while maintaining a",
    "a 0 % detection rate. We introduce Selective Projected Gradient Descent and Orthogonal Projected Gradient Descent, improved attack techniques to generate adversarial examples. We find that existing defenses aim to make generating adversarial examples more difficult by requiring additional constraints on inputs for them to be considered successful. We use our technique to evade four stateof-the-art detection defenses, reducing their accuracy to 0 % while maintaining a",
    "n  of n players and a value function ( a.k.a. characteristic function ) F ( S ) : 2N  Rn. In this paper, we explore a probabilistic treatment of cooperative games ( N, F ( S ) ). Among all the possible probability mass functions ( pmfs ), how should we construct the proper p ( S )? We advocate to choose the pmf with the maximum entrop",
    "n  of n players and a value function ( a.k.a. characteristic function ) F ( S ) : 2N  Rn. In this paper, we explore a probabilistic treatment of cooperative games ( N, F ( S ) ). Among all the possible probability mass functions ( pmfs ), how should we construct the proper p ( S )? We advocate to choose the pmf with the maximum entrop",
    "n  of n players and a value function ( a.k.a. characteristic function ) F ( S ) : 2N  Rn. In this paper, we explore a probabilistic treatment of cooperative games ( N, F ( S ) ). Among all the possible probability mass functions ( pmfs ), how should we construct the proper p ( S )? We advocate to choose the pmf with the maximum entrop",
    "n  of n players and a value function ( a.k.a. characteristic function ) F ( S ) : 2N  Rn. In this paper, we explore a probabilistic treatment of cooperative games ( N, F ( S ) ). Among all the possible probability mass functions ( pmfs ), how should we construct the proper p ( S )? We advocate to choose the pmf with the maximum entrop",
    ". Fig. 1 illustrates with Gaussian Processes ( GP ) that a model's posterior variance is not necessarily a good predictor of the reducible generalization error. Fig. 1 illustrates with Gaussian Processes ( GP ) that a model's posterior variance is not necessarily a good predictor of the reducible generalization error. Fig. 1 illustrates with Gaussian Processes ( GP",
    ". Fig. 1 illustrates with Gaussian Processes ( GP ) that a model's posterior variance is not necessarily a good predictor of the reducible generalization error. Fig. 1 illustrates with Gaussian Processes ( GP ) that a model's posterior variance is not necessarily a good predictor of the reducible generalization error. Fig. 1 illustrates with Gaussian Processes ( GP",
    ". Fig. 1 illustrates with Gaussian Processes ( GP ) that a model's posterior variance is not necessarily a good predictor of the reducible generalization error. Fig. 1 illustrates with Gaussian Processes ( GP ) that a model's posterior variance is not necessarily a good predictor of the reducible generalization error. Fig. 1 illustrates with Gaussian Processes ( GP",
    ". Fig. 1 illustrates with Gaussian Processes ( GP ) that a model's posterior variance is not necessarily a good predictor of the reducible generalization error. Fig. 1 illustrates with Gaussian Processes ( GP ) that a model's posterior variance is not necessarily a good predictor of the reducible generalization error. Fig. 1 illustrates with Gaussian Processes ( GP",
    "more stably compared to the state-of-the-art SVD method. They further improve upon vanilla product quantization significantly in an end-to-end training scenario. Embedded indexes, coupled with approximate nearest neighbor ( ANN ) search algorithms, have established as a promising alternative to search indexes. Embedded indexes can be used to encode users ( or queries ) and items in a latent vector space, and represent their semantic proximity",
    "more stably compared to the state-of-the-art SVD method. They further improve upon vanilla product quantization significantly in an end-to-end training scenario. Embedded indexes, coupled with approximate nearest neighbor ( ANN ) search algorithms, have established as a promising alternative to search indexes. Embedded indexes can be used to encode users ( or queries ) and items in a latent vector space, and represent their semantic proximity",
    "more stably compared to the state-of-the-art SVD method. They further improve upon vanilla product quantization significantly in an end-to-end training scenario. Embedded indexes, coupled with approximate nearest neighbor ( ANN ) search algorithms, have established as a promising alternative to search indexes. Embedded indexes can be used to encode users ( or queries ) and items in a latent vector space, and represent their semantic proximity",
    "more stably compared to the state-of-the-art SVD method. They further improve upon vanilla product quantization significantly in an end-to-end training scenario. Embedded indexes, coupled with approximate nearest neighbor ( ANN ) search algorithms, have established as a promising alternative to search indexes. Embedded indexes can be used to encode users ( or queries ) and items in a latent vector space, and represent their semantic proximity",
    ". Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts.",
    ". Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts.",
    ". Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts.",
    ". Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts. Abstractions enable humans to quickly learn concepts from few examples, and then reason about them by composing previously understood concepts.",
    ".... Self-GenomeNet is the first self-supervised framework that learns a representation of genomic data...... annotation........ datasets.... Self-GenomeNet. 1. 2....",
    ".... Self-GenomeNet is the first self-supervised framework that learns a representation of genomic data...... annotation........ datasets.... Self-GenomeNet. 1. 2....",
    ".... Self-GenomeNet is the first self-supervised framework that learns a representation of genomic data...... annotation........ datasets.... Self-GenomeNet. 1. 2....",
    ".... Self-GenomeNet is the first self-supervised framework that learns a representation of genomic data...... annotation........ datasets.... Self-GenomeNet. 1. 2....",
    "equivariant and, after online optimization, invariant class predictions for known point sets in unknown orientations. Following the motivation in the recent work of Melnyk et al. ( 2021 ), we focus on 3D geometry and spherical decision surfaces. Besides becoming a geometrically explainable approach, we show how our model parameters are fully steerable at inference time.",
    "equivariant and, after online optimization, invariant class predictions for known point sets in unknown orientations. Following the motivation in the recent work of Melnyk et al. ( 2021 ), we focus on 3D geometry and spherical decision surfaces. Besides becoming a geometrically explainable approach, we show how our model parameters are fully steerable at inference time.",
    "equivariant and, after online optimization, invariant class predictions for known point sets in unknown orientations. Following the motivation in the recent work of Melnyk et al. ( 2021 ), we focus on 3D geometry and spherical decision surfaces. Besides becoming a geometrically explainable approach, we show how our model parameters are fully steerable at inference time.",
    "equivariant and, after online optimization, invariant class predictions for known point sets in unknown orientations. Following the motivation in the recent work of Melnyk et al. ( 2021 ), we focus on 3D geometry and spherical decision surfaces. Besides becoming a geometrically explainable approach, we show how our model parameters are fully steerable at inference time.",
    ". Moreover, pretrained language models ( PLMs ) have been widely applied in CL methods in NLP. However, there remain three significant issues that require further investigation. ( 1 ) The existing works focus on input, output, and gradients information of PLMs while. ( 3 ) The later works focus on input, output, and gradients information of PLMs. ( 4 ) The existing works focus on input, output, and gradients information",
    ". Moreover, pretrained language models ( PLMs ) have been widely applied in CL methods in NLP. However, there remain three significant issues that require further investigation. ( 1 ) The existing works focus on input, output, and gradients information of PLMs while. ( 3 ) The later works focus on input, output, and gradients information of PLMs. ( 4 ) The existing works focus on input, output, and gradients information",
    ". Moreover, pretrained language models ( PLMs ) have been widely applied in CL methods in NLP. However, there remain three significant issues that require further investigation. ( 1 ) The existing works focus on input, output, and gradients information of PLMs while. ( 3 ) The later works focus on input, output, and gradients information of PLMs. ( 4 ) The existing works focus on input, output, and gradients information",
    ". Moreover, pretrained language models ( PLMs ) have been widely applied in CL methods in NLP. However, there remain three significant issues that require further investigation. ( 1 ) The existing works focus on input, output, and gradients information of PLMs while. ( 3 ) The later works focus on input, output, and gradients information of PLMs. ( 4 ) The existing works focus on input, output, and gradients information",
    ". The latter brings down the overall accuracy by affecting all classes. In this work, we use the state-of-the-art ( SOTA ) untargeted model poisoning attack. We propose a novel defense called TESSERACT against untargeted model poisoning attacks. In our experiments, this attack has been found to decrease the test accuracy from 90 % to a low 9 % when a DNN is trained using Krum on the MNIST dataset.",
    ". The latter brings down the overall accuracy by affecting all classes. In this work, we use the state-of-the-art ( SOTA ) untargeted model poisoning attack. We propose a novel defense called TESSERACT against untargeted model poisoning attacks. In our experiments, this attack has been found to decrease the test accuracy from 90 % to a low 9 % when a DNN is trained using Krum on the MNIST dataset.",
    ". The latter brings down the overall accuracy by affecting all classes. In this work, we use the state-of-the-art ( SOTA ) untargeted model poisoning attack. We propose a novel defense called TESSERACT against untargeted model poisoning attacks. In our experiments, this attack has been found to decrease the test accuracy from 90 % to a low 9 % when a DNN is trained using Krum on the MNIST dataset.",
    ". The latter brings down the overall accuracy by affecting all classes. In this work, we use the state-of-the-art ( SOTA ) untargeted model poisoning attack. We propose a novel defense called TESSERACT against untargeted model poisoning attacks. In our experiments, this attack has been found to decrease the test accuracy from 90 % to a low 9 % when a DNN is trained using Krum on the MNIST dataset.",
    ". An asymp- totically normal and asymp- totically normal estimation of the object of interest requires debiasing to reduce the effects of regularization and/or model selection on the object of interest. However, our method beats state of the art performance of the prior neural net based estimator of Shi et al. ( 2019 ) for the case of the average treatment effect functional. Prototypical examples include the estimation of average treatment effects, average policy effects,",
    ". An asymp- totically normal and asymp- totically normal estimation of the object of interest requires debiasing to reduce the effects of regularization and/or model selection on the object of interest. However, our method beats state of the art performance of the prior neural net based estimator of Shi et al. ( 2019 ) for the case of the average treatment effect functional. Prototypical examples include the estimation of average treatment effects, average policy effects,",
    ". An asymp- totically normal and asymp- totically normal estimation of the object of interest requires debiasing to reduce the effects of regularization and/or model selection on the object of interest. However, our method beats state of the art performance of the prior neural net based estimator of Shi et al. ( 2019 ) for the case of the average treatment effect functional. Prototypical examples include the estimation of average treatment effects, average policy effects,",
    ". An asymp- totically normal and asymp- totically normal estimation of the object of interest requires debiasing to reduce the effects of regularization and/or model selection on the object of interest. However, our method beats state of the art performance of the prior neural net based estimator of Shi et al. ( 2019 ) for the case of the average treatment effect functional. Prototypical examples include the estimation of average treatment effects, average policy effects,",
    "the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning ( MARL ) problems with average reward. In this paper, we establish the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning ( MARL ) problems with average reward. We show that the sample complexity bound matches that of the state-of-the-art single-agent actorcritic algorithms for reinforcement learning.",
    "the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning ( MARL ) problems with average reward. In this paper, we establish the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning ( MARL ) problems with average reward. We show that the sample complexity bound matches that of the state-of-the-art single-agent actorcritic algorithms for reinforcement learning.",
    "the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning ( MARL ) problems with average reward. In this paper, we establish the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning ( MARL ) problems with average reward. We show that the sample complexity bound matches that of the state-of-the-art single-agent actorcritic algorithms for reinforcement learning.",
    "the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning ( MARL ) problems with average reward. In this paper, we establish the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning ( MARL ) problems with average reward. We show that the sample complexity bound matches that of the state-of-the-art single-agent actorcritic algorithms for reinforcement learning.",
    ". Contrastive Learning ( CL ) emerges to be a promising paradigm for learning data representations without labeled data. However, a theoretical understanding of how contrastive learning actually works in practice is still under-explored. Intuitively, it is an instance discrimination task instead of a classification task ( clustering images from the same class together and differing with other classes ). Intuitively, it is an instance discrimination task instead of a classification",
    ". Contrastive Learning ( CL ) emerges to be a promising paradigm for learning data representations without labeled data. However, a theoretical understanding of how contrastive learning actually works in practice is still under-explored. Intuitively, it is an instance discrimination task instead of a classification task ( clustering images from the same class together and differing with other classes ). Intuitively, it is an instance discrimination task instead of a classification",
    ". Contrastive Learning ( CL ) emerges to be a promising paradigm for learning data representations without labeled data. However, a theoretical understanding of how contrastive learning actually works in practice is still under-explored. Intuitively, it is an instance discrimination task instead of a classification task ( clustering images from the same class together and differing with other classes ). Intuitively, it is an instance discrimination task instead of a classification",
    ". Contrastive Learning ( CL ) emerges to be a promising paradigm for learning data representations without labeled data. However, a theoretical understanding of how contrastive learning actually works in practice is still under-explored. Intuitively, it is an instance discrimination task instead of a classification task ( clustering images from the same class together and differing with other classes ). Intuitively, it is an instance discrimination task instead of a classification",
    ". In the real world, speech signal can be degraded by several different distortions simultaneously. The mismatch between the training data used in SSR and the testing data from the real world degrades the speech restoration performance. To address the mismatch problem, we propose a new task called general speech restoration ( GSR ). GSR aims at restoring multiple distortions in a single model. A number of studies ( Cutler et al., 2021 ; Cau",
    ". In the real world, speech signal can be degraded by several different distortions simultaneously. The mismatch between the training data used in SSR and the testing data from the real world degrades the speech restoration performance. To address the mismatch problem, we propose a new task called general speech restoration ( GSR ). GSR aims at restoring multiple distortions in a single model. A number of studies ( Cutler et al., 2021 ; Cau",
    ". In the real world, speech signal can be degraded by several different distortions simultaneously. The mismatch between the training data used in SSR and the testing data from the real world degrades the speech restoration performance. To address the mismatch problem, we propose a new task called general speech restoration ( GSR ). GSR aims at restoring multiple distortions in a single model. A number of studies ( Cutler et al., 2021 ; Cau",
    ". In the real world, speech signal can be degraded by several different distortions simultaneously. The mismatch between the training data used in SSR and the testing data from the real world degrades the speech restoration performance. To address the mismatch problem, we propose a new task called general speech restoration ( GSR ). GSR aims at restoring multiple distortions in a single model. A number of studies ( Cutler et al., 2021 ; Cau",
    "the \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013.",
    "the \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013.",
    "the \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013.",
    "the \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013. The \u201c Switzerland \u201d variable changed significantly earlier than the other in 2013.",
    "an unbiased estimation of the true gradient in each layer. This undermines the convergence property of SGD-based training algorithms. Second, although SCO algorithms achieve faster convergence, the obtained GNN models usually have poor generalization. Third, although SCO algorithms achieve faster generalization, the obtained GNN models have poor generalization.",
    "an unbiased estimation of the true gradient in each layer. This undermines the convergence property of SGD-based training algorithms. Second, although SCO algorithms achieve faster convergence, the obtained GNN models usually have poor generalization. Third, although SCO algorithms achieve faster generalization, the obtained GNN models have poor generalization.",
    "an unbiased estimation of the true gradient in each layer. This undermines the convergence property of SGD-based training algorithms. Second, although SCO algorithms achieve faster convergence, the obtained GNN models usually have poor generalization. Third, although SCO algorithms achieve faster generalization, the obtained GNN models have poor generalization.",
    "an unbiased estimation of the true gradient in each layer. This undermines the convergence property of SGD-based training algorithms. Second, although SCO algorithms achieve faster convergence, the obtained GNN models usually have poor generalization. Third, although SCO algorithms achieve faster generalization, the obtained GNN models have poor generalization.",
    "given two D-dimensional binary vectors v, w   0, 1  D, the Jaccard similarity is defined as J ( v, w ) = D i=1 1  vi = wi = 1  D i=1 1  vi + wi  1 , ( 1 ). 1.1 A REVIEW OF MINWISE HASHING ( MINHASH ) (",
    "given two D-dimensional binary vectors v, w   0, 1  D, the Jaccard similarity is defined as J ( v, w ) = D i=1 1  vi = wi = 1  D i=1 1  vi + wi  1 , ( 1 ). 1.1 A REVIEW OF MINWISE HASHING ( MINHASH ) (",
    "given two D-dimensional binary vectors v, w   0, 1  D, the Jaccard similarity is defined as J ( v, w ) = D i=1 1  vi = wi = 1  D i=1 1  vi + wi  1 , ( 1 ). 1.1 A REVIEW OF MINWISE HASHING ( MINHASH ) (",
    "given two D-dimensional binary vectors v, w   0, 1  D, the Jaccard similarity is defined as J ( v, w ) = D i=1 1  vi = wi = 1  D i=1 1  vi + wi  1 , ( 1 ). 1.1 A REVIEW OF MINWISE HASHING ( MINHASH ) (",
    ". The problem of adversarial examples, that is small adversarial perturbations of the input, is a serious obstacle for the use of machine learning in safety-critical systems. The problem of adversarial examples, that is small adversarial perturbations of the input, is a serious obstacle for the use of machine learning in safety-critical systems. The problem of adversarial examples, that is adversarial perturbations of the input, is a serious obstacle for the use of",
    ". The problem of adversarial examples, that is small adversarial perturbations of the input, is a serious obstacle for the use of machine learning in safety-critical systems. The problem of adversarial examples, that is small adversarial perturbations of the input, is a serious obstacle for the use of machine learning in safety-critical systems. The problem of adversarial examples, that is adversarial perturbations of the input, is a serious obstacle for the use of",
    ". The problem of adversarial examples, that is small adversarial perturbations of the input, is a serious obstacle for the use of machine learning in safety-critical systems. The problem of adversarial examples, that is small adversarial perturbations of the input, is a serious obstacle for the use of machine learning in safety-critical systems. The problem of adversarial examples, that is adversarial perturbations of the input, is a serious obstacle for the use of",
    ". The problem of adversarial examples, that is small adversarial perturbations of the input, is a serious obstacle for the use of machine learning in safety-critical systems. The problem of adversarial examples, that is small adversarial perturbations of the input, is a serious obstacle for the use of machine learning in safety-critical systems. The problem of adversarial examples, that is adversarial perturbations of the input, is a serious obstacle for the use of",
    "similar to the \u2018 negative transfer \u2019 phenomenon ( Wang et al., 2019 ) in transfer learning ( Standley et al., 2020 ). In this paper, we firstly give a formal definition for negative sharing occurred in MTL. Then, we formally define an ideal and also basic situation of MTL, safe multi-task learning. According to the definition of MTL ( Caruana, 1997 ; Zhang & Yang, 2021",
    "similar to the \u2018 negative transfer \u2019 phenomenon ( Wang et al., 2019 ) in transfer learning ( Standley et al., 2020 ). In this paper, we firstly give a formal definition for negative sharing occurred in MTL. Then, we formally define an ideal and also basic situation of MTL, safe multi-task learning. According to the definition of MTL ( Caruana, 1997 ; Zhang & Yang, 2021",
    "similar to the \u2018 negative transfer \u2019 phenomenon ( Wang et al., 2019 ) in transfer learning ( Standley et al., 2020 ). In this paper, we firstly give a formal definition for negative sharing occurred in MTL. Then, we formally define an ideal and also basic situation of MTL, safe multi-task learning. According to the definition of MTL ( Caruana, 1997 ; Zhang & Yang, 2021",
    "similar to the \u2018 negative transfer \u2019 phenomenon ( Wang et al., 2019 ) in transfer learning ( Standley et al., 2020 ). In this paper, we firstly give a formal definition for negative sharing occurred in MTL. Then, we formally define an ideal and also basic situation of MTL, safe multi-task learning. According to the definition of MTL ( Caruana, 1997 ; Zhang & Yang, 2021",
    "?  ( x ) over strings? ), which are often queried under the principle of probabilistic inference ( Ghahramani, 2015 ). In particular, some common parametric sequence models?  are energy-based ( or can be cast as ). These sequence model families are Turing-complete. In other words, they recognize recursively enumerable languages. It is therefore intuitive that energy-based sequence models",
    "?  ( x ) over strings? ), which are often queried under the principle of probabilistic inference ( Ghahramani, 2015 ). In particular, some common parametric sequence models?  are energy-based ( or can be cast as ). These sequence model families are Turing-complete. In other words, they recognize recursively enumerable languages. It is therefore intuitive that energy-based sequence models",
    "?  ( x ) over strings? ), which are often queried under the principle of probabilistic inference ( Ghahramani, 2015 ). In particular, some common parametric sequence models?  are energy-based ( or can be cast as ). These sequence model families are Turing-complete. In other words, they recognize recursively enumerable languages. It is therefore intuitive that energy-based sequence models",
    "?  ( x ) over strings? ), which are often queried under the principle of probabilistic inference ( Ghahramani, 2015 ). In particular, some common parametric sequence models?  are energy-based ( or can be cast as ). These sequence model families are Turing-complete. In other words, they recognize recursively enumerable languages. It is therefore intuitive that energy-based sequence models",
    "a differentiable solver for the optimization problem ( Genevay et al., 2019b ). The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine",
    "a differentiable solver for the optimization problem ( Genevay et al., 2019b ). The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine",
    "a differentiable solver for the optimization problem ( Genevay et al., 2019b ). The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine",
    "a differentiable solver for the optimization problem ( Genevay et al., 2019b ). The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine learning domains. The Wasserstein distance, which arises from the optimal transport theory, has become an increasingly popular choice in various machine",
    "inefficient exploration can dramatically decrease sample efficiency. As in single agent RL, in MARL, the collective of agents is typically required to coordinate its exploration to find their optimal joint policies. This problem is worsened by the fact that in many MAS, the reward signal provided by the environment is not sufficient to guide the agents toward optimal joint policies. To aid coordinated learning, algorithms such as QMIX ( Rashid et al., 2018 ), Mguni e",
    "inefficient exploration can dramatically decrease sample efficiency. As in single agent RL, in MARL, the collective of agents is typically required to coordinate its exploration to find their optimal joint policies. This problem is worsened by the fact that in many MAS, the reward signal provided by the environment is not sufficient to guide the agents toward optimal joint policies. To aid coordinated learning, algorithms such as QMIX ( Rashid et al., 2018 ), Mguni e",
    "inefficient exploration can dramatically decrease sample efficiency. As in single agent RL, in MARL, the collective of agents is typically required to coordinate its exploration to find their optimal joint policies. This problem is worsened by the fact that in many MAS, the reward signal provided by the environment is not sufficient to guide the agents toward optimal joint policies. To aid coordinated learning, algorithms such as QMIX ( Rashid et al., 2018 ), Mguni e",
    "inefficient exploration can dramatically decrease sample efficiency. As in single agent RL, in MARL, the collective of agents is typically required to coordinate its exploration to find their optimal joint policies. This problem is worsened by the fact that in many MAS, the reward signal provided by the environment is not sufficient to guide the agents toward optimal joint policies. To aid coordinated learning, algorithms such as QMIX ( Rashid et al., 2018 ), Mguni e",
    "multi-hop questions. In this work, we focus on the problem of answering complex, multi-hop questions over long structured documents. In this work, we focus on the problem of answering complex, multi-hop questions over long structured documents. For example, to answer the question \u201c What modules in DOCHOPPER will be finetuned in all the experiments? \u201d, one might first turn to the section title \u201c Model \u201d to identify the different modules in DOCHOPPER.",
    "multi-hop questions. In this work, we focus on the problem of answering complex, multi-hop questions over long structured documents. In this work, we focus on the problem of answering complex, multi-hop questions over long structured documents. For example, to answer the question \u201c What modules in DOCHOPPER will be finetuned in all the experiments? \u201d, one might first turn to the section title \u201c Model \u201d to identify the different modules in DOCHOPPER.",
    "multi-hop questions. In this work, we focus on the problem of answering complex, multi-hop questions over long structured documents. In this work, we focus on the problem of answering complex, multi-hop questions over long structured documents. For example, to answer the question \u201c What modules in DOCHOPPER will be finetuned in all the experiments? \u201d, one might first turn to the section title \u201c Model \u201d to identify the different modules in DOCHOPPER.",
    "multi-hop questions. In this work, we focus on the problem of answering complex, multi-hop questions over long structured documents. In this work, we focus on the problem of answering complex, multi-hop questions over long structured documents. For example, to answer the question \u201c What modules in DOCHOPPER will be finetuned in all the experiments? \u201d, one might first turn to the section title \u201c Model \u201d to identify the different modules in DOCHOPPER.",
    ". Vocal casting is an artisanal process that requires a lot of precision and is carried out by human operators. It involves a voice selection process, which means choosing among several candidate voices in a target language. This selection process is called voice casting. In this article, we address some of the complexity of voice casting and we start with the voices of professional actors playing characters for the gaming industry. The articles Gresse et al. ( 2020 ; 2019 ; 2017 ; 2017",
    ". Vocal casting is an artisanal process that requires a lot of precision and is carried out by human operators. It involves a voice selection process, which means choosing among several candidate voices in a target language. This selection process is called voice casting. In this article, we address some of the complexity of voice casting and we start with the voices of professional actors playing characters for the gaming industry. The articles Gresse et al. ( 2020 ; 2019 ; 2017 ; 2017",
    ". Vocal casting is an artisanal process that requires a lot of precision and is carried out by human operators. It involves a voice selection process, which means choosing among several candidate voices in a target language. This selection process is called voice casting. In this article, we address some of the complexity of voice casting and we start with the voices of professional actors playing characters for the gaming industry. The articles Gresse et al. ( 2020 ; 2019 ; 2017 ; 2017",
    ". Vocal casting is an artisanal process that requires a lot of precision and is carried out by human operators. It involves a voice selection process, which means choosing among several candidate voices in a target language. This selection process is called voice casting. In this article, we address some of the complexity of voice casting and we start with the voices of professional actors playing characters for the gaming industry. The articles Gresse et al. ( 2020 ; 2019 ; 2017 ; 2017",
    ", 2019 ). In particular, convolutional neural networks ( CNN ) can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn",
    ", 2019 ). In particular, convolutional neural networks ( CNN ) can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn",
    ", 2019 ). In particular, convolutional neural networks ( CNN ) can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn",
    ", 2019 ). In particular, convolutional neural networks ( CNN ) can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn the hierarchy of complex image features. In particular, CNN can learn",
    "reward hacking has been widely observed, but not yet systematically studied. To understand how reward hacking arises, we construct four RL environments with misspecified reward functions. Moreover, we find instances of phase transitions : capability thresholds at which the agent \u2019 s behavior qualitatively shifts. Such phase transitions pose challenges to monitoring the safety of ML systems. To address this, we propose an anomaly detection task for aberrant policies and offer several baseline detectors.",
    "reward hacking has been widely observed, but not yet systematically studied. To understand how reward hacking arises, we construct four RL environments with misspecified reward functions. Moreover, we find instances of phase transitions : capability thresholds at which the agent \u2019 s behavior qualitatively shifts. Such phase transitions pose challenges to monitoring the safety of ML systems. To address this, we propose an anomaly detection task for aberrant policies and offer several baseline detectors.",
    "reward hacking has been widely observed, but not yet systematically studied. To understand how reward hacking arises, we construct four RL environments with misspecified reward functions. Moreover, we find instances of phase transitions : capability thresholds at which the agent \u2019 s behavior qualitatively shifts. Such phase transitions pose challenges to monitoring the safety of ML systems. To address this, we propose an anomaly detection task for aberrant policies and offer several baseline detectors.",
    "reward hacking has been widely observed, but not yet systematically studied. To understand how reward hacking arises, we construct four RL environments with misspecified reward functions. Moreover, we find instances of phase transitions : capability thresholds at which the agent \u2019 s behavior qualitatively shifts. Such phase transitions pose challenges to monitoring the safety of ML systems. To address this, we propose an anomaly detection task for aberrant policies and offer several baseline detectors.",
    "... f -divergence. and true posterior distribution q ( z|x ).. f -divergence ( f -TVO ).. ) and true posterior distribution p ( x ).. . . . ; ; . f",
    "... f -divergence. and true posterior distribution q ( z|x ).. f -divergence ( f -TVO ).. ) and true posterior distribution p ( x ).. . . . ; ; . f",
    "... f -divergence. and true posterior distribution q ( z|x ).. f -divergence ( f -TVO ).. ) and true posterior distribution p ( x ).. . . . ; ; . f",
    "... f -divergence. and true posterior distribution q ( z|x ).. f -divergence ( f -TVO ).. ) and true posterior distribution p ( x ).. . . . ; ; . f",
    "( 2019b ) ; Andrychowicz et al. ( 2020a ) ; Vinyals et al. ( 2019b ) ). In this paper, we present a comprehensive empirical study of multiple tools from the deep reinforcement learning toolbox applied to the continuous control in the OpenAI Gym MuJoCo setting. Our insights include : \u2022 The normally distributed action noise, commonly used for exploration, hinders training. \u2022 The normally distributed",
    "( 2019b ) ; Andrychowicz et al. ( 2020a ) ; Vinyals et al. ( 2019b ) ). In this paper, we present a comprehensive empirical study of multiple tools from the deep reinforcement learning toolbox applied to the continuous control in the OpenAI Gym MuJoCo setting. Our insights include : \u2022 The normally distributed action noise, commonly used for exploration, hinders training. \u2022 The normally distributed",
    "( 2019b ) ; Andrychowicz et al. ( 2020a ) ; Vinyals et al. ( 2019b ) ). In this paper, we present a comprehensive empirical study of multiple tools from the deep reinforcement learning toolbox applied to the continuous control in the OpenAI Gym MuJoCo setting. Our insights include : \u2022 The normally distributed action noise, commonly used for exploration, hinders training. \u2022 The normally distributed",
    "( 2019b ) ; Andrychowicz et al. ( 2020a ) ; Vinyals et al. ( 2019b ) ). In this paper, we present a comprehensive empirical study of multiple tools from the deep reinforcement learning toolbox applied to the continuous control in the OpenAI Gym MuJoCo setting. Our insights include : \u2022 The normally distributed action noise, commonly used for exploration, hinders training. \u2022 The normally distributed",
    "a convex optimization problem. We then propose a simple algorithm that is computationally more efficient compared to ELminimizer. In particular, we propose the ELminimizer algorithm, which finds the optimal EL fair predictor by leveraging off-the-shelf convex programming tools. We then propose a simple algorithm that is computationally more efficient compared to ELminimizer. Experiments on real-world data show the effectiveness of our algorithms.",
    "a convex optimization problem. We then propose a simple algorithm that is computationally more efficient compared to ELminimizer. In particular, we propose the ELminimizer algorithm, which finds the optimal EL fair predictor by leveraging off-the-shelf convex programming tools. We then propose a simple algorithm that is computationally more efficient compared to ELminimizer. Experiments on real-world data show the effectiveness of our algorithms.",
    "a convex optimization problem. We then propose a simple algorithm that is computationally more efficient compared to ELminimizer. In particular, we propose the ELminimizer algorithm, which finds the optimal EL fair predictor by leveraging off-the-shelf convex programming tools. We then propose a simple algorithm that is computationally more efficient compared to ELminimizer. Experiments on real-world data show the effectiveness of our algorithms.",
    "a convex optimization problem. We then propose a simple algorithm that is computationally more efficient compared to ELminimizer. In particular, we propose the ELminimizer algorithm, which finds the optimal EL fair predictor by leveraging off-the-shelf convex programming tools. We then propose a simple algorithm that is computationally more efficient compared to ELminimizer. Experiments on real-world data show the effectiveness of our algorithms.",
    "2019 ; Keysers et al., 2019 ; Hupkes et al., 2020 ). Whether models can generalize systematically is still an appealing research topic until now. In this work, we revisit systematic generalization to see whether neural networks still fail after semantic linking. To expose semantic links between new concepts and existing ones, we augment prior knowledge through inductive learning or deductive learning as what humans do in meaningful verbal learning ( Ausubel, 1963",
    "2019 ; Keysers et al., 2019 ; Hupkes et al., 2020 ). Whether models can generalize systematically is still an appealing research topic until now. In this work, we revisit systematic generalization to see whether neural networks still fail after semantic linking. To expose semantic links between new concepts and existing ones, we augment prior knowledge through inductive learning or deductive learning as what humans do in meaningful verbal learning ( Ausubel, 1963",
    "2019 ; Keysers et al., 2019 ; Hupkes et al., 2020 ). Whether models can generalize systematically is still an appealing research topic until now. In this work, we revisit systematic generalization to see whether neural networks still fail after semantic linking. To expose semantic links between new concepts and existing ones, we augment prior knowledge through inductive learning or deductive learning as what humans do in meaningful verbal learning ( Ausubel, 1963",
    "2019 ; Keysers et al., 2019 ; Hupkes et al., 2020 ). Whether models can generalize systematically is still an appealing research topic until now. In this work, we revisit systematic generalization to see whether neural networks still fail after semantic linking. To expose semantic links between new concepts and existing ones, we augment prior knowledge through inductive learning or deductive learning as what humans do in meaningful verbal learning ( Ausubel, 1963",
    "the higher the probability that the points locate on high-frequency parts. With the thriving of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D point clouds. With the flourishing of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D shape representation.",
    "the higher the probability that the points locate on high-frequency parts. With the thriving of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D point clouds. With the flourishing of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D shape representation.",
    "the higher the probability that the points locate on high-frequency parts. With the thriving of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D point clouds. With the flourishing of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D shape representation.",
    "the higher the probability that the points locate on high-frequency parts. With the thriving of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D point clouds. With the flourishing of deep learning, numerous welldesigned neural networks are applied to extract expressive semantics of 3D shape representation.",
    ". Lightweight finetuning achieves stronger ID performance than full finetuning ( Howard & Ruder, 2018 ). Alternatively, freezing most of the pretrained parameters during finetuning, achieves stronger OOD performance than full finetuning. We call these methods lightweight finetuning. 1 INTRODUCTION When finetuning a pretrained language model for natural language generation tasks like summarization ( Narayanan et al.",
    ". Lightweight finetuning achieves stronger ID performance than full finetuning ( Howard & Ruder, 2018 ). Alternatively, freezing most of the pretrained parameters during finetuning, achieves stronger OOD performance than full finetuning. We call these methods lightweight finetuning. 1 INTRODUCTION When finetuning a pretrained language model for natural language generation tasks like summarization ( Narayanan et al.",
    ". Lightweight finetuning achieves stronger ID performance than full finetuning ( Howard & Ruder, 2018 ). Alternatively, freezing most of the pretrained parameters during finetuning, achieves stronger OOD performance than full finetuning. We call these methods lightweight finetuning. 1 INTRODUCTION When finetuning a pretrained language model for natural language generation tasks like summarization ( Narayanan et al.",
    ". Lightweight finetuning achieves stronger ID performance than full finetuning ( Howard & Ruder, 2018 ). Alternatively, freezing most of the pretrained parameters during finetuning, achieves stronger OOD performance than full finetuning. We call these methods lightweight finetuning. 1 INTRODUCTION When finetuning a pretrained language model for natural language generation tasks like summarization ( Narayanan et al.",
    ". In this paper, we leverage data programming ( Ratner et al., 2016 ) which uses a generative model to integrate expert knowledge expressed in the form of noisy heuristics. Since the quality of the training labels is strongly correlated with that of labeling functions, weak supervision may not always yield optimal performance. In this paper, we leverage data programming ( Ratner et al., 2016 ) which uses a generative model to integrate expert knowledge expressed in",
    ". In this paper, we leverage data programming ( Ratner et al., 2016 ) which uses a generative model to integrate expert knowledge expressed in the form of noisy heuristics. Since the quality of the training labels is strongly correlated with that of labeling functions, weak supervision may not always yield optimal performance. In this paper, we leverage data programming ( Ratner et al., 2016 ) which uses a generative model to integrate expert knowledge expressed in",
    ". In this paper, we leverage data programming ( Ratner et al., 2016 ) which uses a generative model to integrate expert knowledge expressed in the form of noisy heuristics. Since the quality of the training labels is strongly correlated with that of labeling functions, weak supervision may not always yield optimal performance. In this paper, we leverage data programming ( Ratner et al., 2016 ) which uses a generative model to integrate expert knowledge expressed in",
    ". In this paper, we leverage data programming ( Ratner et al., 2016 ) which uses a generative model to integrate expert knowledge expressed in the form of noisy heuristics. Since the quality of the training labels is strongly correlated with that of labeling functions, weak supervision may not always yield optimal performance. In this paper, we leverage data programming ( Ratner et al., 2016 ) which uses a generative model to integrate expert knowledge expressed in",
    "a descent method and finds first order stationary points of smooth nonconvex functions. Theoretically, we show that our proposed algorithm is a descent method and finds first order stationary points of smooth nonconvex functions. In this paper, we propose a new and simple algorithm that explicitly encourages learning of features that are shared across various groups.",
    "a descent method and finds first order stationary points of smooth nonconvex functions. Theoretically, we show that our proposed algorithm is a descent method and finds first order stationary points of smooth nonconvex functions. In this paper, we propose a new and simple algorithm that explicitly encourages learning of features that are shared across various groups.",
    "a descent method and finds first order stationary points of smooth nonconvex functions. Theoretically, we show that our proposed algorithm is a descent method and finds first order stationary points of smooth nonconvex functions. In this paper, we propose a new and simple algorithm that explicitly encourages learning of features that are shared across various groups.",
    "a descent method and finds first order stationary points of smooth nonconvex functions. Theoretically, we show that our proposed algorithm is a descent method and finds first order stationary points of smooth nonconvex functions. In this paper, we propose a new and simple algorithm that explicitly encourages learning of features that are shared across various groups.",
    ". Intuitively, such methods aim to explain black box decision-making by understanding how individual features influence prediction outcomes. However, in many real-world applications, feature interactions may be asymmetrical. We propose a method to extend any given univariate removal-based explanation to a bivariate explanation model. Our method is general, and can be applied to a broad array of univariate removal-based explanations, as defined by Covert et",
    ". Intuitively, such methods aim to explain black box decision-making by understanding how individual features influence prediction outcomes. However, in many real-world applications, feature interactions may be asymmetrical. We propose a method to extend any given univariate removal-based explanation to a bivariate explanation model. Our method is general, and can be applied to a broad array of univariate removal-based explanations, as defined by Covert et",
    ". Intuitively, such methods aim to explain black box decision-making by understanding how individual features influence prediction outcomes. However, in many real-world applications, feature interactions may be asymmetrical. We propose a method to extend any given univariate removal-based explanation to a bivariate explanation model. Our method is general, and can be applied to a broad array of univariate removal-based explanations, as defined by Covert et",
    ". Intuitively, such methods aim to explain black box decision-making by understanding how individual features influence prediction outcomes. However, in many real-world applications, feature interactions may be asymmetrical. We propose a method to extend any given univariate removal-based explanation to a bivariate explanation model. Our method is general, and can be applied to a broad array of univariate removal-based explanations, as defined by Covert et",
    ", 2017 ). However, these algorithms lack interpretability, leading to mistrust from the medical community. Our work aims to better describe and understand the decision-making process by observing physician behaviour. These models could be used to build future decision support systems.",
    ", 2017 ). However, these algorithms lack interpretability, leading to mistrust from the medical community. Our work aims to better describe and understand the decision-making process by observing physician behaviour. These models could be used to build future decision support systems.",
    ", 2017 ). However, these algorithms lack interpretability, leading to mistrust from the medical community. Our work aims to better describe and understand the decision-making process by observing physician behaviour. These models could be used to build future decision support systems.",
    ", 2017 ). However, these algorithms lack interpretability, leading to mistrust from the medical community. Our work aims to better describe and understand the decision-making process by observing physician behaviour. These models could be used to build future decision support systems.",
    ". In particular, ( Lim et al., 2019b ) introduces adversarial learning to organize the target network training and augmentation policies search in an online manner. In addition, ( Zhang et al., 2019b ) introduces adversarial learning to organize the target network training and augmentation policies search in an online manner. In addition, ( Lin et al., 2019b ) introduces adversarial learning to organize the target network training",
    ". In particular, ( Lim et al., 2019b ) introduces adversarial learning to organize the target network training and augmentation policies search in an online manner. In addition, ( Zhang et al., 2019b ) introduces adversarial learning to organize the target network training and augmentation policies search in an online manner. In addition, ( Lin et al., 2019b ) introduces adversarial learning to organize the target network training",
    ". In particular, ( Lim et al., 2019b ) introduces adversarial learning to organize the target network training and augmentation policies search in an online manner. In addition, ( Zhang et al., 2019b ) introduces adversarial learning to organize the target network training and augmentation policies search in an online manner. In addition, ( Lin et al., 2019b ) introduces adversarial learning to organize the target network training",
    ". In particular, ( Lim et al., 2019b ) introduces adversarial learning to organize the target network training and augmentation policies search in an online manner. In addition, ( Zhang et al., 2019b ) introduces adversarial learning to organize the target network training and augmentation policies search in an online manner. In addition, ( Lin et al., 2019b ) introduces adversarial learning to organize the target network training",
    "the natural and adversarial distributions. We propose the adversarial distribution alignment method to eliminate the difference between natural and adversarial distributions by considering spurious correlations. Our work is the first attempt towards using causality to understand and mitigate adversarial vulnerability. The lack of robustness hinders the applications of DNNs to some safetycritical areas such as automatic driving ( Tuncali et al., 2018 ) and healthcare ( Finlayson et al., 2019 ).",
    "the natural and adversarial distributions. We propose the adversarial distribution alignment method to eliminate the difference between natural and adversarial distributions by considering spurious correlations. Our work is the first attempt towards using causality to understand and mitigate adversarial vulnerability. The lack of robustness hinders the applications of DNNs to some safetycritical areas such as automatic driving ( Tuncali et al., 2018 ) and healthcare ( Finlayson et al., 2019 ).",
    "the natural and adversarial distributions. We propose the adversarial distribution alignment method to eliminate the difference between natural and adversarial distributions by considering spurious correlations. Our work is the first attempt towards using causality to understand and mitigate adversarial vulnerability. The lack of robustness hinders the applications of DNNs to some safetycritical areas such as automatic driving ( Tuncali et al., 2018 ) and healthcare ( Finlayson et al., 2019 ).",
    "the natural and adversarial distributions. We propose the adversarial distribution alignment method to eliminate the difference between natural and adversarial distributions by considering spurious correlations. Our work is the first attempt towards using causality to understand and mitigate adversarial vulnerability. The lack of robustness hinders the applications of DNNs to some safetycritical areas such as automatic driving ( Tuncali et al., 2018 ) and healthcare ( Finlayson et al., 2019 ).",
    "to learn for each task a new filter subspace for each convolutional layer, i.e., hundreds of parameters as filter atoms. Then, we perform continual learning by simply swapping filter atoms for each task. The effectiveness of our approach is empirically validated and further explained theoretically with an excess risk bound analysis. In this paper, we propose to learn for each task a new filter subspace for each convolutional layer, i.e.",
    "to learn for each task a new filter subspace for each convolutional layer, i.e., hundreds of parameters as filter atoms. Then, we perform continual learning by simply swapping filter atoms for each task. The effectiveness of our approach is empirically validated and further explained theoretically with an excess risk bound analysis. In this paper, we propose to learn for each task a new filter subspace for each convolutional layer, i.e.",
    "to learn for each task a new filter subspace for each convolutional layer, i.e., hundreds of parameters as filter atoms. Then, we perform continual learning by simply swapping filter atoms for each task. The effectiveness of our approach is empirically validated and further explained theoretically with an excess risk bound analysis. In this paper, we propose to learn for each task a new filter subspace for each convolutional layer, i.e.",
    "to learn for each task a new filter subspace for each convolutional layer, i.e., hundreds of parameters as filter atoms. Then, we perform continual learning by simply swapping filter atoms for each task. The effectiveness of our approach is empirically validated and further explained theoretically with an excess risk bound analysis. In this paper, we propose to learn for each task a new filter subspace for each convolutional layer, i.e.",
    "the kernel Hilbert space ( RKHS ). Moreover, iteratively transports the particles by the functional gradient of KL divergence in the reproducing kernel Hilbert space ( RKHS ). Moreover, as the problem dimensionality d becomes larger, the variance estimated by SVGD can be much smaller than variance of the target distribution ( Zhuo et al., 2017 ). This phenomenon is highly undesirable for practitioners due to (",
    "the kernel Hilbert space ( RKHS ). Moreover, iteratively transports the particles by the functional gradient of KL divergence in the reproducing kernel Hilbert space ( RKHS ). Moreover, as the problem dimensionality d becomes larger, the variance estimated by SVGD can be much smaller than variance of the target distribution ( Zhuo et al., 2017 ). This phenomenon is highly undesirable for practitioners due to (",
    "the kernel Hilbert space ( RKHS ). Moreover, iteratively transports the particles by the functional gradient of KL divergence in the reproducing kernel Hilbert space ( RKHS ). Moreover, as the problem dimensionality d becomes larger, the variance estimated by SVGD can be much smaller than variance of the target distribution ( Zhuo et al., 2017 ). This phenomenon is highly undesirable for practitioners due to (",
    "the kernel Hilbert space ( RKHS ). Moreover, iteratively transports the particles by the functional gradient of KL divergence in the reproducing kernel Hilbert space ( RKHS ). Moreover, as the problem dimensionality d becomes larger, the variance estimated by SVGD can be much smaller than variance of the target distribution ( Zhuo et al., 2017 ). This phenomenon is highly undesirable for practitioners due to (",
    ". To combat noisy labels, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust adversarial training methods. To combat noisy labels, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed",
    ". To combat noisy labels, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust adversarial training methods. To combat noisy labels, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed",
    ". To combat noisy labels, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust adversarial training methods. To combat noisy labels, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed",
    ". To combat noisy labels, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust adversarial training methods. To combat noisy labels, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed robust label-noise learning methods. To combat adversarial examples, researchers have designed",
    "a new statistical method, called Robustness Measurement and Assessment ( RoMA ), can measure the expected robustness of a neural network model. Specifically, RoMA determines the probability that a random input perturbation might cause misclassification. the method allows us to provide formal guarantees regarding the expected frequency of errors that a trained model will encounter after deployment. a major disadvantage of the DNN approach is the existence of adversarial inputs Goodfellow et al.",
    "a new statistical method, called Robustness Measurement and Assessment ( RoMA ), can measure the expected robustness of a neural network model. Specifically, RoMA determines the probability that a random input perturbation might cause misclassification. the method allows us to provide formal guarantees regarding the expected frequency of errors that a trained model will encounter after deployment. a major disadvantage of the DNN approach is the existence of adversarial inputs Goodfellow et al.",
    "a new statistical method, called Robustness Measurement and Assessment ( RoMA ), can measure the expected robustness of a neural network model. Specifically, RoMA determines the probability that a random input perturbation might cause misclassification. the method allows us to provide formal guarantees regarding the expected frequency of errors that a trained model will encounter after deployment. a major disadvantage of the DNN approach is the existence of adversarial inputs Goodfellow et al.",
    "a new statistical method, called Robustness Measurement and Assessment ( RoMA ), can measure the expected robustness of a neural network model. Specifically, RoMA determines the probability that a random input perturbation might cause misclassification. the method allows us to provide formal guarantees regarding the expected frequency of errors that a trained model will encounter after deployment. a major disadvantage of the DNN approach is the existence of adversarial inputs Goodfellow et al.",
    "in visual, temporal, visual-temporal domains and language data. Moreover, the interpretability of the learned chunks enables flexible transfer between environments. Taken together, our results show how cognitive science in general and theories of chunking in particular could inform novel and more interpretable approaches to representation learning. In particular, deep learning models suffer from a lack of interpretability since ANNs are sub-symbolic, non-linear structures. This means they the way",
    "in visual, temporal, visual-temporal domains and language data. Moreover, the interpretability of the learned chunks enables flexible transfer between environments. Taken together, our results show how cognitive science in general and theories of chunking in particular could inform novel and more interpretable approaches to representation learning. In particular, deep learning models suffer from a lack of interpretability since ANNs are sub-symbolic, non-linear structures. This means they the way",
    "in visual, temporal, visual-temporal domains and language data. Moreover, the interpretability of the learned chunks enables flexible transfer between environments. Taken together, our results show how cognitive science in general and theories of chunking in particular could inform novel and more interpretable approaches to representation learning. In particular, deep learning models suffer from a lack of interpretability since ANNs are sub-symbolic, non-linear structures. This means they the way",
    "in visual, temporal, visual-temporal domains and language data. Moreover, the interpretability of the learned chunks enables flexible transfer between environments. Taken together, our results show how cognitive science in general and theories of chunking in particular could inform novel and more interpretable approaches to representation learning. In particular, deep learning models suffer from a lack of interpretability since ANNs are sub-symbolic, non-linear structures. This means they the way",
    ". We introduce a novel neural reparametrization scheme. We test our hypothesis on two highly non-convex optimization problems. First, we examine the dynamics of the gradient flow and identify the condition number that dictates the speed of convergence. Second, we introduce a novel neural reparametrization scheme. We test our hypothesis on two highly non-convex optimization problems and obtain impressive speedups. Our method is complementary to existing gradient-based optimization algorithms.",
    ". We introduce a novel neural reparametrization scheme. We test our hypothesis on two highly non-convex optimization problems. First, we examine the dynamics of the gradient flow and identify the condition number that dictates the speed of convergence. Second, we introduce a novel neural reparametrization scheme. We test our hypothesis on two highly non-convex optimization problems and obtain impressive speedups. Our method is complementary to existing gradient-based optimization algorithms.",
    ". We introduce a novel neural reparametrization scheme. We test our hypothesis on two highly non-convex optimization problems. First, we examine the dynamics of the gradient flow and identify the condition number that dictates the speed of convergence. Second, we introduce a novel neural reparametrization scheme. We test our hypothesis on two highly non-convex optimization problems and obtain impressive speedups. Our method is complementary to existing gradient-based optimization algorithms.",
    ". We introduce a novel neural reparametrization scheme. We test our hypothesis on two highly non-convex optimization problems. First, we examine the dynamics of the gradient flow and identify the condition number that dictates the speed of convergence. Second, we introduce a novel neural reparametrization scheme. We test our hypothesis on two highly non-convex optimization problems and obtain impressive speedups. Our method is complementary to existing gradient-based optimization algorithms.",
    "deep convolutional neural networks ( DCNNs ) are powerful tools for multiple tasks of automatic image classification. However, in many real-world cases large datasets are not available. For instance, in the biomedical domain the acquisition and annotation of each image requires the use of costly medical instrumentation, technicians, and medical staff who can annotate each sample manually. In addition, in the biomedical domain the acquisition and annotation of each image requires the use of expensive medical instrumentation, technicians",
    "deep convolutional neural networks ( DCNNs ) are powerful tools for multiple tasks of automatic image classification. However, in many real-world cases large datasets are not available. For instance, in the biomedical domain the acquisition and annotation of each image requires the use of costly medical instrumentation, technicians, and medical staff who can annotate each sample manually. In addition, in the biomedical domain the acquisition and annotation of each image requires the use of expensive medical instrumentation, technicians",
    "deep convolutional neural networks ( DCNNs ) are powerful tools for multiple tasks of automatic image classification. However, in many real-world cases large datasets are not available. For instance, in the biomedical domain the acquisition and annotation of each image requires the use of costly medical instrumentation, technicians, and medical staff who can annotate each sample manually. In addition, in the biomedical domain the acquisition and annotation of each image requires the use of expensive medical instrumentation, technicians",
    "deep convolutional neural networks ( DCNNs ) are powerful tools for multiple tasks of automatic image classification. However, in many real-world cases large datasets are not available. For instance, in the biomedical domain the acquisition and annotation of each image requires the use of costly medical instrumentation, technicians, and medical staff who can annotate each sample manually. In addition, in the biomedical domain the acquisition and annotation of each image requires the use of expensive medical instrumentation, technicians",
    "),. Figure 1...., distributed training with data parallelism is possible. However, scaling the training of GNNs with sampling techniques, such as Equal Contribution., remains challenging. Besides, existing sampling-based methods require centralized data storage and model learning, which could result in privacy concerns in real-world scenarios. For example, moving from single machine to multiple machines reduces the",
    "),. Figure 1...., distributed training with data parallelism is possible. However, scaling the training of GNNs with sampling techniques, such as Equal Contribution., remains challenging. Besides, existing sampling-based methods require centralized data storage and model learning, which could result in privacy concerns in real-world scenarios. For example, moving from single machine to multiple machines reduces the",
    "),. Figure 1...., distributed training with data parallelism is possible. However, scaling the training of GNNs with sampling techniques, such as Equal Contribution., remains challenging. Besides, existing sampling-based methods require centralized data storage and model learning, which could result in privacy concerns in real-world scenarios. For example, moving from single machine to multiple machines reduces the",
    "),. Figure 1...., distributed training with data parallelism is possible. However, scaling the training of GNNs with sampling techniques, such as Equal Contribution., remains challenging. Besides, existing sampling-based methods require centralized data storage and model learning, which could result in privacy concerns in real-world scenarios. For example, moving from single machine to multiple machines reduces the",
    ". This efficiency problem is tackled by special-purpose libraries ( Chetlur et al., 2014 ), compression by network pruning ( Han et al., 2015 ; Li et al., 2016 ; Liu et al., 2019 ) and quantization ( Romero et al., 2014 ). Anytime inference mitigates this efficiency problem by bringing flexibility to model computation. For example, a",
    ". This efficiency problem is tackled by special-purpose libraries ( Chetlur et al., 2014 ), compression by network pruning ( Han et al., 2015 ; Li et al., 2016 ; Liu et al., 2019 ) and quantization ( Romero et al., 2014 ). Anytime inference mitigates this efficiency problem by bringing flexibility to model computation. For example, a",
    ". This efficiency problem is tackled by special-purpose libraries ( Chetlur et al., 2014 ), compression by network pruning ( Han et al., 2015 ; Li et al., 2016 ; Liu et al., 2019 ) and quantization ( Romero et al., 2014 ). Anytime inference mitigates this efficiency problem by bringing flexibility to model computation. For example, a",
    ". This efficiency problem is tackled by special-purpose libraries ( Chetlur et al., 2014 ), compression by network pruning ( Han et al., 2015 ; Li et al., 2016 ; Liu et al., 2019 ) and quantization ( Romero et al., 2014 ). Anytime inference mitigates this efficiency problem by bringing flexibility to model computation. For example, a",
    ". Neural Processes ( NP ) define distributions over functions given a set of observations. In these tasks, a model needs to approximate a function and estimate uncertainty correctly to optimize a black-box function whose analytic information is not given. However, B ( A ) NP underperforms in capturing a functional uncertainty because the residual bootstrapping works in a homoscedastic way. Therefore, B ( A ) NP is",
    ". Neural Processes ( NP ) define distributions over functions given a set of observations. In these tasks, a model needs to approximate a function and estimate uncertainty correctly to optimize a black-box function whose analytic information is not given. However, B ( A ) NP underperforms in capturing a functional uncertainty because the residual bootstrapping works in a homoscedastic way. Therefore, B ( A ) NP is",
    ". Neural Processes ( NP ) define distributions over functions given a set of observations. In these tasks, a model needs to approximate a function and estimate uncertainty correctly to optimize a black-box function whose analytic information is not given. However, B ( A ) NP underperforms in capturing a functional uncertainty because the residual bootstrapping works in a homoscedastic way. Therefore, B ( A ) NP is",
    ". Neural Processes ( NP ) define distributions over functions given a set of observations. In these tasks, a model needs to approximate a function and estimate uncertainty correctly to optimize a black-box function whose analytic information is not given. However, B ( A ) NP underperforms in capturing a functional uncertainty because the residual bootstrapping works in a homoscedastic way. Therefore, B ( A ) NP is",
    ". For example, Enformer ( Avsec et al., 2021 ) combines CNN and transformer architecture as well as multi-head output to predict gene expression and epigenomic marks. As a multi-cellular organism, the human body is formed by different cell types. Therefore, modeling regulatory genome, especially across different cell types, is crucial for both the understanding of this fundamental biological process and the development of RNA-level therapeutic intervention of a vast among of diseases",
    ". For example, Enformer ( Avsec et al., 2021 ) combines CNN and transformer architecture as well as multi-head output to predict gene expression and epigenomic marks. As a multi-cellular organism, the human body is formed by different cell types. Therefore, modeling regulatory genome, especially across different cell types, is crucial for both the understanding of this fundamental biological process and the development of RNA-level therapeutic intervention of a vast among of diseases",
    ". For example, Enformer ( Avsec et al., 2021 ) combines CNN and transformer architecture as well as multi-head output to predict gene expression and epigenomic marks. As a multi-cellular organism, the human body is formed by different cell types. Therefore, modeling regulatory genome, especially across different cell types, is crucial for both the understanding of this fundamental biological process and the development of RNA-level therapeutic intervention of a vast among of diseases",
    ". For example, Enformer ( Avsec et al., 2021 ) combines CNN and transformer architecture as well as multi-head output to predict gene expression and epigenomic marks. As a multi-cellular organism, the human body is formed by different cell types. Therefore, modeling regulatory genome, especially across different cell types, is crucial for both the understanding of this fundamental biological process and the development of RNA-level therapeutic intervention of a vast among of diseases",
    "non-stationary. As a consequence, matching the training set to reality can be either not possible or too complex. Besides, relying on the intrinsic properties of the ML models and their statistical behavior in the presence of in-distribution data is key to identifying OOD samples. While existing state-of-the-art methods on classification problems still output high accuracy even under dataset shift. As a result, the failure of machine learning ( ML ) models to adapt to",
    "non-stationary. As a consequence, matching the training set to reality can be either not possible or too complex. Besides, relying on the intrinsic properties of the ML models and their statistical behavior in the presence of in-distribution data is key to identifying OOD samples. While existing state-of-the-art methods on classification problems still output high accuracy even under dataset shift. As a result, the failure of machine learning ( ML ) models to adapt to",
    "non-stationary. As a consequence, matching the training set to reality can be either not possible or too complex. Besides, relying on the intrinsic properties of the ML models and their statistical behavior in the presence of in-distribution data is key to identifying OOD samples. While existing state-of-the-art methods on classification problems still output high accuracy even under dataset shift. As a result, the failure of machine learning ( ML ) models to adapt to",
    "non-stationary. As a consequence, matching the training set to reality can be either not possible or too complex. Besides, relying on the intrinsic properties of the ML models and their statistical behavior in the presence of in-distribution data is key to identifying OOD samples. While existing state-of-the-art methods on classification problems still output high accuracy even under dataset shift. As a result, the failure of machine learning ( ML ) models to adapt to",
    ". In addition, equivariant representations can be easily \u201c hard-coded \u201d into neural networks. In addition, equivariant CNNs have been shown to capture response properties of neurons in the primary visual cortex beyond classical G\u00e1bor filter models ( Ecker et al., 2018 ). In addition, equivariant CNNs have been shown to capture response properties of neurons in the primary visual cortex beyond classical G\u00e1bor filter models ( Ecker e",
    ". In addition, equivariant representations can be easily \u201c hard-coded \u201d into neural networks. In addition, equivariant CNNs have been shown to capture response properties of neurons in the primary visual cortex beyond classical G\u00e1bor filter models ( Ecker et al., 2018 ). In addition, equivariant CNNs have been shown to capture response properties of neurons in the primary visual cortex beyond classical G\u00e1bor filter models ( Ecker e",
    ". In addition, equivariant representations can be easily \u201c hard-coded \u201d into neural networks. In addition, equivariant CNNs have been shown to capture response properties of neurons in the primary visual cortex beyond classical G\u00e1bor filter models ( Ecker et al., 2018 ). In addition, equivariant CNNs have been shown to capture response properties of neurons in the primary visual cortex beyond classical G\u00e1bor filter models ( Ecker e",
    ". In addition, equivariant representations can be easily \u201c hard-coded \u201d into neural networks. In addition, equivariant CNNs have been shown to capture response properties of neurons in the primary visual cortex beyond classical G\u00e1bor filter models ( Ecker et al., 2018 ). In addition, equivariant CNNs have been shown to capture response properties of neurons in the primary visual cortex beyond classical G\u00e1bor filter models ( Ecker e",
    "a pathologist downloads a pretrained model to classify histopathology images. despite a high reported accuracy, he finds the model performing poorly on his images. he investigates why that is the case. by explaining the cause of the domain shift, we are able to easily fix the model \u2019 s predictions. if the domain shift is due to more complex spurious correlations the model has learned, it might need to be completely retrained before it can",
    "a pathologist downloads a pretrained model to classify histopathology images. despite a high reported accuracy, he finds the model performing poorly on his images. he investigates why that is the case. by explaining the cause of the domain shift, we are able to easily fix the model \u2019 s predictions. if the domain shift is due to more complex spurious correlations the model has learned, it might need to be completely retrained before it can",
    "a pathologist downloads a pretrained model to classify histopathology images. despite a high reported accuracy, he finds the model performing poorly on his images. he investigates why that is the case. by explaining the cause of the domain shift, we are able to easily fix the model \u2019 s predictions. if the domain shift is due to more complex spurious correlations the model has learned, it might need to be completely retrained before it can",
    "a pathologist downloads a pretrained model to classify histopathology images. despite a high reported accuracy, he finds the model performing poorly on his images. he investigates why that is the case. by explaining the cause of the domain shift, we are able to easily fix the model \u2019 s predictions. if the domain shift is due to more complex spurious correlations the model has learned, it might need to be completely retrained before it can",
    "3D point clouds. Deep learning models are becoming one of the most common and promising ways to represent 3D data. Point-based methods are becoming one of the most popular choices to extract features and make predictions for 3D input point clouds. However, KPConv results in very large model sizes for 3D point cloud recognition due to inefficient local feature aggregation via point convolution over kernel weights Wk. As a result, KPConv takes up to  k",
    "3D point clouds. Deep learning models are becoming one of the most common and promising ways to represent 3D data. Point-based methods are becoming one of the most popular choices to extract features and make predictions for 3D input point clouds. However, KPConv results in very large model sizes for 3D point cloud recognition due to inefficient local feature aggregation via point convolution over kernel weights Wk. As a result, KPConv takes up to  k",
    "3D point clouds. Deep learning models are becoming one of the most common and promising ways to represent 3D data. Point-based methods are becoming one of the most popular choices to extract features and make predictions for 3D input point clouds. However, KPConv results in very large model sizes for 3D point cloud recognition due to inefficient local feature aggregation via point convolution over kernel weights Wk. As a result, KPConv takes up to  k",
    "3D point clouds. Deep learning models are becoming one of the most common and promising ways to represent 3D data. Point-based methods are becoming one of the most popular choices to extract features and make predictions for 3D input point clouds. However, KPConv results in very large model sizes for 3D point cloud recognition due to inefficient local feature aggregation via point convolution over kernel weights Wk. As a result, KPConv takes up to  k",
    "the data in adversarial training and show that the three aforementioned problems are all interconnected with the quality of the data employed in adversarial training. In this work, we focus on the data in adversarial training and show that the three aforementioned problems are all interconnected with the data quality. We then conduct both standard training and adversarial training with Projected Gradient Descent ( PGD-AT ). As a demonstration, we partition the training set of CIFAR-10",
    "the data in adversarial training and show that the three aforementioned problems are all interconnected with the quality of the data employed in adversarial training. In this work, we focus on the data in adversarial training and show that the three aforementioned problems are all interconnected with the data quality. We then conduct both standard training and adversarial training with Projected Gradient Descent ( PGD-AT ). As a demonstration, we partition the training set of CIFAR-10",
    "the data in adversarial training and show that the three aforementioned problems are all interconnected with the quality of the data employed in adversarial training. In this work, we focus on the data in adversarial training and show that the three aforementioned problems are all interconnected with the data quality. We then conduct both standard training and adversarial training with Projected Gradient Descent ( PGD-AT ). As a demonstration, we partition the training set of CIFAR-10",
    "the data in adversarial training and show that the three aforementioned problems are all interconnected with the quality of the data employed in adversarial training. In this work, we focus on the data in adversarial training and show that the three aforementioned problems are all interconnected with the data quality. We then conduct both standard training and adversarial training with Projected Gradient Descent ( PGD-AT ). As a demonstration, we partition the training set of CIFAR-10",
    "the number of neurons needed for an approximation scales exponentially in the dimension of the problem d. DeVore et al. ( 1989 ) showed that any function of the Sobolev space of order r and dimension d can be approximated within with a neural network. However, this result does not specify the number of neurons and parameters to train needed for this approximation.",
    "the number of neurons needed for an approximation scales exponentially in the dimension of the problem d. DeVore et al. ( 1989 ) showed that any function of the Sobolev space of order r and dimension d can be approximated within with a neural network. However, this result does not specify the number of neurons and parameters to train needed for this approximation.",
    "the number of neurons needed for an approximation scales exponentially in the dimension of the problem d. DeVore et al. ( 1989 ) showed that any function of the Sobolev space of order r and dimension d can be approximated within with a neural network. However, this result does not specify the number of neurons and parameters to train needed for this approximation.",
    "the number of neurons needed for an approximation scales exponentially in the dimension of the problem d. DeVore et al. ( 1989 ) showed that any function of the Sobolev space of order r and dimension d can be approximated within with a neural network. However, this result does not specify the number of neurons and parameters to train needed for this approximation.",
    "language emergence has been explored in linguistics and artificial intelligence for two main reasons ( Lazaridou & Baroni, 2020 ). On the one hand, artificially reproducing language emergence may help to understand the evolution of human languages ( Steels, 1997 ; Briscoe, 2002 ; Wagner et al., 2003 ). On the other hand, language is known to be structured, and compositional, and imitating such properties would enhance machine",
    "language emergence has been explored in linguistics and artificial intelligence for two main reasons ( Lazaridou & Baroni, 2020 ). On the one hand, artificially reproducing language emergence may help to understand the evolution of human languages ( Steels, 1997 ; Briscoe, 2002 ; Wagner et al., 2003 ). On the other hand, language is known to be structured, and compositional, and imitating such properties would enhance machine",
    "language emergence has been explored in linguistics and artificial intelligence for two main reasons ( Lazaridou & Baroni, 2020 ). On the one hand, artificially reproducing language emergence may help to understand the evolution of human languages ( Steels, 1997 ; Briscoe, 2002 ; Wagner et al., 2003 ). On the other hand, language is known to be structured, and compositional, and imitating such properties would enhance machine",
    "language emergence has been explored in linguistics and artificial intelligence for two main reasons ( Lazaridou & Baroni, 2020 ). On the one hand, artificially reproducing language emergence may help to understand the evolution of human languages ( Steels, 1997 ; Briscoe, 2002 ; Wagner et al., 2003 ). On the other hand, language is known to be structured, and compositional, and imitating such properties would enhance machine",
    ". Graph Neural Networks ( GNNs ) perform well when the graph and node labels are positively correlated. In this work, we are interested in the problem of classifying nodes in a graph. We are also given labels for a subset of the nodes in the graph. The learning model utilizes this information to predict labels for the remaining nodes. However, the performance of GNNs can be poor if this criterion is not satisfied.",
    ". Graph Neural Networks ( GNNs ) perform well when the graph and node labels are positively correlated. In this work, we are interested in the problem of classifying nodes in a graph. We are also given labels for a subset of the nodes in the graph. The learning model utilizes this information to predict labels for the remaining nodes. However, the performance of GNNs can be poor if this criterion is not satisfied.",
    ". Graph Neural Networks ( GNNs ) perform well when the graph and node labels are positively correlated. In this work, we are interested in the problem of classifying nodes in a graph. We are also given labels for a subset of the nodes in the graph. The learning model utilizes this information to predict labels for the remaining nodes. However, the performance of GNNs can be poor if this criterion is not satisfied.",
    ". Graph Neural Networks ( GNNs ) perform well when the graph and node labels are positively correlated. In this work, we are interested in the problem of classifying nodes in a graph. We are also given labels for a subset of the nodes in the graph. The learning model utilizes this information to predict labels for the remaining nodes. However, the performance of GNNs can be poor if this criterion is not satisfied.",
    "shortest distance metric. a graph shortest distance embedding method... Shortest Distance Queries ( SDQs ) in graphs focus on determining the minimum distance between arbitrary node pairs. While most SDQs focus on determining the minimum distance between arbitrary node pairs, most SDQs focus on determining the maximum distance between arbitrary node pairs. 2 INTRODUCTION. Our proposed method possesses strong theoretical background",
    "shortest distance metric. a graph shortest distance embedding method... Shortest Distance Queries ( SDQs ) in graphs focus on determining the minimum distance between arbitrary node pairs. While most SDQs focus on determining the minimum distance between arbitrary node pairs, most SDQs focus on determining the maximum distance between arbitrary node pairs. 2 INTRODUCTION. Our proposed method possesses strong theoretical background",
    "shortest distance metric. a graph shortest distance embedding method... Shortest Distance Queries ( SDQs ) in graphs focus on determining the minimum distance between arbitrary node pairs. While most SDQs focus on determining the minimum distance between arbitrary node pairs, most SDQs focus on determining the maximum distance between arbitrary node pairs. 2 INTRODUCTION. Our proposed method possesses strong theoretical background",
    "shortest distance metric. a graph shortest distance embedding method... Shortest Distance Queries ( SDQs ) in graphs focus on determining the minimum distance between arbitrary node pairs. While most SDQs focus on determining the minimum distance between arbitrary node pairs, most SDQs focus on determining the maximum distance between arbitrary node pairs. 2 INTRODUCTION. Our proposed method possesses strong theoretical background",
    ". Recent studies have shown that large Language Models ( LM ), such as T5 ( Raffel et al., 2019 ) and GPT-3 ( Brown et al., 2020 ), have the capability of storing a tremendous amount of world knowledge in their parameters. While the world knowledge stored in LMs has diverse use cases, it can quickly become outdated as the world changes fast. However, the challenge of renewing the internal world knowledge stored in",
    ". Recent studies have shown that large Language Models ( LM ), such as T5 ( Raffel et al., 2019 ) and GPT-3 ( Brown et al., 2020 ), have the capability of storing a tremendous amount of world knowledge in their parameters. While the world knowledge stored in LMs has diverse use cases, it can quickly become outdated as the world changes fast. However, the challenge of renewing the internal world knowledge stored in",
    ". Recent studies have shown that large Language Models ( LM ), such as T5 ( Raffel et al., 2019 ) and GPT-3 ( Brown et al., 2020 ), have the capability of storing a tremendous amount of world knowledge in their parameters. While the world knowledge stored in LMs has diverse use cases, it can quickly become outdated as the world changes fast. However, the challenge of renewing the internal world knowledge stored in",
    ". Recent studies have shown that large Language Models ( LM ), such as T5 ( Raffel et al., 2019 ) and GPT-3 ( Brown et al., 2020 ), have the capability of storing a tremendous amount of world knowledge in their parameters. While the world knowledge stored in LMs has diverse use cases, it can quickly become outdated as the world changes fast. However, the challenge of renewing the internal world knowledge stored in",
    "..... Decision trees are among the most established machine learning models in the scientific community. They are also widely used as a sub-procedure in ensemble learning.. learning.. learning. learning... ........... learning",
    "..... Decision trees are among the most established machine learning models in the scientific community. They are also widely used as a sub-procedure in ensemble learning.. learning.. learning. learning... ........... learning",
    "..... Decision trees are among the most established machine learning models in the scientific community. They are also widely used as a sub-procedure in ensemble learning.. learning.. learning. learning... ........... learning",
    "..... Decision trees are among the most established machine learning models in the scientific community. They are also widely used as a sub-procedure in ensemble learning.. learning.. learning. learning... ........... learning",
    "inverse time decay is near optimal on quadratic objectives. However, even step decay is near optimal on quadratic objectives. However, step decay scheduler is not optimal on quadratic objectives. In this paper, we present a set of learning rate schedules to further improve convergence properties of SGD. In addition, we present a set of cosine-like learning rates ( Loshchilov & Hutter, 2017 ) in the range [ 0, T",
    "inverse time decay is near optimal on quadratic objectives. However, even step decay is near optimal on quadratic objectives. However, step decay scheduler is not optimal on quadratic objectives. In this paper, we present a set of learning rate schedules to further improve convergence properties of SGD. In addition, we present a set of cosine-like learning rates ( Loshchilov & Hutter, 2017 ) in the range [ 0, T",
    "inverse time decay is near optimal on quadratic objectives. However, even step decay is near optimal on quadratic objectives. However, step decay scheduler is not optimal on quadratic objectives. In this paper, we present a set of learning rate schedules to further improve convergence properties of SGD. In addition, we present a set of cosine-like learning rates ( Loshchilov & Hutter, 2017 ) in the range [ 0, T",
    "inverse time decay is near optimal on quadratic objectives. However, even step decay is near optimal on quadratic objectives. However, step decay scheduler is not optimal on quadratic objectives. In this paper, we present a set of learning rate schedules to further improve convergence properties of SGD. In addition, we present a set of cosine-like learning rates ( Loshchilov & Hutter, 2017 ) in the range [ 0, T",
    ". Model-based reinforcement learning ( MBRL ) has recently shown promise in offline ( or batch ) reinforcement learning ( RL ). MBRL works by training a dynamics model from the offline data, then optimizing a policy using imaginary rollouts from the model. This allows the agent to learn from on-policy experience, as the model is agnostic to the policy used to generate the data. This is crucial for offline RL to be useful for real-world",
    ". Model-based reinforcement learning ( MBRL ) has recently shown promise in offline ( or batch ) reinforcement learning ( RL ). MBRL works by training a dynamics model from the offline data, then optimizing a policy using imaginary rollouts from the model. This allows the agent to learn from on-policy experience, as the model is agnostic to the policy used to generate the data. This is crucial for offline RL to be useful for real-world",
    ". Model-based reinforcement learning ( MBRL ) has recently shown promise in offline ( or batch ) reinforcement learning ( RL ). MBRL works by training a dynamics model from the offline data, then optimizing a policy using imaginary rollouts from the model. This allows the agent to learn from on-policy experience, as the model is agnostic to the policy used to generate the data. This is crucial for offline RL to be useful for real-world",
    ". Model-based reinforcement learning ( MBRL ) has recently shown promise in offline ( or batch ) reinforcement learning ( RL ). MBRL works by training a dynamics model from the offline data, then optimizing a policy using imaginary rollouts from the model. This allows the agent to learn from on-policy experience, as the model is agnostic to the policy used to generate the data. This is crucial for offline RL to be useful for real-world",
    ". Experience replay is an essential component of policy training in reinforcement learning ( RL ). By utilizing many past experiences in a large buffer, experience replay can stabilize and improve policy training. As a result, experience replay with the buffer has indeed proved its effectiveness in Q-learning ( Hessel et al., 2018 ; Schaul et al., 2016 ). Moreover, Zha et al. ( 2019 ) ; Wang &",
    ". Experience replay is an essential component of policy training in reinforcement learning ( RL ). By utilizing many past experiences in a large buffer, experience replay can stabilize and improve policy training. As a result, experience replay with the buffer has indeed proved its effectiveness in Q-learning ( Hessel et al., 2018 ; Schaul et al., 2016 ). Moreover, Zha et al. ( 2019 ) ; Wang &",
    ". Experience replay is an essential component of policy training in reinforcement learning ( RL ). By utilizing many past experiences in a large buffer, experience replay can stabilize and improve policy training. As a result, experience replay with the buffer has indeed proved its effectiveness in Q-learning ( Hessel et al., 2018 ; Schaul et al., 2016 ). Moreover, Zha et al. ( 2019 ) ; Wang &",
    ". Experience replay is an essential component of policy training in reinforcement learning ( RL ). By utilizing many past experiences in a large buffer, experience replay can stabilize and improve policy training. As a result, experience replay with the buffer has indeed proved its effectiveness in Q-learning ( Hessel et al., 2018 ; Schaul et al., 2016 ). Moreover, Zha et al. ( 2019 ) ; Wang &",
    "how to effectively inject human knowledge into the learning process is one of the key challenges to training reliable autonomous agents in safety-critical tasks. In reinforcement learning ( RL ), researchers can inject their intentions into the carefully designed reward function. However, RL methods bear two drawbacks that limit their applications in safety-critical tasks. First, the nature of trial-and-error exploration exposes RL agent to dangerous situations. Second, it is difficult to summarize all the intended behaviors to be learned into the reward",
    "how to effectively inject human knowledge into the learning process is one of the key challenges to training reliable autonomous agents in safety-critical tasks. In reinforcement learning ( RL ), researchers can inject their intentions into the carefully designed reward function. However, RL methods bear two drawbacks that limit their applications in safety-critical tasks. First, the nature of trial-and-error exploration exposes RL agent to dangerous situations. Second, it is difficult to summarize all the intended behaviors to be learned into the reward",
    "how to effectively inject human knowledge into the learning process is one of the key challenges to training reliable autonomous agents in safety-critical tasks. In reinforcement learning ( RL ), researchers can inject their intentions into the carefully designed reward function. However, RL methods bear two drawbacks that limit their applications in safety-critical tasks. First, the nature of trial-and-error exploration exposes RL agent to dangerous situations. Second, it is difficult to summarize all the intended behaviors to be learned into the reward",
    "how to effectively inject human knowledge into the learning process is one of the key challenges to training reliable autonomous agents in safety-critical tasks. In reinforcement learning ( RL ), researchers can inject their intentions into the carefully designed reward function. However, RL methods bear two drawbacks that limit their applications in safety-critical tasks. First, the nature of trial-and-error exploration exposes RL agent to dangerous situations. Second, it is difficult to summarize all the intended behaviors to be learned into the reward",
    ". We demonstrate the convergence of the iterative training process of DMIL and the Expectation-Maximization algorithm. In this work, we achieve state-of-the-art few-shot imitation learning performance on the meta-world ( Yu et al., 2019b ) benchmark and comparable results on the Kitchen environment. In this work, we propose Dual Meta Imitation Learning ( DMIL ), a hierarchical meta imitation learning method where the high-level network",
    ". We demonstrate the convergence of the iterative training process of DMIL and the Expectation-Maximization algorithm. In this work, we achieve state-of-the-art few-shot imitation learning performance on the meta-world ( Yu et al., 2019b ) benchmark and comparable results on the Kitchen environment. In this work, we propose Dual Meta Imitation Learning ( DMIL ), a hierarchical meta imitation learning method where the high-level network",
    ". We demonstrate the convergence of the iterative training process of DMIL and the Expectation-Maximization algorithm. In this work, we achieve state-of-the-art few-shot imitation learning performance on the meta-world ( Yu et al., 2019b ) benchmark and comparable results on the Kitchen environment. In this work, we propose Dual Meta Imitation Learning ( DMIL ), a hierarchical meta imitation learning method where the high-level network",
    ". We demonstrate the convergence of the iterative training process of DMIL and the Expectation-Maximization algorithm. In this work, we achieve state-of-the-art few-shot imitation learning performance on the meta-world ( Yu et al., 2019b ) benchmark and comparable results on the Kitchen environment. In this work, we propose Dual Meta Imitation Learning ( DMIL ), a hierarchical meta imitation learning method where the high-level network",
    ". The parameters associated with the compression method can be trained together with GNNs. We show that the proposed node embedding compression method achieves superior performance compared to the alternatives. Graph neural networks ( GNNs ) are deep learning models designed specifically for graph data. In order to apply such type of model on graph without node features X, one could either 1 ) extract simple graph based node features ( e.g., number of degrees ) from the graph G",
    ". The parameters associated with the compression method can be trained together with GNNs. We show that the proposed node embedding compression method achieves superior performance compared to the alternatives. Graph neural networks ( GNNs ) are deep learning models designed specifically for graph data. In order to apply such type of model on graph without node features X, one could either 1 ) extract simple graph based node features ( e.g., number of degrees ) from the graph G",
    ". The parameters associated with the compression method can be trained together with GNNs. We show that the proposed node embedding compression method achieves superior performance compared to the alternatives. Graph neural networks ( GNNs ) are deep learning models designed specifically for graph data. In order to apply such type of model on graph without node features X, one could either 1 ) extract simple graph based node features ( e.g., number of degrees ) from the graph G",
    ". The parameters associated with the compression method can be trained together with GNNs. We show that the proposed node embedding compression method achieves superior performance compared to the alternatives. Graph neural networks ( GNNs ) are deep learning models designed specifically for graph data. In order to apply such type of model on graph without node features X, one could either 1 ) extract simple graph based node features ( e.g., number of degrees ) from the graph G",
    ", 2019 ; Zhang et al., 2019 ; Acuna et al., 2021 ). Domain-Adversarial Learning ( DAL ), was introduced by Ganin et al. ( 2016 ). This approach focuses on minimizing the discrepancy between source and target domain in a representation space. This approach is known as the Gradient Reversal Layer ( GRL ). GRL flips the sign",
    ", 2019 ; Zhang et al., 2019 ; Acuna et al., 2021 ). Domain-Adversarial Learning ( DAL ), was introduced by Ganin et al. ( 2016 ). This approach focuses on minimizing the discrepancy between source and target domain in a representation space. This approach is known as the Gradient Reversal Layer ( GRL ). GRL flips the sign",
    ", 2019 ; Zhang et al., 2019 ; Acuna et al., 2021 ). Domain-Adversarial Learning ( DAL ), was introduced by Ganin et al. ( 2016 ). This approach focuses on minimizing the discrepancy between source and target domain in a representation space. This approach is known as the Gradient Reversal Layer ( GRL ). GRL flips the sign",
    ", 2019 ; Zhang et al., 2019 ; Acuna et al., 2021 ). Domain-Adversarial Learning ( DAL ), was introduced by Ganin et al. ( 2016 ). This approach focuses on minimizing the discrepancy between source and target domain in a representation space. This approach is known as the Gradient Reversal Layer ( GRL ). GRL flips the sign",
    ", Dropout ( Srivastava et al., 2014 ), Label Smoothing ( Szegedy et al., 2016 ), Label Smoothing ( Foret et al., 2021 ). To prevent overfitting, many methods have been proposed to regularize how machine learning models fit the training data. For example, Flooding proposes the following loss function LFlooding = L  b",
    ", Dropout ( Srivastava et al., 2014 ), Label Smoothing ( Szegedy et al., 2016 ), Label Smoothing ( Foret et al., 2021 ). To prevent overfitting, many methods have been proposed to regularize how machine learning models fit the training data. For example, Flooding proposes the following loss function LFlooding = L  b",
    ", Dropout ( Srivastava et al., 2014 ), Label Smoothing ( Szegedy et al., 2016 ), Label Smoothing ( Foret et al., 2021 ). To prevent overfitting, many methods have been proposed to regularize how machine learning models fit the training data. For example, Flooding proposes the following loss function LFlooding = L  b",
    ", Dropout ( Srivastava et al., 2014 ), Label Smoothing ( Szegedy et al., 2016 ), Label Smoothing ( Foret et al., 2021 ). To prevent overfitting, many methods have been proposed to regularize how machine learning models fit the training data. For example, Flooding proposes the following loss function LFlooding = L  b",
    ". Hierarchical reinforcement learning ( HRL ) aims to simplify the higher-level control or planning problem. Typically, this is taken to mean abstraction of actions in the form of primitive skills. However, significantly simplifying the problem for the higher level requires abstraction of both states and actions. This challenge differs markedly from representation learning problems in other domains, like computer vision and unsupervised learning ( Schroff et al., 2015 ; van den Oord et",
    ". Hierarchical reinforcement learning ( HRL ) aims to simplify the higher-level control or planning problem. Typically, this is taken to mean abstraction of actions in the form of primitive skills. However, significantly simplifying the problem for the higher level requires abstraction of both states and actions. This challenge differs markedly from representation learning problems in other domains, like computer vision and unsupervised learning ( Schroff et al., 2015 ; van den Oord et",
    ". Hierarchical reinforcement learning ( HRL ) aims to simplify the higher-level control or planning problem. Typically, this is taken to mean abstraction of actions in the form of primitive skills. However, significantly simplifying the problem for the higher level requires abstraction of both states and actions. This challenge differs markedly from representation learning problems in other domains, like computer vision and unsupervised learning ( Schroff et al., 2015 ; van den Oord et",
    ". Hierarchical reinforcement learning ( HRL ) aims to simplify the higher-level control or planning problem. Typically, this is taken to mean abstraction of actions in the form of primitive skills. However, significantly simplifying the problem for the higher level requires abstraction of both states and actions. This challenge differs markedly from representation learning problems in other domains, like computer vision and unsupervised learning ( Schroff et al., 2015 ; van den Oord et",
    ". set and graph generation are very similar problems. Yet, it has important applications in drug discovery. In this paper, we instead focus on one-shot generation. This allows for more principled designs. In the following, we only use the terminology of sets in order to avoid overly abstract notations. In the following, we only use the terminology of sets in order to avoid overly abstract notations. In the following, we only use the terminology of sets in order to avoid over",
    ". set and graph generation are very similar problems. Yet, it has important applications in drug discovery. In this paper, we instead focus on one-shot generation. This allows for more principled designs. In the following, we only use the terminology of sets in order to avoid overly abstract notations. In the following, we only use the terminology of sets in order to avoid overly abstract notations. In the following, we only use the terminology of sets in order to avoid over",
    ". set and graph generation are very similar problems. Yet, it has important applications in drug discovery. In this paper, we instead focus on one-shot generation. This allows for more principled designs. In the following, we only use the terminology of sets in order to avoid overly abstract notations. In the following, we only use the terminology of sets in order to avoid overly abstract notations. In the following, we only use the terminology of sets in order to avoid over",
    ". set and graph generation are very similar problems. Yet, it has important applications in drug discovery. In this paper, we instead focus on one-shot generation. This allows for more principled designs. In the following, we only use the terminology of sets in order to avoid overly abstract notations. In the following, we only use the terminology of sets in order to avoid overly abstract notations. In the following, we only use the terminology of sets in order to avoid over",
    "based on a variational formulation whose solution coincides with the solution of the PDE of interest. In this paper, we aim to establish the numerical analysis of such deep learning based PDE solvers. Inspired by recent works which showed that the empirical performance of a model is remarkably predictable via a power law of the data number, known as the neural scaling law. In this paper, we aim to establish the numerical analysis of such deep learning based PDE solvers.",
    "based on a variational formulation whose solution coincides with the solution of the PDE of interest. In this paper, we aim to establish the numerical analysis of such deep learning based PDE solvers. Inspired by recent works which showed that the empirical performance of a model is remarkably predictable via a power law of the data number, known as the neural scaling law. In this paper, we aim to establish the numerical analysis of such deep learning based PDE solvers.",
    "based on a variational formulation whose solution coincides with the solution of the PDE of interest. In this paper, we aim to establish the numerical analysis of such deep learning based PDE solvers. Inspired by recent works which showed that the empirical performance of a model is remarkably predictable via a power law of the data number, known as the neural scaling law. In this paper, we aim to establish the numerical analysis of such deep learning based PDE solvers.",
    "based on a variational formulation whose solution coincides with the solution of the PDE of interest. In this paper, we aim to establish the numerical analysis of such deep learning based PDE solvers. Inspired by recent works which showed that the empirical performance of a model is remarkably predictable via a power law of the data number, known as the neural scaling law. In this paper, we aim to establish the numerical analysis of such deep learning based PDE solvers.",
    "domain transferability is the task of training machine learning models with data from one or more source domains that can be adapted to a target domain. on the other hand, robust machine learning aims to tackle the problem of adversarial data distribution shift. in this paper, we take the first steps towards formally analyzing the relationship between model robustness and domain transferability. we answer the following questions : What are sufficient conditions for domain transferability? Is model robustness the cause of domain transferability?",
    "domain transferability is the task of training machine learning models with data from one or more source domains that can be adapted to a target domain. on the other hand, robust machine learning aims to tackle the problem of adversarial data distribution shift. in this paper, we take the first steps towards formally analyzing the relationship between model robustness and domain transferability. we answer the following questions : What are sufficient conditions for domain transferability? Is model robustness the cause of domain transferability?",
    "domain transferability is the task of training machine learning models with data from one or more source domains that can be adapted to a target domain. on the other hand, robust machine learning aims to tackle the problem of adversarial data distribution shift. in this paper, we take the first steps towards formally analyzing the relationship between model robustness and domain transferability. we answer the following questions : What are sufficient conditions for domain transferability? Is model robustness the cause of domain transferability?",
    "domain transferability is the task of training machine learning models with data from one or more source domains that can be adapted to a target domain. on the other hand, robust machine learning aims to tackle the problem of adversarial data distribution shift. in this paper, we take the first steps towards formally analyzing the relationship between model robustness and domain transferability. we answer the following questions : What are sufficient conditions for domain transferability? Is model robustness the cause of domain transferability?",
    "gradient-based meta-learning algorithms. In this paper, we focus on gradient-based meta-learning algorithms that are more flexible. Gradient-based meta-learning algorithms form the initialization for a base learner and learn the initialization by a bi-level optimization procedure during the meta-training phase. This bi-level optimization scheme, though designed to learn a well-generalized initialization, runs a high risk of inducing a sufficiently expressive initialization that memorizes all meta",
    "gradient-based meta-learning algorithms. In this paper, we focus on gradient-based meta-learning algorithms that are more flexible. Gradient-based meta-learning algorithms form the initialization for a base learner and learn the initialization by a bi-level optimization procedure during the meta-training phase. This bi-level optimization scheme, though designed to learn a well-generalized initialization, runs a high risk of inducing a sufficiently expressive initialization that memorizes all meta",
    "gradient-based meta-learning algorithms. In this paper, we focus on gradient-based meta-learning algorithms that are more flexible. Gradient-based meta-learning algorithms form the initialization for a base learner and learn the initialization by a bi-level optimization procedure during the meta-training phase. This bi-level optimization scheme, though designed to learn a well-generalized initialization, runs a high risk of inducing a sufficiently expressive initialization that memorizes all meta",
    "gradient-based meta-learning algorithms. In this paper, we focus on gradient-based meta-learning algorithms that are more flexible. Gradient-based meta-learning algorithms form the initialization for a base learner and learn the initialization by a bi-level optimization procedure during the meta-training phase. This bi-level optimization scheme, though designed to learn a well-generalized initialization, runs a high risk of inducing a sufficiently expressive initialization that memorizes all meta",
    ". This problem is known in the literature as ad hoc teamwork. For example, in the domain of human-AI collaboration in Hanabi ( Bard et al., 2019 ; Chen et al., 2020 ), ad hoc teamwork requires prior domain knowledge. For example, in search and rescue tasks in a disaster, deployed robots need to interact with robots from other companies or laboratories. Furthermore, in the domain of game",
    ". This problem is known in the literature as ad hoc teamwork. For example, in the domain of human-AI collaboration in Hanabi ( Bard et al., 2019 ; Chen et al., 2020 ), ad hoc teamwork requires prior domain knowledge. For example, in search and rescue tasks in a disaster, deployed robots need to interact with robots from other companies or laboratories. Furthermore, in the domain of game",
    ". This problem is known in the literature as ad hoc teamwork. For example, in the domain of human-AI collaboration in Hanabi ( Bard et al., 2019 ; Chen et al., 2020 ), ad hoc teamwork requires prior domain knowledge. For example, in search and rescue tasks in a disaster, deployed robots need to interact with robots from other companies or laboratories. Furthermore, in the domain of game",
    ". This problem is known in the literature as ad hoc teamwork. For example, in the domain of human-AI collaboration in Hanabi ( Bard et al., 2019 ; Chen et al., 2020 ), ad hoc teamwork requires prior domain knowledge. For example, in search and rescue tasks in a disaster, deployed robots need to interact with robots from other companies or laboratories. Furthermore, in the domain of game",
    "; Xie et al., 2012 ; Yeh et al., 2016 ). Missing values are often encountered for real-world datasets. In this work, we introduce EMFlow that integrates the normalizing flow ( NF ) ( Dinh et al., 2016 ). In addition, EMFlow is able to learn the correlation between missing and observed entries by embedding the data into a lower dimensional",
    "; Xie et al., 2012 ; Yeh et al., 2016 ). Missing values are often encountered for real-world datasets. In this work, we introduce EMFlow that integrates the normalizing flow ( NF ) ( Dinh et al., 2016 ). In addition, EMFlow is able to learn the correlation between missing and observed entries by embedding the data into a lower dimensional",
    "; Xie et al., 2012 ; Yeh et al., 2016 ). Missing values are often encountered for real-world datasets. In this work, we introduce EMFlow that integrates the normalizing flow ( NF ) ( Dinh et al., 2016 ). In addition, EMFlow is able to learn the correlation between missing and observed entries by embedding the data into a lower dimensional",
    "; Xie et al., 2012 ; Yeh et al., 2016 ). Missing values are often encountered for real-world datasets. In this work, we introduce EMFlow that integrates the normalizing flow ( NF ) ( Dinh et al., 2016 ). In addition, EMFlow is able to learn the correlation between missing and observed entries by embedding the data into a lower dimensional",
    "despite their success deep neural networks ( DNNs ) are still largely considered as black boxes. the main issue is that in each layer of a DNN, the linear computation, i.e., multiplication by the weight matrix and the non-linear activations are entangled. Such entanglement has its pros and cons. in terms of interpretability, such entanglement has an adverse effect.",
    "despite their success deep neural networks ( DNNs ) are still largely considered as black boxes. the main issue is that in each layer of a DNN, the linear computation, i.e., multiplication by the weight matrix and the non-linear activations are entangled. Such entanglement has its pros and cons. in terms of interpretability, such entanglement has an adverse effect.",
    "despite their success deep neural networks ( DNNs ) are still largely considered as black boxes. the main issue is that in each layer of a DNN, the linear computation, i.e., multiplication by the weight matrix and the non-linear activations are entangled. Such entanglement has its pros and cons. in terms of interpretability, such entanglement has an adverse effect.",
    "despite their success deep neural networks ( DNNs ) are still largely considered as black boxes. the main issue is that in each layer of a DNN, the linear computation, i.e., multiplication by the weight matrix and the non-linear activations are entangled. Such entanglement has its pros and cons. in terms of interpretability, such entanglement has an adverse effect.",
    ". Lastly, we propose a new normalizer, termed Dynamic Token Normalization ( DTN ). DTN learns to normalize tokens in both intra- and inter-token manners. This enables Transformers to capture both the global contextual information and the local positional context in an image. DTN can be easily plugged into various vision transformers, such as ViT, Swin, PVT, LeViT, T2T",
    ". Lastly, we propose a new normalizer, termed Dynamic Token Normalization ( DTN ). DTN learns to normalize tokens in both intra- and inter-token manners. This enables Transformers to capture both the global contextual information and the local positional context in an image. DTN can be easily plugged into various vision transformers, such as ViT, Swin, PVT, LeViT, T2T",
    ". Lastly, we propose a new normalizer, termed Dynamic Token Normalization ( DTN ). DTN learns to normalize tokens in both intra- and inter-token manners. This enables Transformers to capture both the global contextual information and the local positional context in an image. DTN can be easily plugged into various vision transformers, such as ViT, Swin, PVT, LeViT, T2T",
    ". Lastly, we propose a new normalizer, termed Dynamic Token Normalization ( DTN ). DTN learns to normalize tokens in both intra- and inter-token manners. This enables Transformers to capture both the global contextual information and the local positional context in an image. DTN can be easily plugged into various vision transformers, such as ViT, Swin, PVT, LeViT, T2T",
    "two fundamental questions in machine learning are why overparameterized models generalize and how to make them more robust to distribution shift. Resolving both these questions requires understanding how complex our models should be. For instance, it is thought that overparameterized models generalize well because there are implicit regularizers that constrain the complexity of the learned functions. In practice, spectral bias is difficult to measure : the most direct method involves taking a Fourier transform with respect to the input.",
    "two fundamental questions in machine learning are why overparameterized models generalize and how to make them more robust to distribution shift. Resolving both these questions requires understanding how complex our models should be. For instance, it is thought that overparameterized models generalize well because there are implicit regularizers that constrain the complexity of the learned functions. In practice, spectral bias is difficult to measure : the most direct method involves taking a Fourier transform with respect to the input.",
    "two fundamental questions in machine learning are why overparameterized models generalize and how to make them more robust to distribution shift. Resolving both these questions requires understanding how complex our models should be. For instance, it is thought that overparameterized models generalize well because there are implicit regularizers that constrain the complexity of the learned functions. In practice, spectral bias is difficult to measure : the most direct method involves taking a Fourier transform with respect to the input.",
    "two fundamental questions in machine learning are why overparameterized models generalize and how to make them more robust to distribution shift. Resolving both these questions requires understanding how complex our models should be. For instance, it is thought that overparameterized models generalize well because there are implicit regularizers that constrain the complexity of the learned functions. In practice, spectral bias is difficult to measure : the most direct method involves taking a Fourier transform with respect to the input.",
    ". Finally, we report a promising and detailed analysis on Atari. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between exploration and exploitation.",
    ". Finally, we report a promising and detailed analysis on Atari. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between exploration and exploitation.",
    ". Finally, we report a promising and detailed analysis on Atari. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between exploration and exploitation.",
    ". Finally, we report a promising and detailed analysis on Atari. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between taking the familiar choice that is known to be rewarding and learning about unfamiliar options of uncertain reward. Exploration is about the balance between exploration and exploitation.",
    "OPTk ( D ) is the cost of optimal ( oracle ) k-median solution on the dataset D. In k-median, the goal is to find k center points. In k-means, the objective is to minimize the sum of squared distances between each sample point to its nearest center. In k-median, the goal is to find k center points minimizing the sum of absolute distances between each sample point to its nearest center",
    "OPTk ( D ) is the cost of optimal ( oracle ) k-median solution on the dataset D. In k-median, the goal is to find k center points. In k-means, the objective is to minimize the sum of squared distances between each sample point to its nearest center. In k-median, the goal is to find k center points minimizing the sum of absolute distances between each sample point to its nearest center",
    "OPTk ( D ) is the cost of optimal ( oracle ) k-median solution on the dataset D. In k-median, the goal is to find k center points. In k-means, the objective is to minimize the sum of squared distances between each sample point to its nearest center. In k-median, the goal is to find k center points minimizing the sum of absolute distances between each sample point to its nearest center",
    "OPTk ( D ) is the cost of optimal ( oracle ) k-median solution on the dataset D. In k-median, the goal is to find k center points. In k-means, the objective is to minimize the sum of squared distances between each sample point to its nearest center. In k-median, the goal is to find k center points minimizing the sum of absolute distances between each sample point to its nearest center",
    ", 2019 ). Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. This capability enables us to anticipate future events and plan ahead to perform temporally extended tasks. Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. Predicting what happens next is a cornerstone of intelligence and one",
    ", 2019 ). Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. This capability enables us to anticipate future events and plan ahead to perform temporally extended tasks. Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. Predicting what happens next is a cornerstone of intelligence and one",
    ", 2019 ). Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. This capability enables us to anticipate future events and plan ahead to perform temporally extended tasks. Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. Predicting what happens next is a cornerstone of intelligence and one",
    ", 2019 ). Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. This capability enables us to anticipate future events and plan ahead to perform temporally extended tasks. Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. Predicting what happens next is a cornerstone of intelligence and one of the key capabilities of humans. Predicting what happens next is a cornerstone of intelligence and one",
    ". Finally, we extend our theory to the more usual setting of stochastic gradient descent ( SGD ) on a fixed subsampled training set. In this paper, we calculate the average case performance of SGD on models of the form f ( x ) = w  ( x ) for nonlinear random-feature models and deep neural networks trained with MSE loss. We express test loss dynamics in terms of the induced second and third errors.",
    ". Finally, we extend our theory to the more usual setting of stochastic gradient descent ( SGD ) on a fixed subsampled training set. In this paper, we calculate the average case performance of SGD on models of the form f ( x ) = w  ( x ) for nonlinear random-feature models and deep neural networks trained with MSE loss. We express test loss dynamics in terms of the induced second and third errors.",
    ". Finally, we extend our theory to the more usual setting of stochastic gradient descent ( SGD ) on a fixed subsampled training set. In this paper, we calculate the average case performance of SGD on models of the form f ( x ) = w  ( x ) for nonlinear random-feature models and deep neural networks trained with MSE loss. We express test loss dynamics in terms of the induced second and third errors.",
    ". Finally, we extend our theory to the more usual setting of stochastic gradient descent ( SGD ) on a fixed subsampled training set. In this paper, we calculate the average case performance of SGD on models of the form f ( x ) = w  ( x ) for nonlinear random-feature models and deep neural networks trained with MSE loss. We express test loss dynamics in terms of the induced second and third errors.",
    "2018 ; ; Du et al., 2018 ; Allen-Zhu et al., 2018 ). Despite its simplicity, SGD is hard to understand. ( 1 ) SGD noise is state-dependent ; ( 2 ) SGD noise is nonlinear and non-convex. ( 3 ) SGD noise is nonlinear and non-convex. ( 4 ) SGD noise is nonlinear and non",
    "2018 ; ; Du et al., 2018 ; Allen-Zhu et al., 2018 ). Despite its simplicity, SGD is hard to understand. ( 1 ) SGD noise is state-dependent ; ( 2 ) SGD noise is nonlinear and non-convex. ( 3 ) SGD noise is nonlinear and non-convex. ( 4 ) SGD noise is nonlinear and non",
    "2018 ; ; Du et al., 2018 ; Allen-Zhu et al., 2018 ). Despite its simplicity, SGD is hard to understand. ( 1 ) SGD noise is state-dependent ; ( 2 ) SGD noise is nonlinear and non-convex. ( 3 ) SGD noise is nonlinear and non-convex. ( 4 ) SGD noise is nonlinear and non",
    "2018 ; ; Du et al., 2018 ; Allen-Zhu et al., 2018 ). Despite its simplicity, SGD is hard to understand. ( 1 ) SGD noise is state-dependent ; ( 2 ) SGD noise is nonlinear and non-convex. ( 3 ) SGD noise is nonlinear and non-convex. ( 4 ) SGD noise is nonlinear and non",
    "the hyperparameters. Those hyperparameters are important in helping the inner-learner converge faster and generalize better. However, none of the existing algorithms meet the following criteria. Forward-Mode Differentiation ( FMD ) ( Franceschi et al., 2017 ) in Table 1 is an algorithm that forward-propagates Jacobians ( i.e. derivatives of the update function ) from the first to the last step. This algorithm",
    "the hyperparameters. Those hyperparameters are important in helping the inner-learner converge faster and generalize better. However, none of the existing algorithms meet the following criteria. Forward-Mode Differentiation ( FMD ) ( Franceschi et al., 2017 ) in Table 1 is an algorithm that forward-propagates Jacobians ( i.e. derivatives of the update function ) from the first to the last step. This algorithm",
    "the hyperparameters. Those hyperparameters are important in helping the inner-learner converge faster and generalize better. However, none of the existing algorithms meet the following criteria. Forward-Mode Differentiation ( FMD ) ( Franceschi et al., 2017 ) in Table 1 is an algorithm that forward-propagates Jacobians ( i.e. derivatives of the update function ) from the first to the last step. This algorithm",
    "the hyperparameters. Those hyperparameters are important in helping the inner-learner converge faster and generalize better. However, none of the existing algorithms meet the following criteria. Forward-Mode Differentiation ( FMD ) ( Franceschi et al., 2017 ) in Table 1 is an algorithm that forward-propagates Jacobians ( i.e. derivatives of the update function ) from the first to the last step. This algorithm",
    "2018 ; 2018 ; Yoon et al., 2018 ; Li et al., 2019 ; Dong et al., 2020 ; Lu et al., 2020 ; Lin et al., 2020 ; Lin et al., 2021 ). To overcome this challenge, many recent advances in meta-learning have demonstrated success in fields like few-shot image classification and cold-start recommendation. However,",
    "2018 ; 2018 ; Yoon et al., 2018 ; Li et al., 2019 ; Dong et al., 2020 ; Lu et al., 2020 ; Lin et al., 2020 ; Lin et al., 2021 ). To overcome this challenge, many recent advances in meta-learning have demonstrated success in fields like few-shot image classification and cold-start recommendation. However,",
    "2018 ; 2018 ; Yoon et al., 2018 ; Li et al., 2019 ; Dong et al., 2020 ; Lu et al., 2020 ; Lin et al., 2020 ; Lin et al., 2021 ). To overcome this challenge, many recent advances in meta-learning have demonstrated success in fields like few-shot image classification and cold-start recommendation. However,",
    "2018 ; 2018 ; Yoon et al., 2018 ; Li et al., 2019 ; Dong et al., 2020 ; Lu et al., 2020 ; Lin et al., 2020 ; Lin et al., 2021 ). To overcome this challenge, many recent advances in meta-learning have demonstrated success in fields like few-shot image classification and cold-start recommendation. However,",
    "........... ( 2016 ) ; & ( 2016 )..... ( 2017 )... ( 2017 ).. ( 2017 ). on standard image data sets ( ( 2019 ) ).....",
    "........... ( 2016 ) ; & ( 2016 )..... ( 2017 )... ( 2017 ).. ( 2017 ). on standard image data sets ( ( 2019 ) ).....",
    "........... ( 2016 ) ; & ( 2016 )..... ( 2017 )... ( 2017 ).. ( 2017 ). on standard image data sets ( ( 2019 ) ).....",
    "........... ( 2016 ) ; & ( 2016 )..... ( 2017 )... ( 2017 ).. ( 2017 ). on standard image data sets ( ( 2019 ) ).....",
    ". Similarly, for motion forecasting tasks, models should be insensitive to agent ordering. In this work, we focus on the generative modelling of sequences and sets and demonstrate this method on a variety of different motion forecasting tasks. Suppose we have a set of sequences X =  ( x1,..., xK ) 1,..., ( x1,..",
    ". Similarly, for motion forecasting tasks, models should be insensitive to agent ordering. In this work, we focus on the generative modelling of sequences and sets and demonstrate this method on a variety of different motion forecasting tasks. Suppose we have a set of sequences X =  ( x1,..., xK ) 1,..., ( x1,..",
    ". Similarly, for motion forecasting tasks, models should be insensitive to agent ordering. In this work, we focus on the generative modelling of sequences and sets and demonstrate this method on a variety of different motion forecasting tasks. Suppose we have a set of sequences X =  ( x1,..., xK ) 1,..., ( x1,..",
    ". Similarly, for motion forecasting tasks, models should be insensitive to agent ordering. In this work, we focus on the generative modelling of sequences and sets and demonstrate this method on a variety of different motion forecasting tasks. Suppose we have a set of sequences X =  ( x1,..., xK ) 1,..., ( x1,..",
    "do interpretable ML techniques enable users to discover biases better than by simply inspecting input/output pairs? In this work, we ask : do modern interpretability methods enable users to discover biases better than by simply inspecting input/output pairs? To investigate this question empirically, we first propose TWO4TWO : a synthetic dataset depicting two abstract animals. Its data-generating factors can be correlated with the binary target class, thereby creating arbitrarily",
    "do interpretable ML techniques enable users to discover biases better than by simply inspecting input/output pairs? In this work, we ask : do modern interpretability methods enable users to discover biases better than by simply inspecting input/output pairs? To investigate this question empirically, we first propose TWO4TWO : a synthetic dataset depicting two abstract animals. Its data-generating factors can be correlated with the binary target class, thereby creating arbitrarily",
    "do interpretable ML techniques enable users to discover biases better than by simply inspecting input/output pairs? In this work, we ask : do modern interpretability methods enable users to discover biases better than by simply inspecting input/output pairs? To investigate this question empirically, we first propose TWO4TWO : a synthetic dataset depicting two abstract animals. Its data-generating factors can be correlated with the binary target class, thereby creating arbitrarily",
    "do interpretable ML techniques enable users to discover biases better than by simply inspecting input/output pairs? In this work, we ask : do modern interpretability methods enable users to discover biases better than by simply inspecting input/output pairs? To investigate this question empirically, we first propose TWO4TWO : a synthetic dataset depicting two abstract animals. Its data-generating factors can be correlated with the binary target class, thereby creating arbitrarily",
    "a backdoor that causes a model to misclassify stop signs as speed signs. Once installed, an adversary can exploit the backdoor to change the network \u2019 s predictions at inference time. Techniques We first introduce the notion of self-expanding sets. To separate the training set into homogeneous components, we present the Inverse Self-Paced Learning algorithm. This algorithm is based on a bootstrapped measure of how well a set generalizes",
    "a backdoor that causes a model to misclassify stop signs as speed signs. Once installed, an adversary can exploit the backdoor to change the network \u2019 s predictions at inference time. Techniques We first introduce the notion of self-expanding sets. To separate the training set into homogeneous components, we present the Inverse Self-Paced Learning algorithm. This algorithm is based on a bootstrapped measure of how well a set generalizes",
    "a backdoor that causes a model to misclassify stop signs as speed signs. Once installed, an adversary can exploit the backdoor to change the network \u2019 s predictions at inference time. Techniques We first introduce the notion of self-expanding sets. To separate the training set into homogeneous components, we present the Inverse Self-Paced Learning algorithm. This algorithm is based on a bootstrapped measure of how well a set generalizes",
    "a backdoor that causes a model to misclassify stop signs as speed signs. Once installed, an adversary can exploit the backdoor to change the network \u2019 s predictions at inference time. Techniques We first introduce the notion of self-expanding sets. To separate the training set into homogeneous components, we present the Inverse Self-Paced Learning algorithm. This algorithm is based on a bootstrapped measure of how well a set generalizes",
    ". However, in real tasks, the labels and the text often correlate with each other in a complicated way. The source code is provided in the supplementary file. Labels can be quite different depending on text contexts. It may not be appropriate to simplify their correlations a priori too much. The source code is provided in the supplementary file. The source code is provided in the supplementary file. The source code is provided in the supplementary file. The source code is provided in",
    ". However, in real tasks, the labels and the text often correlate with each other in a complicated way. The source code is provided in the supplementary file. Labels can be quite different depending on text contexts. It may not be appropriate to simplify their correlations a priori too much. The source code is provided in the supplementary file. The source code is provided in the supplementary file. The source code is provided in the supplementary file. The source code is provided in",
    ". However, in real tasks, the labels and the text often correlate with each other in a complicated way. The source code is provided in the supplementary file. Labels can be quite different depending on text contexts. It may not be appropriate to simplify their correlations a priori too much. The source code is provided in the supplementary file. The source code is provided in the supplementary file. The source code is provided in the supplementary file. The source code is provided in",
    ". However, in real tasks, the labels and the text often correlate with each other in a complicated way. The source code is provided in the supplementary file. Labels can be quite different depending on text contexts. It may not be appropriate to simplify their correlations a priori too much. The source code is provided in the supplementary file. The source code is provided in the supplementary file. The source code is provided in the supplementary file. The source code is provided in",
    "deep convolutional models have been at the heart of the recent successes of deep learning in problems where the data consists of high-dimensional signals. However, our theoretical understanding of how deep convolutional models enable efficient learning is still limited. To overcome this issue, we consider instead function classes based on kernel methods, which are known to be learnable with efficient ( polynomial-time ) algorithms. We consider convolutional kernels known as convolutional kernels, which yield good empirical performance",
    "deep convolutional models have been at the heart of the recent successes of deep learning in problems where the data consists of high-dimensional signals. However, our theoretical understanding of how deep convolutional models enable efficient learning is still limited. To overcome this issue, we consider instead function classes based on kernel methods, which are known to be learnable with efficient ( polynomial-time ) algorithms. We consider convolutional kernels known as convolutional kernels, which yield good empirical performance",
    "deep convolutional models have been at the heart of the recent successes of deep learning in problems where the data consists of high-dimensional signals. However, our theoretical understanding of how deep convolutional models enable efficient learning is still limited. To overcome this issue, we consider instead function classes based on kernel methods, which are known to be learnable with efficient ( polynomial-time ) algorithms. We consider convolutional kernels known as convolutional kernels, which yield good empirical performance",
    "deep convolutional models have been at the heart of the recent successes of deep learning in problems where the data consists of high-dimensional signals. However, our theoretical understanding of how deep convolutional models enable efficient learning is still limited. To overcome this issue, we consider instead function classes based on kernel methods, which are known to be learnable with efficient ( polynomial-time ) algorithms. We consider convolutional kernels known as convolutional kernels, which yield good empirical performance",
    ". At finite widths, the NTK is notoriously expensive to compute. This severely limits its practical utility. We propose two novel algorithms that change the exponent of the compute and memory requirements of the finite width NTK. We open-source [ github.com/iclr2022anon/fast finite width ntk ] our two algorithms as general-purpose JAX function transformations that apply to any differentiable computation.",
    ". At finite widths, the NTK is notoriously expensive to compute. This severely limits its practical utility. We propose two novel algorithms that change the exponent of the compute and memory requirements of the finite width NTK. We open-source [ github.com/iclr2022anon/fast finite width ntk ] our two algorithms as general-purpose JAX function transformations that apply to any differentiable computation.",
    ". At finite widths, the NTK is notoriously expensive to compute. This severely limits its practical utility. We propose two novel algorithms that change the exponent of the compute and memory requirements of the finite width NTK. We open-source [ github.com/iclr2022anon/fast finite width ntk ] our two algorithms as general-purpose JAX function transformations that apply to any differentiable computation.",
    ". At finite widths, the NTK is notoriously expensive to compute. This severely limits its practical utility. We propose two novel algorithms that change the exponent of the compute and memory requirements of the finite width NTK. We open-source [ github.com/iclr2022anon/fast finite width ntk ] our two algorithms as general-purpose JAX function transformations that apply to any differentiable computation.",
    "based on pre-collected data. Offline reinforcement learning ( RL ) has shown great promise in a wide range of domains, such as complex games ( Mnih et al., 2015 ; Silver et al., 2017 ) and robotic control ( Haarnoja et al., 2018 ). In contrast, in real-world domains it is common that the behavior of the agent is subject to additional constraints beyond the reward",
    "based on pre-collected data. Offline reinforcement learning ( RL ) has shown great promise in a wide range of domains, such as complex games ( Mnih et al., 2015 ; Silver et al., 2017 ) and robotic control ( Haarnoja et al., 2018 ). In contrast, in real-world domains it is common that the behavior of the agent is subject to additional constraints beyond the reward",
    "based on pre-collected data. Offline reinforcement learning ( RL ) has shown great promise in a wide range of domains, such as complex games ( Mnih et al., 2015 ; Silver et al., 2017 ) and robotic control ( Haarnoja et al., 2018 ). In contrast, in real-world domains it is common that the behavior of the agent is subject to additional constraints beyond the reward",
    "based on pre-collected data. Offline reinforcement learning ( RL ) has shown great promise in a wide range of domains, such as complex games ( Mnih et al., 2015 ; Silver et al., 2017 ) and robotic control ( Haarnoja et al., 2018 ). In contrast, in real-world domains it is common that the behavior of the agent is subject to additional constraints beyond the reward",
    ". Moreover, the training procedure of each sequence is invariably sequential. This paper proposes a parallelization strategy for a recurrent neural network ( RNN ) architecture known as the gated recurrent unit ( GRU ) developed by Cho et al. ( 2014 ). Moreover, the model-parallelism approach is beneficial when the network requires a large number of layers. This paper proposes a parallelization strategy for a recurrent neural",
    ". Moreover, the training procedure of each sequence is invariably sequential. This paper proposes a parallelization strategy for a recurrent neural network ( RNN ) architecture known as the gated recurrent unit ( GRU ) developed by Cho et al. ( 2014 ). Moreover, the model-parallelism approach is beneficial when the network requires a large number of layers. This paper proposes a parallelization strategy for a recurrent neural",
    ". Moreover, the training procedure of each sequence is invariably sequential. This paper proposes a parallelization strategy for a recurrent neural network ( RNN ) architecture known as the gated recurrent unit ( GRU ) developed by Cho et al. ( 2014 ). Moreover, the model-parallelism approach is beneficial when the network requires a large number of layers. This paper proposes a parallelization strategy for a recurrent neural",
    ". Moreover, the training procedure of each sequence is invariably sequential. This paper proposes a parallelization strategy for a recurrent neural network ( RNN ) architecture known as the gated recurrent unit ( GRU ) developed by Cho et al. ( 2014 ). Moreover, the model-parallelism approach is beneficial when the network requires a large number of layers. This paper proposes a parallelization strategy for a recurrent neural",
    ". a neural network called MRMD-AE ( manifold-regularized multiple decoder, autoencoder ), that learns a common embedding from multiple subjects in an experiment while retaining the ability to decode to individual raw fMRI signals. This framework can be used for many downstream applications such as guided brain-computer interface ( BCI ) training in the future. In this paper, we propose a neural network called MRMD-AE",
    ". a neural network called MRMD-AE ( manifold-regularized multiple decoder, autoencoder ), that learns a common embedding from multiple subjects in an experiment while retaining the ability to decode to individual raw fMRI signals. This framework can be used for many downstream applications such as guided brain-computer interface ( BCI ) training in the future. In this paper, we propose a neural network called MRMD-AE",
    ". a neural network called MRMD-AE ( manifold-regularized multiple decoder, autoencoder ), that learns a common embedding from multiple subjects in an experiment while retaining the ability to decode to individual raw fMRI signals. This framework can be used for many downstream applications such as guided brain-computer interface ( BCI ) training in the future. In this paper, we propose a neural network called MRMD-AE",
    ". a neural network called MRMD-AE ( manifold-regularized multiple decoder, autoencoder ), that learns a common embedding from multiple subjects in an experiment while retaining the ability to decode to individual raw fMRI signals. This framework can be used for many downstream applications such as guided brain-computer interface ( BCI ) training in the future. In this paper, we propose a neural network called MRMD-AE",
    ". Large-scale datasets such as ImageNet and Places365 present unique challenges not seen in small-scale settings. As the community moves towards more realistic, large-scale settings, strong baselines and high-quality benchmarks are imperative for future progress. In this paper, we identify a detector based on the maximum logit ( MaxLogit ) that greatly outperforms the MSP in large-scale multi-class anomaly segmentation.",
    ". Large-scale datasets such as ImageNet and Places365 present unique challenges not seen in small-scale settings. As the community moves towards more realistic, large-scale settings, strong baselines and high-quality benchmarks are imperative for future progress. In this paper, we identify a detector based on the maximum logit ( MaxLogit ) that greatly outperforms the MSP in large-scale multi-class anomaly segmentation.",
    ". Large-scale datasets such as ImageNet and Places365 present unique challenges not seen in small-scale settings. As the community moves towards more realistic, large-scale settings, strong baselines and high-quality benchmarks are imperative for future progress. In this paper, we identify a detector based on the maximum logit ( MaxLogit ) that greatly outperforms the MSP in large-scale multi-class anomaly segmentation.",
    ". Large-scale datasets such as ImageNet and Places365 present unique challenges not seen in small-scale settings. As the community moves towards more realistic, large-scale settings, strong baselines and high-quality benchmarks are imperative for future progress. In this paper, we identify a detector based on the maximum logit ( MaxLogit ) that greatly outperforms the MSP in large-scale multi-class anomaly segmentation.",
    "a tournament T on n nodes can be represented in d dimensions if there exists a skew symmetric matrix M  Rnn of rank d. For any given tournament, we show a novel upper bound on the smallest representation dimension that depends on the least size of the number of unique nodes in any feedback arc set of the flip class associated with a tournament. To bridge the gap between the structural and the algebraic world, we ask and answer two fundamental questions regarding the",
    "a tournament T on n nodes can be represented in d dimensions if there exists a skew symmetric matrix M  Rnn of rank d. For any given tournament, we show a novel upper bound on the smallest representation dimension that depends on the least size of the number of unique nodes in any feedback arc set of the flip class associated with a tournament. To bridge the gap between the structural and the algebraic world, we ask and answer two fundamental questions regarding the",
    "a tournament T on n nodes can be represented in d dimensions if there exists a skew symmetric matrix M  Rnn of rank d. For any given tournament, we show a novel upper bound on the smallest representation dimension that depends on the least size of the number of unique nodes in any feedback arc set of the flip class associated with a tournament. To bridge the gap between the structural and the algebraic world, we ask and answer two fundamental questions regarding the",
    "a tournament T on n nodes can be represented in d dimensions if there exists a skew symmetric matrix M  Rnn of rank d. For any given tournament, we show a novel upper bound on the smallest representation dimension that depends on the least size of the number of unique nodes in any feedback arc set of the flip class associated with a tournament. To bridge the gap between the structural and the algebraic world, we ask and answer two fundamental questions regarding the",
    ". Bayesian aggregation satisfying permutation invariance enhanced the prediction accuracy by varying weights for individual context data points. For robustness under noisy situations, bootstrapping method was proposed to orthogonally apply to variants of NPs. In Figure 1a, the attentive neural process Kim et al. ( 2019 ) fails to capture contextual embedding. This manifests as inaccurate predictions at the locations of the context set as seen in Figure 1b.",
    ". Bayesian aggregation satisfying permutation invariance enhanced the prediction accuracy by varying weights for individual context data points. For robustness under noisy situations, bootstrapping method was proposed to orthogonally apply to variants of NPs. In Figure 1a, the attentive neural process Kim et al. ( 2019 ) fails to capture contextual embedding. This manifests as inaccurate predictions at the locations of the context set as seen in Figure 1b.",
    ". Bayesian aggregation satisfying permutation invariance enhanced the prediction accuracy by varying weights for individual context data points. For robustness under noisy situations, bootstrapping method was proposed to orthogonally apply to variants of NPs. In Figure 1a, the attentive neural process Kim et al. ( 2019 ) fails to capture contextual embedding. This manifests as inaccurate predictions at the locations of the context set as seen in Figure 1b.",
    ". Bayesian aggregation satisfying permutation invariance enhanced the prediction accuracy by varying weights for individual context data points. For robustness under noisy situations, bootstrapping method was proposed to orthogonally apply to variants of NPs. In Figure 1a, the attentive neural process Kim et al. ( 2019 ) fails to capture contextual embedding. This manifests as inaccurate predictions at the locations of the context set as seen in Figure 1b.",
    "post hoc explanations. In doing so, we avoid the problems mentioned above of post hoc explanations and help to reduce the issue of ( human ) bias. In doing so, we provide case-based explanations during the inference process. In doing so, we avoid the problems mentioned above of post hoc explanations and help to reduce the issue of ( human ) bias. To further enhance the prototypical network with human supervision, we propose a prototype layer and propose PrototypicalTrans",
    "post hoc explanations. In doing so, we avoid the problems mentioned above of post hoc explanations and help to reduce the issue of ( human ) bias. In doing so, we provide case-based explanations during the inference process. In doing so, we avoid the problems mentioned above of post hoc explanations and help to reduce the issue of ( human ) bias. To further enhance the prototypical network with human supervision, we propose a prototype layer and propose PrototypicalTrans",
    "post hoc explanations. In doing so, we avoid the problems mentioned above of post hoc explanations and help to reduce the issue of ( human ) bias. In doing so, we provide case-based explanations during the inference process. In doing so, we avoid the problems mentioned above of post hoc explanations and help to reduce the issue of ( human ) bias. To further enhance the prototypical network with human supervision, we propose a prototype layer and propose PrototypicalTrans",
    "post hoc explanations. In doing so, we avoid the problems mentioned above of post hoc explanations and help to reduce the issue of ( human ) bias. In doing so, we provide case-based explanations during the inference process. In doing so, we avoid the problems mentioned above of post hoc explanations and help to reduce the issue of ( human ) bias. To further enhance the prototypical network with human supervision, we propose a prototype layer and propose PrototypicalTrans",
    "expansion methods and non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non",
    "expansion methods and non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non",
    "expansion methods and non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non",
    "expansion methods and non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non-expansion methods. In order to understand the fundamental limit of a fixed capacity neural network, we focus on non",
    ". In this paper, we focus on general loss function conditions that induce interesting connections between optimization and generalization. In this paper, we study general loss function conditions that induce interesting connections between optimization and generalization. In this paper, we focus on general loss function conditions that induce interesting connections between optimization and generalization.",
    ". In this paper, we focus on general loss function conditions that induce interesting connections between optimization and generalization. In this paper, we study general loss function conditions that induce interesting connections between optimization and generalization. In this paper, we focus on general loss function conditions that induce interesting connections between optimization and generalization.",
    ". In this paper, we focus on general loss function conditions that induce interesting connections between optimization and generalization. In this paper, we study general loss function conditions that induce interesting connections between optimization and generalization. In this paper, we focus on general loss function conditions that induce interesting connections between optimization and generalization.",
    ". In this paper, we focus on general loss function conditions that induce interesting connections between optimization and generalization. In this paper, we study general loss function conditions that induce interesting connections between optimization and generalization. In this paper, we focus on general loss function conditions that induce interesting connections between optimization and generalization.",
    ", 2018 ),,,.. ( 2019 ) presented a feature-based analysis of adversarial examples. Jere et al. ( 2019 ) presented a feature-based analysis of adversarial examples. Despite the immense progress made by the field, there exist many unanswered questions and ambiguities regarding these methods and adversarial examples. In addition, there exists a thriving research corpus dedicated to",
    ", 2018 ),,,.. ( 2019 ) presented a feature-based analysis of adversarial examples. Jere et al. ( 2019 ) presented a feature-based analysis of adversarial examples. Despite the immense progress made by the field, there exist many unanswered questions and ambiguities regarding these methods and adversarial examples. In addition, there exists a thriving research corpus dedicated to",
    ", 2018 ),,,.. ( 2019 ) presented a feature-based analysis of adversarial examples. Jere et al. ( 2019 ) presented a feature-based analysis of adversarial examples. Despite the immense progress made by the field, there exist many unanswered questions and ambiguities regarding these methods and adversarial examples. In addition, there exists a thriving research corpus dedicated to",
    ", 2018 ),,,.. ( 2019 ) presented a feature-based analysis of adversarial examples. Jere et al. ( 2019 ) presented a feature-based analysis of adversarial examples. Despite the immense progress made by the field, there exist many unanswered questions and ambiguities regarding these methods and adversarial examples. In addition, there exists a thriving research corpus dedicated to",
    ".. 2 INTRODUCTION Deep neural networks ( NNs ) ( LeCun et al., 1998 ) have revolutionized many machine learning areas. Recently, numerous Graph Neural Networks ( GNNs ) have been proposed which empirically outperform traditional neural networks on graph-based machine learning tasks. In some cases, even simple Multi-Layer Perceptrons ( MLPs ) can outperform GNNs by a large margin",
    ".. 2 INTRODUCTION Deep neural networks ( NNs ) ( LeCun et al., 1998 ) have revolutionized many machine learning areas. Recently, numerous Graph Neural Networks ( GNNs ) have been proposed which empirically outperform traditional neural networks on graph-based machine learning tasks. In some cases, even simple Multi-Layer Perceptrons ( MLPs ) can outperform GNNs by a large margin",
    ".. 2 INTRODUCTION Deep neural networks ( NNs ) ( LeCun et al., 1998 ) have revolutionized many machine learning areas. Recently, numerous Graph Neural Networks ( GNNs ) have been proposed which empirically outperform traditional neural networks on graph-based machine learning tasks. In some cases, even simple Multi-Layer Perceptrons ( MLPs ) can outperform GNNs by a large margin",
    ".. 2 INTRODUCTION Deep neural networks ( NNs ) ( LeCun et al., 1998 ) have revolutionized many machine learning areas. Recently, numerous Graph Neural Networks ( GNNs ) have been proposed which empirically outperform traditional neural networks on graph-based machine learning tasks. In some cases, even simple Multi-Layer Perceptrons ( MLPs ) can outperform GNNs by a large margin",
    "large instances are not feasible. To overcome this limitation, this paper investigates techniques to increase the generalization capability of deep RL solvers. This approach is demonstrated on TSP problems. Since the computational cost of training on large instances is prohibitive, increasing the size of the training instances is not practical. To overcome this limitation, this paper investigates techniques to increase the generalization capability of deep RL solvers.",
    "large instances are not feasible. To overcome this limitation, this paper investigates techniques to increase the generalization capability of deep RL solvers. This approach is demonstrated on TSP problems. Since the computational cost of training on large instances is prohibitive, increasing the size of the training instances is not practical. To overcome this limitation, this paper investigates techniques to increase the generalization capability of deep RL solvers.",
    "large instances are not feasible. To overcome this limitation, this paper investigates techniques to increase the generalization capability of deep RL solvers. This approach is demonstrated on TSP problems. Since the computational cost of training on large instances is prohibitive, increasing the size of the training instances is not practical. To overcome this limitation, this paper investigates techniques to increase the generalization capability of deep RL solvers.",
    "large instances are not feasible. To overcome this limitation, this paper investigates techniques to increase the generalization capability of deep RL solvers. This approach is demonstrated on TSP problems. Since the computational cost of training on large instances is prohibitive, increasing the size of the training instances is not practical. To overcome this limitation, this paper investigates techniques to increase the generalization capability of deep RL solvers.",
    "( 2020 ) that adds a proximal term in the loss function to improve the statistical stability of the training process. Currently, federated learning ( FL ) offers a promising approach to collaboratively learn a global model without directly sharing the local data. Consequently, different clients learn from different data distributions. This leads to high heterogeneity among local models and degrades the effectiveness of model aggregation.",
    "( 2020 ) that adds a proximal term in the loss function to improve the statistical stability of the training process. Currently, federated learning ( FL ) offers a promising approach to collaboratively learn a global model without directly sharing the local data. Consequently, different clients learn from different data distributions. This leads to high heterogeneity among local models and degrades the effectiveness of model aggregation.",
    "( 2020 ) that adds a proximal term in the loss function to improve the statistical stability of the training process. Currently, federated learning ( FL ) offers a promising approach to collaboratively learn a global model without directly sharing the local data. Consequently, different clients learn from different data distributions. This leads to high heterogeneity among local models and degrades the effectiveness of model aggregation.",
    "( 2020 ) that adds a proximal term in the loss function to improve the statistical stability of the training process. Currently, federated learning ( FL ) offers a promising approach to collaboratively learn a global model without directly sharing the local data. Consequently, different clients learn from different data distributions. This leads to high heterogeneity among local models and degrades the effectiveness of model aggregation.",
    ". However, the vulnerability of adversarial examples is still one of the most significant aspects that reveals the gap between machine learning systems and humans. In response to this vulnerability, there have been significant efforts in building robust neural network based classifiers against adversarial examples. Randomized smoothing ( Lecuyer et al., 2019 ; Cohen et al., 2019 ; Zhang et al., 2020a ), which is largely based on",
    ". However, the vulnerability of adversarial examples is still one of the most significant aspects that reveals the gap between machine learning systems and humans. In response to this vulnerability, there have been significant efforts in building robust neural network based classifiers against adversarial examples. Randomized smoothing ( Lecuyer et al., 2019 ; Cohen et al., 2019 ; Zhang et al., 2020a ), which is largely based on",
    ". However, the vulnerability of adversarial examples is still one of the most significant aspects that reveals the gap between machine learning systems and humans. In response to this vulnerability, there have been significant efforts in building robust neural network based classifiers against adversarial examples. Randomized smoothing ( Lecuyer et al., 2019 ; Cohen et al., 2019 ; Zhang et al., 2020a ), which is largely based on",
    ". However, the vulnerability of adversarial examples is still one of the most significant aspects that reveals the gap between machine learning systems and humans. In response to this vulnerability, there have been significant efforts in building robust neural network based classifiers against adversarial examples. Randomized smoothing ( Lecuyer et al., 2019 ; Cohen et al., 2019 ; Zhang et al., 2020a ), which is largely based on",
    ". However, this dependence on pre-trained models limits the ability of researchers to explore new backbone architectures. Furthermore, it limits the extent to which practitioners in industry can adapt the model to their particular needs. In this paper, we present efficient methods to enable researchers to accelerate the pre-training of BERT by as much as 2x without loss of accuracy. While processing the padding tokens wastes compute, it is still the most standard approach for leveraging modern massively-parallel compute",
    ". However, this dependence on pre-trained models limits the ability of researchers to explore new backbone architectures. Furthermore, it limits the extent to which practitioners in industry can adapt the model to their particular needs. In this paper, we present efficient methods to enable researchers to accelerate the pre-training of BERT by as much as 2x without loss of accuracy. While processing the padding tokens wastes compute, it is still the most standard approach for leveraging modern massively-parallel compute",
    ". However, this dependence on pre-trained models limits the ability of researchers to explore new backbone architectures. Furthermore, it limits the extent to which practitioners in industry can adapt the model to their particular needs. In this paper, we present efficient methods to enable researchers to accelerate the pre-training of BERT by as much as 2x without loss of accuracy. While processing the padding tokens wastes compute, it is still the most standard approach for leveraging modern massively-parallel compute",
    ". However, this dependence on pre-trained models limits the ability of researchers to explore new backbone architectures. Furthermore, it limits the extent to which practitioners in industry can adapt the model to their particular needs. In this paper, we present efficient methods to enable researchers to accelerate the pre-training of BERT by as much as 2x without loss of accuracy. While processing the padding tokens wastes compute, it is still the most standard approach for leveraging modern massively-parallel compute",
    "a search component that interacts with the model in order to find an output that maximizes the score assigned by the model. This search problem is a hard combinatorial optimization problem. Work carried out while Wang Ling was at DeepMind. Work carried out while Wang Ling was at DeepMind. Authors contributed equally. Work carried out while Wang Ling was at DeepMind. Work carried out while Wang Ling was at DeepMind",
    "a search component that interacts with the model in order to find an output that maximizes the score assigned by the model. This search problem is a hard combinatorial optimization problem. Work carried out while Wang Ling was at DeepMind. Work carried out while Wang Ling was at DeepMind. Authors contributed equally. Work carried out while Wang Ling was at DeepMind. Work carried out while Wang Ling was at DeepMind",
    "a search component that interacts with the model in order to find an output that maximizes the score assigned by the model. This search problem is a hard combinatorial optimization problem. Work carried out while Wang Ling was at DeepMind. Work carried out while Wang Ling was at DeepMind. Authors contributed equally. Work carried out while Wang Ling was at DeepMind. Work carried out while Wang Ling was at DeepMind",
    "a search component that interacts with the model in order to find an output that maximizes the score assigned by the model. This search problem is a hard combinatorial optimization problem. Work carried out while Wang Ling was at DeepMind. Work carried out while Wang Ling was at DeepMind. Authors contributed equally. Work carried out while Wang Ling was at DeepMind. Work carried out while Wang Ling was at DeepMind",
    "an approach for detecting anomaly in images. In this paper, we have carefully designed steps to handle some of the bigger issues that have prevented the deployment of image anomaly detection in the real-world. In this paper, we propose an approach for detecting anomaly in images. We are interested in designing an anomaly detection algorithm. We are interested in detecting anomaly in images. We are interested in detecting anomaly in images. We are interested in detecting anomaly in images.",
    "an approach for detecting anomaly in images. In this paper, we have carefully designed steps to handle some of the bigger issues that have prevented the deployment of image anomaly detection in the real-world. In this paper, we propose an approach for detecting anomaly in images. We are interested in designing an anomaly detection algorithm. We are interested in detecting anomaly in images. We are interested in detecting anomaly in images. We are interested in detecting anomaly in images.",
    "an approach for detecting anomaly in images. In this paper, we have carefully designed steps to handle some of the bigger issues that have prevented the deployment of image anomaly detection in the real-world. In this paper, we propose an approach for detecting anomaly in images. We are interested in designing an anomaly detection algorithm. We are interested in detecting anomaly in images. We are interested in detecting anomaly in images. We are interested in detecting anomaly in images.",
    "an approach for detecting anomaly in images. In this paper, we have carefully designed steps to handle some of the bigger issues that have prevented the deployment of image anomaly detection in the real-world. In this paper, we propose an approach for detecting anomaly in images. We are interested in designing an anomaly detection algorithm. We are interested in detecting anomaly in images. We are interested in detecting anomaly in images. We are interested in detecting anomaly in images.",
    "real-world QA is tainted with misinformation. This includes unintentional factual mistakes made by human writers and deliberate disinformation intended to deceive. Aside from human-created misinformation, we are also facing the inevitability of AI-generated misinformation. We seek to study risks of misinformation to QA models by investigating how QA models behave under the more realistic case of contradicting contexts.",
    "real-world QA is tainted with misinformation. This includes unintentional factual mistakes made by human writers and deliberate disinformation intended to deceive. Aside from human-created misinformation, we are also facing the inevitability of AI-generated misinformation. We seek to study risks of misinformation to QA models by investigating how QA models behave under the more realistic case of contradicting contexts.",
    "real-world QA is tainted with misinformation. This includes unintentional factual mistakes made by human writers and deliberate disinformation intended to deceive. Aside from human-created misinformation, we are also facing the inevitability of AI-generated misinformation. We seek to study risks of misinformation to QA models by investigating how QA models behave under the more realistic case of contradicting contexts.",
    "real-world QA is tainted with misinformation. This includes unintentional factual mistakes made by human writers and deliberate disinformation intended to deceive. Aside from human-created misinformation, we are also facing the inevitability of AI-generated misinformation. We seek to study risks of misinformation to QA models by investigating how QA models behave under the more realistic case of contradicting contexts.",
    "to provide expert demonstrations. Yet for many real-world tasks, designing informative rewards requires significant engineering effort. To alleviate this effort, imitation learning ( IL ) proposes to learn directly from expert demonstrations. Indeed, not requiring expert demonstrations would enable agents to imitate humans and robots with different morphologies. Thus, if we relax the constraining setting of current RL methods, then natural imitation scenarios that alleviate engineering effort appear.",
    "to provide expert demonstrations. Yet for many real-world tasks, designing informative rewards requires significant engineering effort. To alleviate this effort, imitation learning ( IL ) proposes to learn directly from expert demonstrations. Indeed, not requiring expert demonstrations would enable agents to imitate humans and robots with different morphologies. Thus, if we relax the constraining setting of current RL methods, then natural imitation scenarios that alleviate engineering effort appear.",
    "to provide expert demonstrations. Yet for many real-world tasks, designing informative rewards requires significant engineering effort. To alleviate this effort, imitation learning ( IL ) proposes to learn directly from expert demonstrations. Indeed, not requiring expert demonstrations would enable agents to imitate humans and robots with different morphologies. Thus, if we relax the constraining setting of current RL methods, then natural imitation scenarios that alleviate engineering effort appear.",
    "to provide expert demonstrations. Yet for many real-world tasks, designing informative rewards requires significant engineering effort. To alleviate this effort, imitation learning ( IL ) proposes to learn directly from expert demonstrations. Indeed, not requiring expert demonstrations would enable agents to imitate humans and robots with different morphologies. Thus, if we relax the constraining setting of current RL methods, then natural imitation scenarios that alleviate engineering effort appear.",
    ". In contrastive learning, the representation invariant is measured by a contrastive loss. This compares one of the network outputs after the projection head to its augmented version. In contrastive learning, the representation invariant is measured by a contrastive loss. In contrastive learning, the representation invariant is measured by a contrastive loss in the intermediate layers of projection heads. In contrastive learning, the representation invariant is measured by a contrastive loss",
    ". In contrastive learning, the representation invariant is measured by a contrastive loss. This compares one of the network outputs after the projection head to its augmented version. In contrastive learning, the representation invariant is measured by a contrastive loss. In contrastive learning, the representation invariant is measured by a contrastive loss in the intermediate layers of projection heads. In contrastive learning, the representation invariant is measured by a contrastive loss",
    ". In contrastive learning, the representation invariant is measured by a contrastive loss. This compares one of the network outputs after the projection head to its augmented version. In contrastive learning, the representation invariant is measured by a contrastive loss. In contrastive learning, the representation invariant is measured by a contrastive loss in the intermediate layers of projection heads. In contrastive learning, the representation invariant is measured by a contrastive loss",
    ". In contrastive learning, the representation invariant is measured by a contrastive loss. This compares one of the network outputs after the projection head to its augmented version. In contrastive learning, the representation invariant is measured by a contrastive loss. In contrastive learning, the representation invariant is measured by a contrastive loss in the intermediate layers of projection heads. In contrastive learning, the representation invariant is measured by a contrastive loss",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    ". Model extraction attacks can be categorized as active, passive, or reactive. Active defenses perturb the outputs to poison the training objective of an attacker ( Orekondy et al., 2016 ). Passive defenses try to detect an attack ( Orekondy et al., 2016b ). Reactive defenses address model extraction post hoc, i.e., after the attack has been completed.",
    ". Model extraction attacks can be categorized as active, passive, or reactive. Active defenses perturb the outputs to poison the training objective of an attacker ( Orekondy et al., 2016 ). Passive defenses try to detect an attack ( Orekondy et al., 2016b ). Reactive defenses address model extraction post hoc, i.e., after the attack has been completed.",
    ". Model extraction attacks can be categorized as active, passive, or reactive. Active defenses perturb the outputs to poison the training objective of an attacker ( Orekondy et al., 2016 ). Passive defenses try to detect an attack ( Orekondy et al., 2016b ). Reactive defenses address model extraction post hoc, i.e., after the attack has been completed.",
    ". Model extraction attacks can be categorized as active, passive, or reactive. Active defenses perturb the outputs to poison the training objective of an attacker ( Orekondy et al., 2016 ). Passive defenses try to detect an attack ( Orekondy et al., 2016b ). Reactive defenses address model extraction post hoc, i.e., after the attack has been completed.",
    ". A change of variables approach facilitates the transformation of a simple base probability distribution into a more complex model distribution. CNFs have been shown to be capable of modelling complex distributions such as those associated with images. GANs are known to suffer from mode-collapse ( Lin et al., 2017 ), and are notoriously difficult to train compared to VAEs. Moreover, GANs are known to suffer from mode-collapse because their adversarial loss",
    ". A change of variables approach facilitates the transformation of a simple base probability distribution into a more complex model distribution. CNFs have been shown to be capable of modelling complex distributions such as those associated with images. GANs are known to suffer from mode-collapse ( Lin et al., 2017 ), and are notoriously difficult to train compared to VAEs. Moreover, GANs are known to suffer from mode-collapse because their adversarial loss",
    ". A change of variables approach facilitates the transformation of a simple base probability distribution into a more complex model distribution. CNFs have been shown to be capable of modelling complex distributions such as those associated with images. GANs are known to suffer from mode-collapse ( Lin et al., 2017 ), and are notoriously difficult to train compared to VAEs. Moreover, GANs are known to suffer from mode-collapse because their adversarial loss",
    ". A change of variables approach facilitates the transformation of a simple base probability distribution into a more complex model distribution. CNFs have been shown to be capable of modelling complex distributions such as those associated with images. GANs are known to suffer from mode-collapse ( Lin et al., 2017 ), and are notoriously difficult to train compared to VAEs. Moreover, GANs are known to suffer from mode-collapse because their adversarial loss",
    ". Label errors, a.k.a., corrupted instances, tend to be harder to be learned by DNNs than clean instances. The above methods suffer from two major limitations : 1 ) the customized training processes are task-specific and may require fine-tuning hyperparameters for different datasets/noise ; 2 ) the model is trained with noisy supervisions and then makes decisions based on the output ( Northcutt et al., 20",
    ". Label errors, a.k.a., corrupted instances, tend to be harder to be learned by DNNs than clean instances. The above methods suffer from two major limitations : 1 ) the customized training processes are task-specific and may require fine-tuning hyperparameters for different datasets/noise ; 2 ) the model is trained with noisy supervisions and then makes decisions based on the output ( Northcutt et al., 20",
    ". Label errors, a.k.a., corrupted instances, tend to be harder to be learned by DNNs than clean instances. The above methods suffer from two major limitations : 1 ) the customized training processes are task-specific and may require fine-tuning hyperparameters for different datasets/noise ; 2 ) the model is trained with noisy supervisions and then makes decisions based on the output ( Northcutt et al., 20",
    ". Label errors, a.k.a., corrupted instances, tend to be harder to be learned by DNNs than clean instances. The above methods suffer from two major limitations : 1 ) the customized training processes are task-specific and may require fine-tuning hyperparameters for different datasets/noise ; 2 ) the model is trained with noisy supervisions and then makes decisions based on the output ( Northcutt et al., 20",
    "strongest adversary can strategically \u201c lead \u201d the agent to a trap, which is the worst event for the agent. Figure 1 shows an intuitive example, where the strongest adversary only prevents the agent from selecting the best action in the current step. Figure 2 shows an intuitive example, where the strongest adversary can strategically \u201c lead \u201d the agent to a trap. Figure 3 shows an intuitive example, where the strongest adversary can strategically \u201c lead \u201d the agent to a trap, which is the",
    "strongest adversary can strategically \u201c lead \u201d the agent to a trap, which is the worst event for the agent. Figure 1 shows an intuitive example, where the strongest adversary only prevents the agent from selecting the best action in the current step. Figure 2 shows an intuitive example, where the strongest adversary can strategically \u201c lead \u201d the agent to a trap. Figure 3 shows an intuitive example, where the strongest adversary can strategically \u201c lead \u201d the agent to a trap, which is the",
    "strongest adversary can strategically \u201c lead \u201d the agent to a trap, which is the worst event for the agent. Figure 1 shows an intuitive example, where the strongest adversary only prevents the agent from selecting the best action in the current step. Figure 2 shows an intuitive example, where the strongest adversary can strategically \u201c lead \u201d the agent to a trap. Figure 3 shows an intuitive example, where the strongest adversary can strategically \u201c lead \u201d the agent to a trap, which is the",
    "strongest adversary can strategically \u201c lead \u201d the agent to a trap, which is the worst event for the agent. Figure 1 shows an intuitive example, where the strongest adversary only prevents the agent from selecting the best action in the current step. Figure 2 shows an intuitive example, where the strongest adversary can strategically \u201c lead \u201d the agent to a trap. Figure 3 shows an intuitive example, where the strongest adversary can strategically \u201c lead \u201d the agent to a trap, which is the",
    "the scheme of reinforcement learning ( RL ) is conceptually similar to the emergence of intelligence ( Sutton et al., 1998 ). In the sense of learning through interactions with the environment, the scheme of reinforcement learning ( RL ) is conceptually similar to the emergence of intelligence ( Sutton et al., 1998 ). However, the task of encouraging individualized diversity 2 of learned agents is relatively under-explored.",
    "the scheme of reinforcement learning ( RL ) is conceptually similar to the emergence of intelligence ( Sutton et al., 1998 ). In the sense of learning through interactions with the environment, the scheme of reinforcement learning ( RL ) is conceptually similar to the emergence of intelligence ( Sutton et al., 1998 ). However, the task of encouraging individualized diversity 2 of learned agents is relatively under-explored.",
    "the scheme of reinforcement learning ( RL ) is conceptually similar to the emergence of intelligence ( Sutton et al., 1998 ). In the sense of learning through interactions with the environment, the scheme of reinforcement learning ( RL ) is conceptually similar to the emergence of intelligence ( Sutton et al., 1998 ). However, the task of encouraging individualized diversity 2 of learned agents is relatively under-explored.",
    "the scheme of reinforcement learning ( RL ) is conceptually similar to the emergence of intelligence ( Sutton et al., 1998 ). In the sense of learning through interactions with the environment, the scheme of reinforcement learning ( RL ) is conceptually similar to the emergence of intelligence ( Sutton et al., 1998 ). However, the task of encouraging individualized diversity 2 of learned agents is relatively under-explored.",
    ", 2019 ; Wu et al., 2016 ; Zhao et al., 2019b ). Speech dereverberation is one of the most important tasks in speech enhancement, recognition, and other downstream tasks. In particular, the quality of human speech is greatly affected when given reverberant speech input. This underconstrains the dereverberation task since the latent parameters of the recording space are not discernable from the audio alone. Thus,",
    ", 2019 ; Wu et al., 2016 ; Zhao et al., 2019b ). Speech dereverberation is one of the most important tasks in speech enhancement, recognition, and other downstream tasks. In particular, the quality of human speech is greatly affected when given reverberant speech input. This underconstrains the dereverberation task since the latent parameters of the recording space are not discernable from the audio alone. Thus,",
    ", 2019 ; Wu et al., 2016 ; Zhao et al., 2019b ). Speech dereverberation is one of the most important tasks in speech enhancement, recognition, and other downstream tasks. In particular, the quality of human speech is greatly affected when given reverberant speech input. This underconstrains the dereverberation task since the latent parameters of the recording space are not discernable from the audio alone. Thus,",
    ", 2019 ; Wu et al., 2016 ; Zhao et al., 2019b ). Speech dereverberation is one of the most important tasks in speech enhancement, recognition, and other downstream tasks. In particular, the quality of human speech is greatly affected when given reverberant speech input. This underconstrains the dereverberation task since the latent parameters of the recording space are not discernable from the audio alone. Thus,",
    "a transformer-based language model was introduced by Vaswani et al. ( 2017 ). they speculated that it \u201c may [... ] extrapolate to sequence lengths longer than the ones encountered during training. but the transformer model has not yet been able to achieve extrapolation. we introduce a simpler and more efficient position method, Attention with Linear Biases ( ALiBi ). ALiBi biases query-key attention scores with a",
    "a transformer-based language model was introduced by Vaswani et al. ( 2017 ). they speculated that it \u201c may [... ] extrapolate to sequence lengths longer than the ones encountered during training. but the transformer model has not yet been able to achieve extrapolation. we introduce a simpler and more efficient position method, Attention with Linear Biases ( ALiBi ). ALiBi biases query-key attention scores with a",
    "a transformer-based language model was introduced by Vaswani et al. ( 2017 ). they speculated that it \u201c may [... ] extrapolate to sequence lengths longer than the ones encountered during training. but the transformer model has not yet been able to achieve extrapolation. we introduce a simpler and more efficient position method, Attention with Linear Biases ( ALiBi ). ALiBi biases query-key attention scores with a",
    "a transformer-based language model was introduced by Vaswani et al. ( 2017 ). they speculated that it \u201c may [... ] extrapolate to sequence lengths longer than the ones encountered during training. but the transformer model has not yet been able to achieve extrapolation. we introduce a simpler and more efficient position method, Attention with Linear Biases ( ALiBi ). ALiBi biases query-key attention scores with a",
    ". However, in many real-world machine learning applications, we are often required to optimize multiple conflicting objectives simultaneously. For example, in autonomous driving ( Ma et al., 2018a ; b ), the advertiser needs to learn to solve multiple tasks such as self-localization and object identification at the same time. In many real-world machine learning applications, we are often required to optimize multiple conflicting objectives simultaneously. Recently, the first-order gradient-based",
    ". However, in many real-world machine learning applications, we are often required to optimize multiple conflicting objectives simultaneously. For example, in autonomous driving ( Ma et al., 2018a ; b ), the advertiser needs to learn to solve multiple tasks such as self-localization and object identification at the same time. In many real-world machine learning applications, we are often required to optimize multiple conflicting objectives simultaneously. Recently, the first-order gradient-based",
    ". However, in many real-world machine learning applications, we are often required to optimize multiple conflicting objectives simultaneously. For example, in autonomous driving ( Ma et al., 2018a ; b ), the advertiser needs to learn to solve multiple tasks such as self-localization and object identification at the same time. In many real-world machine learning applications, we are often required to optimize multiple conflicting objectives simultaneously. Recently, the first-order gradient-based",
    ". However, in many real-world machine learning applications, we are often required to optimize multiple conflicting objectives simultaneously. For example, in autonomous driving ( Ma et al., 2018a ; b ), the advertiser needs to learn to solve multiple tasks such as self-localization and object identification at the same time. In many real-world machine learning applications, we are often required to optimize multiple conflicting objectives simultaneously. Recently, the first-order gradient-based",
    ". Besides solving the replay memory issue, generative replay has been recently explored. Besides solving the replay memory issue, generative replay introduces much complexity due to the need for an interleaved incremental training of both a classifier and a generator. Moreover, generative replay introduces much complexity due to the need for an interleaved incremental training of both a classifier and a generator. Moreover, generative replay introduces much complexity due to the in",
    ". Besides solving the replay memory issue, generative replay has been recently explored. Besides solving the replay memory issue, generative replay introduces much complexity due to the need for an interleaved incremental training of both a classifier and a generator. Moreover, generative replay introduces much complexity due to the need for an interleaved incremental training of both a classifier and a generator. Moreover, generative replay introduces much complexity due to the in",
    ". Besides solving the replay memory issue, generative replay has been recently explored. Besides solving the replay memory issue, generative replay introduces much complexity due to the need for an interleaved incremental training of both a classifier and a generator. Moreover, generative replay introduces much complexity due to the need for an interleaved incremental training of both a classifier and a generator. Moreover, generative replay introduces much complexity due to the in",
    ". Besides solving the replay memory issue, generative replay has been recently explored. Besides solving the replay memory issue, generative replay introduces much complexity due to the need for an interleaved incremental training of both a classifier and a generator. Moreover, generative replay introduces much complexity due to the need for an interleaved incremental training of both a classifier and a generator. Moreover, generative replay introduces much complexity due to the in",
    ". Graph partitioning ( GP ) is a classic inference task to describe the entities and their relations using a set of nodes and edges. Due to the NP-hardness, to balance the quality and efficiency of GP remains a challenge. On the other hand, prior work has demonstrated the ability of machine learning ( ML ) techniques to achieve high GP quality. Graph embedding emerges as a promising technique for GP in recent studies.",
    ". Graph partitioning ( GP ) is a classic inference task to describe the entities and their relations using a set of nodes and edges. Due to the NP-hardness, to balance the quality and efficiency of GP remains a challenge. On the other hand, prior work has demonstrated the ability of machine learning ( ML ) techniques to achieve high GP quality. Graph embedding emerges as a promising technique for GP in recent studies.",
    ". Graph partitioning ( GP ) is a classic inference task to describe the entities and their relations using a set of nodes and edges. Due to the NP-hardness, to balance the quality and efficiency of GP remains a challenge. On the other hand, prior work has demonstrated the ability of machine learning ( ML ) techniques to achieve high GP quality. Graph embedding emerges as a promising technique for GP in recent studies.",
    ". Graph partitioning ( GP ) is a classic inference task to describe the entities and their relations using a set of nodes and edges. Due to the NP-hardness, to balance the quality and efficiency of GP remains a challenge. On the other hand, prior work has demonstrated the ability of machine learning ( ML ) techniques to achieve high GP quality. Graph embedding emerges as a promising technique for GP in recent studies.",
    ", 2018 ), and protein interface prediction ( Xu et al., 2019 ). Graph neural networks ( GNNs ) have been widely applied to many learning tasks. Graph neural networks ( GNNs ) are based on the concept of convolution to graphs. While this approach is effective in some settings, it is based on soft assigment matrices. ( c ) the algorithm isn \u2019 t able to",
    ", 2018 ), and protein interface prediction ( Xu et al., 2019 ). Graph neural networks ( GNNs ) have been widely applied to many learning tasks. Graph neural networks ( GNNs ) are based on the concept of convolution to graphs. While this approach is effective in some settings, it is based on soft assigment matrices. ( c ) the algorithm isn \u2019 t able to",
    ", 2018 ), and protein interface prediction ( Xu et al., 2019 ). Graph neural networks ( GNNs ) have been widely applied to many learning tasks. Graph neural networks ( GNNs ) are based on the concept of convolution to graphs. While this approach is effective in some settings, it is based on soft assigment matrices. ( c ) the algorithm isn \u2019 t able to",
    ", 2018 ), and protein interface prediction ( Xu et al., 2019 ). Graph neural networks ( GNNs ) have been widely applied to many learning tasks. Graph neural networks ( GNNs ) are based on the concept of convolution to graphs. While this approach is effective in some settings, it is based on soft assigment matrices. ( c ) the algorithm isn \u2019 t able to",
    "nonlinear ICA is a fundamental problem in machine learning. It aims to identify the underlying independent components ( sources ) from data which is assumed to be a nonlinear function ( mixing function ) of these sources. However, in many cases such restrictions on the sources are difficult to satisfy or even verify. Moreover, results on real-world images indicate that our framework can disentangle interpretable features. 1 INTRODUCTION. Nonlinear ICA is a fundamental",
    "nonlinear ICA is a fundamental problem in machine learning. It aims to identify the underlying independent components ( sources ) from data which is assumed to be a nonlinear function ( mixing function ) of these sources. However, in many cases such restrictions on the sources are difficult to satisfy or even verify. Moreover, results on real-world images indicate that our framework can disentangle interpretable features. 1 INTRODUCTION. Nonlinear ICA is a fundamental",
    "nonlinear ICA is a fundamental problem in machine learning. It aims to identify the underlying independent components ( sources ) from data which is assumed to be a nonlinear function ( mixing function ) of these sources. However, in many cases such restrictions on the sources are difficult to satisfy or even verify. Moreover, results on real-world images indicate that our framework can disentangle interpretable features. 1 INTRODUCTION. Nonlinear ICA is a fundamental",
    "nonlinear ICA is a fundamental problem in machine learning. It aims to identify the underlying independent components ( sources ) from data which is assumed to be a nonlinear function ( mixing function ) of these sources. However, in many cases such restrictions on the sources are difficult to satisfy or even verify. Moreover, results on real-world images indicate that our framework can disentangle interpretable features. 1 INTRODUCTION. Nonlinear ICA is a fundamental",
    ". In addition, a collection of graph convolutional networks ( GCNs ), including MPGCNs and spectral GCNs, have been proposed by generalizing architectures used for data in the Euclidean domain, to the irregular graphs. However, both types of architectures have implicit limitations when it comes to efficiently representing graph data information. MPGCNs ( Gilmer et al., 2017 ; Velikovi et al.",
    ". In addition, a collection of graph convolutional networks ( GCNs ), including MPGCNs and spectral GCNs, have been proposed by generalizing architectures used for data in the Euclidean domain, to the irregular graphs. However, both types of architectures have implicit limitations when it comes to efficiently representing graph data information. MPGCNs ( Gilmer et al., 2017 ; Velikovi et al.",
    ". In addition, a collection of graph convolutional networks ( GCNs ), including MPGCNs and spectral GCNs, have been proposed by generalizing architectures used for data in the Euclidean domain, to the irregular graphs. However, both types of architectures have implicit limitations when it comes to efficiently representing graph data information. MPGCNs ( Gilmer et al., 2017 ; Velikovi et al.",
    ". In addition, a collection of graph convolutional networks ( GCNs ), including MPGCNs and spectral GCNs, have been proposed by generalizing architectures used for data in the Euclidean domain, to the irregular graphs. However, both types of architectures have implicit limitations when it comes to efficiently representing graph data information. MPGCNs ( Gilmer et al., 2017 ; Velikovi et al.",
    "supervised pre-training. Self-supervised pre-training has been widely applied in applications of deep learning ( Tan et al., 2018 ). Unlike supervised pre-training, self-supervised pre-training is mainly based on instance discrimination. It effectively captures many important and discriminative features that are useful for downstream tasks. However, without appropriate guidance of supervision information, self-supervised pre-training lacks the ability to learn effective representation from upstream datasets.",
    "supervised pre-training. Self-supervised pre-training has been widely applied in applications of deep learning ( Tan et al., 2018 ). Unlike supervised pre-training, self-supervised pre-training is mainly based on instance discrimination. It effectively captures many important and discriminative features that are useful for downstream tasks. However, without appropriate guidance of supervision information, self-supervised pre-training lacks the ability to learn effective representation from upstream datasets.",
    "supervised pre-training. Self-supervised pre-training has been widely applied in applications of deep learning ( Tan et al., 2018 ). Unlike supervised pre-training, self-supervised pre-training is mainly based on instance discrimination. It effectively captures many important and discriminative features that are useful for downstream tasks. However, without appropriate guidance of supervision information, self-supervised pre-training lacks the ability to learn effective representation from upstream datasets.",
    "supervised pre-training. Self-supervised pre-training has been widely applied in applications of deep learning ( Tan et al., 2018 ). Unlike supervised pre-training, self-supervised pre-training is mainly based on instance discrimination. It effectively captures many important and discriminative features that are useful for downstream tasks. However, without appropriate guidance of supervision information, self-supervised pre-training lacks the ability to learn effective representation from upstream datasets.",
    ". However, despite using more expressive shape and expression spaces, these models still fail to capture fine details in geometry. Recent methods that accurately estimate facial geometric details from single images ( Chen et al., 2019 ; 2018 ; Tun Trn et al., 2018 ; Tran et al., 2019 ), while being unable to hallucinate and photo-realistically render novel details under expression change. Thus, it is now possible to",
    ". However, despite using more expressive shape and expression spaces, these models still fail to capture fine details in geometry. Recent methods that accurately estimate facial geometric details from single images ( Chen et al., 2019 ; 2018 ; Tun Trn et al., 2018 ; Tran et al., 2019 ), while being unable to hallucinate and photo-realistically render novel details under expression change. Thus, it is now possible to",
    ". However, despite using more expressive shape and expression spaces, these models still fail to capture fine details in geometry. Recent methods that accurately estimate facial geometric details from single images ( Chen et al., 2019 ; 2018 ; Tun Trn et al., 2018 ; Tran et al., 2019 ), while being unable to hallucinate and photo-realistically render novel details under expression change. Thus, it is now possible to",
    ". However, despite using more expressive shape and expression spaces, these models still fail to capture fine details in geometry. Recent methods that accurately estimate facial geometric details from single images ( Chen et al., 2019 ; 2018 ; Tun Trn et al., 2018 ; Tran et al., 2019 ), while being unable to hallucinate and photo-realistically render novel details under expression change. Thus, it is now possible to",
    ". We show in our work that the information in the content itself can be separated with a VAE-based model. This separation provides better transparency, but also better transfer performance. Our framework includes a model and an evaluation protocol aimed at measuring the disentanglement of syntactic roles. In our work, we demonstrate that the information in the content itself can be separated with a VAE-based model.",
    ". We show in our work that the information in the content itself can be separated with a VAE-based model. This separation provides better transparency, but also better transfer performance. Our framework includes a model and an evaluation protocol aimed at measuring the disentanglement of syntactic roles. In our work, we demonstrate that the information in the content itself can be separated with a VAE-based model.",
    ". We show in our work that the information in the content itself can be separated with a VAE-based model. This separation provides better transparency, but also better transfer performance. Our framework includes a model and an evaluation protocol aimed at measuring the disentanglement of syntactic roles. In our work, we demonstrate that the information in the content itself can be separated with a VAE-based model.",
    ". We show in our work that the information in the content itself can be separated with a VAE-based model. This separation provides better transparency, but also better transfer performance. Our framework includes a model and an evaluation protocol aimed at measuring the disentanglement of syntactic roles. In our work, we demonstrate that the information in the content itself can be separated with a VAE-based model.",
    "agents with coordinated behaviors learn remarkably faster ( Roy et al., 2019 ). Deep Reinforcement Learning ( DRL ) has been applied to solve various challenging problems. Multi-Agent Reinforcement Learning ( MARL ) refers to the task of training a set of agents to maximize collective and/or individual rewards. Recent works have shown that agents with coordinated behaviors learn remarkably faster ( Roy et al., 2019 ) since coordination helps the discovery of effective policies",
    "agents with coordinated behaviors learn remarkably faster ( Roy et al., 2019 ). Deep Reinforcement Learning ( DRL ) has been applied to solve various challenging problems. Multi-Agent Reinforcement Learning ( MARL ) refers to the task of training a set of agents to maximize collective and/or individual rewards. Recent works have shown that agents with coordinated behaviors learn remarkably faster ( Roy et al., 2019 ) since coordination helps the discovery of effective policies",
    "agents with coordinated behaviors learn remarkably faster ( Roy et al., 2019 ). Deep Reinforcement Learning ( DRL ) has been applied to solve various challenging problems. Multi-Agent Reinforcement Learning ( MARL ) refers to the task of training a set of agents to maximize collective and/or individual rewards. Recent works have shown that agents with coordinated behaviors learn remarkably faster ( Roy et al., 2019 ) since coordination helps the discovery of effective policies",
    "agents with coordinated behaviors learn remarkably faster ( Roy et al., 2019 ). Deep Reinforcement Learning ( DRL ) has been applied to solve various challenging problems. Multi-Agent Reinforcement Learning ( MARL ) refers to the task of training a set of agents to maximize collective and/or individual rewards. Recent works have shown that agents with coordinated behaviors learn remarkably faster ( Roy et al., 2019 ) since coordination helps the discovery of effective policies",
    "; for an example with a real T5 model ( Raffel et al., 2020 ), see Table 2 ). When a large neural network produces an undesirable output, making a localized update to correct its behavior is non-trivial. This overfitting leads to failures of locality and generality.",
    "; for an example with a real T5 model ( Raffel et al., 2020 ), see Table 2 ). When a large neural network produces an undesirable output, making a localized update to correct its behavior is non-trivial. This overfitting leads to failures of locality and generality.",
    "; for an example with a real T5 model ( Raffel et al., 2020 ), see Table 2 ). When a large neural network produces an undesirable output, making a localized update to correct its behavior is non-trivial. This overfitting leads to failures of locality and generality.",
    "; for an example with a real T5 model ( Raffel et al., 2020 ), see Table 2 ). When a large neural network produces an undesirable output, making a localized update to correct its behavior is non-trivial. This overfitting leads to failures of locality and generality.",
    ". Inductive biases limit the space of possible models by reducing the opportunities for computational shortcuts. In this work, we present the finite volume neural network ( FINN ) model\u2014a physics-aware neural network structure adhering to the idea of spatial and temporal discretization in numerical simulation. FINN consists of multiple neural network modules that interact in a distributed, compositional manner. This modularization allows to combine two advantages that are not yet met by state-of",
    ". Inductive biases limit the space of possible models by reducing the opportunities for computational shortcuts. In this work, we present the finite volume neural network ( FINN ) model\u2014a physics-aware neural network structure adhering to the idea of spatial and temporal discretization in numerical simulation. FINN consists of multiple neural network modules that interact in a distributed, compositional manner. This modularization allows to combine two advantages that are not yet met by state-of",
    ". Inductive biases limit the space of possible models by reducing the opportunities for computational shortcuts. In this work, we present the finite volume neural network ( FINN ) model\u2014a physics-aware neural network structure adhering to the idea of spatial and temporal discretization in numerical simulation. FINN consists of multiple neural network modules that interact in a distributed, compositional manner. This modularization allows to combine two advantages that are not yet met by state-of",
    ". Inductive biases limit the space of possible models by reducing the opportunities for computational shortcuts. In this work, we present the finite volume neural network ( FINN ) model\u2014a physics-aware neural network structure adhering to the idea of spatial and temporal discretization in numerical simulation. FINN consists of multiple neural network modules that interact in a distributed, compositional manner. This modularization allows to combine two advantages that are not yet met by state-of",
    ". Do these regions encode specific syntactic or semantic code properties? Further, are different regions involved in encoding different such properties? To date, no systematic method exists to generate the evidence from which to draw answers. A question of interest, as yet uninvestigated, is what aspects of computer programs, i.e. code, are encoded in brain activity patterns when code is comprehended.",
    ". Do these regions encode specific syntactic or semantic code properties? Further, are different regions involved in encoding different such properties? To date, no systematic method exists to generate the evidence from which to draw answers. A question of interest, as yet uninvestigated, is what aspects of computer programs, i.e. code, are encoded in brain activity patterns when code is comprehended.",
    ". Do these regions encode specific syntactic or semantic code properties? Further, are different regions involved in encoding different such properties? To date, no systematic method exists to generate the evidence from which to draw answers. A question of interest, as yet uninvestigated, is what aspects of computer programs, i.e. code, are encoded in brain activity patterns when code is comprehended.",
    ". Do these regions encode specific syntactic or semantic code properties? Further, are different regions involved in encoding different such properties? To date, no systematic method exists to generate the evidence from which to draw answers. A question of interest, as yet uninvestigated, is what aspects of computer programs, i.e. code, are encoded in brain activity patterns when code is comprehended.",
    ". Compared to cascaded systems, direct speech-to-text translation ( ST ) is rapidly emerging. Direct S2ST has the potential of : 1 ) retaining paralinguistic and non-linguistic information during the translation, such as speaker \u2019 s voice ( Jia et al., 2019b ) ; 2 ) working on languages without written form ; 3 ) avoiding error compounding across sub-systems. Translatotron ( Jia e",
    ". Compared to cascaded systems, direct speech-to-text translation ( ST ) is rapidly emerging. Direct S2ST has the potential of : 1 ) retaining paralinguistic and non-linguistic information during the translation, such as speaker \u2019 s voice ( Jia et al., 2019b ) ; 2 ) working on languages without written form ; 3 ) avoiding error compounding across sub-systems. Translatotron ( Jia e",
    ". Compared to cascaded systems, direct speech-to-text translation ( ST ) is rapidly emerging. Direct S2ST has the potential of : 1 ) retaining paralinguistic and non-linguistic information during the translation, such as speaker \u2019 s voice ( Jia et al., 2019b ) ; 2 ) working on languages without written form ; 3 ) avoiding error compounding across sub-systems. Translatotron ( Jia e",
    ". Compared to cascaded systems, direct speech-to-text translation ( ST ) is rapidly emerging. Direct S2ST has the potential of : 1 ) retaining paralinguistic and non-linguistic information during the translation, such as speaker \u2019 s voice ( Jia et al., 2019b ) ; 2 ) working on languages without written form ; 3 ) avoiding error compounding across sub-systems. Translatotron ( Jia e",
    ".. the rapid learning of attributes that were not previously labeled.. Some attribute-based models use attributes as direct outputs before the classes for improved modularity and interpretability ( Farhadi et al., 2009 ; Koh et al., 2020 ). However, many attribute-based models rely on attributes as direct outputs before the classes for improved modularity and interpretability ( Farhadi et al., 2009 ;",
    ".. the rapid learning of attributes that were not previously labeled.. Some attribute-based models use attributes as direct outputs before the classes for improved modularity and interpretability ( Farhadi et al., 2009 ; Koh et al., 2020 ). However, many attribute-based models rely on attributes as direct outputs before the classes for improved modularity and interpretability ( Farhadi et al., 2009 ;",
    ".. the rapid learning of attributes that were not previously labeled.. Some attribute-based models use attributes as direct outputs before the classes for improved modularity and interpretability ( Farhadi et al., 2009 ; Koh et al., 2020 ). However, many attribute-based models rely on attributes as direct outputs before the classes for improved modularity and interpretability ( Farhadi et al., 2009 ;",
    ".. the rapid learning of attributes that were not previously labeled.. Some attribute-based models use attributes as direct outputs before the classes for improved modularity and interpretability ( Farhadi et al., 2009 ; Koh et al., 2020 ). However, many attribute-based models rely on attributes as direct outputs before the classes for improved modularity and interpretability ( Farhadi et al., 2009 ;",
    "a general purpose sampling algorithm for unnormalized distributions. This algorithm is based on the Metropolis\u2013Hastings algorithm. MCMC methods are widely used to sample from unnormalized distributions. In this work, we propose a general purpose sampling algorithm for unnormalized distributions. In this work, we propose a general purpose sampling algorithm for unnormalized distributions. In this work, we present a general purpose sampling algorithm for unnormalized distributions.",
    "a general purpose sampling algorithm for unnormalized distributions. This algorithm is based on the Metropolis\u2013Hastings algorithm. MCMC methods are widely used to sample from unnormalized distributions. In this work, we propose a general purpose sampling algorithm for unnormalized distributions. In this work, we propose a general purpose sampling algorithm for unnormalized distributions. In this work, we present a general purpose sampling algorithm for unnormalized distributions.",
    "a general purpose sampling algorithm for unnormalized distributions. This algorithm is based on the Metropolis\u2013Hastings algorithm. MCMC methods are widely used to sample from unnormalized distributions. In this work, we propose a general purpose sampling algorithm for unnormalized distributions. In this work, we propose a general purpose sampling algorithm for unnormalized distributions. In this work, we present a general purpose sampling algorithm for unnormalized distributions.",
    "a general purpose sampling algorithm for unnormalized distributions. This algorithm is based on the Metropolis\u2013Hastings algorithm. MCMC methods are widely used to sample from unnormalized distributions. In this work, we propose a general purpose sampling algorithm for unnormalized distributions. In this work, we propose a general purpose sampling algorithm for unnormalized distributions. In this work, we present a general purpose sampling algorithm for unnormalized distributions.",
    ". For larger images, injectivity would necessitate the same number of qubits as the original image. In this paper, we use a quantum neural network ( QNN ) to classify the MNIST dataset of handwritten digits ( LeCun & Cortes ( 2010 ) ). In parallel, quantum computing ( QC ) has long promised dramatic increases in computational power over classical computers. In this paper, we use a quantum neural network (",
    ". For larger images, injectivity would necessitate the same number of qubits as the original image. In this paper, we use a quantum neural network ( QNN ) to classify the MNIST dataset of handwritten digits ( LeCun & Cortes ( 2010 ) ). In parallel, quantum computing ( QC ) has long promised dramatic increases in computational power over classical computers. In this paper, we use a quantum neural network (",
    ". For larger images, injectivity would necessitate the same number of qubits as the original image. In this paper, we use a quantum neural network ( QNN ) to classify the MNIST dataset of handwritten digits ( LeCun & Cortes ( 2010 ) ). In parallel, quantum computing ( QC ) has long promised dramatic increases in computational power over classical computers. In this paper, we use a quantum neural network (",
    ". For larger images, injectivity would necessitate the same number of qubits as the original image. In this paper, we use a quantum neural network ( QNN ) to classify the MNIST dataset of handwritten digits ( LeCun & Cortes ( 2010 ) ). In parallel, quantum computing ( QC ) has long promised dramatic increases in computational power over classical computers. In this paper, we use a quantum neural network (",
    ". In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field",
    ". In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field",
    ". In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field",
    ". In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field of face recognition calls for a fundamental redesign about model training while preserving privacy. In the wake of growing social consensus on data privacy, the field",
    "LINEAR is a widely used method for obtaining strong performance on a variety of target tasks where training data is scarce. FINETUNING is often preferred over LINEAR since it consistently leads to better performance on a variety of target tasks even when data is scarce. FINETUNING uses targetdomain data to adapt all weights in the feature extractor together with the new output head. this procedure requires doing forward and backward passes through the entire network at each training step.",
    "LINEAR is a widely used method for obtaining strong performance on a variety of target tasks where training data is scarce. FINETUNING is often preferred over LINEAR since it consistently leads to better performance on a variety of target tasks even when data is scarce. FINETUNING uses targetdomain data to adapt all weights in the feature extractor together with the new output head. this procedure requires doing forward and backward passes through the entire network at each training step.",
    "LINEAR is a widely used method for obtaining strong performance on a variety of target tasks where training data is scarce. FINETUNING is often preferred over LINEAR since it consistently leads to better performance on a variety of target tasks even when data is scarce. FINETUNING uses targetdomain data to adapt all weights in the feature extractor together with the new output head. this procedure requires doing forward and backward passes through the entire network at each training step.",
    "LINEAR is a widely used method for obtaining strong performance on a variety of target tasks where training data is scarce. FINETUNING is often preferred over LINEAR since it consistently leads to better performance on a variety of target tasks even when data is scarce. FINETUNING uses targetdomain data to adapt all weights in the feature extractor together with the new output head. this procedure requires doing forward and backward passes through the entire network at each training step.",
    ".. ( 2018 ).. ( 2018 )... ( 2018 )...... Moreover, an observation contains lots of noisy patterns that record object-irrelevant information.    .  ; ; ; ; ; Zhu et al., 2019 ).",
    ".. ( 2018 ).. ( 2018 )... ( 2018 )...... Moreover, an observation contains lots of noisy patterns that record object-irrelevant information.    .  ; ; ; ; ; Zhu et al., 2019 ).",
    ".. ( 2018 ).. ( 2018 )... ( 2018 )...... Moreover, an observation contains lots of noisy patterns that record object-irrelevant information.    .  ; ; ; ; ; Zhu et al., 2019 ).",
    ".. ( 2018 ).. ( 2018 )... ( 2018 )...... Moreover, an observation contains lots of noisy patterns that record object-irrelevant information.    .  ; ; ; ; ; Zhu et al., 2019 ).",
    ". a cost matrix. a cost matrix is in Fig. 1 ( b ). Cost-sensitive loss is hard to optimize since it is non-smooth and non-convex. Cost-sensitive loss is hard to optimize since it is non-convex. Cost-sensitive loss is hard to optimize since it is non-smooth and non-convex. Cost-sensitive loss is hard to optimize since it is non-smooth.",
    ". a cost matrix. a cost matrix is in Fig. 1 ( b ). Cost-sensitive loss is hard to optimize since it is non-smooth and non-convex. Cost-sensitive loss is hard to optimize since it is non-convex. Cost-sensitive loss is hard to optimize since it is non-smooth and non-convex. Cost-sensitive loss is hard to optimize since it is non-smooth.",
    ". a cost matrix. a cost matrix is in Fig. 1 ( b ). Cost-sensitive loss is hard to optimize since it is non-smooth and non-convex. Cost-sensitive loss is hard to optimize since it is non-convex. Cost-sensitive loss is hard to optimize since it is non-smooth and non-convex. Cost-sensitive loss is hard to optimize since it is non-smooth.",
    ". a cost matrix. a cost matrix is in Fig. 1 ( b ). Cost-sensitive loss is hard to optimize since it is non-smooth and non-convex. Cost-sensitive loss is hard to optimize since it is non-convex. Cost-sensitive loss is hard to optimize since it is non-smooth and non-convex. Cost-sensitive loss is hard to optimize since it is non-smooth.",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    "the generalization gap ( from source to target distribution ) remains unresolved. We consider the unsupervised setting where we do not have access to labels on the target domain. While ( i ) is hard to achieve in practice, ( i ) may be the case in the unsupervised setting. We consider the unsupervised setting where we do not have access to labels on the target domain. The setting we consider is similar to the setting suggested by Wang et al. ( 2021",
    "the generalization gap ( from source to target distribution ) remains unresolved. We consider the unsupervised setting where we do not have access to labels on the target domain. While ( i ) is hard to achieve in practice, ( i ) may be the case in the unsupervised setting. We consider the unsupervised setting where we do not have access to labels on the target domain. The setting we consider is similar to the setting suggested by Wang et al. ( 2021",
    "the generalization gap ( from source to target distribution ) remains unresolved. We consider the unsupervised setting where we do not have access to labels on the target domain. While ( i ) is hard to achieve in practice, ( i ) may be the case in the unsupervised setting. We consider the unsupervised setting where we do not have access to labels on the target domain. The setting we consider is similar to the setting suggested by Wang et al. ( 2021",
    "the generalization gap ( from source to target distribution ) remains unresolved. We consider the unsupervised setting where we do not have access to labels on the target domain. While ( i ) is hard to achieve in practice, ( i ) may be the case in the unsupervised setting. We consider the unsupervised setting where we do not have access to labels on the target domain. The setting we consider is similar to the setting suggested by Wang et al. ( 2021",
    "a novel method that learns meaningful representations from videos, titles and comments, which are abundant on the internet. Due to the nature of user comments, we introduce an attention-based mechanism that allows the model to disregard text with irrelevant content. In our experiments, we demonstrate that, by using comments, our method is able to learn better, more contextualised, representations.",
    "a novel method that learns meaningful representations from videos, titles and comments, which are abundant on the internet. Due to the nature of user comments, we introduce an attention-based mechanism that allows the model to disregard text with irrelevant content. In our experiments, we demonstrate that, by using comments, our method is able to learn better, more contextualised, representations.",
    "a novel method that learns meaningful representations from videos, titles and comments, which are abundant on the internet. Due to the nature of user comments, we introduce an attention-based mechanism that allows the model to disregard text with irrelevant content. In our experiments, we demonstrate that, by using comments, our method is able to learn better, more contextualised, representations.",
    "a novel method that learns meaningful representations from videos, titles and comments, which are abundant on the internet. Due to the nature of user comments, we introduce an attention-based mechanism that allows the model to disregard text with irrelevant content. In our experiments, we demonstrate that, by using comments, our method is able to learn better, more contextualised, representations.",
    "unsupervised skill discovery is based upon maximizing the discriminability of skills represented by latent variables on which a policy is conditioned. These skills can be evaluated zero-shot, fine-tuned, or composed in a hierarchical RL setup to maximize task reward when one is introduced. equal contribution to learning. equal contribution to learning. equal contribution to learning. equal contribution to learning. equal contribution to learning",
    "unsupervised skill discovery is based upon maximizing the discriminability of skills represented by latent variables on which a policy is conditioned. These skills can be evaluated zero-shot, fine-tuned, or composed in a hierarchical RL setup to maximize task reward when one is introduced. equal contribution to learning. equal contribution to learning. equal contribution to learning. equal contribution to learning. equal contribution to learning",
    "unsupervised skill discovery is based upon maximizing the discriminability of skills represented by latent variables on which a policy is conditioned. These skills can be evaluated zero-shot, fine-tuned, or composed in a hierarchical RL setup to maximize task reward when one is introduced. equal contribution to learning. equal contribution to learning. equal contribution to learning. equal contribution to learning. equal contribution to learning",
    "unsupervised skill discovery is based upon maximizing the discriminability of skills represented by latent variables on which a policy is conditioned. These skills can be evaluated zero-shot, fine-tuned, or composed in a hierarchical RL setup to maximize task reward when one is introduced. equal contribution to learning. equal contribution to learning. equal contribution to learning. equal contribution to learning. equal contribution to learning",
    "based on string-based and graph-based representations ( Segler et al., 2018 ; You et al., 2018 ; You et al., 2018 ; Jin et al., 2020 ). Since the string-based models ignore the inherent graph structure, recent works explore the graph-based generation that use ( a ) atom-by-atom ( You et al., 2018 ; 2019 ; 2020 )",
    "based on string-based and graph-based representations ( Segler et al., 2018 ; You et al., 2018 ; You et al., 2018 ; Jin et al., 2020 ). Since the string-based models ignore the inherent graph structure, recent works explore the graph-based generation that use ( a ) atom-by-atom ( You et al., 2018 ; 2019 ; 2020 )",
    "based on string-based and graph-based representations ( Segler et al., 2018 ; You et al., 2018 ; You et al., 2018 ; Jin et al., 2020 ). Since the string-based models ignore the inherent graph structure, recent works explore the graph-based generation that use ( a ) atom-by-atom ( You et al., 2018 ; 2019 ; 2020 )",
    "based on string-based and graph-based representations ( Segler et al., 2018 ; You et al., 2018 ; You et al., 2018 ; Jin et al., 2020 ). Since the string-based models ignore the inherent graph structure, recent works explore the graph-based generation that use ( a ) atom-by-atom ( You et al., 2018 ; 2019 ; 2020 )",
    "spectral analysis of deep neural networks offers one perspective on \u201c implicit bias \u201d in neural network training. Deep neural networks demonstrate a learning bias towards low frequency functions. This has sparked the interest in investigating the notion of \u201c implicit bias \u201d in neural network training. Deep neural networks have demonstrated remarkable success in different domains [ 22, 11 ]. Deep neural networks can approximate complex functions or even datasets with randomized labels arbitrarily. This has sparked the interest in investigating the notion of",
    "spectral analysis of deep neural networks offers one perspective on \u201c implicit bias \u201d in neural network training. Deep neural networks demonstrate a learning bias towards low frequency functions. This has sparked the interest in investigating the notion of \u201c implicit bias \u201d in neural network training. Deep neural networks have demonstrated remarkable success in different domains [ 22, 11 ]. Deep neural networks can approximate complex functions or even datasets with randomized labels arbitrarily. This has sparked the interest in investigating the notion of",
    "spectral analysis of deep neural networks offers one perspective on \u201c implicit bias \u201d in neural network training. Deep neural networks demonstrate a learning bias towards low frequency functions. This has sparked the interest in investigating the notion of \u201c implicit bias \u201d in neural network training. Deep neural networks have demonstrated remarkable success in different domains [ 22, 11 ]. Deep neural networks can approximate complex functions or even datasets with randomized labels arbitrarily. This has sparked the interest in investigating the notion of",
    "spectral analysis of deep neural networks offers one perspective on \u201c implicit bias \u201d in neural network training. Deep neural networks demonstrate a learning bias towards low frequency functions. This has sparked the interest in investigating the notion of \u201c implicit bias \u201d in neural network training. Deep neural networks have demonstrated remarkable success in different domains [ 22, 11 ]. Deep neural networks can approximate complex functions or even datasets with randomized labels arbitrarily. This has sparked the interest in investigating the notion of",
    ". Sparse NNs, whose large portions of parameters are zero, have been studied to address those gaps. One of them follows the typical pruning-and-finetuning pipeline in conventional pruning methods. Another explores the possibility of \u201c pruning-at-initialization \u201d for finding sparse NNs.",
    ". Sparse NNs, whose large portions of parameters are zero, have been studied to address those gaps. One of them follows the typical pruning-and-finetuning pipeline in conventional pruning methods. Another explores the possibility of \u201c pruning-at-initialization \u201d for finding sparse NNs.",
    ". Sparse NNs, whose large portions of parameters are zero, have been studied to address those gaps. One of them follows the typical pruning-and-finetuning pipeline in conventional pruning methods. Another explores the possibility of \u201c pruning-at-initialization \u201d for finding sparse NNs.",
    ". Sparse NNs, whose large portions of parameters are zero, have been studied to address those gaps. One of them follows the typical pruning-and-finetuning pipeline in conventional pruning methods. Another explores the possibility of \u201c pruning-at-initialization \u201d for finding sparse NNs.",
    ". Graphs are ubiquitous in different domains such as chemistry ( Duvenaud et al., 2015 ), social media ( Qiu et al., 2018 ) and so on. Graphs are ubiquitous in different domains. Graphs can represent complex relationships among nodes. Graphs are ubiquitous in different domains such as chemistry ( Duvenaud et al., 2015 ), social media ( Qiu",
    ". Graphs are ubiquitous in different domains such as chemistry ( Duvenaud et al., 2015 ), social media ( Qiu et al., 2018 ) and so on. Graphs are ubiquitous in different domains. Graphs can represent complex relationships among nodes. Graphs are ubiquitous in different domains such as chemistry ( Duvenaud et al., 2015 ), social media ( Qiu",
    ". Graphs are ubiquitous in different domains such as chemistry ( Duvenaud et al., 2015 ), social media ( Qiu et al., 2018 ) and so on. Graphs are ubiquitous in different domains. Graphs can represent complex relationships among nodes. Graphs are ubiquitous in different domains such as chemistry ( Duvenaud et al., 2015 ), social media ( Qiu",
    ". Graphs are ubiquitous in different domains such as chemistry ( Duvenaud et al., 2015 ), social media ( Qiu et al., 2018 ) and so on. Graphs are ubiquitous in different domains. Graphs can represent complex relationships among nodes. Graphs are ubiquitous in different domains such as chemistry ( Duvenaud et al., 2015 ), social media ( Qiu",
    ". With the progress in differentiable rendering ( Sitzmann et al., 2019b ; Kato et al., 2018 ; Niemeyer et al., 2020 ), recent neural rendering approaches have achieved impressive results using 3D supervision from single image. While 2D texture recovery could be equally valuable for other domains such as garments, or faces, the existing datasets are limited.",
    ". With the progress in differentiable rendering ( Sitzmann et al., 2019b ; Kato et al., 2018 ; Niemeyer et al., 2020 ), recent neural rendering approaches have achieved impressive results using 3D supervision from single image. While 2D texture recovery could be equally valuable for other domains such as garments, or faces, the existing datasets are limited.",
    ". With the progress in differentiable rendering ( Sitzmann et al., 2019b ; Kato et al., 2018 ; Niemeyer et al., 2020 ), recent neural rendering approaches have achieved impressive results using 3D supervision from single image. While 2D texture recovery could be equally valuable for other domains such as garments, or faces, the existing datasets are limited.",
    ". With the progress in differentiable rendering ( Sitzmann et al., 2019b ; Kato et al., 2018 ; Niemeyer et al., 2020 ), recent neural rendering approaches have achieved impressive results using 3D supervision from single image. While 2D texture recovery could be equally valuable for other domains such as garments, or faces, the existing datasets are limited.",
    "fine-grained recognition. Its practical applications include fine-grained image classification ( Welinder et al., 2010 ; Krause et al., 2013 ; Maji et al., 2013 ), re-identification ( Zheng et al., 2017b ; Liu et al., 2016b ). However, to maintain computational complexity, full conservation of feature resolution would instead restrict a",
    "fine-grained recognition. Its practical applications include fine-grained image classification ( Welinder et al., 2010 ; Krause et al., 2013 ; Maji et al., 2013 ), re-identification ( Zheng et al., 2017b ; Liu et al., 2016b ). However, to maintain computational complexity, full conservation of feature resolution would instead restrict a",
    "fine-grained recognition. Its practical applications include fine-grained image classification ( Welinder et al., 2010 ; Krause et al., 2013 ; Maji et al., 2013 ), re-identification ( Zheng et al., 2017b ; Liu et al., 2016b ). However, to maintain computational complexity, full conservation of feature resolution would instead restrict a",
    "fine-grained recognition. Its practical applications include fine-grained image classification ( Welinder et al., 2010 ; Krause et al., 2013 ; Maji et al., 2013 ), re-identification ( Zheng et al., 2017b ; Liu et al., 2016b ). However, to maintain computational complexity, full conservation of feature resolution would instead restrict a",
    "( 2018 ) ; Beery et al. ( 2018 ) ; B\u00fchlmann ( 2018 ) ; Gong et al. ( 2016 ) ; Arjovsky et al. ( 2019 ). This work was done during authors \u2019 internship at AWS Shanghai AI Lab. a prediction model and l ( ,  ) as a loss function, the OOD problem could be formally represented as min f",
    "( 2018 ) ; Beery et al. ( 2018 ) ; B\u00fchlmann ( 2018 ) ; Gong et al. ( 2016 ) ; Arjovsky et al. ( 2019 ). This work was done during authors \u2019 internship at AWS Shanghai AI Lab. a prediction model and l ( ,  ) as a loss function, the OOD problem could be formally represented as min f",
    "( 2018 ) ; Beery et al. ( 2018 ) ; B\u00fchlmann ( 2018 ) ; Gong et al. ( 2016 ) ; Arjovsky et al. ( 2019 ). This work was done during authors \u2019 internship at AWS Shanghai AI Lab. a prediction model and l ( ,  ) as a loss function, the OOD problem could be formally represented as min f",
    "( 2018 ) ; Beery et al. ( 2018 ) ; B\u00fchlmann ( 2018 ) ; Gong et al. ( 2016 ) ; Arjovsky et al. ( 2019 ). This work was done during authors \u2019 internship at AWS Shanghai AI Lab. a prediction model and l ( ,  ) as a loss function, the OOD problem could be formally represented as min f",
    ". Representation learning learns a fixed-dimension embedding from the original time series. Without human recognizable patterns, it is much harder to label time series data than images and languages in realworld applications. To deal with labeling limitations, contrastive learning methods have been widely adopted in various domains for their soaring performance on representation learning. In addition, contrastive learning methods typically train an encoder to map instances to an embedding space where dissimilar ( negative ) instances are easily",
    ". Representation learning learns a fixed-dimension embedding from the original time series. Without human recognizable patterns, it is much harder to label time series data than images and languages in realworld applications. To deal with labeling limitations, contrastive learning methods have been widely adopted in various domains for their soaring performance on representation learning. In addition, contrastive learning methods typically train an encoder to map instances to an embedding space where dissimilar ( negative ) instances are easily",
    ". Representation learning learns a fixed-dimension embedding from the original time series. Without human recognizable patterns, it is much harder to label time series data than images and languages in realworld applications. To deal with labeling limitations, contrastive learning methods have been widely adopted in various domains for their soaring performance on representation learning. In addition, contrastive learning methods typically train an encoder to map instances to an embedding space where dissimilar ( negative ) instances are easily",
    ". Representation learning learns a fixed-dimension embedding from the original time series. Without human recognizable patterns, it is much harder to label time series data than images and languages in realworld applications. To deal with labeling limitations, contrastive learning methods have been widely adopted in various domains for their soaring performance on representation learning. In addition, contrastive learning methods typically train an encoder to map instances to an embedding space where dissimilar ( negative ) instances are easily",
    ". The lottery ticket hypothesis ( LTH ) for deep neural networks ( DNNs ) proposes that dense DNNs contain sparse subnetworks that can be trained in isolation. These subnetworks can reach performance that is equal to, or better than, that of the full DNN in the same number of training iterations. In addition, there is no principled understanding of why winning tickets can be transferred between tasks. This is in striking analogy to the state of statistical physics",
    ". The lottery ticket hypothesis ( LTH ) for deep neural networks ( DNNs ) proposes that dense DNNs contain sparse subnetworks that can be trained in isolation. These subnetworks can reach performance that is equal to, or better than, that of the full DNN in the same number of training iterations. In addition, there is no principled understanding of why winning tickets can be transferred between tasks. This is in striking analogy to the state of statistical physics",
    ". The lottery ticket hypothesis ( LTH ) for deep neural networks ( DNNs ) proposes that dense DNNs contain sparse subnetworks that can be trained in isolation. These subnetworks can reach performance that is equal to, or better than, that of the full DNN in the same number of training iterations. In addition, there is no principled understanding of why winning tickets can be transferred between tasks. This is in striking analogy to the state of statistical physics",
    ". The lottery ticket hypothesis ( LTH ) for deep neural networks ( DNNs ) proposes that dense DNNs contain sparse subnetworks that can be trained in isolation. These subnetworks can reach performance that is equal to, or better than, that of the full DNN in the same number of training iterations. In addition, there is no principled understanding of why winning tickets can be transferred between tasks. This is in striking analogy to the state of statistical physics",
    "transformer-based models such as BERT have proven successful in information retrieval problem. Such neural ranking models have two flavours : dual-encoder ( DE ) models, which learn separate embeddings for the query and document. Third, we show empirically that the gap between CA and DE models may be due to the latter overfitting to the training set. To mitigate this behaviour, we propose a distillation strategy that focuses on preserving the ordering amongst documents.",
    "transformer-based models such as BERT have proven successful in information retrieval problem. Such neural ranking models have two flavours : dual-encoder ( DE ) models, which learn separate embeddings for the query and document. Third, we show empirically that the gap between CA and DE models may be due to the latter overfitting to the training set. To mitigate this behaviour, we propose a distillation strategy that focuses on preserving the ordering amongst documents.",
    "transformer-based models such as BERT have proven successful in information retrieval problem. Such neural ranking models have two flavours : dual-encoder ( DE ) models, which learn separate embeddings for the query and document. Third, we show empirically that the gap between CA and DE models may be due to the latter overfitting to the training set. To mitigate this behaviour, we propose a distillation strategy that focuses on preserving the ordering amongst documents.",
    "transformer-based models such as BERT have proven successful in information retrieval problem. Such neural ranking models have two flavours : dual-encoder ( DE ) models, which learn separate embeddings for the query and document. Third, we show empirically that the gap between CA and DE models may be due to the latter overfitting to the training set. To mitigate this behaviour, we propose a distillation strategy that focuses on preserving the ordering amongst documents.",
    "), and robot manipulation ( e.g., Lillicrap et al., 2016 ). Policy Optimization methods ( PO, Deisenroth et al., 2013 ) have been widely exploited in Reinforcement Learning ( RL, Sutton & Barto, 2018 ) with successful results in addressing, to name a few, continuous-control ( e.g., Peters & Schaal",
    "), and robot manipulation ( e.g., Lillicrap et al., 2016 ). Policy Optimization methods ( PO, Deisenroth et al., 2013 ) have been widely exploited in Reinforcement Learning ( RL, Sutton & Barto, 2018 ) with successful results in addressing, to name a few, continuous-control ( e.g., Peters & Schaal",
    "), and robot manipulation ( e.g., Lillicrap et al., 2016 ). Policy Optimization methods ( PO, Deisenroth et al., 2013 ) have been widely exploited in Reinforcement Learning ( RL, Sutton & Barto, 2018 ) with successful results in addressing, to name a few, continuous-control ( e.g., Peters & Schaal",
    "), and robot manipulation ( e.g., Lillicrap et al., 2016 ). Policy Optimization methods ( PO, Deisenroth et al., 2013 ) have been widely exploited in Reinforcement Learning ( RL, Sutton & Barto, 2018 ) with successful results in addressing, to name a few, continuous-control ( e.g., Peters & Schaal",
    "2018 ; Sch\u00fctt et al., 2017a ; 2018 ; Xie & Grossman, 2018 ; Xie & Grossman, 2018 ). Graph Neural Networks ( GNNs ) have emerged as the standard architecture of choice for modeling atomic systems. These models operate on graph-structured inputs, where nodes represent atoms, and edges represent bonds or atomic neighbors within a cutoff distance",
    "2018 ; Sch\u00fctt et al., 2017a ; 2018 ; Xie & Grossman, 2018 ; Xie & Grossman, 2018 ). Graph Neural Networks ( GNNs ) have emerged as the standard architecture of choice for modeling atomic systems. These models operate on graph-structured inputs, where nodes represent atoms, and edges represent bonds or atomic neighbors within a cutoff distance",
    "2018 ; Sch\u00fctt et al., 2017a ; 2018 ; Xie & Grossman, 2018 ; Xie & Grossman, 2018 ). Graph Neural Networks ( GNNs ) have emerged as the standard architecture of choice for modeling atomic systems. These models operate on graph-structured inputs, where nodes represent atoms, and edges represent bonds or atomic neighbors within a cutoff distance",
    "2018 ; Sch\u00fctt et al., 2017a ; 2018 ; Xie & Grossman, 2018 ; Xie & Grossman, 2018 ). Graph Neural Networks ( GNNs ) have emerged as the standard architecture of choice for modeling atomic systems. These models operate on graph-structured inputs, where nodes represent atoms, and edges represent bonds or atomic neighbors within a cutoff distance",
    "long texts. These problems are exacerbated when forcing autoregressive models to generate longer texts. These problems are critical for goal-oriented tasks such as story, dialog or recipe generation. These problems suggest that LLMs currently fail to properly capture how documents evolve from beginning to end and condition generation on goals. These problems are further exacerbated when forcing autoregressive models to generate longer texts as the model struggles to extrapolate beyond its expected text end point.",
    "long texts. These problems are exacerbated when forcing autoregressive models to generate longer texts. These problems are critical for goal-oriented tasks such as story, dialog or recipe generation. These problems suggest that LLMs currently fail to properly capture how documents evolve from beginning to end and condition generation on goals. These problems are further exacerbated when forcing autoregressive models to generate longer texts as the model struggles to extrapolate beyond its expected text end point.",
    "long texts. These problems are exacerbated when forcing autoregressive models to generate longer texts. These problems are critical for goal-oriented tasks such as story, dialog or recipe generation. These problems suggest that LLMs currently fail to properly capture how documents evolve from beginning to end and condition generation on goals. These problems are further exacerbated when forcing autoregressive models to generate longer texts as the model struggles to extrapolate beyond its expected text end point.",
    "long texts. These problems are exacerbated when forcing autoregressive models to generate longer texts. These problems are critical for goal-oriented tasks such as story, dialog or recipe generation. These problems suggest that LLMs currently fail to properly capture how documents evolve from beginning to end and condition generation on goals. These problems are further exacerbated when forcing autoregressive models to generate longer texts as the model struggles to extrapolate beyond its expected text end point.",
    "a process of inferring latent causes of 2D images. Therefore, discovering objects is a process of inferring latent causes of 2D images. Therefore, an increasing interest has developed recently to build unsupervised or self-supervised models to infer objects from images. Our work offers a new learning objective and architecture to overcome the limitation of existing works in segmenting more complex scenes.",
    "a process of inferring latent causes of 2D images. Therefore, discovering objects is a process of inferring latent causes of 2D images. Therefore, an increasing interest has developed recently to build unsupervised or self-supervised models to infer objects from images. Our work offers a new learning objective and architecture to overcome the limitation of existing works in segmenting more complex scenes.",
    "a process of inferring latent causes of 2D images. Therefore, discovering objects is a process of inferring latent causes of 2D images. Therefore, an increasing interest has developed recently to build unsupervised or self-supervised models to infer objects from images. Our work offers a new learning objective and architecture to overcome the limitation of existing works in segmenting more complex scenes.",
    "a process of inferring latent causes of 2D images. Therefore, discovering objects is a process of inferring latent causes of 2D images. Therefore, an increasing interest has developed recently to build unsupervised or self-supervised models to infer objects from images. Our work offers a new learning objective and architecture to overcome the limitation of existing works in segmenting more complex scenes.",
    ". Then, they proposed models that extract periodic representations or short-term temporal features directly from the ST data using recurrent-based convolution operations. Based on that, in STDN ( Yao et al., 2019b ), the explicit extraction of the long-term periodic representations or short-term temporal features was shown to improve the prediction. 2 ) Difficulty in separating the extraction of spatial and temporal features. The spatial and temp",
    ". Then, they proposed models that extract periodic representations or short-term temporal features directly from the ST data using recurrent-based convolution operations. Based on that, in STDN ( Yao et al., 2019b ), the explicit extraction of the long-term periodic representations or short-term temporal features was shown to improve the prediction. 2 ) Difficulty in separating the extraction of spatial and temporal features. The spatial and temp",
    ". Then, they proposed models that extract periodic representations or short-term temporal features directly from the ST data using recurrent-based convolution operations. Based on that, in STDN ( Yao et al., 2019b ), the explicit extraction of the long-term periodic representations or short-term temporal features was shown to improve the prediction. 2 ) Difficulty in separating the extraction of spatial and temporal features. The spatial and temp",
    ". Then, they proposed models that extract periodic representations or short-term temporal features directly from the ST data using recurrent-based convolution operations. Based on that, in STDN ( Yao et al., 2019b ), the explicit extraction of the long-term periodic representations or short-term temporal features was shown to improve the prediction. 2 ) Difficulty in separating the extraction of spatial and temporal features. The spatial and temp",
    ". In the case of ICU EHR data, this can occur due to patients being moved between different locations for procedures or tests. In mobile health studies, the same problem can occur due to participants forgetting to wear or carry devices. In this paper, we propose a novel deep learning framework for probabilistic interpolation of irregularly sampled time series.",
    ". In the case of ICU EHR data, this can occur due to patients being moved between different locations for procedures or tests. In mobile health studies, the same problem can occur due to participants forgetting to wear or carry devices. In this paper, we propose a novel deep learning framework for probabilistic interpolation of irregularly sampled time series.",
    ". In the case of ICU EHR data, this can occur due to patients being moved between different locations for procedures or tests. In mobile health studies, the same problem can occur due to participants forgetting to wear or carry devices. In this paper, we propose a novel deep learning framework for probabilistic interpolation of irregularly sampled time series.",
    ". In the case of ICU EHR data, this can occur due to patients being moved between different locations for procedures or tests. In mobile health studies, the same problem can occur due to participants forgetting to wear or carry devices. In this paper, we propose a novel deep learning framework for probabilistic interpolation of irregularly sampled time series.",
    ". coherence. These results suggest that graph-based partitioning can reveal modularity and help us understand how deep neural networks function. In particular, modularity implies that the structure of a system conveys information about its functionality. This leads us to the following definition : a neural network is modular to the extent that parts of its computational graph ( structure ) can be represented as performing some comprehensible subtask relevant to the overall task ( functionality ). We call these parts modules.",
    ". coherence. These results suggest that graph-based partitioning can reveal modularity and help us understand how deep neural networks function. In particular, modularity implies that the structure of a system conveys information about its functionality. This leads us to the following definition : a neural network is modular to the extent that parts of its computational graph ( structure ) can be represented as performing some comprehensible subtask relevant to the overall task ( functionality ). We call these parts modules.",
    ". coherence. These results suggest that graph-based partitioning can reveal modularity and help us understand how deep neural networks function. In particular, modularity implies that the structure of a system conveys information about its functionality. This leads us to the following definition : a neural network is modular to the extent that parts of its computational graph ( structure ) can be represented as performing some comprehensible subtask relevant to the overall task ( functionality ). We call these parts modules.",
    ". coherence. These results suggest that graph-based partitioning can reveal modularity and help us understand how deep neural networks function. In particular, modularity implies that the structure of a system conveys information about its functionality. This leads us to the following definition : a neural network is modular to the extent that parts of its computational graph ( structure ) can be represented as performing some comprehensible subtask relevant to the overall task ( functionality ). We call these parts modules.",
    ", 2019 ; Kim et al., 2019 ; Sim et al., 2018 ; Park et al., 2018 ; Dong et al., 2018a ). ASR has become an indispensable technology in consumer-interactive devices over the past few years. By contrast, recent studies have spurred the success of ASR fully run on devices, which can be advantageous in terms of computational resources, latency, and user data privacy",
    ", 2019 ; Kim et al., 2019 ; Sim et al., 2018 ; Park et al., 2018 ; Dong et al., 2018a ). ASR has become an indispensable technology in consumer-interactive devices over the past few years. By contrast, recent studies have spurred the success of ASR fully run on devices, which can be advantageous in terms of computational resources, latency, and user data privacy",
    ", 2019 ; Kim et al., 2019 ; Sim et al., 2018 ; Park et al., 2018 ; Dong et al., 2018a ). ASR has become an indispensable technology in consumer-interactive devices over the past few years. By contrast, recent studies have spurred the success of ASR fully run on devices, which can be advantageous in terms of computational resources, latency, and user data privacy",
    ", 2019 ; Kim et al., 2019 ; Sim et al., 2018 ; Park et al., 2018 ; Dong et al., 2018a ). ASR has become an indispensable technology in consumer-interactive devices over the past few years. By contrast, recent studies have spurred the success of ASR fully run on devices, which can be advantageous in terms of computational resources, latency, and user data privacy",
    ". By choosing scale parameters that depend on the width of the neural network, to upper bound the variance, they design initialization schemes that avoid vanishing gradients. By choosing scale parameters that depend on the width of the neural network, to upper bound the variance, they design initialization schemes that avoid vanishing gradients. Zhang et al. ( a ) ; Yang and Schoenholz observe that initializing the residual branches at zero benefits signal propagation and optimization.",
    ". By choosing scale parameters that depend on the width of the neural network, to upper bound the variance, they design initialization schemes that avoid vanishing gradients. By choosing scale parameters that depend on the width of the neural network, to upper bound the variance, they design initialization schemes that avoid vanishing gradients. Zhang et al. ( a ) ; Yang and Schoenholz observe that initializing the residual branches at zero benefits signal propagation and optimization.",
    ". By choosing scale parameters that depend on the width of the neural network, to upper bound the variance, they design initialization schemes that avoid vanishing gradients. By choosing scale parameters that depend on the width of the neural network, to upper bound the variance, they design initialization schemes that avoid vanishing gradients. Zhang et al. ( a ) ; Yang and Schoenholz observe that initializing the residual branches at zero benefits signal propagation and optimization.",
    ". By choosing scale parameters that depend on the width of the neural network, to upper bound the variance, they design initialization schemes that avoid vanishing gradients. By choosing scale parameters that depend on the width of the neural network, to upper bound the variance, they design initialization schemes that avoid vanishing gradients. Zhang et al. ( a ) ; Yang and Schoenholz observe that initializing the residual branches at zero benefits signal propagation and optimization.",
    ". Backdoor attacks aim to embed predefined triggers into a model during training time. Moreover, these attacks pose a great challenge to deploy machine learning in mission-critical applications. Various approaches have been proposed to remove the effect of backdoor attacks from a poisoned model. However, the effectiveness of these approaches is particularly sensitive to the underlying attack and data augmentation techniques utilized to enrich the fine-tuning dataset.",
    ". Backdoor attacks aim to embed predefined triggers into a model during training time. Moreover, these attacks pose a great challenge to deploy machine learning in mission-critical applications. Various approaches have been proposed to remove the effect of backdoor attacks from a poisoned model. However, the effectiveness of these approaches is particularly sensitive to the underlying attack and data augmentation techniques utilized to enrich the fine-tuning dataset.",
    ". Backdoor attacks aim to embed predefined triggers into a model during training time. Moreover, these attacks pose a great challenge to deploy machine learning in mission-critical applications. Various approaches have been proposed to remove the effect of backdoor attacks from a poisoned model. However, the effectiveness of these approaches is particularly sensitive to the underlying attack and data augmentation techniques utilized to enrich the fine-tuning dataset.",
    ". Backdoor attacks aim to embed predefined triggers into a model during training time. Moreover, these attacks pose a great challenge to deploy machine learning in mission-critical applications. Various approaches have been proposed to remove the effect of backdoor attacks from a poisoned model. However, the effectiveness of these approaches is particularly sensitive to the underlying attack and data augmentation techniques utilized to enrich the fine-tuning dataset.",
    "finite sum optimization. ( 1 ) Stochastic gradient descent ( SGD ) approximately solves finite sum problems. ( 1 ) Permutation-based SGD approximates solves finite sum problems. Permutation-based SGD approximates solves finite sum problems by iteratively updating the optimization variables according to the following rule...... ( 1 ) Permutation-based SGD approximates solves finite sum problems.",
    "finite sum optimization. ( 1 ) Stochastic gradient descent ( SGD ) approximately solves finite sum problems. ( 1 ) Permutation-based SGD approximates solves finite sum problems. Permutation-based SGD approximates solves finite sum problems by iteratively updating the optimization variables according to the following rule...... ( 1 ) Permutation-based SGD approximates solves finite sum problems.",
    "finite sum optimization. ( 1 ) Stochastic gradient descent ( SGD ) approximately solves finite sum problems. ( 1 ) Permutation-based SGD approximates solves finite sum problems. Permutation-based SGD approximates solves finite sum problems by iteratively updating the optimization variables according to the following rule...... ( 1 ) Permutation-based SGD approximates solves finite sum problems.",
    "finite sum optimization. ( 1 ) Stochastic gradient descent ( SGD ) approximately solves finite sum problems. ( 1 ) Permutation-based SGD approximates solves finite sum problems. Permutation-based SGD approximates solves finite sum problems by iteratively updating the optimization variables according to the following rule...... ( 1 ) Permutation-based SGD approximates solves finite sum problems.",
    ".... ).. )... ). In contrast, autoregressive flows ( Papamakarios et al., 2017 ) are universal probability approximators.......... is...",
    ".... ).. )... ). In contrast, autoregressive flows ( Papamakarios et al., 2017 ) are universal probability approximators.......... is...",
    ".... ).. )... ). In contrast, autoregressive flows ( Papamakarios et al., 2017 ) are universal probability approximators.......... is...",
    ".... ).. )... ). In contrast, autoregressive flows ( Papamakarios et al., 2017 ) are universal probability approximators.......... is...",
    ". 1 INTRODUCTION. We consider the unsupervised learning scenario. This scenario aims at learning distributed representations for complex natural data without human annotations. In addition, expressiveness is the ability to discriminate objects and concepts of the world. On the other hand, learnability is a trade-off between expressiveness and learnability. We argue that in addition to maximizing expressiveness, a good representation should also be learnable, e.g.. support",
    ". 1 INTRODUCTION. We consider the unsupervised learning scenario. This scenario aims at learning distributed representations for complex natural data without human annotations. In addition, expressiveness is the ability to discriminate objects and concepts of the world. On the other hand, learnability is a trade-off between expressiveness and learnability. We argue that in addition to maximizing expressiveness, a good representation should also be learnable, e.g.. support",
    ". 1 INTRODUCTION. We consider the unsupervised learning scenario. This scenario aims at learning distributed representations for complex natural data without human annotations. In addition, expressiveness is the ability to discriminate objects and concepts of the world. On the other hand, learnability is a trade-off between expressiveness and learnability. We argue that in addition to maximizing expressiveness, a good representation should also be learnable, e.g.. support",
    ". 1 INTRODUCTION. We consider the unsupervised learning scenario. This scenario aims at learning distributed representations for complex natural data without human annotations. In addition, expressiveness is the ability to discriminate objects and concepts of the world. On the other hand, learnability is a trade-off between expressiveness and learnability. We argue that in addition to maximizing expressiveness, a good representation should also be learnable, e.g.. support",
    "black-box attacks with segmentation priors can achieve much better imperceptibility performance with little reduction in query efficiency and success rate. Furthermore, our approach is found to be more robust to detection-based defense. In this paper, we propose to use segmentation priors for black-box attacks such that the perturbations are limited in the salient region. Furthermore, our approach is found to be more robust to detection-based defense.",
    "black-box attacks with segmentation priors can achieve much better imperceptibility performance with little reduction in query efficiency and success rate. Furthermore, our approach is found to be more robust to detection-based defense. In this paper, we propose to use segmentation priors for black-box attacks such that the perturbations are limited in the salient region. Furthermore, our approach is found to be more robust to detection-based defense.",
    "black-box attacks with segmentation priors can achieve much better imperceptibility performance with little reduction in query efficiency and success rate. Furthermore, our approach is found to be more robust to detection-based defense. In this paper, we propose to use segmentation priors for black-box attacks such that the perturbations are limited in the salient region. Furthermore, our approach is found to be more robust to detection-based defense.",
    "black-box attacks with segmentation priors can achieve much better imperceptibility performance with little reduction in query efficiency and success rate. Furthermore, our approach is found to be more robust to detection-based defense. In this paper, we propose to use segmentation priors for black-box attacks such that the perturbations are limited in the salient region. Furthermore, our approach is found to be more robust to detection-based defense.",
    "retrosynthetic analysis ( Corey et al., 1972 ) and its reverse problem, reaction outcome prediction ( Corey & Wipke, 1969 ). Both tasks are fundamental problems in computer-aided organic synthesis. Translation-based approaches have become popular. For both tasks, translation-based approaches have become popular.",
    "retrosynthetic analysis ( Corey et al., 1972 ) and its reverse problem, reaction outcome prediction ( Corey & Wipke, 1969 ). Both tasks are fundamental problems in computer-aided organic synthesis. Translation-based approaches have become popular. For both tasks, translation-based approaches have become popular.",
    "retrosynthetic analysis ( Corey et al., 1972 ) and its reverse problem, reaction outcome prediction ( Corey & Wipke, 1969 ). Both tasks are fundamental problems in computer-aided organic synthesis. Translation-based approaches have become popular. For both tasks, translation-based approaches have become popular.",
    "retrosynthetic analysis ( Corey et al., 1972 ) and its reverse problem, reaction outcome prediction ( Corey & Wipke, 1969 ). Both tasks are fundamental problems in computer-aided organic synthesis. Translation-based approaches have become popular. For both tasks, translation-based approaches have become popular.",
    "x-axis represents symptoms and y-axis is the proportion of diseases related. From figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, there are obvious differences in the distribution of symptoms for different diseases. As shown in figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, there are obvious differences in the distribution of symptoms for different diseases.",
    "x-axis represents symptoms and y-axis is the proportion of diseases related. From figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, there are obvious differences in the distribution of symptoms for different diseases. As shown in figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, there are obvious differences in the distribution of symptoms for different diseases.",
    "x-axis represents symptoms and y-axis is the proportion of diseases related. From figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, there are obvious differences in the distribution of symptoms for different diseases. As shown in figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, there are obvious differences in the distribution of symptoms for different diseases.",
    "x-axis represents symptoms and y-axis is the proportion of diseases related. From figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, there are obvious differences in the distribution of symptoms for different diseases. As shown in figure 1, we present the correlation between diseases and symptoms. As shown in figure 1, there are obvious differences in the distribution of symptoms for different diseases.",
    "label deficiency is further complicated in FL, due to the heterogeneous nature of the data at edge devices. Moreover, to address this challenge, we have developed a distributed training system and related evaluation protocol for SSFL. Moreover, the gap of evaluation accuracy between supervised learning and unsupervised learning in FL is both small and reasonable. Moreover, the performance comparison indicates that representation regularization-based personalization method is able to outperform unsupervised learning in FL",
    "label deficiency is further complicated in FL, due to the heterogeneous nature of the data at edge devices. Moreover, to address this challenge, we have developed a distributed training system and related evaluation protocol for SSFL. Moreover, the gap of evaluation accuracy between supervised learning and unsupervised learning in FL is both small and reasonable. Moreover, the performance comparison indicates that representation regularization-based personalization method is able to outperform unsupervised learning in FL",
    "label deficiency is further complicated in FL, due to the heterogeneous nature of the data at edge devices. Moreover, to address this challenge, we have developed a distributed training system and related evaluation protocol for SSFL. Moreover, the gap of evaluation accuracy between supervised learning and unsupervised learning in FL is both small and reasonable. Moreover, the performance comparison indicates that representation regularization-based personalization method is able to outperform unsupervised learning in FL",
    "label deficiency is further complicated in FL, due to the heterogeneous nature of the data at edge devices. Moreover, to address this challenge, we have developed a distributed training system and related evaluation protocol for SSFL. Moreover, the gap of evaluation accuracy between supervised learning and unsupervised learning in FL is both small and reasonable. Moreover, the performance comparison indicates that representation regularization-based personalization method is able to outperform unsupervised learning in FL",
    ". In fact, ResNet is composed of a series of residual mappings. Each residual block is realized by adding a shortcut connection to connect the input and output of the original mapping ( F ). In fact, ResNet is composed of a series of residual mappings. Each residual block is realized by adding a shortcut connection to connect the input and output of the original mapping ( F ). In fact, ResNet is composed of a series of residual mappings. ResNet",
    ". In fact, ResNet is composed of a series of residual mappings. Each residual block is realized by adding a shortcut connection to connect the input and output of the original mapping ( F ). In fact, ResNet is composed of a series of residual mappings. Each residual block is realized by adding a shortcut connection to connect the input and output of the original mapping ( F ). In fact, ResNet is composed of a series of residual mappings. ResNet",
    ". In fact, ResNet is composed of a series of residual mappings. Each residual block is realized by adding a shortcut connection to connect the input and output of the original mapping ( F ). In fact, ResNet is composed of a series of residual mappings. Each residual block is realized by adding a shortcut connection to connect the input and output of the original mapping ( F ). In fact, ResNet is composed of a series of residual mappings. ResNet",
    ". In fact, ResNet is composed of a series of residual mappings. Each residual block is realized by adding a shortcut connection to connect the input and output of the original mapping ( F ). In fact, ResNet is composed of a series of residual mappings. Each residual block is realized by adding a shortcut connection to connect the input and output of the original mapping ( F ). In fact, ResNet is composed of a series of residual mappings. ResNet",
    "language games were first introduced by Wittgenstein ( 1954 ) to explore the meanings of language utterances. Instantiating this concept with the signalling game design from Lewis ( 1969 ) enables linguists to explore the emergence of linguistic structure. The success of deep learning ( DL ) models on complicated cognitive tasks inspired researchers to apply DL-based models to language games.",
    "language games were first introduced by Wittgenstein ( 1954 ) to explore the meanings of language utterances. Instantiating this concept with the signalling game design from Lewis ( 1969 ) enables linguists to explore the emergence of linguistic structure. The success of deep learning ( DL ) models on complicated cognitive tasks inspired researchers to apply DL-based models to language games.",
    "language games were first introduced by Wittgenstein ( 1954 ) to explore the meanings of language utterances. Instantiating this concept with the signalling game design from Lewis ( 1969 ) enables linguists to explore the emergence of linguistic structure. The success of deep learning ( DL ) models on complicated cognitive tasks inspired researchers to apply DL-based models to language games.",
    "language games were first introduced by Wittgenstein ( 1954 ) to explore the meanings of language utterances. Instantiating this concept with the signalling game design from Lewis ( 1969 ) enables linguists to explore the emergence of linguistic structure. The success of deep learning ( DL ) models on complicated cognitive tasks inspired researchers to apply DL-based models to language games.",
    ", 2018 ). In general RL, an agent interacts with an external environment taking sequences of actions that cause transitions between states of the environment. The agent has to decide whether to exploit the actions that are known to maximize immediate reward or whether to explore unfamiliar actions and states in order to potentially increase future rewards. This difficulty limits the applicability of conventional explorations strategies based on UCB and TS for general RL problems.",
    ", 2018 ). In general RL, an agent interacts with an external environment taking sequences of actions that cause transitions between states of the environment. The agent has to decide whether to exploit the actions that are known to maximize immediate reward or whether to explore unfamiliar actions and states in order to potentially increase future rewards. This difficulty limits the applicability of conventional explorations strategies based on UCB and TS for general RL problems.",
    ", 2018 ). In general RL, an agent interacts with an external environment taking sequences of actions that cause transitions between states of the environment. The agent has to decide whether to exploit the actions that are known to maximize immediate reward or whether to explore unfamiliar actions and states in order to potentially increase future rewards. This difficulty limits the applicability of conventional explorations strategies based on UCB and TS for general RL problems.",
    ", 2018 ). In general RL, an agent interacts with an external environment taking sequences of actions that cause transitions between states of the environment. The agent has to decide whether to exploit the actions that are known to maximize immediate reward or whether to explore unfamiliar actions and states in order to potentially increase future rewards. This difficulty limits the applicability of conventional explorations strategies based on UCB and TS for general RL problems.",
    "2018 ; ; Weissenborn et al., 2019 ; 2019 ; 2020 ; Tian et al., 2021 ; Yan et al., 2021 ). However, video generation remains a major challenge of deep generative models. In particular, implicit neural representations have been proposed to learn the video distribution. In particular, implicit neural representations have been proposed to learn the video distribution. In particular, implicit neural representation",
    "2018 ; ; Weissenborn et al., 2019 ; 2019 ; 2020 ; Tian et al., 2021 ; Yan et al., 2021 ). However, video generation remains a major challenge of deep generative models. In particular, implicit neural representations have been proposed to learn the video distribution. In particular, implicit neural representations have been proposed to learn the video distribution. In particular, implicit neural representation",
    "2018 ; ; Weissenborn et al., 2019 ; 2019 ; 2020 ; Tian et al., 2021 ; Yan et al., 2021 ). However, video generation remains a major challenge of deep generative models. In particular, implicit neural representations have been proposed to learn the video distribution. In particular, implicit neural representations have been proposed to learn the video distribution. In particular, implicit neural representation",
    "2018 ; ; Weissenborn et al., 2019 ; 2019 ; 2020 ; Tian et al., 2021 ; Yan et al., 2021 ). However, video generation remains a major challenge of deep generative models. In particular, implicit neural representations have been proposed to learn the video distribution. In particular, implicit neural representations have been proposed to learn the video distribution. In particular, implicit neural representation",
    ". Powerset voting operates over the entire binary vector by viewing the possible outcomes as a power set. We empirically compare our techniques with DPSGD on large real-world healthcare data and standard multi-label benchmarks. We find that our techniques outperform all others in the centralized setting. We enable multi-label CaPC and show that our mechanisms can be used to collaboratively improve models in a multi-site ( distributed ) setting.",
    ". Powerset voting operates over the entire binary vector by viewing the possible outcomes as a power set. We empirically compare our techniques with DPSGD on large real-world healthcare data and standard multi-label benchmarks. We find that our techniques outperform all others in the centralized setting. We enable multi-label CaPC and show that our mechanisms can be used to collaboratively improve models in a multi-site ( distributed ) setting.",
    ". Powerset voting operates over the entire binary vector by viewing the possible outcomes as a power set. We empirically compare our techniques with DPSGD on large real-world healthcare data and standard multi-label benchmarks. We find that our techniques outperform all others in the centralized setting. We enable multi-label CaPC and show that our mechanisms can be used to collaboratively improve models in a multi-site ( distributed ) setting.",
    ". Powerset voting operates over the entire binary vector by viewing the possible outcomes as a power set. We empirically compare our techniques with DPSGD on large real-world healthcare data and standard multi-label benchmarks. We find that our techniques outperform all others in the centralized setting. We enable multi-label CaPC and show that our mechanisms can be used to collaboratively improve models in a multi-site ( distributed ) setting.",
    ". 1.1 OUR CONTRIBUTIONS. We introduce learning rate grafting. This meta-algorithm blends the steps of two different optimizers by combining the step magnitudes of one ( M ) with the normalized directions of the other ( D ). 1.2 OUR CONTRIBUTIONS. Our results serve not only as a sanity check on explanatory theory, but also as a way to simplify the optimizer search space in practical settings",
    ". 1.1 OUR CONTRIBUTIONS. We introduce learning rate grafting. This meta-algorithm blends the steps of two different optimizers by combining the step magnitudes of one ( M ) with the normalized directions of the other ( D ). 1.2 OUR CONTRIBUTIONS. Our results serve not only as a sanity check on explanatory theory, but also as a way to simplify the optimizer search space in practical settings",
    ". 1.1 OUR CONTRIBUTIONS. We introduce learning rate grafting. This meta-algorithm blends the steps of two different optimizers by combining the step magnitudes of one ( M ) with the normalized directions of the other ( D ). 1.2 OUR CONTRIBUTIONS. Our results serve not only as a sanity check on explanatory theory, but also as a way to simplify the optimizer search space in practical settings",
    ". 1.1 OUR CONTRIBUTIONS. We introduce learning rate grafting. This meta-algorithm blends the steps of two different optimizers by combining the step magnitudes of one ( M ) with the normalized directions of the other ( D ). 1.2 OUR CONTRIBUTIONS. Our results serve not only as a sanity check on explanatory theory, but also as a way to simplify the optimizer search space in practical settings",
    "... We propose a principled approach for using the well known trust region policy optimization ( TRPO ) algorithm with offline demonstration data for guidance. The first step is identical to traditional TRPO to generate a candidate policy. In the second step, the objective is to find a candidate policy. In the third step, the objective is to find a candidate policy. In the fourth step, the objective is to find a candidate policy. In the final step,",
    "... We propose a principled approach for using the well known trust region policy optimization ( TRPO ) algorithm with offline demonstration data for guidance. The first step is identical to traditional TRPO to generate a candidate policy. In the second step, the objective is to find a candidate policy. In the third step, the objective is to find a candidate policy. In the fourth step, the objective is to find a candidate policy. In the final step,",
    "... We propose a principled approach for using the well known trust region policy optimization ( TRPO ) algorithm with offline demonstration data for guidance. The first step is identical to traditional TRPO to generate a candidate policy. In the second step, the objective is to find a candidate policy. In the third step, the objective is to find a candidate policy. In the fourth step, the objective is to find a candidate policy. In the final step,",
    "... We propose a principled approach for using the well known trust region policy optimization ( TRPO ) algorithm with offline demonstration data for guidance. The first step is identical to traditional TRPO to generate a candidate policy. In the second step, the objective is to find a candidate policy. In the third step, the objective is to find a candidate policy. In the fourth step, the objective is to find a candidate policy. In the final step,",
    "a Pareto front is defined as the set of optimal points away from which no single objective can be improved without diminishing at least one other objective. A Pareto front is then defined as the set of optimal points away from which no single objective can be improved without diminishing at least one other objective. Currently, many saddle point solvers have been proposed for MOO problems. However, some recently proposed Multi-Task Learning ( MTL ) solvers criticize Linear Scalar",
    "a Pareto front is defined as the set of optimal points away from which no single objective can be improved without diminishing at least one other objective. A Pareto front is then defined as the set of optimal points away from which no single objective can be improved without diminishing at least one other objective. Currently, many saddle point solvers have been proposed for MOO problems. However, some recently proposed Multi-Task Learning ( MTL ) solvers criticize Linear Scalar",
    "a Pareto front is defined as the set of optimal points away from which no single objective can be improved without diminishing at least one other objective. A Pareto front is then defined as the set of optimal points away from which no single objective can be improved without diminishing at least one other objective. Currently, many saddle point solvers have been proposed for MOO problems. However, some recently proposed Multi-Task Learning ( MTL ) solvers criticize Linear Scalar",
    "a Pareto front is defined as the set of optimal points away from which no single objective can be improved without diminishing at least one other objective. A Pareto front is then defined as the set of optimal points away from which no single objective can be improved without diminishing at least one other objective. Currently, many saddle point solvers have been proposed for MOO problems. However, some recently proposed Multi-Task Learning ( MTL ) solvers criticize Linear Scalar",
    "a library of diverse experts pre-trained on different tasks. Sec. 4.......,, and.,.., a library of experts.,. Such a nave approach clearly does not scale and. at minimum, requires developing techniques for selecting experts that is sub-linear in the size of",
    "a library of diverse experts pre-trained on different tasks. Sec. 4.......,, and.,.., a library of experts.,. Such a nave approach clearly does not scale and. at minimum, requires developing techniques for selecting experts that is sub-linear in the size of",
    "a library of diverse experts pre-trained on different tasks. Sec. 4.......,, and.,.., a library of experts.,. Such a nave approach clearly does not scale and. at minimum, requires developing techniques for selecting experts that is sub-linear in the size of",
    "a library of diverse experts pre-trained on different tasks. Sec. 4.......,, and.,.., a library of experts.,. Such a nave approach clearly does not scale and. at minimum, requires developing techniques for selecting experts that is sub-linear in the size of",
    ". This paper is concerned with the problem of finding the most efficient prediction set with valid coverage. Conformal prediction has been used for learning prediction sets in a variety of tasks in regres- sion, classification ( Cauchois et al., 2020b ; Romano et al., 2020b ), structured prediction ( Bates et al., 2021 ). Our approach builds on conformal prediction ( Vovk et al.",
    ". This paper is concerned with the problem of finding the most efficient prediction set with valid coverage. Conformal prediction has been used for learning prediction sets in a variety of tasks in regres- sion, classification ( Cauchois et al., 2020b ; Romano et al., 2020b ), structured prediction ( Bates et al., 2021 ). Our approach builds on conformal prediction ( Vovk et al.",
    ". This paper is concerned with the problem of finding the most efficient prediction set with valid coverage. Conformal prediction has been used for learning prediction sets in a variety of tasks in regres- sion, classification ( Cauchois et al., 2020b ; Romano et al., 2020b ), structured prediction ( Bates et al., 2021 ). Our approach builds on conformal prediction ( Vovk et al.",
    ". This paper is concerned with the problem of finding the most efficient prediction set with valid coverage. Conformal prediction has been used for learning prediction sets in a variety of tasks in regres- sion, classification ( Cauchois et al., 2020b ; Romano et al., 2020b ), structured prediction ( Bates et al., 2021 ). Our approach builds on conformal prediction ( Vovk et al.",
    "a small set of exemplary images. We learn a transferable reward signal formulated using ordinal metric learning. Our proposed method enables test-time policy adaptation to new environments where the reward signals are not readily available. In addition, the transferable reward allows repurposing the trained agent from one specific class to another.",
    "a small set of exemplary images. We learn a transferable reward signal formulated using ordinal metric learning. Our proposed method enables test-time policy adaptation to new environments where the reward signals are not readily available. In addition, the transferable reward allows repurposing the trained agent from one specific class to another.",
    "a small set of exemplary images. We learn a transferable reward signal formulated using ordinal metric learning. Our proposed method enables test-time policy adaptation to new environments where the reward signals are not readily available. In addition, the transferable reward allows repurposing the trained agent from one specific class to another.",
    "a small set of exemplary images. We learn a transferable reward signal formulated using ordinal metric learning. Our proposed method enables test-time policy adaptation to new environments where the reward signals are not readily available. In addition, the transferable reward allows repurposing the trained agent from one specific class to another.",
    ". Transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks. However, transformers have quadratic computational complexity in terms of the number of tokens. Thus, transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks. Thus, transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks.",
    ". Transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks. However, transformers have quadratic computational complexity in terms of the number of tokens. Thus, transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks. Thus, transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks.",
    ". Transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks. However, transformers have quadratic computational complexity in terms of the number of tokens. Thus, transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks. Thus, transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks.",
    ". Transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks. However, transformers have quadratic computational complexity in terms of the number of tokens. Thus, transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks. Thus, transformers can capture long-range dependencies by the attention module and have demonstrated tremendous success in natural language processing tasks.",
    "a wheeled robot can learn to drive on unfamiliar roads faster than learning from scratch. In this paper, we follow a common assumption that diversifying options improves the reusability of options. The most intuitive strategy would be visiting all states as equally as possible. However, this can be difficult to measure without prior knowledge. In this paper, we argue that diversifying options improves the reusability of options. In this paper, we argue that diversifying options improves the",
    "a wheeled robot can learn to drive on unfamiliar roads faster than learning from scratch. In this paper, we follow a common assumption that diversifying options improves the reusability of options. The most intuitive strategy would be visiting all states as equally as possible. However, this can be difficult to measure without prior knowledge. In this paper, we argue that diversifying options improves the reusability of options. In this paper, we argue that diversifying options improves the",
    "a wheeled robot can learn to drive on unfamiliar roads faster than learning from scratch. In this paper, we follow a common assumption that diversifying options improves the reusability of options. The most intuitive strategy would be visiting all states as equally as possible. However, this can be difficult to measure without prior knowledge. In this paper, we argue that diversifying options improves the reusability of options. In this paper, we argue that diversifying options improves the",
    "a wheeled robot can learn to drive on unfamiliar roads faster than learning from scratch. In this paper, we follow a common assumption that diversifying options improves the reusability of options. The most intuitive strategy would be visiting all states as equally as possible. However, this can be difficult to measure without prior knowledge. In this paper, we argue that diversifying options improves the reusability of options. In this paper, we argue that diversifying options improves the",
    ", 2019 ; Tian et al., 2019 ; Zhou et al., 2019a ; Carion et al., 2019a ; Zhou et al., 2019a ). Object detection, which aims at localizing and classifying objects in a given scene, is one of the most iconic abilities of biological intelligence. It was introduced to the artificial intelligence field to endow an intelligence agent with the ability of scene understanding",
    ", 2019 ; Tian et al., 2019 ; Zhou et al., 2019a ; Carion et al., 2019a ; Zhou et al., 2019a ). Object detection, which aims at localizing and classifying objects in a given scene, is one of the most iconic abilities of biological intelligence. It was introduced to the artificial intelligence field to endow an intelligence agent with the ability of scene understanding",
    ", 2019 ; Tian et al., 2019 ; Zhou et al., 2019a ; Carion et al., 2019a ; Zhou et al., 2019a ). Object detection, which aims at localizing and classifying objects in a given scene, is one of the most iconic abilities of biological intelligence. It was introduced to the artificial intelligence field to endow an intelligence agent with the ability of scene understanding",
    ", 2019 ; Tian et al., 2019 ; Zhou et al., 2019a ; Carion et al., 2019a ; Zhou et al., 2019a ). Object detection, which aims at localizing and classifying objects in a given scene, is one of the most iconic abilities of biological intelligence. It was introduced to the artificial intelligence field to endow an intelligence agent with the ability of scene understanding",
    "a large unlabeled dataset along with a small labeled ( seed ) dataset and an annotation budget, how do we select a subset of the unlabeled dataset, which, when annotated, will achieve the best performance? a batch setting ( Sener & Savarese, 2018 ; Zhdanov, 2019 ; Shui et al., 2020 ; Ghorbani et al.,",
    "a large unlabeled dataset along with a small labeled ( seed ) dataset and an annotation budget, how do we select a subset of the unlabeled dataset, which, when annotated, will achieve the best performance? a batch setting ( Sener & Savarese, 2018 ; Zhdanov, 2019 ; Shui et al., 2020 ; Ghorbani et al.,",
    "a large unlabeled dataset along with a small labeled ( seed ) dataset and an annotation budget, how do we select a subset of the unlabeled dataset, which, when annotated, will achieve the best performance? a batch setting ( Sener & Savarese, 2018 ; Zhdanov, 2019 ; Shui et al., 2020 ; Ghorbani et al.,",
    "a large unlabeled dataset along with a small labeled ( seed ) dataset and an annotation budget, how do we select a subset of the unlabeled dataset, which, when annotated, will achieve the best performance? a batch setting ( Sener & Savarese, 2018 ; Zhdanov, 2019 ; Shui et al., 2020 ; Ghorbani et al.,",
    "; Volpi et al., 2018 ). The current state of the art for semantic segmentation, however, lacks dire in out-of-distribution robustness. In this work, we study the generalization problem of semantic segmentation from synthetic data ( Richter et al., 2016 ; Chen et al., 2018b ) through the lens of adaptation. Instead of modifying the model architecture ( Richter et al.",
    "; Volpi et al., 2018 ). The current state of the art for semantic segmentation, however, lacks dire in out-of-distribution robustness. In this work, we study the generalization problem of semantic segmentation from synthetic data ( Richter et al., 2016 ; Chen et al., 2018b ) through the lens of adaptation. Instead of modifying the model architecture ( Richter et al.",
    "; Volpi et al., 2018 ). The current state of the art for semantic segmentation, however, lacks dire in out-of-distribution robustness. In this work, we study the generalization problem of semantic segmentation from synthetic data ( Richter et al., 2016 ; Chen et al., 2018b ) through the lens of adaptation. Instead of modifying the model architecture ( Richter et al.",
    "; Volpi et al., 2018 ). The current state of the art for semantic segmentation, however, lacks dire in out-of-distribution robustness. In this work, we study the generalization problem of semantic segmentation from synthetic data ( Richter et al., 2016 ; Chen et al., 2018b ) through the lens of adaptation. Instead of modifying the model architecture ( Richter et al.",
    "satisfied for the samples of the training set. By making the assumption that the dependency structures are class-dependent, one can construct a criterion that is more likely to hold for samples from other ( unseen ) distributions. In this work, we consider subsets of consecutive variables. In this way, for a given input sample xi  Rd, we obtain a set of pairs  ( aji, b j i )",
    "satisfied for the samples of the training set. By making the assumption that the dependency structures are class-dependent, one can construct a criterion that is more likely to hold for samples from other ( unseen ) distributions. In this work, we consider subsets of consecutive variables. In this way, for a given input sample xi  Rd, we obtain a set of pairs  ( aji, b j i )",
    "satisfied for the samples of the training set. By making the assumption that the dependency structures are class-dependent, one can construct a criterion that is more likely to hold for samples from other ( unseen ) distributions. In this work, we consider subsets of consecutive variables. In this way, for a given input sample xi  Rd, we obtain a set of pairs  ( aji, b j i )",
    "satisfied for the samples of the training set. By making the assumption that the dependency structures are class-dependent, one can construct a criterion that is more likely to hold for samples from other ( unseen ) distributions. In this work, we consider subsets of consecutive variables. In this way, for a given input sample xi  Rd, we obtain a set of pairs  ( aji, b j i )",
    ".. the nosological relation among neuropsychiatric disorders. However, due to their inherent high dimensionality, it poses a formidable data-analytic challenge in uncovering the targeted nosological relation. Thus, the objective of this research is to seek the optimum low-dimensional embeddings of FC features. However, without the supplied supervision signals, over-reliance on data-driven methods may not be sufficient to derive the optimal low-dimensional embedding",
    ".. the nosological relation among neuropsychiatric disorders. However, due to their inherent high dimensionality, it poses a formidable data-analytic challenge in uncovering the targeted nosological relation. Thus, the objective of this research is to seek the optimum low-dimensional embeddings of FC features. However, without the supplied supervision signals, over-reliance on data-driven methods may not be sufficient to derive the optimal low-dimensional embedding",
    ".. the nosological relation among neuropsychiatric disorders. However, due to their inherent high dimensionality, it poses a formidable data-analytic challenge in uncovering the targeted nosological relation. Thus, the objective of this research is to seek the optimum low-dimensional embeddings of FC features. However, without the supplied supervision signals, over-reliance on data-driven methods may not be sufficient to derive the optimal low-dimensional embedding",
    ".. the nosological relation among neuropsychiatric disorders. However, due to their inherent high dimensionality, it poses a formidable data-analytic challenge in uncovering the targeted nosological relation. Thus, the objective of this research is to seek the optimum low-dimensional embeddings of FC features. However, without the supplied supervision signals, over-reliance on data-driven methods may not be sufficient to derive the optimal low-dimensional embedding",
    ", 2019 ; Schuld & Killoran, 2021 ). DNN training algorithms are computationally expensive for many new scientific applications. However, the imminent advent of quantum computing devices opens up new possibilities of exploiting quantum machine learning ( QML ) in the new scientific domains.",
    ", 2019 ; Schuld & Killoran, 2021 ). DNN training algorithms are computationally expensive for many new scientific applications. However, the imminent advent of quantum computing devices opens up new possibilities of exploiting quantum machine learning ( QML ) in the new scientific domains.",
    ", 2019 ; Schuld & Killoran, 2021 ). DNN training algorithms are computationally expensive for many new scientific applications. However, the imminent advent of quantum computing devices opens up new possibilities of exploiting quantum machine learning ( QML ) in the new scientific domains.",
    ", 2019 ; Schuld & Killoran, 2021 ). DNN training algorithms are computationally expensive for many new scientific applications. However, the imminent advent of quantum computing devices opens up new possibilities of exploiting quantum machine learning ( QML ) in the new scientific domains.",
    "a low-dimensional submanifold of neural networks. This submanifold is parametrized by a low-dimensional parameter   Rd. This allows us to apply traditional ideas from clustering and interpolation to the space of neural networks. For example, two neural networks may correspond to nearby points in model embedding space if they correspond to neural networks which implement similar high-level computational processes. In this way, two neural networks may correspond to nearby points in model embedd",
    "a low-dimensional submanifold of neural networks. This submanifold is parametrized by a low-dimensional parameter   Rd. This allows us to apply traditional ideas from clustering and interpolation to the space of neural networks. For example, two neural networks may correspond to nearby points in model embedding space if they correspond to neural networks which implement similar high-level computational processes. In this way, two neural networks may correspond to nearby points in model embedd",
    "a low-dimensional submanifold of neural networks. This submanifold is parametrized by a low-dimensional parameter   Rd. This allows us to apply traditional ideas from clustering and interpolation to the space of neural networks. For example, two neural networks may correspond to nearby points in model embedding space if they correspond to neural networks which implement similar high-level computational processes. In this way, two neural networks may correspond to nearby points in model embedd",
    "a low-dimensional submanifold of neural networks. This submanifold is parametrized by a low-dimensional parameter   Rd. This allows us to apply traditional ideas from clustering and interpolation to the space of neural networks. For example, two neural networks may correspond to nearby points in model embedding space if they correspond to neural networks which implement similar high-level computational processes. In this way, two neural networks may correspond to nearby points in model embedd",
    "a scalar constraint function is implemented as a trainable function approximator. We test the model on a variety of challenging physical domains. We show how hand-designed constraints can be added at test time to satisfy objectives which were not present in the training data. 1 INTRODUCTION. Consider a bowling ball colliding with a bowling pin. You might explain the collision as involving a pair of forces being generated, one which causes the ball to move",
    "a scalar constraint function is implemented as a trainable function approximator. We test the model on a variety of challenging physical domains. We show how hand-designed constraints can be added at test time to satisfy objectives which were not present in the training data. 1 INTRODUCTION. Consider a bowling ball colliding with a bowling pin. You might explain the collision as involving a pair of forces being generated, one which causes the ball to move",
    "a scalar constraint function is implemented as a trainable function approximator. We test the model on a variety of challenging physical domains. We show how hand-designed constraints can be added at test time to satisfy objectives which were not present in the training data. 1 INTRODUCTION. Consider a bowling ball colliding with a bowling pin. You might explain the collision as involving a pair of forces being generated, one which causes the ball to move",
    "a scalar constraint function is implemented as a trainable function approximator. We test the model on a variety of challenging physical domains. We show how hand-designed constraints can be added at test time to satisfy objectives which were not present in the training data. 1 INTRODUCTION. Consider a bowling ball colliding with a bowling pin. You might explain the collision as involving a pair of forces being generated, one which causes the ball to move",
    ". In contrast, maintaining a set of policies allows data to be collected with diverse behaviors. Reinforcement Learning ( RL ) is an effective method for training agents to make decisions in a given environment. As RL is applied to more real-world scenarios, we may need to find a set of policies with both high quality ( i.e., rewards ) and diverse behaviors. In contrast, maintaining a set of policies can improve robustness, e.g.",
    ". In contrast, maintaining a set of policies allows data to be collected with diverse behaviors. Reinforcement Learning ( RL ) is an effective method for training agents to make decisions in a given environment. As RL is applied to more real-world scenarios, we may need to find a set of policies with both high quality ( i.e., rewards ) and diverse behaviors. In contrast, maintaining a set of policies can improve robustness, e.g.",
    ". In contrast, maintaining a set of policies allows data to be collected with diverse behaviors. Reinforcement Learning ( RL ) is an effective method for training agents to make decisions in a given environment. As RL is applied to more real-world scenarios, we may need to find a set of policies with both high quality ( i.e., rewards ) and diverse behaviors. In contrast, maintaining a set of policies can improve robustness, e.g.",
    ". In contrast, maintaining a set of policies allows data to be collected with diverse behaviors. Reinforcement Learning ( RL ) is an effective method for training agents to make decisions in a given environment. As RL is applied to more real-world scenarios, we may need to find a set of policies with both high quality ( i.e., rewards ) and diverse behaviors. In contrast, maintaining a set of policies can improve robustness, e.g.",
    "this paper aims to relax the assumption of requiring bi-directional communication among agents in a distributed RL algorithm. This assumption is arguably restrictive and will be violated due to reasons such as packet drops or delays, privacy constraints among the agents, adversarial attacks, or even sophisticated resilient consensus algorithms being used to construct the distributed RL algorithm. As we discuss in more detail below, this paper aims to relax the assumption of requiring bi-directional communication among agents in a distributed RL algorithm",
    "this paper aims to relax the assumption of requiring bi-directional communication among agents in a distributed RL algorithm. This assumption is arguably restrictive and will be violated due to reasons such as packet drops or delays, privacy constraints among the agents, adversarial attacks, or even sophisticated resilient consensus algorithms being used to construct the distributed RL algorithm. As we discuss in more detail below, this paper aims to relax the assumption of requiring bi-directional communication among agents in a distributed RL algorithm",
    "this paper aims to relax the assumption of requiring bi-directional communication among agents in a distributed RL algorithm. This assumption is arguably restrictive and will be violated due to reasons such as packet drops or delays, privacy constraints among the agents, adversarial attacks, or even sophisticated resilient consensus algorithms being used to construct the distributed RL algorithm. As we discuss in more detail below, this paper aims to relax the assumption of requiring bi-directional communication among agents in a distributed RL algorithm",
    "this paper aims to relax the assumption of requiring bi-directional communication among agents in a distributed RL algorithm. This assumption is arguably restrictive and will be violated due to reasons such as packet drops or delays, privacy constraints among the agents, adversarial attacks, or even sophisticated resilient consensus algorithms being used to construct the distributed RL algorithm. As we discuss in more detail below, this paper aims to relax the assumption of requiring bi-directional communication among agents in a distributed RL algorithm",
    "Wenbing Huang and Jiaqi Han ; A Corresponding authors : Yu Rong and Fuchun Sun. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works",
    "Wenbing Huang and Jiaqi Han ; A Corresponding authors : Yu Rong and Fuchun Sun. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works",
    "Wenbing Huang and Jiaqi Han ; A Corresponding authors : Yu Rong and Fuchun Sun. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works",
    "Wenbing Huang and Jiaqi Han ; A Corresponding authors : Yu Rong and Fuchun Sun. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works as an intern in Tencent AI Lab. This work is done when Jiaqi Han works",
    "fi ( w, zi, j ) be the loss of the model on the training example zi, j. Let w  Rd represent the parameters of a ( supervised ) learning model and fi ( w, zi, j ) be the loss of the model on the training example zi, j. Let fi ( w, zi, j ) be the loss of the model on the training example zi, j.",
    "fi ( w, zi, j ) be the loss of the model on the training example zi, j. Let w  Rd represent the parameters of a ( supervised ) learning model and fi ( w, zi, j ) be the loss of the model on the training example zi, j. Let fi ( w, zi, j ) be the loss of the model on the training example zi, j.",
    "fi ( w, zi, j ) be the loss of the model on the training example zi, j. Let w  Rd represent the parameters of a ( supervised ) learning model and fi ( w, zi, j ) be the loss of the model on the training example zi, j. Let fi ( w, zi, j ) be the loss of the model on the training example zi, j.",
    "fi ( w, zi, j ) be the loss of the model on the training example zi, j. Let w  Rd represent the parameters of a ( supervised ) learning model and fi ( w, zi, j ) be the loss of the model on the training example zi, j. Let fi ( w, zi, j ) be the loss of the model on the training example zi, j.",
    ", augmented versions of an image are mapped on to close-by latent representations. This is a promising step forward for artificial intelligence. Self-supervised learning has emerged as a promising alternative to fully supervised approaches. In the domain of visual object recognition, recent contrastive learning approaches have obtained strong results on standard object recognition benchmarks. In contrast to fully supervised approaches, self-supervised learning has emerged as a promising alternative to fully supervised approaches.",
    ", augmented versions of an image are mapped on to close-by latent representations. This is a promising step forward for artificial intelligence. Self-supervised learning has emerged as a promising alternative to fully supervised approaches. In the domain of visual object recognition, recent contrastive learning approaches have obtained strong results on standard object recognition benchmarks. In contrast to fully supervised approaches, self-supervised learning has emerged as a promising alternative to fully supervised approaches.",
    ", augmented versions of an image are mapped on to close-by latent representations. This is a promising step forward for artificial intelligence. Self-supervised learning has emerged as a promising alternative to fully supervised approaches. In the domain of visual object recognition, recent contrastive learning approaches have obtained strong results on standard object recognition benchmarks. In contrast to fully supervised approaches, self-supervised learning has emerged as a promising alternative to fully supervised approaches.",
    ", augmented versions of an image are mapped on to close-by latent representations. This is a promising step forward for artificial intelligence. Self-supervised learning has emerged as a promising alternative to fully supervised approaches. In the domain of visual object recognition, recent contrastive learning approaches have obtained strong results on standard object recognition benchmarks. In contrast to fully supervised approaches, self-supervised learning has emerged as a promising alternative to fully supervised approaches.",
    "large tree branching factors. MCTS planners use a forward environment model to build a search tree, estimate the value of each action in the current state, and execute the best-estimated one. MCTS planners use a forward environment model to build a search tree, estimate the value of each action in the current state, and execute the best-estimated one. AlphaZero combines MCTS with the ability of RL algorithms to generalize across states",
    "large tree branching factors. MCTS planners use a forward environment model to build a search tree, estimate the value of each action in the current state, and execute the best-estimated one. MCTS planners use a forward environment model to build a search tree, estimate the value of each action in the current state, and execute the best-estimated one. AlphaZero combines MCTS with the ability of RL algorithms to generalize across states",
    "large tree branching factors. MCTS planners use a forward environment model to build a search tree, estimate the value of each action in the current state, and execute the best-estimated one. MCTS planners use a forward environment model to build a search tree, estimate the value of each action in the current state, and execute the best-estimated one. AlphaZero combines MCTS with the ability of RL algorithms to generalize across states",
    "large tree branching factors. MCTS planners use a forward environment model to build a search tree, estimate the value of each action in the current state, and execute the best-estimated one. MCTS planners use a forward environment model to build a search tree, estimate the value of each action in the current state, and execute the best-estimated one. AlphaZero combines MCTS with the ability of RL algorithms to generalize across states",
    "i.i.d. .... a sequence of tasks without access to historical data. Single-Task Learning ( STL ) can be regarded as an expansion-based method which trains a single task. STL is an expansion-based method which trains a single task. STL is an expansion-based methoda single task without access to historical data. STL is an expansion-based method which trains a single",
    "i.i.d. .... a sequence of tasks without access to historical data. Single-Task Learning ( STL ) can be regarded as an expansion-based method which trains a single task. STL is an expansion-based method which trains a single task. STL is an expansion-based methoda single task without access to historical data. STL is an expansion-based method which trains a single",
    "i.i.d. .... a sequence of tasks without access to historical data. Single-Task Learning ( STL ) can be regarded as an expansion-based method which trains a single task. STL is an expansion-based method which trains a single task. STL is an expansion-based methoda single task without access to historical data. STL is an expansion-based method which trains a single",
    "i.i.d. .... a sequence of tasks without access to historical data. Single-Task Learning ( STL ) can be regarded as an expansion-based method which trains a single task. STL is an expansion-based method which trains a single task. STL is an expansion-based methoda single task without access to historical data. STL is an expansion-based method which trains a single",
    ". Transfer Learning ( TL) refers to the process in which a parent model is used to improve the performance of a child model on a new target domain/task. In this work, we provide a complementary perspective. Transfer Learning ( TL) refers to the process in which a parent model is used to improve the performance of a child model on a new target domain/task. In this work, we analyze and leverage the shared knowledge between the parent and child models.",
    ". Transfer Learning ( TL) refers to the process in which a parent model is used to improve the performance of a child model on a new target domain/task. In this work, we provide a complementary perspective. Transfer Learning ( TL) refers to the process in which a parent model is used to improve the performance of a child model on a new target domain/task. In this work, we analyze and leverage the shared knowledge between the parent and child models.",
    ". Transfer Learning ( TL) refers to the process in which a parent model is used to improve the performance of a child model on a new target domain/task. In this work, we provide a complementary perspective. Transfer Learning ( TL) refers to the process in which a parent model is used to improve the performance of a child model on a new target domain/task. In this work, we analyze and leverage the shared knowledge between the parent and child models.",
    ". Transfer Learning ( TL) refers to the process in which a parent model is used to improve the performance of a child model on a new target domain/task. In this work, we provide a complementary perspective. Transfer Learning ( TL) refers to the process in which a parent model is used to improve the performance of a child model on a new target domain/task. In this work, we analyze and leverage the shared knowledge between the parent and child models.",
    "). In terms of applications, learning from graph data is ubiquitous in a number of ML tasks. A first one is to learn graph representations that can encode the graph structure. Another task is to find a meaningful notion of similarity/distance between graphs. A third task is to find a meaningful notion of similarity/distance between graphs. A third task is to find a meaningful notion of similarity/distance between graphs. A third task is",
    "). In terms of applications, learning from graph data is ubiquitous in a number of ML tasks. A first one is to learn graph representations that can encode the graph structure. Another task is to find a meaningful notion of similarity/distance between graphs. A third task is to find a meaningful notion of similarity/distance between graphs. A third task is to find a meaningful notion of similarity/distance between graphs. A third task is",
    "). In terms of applications, learning from graph data is ubiquitous in a number of ML tasks. A first one is to learn graph representations that can encode the graph structure. Another task is to find a meaningful notion of similarity/distance between graphs. A third task is to find a meaningful notion of similarity/distance between graphs. A third task is to find a meaningful notion of similarity/distance between graphs. A third task is",
    "). In terms of applications, learning from graph data is ubiquitous in a number of ML tasks. A first one is to learn graph representations that can encode the graph structure. Another task is to find a meaningful notion of similarity/distance between graphs. A third task is to find a meaningful notion of similarity/distance between graphs. A third task is to find a meaningful notion of similarity/distance between graphs. A third task is",
    ". Alternatively, some human models eschew rewards and rationality to include random deviations from optimal decision-making. Both methods are successful in many settings but also suffer drawbacks. Imitation learning has been applied to modeling humans in driving ( Ding et al., 2011 ), arm motion ( Ma et al., 2017 ), and pedestrian navigation ( Schmerling et al., 2019 ; Wang et al.,",
    ". Alternatively, some human models eschew rewards and rationality to include random deviations from optimal decision-making. Both methods are successful in many settings but also suffer drawbacks. Imitation learning has been applied to modeling humans in driving ( Ding et al., 2011 ), arm motion ( Ma et al., 2017 ), and pedestrian navigation ( Schmerling et al., 2019 ; Wang et al.,",
    ". Alternatively, some human models eschew rewards and rationality to include random deviations from optimal decision-making. Both methods are successful in many settings but also suffer drawbacks. Imitation learning has been applied to modeling humans in driving ( Ding et al., 2011 ), arm motion ( Ma et al., 2017 ), and pedestrian navigation ( Schmerling et al., 2019 ; Wang et al.,",
    ". Alternatively, some human models eschew rewards and rationality to include random deviations from optimal decision-making. Both methods are successful in many settings but also suffer drawbacks. Imitation learning has been applied to modeling humans in driving ( Ding et al., 2011 ), arm motion ( Ma et al., 2017 ), and pedestrian navigation ( Schmerling et al., 2019 ; Wang et al.,",
    "1. QAT requires to simulate quantization in the training process, which invokes time-consuming retraining and hyper-parameter tuning. In contrast, data-free quantization ( DFQ ) has recently been presented as a promising way to quantize models without original datasets. QAT requires to simulate quantization in the training process, which invokes time-consuming retraining and hyper-parameter tuning. QAT requires to simulate quantization in the training process, which",
    "1. QAT requires to simulate quantization in the training process, which invokes time-consuming retraining and hyper-parameter tuning. In contrast, data-free quantization ( DFQ ) has recently been presented as a promising way to quantize models without original datasets. QAT requires to simulate quantization in the training process, which invokes time-consuming retraining and hyper-parameter tuning. QAT requires to simulate quantization in the training process, which",
    "1. QAT requires to simulate quantization in the training process, which invokes time-consuming retraining and hyper-parameter tuning. In contrast, data-free quantization ( DFQ ) has recently been presented as a promising way to quantize models without original datasets. QAT requires to simulate quantization in the training process, which invokes time-consuming retraining and hyper-parameter tuning. QAT requires to simulate quantization in the training process, which",
    "1. QAT requires to simulate quantization in the training process, which invokes time-consuming retraining and hyper-parameter tuning. In contrast, data-free quantization ( DFQ ) has recently been presented as a promising way to quantize models without original datasets. QAT requires to simulate quantization in the training process, which invokes time-consuming retraining and hyper-parameter tuning. QAT requires to simulate quantization in the training process, which",
    ". TSS is a step-level extension of a well known time series classification problem. Time series are ordered sequences of data values. TSS is a step-level extension of a well known time series classification problem. TSS is essential in various impactful domains, e.g. stock trajectories partitioning ( Chakraborty et al., 2016 ), speaker diarisation ( Perslev et al.,",
    ". TSS is a step-level extension of a well known time series classification problem. Time series are ordered sequences of data values. TSS is a step-level extension of a well known time series classification problem. TSS is essential in various impactful domains, e.g. stock trajectories partitioning ( Chakraborty et al., 2016 ), speaker diarisation ( Perslev et al.,",
    ". TSS is a step-level extension of a well known time series classification problem. Time series are ordered sequences of data values. TSS is a step-level extension of a well known time series classification problem. TSS is essential in various impactful domains, e.g. stock trajectories partitioning ( Chakraborty et al., 2016 ), speaker diarisation ( Perslev et al.,",
    ". TSS is a step-level extension of a well known time series classification problem. Time series are ordered sequences of data values. TSS is a step-level extension of a well known time series classification problem. TSS is essential in various impactful domains, e.g. stock trajectories partitioning ( Chakraborty et al., 2016 ), speaker diarisation ( Perslev et al.,",
    ". Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information. Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information. However, GNNs suffer from its black-box nature and lack a faithful explanation of its predictions. Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information ( Zhou et al.,",
    ". Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information. Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information. However, GNNs suffer from its black-box nature and lack a faithful explanation of its predictions. Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information ( Zhou et al.,",
    ". Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information. Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information. However, GNNs suffer from its black-box nature and lack a faithful explanation of its predictions. Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information ( Zhou et al.,",
    ". Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information. Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information. However, GNNs suffer from its black-box nature and lack a faithful explanation of its predictions. Graph Neural Networks ( GNNs ) play an important role in modeling data with complex relational information ( Zhou et al.,",
    ", 2018 ). Convolutional neural networks ( CNNs ) have been the most widely used neural architecture across a wide range of tasks. To that end, pooling layers and strided convolutions aggressively reduce the resolution of their inputs. This improves shift-invariance. Fourth, pooling layers act as a bottleneck that forces features to focus on information relevant to the task at hand. Fourth, a reduced resolution implies a reduced number of floating-",
    ", 2018 ). Convolutional neural networks ( CNNs ) have been the most widely used neural architecture across a wide range of tasks. To that end, pooling layers and strided convolutions aggressively reduce the resolution of their inputs. This improves shift-invariance. Fourth, pooling layers act as a bottleneck that forces features to focus on information relevant to the task at hand. Fourth, a reduced resolution implies a reduced number of floating-",
    ", 2018 ). Convolutional neural networks ( CNNs ) have been the most widely used neural architecture across a wide range of tasks. To that end, pooling layers and strided convolutions aggressively reduce the resolution of their inputs. This improves shift-invariance. Fourth, pooling layers act as a bottleneck that forces features to focus on information relevant to the task at hand. Fourth, a reduced resolution implies a reduced number of floating-",
    ", 2018 ). Convolutional neural networks ( CNNs ) have been the most widely used neural architecture across a wide range of tasks. To that end, pooling layers and strided convolutions aggressively reduce the resolution of their inputs. This improves shift-invariance. Fourth, pooling layers act as a bottleneck that forces features to focus on information relevant to the task at hand. Fourth, a reduced resolution implies a reduced number of floating-",
    "how many predictions can be changed by an adversary. In the following, we derive a method that provides provable guarantees on how many predictions can be changed by an adversary. Since all outputs operate on the same input, they also have to be attacked simultaneously by choosing a single perturbed input. In the following, we derive a method that provides provable guarantees on how many predictions can be changed by an adversary. In the following, we derive a method",
    "how many predictions can be changed by an adversary. In the following, we derive a method that provides provable guarantees on how many predictions can be changed by an adversary. Since all outputs operate on the same input, they also have to be attacked simultaneously by choosing a single perturbed input. In the following, we derive a method that provides provable guarantees on how many predictions can be changed by an adversary. In the following, we derive a method",
    "how many predictions can be changed by an adversary. In the following, we derive a method that provides provable guarantees on how many predictions can be changed by an adversary. Since all outputs operate on the same input, they also have to be attacked simultaneously by choosing a single perturbed input. In the following, we derive a method that provides provable guarantees on how many predictions can be changed by an adversary. In the following, we derive a method",
    "how many predictions can be changed by an adversary. In the following, we derive a method that provides provable guarantees on how many predictions can be changed by an adversary. Since all outputs operate on the same input, they also have to be attacked simultaneously by choosing a single perturbed input. In the following, we derive a method that provides provable guarantees on how many predictions can be changed by an adversary. In the following, we derive a method",
    "general-purpose flows. Such structured prior information can enable the user to form effective inferences using much less data than would otherwise be required. For example, in the field of astrophysics differentiable probabilistic programs have been successfully used to study strong gravitational lensing ( Chianese et al., 2020 ) and dark matter substructures ( Coogan et al., 2020 ). However, it remains the case that \u201c all models are wrong",
    "general-purpose flows. Such structured prior information can enable the user to form effective inferences using much less data than would otherwise be required. For example, in the field of astrophysics differentiable probabilistic programs have been successfully used to study strong gravitational lensing ( Chianese et al., 2020 ) and dark matter substructures ( Coogan et al., 2020 ). However, it remains the case that \u201c all models are wrong",
    "general-purpose flows. Such structured prior information can enable the user to form effective inferences using much less data than would otherwise be required. For example, in the field of astrophysics differentiable probabilistic programs have been successfully used to study strong gravitational lensing ( Chianese et al., 2020 ) and dark matter substructures ( Coogan et al., 2020 ). However, it remains the case that \u201c all models are wrong",
    "general-purpose flows. Such structured prior information can enable the user to form effective inferences using much less data than would otherwise be required. For example, in the field of astrophysics differentiable probabilistic programs have been successfully used to study strong gravitational lensing ( Chianese et al., 2020 ) and dark matter substructures ( Coogan et al., 2020 ). However, it remains the case that \u201c all models are wrong",
    ",. we \u201c orient \u201d large pre-trained language models ( LMs ) by asking whether models can learn to ground an entire domain ( e.g., direction ) after grounding only a subset of the points in that domain ( e.g., left ). In particular, for generative LMs that have been trained only on large text corpora, we \u201c orient \u201d the models by showing them how some word forms",
    ",. we \u201c orient \u201d large pre-trained language models ( LMs ) by asking whether models can learn to ground an entire domain ( e.g., direction ) after grounding only a subset of the points in that domain ( e.g., left ). In particular, for generative LMs that have been trained only on large text corpora, we \u201c orient \u201d the models by showing them how some word forms",
    ",. we \u201c orient \u201d large pre-trained language models ( LMs ) by asking whether models can learn to ground an entire domain ( e.g., direction ) after grounding only a subset of the points in that domain ( e.g., left ). In particular, for generative LMs that have been trained only on large text corpora, we \u201c orient \u201d the models by showing them how some word forms",
    ",. we \u201c orient \u201d large pre-trained language models ( LMs ) by asking whether models can learn to ground an entire domain ( e.g., direction ) after grounding only a subset of the points in that domain ( e.g., left ). In particular, for generative LMs that have been trained only on large text corpora, we \u201c orient \u201d the models by showing them how some word forms",
    "in emergent language research, the goal is to study language as it emerges from the inherent properties of the environment, language, and agents. one pitfall for such experiments is that the language simply mirrors some of design choices of the environment or experimental setting more generally. for emergent language research, the inductive bias which shaped rewards introduce is especially problematic because it exerts a significant influence on the learned language whose emergent properties are the object of study.",
    "in emergent language research, the goal is to study language as it emerges from the inherent properties of the environment, language, and agents. one pitfall for such experiments is that the language simply mirrors some of design choices of the environment or experimental setting more generally. for emergent language research, the inductive bias which shaped rewards introduce is especially problematic because it exerts a significant influence on the learned language whose emergent properties are the object of study.",
    "in emergent language research, the goal is to study language as it emerges from the inherent properties of the environment, language, and agents. one pitfall for such experiments is that the language simply mirrors some of design choices of the environment or experimental setting more generally. for emergent language research, the inductive bias which shaped rewards introduce is especially problematic because it exerts a significant influence on the learned language whose emergent properties are the object of study.",
    "in emergent language research, the goal is to study language as it emerges from the inherent properties of the environment, language, and agents. one pitfall for such experiments is that the language simply mirrors some of design choices of the environment or experimental setting more generally. for emergent language research, the inductive bias which shaped rewards introduce is especially problematic because it exerts a significant influence on the learned language whose emergent properties are the object of study.",
    "( 1 ) invariance of the feature representations strongly correlates with transfer performance. ( 2 ) distributional shift in class priors negatively affects performance. In addition, we propose an unsupervised cross-lingual learning method, called importance-weighted domain alignment ( IWDA ). Our method performs representation alignment, prior shift estimation, and correction. In addition, our method delivers further performance gains when combined with existing semi-supervised learning techniques.",
    "( 1 ) invariance of the feature representations strongly correlates with transfer performance. ( 2 ) distributional shift in class priors negatively affects performance. In addition, we propose an unsupervised cross-lingual learning method, called importance-weighted domain alignment ( IWDA ). Our method performs representation alignment, prior shift estimation, and correction. In addition, our method delivers further performance gains when combined with existing semi-supervised learning techniques.",
    "( 1 ) invariance of the feature representations strongly correlates with transfer performance. ( 2 ) distributional shift in class priors negatively affects performance. In addition, we propose an unsupervised cross-lingual learning method, called importance-weighted domain alignment ( IWDA ). Our method performs representation alignment, prior shift estimation, and correction. In addition, our method delivers further performance gains when combined with existing semi-supervised learning techniques.",
    "( 1 ) invariance of the feature representations strongly correlates with transfer performance. ( 2 ) distributional shift in class priors negatively affects performance. In addition, we propose an unsupervised cross-lingual learning method, called importance-weighted domain alignment ( IWDA ). Our method performs representation alignment, prior shift estimation, and correction. In addition, our method delivers further performance gains when combined with existing semi-supervised learning techniques.",
    ". In a machine learning problem, a learner or agent learns a task by iteratively adjusting its parameters under a given update rule. In contrast, humans learn seamlessly by relying on previous experiences to inform their learning processes. Meta-learning is one approach that learns ( parts of ) an update rule by applying it for some number of steps and then evaluating the resulting performance.",
    ". In a machine learning problem, a learner or agent learns a task by iteratively adjusting its parameters under a given update rule. In contrast, humans learn seamlessly by relying on previous experiences to inform their learning processes. Meta-learning is one approach that learns ( parts of ) an update rule by applying it for some number of steps and then evaluating the resulting performance.",
    ". In a machine learning problem, a learner or agent learns a task by iteratively adjusting its parameters under a given update rule. In contrast, humans learn seamlessly by relying on previous experiences to inform their learning processes. Meta-learning is one approach that learns ( parts of ) an update rule by applying it for some number of steps and then evaluating the resulting performance.",
    ". In a machine learning problem, a learner or agent learns a task by iteratively adjusting its parameters under a given update rule. In contrast, humans learn seamlessly by relying on previous experiences to inform their learning processes. Meta-learning is one approach that learns ( parts of ) an update rule by applying it for some number of steps and then evaluating the resulting performance.",
    "a lack of standardization around how to measure generalization in model-based RL. These benchmarks have not yet been widely adopted in the model-based setting. In this paper, we investigate three factors of generalization in model-based RL : planning, self-supervised representation learning, and procedural data diversity. We also analyze these methods through a variety of modifications and ablations to MuZero.",
    "a lack of standardization around how to measure generalization in model-based RL. These benchmarks have not yet been widely adopted in the model-based setting. In this paper, we investigate three factors of generalization in model-based RL : planning, self-supervised representation learning, and procedural data diversity. We also analyze these methods through a variety of modifications and ablations to MuZero.",
    "a lack of standardization around how to measure generalization in model-based RL. These benchmarks have not yet been widely adopted in the model-based setting. In this paper, we investigate three factors of generalization in model-based RL : planning, self-supervised representation learning, and procedural data diversity. We also analyze these methods through a variety of modifications and ablations to MuZero.",
    "a lack of standardization around how to measure generalization in model-based RL. These benchmarks have not yet been widely adopted in the model-based setting. In this paper, we investigate three factors of generalization in model-based RL : planning, self-supervised representation learning, and procedural data diversity. We also analyze these methods through a variety of modifications and ablations to MuZero.",
    ", 2019 ). The graph learning task is a supervised network inverse problem. We train the graph learning task in a supervised fashion to learn the distribution of latent undirected graphs. The graph learning task is a supervised network inverse problem. In this paper, we train a graph deconvolution network ( GDN ), which we train in a supervised fashion to learn the distribution of latent undirected graphs. The graph learning task is a",
    ", 2019 ). The graph learning task is a supervised network inverse problem. We train the graph learning task in a supervised fashion to learn the distribution of latent undirected graphs. The graph learning task is a supervised network inverse problem. In this paper, we train a graph deconvolution network ( GDN ), which we train in a supervised fashion to learn the distribution of latent undirected graphs. The graph learning task is a",
    ", 2019 ). The graph learning task is a supervised network inverse problem. We train the graph learning task in a supervised fashion to learn the distribution of latent undirected graphs. The graph learning task is a supervised network inverse problem. In this paper, we train a graph deconvolution network ( GDN ), which we train in a supervised fashion to learn the distribution of latent undirected graphs. The graph learning task is a",
    ", 2019 ). The graph learning task is a supervised network inverse problem. We train the graph learning task in a supervised fashion to learn the distribution of latent undirected graphs. The graph learning task is a supervised network inverse problem. In this paper, we train a graph deconvolution network ( GDN ), which we train in a supervised fashion to learn the distribution of latent undirected graphs. The graph learning task is a",
    "sparse reward provides infrequent feedback of the agent \u2019 s performance. This leads to RL algorithms requiring large numbers of samples ( and high expense ) for solving problems. Moreover, poor choices of shaping rewards can worsen the agent \u2019 s performance. Our framework, ROSA, constructs shaping rewards during learning.",
    "sparse reward provides infrequent feedback of the agent \u2019 s performance. This leads to RL algorithms requiring large numbers of samples ( and high expense ) for solving problems. Moreover, poor choices of shaping rewards can worsen the agent \u2019 s performance. Our framework, ROSA, constructs shaping rewards during learning.",
    "sparse reward provides infrequent feedback of the agent \u2019 s performance. This leads to RL algorithms requiring large numbers of samples ( and high expense ) for solving problems. Moreover, poor choices of shaping rewards can worsen the agent \u2019 s performance. Our framework, ROSA, constructs shaping rewards during learning.",
    "sparse reward provides infrequent feedback of the agent \u2019 s performance. This leads to RL algorithms requiring large numbers of samples ( and high expense ) for solving problems. Moreover, poor choices of shaping rewards can worsen the agent \u2019 s performance. Our framework, ROSA, constructs shaping rewards during learning.",
    ". Federated Learning ( FL ) involves distributed training where a central server coordinates with multiple agents to collaboratively train a machine learning model. Agents keep their own training data, e.g., due to privacy concerns. Given the distributed training, FL raises new security concerns as the server has less control of the training data and agent devices. Several studies have focused on making HFL more robust, wherein each agent has a different training set, while in VFL",
    ". Federated Learning ( FL ) involves distributed training where a central server coordinates with multiple agents to collaboratively train a machine learning model. Agents keep their own training data, e.g., due to privacy concerns. Given the distributed training, FL raises new security concerns as the server has less control of the training data and agent devices. Several studies have focused on making HFL more robust, wherein each agent has a different training set, while in VFL",
    ". Federated Learning ( FL ) involves distributed training where a central server coordinates with multiple agents to collaboratively train a machine learning model. Agents keep their own training data, e.g., due to privacy concerns. Given the distributed training, FL raises new security concerns as the server has less control of the training data and agent devices. Several studies have focused on making HFL more robust, wherein each agent has a different training set, while in VFL",
    ". Federated Learning ( FL ) involves distributed training where a central server coordinates with multiple agents to collaboratively train a machine learning model. Agents keep their own training data, e.g., due to privacy concerns. Given the distributed training, FL raises new security concerns as the server has less control of the training data and agent devices. Several studies have focused on making HFL more robust, wherein each agent has a different training set, while in VFL",
    "document retrieval is the task of finding relevant documents in a large collection to answer specific queries. Traditionally, retrieval systems, or retrievers, leverage lexical similarities to match queries and documents. by contrast, approaches based on neural networks allow learning beyond lexical similarities. in this setting, dense retrievers are often outperformed by classical methods based on term-frequency, which do not require supervision ( Thakur et al., 2021 ).",
    "document retrieval is the task of finding relevant documents in a large collection to answer specific queries. Traditionally, retrieval systems, or retrievers, leverage lexical similarities to match queries and documents. by contrast, approaches based on neural networks allow learning beyond lexical similarities. in this setting, dense retrievers are often outperformed by classical methods based on term-frequency, which do not require supervision ( Thakur et al., 2021 ).",
    "document retrieval is the task of finding relevant documents in a large collection to answer specific queries. Traditionally, retrieval systems, or retrievers, leverage lexical similarities to match queries and documents. by contrast, approaches based on neural networks allow learning beyond lexical similarities. in this setting, dense retrievers are often outperformed by classical methods based on term-frequency, which do not require supervision ( Thakur et al., 2021 ).",
    "document retrieval is the task of finding relevant documents in a large collection to answer specific queries. Traditionally, retrieval systems, or retrievers, leverage lexical similarities to match queries and documents. by contrast, approaches based on neural networks allow learning beyond lexical similarities. in this setting, dense retrievers are often outperformed by classical methods based on term-frequency, which do not require supervision ( Thakur et al., 2021 ).",
    ". Pretraining a model on a large dataset before transferring to a downstream task \u2019 s training data substantially improves accuracy over training from scratch. Pretraining a model on a large dataset before transferring to a downstream task \u2019 s training data substantially improves accuracy over training from scratch. In addition, fine-tuning all layers of a network can improve pretrained features by tailoring them to the specific task, while linear probing freezes these features. In this",
    ". Pretraining a model on a large dataset before transferring to a downstream task \u2019 s training data substantially improves accuracy over training from scratch. Pretraining a model on a large dataset before transferring to a downstream task \u2019 s training data substantially improves accuracy over training from scratch. In addition, fine-tuning all layers of a network can improve pretrained features by tailoring them to the specific task, while linear probing freezes these features. In this",
    ". Pretraining a model on a large dataset before transferring to a downstream task \u2019 s training data substantially improves accuracy over training from scratch. Pretraining a model on a large dataset before transferring to a downstream task \u2019 s training data substantially improves accuracy over training from scratch. In addition, fine-tuning all layers of a network can improve pretrained features by tailoring them to the specific task, while linear probing freezes these features. In this",
    ". Pretraining a model on a large dataset before transferring to a downstream task \u2019 s training data substantially improves accuracy over training from scratch. Pretraining a model on a large dataset before transferring to a downstream task \u2019 s training data substantially improves accuracy over training from scratch. In addition, fine-tuning all layers of a network can improve pretrained features by tailoring them to the specific task, while linear probing freezes these features. In this",
    ". In this paper, we demystify assumptions behind L2DNC. In learning to discover novel classes ( L2DNC ), we are given labeled data from seen classes and unlabeled data from unseen classes. In this paper, we demystify assumptions behind L2DNC and find that high-level semantic features should be shared among the seen and unseen classes. Therefore, unseen-class data should be collected on the way",
    ". In this paper, we demystify assumptions behind L2DNC. In learning to discover novel classes ( L2DNC ), we are given labeled data from seen classes and unlabeled data from unseen classes. In this paper, we demystify assumptions behind L2DNC and find that high-level semantic features should be shared among the seen and unseen classes. Therefore, unseen-class data should be collected on the way",
    ". In this paper, we demystify assumptions behind L2DNC. In learning to discover novel classes ( L2DNC ), we are given labeled data from seen classes and unlabeled data from unseen classes. In this paper, we demystify assumptions behind L2DNC and find that high-level semantic features should be shared among the seen and unseen classes. Therefore, unseen-class data should be collected on the way",
    ". In this paper, we demystify assumptions behind L2DNC. In learning to discover novel classes ( L2DNC ), we are given labeled data from seen classes and unlabeled data from unseen classes. In this paper, we demystify assumptions behind L2DNC and find that high-level semantic features should be shared among the seen and unseen classes. Therefore, unseen-class data should be collected on the way",
    "in reinforcement learning ( RL ), how do we combine observation and experimentation in order to improve the performance of a learning agent? In the context of medicine, where offline data is collected from physicians who may rely on information absent from their patient \u2019 s medical records. Suppose that wealthy patients in general get prescribed specific treatments by their physicians, because they can afford it. this creates a spurious correlation called confounding, and will cause a spurious correlation called confounding",
    "in reinforcement learning ( RL ), how do we combine observation and experimentation in order to improve the performance of a learning agent? In the context of medicine, where offline data is collected from physicians who may rely on information absent from their patient \u2019 s medical records. Suppose that wealthy patients in general get prescribed specific treatments by their physicians, because they can afford it. this creates a spurious correlation called confounding, and will cause a spurious correlation called confounding",
    "in reinforcement learning ( RL ), how do we combine observation and experimentation in order to improve the performance of a learning agent? In the context of medicine, where offline data is collected from physicians who may rely on information absent from their patient \u2019 s medical records. Suppose that wealthy patients in general get prescribed specific treatments by their physicians, because they can afford it. this creates a spurious correlation called confounding, and will cause a spurious correlation called confounding",
    "in reinforcement learning ( RL ), how do we combine observation and experimentation in order to improve the performance of a learning agent? In the context of medicine, where offline data is collected from physicians who may rely on information absent from their patient \u2019 s medical records. Suppose that wealthy patients in general get prescribed specific treatments by their physicians, because they can afford it. this creates a spurious correlation called confounding, and will cause a spurious correlation called confounding",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    ". Several real-world problems can be cast as combinatorial optimization problems over a graph. From distributing packages ( Mathew et al., 2015 ) to improving the general health ( Wilder et al., 2018 ). However, the majority of these problems are NP-hard, and hence we can only approximate their solution in a satisfactory time limit that matches the real world requirements. Recently, machine learning methods have emerged as a promising solution to",
    ". Several real-world problems can be cast as combinatorial optimization problems over a graph. From distributing packages ( Mathew et al., 2015 ) to improving the general health ( Wilder et al., 2018 ). However, the majority of these problems are NP-hard, and hence we can only approximate their solution in a satisfactory time limit that matches the real world requirements. Recently, machine learning methods have emerged as a promising solution to",
    ". Several real-world problems can be cast as combinatorial optimization problems over a graph. From distributing packages ( Mathew et al., 2015 ) to improving the general health ( Wilder et al., 2018 ). However, the majority of these problems are NP-hard, and hence we can only approximate their solution in a satisfactory time limit that matches the real world requirements. Recently, machine learning methods have emerged as a promising solution to",
    ". Several real-world problems can be cast as combinatorial optimization problems over a graph. From distributing packages ( Mathew et al., 2015 ) to improving the general health ( Wilder et al., 2018 ). However, the majority of these problems are NP-hard, and hence we can only approximate their solution in a satisfactory time limit that matches the real world requirements. Recently, machine learning methods have emerged as a promising solution to",
    ".. This is the reason. Active learning is a challenging task. On the one hand, some active learning methods introduce heuristic approaches. These heuristics provide theoretical guarantees on the target risk. However, the computation of the distribution distances is not straightforward. For instance, the distance between the labeled set and the unlabeled one is not straightforward ( Viering et al., 2019 ). On the other hand,",
    ".. This is the reason. Active learning is a challenging task. On the one hand, some active learning methods introduce heuristic approaches. These heuristics provide theoretical guarantees on the target risk. However, the computation of the distribution distances is not straightforward. For instance, the distance between the labeled set and the unlabeled one is not straightforward ( Viering et al., 2019 ). On the other hand,",
    ".. This is the reason. Active learning is a challenging task. On the one hand, some active learning methods introduce heuristic approaches. These heuristics provide theoretical guarantees on the target risk. However, the computation of the distribution distances is not straightforward. For instance, the distance between the labeled set and the unlabeled one is not straightforward ( Viering et al., 2019 ). On the other hand,",
    ".. This is the reason. Active learning is a challenging task. On the one hand, some active learning methods introduce heuristic approaches. These heuristics provide theoretical guarantees on the target risk. However, the computation of the distribution distances is not straightforward. For instance, the distance between the labeled set and the unlabeled one is not straightforward ( Viering et al., 2019 ). On the other hand,",
    "h1 1    hd d |b (  ). ( 1 ) In this work, singular learning theory is brought to bear on the challenge of performing inference in Bayesian neural networks. In particular, singular learning theory helps us understand the large-sample properties of the posterior distribution over neural network weights w  Rd. In this work, singular learning theory helps us understand the large-sample properties of the posterior",
    "h1 1    hd d |b (  ). ( 1 ) In this work, singular learning theory is brought to bear on the challenge of performing inference in Bayesian neural networks. In particular, singular learning theory helps us understand the large-sample properties of the posterior distribution over neural network weights w  Rd. In this work, singular learning theory helps us understand the large-sample properties of the posterior",
    "h1 1    hd d |b (  ). ( 1 ) In this work, singular learning theory is brought to bear on the challenge of performing inference in Bayesian neural networks. In particular, singular learning theory helps us understand the large-sample properties of the posterior distribution over neural network weights w  Rd. In this work, singular learning theory helps us understand the large-sample properties of the posterior",
    "h1 1    hd d |b (  ). ( 1 ) In this work, singular learning theory is brought to bear on the challenge of performing inference in Bayesian neural networks. In particular, singular learning theory helps us understand the large-sample properties of the posterior distribution over neural network weights w  Rd. In this work, singular learning theory helps us understand the large-sample properties of the posterior",
    ". This problem setting is known as domain generalisation ( DG ). This problem setting is difficult to model formally for principled derivation and theoretical analysis of algorithms. To make matters worse, a recent study by Gulrajani & Lopez-Paz ( 2021 ) assessed the state of machine learning research with a carefully conducted comparative evaluation of algorithms on a common platform. Intuitively, while the held-out domain of interest is unobservable during training",
    ". This problem setting is known as domain generalisation ( DG ). This problem setting is difficult to model formally for principled derivation and theoretical analysis of algorithms. To make matters worse, a recent study by Gulrajani & Lopez-Paz ( 2021 ) assessed the state of machine learning research with a carefully conducted comparative evaluation of algorithms on a common platform. Intuitively, while the held-out domain of interest is unobservable during training",
    ". This problem setting is known as domain generalisation ( DG ). This problem setting is difficult to model formally for principled derivation and theoretical analysis of algorithms. To make matters worse, a recent study by Gulrajani & Lopez-Paz ( 2021 ) assessed the state of machine learning research with a carefully conducted comparative evaluation of algorithms on a common platform. Intuitively, while the held-out domain of interest is unobservable during training",
    ". This problem setting is known as domain generalisation ( DG ). This problem setting is difficult to model formally for principled derivation and theoretical analysis of algorithms. To make matters worse, a recent study by Gulrajani & Lopez-Paz ( 2021 ) assessed the state of machine learning research with a carefully conducted comparative evaluation of algorithms on a common platform. Intuitively, while the held-out domain of interest is unobservable during training",
    "maximum n-times coverage is a generalization of the multi-set multi-cover problem, is NP-complete, and is not submodular. a log ( n ) time approximation algorithm for CIP solves the maximum n-times coverage problem. a log ( n ) time approximation algorithm for CIP solves the min-cost n-times coverage problem. a log ( n ) time approximation",
    "maximum n-times coverage is a generalization of the multi-set multi-cover problem, is NP-complete, and is not submodular. a log ( n ) time approximation algorithm for CIP solves the maximum n-times coverage problem. a log ( n ) time approximation algorithm for CIP solves the min-cost n-times coverage problem. a log ( n ) time approximation",
    "maximum n-times coverage is a generalization of the multi-set multi-cover problem, is NP-complete, and is not submodular. a log ( n ) time approximation algorithm for CIP solves the maximum n-times coverage problem. a log ( n ) time approximation algorithm for CIP solves the min-cost n-times coverage problem. a log ( n ) time approximation",
    "maximum n-times coverage is a generalization of the multi-set multi-cover problem, is NP-complete, and is not submodular. a log ( n ) time approximation algorithm for CIP solves the maximum n-times coverage problem. a log ( n ) time approximation algorithm for CIP solves the min-cost n-times coverage problem. a log ( n ) time approximation",
    "; ; LeCun et al., 2016 ). Moreover, spiking neural networks ( SNNs ) are increasing attracting from researchers. In addition, BPTT with surrogate functions is more friendly to the event-based datasets. In addition, BPTT with surrogate functions is more friendly to the event-based datasets. In addition, BPTT with surrogate functions is more friendly to the event-based dataset",
    "; ; LeCun et al., 2016 ). Moreover, spiking neural networks ( SNNs ) are increasing attracting from researchers. In addition, BPTT with surrogate functions is more friendly to the event-based datasets. In addition, BPTT with surrogate functions is more friendly to the event-based datasets. In addition, BPTT with surrogate functions is more friendly to the event-based dataset",
    "; ; LeCun et al., 2016 ). Moreover, spiking neural networks ( SNNs ) are increasing attracting from researchers. In addition, BPTT with surrogate functions is more friendly to the event-based datasets. In addition, BPTT with surrogate functions is more friendly to the event-based datasets. In addition, BPTT with surrogate functions is more friendly to the event-based dataset",
    "; ; LeCun et al., 2016 ). Moreover, spiking neural networks ( SNNs ) are increasing attracting from researchers. In addition, BPTT with surrogate functions is more friendly to the event-based datasets. In addition, BPTT with surrogate functions is more friendly to the event-based datasets. In addition, BPTT with surrogate functions is more friendly to the event-based dataset",
    "a mixture of distributions that gradually changes between daytime and nighttime modes. We find this intuitive model to better match the observations in practical federated learning systems. Specifically, cross-device FL has been used in practice to boost utility and privacy for applications such as next word prediction ( Wang et al., 2021 ).",
    "a mixture of distributions that gradually changes between daytime and nighttime modes. We find this intuitive model to better match the observations in practical federated learning systems. Specifically, cross-device FL has been used in practice to boost utility and privacy for applications such as next word prediction ( Wang et al., 2021 ).",
    "a mixture of distributions that gradually changes between daytime and nighttime modes. We find this intuitive model to better match the observations in practical federated learning systems. Specifically, cross-device FL has been used in practice to boost utility and privacy for applications such as next word prediction ( Wang et al., 2021 ).",
    "a mixture of distributions that gradually changes between daytime and nighttime modes. We find this intuitive model to better match the observations in practical federated learning systems. Specifically, cross-device FL has been used in practice to boost utility and privacy for applications such as next word prediction ( Wang et al., 2021 ).",
    ", 2018 ).........., 2018 ). Deep Networks ( DNs ) are powerful and versatile function approximators that have reached outstanding performances across various tasks... ,  , 2019 )..,.., to",
    ", 2018 ).........., 2018 ). Deep Networks ( DNs ) are powerful and versatile function approximators that have reached outstanding performances across various tasks... ,  , 2019 )..,.., to",
    ", 2018 ).........., 2018 ). Deep Networks ( DNs ) are powerful and versatile function approximators that have reached outstanding performances across various tasks... ,  , 2019 )..,.., to",
    ", 2018 ).........., 2018 ). Deep Networks ( DNs ) are powerful and versatile function approximators that have reached outstanding performances across various tasks... ,  , 2019 )..,.., to",
    ". Specifically, the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. With the rapid advancement of representation learning ( LeCun et al., 2015 ), the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. Specifically, the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. For example, at a given predicted healthcare need score  = t, Black patients are more likely to",
    ". Specifically, the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. With the rapid advancement of representation learning ( LeCun et al., 2015 ), the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. Specifically, the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. For example, at a given predicted healthcare need score  = t, Black patients are more likely to",
    ". Specifically, the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. With the rapid advancement of representation learning ( LeCun et al., 2015 ), the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. Specifically, the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. For example, at a given predicted healthcare need score  = t, Black patients are more likely to",
    ". Specifically, the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. With the rapid advancement of representation learning ( LeCun et al., 2015 ), the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. Specifically, the learned fair representation can easily transfer the unbiased prior knowledge to the downstream tasks. For example, at a given predicted healthcare need score  = t, Black patients are more likely to",
    "we will refer to this set of approaches as RL VIA SUPERVISED LEARNING ( RVS ). While conceptually simple, such methods can be difficult to apply in practice. Recent work has explored an appealing alternative approach : convert the RL problem into a conditional, filtered, or weighted imitation learning problem. These approaches most commonly conditioning on goals ( Lynch et al., 2020 ; Codevilla et al., 2018 ; Ding",
    "we will refer to this set of approaches as RL VIA SUPERVISED LEARNING ( RVS ). While conceptually simple, such methods can be difficult to apply in practice. Recent work has explored an appealing alternative approach : convert the RL problem into a conditional, filtered, or weighted imitation learning problem. These approaches most commonly conditioning on goals ( Lynch et al., 2020 ; Codevilla et al., 2018 ; Ding",
    "we will refer to this set of approaches as RL VIA SUPERVISED LEARNING ( RVS ). While conceptually simple, such methods can be difficult to apply in practice. Recent work has explored an appealing alternative approach : convert the RL problem into a conditional, filtered, or weighted imitation learning problem. These approaches most commonly conditioning on goals ( Lynch et al., 2020 ; Codevilla et al., 2018 ; Ding",
    "we will refer to this set of approaches as RL VIA SUPERVISED LEARNING ( RVS ). While conceptually simple, such methods can be difficult to apply in practice. Recent work has explored an appealing alternative approach : convert the RL problem into a conditional, filtered, or weighted imitation learning problem. These approaches most commonly conditioning on goals ( Lynch et al., 2020 ; Codevilla et al., 2018 ; Ding",
    ". We show that map induction can improve the performance of a POMDP planner during exploration. In this paper we introduce our computational model. We first review the literature on human spatial cognition involved in exploration in novel spaces. We then introduce our computational model. We show that map induction can improve the performance of a POMDP planner during exploration.",
    ". We show that map induction can improve the performance of a POMDP planner during exploration. In this paper we introduce our computational model. We first review the literature on human spatial cognition involved in exploration in novel spaces. We then introduce our computational model. We show that map induction can improve the performance of a POMDP planner during exploration.",
    ". We show that map induction can improve the performance of a POMDP planner during exploration. In this paper we introduce our computational model. We first review the literature on human spatial cognition involved in exploration in novel spaces. We then introduce our computational model. We show that map induction can improve the performance of a POMDP planner during exploration.",
    ". We show that map induction can improve the performance of a POMDP planner during exploration. In this paper we introduce our computational model. We first review the literature on human spatial cognition involved in exploration in novel spaces. We then introduce our computational model. We show that map induction can improve the performance of a POMDP planner during exploration.",
    ". The Markov random field ( MRF ) has been shown to be important in computational perception. It allows for modeling of non-causal relationships in a particular dataset. Data-driven approaches, however, are prone to noisy estimates and have limited capacity to represent uncertainty inherent in their estimates. Reducing the domain knowledge required by NBP methods would enable their use in a broader range of applications.",
    ". The Markov random field ( MRF ) has been shown to be important in computational perception. It allows for modeling of non-causal relationships in a particular dataset. Data-driven approaches, however, are prone to noisy estimates and have limited capacity to represent uncertainty inherent in their estimates. Reducing the domain knowledge required by NBP methods would enable their use in a broader range of applications.",
    ". The Markov random field ( MRF ) has been shown to be important in computational perception. It allows for modeling of non-causal relationships in a particular dataset. Data-driven approaches, however, are prone to noisy estimates and have limited capacity to represent uncertainty inherent in their estimates. Reducing the domain knowledge required by NBP methods would enable their use in a broader range of applications.",
    ". The Markov random field ( MRF ) has been shown to be important in computational perception. It allows for modeling of non-causal relationships in a particular dataset. Data-driven approaches, however, are prone to noisy estimates and have limited capacity to represent uncertainty inherent in their estimates. Reducing the domain knowledge required by NBP methods would enable their use in a broader range of applications.",
    "graph-based models can learn a distribution over drug-like molecules from raw data. In silico drug discovery requires navigating a vast chemical space. This poses challenges well beyond those solvable by brute-force search. Recently, deep learning models are becoming increasingly popular. graph-based models can learn a distribution over drug-like molecules from raw data. motifs can be used to build molecules fragment-by-fragment instead of atom-by-atom.",
    "graph-based models can learn a distribution over drug-like molecules from raw data. In silico drug discovery requires navigating a vast chemical space. This poses challenges well beyond those solvable by brute-force search. Recently, deep learning models are becoming increasingly popular. graph-based models can learn a distribution over drug-like molecules from raw data. motifs can be used to build molecules fragment-by-fragment instead of atom-by-atom.",
    "graph-based models can learn a distribution over drug-like molecules from raw data. In silico drug discovery requires navigating a vast chemical space. This poses challenges well beyond those solvable by brute-force search. Recently, deep learning models are becoming increasingly popular. graph-based models can learn a distribution over drug-like molecules from raw data. motifs can be used to build molecules fragment-by-fragment instead of atom-by-atom.",
    "graph-based models can learn a distribution over drug-like molecules from raw data. In silico drug discovery requires navigating a vast chemical space. This poses challenges well beyond those solvable by brute-force search. Recently, deep learning models are becoming increasingly popular. graph-based models can learn a distribution over drug-like molecules from raw data. motifs can be used to build molecules fragment-by-fragment instead of atom-by-atom.",
    ". a policy from demonstrations of expert behavior. In this paper, we show that, for deterministic experts, imitation learning can be done by reduction to reinforcement learning with a stationary reward. Adversarial IL learns a representation and a policy simultaneously by using a non-stationary reward obtained from a discriminator network. Adversarial IL learns a representation and a policy simultaneously by using a non-stationary reward obtained from a discrimin",
    ". a policy from demonstrations of expert behavior. In this paper, we show that, for deterministic experts, imitation learning can be done by reduction to reinforcement learning with a stationary reward. Adversarial IL learns a representation and a policy simultaneously by using a non-stationary reward obtained from a discriminator network. Adversarial IL learns a representation and a policy simultaneously by using a non-stationary reward obtained from a discrimin",
    ". a policy from demonstrations of expert behavior. In this paper, we show that, for deterministic experts, imitation learning can be done by reduction to reinforcement learning with a stationary reward. Adversarial IL learns a representation and a policy simultaneously by using a non-stationary reward obtained from a discriminator network. Adversarial IL learns a representation and a policy simultaneously by using a non-stationary reward obtained from a discrimin",
    ". a policy from demonstrations of expert behavior. In this paper, we show that, for deterministic experts, imitation learning can be done by reduction to reinforcement learning with a stationary reward. Adversarial IL learns a representation and a policy simultaneously by using a non-stationary reward obtained from a discriminator network. Adversarial IL learns a representation and a policy simultaneously by using a non-stationary reward obtained from a discrimin",
    "overparameterized models can achieve high test performance. However, when applied to modern overparameterized models, these methods could overfit very easily. Thus, when applied to modern overparameterized models, these methods could overfit very easily. Consequently, these methods could overfit very easily, so that they have poor test worst-group performance. For example, Sagawa et al. ( 2020a ) studied a reweighting algorithm called group D",
    "overparameterized models can achieve high test performance. However, when applied to modern overparameterized models, these methods could overfit very easily. Thus, when applied to modern overparameterized models, these methods could overfit very easily. Consequently, these methods could overfit very easily, so that they have poor test worst-group performance. For example, Sagawa et al. ( 2020a ) studied a reweighting algorithm called group D",
    "overparameterized models can achieve high test performance. However, when applied to modern overparameterized models, these methods could overfit very easily. Thus, when applied to modern overparameterized models, these methods could overfit very easily. Consequently, these methods could overfit very easily, so that they have poor test worst-group performance. For example, Sagawa et al. ( 2020a ) studied a reweighting algorithm called group D",
    "overparameterized models can achieve high test performance. However, when applied to modern overparameterized models, these methods could overfit very easily. Thus, when applied to modern overparameterized models, these methods could overfit very easily. Consequently, these methods could overfit very easily, so that they have poor test worst-group performance. For example, Sagawa et al. ( 2020a ) studied a reweighting algorithm called group D",
    ". In this paper, we introduce Rational Inattention Reinforcement Learning ( RIRL ), a MARL framework with agents that can be rationally inattentive. RIRL assumes that agents behave rationally and execute the objective-maximizing behavior. In this paper, we introduce Rational Inattention Reinforcement Learning ( RIRL ), a MARL framework with agents that can be rationally inattentive.",
    ". In this paper, we introduce Rational Inattention Reinforcement Learning ( RIRL ), a MARL framework with agents that can be rationally inattentive. RIRL assumes that agents behave rationally and execute the objective-maximizing behavior. In this paper, we introduce Rational Inattention Reinforcement Learning ( RIRL ), a MARL framework with agents that can be rationally inattentive.",
    ". In this paper, we introduce Rational Inattention Reinforcement Learning ( RIRL ), a MARL framework with agents that can be rationally inattentive. RIRL assumes that agents behave rationally and execute the objective-maximizing behavior. In this paper, we introduce Rational Inattention Reinforcement Learning ( RIRL ), a MARL framework with agents that can be rationally inattentive.",
    ". In this paper, we introduce Rational Inattention Reinforcement Learning ( RIRL ), a MARL framework with agents that can be rationally inattentive. RIRL assumes that agents behave rationally and execute the objective-maximizing behavior. In this paper, we introduce Rational Inattention Reinforcement Learning ( RIRL ), a MARL framework with agents that can be rationally inattentive.",
    "imperceptible adversarial examples. Since the structure of natural speech is highly complicated, these two types of algorithms face several challenges. \u2022 Waveform-oriented attacks are usually not imperceptible enough. \u2022 Waveform-oriented attacks are usually not imperceptible enough.",
    "imperceptible adversarial examples. Since the structure of natural speech is highly complicated, these two types of algorithms face several challenges. \u2022 Waveform-oriented attacks are usually not imperceptible enough. \u2022 Waveform-oriented attacks are usually not imperceptible enough.",
    "imperceptible adversarial examples. Since the structure of natural speech is highly complicated, these two types of algorithms face several challenges. \u2022 Waveform-oriented attacks are usually not imperceptible enough. \u2022 Waveform-oriented attacks are usually not imperceptible enough.",
    "imperceptible adversarial examples. Since the structure of natural speech is highly complicated, these two types of algorithms face several challenges. \u2022 Waveform-oriented attacks are usually not imperceptible enough. \u2022 Waveform-oriented attacks are usually not imperceptible enough.",
    "DirectPred.. DirectCopy (  ).... self-supervised learning ( abbreviated as nc-SSL ) shows comparable ( or even better ) performance for downstream tasks ( e.g., image classification ). 2 INTRODUCTION. In our work, we show that DirectSet (  ) learns representations by minimizing the distance between two views. Our",
    "DirectPred.. DirectCopy (  ).... self-supervised learning ( abbreviated as nc-SSL ) shows comparable ( or even better ) performance for downstream tasks ( e.g., image classification ). 2 INTRODUCTION. In our work, we show that DirectSet (  ) learns representations by minimizing the distance between two views. Our",
    "DirectPred.. DirectCopy (  ).... self-supervised learning ( abbreviated as nc-SSL ) shows comparable ( or even better ) performance for downstream tasks ( e.g., image classification ). 2 INTRODUCTION. In our work, we show that DirectSet (  ) learns representations by minimizing the distance between two views. Our",
    "DirectPred.. DirectCopy (  ).... self-supervised learning ( abbreviated as nc-SSL ) shows comparable ( or even better ) performance for downstream tasks ( e.g., image classification ). 2 INTRODUCTION. In our work, we show that DirectSet (  ) learns representations by minimizing the distance between two views. Our",
    "exploding and vanishing gradients problem has received considerable attention in the literature. One approach relies on enforcing the hidden state gradients of the underlying recurrent neural networks ( RNNs ). This might lead to significantly reduced expressivity, i.e., the ability of the model to learn complicated inputoutput maps.",
    "exploding and vanishing gradients problem has received considerable attention in the literature. One approach relies on enforcing the hidden state gradients of the underlying recurrent neural networks ( RNNs ). This might lead to significantly reduced expressivity, i.e., the ability of the model to learn complicated inputoutput maps.",
    "exploding and vanishing gradients problem has received considerable attention in the literature. One approach relies on enforcing the hidden state gradients of the underlying recurrent neural networks ( RNNs ). This might lead to significantly reduced expressivity, i.e., the ability of the model to learn complicated inputoutput maps.",
    "exploding and vanishing gradients problem has received considerable attention in the literature. One approach relies on enforcing the hidden state gradients of the underlying recurrent neural networks ( RNNs ). This might lead to significantly reduced expressivity, i.e., the ability of the model to learn complicated inputoutput maps.",
    ".. geometric deep learning..., atoms in a molecule, atoms in a molecule, or molecules in a molecule.... molecule, or data... ...,,,....,molecule",
    ".. geometric deep learning..., atoms in a molecule, atoms in a molecule, or molecules in a molecule.... molecule, or data... ...,,,....,molecule",
    ".. geometric deep learning..., atoms in a molecule, atoms in a molecule, or molecules in a molecule.... molecule, or data... ...,,,....,molecule",
    ".. geometric deep learning..., atoms in a molecule, atoms in a molecule, or molecules in a molecule.... molecule, or data... ...,,,....,molecule",
    "a retailer seeks to find the most cost-effective suborder-warehouse assignment policy that minimizes the overall cost in the order fulfillment. a good fulfillment policy could reduce expenses by millions of dollars for large online retailers such as Alibaba and Amazon. a good fulfillment policy could reduce expenses by millions of dollars for large online retailers such as Alibaba and Amazon.",
    "a retailer seeks to find the most cost-effective suborder-warehouse assignment policy that minimizes the overall cost in the order fulfillment. a good fulfillment policy could reduce expenses by millions of dollars for large online retailers such as Alibaba and Amazon. a good fulfillment policy could reduce expenses by millions of dollars for large online retailers such as Alibaba and Amazon.",
    "a retailer seeks to find the most cost-effective suborder-warehouse assignment policy that minimizes the overall cost in the order fulfillment. a good fulfillment policy could reduce expenses by millions of dollars for large online retailers such as Alibaba and Amazon. a good fulfillment policy could reduce expenses by millions of dollars for large online retailers such as Alibaba and Amazon.",
    "a retailer seeks to find the most cost-effective suborder-warehouse assignment policy that minimizes the overall cost in the order fulfillment. a good fulfillment policy could reduce expenses by millions of dollars for large online retailers such as Alibaba and Amazon. a good fulfillment policy could reduce expenses by millions of dollars for large online retailers such as Alibaba and Amazon.",
    "abstractive approaches focus on using the seen words in a conversation to summarize it. While extractive approaches focus on using the seen words in a conversation to summarize it, abstractive approaches usually use a text generation model to perform summarization. This kind of out-of-context inference is a language phenomenon in the field of pragmatics ground truth summarizations. To the best of our knowledge, neither evaluation metrics nor suitable methods are available for such kind of out-of-",
    "abstractive approaches focus on using the seen words in a conversation to summarize it. While extractive approaches focus on using the seen words in a conversation to summarize it, abstractive approaches usually use a text generation model to perform summarization. This kind of out-of-context inference is a language phenomenon in the field of pragmatics ground truth summarizations. To the best of our knowledge, neither evaluation metrics nor suitable methods are available for such kind of out-of-",
    "abstractive approaches focus on using the seen words in a conversation to summarize it. While extractive approaches focus on using the seen words in a conversation to summarize it, abstractive approaches usually use a text generation model to perform summarization. This kind of out-of-context inference is a language phenomenon in the field of pragmatics ground truth summarizations. To the best of our knowledge, neither evaluation metrics nor suitable methods are available for such kind of out-of-",
    "previously unseen entities and the attributes correspond to the contexts in which these entities occur. In the case of zero-shot learning, the entities correspond to category prototypes and the attributes correspond to the associated topics and words. In the case of attribute embeddings, the entities correspond to documents and the attributes correspond to the associated topics and words. This is an important advantage of attribute embeddings because they can implicitly capture some of the dependencies that hold between the attributes.",
    "previously unseen entities and the attributes correspond to the contexts in which these entities occur. In the case of zero-shot learning, the entities correspond to category prototypes and the attributes correspond to the associated topics and words. In the case of attribute embeddings, the entities correspond to documents and the attributes correspond to the associated topics and words. This is an important advantage of attribute embeddings because they can implicitly capture some of the dependencies that hold between the attributes.",
    "previously unseen entities and the attributes correspond to the contexts in which these entities occur. In the case of zero-shot learning, the entities correspond to category prototypes and the attributes correspond to the associated topics and words. In the case of attribute embeddings, the entities correspond to documents and the attributes correspond to the associated topics and words. This is an important advantage of attribute embeddings because they can implicitly capture some of the dependencies that hold between the attributes.",
    ". In recent years, language models have achieved impressive results on a variety of NLP tasks. These tasks include recognizing textual entailment, machine reading comprehension, and machine translation. However, if we start relying on such language models, there is the danger that we obtain good responses only in common test settings.",
    ". In recent years, language models have achieved impressive results on a variety of NLP tasks. These tasks include recognizing textual entailment, machine reading comprehension, and machine translation. However, if we start relying on such language models, there is the danger that we obtain good responses only in common test settings.",
    ". In recent years, language models have achieved impressive results on a variety of NLP tasks. These tasks include recognizing textual entailment, machine reading comprehension, and machine translation. However, if we start relying on such language models, there is the danger that we obtain good responses only in common test settings.",
    "an evaluation scheme to test the degree a learner can apply previously learned knowledge to solve new problems. In this paper, we introduce the compositional recursive learner, a framework for sequentially composing representation transformations that each solve a subproblem of a larger problem. In this paper, we propose compositional generalization as an evaluation scheme to test the degree a learner can apply previously learned knowledge to solve new problems.",
    "an evaluation scheme to test the degree a learner can apply previously learned knowledge to solve new problems. In this paper, we introduce the compositional recursive learner, a framework for sequentially composing representation transformations that each solve a subproblem of a larger problem. In this paper, we propose compositional generalization as an evaluation scheme to test the degree a learner can apply previously learned knowledge to solve new problems.",
    "....., 2016 ).., 2016 ; Reagen et al., 2016 ). et al., 2016 ). et al., 2016 ;, 2016 )... . .......",
    "....., 2016 ).., 2016 ; Reagen et al., 2016 ). et al., 2016 ). et al., 2016 ;, 2016 )... . .......",
    ". When the focus is on discovery, feature selection methods typically focus on trying to control either the Family-Wise Error Rate ( FWER ) or the False Discovery Rate ( FDR ). The knockoff framework is an innovative FDR-controlling feature selection method. Knockoffs can be used to select a set of candidate features for further investigation. Knockoffs can be used to select a set of candidate features for further investigation. Knockoffs can",
    ". When the focus is on discovery, feature selection methods typically focus on trying to control either the Family-Wise Error Rate ( FWER ) or the False Discovery Rate ( FDR ). The knockoff framework is an innovative FDR-controlling feature selection method. Knockoffs can be used to select a set of candidate features for further investigation. Knockoffs can be used to select a set of candidate features for further investigation. Knockoffs can",
    "1 INTRODUCTION. Deep convolutional neural networks ( CNNs ) have been ubiquitously utilized in various application domains. However, their performance comes at the cost of a significant amount of computation. In this paper, we focus on the Winograd convolution. Pruning removes redundant weight parameters. On the other hand, Winograd convolution transforms the computation into different domains. The sparsity is much lower than what we need for improving computation performance",
    "1 INTRODUCTION. Deep convolutional neural networks ( CNNs ) have been ubiquitously utilized in various application domains. However, their performance comes at the cost of a significant amount of computation. In this paper, we focus on the Winograd convolution. Pruning removes redundant weight parameters. On the other hand, Winograd convolution transforms the computation into different domains. The sparsity is much lower than what we need for improving computation performance",
    ". Deep generative modelling has recently emerged as a suitable approach to this problem. The Generative Adversarial Network ( GAN ) has recently emerged as a powerful framework for modeling complex data distributions without having to approximate intractable likelihoods. In the formulation by Goodfellow et al. ( 2014 ), a GAN consists of two networks : a generator G that is trained to yield unique samples from the data distribution, and a discriminator D that",
    ". Deep generative modelling has recently emerged as a suitable approach to this problem. The Generative Adversarial Network ( GAN ) has recently emerged as a powerful framework for modeling complex data distributions without having to approximate intractable likelihoods. In the formulation by Goodfellow et al. ( 2014 ), a GAN consists of two networks : a generator G that is trained to yield unique samples from the data distribution, and a discriminator D that",
    "f ( z ) q ( z ) dz = Ezq ( z ) [ f ( z ) ] [ f ( z ) ] [ f ( z ) ] [ f ( z ) ] [ f ( z ) ] [ f ( z ) ] [ f ( z ) ) [ f ( z ) ]. (",
    "f ( z ) q ( z ) dz = Ezq ( z ) [ f ( z ) ] [ f ( z ) ] [ f ( z ) ] [ f ( z ) ] [ f ( z ) ] [ f ( z ) ] [ f ( z ) ) [ f ( z ) ]. (",
    ". In particular, modularity in the programming languages used by deep learning libraries revolutionizes the development, communication and deployment of DNNs. In particular, modularity in the programming languages used by deep learning libraries revolutionizes the development, communication and deployment of DNNs. In particular, modularity in the programming languages used by deep learning libraries revolutionizes the development, communication and deployment of DNNs. In particular, modularity in the programming languages used by deep learning libraries revolutionize",
    ". In particular, modularity in the programming languages used by deep learning libraries revolutionizes the development, communication and deployment of DNNs. In particular, modularity in the programming languages used by deep learning libraries revolutionizes the development, communication and deployment of DNNs. In particular, modularity in the programming languages used by deep learning libraries revolutionizes the development, communication and deployment of DNNs. In particular, modularity in the programming languages used by deep learning libraries revolutionize",
    "based on a saliency criterion that identifies connections in the network that are important to the given task in a data-dependent way before training. Since pruning is included as part of an iterative optimization procedure, all these methods require expensive prune \u2013 retrain cycles and heuristic design choices with additional hyperparameters. \u2022 Simplicity. Since the network is pruned once prior to training, there is no need for pretraining and complex pruning schedules.",
    "based on a saliency criterion that identifies connections in the network that are important to the given task in a data-dependent way before training. Since pruning is included as part of an iterative optimization procedure, all these methods require expensive prune \u2013 retrain cycles and heuristic design choices with additional hyperparameters. \u2022 Simplicity. Since the network is pruned once prior to training, there is no need for pretraining and complex pruning schedules.",
    ". In machine translation, Koehn & Knowles ( 2017 ) found that beam search \u201c only improves translation for narrow beams and deteriorates when exposed to a larger search space \u201d. In this work, we analyze the performance of beam search across multiple tasks including machine translation, abstractive summarization, and image captioning. We present an explanatory model that 1 \u201c Copies \u201d are predictions that share at least 50 % of their unigrams with",
    ". In machine translation, Koehn & Knowles ( 2017 ) found that beam search \u201c only improves translation for narrow beams and deteriorates when exposed to a larger search space \u201d. In this work, we analyze the performance of beam search across multiple tasks including machine translation, abstractive summarization, and image captioning. We present an explanatory model that 1 \u201c Copies \u201d are predictions that share at least 50 % of their unigrams with",
    ". We then move the starting point backward until the agent is training only on the initial state of the task. We call this technique Backplay. Our contributions are threefold. 1. We characterize analytically and qualitatively which environments Backplay will aid. 2. We empirically show that Backplay compares favorably to other methods that improve sample complexity. 4. We also empirically demonstrate that Backplay can outperform its demonstrator and even learn an optimal policy following a sub-opti",
    ". We then move the starting point backward until the agent is training only on the initial state of the task. We call this technique Backplay. Our contributions are threefold. 1. We characterize analytically and qualitatively which environments Backplay will aid. 2. We empirically show that Backplay compares favorably to other methods that improve sample complexity. 4. We also empirically demonstrate that Backplay can outperform its demonstrator and even learn an optimal policy following a sub-opti",
    ". Pruning algorithms aim at removing redundancies within their parameters. This has been widely exploited due to its simplicity and efficacy. In this paper, we propose a new pruning approach. Pruning algorithms differ on the pruning criteria employed. Pruning algorithms differ on the pruning criteria employed. Pruning algorithms differ on the pruning criteria employed. Pruning algorithms differ on the pruning criteria employed. Pruning algorithms differ on the pruning criteria employed.",
    ". Pruning algorithms aim at removing redundancies within their parameters. This has been widely exploited due to its simplicity and efficacy. In this paper, we propose a new pruning approach. Pruning algorithms differ on the pruning criteria employed. Pruning algorithms differ on the pruning criteria employed. Pruning algorithms differ on the pruning criteria employed. Pruning algorithms differ on the pruning criteria employed. Pruning algorithms differ on the pruning criteria employed.",
    ". Then, we quantify the causal effect of interventions to control objects in the output. Finally, we present an analytic framework to visualize and understand GANs at the unit-, object-, and scene-level. This framework provides open source interpretation tools to help researchers and practitioners better understand their GAN models.",
    ". Then, we quantify the causal effect of interventions to control objects in the output. Finally, we present an analytic framework to visualize and understand GANs at the unit-, object-, and scene-level. This framework provides open source interpretation tools to help researchers and practitioners better understand their GAN models.",
    "function space. If the two are tightly coupled, then parameter space can be taken as a proxy for function space. In the second setting we consider multitask learning. In the first setting we consider multitask learning. In the second setting we consider multitask learning. In the third setting we consider multitask learning. In the third setting we consider multitask learning. In the third setting we consider multitask learning. In the third setting we consider multitask learning. In the third setting we consider multitask",
    "function space. If the two are tightly coupled, then parameter space can be taken as a proxy for function space. In the second setting we consider multitask learning. In the first setting we consider multitask learning. In the second setting we consider multitask learning. In the third setting we consider multitask learning. In the third setting we consider multitask learning. In the third setting we consider multitask learning. In the third setting we consider multitask learning. In the third setting we consider multitask",
    "stochastic differential equations. Such processes can be considered conceptually as stochastic dynamic processes. In this paper, we propose to learn a generative neural network model of biological dynamic systems. DyMoN provides a representational advantage by serving as an embodiment of the dynamics in lieu of a predetermined model. This representation is deep and factored. It provides a generative advantage as it generates new trajectories that have not been seen previously in the system.",
    "stochastic differential equations. Such processes can be considered conceptually as stochastic dynamic processes. In this paper, we propose to learn a generative neural network model of biological dynamic systems. DyMoN provides a representational advantage by serving as an embodiment of the dynamics in lieu of a predetermined model. This representation is deep and factored. It provides a generative advantage as it generates new trajectories that have not been seen previously in the system.",
    "supervised learning with entire ground truth labels. In this paper, we propose a method to mimic such human capability. We first show that there exists a approximate linear map between two separated neural networks of Generative Adversarial Networks ( GANs ). Secondly, we prove that the number of classes k is the same as the number of classes in the original space in spectral clustering theory. By combining the results, We derive a novel unsupervised classification framework",
    "supervised learning with entire ground truth labels. In this paper, we propose a method to mimic such human capability. We first show that there exists a approximate linear map between two separated neural networks of Generative Adversarial Networks ( GANs ). Secondly, we prove that the number of classes k is the same as the number of classes in the original space in spectral clustering theory. By combining the results, We derive a novel unsupervised classification framework",
    "based on an idea explored in Vinyals et al. ( 2015a ). They find that some permutations of sets allow for easier learning on a task than others. They do this by ordering the set elements in some predetermined way and feeding the resulting sequence into a recurrent neural network. Our main contribution is a Permutation-Optimisation ( PO ) module that satisfies these requirements. it optimises a set in a way that",
    "based on an idea explored in Vinyals et al. ( 2015a ). They find that some permutations of sets allow for easier learning on a task than others. They do this by ordering the set elements in some predetermined way and feeding the resulting sequence into a recurrent neural network. Our main contribution is a Permutation-Optimisation ( PO ) module that satisfies these requirements. it optimises a set in a way that",
    "( 2017 ) ; Xu et al. ( 2017 ) ; Xu et al. ( 2017 ) ; Finn et al. ( 2017 ) ; Xu et al. ( 2017 ) ; Xu et al. ( 2017 ) ; Xu et al. ( 2017 ) ; Wang et al. ( 2018 ) ; Qiao",
    "( 2017 ) ; Xu et al. ( 2017 ) ; Xu et al. ( 2017 ) ; Finn et al. ( 2017 ) ; Xu et al. ( 2017 ) ; Xu et al. ( 2017 ) ; Xu et al. ( 2017 ) ; Wang et al. ( 2018 ) ; Qiao",
    "a key challenge in meta-learning is fast adaptation : learning on previously unseen tasks fast and with little data. We propose context adaptation for meta-learning ( CAML ), a new method for fast adaptation via meta-learning. Like MAML, CAML learns a model initialisation that can quickly be adapted to new tasks. but unlike many transfer learning algorithms, it adapts only a fraction of the model to the new task.",
    "a key challenge in meta-learning is fast adaptation : learning on previously unseen tasks fast and with little data. We propose context adaptation for meta-learning ( CAML ), a new method for fast adaptation via meta-learning. Like MAML, CAML learns a model initialisation that can quickly be adapted to new tasks. but unlike many transfer learning algorithms, it adapts only a fraction of the model to the new task.",
    "the user sanitizes the data, at the sensing and/or transmitting stage, without affecting the utility they need. We propose that a user and the service provider collaborate towards achieving userspecific privacy. This new paradigm of collaborative privacy environment is critical since it has also been shown that algorithmic or data augmentation and unpredictable correlations can break privacy.",
    "the user sanitizes the data, at the sensing and/or transmitting stage, without affecting the utility they need. We propose that a user and the service provider collaborate towards achieving userspecific privacy. This new paradigm of collaborative privacy environment is critical since it has also been shown that algorithmic or data augmentation and unpredictable correlations can break privacy.",
    "the discriminator becomes useless. In this work we introduce a new technique to overcome this problem - progressive augmentation of GANs ( PA-GAN ). PA-GAN helps to control the behaviour of the discriminator and thus improve its performance. PA-GAN is a new approach to improve the performance of GANs.",
    "the discriminator becomes useless. In this work we introduce a new technique to overcome this problem - progressive augmentation of GANs ( PA-GAN ). PA-GAN helps to control the behaviour of the discriminator and thus improve its performance. PA-GAN is a new approach to improve the performance of GANs.",
    "in area V1. In this paper, we introduce a convolutional neural network model of V1. We train this model directly on the responses of 6000 mouse V1 neurons. While we do not answer the biological question whether there are indeed well-defined clusters of functional cell types in V1, we provide the technical foundation by extending the work of Klindt and colleagues ( Klindt et al., 2017 ). We train this model directly on the responses of 6000",
    "in area V1. In this paper, we introduce a convolutional neural network model of V1. We train this model directly on the responses of 6000 mouse V1 neurons. While we do not answer the biological question whether there are indeed well-defined clusters of functional cell types in V1, we provide the technical foundation by extending the work of Klindt and colleagues ( Klindt et al., 2017 ). We train this model directly on the responses of 6000",
    ". In this work, we make the above aspirations rigorous. We posit the following desiderata : D1 fast algorithmic convergence ; D2 good generalisation performance ; D3 communication efficiency. As far as robustness, aggregating gradients by a majority vote denies any individual worker too much power, suggesting it may be a natural way to achieve D4. Whilst D1 is immmediate, D2 is immmediate. W",
    ". In this work, we make the above aspirations rigorous. We posit the following desiderata : D1 fast algorithmic convergence ; D2 good generalisation performance ; D3 communication efficiency. As far as robustness, aggregating gradients by a majority vote denies any individual worker too much power, suggesting it may be a natural way to achieve D4. Whilst D1 is immmediate, D2 is immmediate. W",
    "based on generative adversarial networks. We model the order stream as a stochastic process with finite history dependence. We employ a conditional Wasserstein GAN to capture history dependence of orders in a stock market. We test our approach with actual market and synthetic data. We find the generated data to be close to real data.",
    "based on generative adversarial networks. We model the order stream as a stochastic process with finite history dependence. We employ a conditional Wasserstein GAN to capture history dependence of orders in a stock market. We test our approach with actual market and synthetic data. We find the generated data to be close to real data.",
    "arbitrary noise. For instance, sensors on a robot will be affected by physical conditions such as temperature and lighting. This way the RL agent ( machine ) will obtain reward with bias. In this paper, we develop an unbiased reward estimator aided robust framework that enables an RL agent to learn in a noisy environment with observing only perturbed rewards.",
    "arbitrary noise. For instance, sensors on a robot will be affected by physical conditions such as temperature and lighting. This way the RL agent ( machine ) will obtain reward with bias. In this paper, we develop an unbiased reward estimator aided robust framework that enables an RL agent to learn in a noisy environment with observing only perturbed rewards.",
    "a powerlaw region within which the number of gradient updates to convergence has a reciprocal relationship to model size. In this paper, we present a variety of experiments designed to characterize the effect of width on error surface. These experiments are designed to qualitatively answer simple questions. ( 1 ) direct distance from initial weight to final weights shrinks. ( 3 ) total path length traveled gets shrinks. ( 4 ) step size gets larger. ( 5 ) step size gets larger.",
    "a powerlaw region within which the number of gradient updates to convergence has a reciprocal relationship to model size. In this paper, we present a variety of experiments designed to characterize the effect of width on error surface. These experiments are designed to qualitatively answer simple questions. ( 1 ) direct distance from initial weight to final weights shrinks. ( 3 ) total path length traveled gets shrinks. ( 4 ) step size gets larger. ( 5 ) step size gets larger.",
    ". 1.1 INPUT LENGTH INDEPENDENCE AND THE CONNECTION TO RL. In this paper, we explore whether machine learning can be used to learn algorithms for classic combinatorial optimization problems. 1.1 INPUT LENGTH INDEPENDENCE AND THE CONNECTION TO RL. 1.2 INPUT LENGTH INDEPENDENCE AND THE CONNECTION TO RL. 1.3 INPUT LENGTH INDEPENDENCE",
    ". 1.1 INPUT LENGTH INDEPENDENCE AND THE CONNECTION TO RL. In this paper, we explore whether machine learning can be used to learn algorithms for classic combinatorial optimization problems. 1.1 INPUT LENGTH INDEPENDENCE AND THE CONNECTION TO RL. 1.2 INPUT LENGTH INDEPENDENCE AND THE CONNECTION TO RL. 1.3 INPUT LENGTH INDEPENDENCE",
    "... The system with adaptive components performed better on many of the tasks. As hypothesized, the system with adaptive components performed better on many of the tasks. This trade-off is relevant because these inductive biases are not free. This trade-off is relevant because these inductive biases are not free. In this paper, we re-examine several domain-specific components that modify the agent \u2019 s objective and its interface to the environment.",
    "... The system with adaptive components performed better on many of the tasks. As hypothesized, the system with adaptive components performed better on many of the tasks. This trade-off is relevant because these inductive biases are not free. This trade-off is relevant because these inductive biases are not free. In this paper, we re-examine several domain-specific components that modify the agent \u2019 s objective and its interface to the environment.",
    "\u201d Exit the bedroom and go towards the table. Go to the stairs on the left of the couch. Wait on the third step. \u201d. In Fig. 1, the agent is expected to \u201d Go to the stairs \u201d after completing \u201d go towards the table \u201d. Intuitively, the agent is expected to \u201d Go to the stairs \u201d after completing \u201d go towards the table \u201d. Intuitively, the agent is expected to",
    "\u201d Exit the bedroom and go towards the table. Go to the stairs on the left of the couch. Wait on the third step. \u201d. In Fig. 1, the agent is expected to \u201d Go to the stairs \u201d after completing \u201d go towards the table \u201d. Intuitively, the agent is expected to \u201d Go to the stairs \u201d after completing \u201d go towards the table \u201d. Intuitively, the agent is expected to",
    ". In particular, the semantic information, which is typically well-defined in the target DSL, is not effectively leveraged by existing work. In this work, we develop simple yet principled techniques that can be combined with any existing encoder-decoder-style neural program synthesizers. The main novel technique is called execution-guided synthesis. The main idea is to view the program execution as a sequence of manipulations to transform each input state into the corresponding output state",
    ". In particular, the semantic information, which is typically well-defined in the target DSL, is not effectively leveraged by existing work. In this work, we develop simple yet principled techniques that can be combined with any existing encoder-decoder-style neural program synthesizers. The main novel technique is called execution-guided synthesis. The main idea is to view the program execution as a sequence of manipulations to transform each input state into the corresponding output state",
    ". In particular, we show that BNGD converges for any constant learning rate   ( 0, 1 ], regardless of the conditioning of the regression problem. This is in stark contrast with GD, where the condition number of the regression problem adversely affects stability and convergence. In particular, we show that BNGD converges for any constant learning rate   ( 0, 1 ), regardless of the conditioning of the regression problem",
    ". In particular, we show that BNGD converges for any constant learning rate   ( 0, 1 ], regardless of the conditioning of the regression problem. This is in stark contrast with GD, where the condition number of the regression problem adversely affects stability and convergence. In particular, we show that BNGD converges for any constant learning rate   ( 0, 1 ), regardless of the conditioning of the regression problem",
    "..... ( 2017 ) derived connections between data noising and smoothing. We empirically verify our analysis on two benchmark language modeling datasets and demonstrate performance improvements over existing methods. In particular, we propose variational smoothing with tied input and output embedding matrices and an element-wise variational smoothing method. In particular, we demonstrate performance improvements on downstream models such as machine translation. Xie et al",
    "..... ( 2017 ) derived connections between data noising and smoothing. We empirically verify our analysis on two benchmark language modeling datasets and demonstrate performance improvements over existing methods. In particular, we propose variational smoothing with tied input and output embedding matrices and an element-wise variational smoothing method. In particular, we demonstrate performance improvements on downstream models such as machine translation. Xie et al",
    "a classifier-agnostic saliency map extraction. This approach outperforms existing weakly-supervised localization techniques. For instance, Selvaraju et al. ( 2017 ) propose averaging multiple saliency maps created for perturbed images to obtain a smooth saliency map. We observe that the proposed approach extracts higher quality saliency maps and outperforms existing weakly-supervised localization techniques. 1 INTRODUCTION",
    "a classifier-agnostic saliency map extraction. This approach outperforms existing weakly-supervised localization techniques. For instance, Selvaraju et al. ( 2017 ) propose averaging multiple saliency maps created for perturbed images to obtain a smooth saliency map. We observe that the proposed approach extracts higher quality saliency maps and outperforms existing weakly-supervised localization techniques. 1 INTRODUCTION",
    ".... ( 2017 ) ; Teh et al. ( 2017 ) ; Parisotto et al. ( 2016 ).... ( 2017 ) ;.. .,. ; ; ; ( 2015 ) ;  ( 2015 ) ; .",
    ".... ( 2017 ) ; Teh et al. ( 2017 ) ; Parisotto et al. ( 2016 ).... ( 2017 ) ;.. .,. ; ; ; ( 2015 ) ;  ( 2015 ) ; .",
    "faster. With the increase in the size of data, the complexity of the accurate models also increases. Thus, the compact modeling of time-varying complex systems1 is a challenging task and appealing for more investigation. In this work, we interpret complex systems ( networks ) as graphs comprising of nodes interacting spatially and temporally. how the most relevant information propagates across nodes interacting spatially and temporally. how the most relevant information also gets transformed at each hop in an",
    "faster. With the increase in the size of data, the complexity of the accurate models also increases. Thus, the compact modeling of time-varying complex systems1 is a challenging task and appealing for more investigation. In this work, we interpret complex systems ( networks ) as graphs comprising of nodes interacting spatially and temporally. how the most relevant information propagates across nodes interacting spatially and temporally. how the most relevant information also gets transformed at each hop in an",
    "a problem of learning all conditional distributions of the form p ( x|y ). This problem generalizes both learning the joint distribution p ( x ) and learning the conditional distribution p ( x|y ). In this paper, we consider two most natural applications of the proposed model. The first is feature imputation where the goal is to restore the missing features given the observed ones. Another application is image inpainting in which the goal is to fill",
    "a problem of learning all conditional distributions of the form p ( x|y ). This problem generalizes both learning the joint distribution p ( x ) and learning the conditional distribution p ( x|y ). In this paper, we consider two most natural applications of the proposed model. The first is feature imputation where the goal is to restore the missing features given the observed ones. Another application is image inpainting in which the goal is to fill",
    "more stable. In particular, smaller batches are not able to fit in memory and be processed as a batch on a single GPU. In this paper, we propose an algorithm that computes reasonably approximate gradients, while significantly reducing a network's memory footprint. Moreover, smaller batches also complicate the use of batch-normalization ( Ioffe & Szegedy, 2015 ). In particular, deep residual networks for large images drop resolution early, so",
    "more stable. In particular, smaller batches are not able to fit in memory and be processed as a batch on a single GPU. In this paper, we propose an algorithm that computes reasonably approximate gradients, while significantly reducing a network's memory footprint. Moreover, smaller batches also complicate the use of batch-normalization ( Ioffe & Szegedy, 2015 ). In particular, deep residual networks for large images drop resolution early, so",
    "; Barnes et al., 2009 ; Denton et al., 2016 ; Yang et al., 2016 ; Denton et al., 2016 ; Yang et al., 2016 ). In the first paradigm, texture synthesis or patch matching are usually used. In the second paradigm, we adopt the data distribution based generative method and focus on human face completion. Three important issues are addressed. First,",
    "; Barnes et al., 2009 ; Denton et al., 2016 ; Yang et al., 2016 ; Denton et al., 2016 ; Yang et al., 2016 ). In the first paradigm, texture synthesis or patch matching are usually used. In the second paradigm, we adopt the data distribution based generative method and focus on human face completion. Three important issues are addressed. First,",
    ". In the context of deep learning, reduced precision deep learning has attracted the attention of both hardware and algorithms researchers. First, it offers well defined and scalable hardware efficiency. Second, it offers well defined and scalable hardware efficiency. Third, it offers well defined and scalable hardware efficiency. Fourth, it offers well defined and scalable hardware efficiency. Fourth, it offers well defined and scalable hardware efficiency. Work done while at IBM Research. Work done while",
    ". In the context of deep learning, reduced precision deep learning has attracted the attention of both hardware and algorithms researchers. First, it offers well defined and scalable hardware efficiency. Second, it offers well defined and scalable hardware efficiency. Third, it offers well defined and scalable hardware efficiency. Fourth, it offers well defined and scalable hardware efficiency. Fourth, it offers well defined and scalable hardware efficiency. Work done while at IBM Research. Work done while",
    "............. This paper analyzes the implicit regularization of gradient descent and gradient flow on deep linear networks and linearly separable data..............................",
    "............. This paper analyzes the implicit regularization of gradient descent and gradient flow on deep linear networks and linearly separable data..............................",
    "an adversarial discriminator. However, the HRED system suffers from lack of diversity. For example, Li et al. ( 2016b ) integrates attribute embeddings into a single turn ( Seq2Seq ) generative dialogue model. However, there has been some recent work on introducing persona into dialogue models. For example, Li et al. ( 2016b ) integrates attribute embeddings into a single",
    "an adversarial discriminator. However, the HRED system suffers from lack of diversity. For example, Li et al. ( 2016b ) integrates attribute embeddings into a single turn ( Seq2Seq ) generative dialogue model. However, there has been some recent work on introducing persona into dialogue models. For example, Li et al. ( 2016b ) integrates attribute embeddings into a single",
    "Developing agents that can interact with humans in natural language while perceiving and taking actions in their environments is one of the fundamental goals in artificial intelligence. building agents that can interact with humans in natural language while perceiving and taking actions in their environments is one of the fundamental goals in artificial intelligence.",
    "Developing agents that can interact with humans in natural language while perceiving and taking actions in their environments is one of the fundamental goals in artificial intelligence. building agents that can interact with humans in natural language while perceiving and taking actions in their environments is one of the fundamental goals in artificial intelligence.",
    "undirected generative models. This paper aims to advance the learning of neural random fields ( RFs ). These models use neural networks with multiple ( deterministic ) layers of stochastic or deterministic variables to define the potential function p ( x ) over observation x with parameter . The probability distribution p ( x )  exp ( u ( x )  exp ( u ( x ) ) is then",
    "undirected generative models. This paper aims to advance the learning of neural random fields ( RFs ). These models use neural networks with multiple ( deterministic ) layers of stochastic or deterministic variables to define the potential function p ( x ) over observation x with parameter . The probability distribution p ( x )  exp ( u ( x )  exp ( u ( x ) ) is then",
    "given a single ( attributed ) network and a subset of nodes whose class labels are known ( e.g., the topic of a paper in a citation graph ), the goal is to infer the classes of the unlabeled nodes. While there exist many classical approaches to node classification, recent works have also shown that such approaches are vulnerable to adversarial attacks both at test time ( evasion ) and training time ( poisoning attacks )",
    "given a single ( attributed ) network and a subset of nodes whose class labels are known ( e.g., the topic of a paper in a citation graph ), the goal is to infer the classes of the unlabeled nodes. While there exist many classical approaches to node classification, recent works have also shown that such approaches are vulnerable to adversarial attacks both at test time ( evasion ) and training time ( poisoning attacks )",
    "WAE-GAN requires a separate optimization problem to approximate the used divergence measure. In WAE-MMD the discriminator has a closed-form for the distance of a sample from the standard multivariate normal distribution. In SWAE we introduce the CramerWold distance between distributions, which has a closed-form for the distance of a sample from the standard multivariate normal distribution. We use it to construct a significantly simpler AutoEncoder based generative model",
    "WAE-GAN requires a separate optimization problem to approximate the used divergence measure. In WAE-MMD the discriminator has a closed-form for the distance of a sample from the standard multivariate normal distribution. In SWAE we introduce the CramerWold distance between distributions, which has a closed-form for the distance of a sample from the standard multivariate normal distribution. We use it to construct a significantly simpler AutoEncoder based generative model",
    "many-shot ). This \u201c many-shot \u201d problem is very common in various applications. For example, in image search, the number of candidate classes can easily range from hundreds to tens of thousands ( i.e., many-class ). However, the training samples available for each class can be less than 100 ( i.e., few-shot ). This \u201c many-class few-shot \u201d problem is very common in various applications.",
    "many-shot ). This \u201c many-shot \u201d problem is very common in various applications. For example, in image search, the number of candidate classes can easily range from hundreds to tens of thousands ( i.e., many-class ). However, the training samples available for each class can be less than 100 ( i.e., few-shot ). This \u201c many-class few-shot \u201d problem is very common in various applications.",
    "hard attention completely ignores part of the input sequence. With soft attention, all inputs are read, but the attention mechanism is fully differentiable. In comparison, hard attention completely ignores part of the input sequence. This is often denoted as speed reading : obtaining the same accuracy while using ( far ) fewer FLOPs. This is often denoted as speed reading : obtaining the same accuracy while using ( far ) fewer FLOPs.",
    "hard attention completely ignores part of the input sequence. With soft attention, all inputs are read, but the attention mechanism is fully differentiable. In comparison, hard attention completely ignores part of the input sequence. This is often denoted as speed reading : obtaining the same accuracy while using ( far ) fewer FLOPs. This is often denoted as speed reading : obtaining the same accuracy while using ( far ) fewer FLOPs.",
    "deep convolutional neural networks ( CNNs ) can be highly vulnerable to adversarial perturbations Szegedy et al. ( 2013 ) ; Goodfellow et al. ( 2015 ). However, these defense techniques are not completely effective against adversarial attacks. Data-level methods include adversarial training Szegedy et al. ( 2013 ) ; Goodfellow et al. ( 2015 ). Algorith",
    "deep convolutional neural networks ( CNNs ) can be highly vulnerable to adversarial perturbations Szegedy et al. ( 2013 ) ; Goodfellow et al. ( 2015 ). However, these defense techniques are not completely effective against adversarial attacks. Data-level methods include adversarial training Szegedy et al. ( 2013 ) ; Goodfellow et al. ( 2015 ). Algorith",
    ", 2017b ). However, most reinforcement learning algorithms explore with stochasticity in stepwise action space and suffer from low learning efficiency when state and action spaces are intractable. This requires complex additional structures and strong human priors when state and action spaces are intractable. This inspires one to disentangle policy stochasticity, with a structure of time scales. In this way, agents can learn to explore with stochasticity in stepwise action space.",
    ", 2017b ). However, most reinforcement learning algorithms explore with stochasticity in stepwise action space and suffer from low learning efficiency when state and action spaces are intractable. This requires complex additional structures and strong human priors when state and action spaces are intractable. This inspires one to disentangle policy stochasticity, with a structure of time scales. In this way, agents can learn to explore with stochasticity in stepwise action space.",
    "the Jacobian eigenvalue. Depending on the metric used, different strategies arise for combating vanishing gradients. In particular, the exploding / vanishing gradient problem has been a major challenge for building very deep neural networks. While the papers cited above provide much evidence that gradient explosion / vanishing when defined according to some metrics is associated with poor performance. 1. We introduce the nonlinearity coefficient ( NLC ), a",
    "the Jacobian eigenvalue. Depending on the metric used, different strategies arise for combating vanishing gradients. In particular, the exploding / vanishing gradient problem has been a major challenge for building very deep neural networks. While the papers cited above provide much evidence that gradient explosion / vanishing when defined according to some metrics is associated with poor performance. 1. We introduce the nonlinearity coefficient ( NLC ), a",
    ". Bias amplification occurs when the distribution over prediction outputs is skewed in comparison to the prior distribution of the prediction target. Aside from being problematic for accuracy, this phenomenon is also potentially concerning as it relates to the fairness of a model\u2019 s predictions. Interestingly, linear classifiers trained with gradient descent tend to overestimate the importance of moderately-predictive, or \u201c weak, \u201d features if insufficient training data is available.",
    ". Bias amplification occurs when the distribution over prediction outputs is skewed in comparison to the prior distribution of the prediction target. Aside from being problematic for accuracy, this phenomenon is also potentially concerning as it relates to the fairness of a model\u2019 s predictions. Interestingly, linear classifiers trained with gradient descent tend to overestimate the importance of moderately-predictive, or \u201c weak, \u201d features if insufficient training data is available.",
    ".. This is surprising given the conventional wisdom on the trade-off between model capacity and generalization. We propose a different route towards understanding generalization : making the regularization explicit. The motivations are : 1 ) with an explicit regularizer, we can analyze generalization without fully understanding optimization ; 2 ) it is unknown if the explicit regularizer can be used to analyze generalization without fully understanding optimization.",
    ".. This is surprising given the conventional wisdom on the trade-off between model capacity and generalization. We propose a different route towards understanding generalization : making the regularization explicit. The motivations are : 1 ) with an explicit regularizer, we can analyze generalization without fully understanding optimization ; 2 ) it is unknown if the explicit regularizer can be used to analyze generalization without fully understanding optimization.",
    ". However, in real-life, images contain multiple distinct objects at different locations within the image. In this paper, we propose a model that does not require a full semantic layout. This allows us to model images that contain multiple distinct objects at different locations within the image and with different relations to each other. In this paper, we propose a model that does not require a full semantic layout, but instead only requires the desired object locations and identities ( see Figure 1 ).",
    ". However, in real-life, images contain multiple distinct objects at different locations within the image. In this paper, we propose a model that does not require a full semantic layout. This allows us to model images that contain multiple distinct objects at different locations within the image and with different relations to each other. In this paper, we propose a model that does not require a full semantic layout, but instead only requires the desired object locations and identities ( see Figure 1 ).",
    "global model methods, where models are used for planning and then backpropagate through those predictions. In contrast, local model methods, where simple models provide gradient directions that are used for policy improvement, use linear models. As illustrated in Figure 1, we devise an efficient local model method based on the linear-quadratic regulator ( LQR ) ( Camacho & Bordons, 1997 ; Todorov & Li, 2005 ; Levine & Ab",
    "global model methods, where models are used for planning and then backpropagate through those predictions. In contrast, local model methods, where simple models provide gradient directions that are used for policy improvement, use linear models. As illustrated in Figure 1, we devise an efficient local model method based on the linear-quadratic regulator ( LQR ) ( Camacho & Bordons, 1997 ; Todorov & Li, 2005 ; Levine & Ab",
    "re-evaluating her decision in this way. She could and should have known that a2 was a better choice had she only interpreted the cues during the interview correctly. In this way, she concludes that she made a regrettable decision. In this paper, we propose the Counterfactually-Guided Policy Search ( CF-GPS ) algorithm. CF-GPS is based on structural causal models ( SCMs ) that predict alternate outcomes of past",
    "re-evaluating her decision in this way. She could and should have known that a2 was a better choice had she only interpreted the cues during the interview correctly. In this way, she concludes that she made a regrettable decision. In this paper, we propose the Counterfactually-Guided Policy Search ( CF-GPS ) algorithm. CF-GPS is based on structural causal models ( SCMs ) that predict alternate outcomes of past",
    "Fig. 1 ( a ) shows the ineffectiveness of generalization estimation in parameter space and the potential in input space. However, the loss increments introduced by adversarial noises can be well reflected in the loss surface in input space as visualized in Fig. 1 ( b ). the differences in Fig. 1 suggest the ineffectiveness of generalization estimation in parameter space and the potential in input space.",
    "Fig. 1 ( a ) shows the ineffectiveness of generalization estimation in parameter space and the potential in input space. However, the loss increments introduced by adversarial noises can be well reflected in the loss surface in input space as visualized in Fig. 1 ( b ). the differences in Fig. 1 suggest the ineffectiveness of generalization estimation in parameter space and the potential in input space.",
    ", 2016 ), and quantization ( Zhou et al., 2016 ; Li et al., 2016 ). Many of these applications have to operate in highly energy-constrained environments. In addition, many of these applications have to operate in highly energy-constrained environments. For instance, autonomous drones have to continuously perform computer vision tasks without a constant power supply. As a result, many of these applications have to operate in highly energy-con",
    ", 2016 ), and quantization ( Zhou et al., 2016 ; Li et al., 2016 ). Many of these applications have to operate in highly energy-constrained environments. In addition, many of these applications have to operate in highly energy-constrained environments. For instance, autonomous drones have to continuously perform computer vision tasks without a constant power supply. As a result, many of these applications have to operate in highly energy-con",
    "the exploration-exploitation dilemma that the agent faces. In this paper, we focus on BAMDP problems in which the latent parameter space is either a discrete finite set or a bounded continuous set that can be approximated via discretization. In particular, discretizing the latent space can result in an arbitrarily large belief vector. Although point-based value approximations ( Kurniawati et al., 2008 ; Pineau et al.",
    "the exploration-exploitation dilemma that the agent faces. In this paper, we focus on BAMDP problems in which the latent parameter space is either a discrete finite set or a bounded continuous set that can be approximated via discretization. In particular, discretizing the latent space can result in an arbitrarily large belief vector. Although point-based value approximations ( Kurniawati et al., 2008 ; Pineau et al.",
    ". In this paper, we focus on co-occurrence information of the entities and their contexts ( e.g., a word ). This allows us to leverage embeddings of the contexts instead of the original entities. This allows us to minimize the cost of moving the contexts of a given entity to the contexts of another. This is called Context Mover \u2019 s Distance ( CMD ). The contexts can be words, phrases, sentences",
    ". In this paper, we focus on co-occurrence information of the entities and their contexts ( e.g., a word ). This allows us to leverage embeddings of the contexts instead of the original entities. This allows us to minimize the cost of moving the contexts of a given entity to the contexts of another. This is called Context Mover \u2019 s Distance ( CMD ). The contexts can be words, phrases, sentences",
    "in the unlimited-sample regime. This paper address these questions by teasing apart the different factors involved in an MBRL framework. These include ( i ) the ability to generalize to new tasks in the environment ; ( ii ) learning from off-policy data. Correspondingly, the gap in asymptotic performance is limited by the ability of the model to accurately predict over long-time scales. This paper address these questions by teasing apart the",
    "in the unlimited-sample regime. This paper address these questions by teasing apart the different factors involved in an MBRL framework. These include ( i ) the ability to generalize to new tasks in the environment ; ( ii ) learning from off-policy data. Correspondingly, the gap in asymptotic performance is limited by the ability of the model to accurately predict over long-time scales. This paper address these questions by teasing apart the",
    ", 2017 ) and their implementations on CPU and GPU ( Tulloch & Jia, 2017 ). In this paper, we propose a novel concept called precision highway where an end-to-end path of high-precision information reduces the accumulated quantization error. Our proposed method is similar to recent studies ( Rastegari et al., 2016 ; Hubara et al., 2016 ; Hubara et al., 2016",
    ", 2017 ) and their implementations on CPU and GPU ( Tulloch & Jia, 2017 ). In this paper, we propose a novel concept called precision highway where an end-to-end path of high-precision information reduces the accumulated quantization error. Our proposed method is similar to recent studies ( Rastegari et al., 2016 ; Hubara et al., 2016 ; Hubara et al., 2016",
    "the most probable original image from all those possible original images. The general image restoration is formulated as a constrained optimization problem. Its objective is to maximize a posteriori probability of latent variables. Its constraint is that the image generated by these latent variables must be the same as the degraded image. The general image restoration is formulated as a constrained optimization problem. Its goal is to maximize a posteriori probability of latent variables. Its constraint is that the",
    "the most probable original image from all those possible original images. The general image restoration is formulated as a constrained optimization problem. Its objective is to maximize a posteriori probability of latent variables. Its constraint is that the image generated by these latent variables must be the same as the degraded image. The general image restoration is formulated as a constrained optimization problem. Its goal is to maximize a posteriori probability of latent variables. Its constraint is that the",
    "a 1 1 conv-layer at the end of each block in the student-net. The added layer can be absorbed/merged into the previous one. Experiments verify that the proposed method is very efficient and effective to distill knowledge from teacher-net to student-net constructing in different ways on various datasets.",
    "a 1 1 conv-layer at the end of each block in the student-net. The added layer can be absorbed/merged into the previous one. Experiments verify that the proposed method is very efficient and effective to distill knowledge from teacher-net to student-net constructing in different ways on various datasets.",
    ". transferability. transferability. task transferability. task transferability. determining task transferability. reliably determining task transferability. determining task transferability. determining task transferability. reliably estimating task transferability.. . ...........",
    ". transferability. transferability. task transferability. task transferability. determining task transferability. reliably determining task transferability. determining task transferability. determining task transferability. reliably estimating task transferability.. . ...........",
    ". For example, we may decide to use the \u201c In order to..., he..., because... \u201d structure before telling a long story. In this work, we are interested in letting the neural language generation model plan the sentence structure before generating words. In other words, the model is unaware of the \u201c big picture \u201d of the sentence structure. Therefore, we are interested in letting the model plan the sentence structure before generating words.",
    ". For example, we may decide to use the \u201c In order to..., he..., because... \u201d structure before telling a long story. In this work, we are interested in letting the neural language generation model plan the sentence structure before generating words. In other words, the model is unaware of the \u201c big picture \u201d of the sentence structure. Therefore, we are interested in letting the model plan the sentence structure before generating words.",
    "saturating and non-saturating. In practice, gradients may vanish and, if so, training will stop. In high-dimensional setting, this problem is generally more noticeable. To improve on SGAN, many GAN variants have been suggested using different loss functions and discriminators that are not classifiers ( e.g., LSGAN ( Mao et al., 2017 ) ).",
    "saturating and non-saturating. In practice, gradients may vanish and, if so, training will stop. In high-dimensional setting, this problem is generally more noticeable. To improve on SGAN, many GAN variants have been suggested using different loss functions and discriminators that are not classifiers ( e.g., LSGAN ( Mao et al., 2017 ) ).",
    "... Given a sequence of supervised learning tasks T = ( T1, T2,.., TN ), we want to learn them one by one in the given sequence such that the learning of each new task will not forget the models learned for the previous tasks. Problem Statement : Given a sequence of supervised learning tasks T = ( T1, T2,..., TN ), we want to learn",
    "... Given a sequence of supervised learning tasks T = ( T1, T2,.., TN ), we want to learn them one by one in the given sequence such that the learning of each new task will not forget the models learned for the previous tasks. Problem Statement : Given a sequence of supervised learning tasks T = ( T1, T2,..., TN ), we want to learn",
    ". Furthermore, we show that embedding RFM modules inside agents results in faster learning systems compared to non-augmented baselines. Furthermore, we show that embedding RFM modules inside agents results in faster learning systems compared to non-augmented baselines. In particular, in hand-engineered multi-agent systems ( e.g. assembly lines ), it is possible to obtain coordination by design, where expert engineers carefully orchestrate each agent.",
    ". Furthermore, we show that embedding RFM modules inside agents results in faster learning systems compared to non-augmented baselines. Furthermore, we show that embedding RFM modules inside agents results in faster learning systems compared to non-augmented baselines. In particular, in hand-engineered multi-agent systems ( e.g. assembly lines ), it is possible to obtain coordination by design, where expert engineers carefully orchestrate each agent.",
    "...... reverse reinforcement learning ( IRL ) is an approach that aims to address this problem by instead inferring the reward function from demonstrations of a task. This requires engineering a set of features by hand that work well for a specific problem. This requires engineering a set of features by hand that work well for a specific problem. Inverse reinforcement learning ( IRL ) is an approach that addresses this problem by infer",
    "...... reverse reinforcement learning ( IRL ) is an approach that aims to address this problem by instead inferring the reward function from demonstrations of a task. This requires engineering a set of features by hand that work well for a specific problem. This requires engineering a set of features by hand that work well for a specific problem. Inverse reinforcement learning ( IRL ) is an approach that addresses this problem by infer",
    ", 2017 ; ; Grant et al., 2018 ), a framework for meta-learning approximate probabilistic inference for prediction ( ML-PIP ). This framework provides this view in terms of amortizing posterior predictive distributions. Second, we leverage shared statistical structure between tasks via hierarchical probabilistic models developed for multi-task learning. Third, we extend existing probabilistic models developed for multi-task learning ( Garnelo et al",
    ", 2017 ; ; Grant et al., 2018 ), a framework for meta-learning approximate probabilistic inference for prediction ( ML-PIP ). This framework provides this view in terms of amortizing posterior predictive distributions. Second, we leverage shared statistical structure between tasks via hierarchical probabilistic models developed for multi-task learning. Third, we extend existing probabilistic models developed for multi-task learning ( Garnelo et al",
    "fine-grained object recognition is one of the fundamental problems in computer vision. It involves finding and identifying objects in images. It plays an important role in many real-world applications such as advanced driver assistance systems, military target detection, diagnosis with medical images, video surveillance, and identity recognition. Object recognition is one of the fundamental problems in computer vision. It involves finding and identifying objects in images.",
    "fine-grained object recognition is one of the fundamental problems in computer vision. It involves finding and identifying objects in images. It plays an important role in many real-world applications such as advanced driver assistance systems, military target detection, diagnosis with medical images, video surveillance, and identity recognition. Object recognition is one of the fundamental problems in computer vision. It involves finding and identifying objects in images.",
    ". On the other end of the spectrum, Generative Adversarial Networks ( GANs ) ( Goodfellow et al., 2014 ) have seen great recent success at generating high-resolution images. The potential for audio GANs extends further, as adversarial costs have unlocked intriguing domain transformations for high-resolution audio.",
    ". On the other end of the spectrum, Generative Adversarial Networks ( GANs ) ( Goodfellow et al., 2014 ) have seen great recent success at generating high-resolution images. The potential for audio GANs extends further, as adversarial costs have unlocked intriguing domain transformations for high-resolution audio.",
    "the adversarial test accuracy ( CW ). An increase in the mean adversarial distortion or in the adversarial test accuracy indicates an improvement in robustness. We present an efficient implementation of a mixed-integer linear programming ( MILP ) verifier for properties of piecewise-linear feed-forward neural networks. Our tight formulation for nonlinearities and our novel presolve algorithm combine to minimize the number of binary variables in the MILP problem and dramatically improve its numerical conditioning.",
    "the adversarial test accuracy ( CW ). An increase in the mean adversarial distortion or in the adversarial test accuracy indicates an improvement in robustness. We present an efficient implementation of a mixed-integer linear programming ( MILP ) verifier for properties of piecewise-linear feed-forward neural networks. Our tight formulation for nonlinearities and our novel presolve algorithm combine to minimize the number of binary variables in the MILP problem and dramatically improve its numerical conditioning.",
    "bounded rationality. For many interesting reinforcement learning tasks, good policies exhibit similar behaviors in different contexts. This intuition has been explored across multiple fields, from cognitive science ( e.g. Simon, 1956 ) to neuroscience and machine learning. In this paper we explore this idea, starting from the KL regularized expected reward objective ( e.g. Todorov, 2007 ; Toussaint, 1956 ; Toussaint, 1956",
    "bounded rationality. For many interesting reinforcement learning tasks, good policies exhibit similar behaviors in different contexts. This intuition has been explored across multiple fields, from cognitive science ( e.g. Simon, 1956 ) to neuroscience and machine learning. In this paper we explore this idea, starting from the KL regularized expected reward objective ( e.g. Todorov, 2007 ; Toussaint, 1956 ; Toussaint, 1956",
    "Work done during internship at Allen Institute for Artificial Intelligence ( Allen Institute for Artificial Intelligence ). 1We present FLOWQA, a model designed for conversational machine comprehension. FLOWQA consists of a base neural model for single-turn MC and a FLOW mechanism that encodes the conversation history. instead of using the shallow history, i.e., previous questions and answers, we feed the model with the entire hidden representations generated during the process of answering",
    "Work done during internship at Allen Institute for Artificial Intelligence ( Allen Institute for Artificial Intelligence ). 1We present FLOWQA, a model designed for conversational machine comprehension. FLOWQA consists of a base neural model for single-turn MC and a FLOW mechanism that encodes the conversation history. instead of using the shallow history, i.e., previous questions and answers, we feed the model with the entire hidden representations generated during the process of answering",
    "History A is in the process of adding an extra argument to the foo function. History B is in the process of removing the second argument from the foo function. In the case of History A, History B is in the process of adding an extra argument to the foo function. In the case of History B, History A is in the process of adding an extra argument to the foo function. In the case of History A, History B is in the process of removing the second argument from the fo",
    "History A is in the process of adding an extra argument to the foo function. History B is in the process of removing the second argument from the foo function. In the case of History A, History B is in the process of adding an extra argument to the foo function. In the case of History B, History A is in the process of adding an extra argument to the foo function. In the case of History A, History B is in the process of removing the second argument from the fo",
    "supervised learning ( unknown classes in the target domain ) and semi-supervised learning ( mix of labeled and unlabeled with known classes ). To relax these limitations, we propose to reduce the problem of classification to a meta problem that underlies a set of learning problems. In this meta problem, we learn a model that does not require explicit class label y but rather a weaker form of information.",
    "supervised learning ( unknown classes in the target domain ) and semi-supervised learning ( mix of labeled and unlabeled with known classes ). To relax these limitations, we propose to reduce the problem of classification to a meta problem that underlies a set of learning problems. In this meta problem, we learn a model that does not require explicit class label y but rather a weaker form of information.",
    "deep learning methods have been very successful in many natural language processing tasks. however, despite significantly raised performance scores on benchmark datasets, researchers increasingly worry about interpretability and quality of model decisions. to this end, we carefully design data to replicate experiments from psycholinguistics where the same question was investigated for humans. To this end, we carefully design data to replicate experiments from psycholinguistics where the same question was investigated for humans. Moreover, we identify confounding factors, like spatial arrangement of the scene",
    "deep learning methods have been very successful in many natural language processing tasks. however, despite significantly raised performance scores on benchmark datasets, researchers increasingly worry about interpretability and quality of model decisions. to this end, we carefully design data to replicate experiments from psycholinguistics where the same question was investigated for humans. To this end, we carefully design data to replicate experiments from psycholinguistics where the same question was investigated for humans. Moreover, we identify confounding factors, like spatial arrangement of the scene",
    ". Link prediction has become an important subfield of artificial intelligence ( Nickel et al., 2016a ). In relational learning, link prediction is done by inferring explicit rules about relationships and applying these inferred rules to reason about unobserved facts. In relational learning, link prediction is done by inferring explicit rules about relationships and applying these inferred rules to reason about unobserved facts. In relational learning, link prediction is done by inferring",
    ". Link prediction has become an important subfield of artificial intelligence ( Nickel et al., 2016a ). In relational learning, link prediction is done by inferring explicit rules about relationships and applying these inferred rules to reason about unobserved facts. In relational learning, link prediction is done by inferring explicit rules about relationships and applying these inferred rules to reason about unobserved facts. In relational learning, link prediction is done by inferring",
    ". Supervised dimension reduction aims to explore low dimensional representations for high dimensional data. Unlike unsupervised dimension reduction, supervised dimension reduction involves a response variable. It finds the intrinsic lower-dimensional representations that are relevant to the prediction of the response values. Supervised dimension reduction methods can date back to the well known linear discriminant analysis ( LDA ) while its blossom occurred in the last twenty years. As the data is simultaneously big and high dimensional, it becomes necessary to",
    ". Supervised dimension reduction aims to explore low dimensional representations for high dimensional data. Unlike unsupervised dimension reduction, supervised dimension reduction involves a response variable. It finds the intrinsic lower-dimensional representations that are relevant to the prediction of the response values. Supervised dimension reduction methods can date back to the well known linear discriminant analysis ( LDA ) while its blossom occurred in the last twenty years. As the data is simultaneously big and high dimensional, it becomes necessary to",
    "2 ) trained models must be robust to unexpected missing or noisy modalities during testing. In this paper, we introduce the Multimodal Factorization Model ( MFM ) that factorizes multimodal representations into multimodal discriminative factors and modality-specific generative factors. The discriminative objective ensures that the representations learned are rich in intra-modal and cross-modal features useful towards predicting the label. The generative objective allows the model to infer missing modalities at test time and deal",
    "2 ) trained models must be robust to unexpected missing or noisy modalities during testing. In this paper, we introduce the Multimodal Factorization Model ( MFM ) that factorizes multimodal representations into multimodal discriminative factors and modality-specific generative factors. The discriminative objective ensures that the representations learned are rich in intra-modal and cross-modal features useful towards predicting the label. The generative objective allows the model to infer missing modalities at test time and deal",
    "in both sample naturalness and voice similarity with merely a few minutes of audio data from new speakers. We present a meta-learning approach for adaptive text-to-speech ( TTS ) with few data. During training, we learn a multi-speaker model using a shared conditional WaveNet core and independent learned embeddings for each speaker. The aim of training is not to produce a fixed final model. Instead, the aim is to produce a",
    "in both sample naturalness and voice similarity with merely a few minutes of audio data from new speakers. We present a meta-learning approach for adaptive text-to-speech ( TTS ) with few data. During training, we learn a multi-speaker model using a shared conditional WaveNet core and independent learned embeddings for each speaker. The aim of training is not to produce a fixed final model. Instead, the aim is to produce a",
    "( 1 ). ( 1 ). ( 1 ). ( 1 ). ( eCp ).. of ( 1 )... of ( 1 )..... of ( 1 ).... ( 2018 ).....",
    "( 1 ). ( 1 ). ( 1 ). ( 1 ). ( eCp ).. of ( 1 )... of ( 1 )..... of ( 1 ).... ( 2018 ).....",
    "a hierarchical, object-based scene representation. Experiments demonstrate that our model works well on synthetic data and transfers to real images with such compositional structure. In this paper, we present scene programs, representing a scene via a symbolic program for its objects, attributes, and their relations. We also propose a model that infers such scene programs by exploiting a hierarchical, object-based scene representation. In contrast, the problem of understanding high-level",
    "a hierarchical, object-based scene representation. Experiments demonstrate that our model works well on synthetic data and transfers to real images with such compositional structure. In this paper, we present scene programs, representing a scene via a symbolic program for its objects, attributes, and their relations. We also propose a model that infers such scene programs by exploiting a hierarchical, object-based scene representation. In contrast, the problem of understanding high-level",
    "the number of computes needed for the network update is also reduced by at least 10. Finally, we propose a temporal curriculum learning schedule for the g-LSTM which helps speed up the convergence time of the equivalent LSTM on long sequences. In the last few years, various methods which reduce the state updates of an RNN ( LSTM ) have been explored to better learn long time dependencies from data.",
    "the number of computes needed for the network update is also reduced by at least 10. Finally, we propose a temporal curriculum learning schedule for the g-LSTM which helps speed up the convergence time of the equivalent LSTM on long sequences. In the last few years, various methods which reduce the state updates of an RNN ( LSTM ) have been explored to better learn long time dependencies from data.",
    ". However, they are also highly confident when tested against unseen samples. In fact, knowing when the model is wrong or inaccurate has a direct impact in many production systems, such as self-driving cars, authentication and disease identification ( Amodei et al., 2016 ). Moreover, they demonstrated that a simple and yet powerful method of temperature scaling in the softmax scores is an effective method for obtaining a calibrated confidence score from a deep neural",
    ". However, they are also highly confident when tested against unseen samples. In fact, knowing when the model is wrong or inaccurate has a direct impact in many production systems, such as self-driving cars, authentication and disease identification ( Amodei et al., 2016 ). Moreover, they demonstrated that a simple and yet powerful method of temperature scaling in the softmax scores is an effective method for obtaining a calibrated confidence score from a deep neural",
    ". However, the theoretical underpinnings behind deep neural networks remain unclear to a large extent. For example, a regression problem, for example, assumes that each sample y is generated as y = 1K K k=1  ( w? > k x ). Second, a regression problem, for example, assumes that each sample y is generated as y = 1K K k=1",
    ". However, the theoretical underpinnings behind deep neural networks remain unclear to a large extent. For example, a regression problem, for example, assumes that each sample y is generated as y = 1K K k=1  ( w? > k x ). Second, a regression problem, for example, assumes that each sample y is generated as y = 1K K k=1",
    "channel saliency measures and removes all input and output connections from unimportant channels. By removing channels, the capabilities of CNNs are permanently lost. Lastly, channel pruning has threefold disadvantages. Firstly, by removing channels, the capabilities of CNNs are permanently lost. Secondly, despite the fact that channel pruning may drastically shrink model size, without careful design, computational resources can not be effectively reduced in a CNN without a detrimental impact on its accuracy.",
    "channel saliency measures and removes all input and output connections from unimportant channels. By removing channels, the capabilities of CNNs are permanently lost. Lastly, channel pruning has threefold disadvantages. Firstly, by removing channels, the capabilities of CNNs are permanently lost. Secondly, despite the fact that channel pruning may drastically shrink model size, without careful design, computational resources can not be effectively reduced in a CNN without a detrimental impact on its accuracy.",
    "based on the mixed Nash Equilibria ( NE ) perspective. We then prove rigorous convergence rates to the mixed NE. Finally, we provide experimental evidence that our approach outperforms methods that seek pure strategy equilibria ( NE ). In the language of game theory, GAN seeks for a pure strategy equilibrium, which is well-known to be ill-posed in many scenarios. Indeed, a pure strategy equilibrium might not",
    "based on the mixed Nash Equilibria ( NE ) perspective. We then prove rigorous convergence rates to the mixed NE. Finally, we provide experimental evidence that our approach outperforms methods that seek pure strategy equilibria ( NE ). In the language of game theory, GAN seeks for a pure strategy equilibrium, which is well-known to be ill-posed in many scenarios. Indeed, a pure strategy equilibrium might not",
    ". As the space of deep learning applications expands and starts to personalize, there is a growing need for the ability to quickly build and customize models. In this paper we explore a different angle : we would like to be able to build models that require only a few parameters to be trained in order to be re-purposed to a different task. While there is ample existing work on compressing models and learning as few weights as possible, there is no prior work that tries to minimize",
    ". As the space of deep learning applications expands and starts to personalize, there is a growing need for the ability to quickly build and customize models. In this paper we explore a different angle : we would like to be able to build models that require only a few parameters to be trained in order to be re-purposed to a different task. While there is ample existing work on compressing models and learning as few weights as possible, there is no prior work that tries to minimize",
    ". In this paper, we relax the assumption that the entire mini-batch should be normalized with the same mean and variance. We further show that MN can be incorporated into other normalization techniques such as group normalization. 3 RELATED WORK. Normalization. Normalizing input data ( LeCun et al., 1998 ) or initial weights of neural networks ( LeCun et al., 1998 ). Normalization. Normalizing input",
    ". In this paper, we relax the assumption that the entire mini-batch should be normalized with the same mean and variance. We further show that MN can be incorporated into other normalization techniques such as group normalization. 3 RELATED WORK. Normalization. Normalizing input data ( LeCun et al., 1998 ) or initial weights of neural networks ( LeCun et al., 1998 ). Normalization. Normalizing input",
    "a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively. the winning tickets that we find are less than 10-20 % of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy.",
    "a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively. the winning tickets that we find are less than 10-20 % of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy.",
    ". In addition, there have been recent studies on using neural network representations for exploration. For example, count-based exploration with neural density estimation ( Ostrovski et al., 2017 ) presents one of the state-of-the-art techniques on the most challenging Atari games with sparse rewards. To address these questions, we investigate whether we can learn a complementary, more intuitive, and interpretable high-level abstraction for exploration.",
    ". In addition, there have been recent studies on using neural network representations for exploration. For example, count-based exploration with neural density estimation ( Ostrovski et al., 2017 ) presents one of the state-of-the-art techniques on the most challenging Atari games with sparse rewards. To address these questions, we investigate whether we can learn a complementary, more intuitive, and interpretable high-level abstraction for exploration.",
    "HyperGAN can also provide better uncertainty than standard ensembles. This is evaluated by the ability of HyperGAN-generated ensembles to detect outliers and adversarial examples. In addition to being highly accurate on inlier data, HyperGAN can also provide reasonable uncertainty estimates. 1 INTRODUCTION. Since the inception of deep neural networks, it has been found that it is possible to train from different random initializations and obtain networks that achieve quite similar accuracy.",
    "HyperGAN can also provide better uncertainty than standard ensembles. This is evaluated by the ability of HyperGAN-generated ensembles to detect outliers and adversarial examples. In addition to being highly accurate on inlier data, HyperGAN can also provide reasonable uncertainty estimates. 1 INTRODUCTION. Since the inception of deep neural networks, it has been found that it is possible to train from different random initializations and obtain networks that achieve quite similar accuracy.",
    ". The variational auto encoder ( VAE ) is a generative model which it is trained to approximate the true data generating distribution p ( x ) of an observed random vector x. During training, the VAE maximizes the probability p ( x ) to observe the data x. Thus, the VAE is an especially suited model for tasks like density estimation, data generation, data interpolation, outlier and anomaly detection ( An",
    ". The variational auto encoder ( VAE ) is a generative model which it is trained to approximate the true data generating distribution p ( x ) of an observed random vector x. During training, the VAE maximizes the probability p ( x ) to observe the data x. Thus, the VAE is an especially suited model for tasks like density estimation, data generation, data interpolation, outlier and anomaly detection ( An",
    "adversarial images in neural nets have been studied for over a decade. In addition to highlighting security implications adversarial attacks on machine learning systems have been studied intensely. Adversarial attacks on deep learning image recognition models have first been discussed by Szegedy et al. ( 2013 ). In addition to highlighting security implications adversarial attacks on machine learning systems have been studied intensely.",
    "adversarial images in neural nets have been studied for over a decade. In addition to highlighting security implications adversarial attacks on machine learning systems have been studied intensely. Adversarial attacks on deep learning image recognition models have first been discussed by Szegedy et al. ( 2013 ). In addition to highlighting security implications adversarial attacks on machine learning systems have been studied intensely.",
    ". These regions of an image are small regions of an image in which only a part of an object is observed. A slight adjustment of the visible area produces a sharp drop in DNN recognition accuracy. In this paper, we provide evidence for the latter hypothesis by showing that there is a large set of analogs to minimal images that affect DNNs. These are different from the minimal images for humans in several aspects, namely region size and location, and frequency and sharpness of the drop in accuracy",
    ". These regions of an image are small regions of an image in which only a part of an object is observed. A slight adjustment of the visible area produces a sharp drop in DNN recognition accuracy. In this paper, we provide evidence for the latter hypothesis by showing that there is a large set of analogs to minimal images that affect DNNs. These are different from the minimal images for humans in several aspects, namely region size and location, and frequency and sharpness of the drop in accuracy",
    ". By default, workers choose the most preferred tasks. This is unproductive from the perspective of the entire project. Therefore, the manager gives additional incentives in the form of contracts. Each contract assigns a goal and a bonus for achieving the goal to a worker. To generate optimal contracts, the manager must infer the workers \u2019 minds and learn a good policy of goal and reward assignment. To generate optimal contracts, the manager must infer the workers \u2019 minds and learn",
    ". By default, workers choose the most preferred tasks. This is unproductive from the perspective of the entire project. Therefore, the manager gives additional incentives in the form of contracts. Each contract assigns a goal and a bonus for achieving the goal to a worker. To generate optimal contracts, the manager must infer the workers \u2019 minds and learn a good policy of goal and reward assignment. To generate optimal contracts, the manager must infer the workers \u2019 minds and learn",
    "........ We introduce a unified RNN that handles five different feature types, each in a different manner.. applications. However,,....................",
    "........ We introduce a unified RNN that handles five different feature types, each in a different manner.. applications. However,,....................",
    ". This paper presents a novel neural representation of propositional formulae. This neural representation makes it possible to test whether a given formula has a given property. In particular, we try to obtain a useful heuristic that can help us in guiding a proof search. This paper presents a novel neural representation of propositional formulae that makes it possible to test whether a given formula is always true or not. In particular, we try to solve a well-known CONP-",
    ". This paper presents a novel neural representation of propositional formulae. This neural representation makes it possible to test whether a given formula has a given property. In particular, we try to obtain a useful heuristic that can help us in guiding a proof search. This paper presents a novel neural representation of propositional formulae that makes it possible to test whether a given formula is always true or not. In particular, we try to solve a well-known CONP-",
    ". In this work, we aim at extending the understanding of CL in the context of deep neural networks. More specifically, we wish to understand to what extent curriculum can improve the accuracy and convergence rate of deep neural networks. In this work, we aim at extending the understanding of CL in the context of deep neural networks. In this work, we examine two ideas motivated by transfer learning and bootstrapping respectively.",
    ". In this work, we aim at extending the understanding of CL in the context of deep neural networks. More specifically, we wish to understand to what extent curriculum can improve the accuracy and convergence rate of deep neural networks. In this work, we aim at extending the understanding of CL in the context of deep neural networks. In this work, we examine two ideas motivated by transfer learning and bootstrapping respectively.",
    "generalization bounds that use noise-resilience of deep networks on training data. However, these bounds are quite limited : they either apply to a stochastic version of the classifier ( where the parameters are drawn from a distribution ) or to a compressed version of the classifier ( where the parameters are modified and represented using fewer bits ). In this paper, we revisit the PAC-Bayesian analysis of deep networks in Neyshabur et al",
    "generalization bounds that use noise-resilience of deep networks on training data. However, these bounds are quite limited : they either apply to a stochastic version of the classifier ( where the parameters are drawn from a distribution ) or to a compressed version of the classifier ( where the parameters are modified and represented using fewer bits ). In this paper, we revisit the PAC-Bayesian analysis of deep networks in Neyshabur et al",
    ". In this paper, we build on Vector Quantized Variational Autoencoder ( VQ-VAE ) ( van den Oord et al., 2017 ), a recently proposed training technique for learning discrete latent variables. The decoder is a vector quantized variable autoencoder ( VQ-VAE ) ( van den Oord et al., 2017 ). The decoder is based on a",
    ". In this paper, we build on Vector Quantized Variational Autoencoder ( VQ-VAE ) ( van den Oord et al., 2017 ), a recently proposed training technique for learning discrete latent variables. The decoder is a vector quantized variable autoencoder ( VQ-VAE ) ( van den Oord et al., 2017 ). The decoder is based on a",
    "the combination of different views gives representational improvement over each view and demonstrates solid transferability on standard downstream tasks. Multi-view learning can provide self-supervision when different views are available of the same data. Distributional hypothesis provides another form of useful self-supervision from adjacent sentences which are plentiful in large unlabelled corpora. In this paper, we present two multi-view frameworks for learning sentence representations in an unsupervised fashion.",
    "the combination of different views gives representational improvement over each view and demonstrates solid transferability on standard downstream tasks. Multi-view learning can provide self-supervision when different views are available of the same data. Distributional hypothesis provides another form of useful self-supervision from adjacent sentences which are plentiful in large unlabelled corpora. In this paper, we present two multi-view frameworks for learning sentence representations in an unsupervised fashion.",
    "; synchronous Dekel et al. ( 2012 ) ; Duchi et al. ( 2012 ) ; Tsianos & Rabbat ( 2016 ) ; Zinkevich et al. ( 2010 ) ; Zinkevich et al. ( 2010 ) and asynchronous Recht et al. ( 2011 ) ; Tandon et al. ( 2017 ) ; Pan et",
    "; synchronous Dekel et al. ( 2012 ) ; Duchi et al. ( 2012 ) ; Tsianos & Rabbat ( 2016 ) ; Zinkevich et al. ( 2010 ) ; Zinkevich et al. ( 2010 ) and asynchronous Recht et al. ( 2011 ) ; Tandon et al. ( 2017 ) ; Pan et",
    ". Extrinsic motivation refers to being moved to act based on the way it makes one feel. This is contrasted with extrinsic motivation that involves explicit goals. The combination of sensory inputs, physiological responses and cognitive evaluation form emotions that influence how humans learn, plan and make decisions. Driving is an everyday example of a task in which we rely on both intrinsic and extrinsic motivations. When traveling in a car at highspeed one may experience",
    ". Extrinsic motivation refers to being moved to act based on the way it makes one feel. This is contrasted with extrinsic motivation that involves explicit goals. The combination of sensory inputs, physiological responses and cognitive evaluation form emotions that influence how humans learn, plan and make decisions. Driving is an everyday example of a task in which we rely on both intrinsic and extrinsic motivations. When traveling in a car at highspeed one may experience",
    "a vector-valued input x, and using draws from that distribution to make predictions on test inputs. In the Bayesian machine learning literature, non-parametric models such as Gaussian Processes ( GPs ) are popular choices of this approach. Neural Processes ( NPs ) ( Garnelo et al., 2018a ; b ) offer an efficient method to modelling a distribution over regression functions. NPs",
    "a vector-valued input x, and using draws from that distribution to make predictions on test inputs. In the Bayesian machine learning literature, non-parametric models such as Gaussian Processes ( GPs ) are popular choices of this approach. Neural Processes ( NPs ) ( Garnelo et al., 2018a ; b ) offer an efficient method to modelling a distribution over regression functions. NPs",
    ". Meta-RL is a multi-stage process in which the artificial agent, after a few sampled environment interactions, adapts its behavior to the given task. While achieving impressive results, most successful artificial agents struggle in such scenarios. Meta-RL is a multi-stage process in which the agent, after a few sampled environment interactions, adapts its behavior to the given task. Despite recent progress, little work has been done to promote theoretical understanding of this process.",
    ". Meta-RL is a multi-stage process in which the artificial agent, after a few sampled environment interactions, adapts its behavior to the given task. While achieving impressive results, most successful artificial agents struggle in such scenarios. Meta-RL is a multi-stage process in which the agent, after a few sampled environment interactions, adapts its behavior to the given task. Despite recent progress, little work has been done to promote theoretical understanding of this process.",
    "neuroSAT is a novel message passing neural network ( MPNN ) that learns to solve SAT problems after only being trained as a classifier to predict satisfiability. NeuroSAT can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems. Moreover, NeuroSAT can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems.",
    "neuroSAT is a novel message passing neural network ( MPNN ) that learns to solve SAT problems after only being trained as a classifier to predict satisfiability. NeuroSAT can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems. Moreover, NeuroSAT can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems.",
    "30 million driving examples, corresponding to about 60 days of continual driving. we use a perception system that processes raw sensor information. we present this mid-level input to a recurrent neural network ( RNN ). RNN outputs a driving trajectory that is consumed by a controller which translates it to steering and acceleration. the net can be easily tested and validated in closed-loop simulations before running on a real car.",
    "30 million driving examples, corresponding to about 60 days of continual driving. we use a perception system that processes raw sensor information. we present this mid-level input to a recurrent neural network ( RNN ). RNN outputs a driving trajectory that is consumed by a controller which translates it to steering and acceleration. the net can be easily tested and validated in closed-loop simulations before running on a real car.",
    ". Large-scale labeled data has been critical to the recent success of deep learning ( Halevy et al., 2009 ; Sun et al., 2017 ; Hestness et al., 2017 ). However, for these large datasets, training deep networks can incur prohibitively long training times. In this paper, we introduce a new method called Select Via Proxy ( SVP ) that provides a computationally efficient way of",
    ". Large-scale labeled data has been critical to the recent success of deep learning ( Halevy et al., 2009 ; Sun et al., 2017 ; Hestness et al., 2017 ). However, for these large datasets, training deep networks can incur prohibitively long training times. In this paper, we introduce a new method called Select Via Proxy ( SVP ) that provides a computationally efficient way of",
    "humanoid robots to perform complex nonprehensile manipulations ( Finn & Levine, 2017 ). In addition, iterative linear quadratic regulator ( iLQR ) has enabled humanoid robots to get up from an arbitrary seated pose ( Tassa et al., 2012 ). In this paper, we address the limitations of the aforementioned planning algorithms by creating a more general view of planning that can leverage advances in",
    "humanoid robots to perform complex nonprehensile manipulations ( Finn & Levine, 2017 ). In addition, iterative linear quadratic regulator ( iLQR ) has enabled humanoid robots to get up from an arbitrary seated pose ( Tassa et al., 2012 ). In this paper, we address the limitations of the aforementioned planning algorithms by creating a more general view of planning that can leverage advances in",
    ". Neural networks have been demonstrated to be vulnerable to adversarial examples. In particular, Tsipras et al. ( 2019 ) demonstrated the inevitable tradeoff between robustness and clean accuracy in some particular examples. In this paper, we contribute to this growing literature from a new angle. We focus on the adversarial training method, arguably the most popular defense method so far due to its simplicity, effectiveness and scalability.",
    ". Neural networks have been demonstrated to be vulnerable to adversarial examples. In particular, Tsipras et al. ( 2019 ) demonstrated the inevitable tradeoff between robustness and clean accuracy in some particular examples. In this paper, we contribute to this growing literature from a new angle. We focus on the adversarial training method, arguably the most popular defense method so far due to its simplicity, effectiveness and scalability.",
    "EquiNorm. EquiNorm is a normalization that works in weight space and uses a form of batch statistics unlike previous weight space approaches. When combined with additional regularization, EquiNorm can significantly outperform BatchNorm. BatchNorm has been extended as batch renormalization ( Ioffe, 2017 ) to handle smaller batch sizes. BatchNorm has also been extended as batch renormalization ( Ioffe, 2017 ) to handle smaller batch sizes. EquiNorm is an alternative to batch",
    "EquiNorm. EquiNorm is a normalization that works in weight space and uses a form of batch statistics unlike previous weight space approaches. When combined with additional regularization, EquiNorm can significantly outperform BatchNorm. BatchNorm has been extended as batch renormalization ( Ioffe, 2017 ) to handle smaller batch sizes. BatchNorm has also been extended as batch renormalization ( Ioffe, 2017 ) to handle smaller batch sizes. EquiNorm is an alternative to batch",
    ".. Finally, we remove mislabeled examples from the dataset. Finally, we continue training until convergence. In this paper, we propose On-the-fly Data Denoising ( ODD ). This is a simple and robust method for training with noisy examples. This method is based on the implicit regularization effect of stochastic gradient descent. In this paper, we show that ODD performs significantly better than the state-of-the-art on",
    ".. Finally, we remove mislabeled examples from the dataset. Finally, we continue training until convergence. In this paper, we propose On-the-fly Data Denoising ( ODD ). This is a simple and robust method for training with noisy examples. This method is based on the implicit regularization effect of stochastic gradient descent. In this paper, we show that ODD performs significantly better than the state-of-the-art on",
    "pretraining on a large corpus allows us to learn the generative model. The conditional token probabilities predicted by the pretrained model carry information about the hidden variables. In downstream adaptation, we aim to recover this information to solve the downstream task. While full finetuning is the de facto empirical standard, theoretical understanding is scarce. In this paper, we focus on head tuning 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). and prompt tuning [ 31",
    "pretraining on a large corpus allows us to learn the generative model. The conditional token probabilities predicted by the pretrained model carry information about the hidden variables. In downstream adaptation, we aim to recover this information to solve the downstream task. While full finetuning is the de facto empirical standard, theoretical understanding is scarce. In this paper, we focus on head tuning 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). and prompt tuning [ 31",
    "pretraining on a large corpus allows us to learn the generative model. The conditional token probabilities predicted by the pretrained model carry information about the hidden variables. In downstream adaptation, we aim to recover this information to solve the downstream task. While full finetuning is the de facto empirical standard, theoretical understanding is scarce. In this paper, we focus on head tuning 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). and prompt tuning [ 31",
    "pretraining on a large corpus allows us to learn the generative model. The conditional token probabilities predicted by the pretrained model carry information about the hidden variables. In downstream adaptation, we aim to recover this information to solve the downstream task. While full finetuning is the de facto empirical standard, theoretical understanding is scarce. In this paper, we focus on head tuning 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). and prompt tuning [ 31",
    "available at https : //github.com/Gordon-Guojun-Zhang/Transferability-NeurIPS2021. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "available at https : //github.com/Gordon-Guojun-Zhang/Transferability-NeurIPS2021. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "available at https : //github.com/Gordon-Guojun-Zhang/Transferability-NeurIPS2021. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "available at https : //github.com/Gordon-Guojun-Zhang/Transferability-NeurIPS2021. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "a task is either ( 1 ) a set of 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). acceptable behaviors ( policies ), ( 2 ) a partial ordering over behaviors, or ( 3 ) a partial ordering over trajectories. Further detail and motivation.. Motivation.. Motivation.. Motivation.. Motivation. Motivation. Motivation. Motivation. Motivation. Motivation. Motivation.",
    "a task is either ( 1 ) a set of 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). acceptable behaviors ( policies ), ( 2 ) a partial ordering over behaviors, or ( 3 ) a partial ordering over trajectories. Further detail and motivation.. Motivation.. Motivation.. Motivation.. Motivation. Motivation. Motivation. Motivation. Motivation. Motivation. Motivation.",
    "a task is either ( 1 ) a set of 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). acceptable behaviors ( policies ), ( 2 ) a partial ordering over behaviors, or ( 3 ) a partial ordering over trajectories. Further detail and motivation.. Motivation.. Motivation.. Motivation.. Motivation. Motivation. Motivation. Motivation. Motivation. Motivation. Motivation.",
    "a task is either ( 1 ) a set of 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). acceptable behaviors ( policies ), ( 2 ) a partial ordering over behaviors, or ( 3 ) a partial ordering over trajectories. Further detail and motivation.. Motivation.. Motivation.. Motivation.. Motivation. Motivation. Motivation. Motivation. Motivation. Motivation. Motivation.",
    "supervised learning ( RL ) can be sub-optimal for generalizing to new contexts in RL. For example, imagine a robotic zookeeper for feeding otters that must be trained on some set of zoos. It can either peek through all the habitat windows looking for otters, which succeeds with 95 % probability in all zoos. It can also follow an image of a hand-drawn map of the z",
    "supervised learning ( RL ) can be sub-optimal for generalizing to new contexts in RL. For example, imagine a robotic zookeeper for feeding otters that must be trained on some set of zoos. It can either peek through all the habitat windows looking for otters, which succeeds with 95 % probability in all zoos. It can also follow an image of a hand-drawn map of the z",
    "supervised learning ( RL ) can be sub-optimal for generalizing to new contexts in RL. For example, imagine a robotic zookeeper for feeding otters that must be trained on some set of zoos. It can either peek through all the habitat windows looking for otters, which succeeds with 95 % probability in all zoos. It can also follow an image of a hand-drawn map of the z",
    "supervised learning ( RL ) can be sub-optimal for generalizing to new contexts in RL. For example, imagine a robotic zookeeper for feeding otters that must be trained on some set of zoos. It can either peek through all the habitat windows looking for otters, which succeeds with 95 % probability in all zoos. It can also follow an image of a hand-drawn map of the z",
    "at meta-testing time. If an agent can achieve good performance at meta-testing time, it embodies the ability to transfer knowledge from prior experiences at meta-training time. In this paper, we focus on gradient-based adaptations [ 4 ], where the agent carries out policy gradient updates [ 16 ] at both meta-training and meta-testing time. In this paper, we discuss how meta-RL formalizes the learning and transfer of prior knowledge in RL",
    "at meta-testing time. If an agent can achieve good performance at meta-testing time, it embodies the ability to transfer knowledge from prior experiences at meta-training time. In this paper, we focus on gradient-based adaptations [ 4 ], where the agent carries out policy gradient updates [ 16 ] at both meta-training and meta-testing time. In this paper, we discuss how meta-RL formalizes the learning and transfer of prior knowledge in RL",
    "at meta-testing time. If an agent can achieve good performance at meta-testing time, it embodies the ability to transfer knowledge from prior experiences at meta-training time. In this paper, we focus on gradient-based adaptations [ 4 ], where the agent carries out policy gradient updates [ 16 ] at both meta-training and meta-testing time. In this paper, we discuss how meta-RL formalizes the learning and transfer of prior knowledge in RL",
    "at meta-testing time. If an agent can achieve good performance at meta-testing time, it embodies the ability to transfer knowledge from prior experiences at meta-training time. In this paper, we focus on gradient-based adaptations [ 4 ], where the agent carries out policy gradient updates [ 16 ] at both meta-training and meta-testing time. In this paper, we discuss how meta-RL formalizes the learning and transfer of prior knowledge in RL",
    "a convex cost function F ( w ) with F ( w ) = 1N N i=1 Fi ( w ). In this work, we solve the following distributed convex optimization problem using stochastic gradient algorithms [ 25, 5 ] : minwRd F ( w ) with F ( w ) = 1N N i=1 Fi ( w ) where ( Fi ) N i=1",
    "a convex cost function F ( w ) with F ( w ) = 1N N i=1 Fi ( w ). In this work, we solve the following distributed convex optimization problem using stochastic gradient algorithms [ 25, 5 ] : minwRd F ( w ) with F ( w ) = 1N N i=1 Fi ( w ) where ( Fi ) N i=1",
    "a convex cost function F ( w ) with F ( w ) = 1N N i=1 Fi ( w ). In this work, we solve the following distributed convex optimization problem using stochastic gradient algorithms [ 25, 5 ] : minwRd F ( w ) with F ( w ) = 1N N i=1 Fi ( w ) where ( Fi ) N i=1",
    "a convex cost function F ( w ) with F ( w ) = 1N N i=1 Fi ( w ). In this work, we solve the following distributed convex optimization problem using stochastic gradient algorithms [ 25, 5 ] : minwRd F ( w ) with F ( w ) = 1N N i=1 Fi ( w ) where ( Fi ) N i=1",
    ".... we will formalize passing stress tests as counterfactual invariance...... this paper reveals is spurious correlations........ remains open..??.... counterfactual invariance..",
    ".... we will formalize passing stress tests as counterfactual invariance...... this paper reveals is spurious correlations........ remains open..??.... counterfactual invariance..",
    ".... we will formalize passing stress tests as counterfactual invariance...... this paper reveals is spurious correlations........ remains open..??.... counterfactual invariance..",
    ".... we will formalize passing stress tests as counterfactual invariance...... this paper reveals is spurious correlations........ remains open..??.... counterfactual invariance..",
    "... a discriminator. discriminator without introducing any external augmentations or regularization terms. We call our method Adaptive Pseudo Augmentation ( APA ). By using the Corresponding author. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). generator. We present a simple yet effective way to regularize the discriminator overfitting without introducing any external discrimin",
    "... a discriminator. discriminator without introducing any external augmentations or regularization terms. We call our method Adaptive Pseudo Augmentation ( APA ). By using the Corresponding author. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). generator. We present a simple yet effective way to regularize the discriminator overfitting without introducing any external discrimin",
    "... a discriminator. discriminator without introducing any external augmentations or regularization terms. We call our method Adaptive Pseudo Augmentation ( APA ). By using the Corresponding author. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). generator. We present a simple yet effective way to regularize the discriminator overfitting without introducing any external discrimin",
    "... a discriminator. discriminator without introducing any external augmentations or regularization terms. We call our method Adaptive Pseudo Augmentation ( APA ). By using the Corresponding author. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). generator. We present a simple yet effective way to regularize the discriminator overfitting without introducing any external discrimin",
    ". Similarly, an event stream can be viewed as a sample from a multivariate point process over a set of event labels. Moreover, work in dynamic treatment aims to reduce bias or high variance in discrete-time data. In 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". Similarly, an event stream can be viewed as a sample from a multivariate point process over a set of event labels. Moreover, work in dynamic treatment aims to reduce bias or high variance in discrete-time data. In 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". Similarly, an event stream can be viewed as a sample from a multivariate point process over a set of event labels. Moreover, work in dynamic treatment aims to reduce bias or high variance in discrete-time data. In 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". Similarly, an event stream can be viewed as a sample from a multivariate point process over a set of event labels. Moreover, work in dynamic treatment aims to reduce bias or high variance in discrete-time data. In 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "Rd is the feature vector of node u in the k-th iteration of message passing. In real-world applications, some node features can be abnormal from various aspects. For instance, in social networks, new users might not have complete profile before they make connections with others. In transportation networks, node features can be noisy since there exist certain certain aspects. Moreover, node features can be adversarially chosen by the attacker to manipulate the prediction made by GNNs",
    "Rd is the feature vector of node u in the k-th iteration of message passing. In real-world applications, some node features can be abnormal from various aspects. For instance, in social networks, new users might not have complete profile before they make connections with others. In transportation networks, node features can be noisy since there exist certain certain aspects. Moreover, node features can be adversarially chosen by the attacker to manipulate the prediction made by GNNs",
    "Rd is the feature vector of node u in the k-th iteration of message passing. In real-world applications, some node features can be abnormal from various aspects. For instance, in social networks, new users might not have complete profile before they make connections with others. In transportation networks, node features can be noisy since there exist certain certain aspects. Moreover, node features can be adversarially chosen by the attacker to manipulate the prediction made by GNNs",
    "Rd is the feature vector of node u in the k-th iteration of message passing. In real-world applications, some node features can be abnormal from various aspects. For instance, in social networks, new users might not have complete profile before they make connections with others. In transportation networks, node features can be noisy since there exist certain certain aspects. Moreover, node features can be adversarially chosen by the attacker to manipulate the prediction made by GNNs",
    ". We extend the regret analysis for optimistic policies to bilinear saddle-point problems which include zero-sum matrix games and constrained bandits as special cases. In this case we extend the regret analysis for optimistic policies to bilinear saddle-point problems. We call the resulting algorithm \u2018 variational Bayesian optimistic sampling \u2019 ( VBOS ). Firstly, TS requires samples from the true posterior, which may be intractable for some problems. Secondly, TS requires",
    ". We extend the regret analysis for optimistic policies to bilinear saddle-point problems which include zero-sum matrix games and constrained bandits as special cases. In this case we extend the regret analysis for optimistic policies to bilinear saddle-point problems. We call the resulting algorithm \u2018 variational Bayesian optimistic sampling \u2019 ( VBOS ). Firstly, TS requires samples from the true posterior, which may be intractable for some problems. Secondly, TS requires",
    ". We extend the regret analysis for optimistic policies to bilinear saddle-point problems which include zero-sum matrix games and constrained bandits as special cases. In this case we extend the regret analysis for optimistic policies to bilinear saddle-point problems. We call the resulting algorithm \u2018 variational Bayesian optimistic sampling \u2019 ( VBOS ). Firstly, TS requires samples from the true posterior, which may be intractable for some problems. Secondly, TS requires",
    ". We extend the regret analysis for optimistic policies to bilinear saddle-point problems which include zero-sum matrix games and constrained bandits as special cases. In this case we extend the regret analysis for optimistic policies to bilinear saddle-point problems. We call the resulting algorithm \u2018 variational Bayesian optimistic sampling \u2019 ( VBOS ). Firstly, TS requires samples from the true posterior, which may be intractable for some problems. Secondly, TS requires",
    "finite-sum composite optimization problem min xRd F ( x ) + r ( x ) and F ( x ) = 1 n n i=1 fi ( x ). ( 1 ) where each fi ( x ) is differentiable and convex. ( 1 ) where each fi ( x ) is differentiable and convex. ( 1 ) where each fi ( x ) is differenti",
    "finite-sum composite optimization problem min xRd F ( x ) + r ( x ) and F ( x ) = 1 n n i=1 fi ( x ). ( 1 ) where each fi ( x ) is differentiable and convex. ( 1 ) where each fi ( x ) is differentiable and convex. ( 1 ) where each fi ( x ) is differenti",
    "finite-sum composite optimization problem min xRd F ( x ) + r ( x ) and F ( x ) = 1 n n i=1 fi ( x ). ( 1 ) where each fi ( x ) is differentiable and convex. ( 1 ) where each fi ( x ) is differentiable and convex. ( 1 ) where each fi ( x ) is differenti",
    "finite-sum composite optimization problem min xRd F ( x ) + r ( x ) and F ( x ) = 1 n n i=1 fi ( x ). ( 1 ) where each fi ( x ) is differentiable and convex. ( 1 ) where each fi ( x ) is differentiable and convex. ( 1 ) where each fi ( x ) is differenti",
    "a logsumexp objective in terms of state-action advantages. If this objective is optimized, then the optimal policy of the original primal problem may be derived as a softmax of the state-action advantages. If this objective is optimized, then the optimal policy of the original primal problem may be derived as a softmax of the state-action advantages. Second, in practice, the dual objective in terms of advantages is likely not optimized fully. Rather, standard gradient-",
    "a logsumexp objective in terms of state-action advantages. If this objective is optimized, then the optimal policy of the original primal problem may be derived as a softmax of the state-action advantages. If this objective is optimized, then the optimal policy of the original primal problem may be derived as a softmax of the state-action advantages. Second, in practice, the dual objective in terms of advantages is likely not optimized fully. Rather, standard gradient-",
    "a logsumexp objective in terms of state-action advantages. If this objective is optimized, then the optimal policy of the original primal problem may be derived as a softmax of the state-action advantages. If this objective is optimized, then the optimal policy of the original primal problem may be derived as a softmax of the state-action advantages. Second, in practice, the dual objective in terms of advantages is likely not optimized fully. Rather, standard gradient-",
    "a logsumexp objective in terms of state-action advantages. If this objective is optimized, then the optimal policy of the original primal problem may be derived as a softmax of the state-action advantages. If this objective is optimized, then the optimal policy of the original primal problem may be derived as a softmax of the state-action advantages. Second, in practice, the dual objective in terms of advantages is likely not optimized fully. Rather, standard gradient-",
    "the generalization and robustness of feature representations. This paper focuses on the intersection of the above two directions. The first is to explain the knowledge encoded in a DNN. The second is to evaluate the representation power of a DNN. These metrics provide new perspectives to diagnose DNNs for 3D point clouds. Specifically, we aim to design metrics to illustrate properties of feature representations for different point cloud regions. These metrics provide new perspectives to diagnose DNNs for 3D point clouds",
    "the generalization and robustness of feature representations. This paper focuses on the intersection of the above two directions. The first is to explain the knowledge encoded in a DNN. The second is to evaluate the representation power of a DNN. These metrics provide new perspectives to diagnose DNNs for 3D point clouds. Specifically, we aim to design metrics to illustrate properties of feature representations for different point cloud regions. These metrics provide new perspectives to diagnose DNNs for 3D point clouds",
    "the generalization and robustness of feature representations. This paper focuses on the intersection of the above two directions. The first is to explain the knowledge encoded in a DNN. The second is to evaluate the representation power of a DNN. These metrics provide new perspectives to diagnose DNNs for 3D point clouds. Specifically, we aim to design metrics to illustrate properties of feature representations for different point cloud regions. These metrics provide new perspectives to diagnose DNNs for 3D point clouds",
    "the generalization and robustness of feature representations. This paper focuses on the intersection of the above two directions. The first is to explain the knowledge encoded in a DNN. The second is to evaluate the representation power of a DNN. These metrics provide new perspectives to diagnose DNNs for 3D point clouds. Specifically, we aim to design metrics to illustrate properties of feature representations for different point cloud regions. These metrics provide new perspectives to diagnose DNNs for 3D point clouds",
    ". Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a single item. Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a single item. Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a",
    ". Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a single item. Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a single item. Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a",
    ". Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a single item. Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a single item. Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a",
    ". Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a single item. Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a single item. Beyond this case, results are more limited. Myerson \u2019 s work completely characterizes strategyproof, revenue-maximizing auctions for a",
    ".... j \u2019 s data set Dj ; the user \u2019 s goal is to learn a prediction rule that generalizes well to unseen examples from Pj. We show that our algorithms satisfy user-level privacy guarantees. We also establish a general, information-theoretic upper bound via an exponential mechanism-based algorithm. 1 Introduction. In this paper, we present a model for reasoning rigorously about the loss to",
    ".... j \u2019 s data set Dj ; the user \u2019 s goal is to learn a prediction rule that generalizes well to unseen examples from Pj. We show that our algorithms satisfy user-level privacy guarantees. We also establish a general, information-theoretic upper bound via an exponential mechanism-based algorithm. 1 Introduction. In this paper, we present a model for reasoning rigorously about the loss to",
    ".... j \u2019 s data set Dj ; the user \u2019 s goal is to learn a prediction rule that generalizes well to unseen examples from Pj. We show that our algorithms satisfy user-level privacy guarantees. We also establish a general, information-theoretic upper bound via an exponential mechanism-based algorithm. 1 Introduction. In this paper, we present a model for reasoning rigorously about the loss to",
    ".... j \u2019 s data set Dj ; the user \u2019 s goal is to learn a prediction rule that generalizes well to unseen examples from Pj. We show that our algorithms satisfy user-level privacy guarantees. We also establish a general, information-theoretic upper bound via an exponential mechanism-based algorithm. 1 Introduction. In this paper, we present a model for reasoning rigorously about the loss to",
    ". This raises important questions for the field : To what extent have we solved the problem? If we haven \u2019 t, what are we still missing? How good are we really? Work done as an intern at Facebook AI Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Work done as an intern at Facebook AI Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". This raises important questions for the field : To what extent have we solved the problem? If we haven \u2019 t, what are we still missing? How good are we really? Work done as an intern at Facebook AI Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Work done as an intern at Facebook AI Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". This raises important questions for the field : To what extent have we solved the problem? If we haven \u2019 t, what are we still missing? How good are we really? Work done as an intern at Facebook AI Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Work done as an intern at Facebook AI Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". This raises important questions for the field : To what extent have we solved the problem? If we haven \u2019 t, what are we still missing? How good are we really? Work done as an intern at Facebook AI Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Work done as an intern at Facebook AI Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "grid-like cells that fire only when an animal faces a particular direction are among the more stereotypical MEC grid-like cells. Furthermore, border cells that fire only when an animal faces a particular direction are among the more stereotypical grid-like cells. How can we characterize what these other, more heterogeneous populations of cells do? To this end, we identify the similarity transform between neural populations in different animals. To this end, we identify the similarity transform between neural populations in",
    "grid-like cells that fire only when an animal faces a particular direction are among the more stereotypical MEC grid-like cells. Furthermore, border cells that fire only when an animal faces a particular direction are among the more stereotypical grid-like cells. How can we characterize what these other, more heterogeneous populations of cells do? To this end, we identify the similarity transform between neural populations in different animals. To this end, we identify the similarity transform between neural populations in",
    "grid-like cells that fire only when an animal faces a particular direction are among the more stereotypical MEC grid-like cells. Furthermore, border cells that fire only when an animal faces a particular direction are among the more stereotypical grid-like cells. How can we characterize what these other, more heterogeneous populations of cells do? To this end, we identify the similarity transform between neural populations in different animals. To this end, we identify the similarity transform between neural populations in",
    "grid-like cells that fire only when an animal faces a particular direction are among the more stereotypical MEC grid-like cells. Furthermore, border cells that fire only when an animal faces a particular direction are among the more stereotypical grid-like cells. How can we characterize what these other, more heterogeneous populations of cells do? To this end, we identify the similarity transform between neural populations in different animals. To this end, we identify the similarity transform between neural populations in",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    "( P )  P,  1/d. In this paper, we introduce a teacher-student framework for kernel regression. ( 1 ) Here, x is a d-dimensional input and xi denotes a d-dimensional output. ( 2 ) Here, xi denotes a d-dimensional output and xi denotes a d-dimensional output. ( 3 ) Here,",
    "( P )  P,  1/d. In this paper, we introduce a teacher-student framework for kernel regression. ( 1 ) Here, x is a d-dimensional input and xi denotes a d-dimensional output. ( 2 ) Here, xi denotes a d-dimensional output and xi denotes a d-dimensional output. ( 3 ) Here,",
    "( P )  P,  1/d. In this paper, we introduce a teacher-student framework for kernel regression. ( 1 ) Here, x is a d-dimensional input and xi denotes a d-dimensional output. ( 2 ) Here, xi denotes a d-dimensional output and xi denotes a d-dimensional output. ( 3 ) Here,",
    "( P )  P,  1/d. In this paper, we introduce a teacher-student framework for kernel regression. ( 1 ) Here, x is a d-dimensional input and xi denotes a d-dimensional output. ( 2 ) Here, xi denotes a d-dimensional output and xi denotes a d-dimensional output. ( 3 ) Here,",
    "the decoder network to efficiently generate new samples from the training distribution. In contrast to the KL-divergence, the Wasserstein distance measure induces a metric on probability. Moreover, it prevents the undesired behaviour of multiple data points being mapped to the same latent representation by the encoder. In contrast, the Wasserstein distance measure induces a metric on probability. In contrast to the KL-divergence, the Wasserstein distance",
    "the decoder network to efficiently generate new samples from the training distribution. In contrast to the KL-divergence, the Wasserstein distance measure induces a metric on probability. Moreover, it prevents the undesired behaviour of multiple data points being mapped to the same latent representation by the encoder. In contrast, the Wasserstein distance measure induces a metric on probability. In contrast to the KL-divergence, the Wasserstein distance",
    "the decoder network to efficiently generate new samples from the training distribution. In contrast to the KL-divergence, the Wasserstein distance measure induces a metric on probability. Moreover, it prevents the undesired behaviour of multiple data points being mapped to the same latent representation by the encoder. In contrast, the Wasserstein distance measure induces a metric on probability. In contrast to the KL-divergence, the Wasserstein distance",
    "the decoder network to efficiently generate new samples from the training distribution. In contrast to the KL-divergence, the Wasserstein distance measure induces a metric on probability. Moreover, it prevents the undesired behaviour of multiple data points being mapped to the same latent representation by the encoder. In contrast, the Wasserstein distance measure induces a metric on probability. In contrast to the KL-divergence, the Wasserstein distance",
    ". In this work, we investigate to detect adversarial examples by disentangling input images as class features and semantic features. By disentangling input images as class features and semantic features, we train an autoencoder over both correctly paired class/semantic features and in-11 correctly paired class/semantic features to reconstruct benign and counterexamples. Notably, our method exhibits better performance in various measurements ( AUC, FPR, TPR",
    ". In this work, we investigate to detect adversarial examples by disentangling input images as class features and semantic features. By disentangling input images as class features and semantic features, we train an autoencoder over both correctly paired class/semantic features and in-11 correctly paired class/semantic features to reconstruct benign and counterexamples. Notably, our method exhibits better performance in various measurements ( AUC, FPR, TPR",
    ". In this work, we investigate to detect adversarial examples by disentangling input images as class features and semantic features. By disentangling input images as class features and semantic features, we train an autoencoder over both correctly paired class/semantic features and in-11 correctly paired class/semantic features to reconstruct benign and counterexamples. Notably, our method exhibits better performance in various measurements ( AUC, FPR, TPR",
    ". In this work, we investigate to detect adversarial examples by disentangling input images as class features and semantic features. By disentangling input images as class features and semantic features, we train an autoencoder over both correctly paired class/semantic features and in-11 correctly paired class/semantic features to reconstruct benign and counterexamples. Notably, our method exhibits better performance in various measurements ( AUC, FPR, TPR",
    ". However, there is no consensus on which brain regions are involved in processing syntax. To date, there is no consensus on which brain regions are involved in processing syntax. In the past decade, neuroscientists have devised 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). complexity metrics capturing the word-by-word evolving syntactic demands required to understand the material. complexity metrics identifying regions with activity correlated with syntactic effort.",
    ". However, there is no consensus on which brain regions are involved in processing syntax. To date, there is no consensus on which brain regions are involved in processing syntax. In the past decade, neuroscientists have devised 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). complexity metrics capturing the word-by-word evolving syntactic demands required to understand the material. complexity metrics identifying regions with activity correlated with syntactic effort.",
    ". However, there is no consensus on which brain regions are involved in processing syntax. To date, there is no consensus on which brain regions are involved in processing syntax. In the past decade, neuroscientists have devised 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). complexity metrics capturing the word-by-word evolving syntactic demands required to understand the material. complexity metrics identifying regions with activity correlated with syntactic effort.",
    ". However, there is no consensus on which brain regions are involved in processing syntax. To date, there is no consensus on which brain regions are involved in processing syntax. In the past decade, neuroscientists have devised 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). complexity metrics capturing the word-by-word evolving syntactic demands required to understand the material. complexity metrics identifying regions with activity correlated with syntactic effort.",
    ".. ( i ) Since the set of attributes is fixed and pre-defined, it is difficult to introduce new attributes to an existing model. This, in turn, limits the model \u2019 s compositional ability for unseen attributes and their novel combinations. This, in turn, limits the model \u2019 s compositional ability for novel concept combinations. This, in turn, limits the model \u2019 s compositional ability for novel concept combinations.",
    ".. ( i ) Since the set of attributes is fixed and pre-defined, it is difficult to introduce new attributes to an existing model. This, in turn, limits the model \u2019 s compositional ability for unseen attributes and their novel combinations. This, in turn, limits the model \u2019 s compositional ability for novel concept combinations. This, in turn, limits the model \u2019 s compositional ability for novel concept combinations.",
    ".. ( i ) Since the set of attributes is fixed and pre-defined, it is difficult to introduce new attributes to an existing model. This, in turn, limits the model \u2019 s compositional ability for unseen attributes and their novel combinations. This, in turn, limits the model \u2019 s compositional ability for novel concept combinations. This, in turn, limits the model \u2019 s compositional ability for novel concept combinations.",
    ".. ( i ) Since the set of attributes is fixed and pre-defined, it is difficult to introduce new attributes to an existing model. This, in turn, limits the model \u2019 s compositional ability for unseen attributes and their novel combinations. This, in turn, limits the model \u2019 s compositional ability for novel concept combinations. This, in turn, limits the model \u2019 s compositional ability for novel concept combinations.",
    "a reward that is unknown to the player. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time in order to maximize the cumulative reward",
    "a reward that is unknown to the player. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time in order to maximize the cumulative reward",
    "a reward that is unknown to the player. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time in order to maximize the cumulative reward",
    "a reward that is unknown to the player. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time. With all previous observations, the player needs to decide which arm to pull each time in order to maximize the cumulative reward",
    "a model-based offline RL algorithm that matches or exceeds the performance of prior offline RL algorithms in benchmark tasks. Offline reinforcement learning ( offline RL ) [ 30, 34 ] refers to the setting where policies are trained using static, previously collected datasets. In contrast, model-based algorithms learn a pessimistic dynamics model, which in turn induces a conservative estimate of the value function. In this work, we develop a principled model-based",
    "a model-based offline RL algorithm that matches or exceeds the performance of prior offline RL algorithms in benchmark tasks. Offline reinforcement learning ( offline RL ) [ 30, 34 ] refers to the setting where policies are trained using static, previously collected datasets. In contrast, model-based algorithms learn a pessimistic dynamics model, which in turn induces a conservative estimate of the value function. In this work, we develop a principled model-based",
    "a model-based offline RL algorithm that matches or exceeds the performance of prior offline RL algorithms in benchmark tasks. Offline reinforcement learning ( offline RL ) [ 30, 34 ] refers to the setting where policies are trained using static, previously collected datasets. In contrast, model-based algorithms learn a pessimistic dynamics model, which in turn induces a conservative estimate of the value function. In this work, we develop a principled model-based",
    "a model-based offline RL algorithm that matches or exceeds the performance of prior offline RL algorithms in benchmark tasks. Offline reinforcement learning ( offline RL ) [ 30, 34 ] refers to the setting where policies are trained using static, previously collected datasets. In contrast, model-based algorithms learn a pessimistic dynamics model, which in turn induces a conservative estimate of the value function. In this work, we develop a principled model-based",
    ". For near-term purposes, we are interested in how data from different classes gradually become separable in their feature space by repetitively calling backpropagation. More precisely, imagine that the gradient is evaluated in an image of a cat, how does the hidden representation of another image\u2014say, an image of another 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). In this spirit, we are interested in how data from different classes gradually become separable in their",
    ". For near-term purposes, we are interested in how data from different classes gradually become separable in their feature space by repetitively calling backpropagation. More precisely, imagine that the gradient is evaluated in an image of a cat, how does the hidden representation of another image\u2014say, an image of another 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). In this spirit, we are interested in how data from different classes gradually become separable in their",
    ". For near-term purposes, we are interested in how data from different classes gradually become separable in their feature space by repetitively calling backpropagation. More precisely, imagine that the gradient is evaluated in an image of a cat, how does the hidden representation of another image\u2014say, an image of another 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). In this spirit, we are interested in how data from different classes gradually become separable in their",
    ". For near-term purposes, we are interested in how data from different classes gradually become separable in their feature space by repetitively calling backpropagation. More precisely, imagine that the gradient is evaluated in an image of a cat, how does the hidden representation of another image\u2014say, an image of another 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). In this spirit, we are interested in how data from different classes gradually become separable in their",
    ". Contributed equally. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at US",
    ". Contributed equally. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at US",
    ". Contributed equally. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at US",
    ". Contributed equally. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at USC. Work partially done as a visiting scholar at US",
    ". However, these numerical methods are often quite computationally expensive. As a result, the area of Scientific Machine Learning ( SciML ) has emerged. ( typically, differential equations ). ( typically, PDEs ). As a result, the area of Scientific Machine Learning ( SciML ) aims to couple traditional scientific mechanistic modeling. ( typically, PDEs ) with data-driven ML methodologies. ( most recently, neural",
    ". However, these numerical methods are often quite computationally expensive. As a result, the area of Scientific Machine Learning ( SciML ) has emerged. ( typically, differential equations ). ( typically, PDEs ). As a result, the area of Scientific Machine Learning ( SciML ) aims to couple traditional scientific mechanistic modeling. ( typically, PDEs ) with data-driven ML methodologies. ( most recently, neural",
    ". However, these numerical methods are often quite computationally expensive. As a result, the area of Scientific Machine Learning ( SciML ) has emerged. ( typically, differential equations ). ( typically, PDEs ). As a result, the area of Scientific Machine Learning ( SciML ) aims to couple traditional scientific mechanistic modeling. ( typically, PDEs ) with data-driven ML methodologies. ( most recently, neural",
    ". However, these numerical methods are often quite computationally expensive. As a result, the area of Scientific Machine Learning ( SciML ) has emerged. ( typically, differential equations ). ( typically, PDEs ). As a result, the area of Scientific Machine Learning ( SciML ) aims to couple traditional scientific mechanistic modeling. ( typically, PDEs ) with data-driven ML methodologies. ( most recently, neural",
    "a.k.a. domain alignment. Recently, self-training ( a.k.a. pseudo-labeling ) has been gaining momentum as a promising alternative to feature adaptation. Using confidence threshold or reweighting, recent works try to alleviate the negative effect of domain alignment. Corresponding author : Mingsheng Long ( mingshenglong). Corresponding author : mingshe",
    "a.k.a. domain alignment. Recently, self-training ( a.k.a. pseudo-labeling ) has been gaining momentum as a promising alternative to feature adaptation. Using confidence threshold or reweighting, recent works try to alleviate the negative effect of domain alignment. Corresponding author : Mingsheng Long ( mingshenglong). Corresponding author : mingshe",
    "a.k.a. domain alignment. Recently, self-training ( a.k.a. pseudo-labeling ) has been gaining momentum as a promising alternative to feature adaptation. Using confidence threshold or reweighting, recent works try to alleviate the negative effect of domain alignment. Corresponding author : Mingsheng Long ( mingshenglong). Corresponding author : mingshe",
    "a.k.a. domain alignment. Recently, self-training ( a.k.a. pseudo-labeling ) has been gaining momentum as a promising alternative to feature adaptation. Using confidence threshold or reweighting, recent works try to alleviate the negative effect of domain alignment. Corresponding author : Mingsheng Long ( mingshenglong). Corresponding author : mingshe",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    "parent_child ( A, B ) AND parent_child ( A, V ), which in turn can be used to construct yet another relation cousin ( U, V ). In doing so, they only reuse computational units ( here, RNN cells ) vertically, i.e., in depth. Such rigidity , Equal contribution, ordered alphabetically by last name. 1Max-Planck-Institute for Intelligent Systems",
    "parent_child ( A, B ) AND parent_child ( A, V ), which in turn can be used to construct yet another relation cousin ( U, V ). In doing so, they only reuse computational units ( here, RNN cells ) vertically, i.e., in depth. Such rigidity , Equal contribution, ordered alphabetically by last name. 1Max-Planck-Institute for Intelligent Systems",
    "parent_child ( A, B ) AND parent_child ( A, V ), which in turn can be used to construct yet another relation cousin ( U, V ). In doing so, they only reuse computational units ( here, RNN cells ) vertically, i.e., in depth. Such rigidity , Equal contribution, ordered alphabetically by last name. 1Max-Planck-Institute for Intelligent Systems",
    "parent_child ( A, B ) AND parent_child ( A, V ), which in turn can be used to construct yet another relation cousin ( U, V ). In doing so, they only reuse computational units ( here, RNN cells ) vertically, i.e., in depth. Such rigidity , Equal contribution, ordered alphabetically by last name. 1Max-Planck-Institute for Intelligent Systems",
    "pre-trained policies can be leveraged for exploration and that is complementary to fine-tuning neural network weights. When combined with standard fine-tuning strategies, the largest gains are generally observed in challenging domains like computer vision [ 31, 30 ] and natural language processing [ 15, 50 ]. The benefits of unsupervised methods that learn in the absence of reward27 have also garnered much research attention.",
    "pre-trained policies can be leveraged for exploration and that is complementary to fine-tuning neural network weights. When combined with standard fine-tuning strategies, the largest gains are generally observed in challenging domains like computer vision [ 31, 30 ] and natural language processing [ 15, 50 ]. The benefits of unsupervised methods that learn in the absence of reward27 have also garnered much research attention.",
    "pre-trained policies can be leveraged for exploration and that is complementary to fine-tuning neural network weights. When combined with standard fine-tuning strategies, the largest gains are generally observed in challenging domains like computer vision [ 31, 30 ] and natural language processing [ 15, 50 ]. The benefits of unsupervised methods that learn in the absence of reward27 have also garnered much research attention.",
    "pre-trained policies can be leveraged for exploration and that is complementary to fine-tuning neural network weights. When combined with standard fine-tuning strategies, the largest gains are generally observed in challenging domains like computer vision [ 31, 30 ] and natural language processing [ 15, 50 ]. The benefits of unsupervised methods that learn in the absence of reward27 have also garnered much research attention.",
    "based on scores of pairs of items in a ranked list. The distribution over scores is defined with respect to scores of pairs of items in a ranked list. Surrogate loss functions, in turn, can belong to one of three types. PiRank, a listwise approach where the scores are learned via deep neural networks and the surrogate loss is obtained via a differentiable relaxation to the sorting operator. This work was done prior to joining Amazon. 35th",
    "based on scores of pairs of items in a ranked list. The distribution over scores is defined with respect to scores of pairs of items in a ranked list. Surrogate loss functions, in turn, can belong to one of three types. PiRank, a listwise approach where the scores are learned via deep neural networks and the surrogate loss is obtained via a differentiable relaxation to the sorting operator. This work was done prior to joining Amazon. 35th",
    "based on scores of pairs of items in a ranked list. The distribution over scores is defined with respect to scores of pairs of items in a ranked list. Surrogate loss functions, in turn, can belong to one of three types. PiRank, a listwise approach where the scores are learned via deep neural networks and the surrogate loss is obtained via a differentiable relaxation to the sorting operator. This work was done prior to joining Amazon. 35th",
    "based on scores of pairs of items in a ranked list. The distribution over scores is defined with respect to scores of pairs of items in a ranked list. Surrogate loss functions, in turn, can belong to one of three types. PiRank, a listwise approach where the scores are learned via deep neural networks and the surrogate loss is obtained via a differentiable relaxation to the sorting operator. This work was done prior to joining Amazon. 35th",
    "[ 1 ].... |00... 0,. Then............  (  ) |H| (  )  ), ( 1 ). ( 1 )...",
    "[ 1 ].... |00... 0,. Then............  (  ) |H| (  )  ), ( 1 ). ( 1 )...",
    "[ 1 ].... |00... 0,. Then............  (  ) |H| (  )  ), ( 1 ). ( 1 )...",
    "[ 1 ].... |00... 0,. Then............  (  ) |H| (  )  ), ( 1 ). ( 1 )...",
    "supervised by a support set containing a few labeled samples per new class. To simulate generalization challenges at test times, such strategies build sequences of artificially balanced few-shot tasks. To simulate generalization challenges at test times, such strategies build sequences of artificially balanced few-shot tasks ( or episodes ) during base training. To simulate generalization challenges, such strategies build sequences of artificially balanced few-shot tasks ( or episodes ) during base training.",
    "supervised by a support set containing a few labeled samples per new class. To simulate generalization challenges at test times, such strategies build sequences of artificially balanced few-shot tasks. To simulate generalization challenges at test times, such strategies build sequences of artificially balanced few-shot tasks ( or episodes ) during base training. To simulate generalization challenges, such strategies build sequences of artificially balanced few-shot tasks ( or episodes ) during base training.",
    "supervised by a support set containing a few labeled samples per new class. To simulate generalization challenges at test times, such strategies build sequences of artificially balanced few-shot tasks. To simulate generalization challenges at test times, such strategies build sequences of artificially balanced few-shot tasks ( or episodes ) during base training. To simulate generalization challenges, such strategies build sequences of artificially balanced few-shot tasks ( or episodes ) during base training.",
    "supervised by a support set containing a few labeled samples per new class. To simulate generalization challenges at test times, such strategies build sequences of artificially balanced few-shot tasks. To simulate generalization challenges at test times, such strategies build sequences of artificially balanced few-shot tasks ( or episodes ) during base training. To simulate generalization challenges, such strategies build sequences of artificially balanced few-shot tasks ( or episodes ) during base training.",
    "tiny deep learning on microcontroller units ( MCUs ) is challenging due to the limited memory size. patch-by-patch inference scheduling effectively reduces the peak memory usage of existing networks by 4-8. receptive field redistribution to shift the receptive field and FLOPs to the later stage and reduce the computation overhead. MCUNetV2 sets a record ImageNet accuracy on MCU ( 71.8 % ) and achieves 16.9 % higher m",
    "tiny deep learning on microcontroller units ( MCUs ) is challenging due to the limited memory size. patch-by-patch inference scheduling effectively reduces the peak memory usage of existing networks by 4-8. receptive field redistribution to shift the receptive field and FLOPs to the later stage and reduce the computation overhead. MCUNetV2 sets a record ImageNet accuracy on MCU ( 71.8 % ) and achieves 16.9 % higher m",
    "tiny deep learning on microcontroller units ( MCUs ) is challenging due to the limited memory size. patch-by-patch inference scheduling effectively reduces the peak memory usage of existing networks by 4-8. receptive field redistribution to shift the receptive field and FLOPs to the later stage and reduce the computation overhead. MCUNetV2 sets a record ImageNet accuracy on MCU ( 71.8 % ) and achieves 16.9 % higher m",
    "tiny deep learning on microcontroller units ( MCUs ) is challenging due to the limited memory size. patch-by-patch inference scheduling effectively reduces the peak memory usage of existing networks by 4-8. receptive field redistribution to shift the receptive field and FLOPs to the later stage and reduce the computation overhead. MCUNetV2 sets a record ImageNet accuracy on MCU ( 71.8 % ) and achieves 16.9 % higher m",
    "a company assembles an internal research group to develop key technologies to be used in its next-generation product in 5 years. Since research progress is hard to monitor, the company manages the group based on its annual reports. At the beginning of each year, the group submits a report. Taking into consideration this report, the company decides the compensation level and the headcount of the group in the current year. Moreover, after the product launches, the company may also pay a",
    "a company assembles an internal research group to develop key technologies to be used in its next-generation product in 5 years. Since research progress is hard to monitor, the company manages the group based on its annual reports. At the beginning of each year, the group submits a report. Taking into consideration this report, the company decides the compensation level and the headcount of the group in the current year. Moreover, after the product launches, the company may also pay a",
    "a company assembles an internal research group to develop key technologies to be used in its next-generation product in 5 years. Since research progress is hard to monitor, the company manages the group based on its annual reports. At the beginning of each year, the group submits a report. Taking into consideration this report, the company decides the compensation level and the headcount of the group in the current year. Moreover, after the product launches, the company may also pay a",
    "a company assembles an internal research group to develop key technologies to be used in its next-generation product in 5 years. Since research progress is hard to monitor, the company manages the group based on its annual reports. At the beginning of each year, the group submits a report. Taking into consideration this report, the company decides the compensation level and the headcount of the group in the current year. Moreover, after the product launches, the company may also pay a",
    "graph related tasks. ( i ) How does graph architecture search select its desired architectures? and ( ii ) How optimal are the architectures selected by graph neural architecture search? and ( iii ) How optimal are the architectures selected by graph neural architecture search? 2 Nevertheless, the failure of existing works in answering the questions significantly limits their capabilities of designing powerful GNN architectures. In this paper, we explore how graph neural architecture search is able to select the desired",
    "graph related tasks. ( i ) How does graph architecture search select its desired architectures? and ( ii ) How optimal are the architectures selected by graph neural architecture search? and ( iii ) How optimal are the architectures selected by graph neural architecture search? 2 Nevertheless, the failure of existing works in answering the questions significantly limits their capabilities of designing powerful GNN architectures. In this paper, we explore how graph neural architecture search is able to select the desired",
    "graph related tasks. ( i ) How does graph architecture search select its desired architectures? and ( ii ) How optimal are the architectures selected by graph neural architecture search? and ( iii ) How optimal are the architectures selected by graph neural architecture search? 2 Nevertheless, the failure of existing works in answering the questions significantly limits their capabilities of designing powerful GNN architectures. In this paper, we explore how graph neural architecture search is able to select the desired",
    "graph related tasks. ( i ) How does graph architecture search select its desired architectures? and ( ii ) How optimal are the architectures selected by graph neural architecture search? and ( iii ) How optimal are the architectures selected by graph neural architecture search? 2 Nevertheless, the failure of existing works in answering the questions significantly limits their capabilities of designing powerful GNN architectures. In this paper, we explore how graph neural architecture search is able to select the desired",
    "a clustering objective is given. For example, there may be two colors, red and blue, and the constraint could require per-color representation between 40 % and 60 %. This constraint is called the price of fairness ( PoF ), mathematically defined as PoF = ( cost of fair solution ) / ( cost of agnostic solution ). The price of fairness ( PoF ) is not a morally-laden and application-",
    "a clustering objective is given. For example, there may be two colors, red and blue, and the constraint could require per-color representation between 40 % and 60 %. This constraint is called the price of fairness ( PoF ), mathematically defined as PoF = ( cost of fair solution ) / ( cost of agnostic solution ). The price of fairness ( PoF ) is not a morally-laden and application-",
    "a clustering objective is given. For example, there may be two colors, red and blue, and the constraint could require per-color representation between 40 % and 60 %. This constraint is called the price of fairness ( PoF ), mathematically defined as PoF = ( cost of fair solution ) / ( cost of agnostic solution ). The price of fairness ( PoF ) is not a morally-laden and application-",
    "a clustering objective is given. For example, there may be two colors, red and blue, and the constraint could require per-color representation between 40 % and 60 %. This constraint is called the price of fairness ( PoF ), mathematically defined as PoF = ( cost of fair solution ) / ( cost of agnostic solution ). The price of fairness ( PoF ) is not a morally-laden and application-",
    "E ( G ) ( 1 Pij ) /E ( G ) ( 1 Pij ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ). Our work centers on edge independent graph models",
    "E ( G ) ( 1 Pij ) /E ( G ) ( 1 Pij ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ). Our work centers on edge independent graph models",
    "E ( G ) ( 1 Pij ) /E ( G ) ( 1 Pij ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ). Our work centers on edge independent graph models",
    "E ( G ) ( 1 Pij ) /E ( G ) ( 1 Pij ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ) ( 0, 1 ). Our work centers on edge independent graph models",
    ".1 1Definition in Section 2. Nonsmooth algorithmic differentiation : The training phase of neural networks relies on firstorder methods such as SGD [ 14, 9 ] and crucially on algorithmic differentiation [ 15 ].1 1Definition in Section 2.1 1Definition in Section 2.1 1Definition in Section 3.1 1Definition in Section 4.1 1Definition in Section 2.1 1Definition",
    ".1 1Definition in Section 2. Nonsmooth algorithmic differentiation : The training phase of neural networks relies on firstorder methods such as SGD [ 14, 9 ] and crucially on algorithmic differentiation [ 15 ].1 1Definition in Section 2.1 1Definition in Section 2.1 1Definition in Section 3.1 1Definition in Section 4.1 1Definition in Section 2.1 1Definition",
    ".1 1Definition in Section 2. Nonsmooth algorithmic differentiation : The training phase of neural networks relies on firstorder methods such as SGD [ 14, 9 ] and crucially on algorithmic differentiation [ 15 ].1 1Definition in Section 2.1 1Definition in Section 2.1 1Definition in Section 3.1 1Definition in Section 4.1 1Definition in Section 2.1 1Definition",
    ".1 1Definition in Section 2. Nonsmooth algorithmic differentiation : The training phase of neural networks relies on firstorder methods such as SGD [ 14, 9 ] and crucially on algorithmic differentiation [ 15 ].1 1Definition in Section 2.1 1Definition in Section 2.1 1Definition in Section 3.1 1Definition in Section 4.1 1Definition in Section 2.1 1Definition",
    "many areas of reinforcement learning ( RL ) research focus on specialized problems. these problems are often symptoms of a deeper underlying problem. for example, an agent that ignores 99.9 % of bits will prefer states where the dynamics are easy to predict. Moreover, an agent that minimizes bits will prefer states where the dynamics are easy to predict. Moreover, an agent that minimizes bits will prefer states where the dynamics are easy to predict.",
    "many areas of reinforcement learning ( RL ) research focus on specialized problems. these problems are often symptoms of a deeper underlying problem. for example, an agent that ignores 99.9 % of bits will prefer states where the dynamics are easy to predict. Moreover, an agent that minimizes bits will prefer states where the dynamics are easy to predict. Moreover, an agent that minimizes bits will prefer states where the dynamics are easy to predict.",
    "many areas of reinforcement learning ( RL ) research focus on specialized problems. these problems are often symptoms of a deeper underlying problem. for example, an agent that ignores 99.9 % of bits will prefer states where the dynamics are easy to predict. Moreover, an agent that minimizes bits will prefer states where the dynamics are easy to predict. Moreover, an agent that minimizes bits will prefer states where the dynamics are easy to predict.",
    "many areas of reinforcement learning ( RL ) research focus on specialized problems. these problems are often symptoms of a deeper underlying problem. for example, an agent that ignores 99.9 % of bits will prefer states where the dynamics are easy to predict. Moreover, an agent that minimizes bits will prefer states where the dynamics are easy to predict. Moreover, an agent that minimizes bits will prefer states where the dynamics are easy to predict.",
    "[ 17, 19 ].......-learning paradigm has inherent limitations...-learning paradigm has inherent limitations.... .... . .. oversmoothing... over-squashing.....",
    "[ 17, 19 ].......-learning paradigm has inherent limitations...-learning paradigm has inherent limitations.... .... . .. oversmoothing... over-squashing.....",
    "[ 17, 19 ].......-learning paradigm has inherent limitations...-learning paradigm has inherent limitations.... .... . .. oversmoothing... over-squashing.....",
    "[ 17, 19 ].......-learning paradigm has inherent limitations...-learning paradigm has inherent limitations.... .... . .. oversmoothing... over-squashing.....",
    "partisans for Party A prefer candidate a based on her support for the platform of party B ; swing voters prefer candidate b based on her support for the platform of party B ; and finally, there are contingent participants who only have partial information on which alternative is \u201c preferable for them \u201d. In votes for corporate strategies, for hiring decisions, and for policy decisions typically some participants would like to select according to some truth they are collectively trying to find. corresponding author 35th Conference on",
    "partisans for Party A prefer candidate a based on her support for the platform of party B ; swing voters prefer candidate b based on her support for the platform of party B ; and finally, there are contingent participants who only have partial information on which alternative is \u201c preferable for them \u201d. In votes for corporate strategies, for hiring decisions, and for policy decisions typically some participants would like to select according to some truth they are collectively trying to find. corresponding author 35th Conference on",
    "partisans for Party A prefer candidate a based on her support for the platform of party B ; swing voters prefer candidate b based on her support for the platform of party B ; and finally, there are contingent participants who only have partial information on which alternative is \u201c preferable for them \u201d. In votes for corporate strategies, for hiring decisions, and for policy decisions typically some participants would like to select according to some truth they are collectively trying to find. corresponding author 35th Conference on",
    "partisans for Party A prefer candidate a based on her support for the platform of party B ; swing voters prefer candidate b based on her support for the platform of party B ; and finally, there are contingent participants who only have partial information on which alternative is \u201c preferable for them \u201d. In votes for corporate strategies, for hiring decisions, and for policy decisions typically some participants would like to select according to some truth they are collectively trying to find. corresponding author 35th Conference on",
    "sidak first discovered that the Hessian rank formula holds experimentally to high fidelity. he wrote the entire paper and noted the rank-deficiency interpretation. Gregor proved Lemma 8, assisted in a part of Theorem 3, and empirically observed the eventual formula for the Hessian rank. Sidak wrote the entire paper and noted the rank-deficiency interpretation.",
    "sidak first discovered that the Hessian rank formula holds experimentally to high fidelity. he wrote the entire paper and noted the rank-deficiency interpretation. Gregor proved Lemma 8, assisted in a part of Theorem 3, and empirically observed the eventual formula for the Hessian rank. Sidak wrote the entire paper and noted the rank-deficiency interpretation.",
    "sidak first discovered that the Hessian rank formula holds experimentally to high fidelity. he wrote the entire paper and noted the rank-deficiency interpretation. Gregor proved Lemma 8, assisted in a part of Theorem 3, and empirically observed the eventual formula for the Hessian rank. Sidak wrote the entire paper and noted the rank-deficiency interpretation.",
    "sidak first discovered that the Hessian rank formula holds experimentally to high fidelity. he wrote the entire paper and noted the rank-deficiency interpretation. Gregor proved Lemma 8, assisted in a part of Theorem 3, and empirically observed the eventual formula for the Hessian rank. Sidak wrote the entire paper and noted the rank-deficiency interpretation.",
    "LSBD-VAE, a semi-supervised7 method to learn LSBD representations. Furthermore, ( 1 ) various desirable properties expressed by existing disentanglement metrics are10 also achieved by LSBD representations. In this paper we propose a mathematically sound metric to quantify LSBD. Such a metric is crucial to evaluate LSBD methods and to compare to previous understandings of disentanglement.",
    "LSBD-VAE, a semi-supervised7 method to learn LSBD representations. Furthermore, ( 1 ) various desirable properties expressed by existing disentanglement metrics are10 also achieved by LSBD representations. In this paper we propose a mathematically sound metric to quantify LSBD. Such a metric is crucial to evaluate LSBD methods and to compare to previous understandings of disentanglement.",
    "LSBD-VAE, a semi-supervised7 method to learn LSBD representations. Furthermore, ( 1 ) various desirable properties expressed by existing disentanglement metrics are10 also achieved by LSBD representations. In this paper we propose a mathematically sound metric to quantify LSBD. Such a metric is crucial to evaluate LSBD methods and to compare to previous understandings of disentanglement.",
    "LSBD-VAE, a semi-supervised7 method to learn LSBD representations. Furthermore, ( 1 ) various desirable properties expressed by existing disentanglement metrics are10 also achieved by LSBD representations. In this paper we propose a mathematically sound metric to quantify LSBD. Such a metric is crucial to evaluate LSBD methods and to compare to previous understandings of disentanglement.",
    "that DSSMs often do not learn the correct system dynamics. This is suboptimal for accurate predictions or performing downstream tasks. To address these problems, we propose the following solutions : ( i ) we introduce a constrained optimisation ( CO ) framework as a solution. ( ii ) we introduce a constrained optimisation ( CO ) framework as a solution. ( iv ) we introduce a constrained optimisation ( CO ) framework as",
    "that DSSMs often do not learn the correct system dynamics. This is suboptimal for accurate predictions or performing downstream tasks. To address these problems, we propose the following solutions : ( i ) we introduce a constrained optimisation ( CO ) framework as a solution. ( ii ) we introduce a constrained optimisation ( CO ) framework as a solution. ( iv ) we introduce a constrained optimisation ( CO ) framework as",
    "that DSSMs often do not learn the correct system dynamics. This is suboptimal for accurate predictions or performing downstream tasks. To address these problems, we propose the following solutions : ( i ) we introduce a constrained optimisation ( CO ) framework as a solution. ( ii ) we introduce a constrained optimisation ( CO ) framework as a solution. ( iv ) we introduce a constrained optimisation ( CO ) framework as",
    "that DSSMs often do not learn the correct system dynamics. This is suboptimal for accurate predictions or performing downstream tasks. To address these problems, we propose the following solutions : ( i ) we introduce a constrained optimisation ( CO ) framework as a solution. ( ii ) we introduce a constrained optimisation ( CO ) framework as a solution. ( iv ) we introduce a constrained optimisation ( CO ) framework as",
    ". In this paper, we focus on the problem where we have access only to trained deep classifiers and not the actual training data or generative models. In this paper, we focus on the problem where we have access only to trained deep classifiers and not the actual training data or generative models. Synthesizing images from the underlying data distribution 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). by inverting a deep model, while not requiring",
    ". In this paper, we focus on the problem where we have access only to trained deep classifiers and not the actual training data or generative models. In this paper, we focus on the problem where we have access only to trained deep classifiers and not the actual training data or generative models. Synthesizing images from the underlying data distribution 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). by inverting a deep model, while not requiring",
    ". In this paper, we focus on the problem where we have access only to trained deep classifiers and not the actual training data or generative models. In this paper, we focus on the problem where we have access only to trained deep classifiers and not the actual training data or generative models. Synthesizing images from the underlying data distribution 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). by inverting a deep model, while not requiring",
    ". In this paper, we focus on the problem where we have access only to trained deep classifiers and not the actual training data or generative models. In this paper, we focus on the problem where we have access only to trained deep classifiers and not the actual training data or generative models. Synthesizing images from the underlying data distribution 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). by inverting a deep model, while not requiring",
    "Equal contribution 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). In the medical domain, this is referred to as the study of practice variation. In the legal domain, characterizing the cases where judges vary most in their leniency in their decisions can inform the development and dissemination of clinical guidelines.",
    "Equal contribution 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). In the medical domain, this is referred to as the study of practice variation. In the legal domain, characterizing the cases where judges vary most in their leniency in their decisions can inform the development and dissemination of clinical guidelines.",
    "Equal contribution 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). In the medical domain, this is referred to as the study of practice variation. In the legal domain, characterizing the cases where judges vary most in their leniency in their decisions can inform the development and dissemination of clinical guidelines.",
    "Equal contribution 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). In the medical domain, this is referred to as the study of practice variation. In the legal domain, characterizing the cases where judges vary most in their leniency in their decisions can inform the development and dissemination of clinical guidelines.",
    ". a style-based generator architecture.. However, the style-based generator can suffer from the style control via AdaIN operation. This work was done while Yanhong Zeng was a research intern at Microsoft Research Asia. 35th Conference on Neural Information Processing Systems ( NeurIPS ) ( NeurIPS ). This work was done while Yanhong Zeng was a research intern at Microsoft Research Asia. This work was done while Yanhong",
    ". a style-based generator architecture.. However, the style-based generator can suffer from the style control via AdaIN operation. This work was done while Yanhong Zeng was a research intern at Microsoft Research Asia. 35th Conference on Neural Information Processing Systems ( NeurIPS ) ( NeurIPS ). This work was done while Yanhong Zeng was a research intern at Microsoft Research Asia. This work was done while Yanhong",
    ". a style-based generator architecture.. However, the style-based generator can suffer from the style control via AdaIN operation. This work was done while Yanhong Zeng was a research intern at Microsoft Research Asia. 35th Conference on Neural Information Processing Systems ( NeurIPS ) ( NeurIPS ). This work was done while Yanhong Zeng was a research intern at Microsoft Research Asia. This work was done while Yanhong",
    ". a style-based generator architecture.. However, the style-based generator can suffer from the style control via AdaIN operation. This work was done while Yanhong Zeng was a research intern at Microsoft Research Asia. 35th Conference on Neural Information Processing Systems ( NeurIPS ) ( NeurIPS ). This work was done while Yanhong Zeng was a research intern at Microsoft Research Asia. This work was done while Yanhong",
    ". Instead, regularization is commonly used to reduce the effect of noise and to obtain an estimator with better generalization. In particular, a plethora of recent papers explicitly study generalization properties on min-  2-norm interpolators [ 15, 18, 23, 6, 33, 34, 35 ] and max-  2-margin interpolators [ 15, 18, 23, 6, 33, 34, 35",
    ". Instead, regularization is commonly used to reduce the effect of noise and to obtain an estimator with better generalization. In particular, a plethora of recent papers explicitly study generalization properties on min-  2-norm interpolators [ 15, 18, 23, 6, 33, 34, 35 ] and max-  2-margin interpolators [ 15, 18, 23, 6, 33, 34, 35",
    ". Instead, regularization is commonly used to reduce the effect of noise and to obtain an estimator with better generalization. In particular, a plethora of recent papers explicitly study generalization properties on min-  2-norm interpolators [ 15, 18, 23, 6, 33, 34, 35 ] and max-  2-margin interpolators [ 15, 18, 23, 6, 33, 34, 35",
    ". Instead, regularization is commonly used to reduce the effect of noise and to obtain an estimator with better generalization. In particular, a plethora of recent papers explicitly study generalization properties on min-  2-norm interpolators [ 15, 18, 23, 6, 33, 34, 35 ] and max-  2-margin interpolators [ 15, 18, 23, 6, 33, 34, 35",
    "2D images [ 4 ] or 3D point clouds [ 5, 6 ]. Without ground truth correspondence annotations, existing methods cannot be generalized to other categories. In this work, we focus on learning point cloud correspondences. Without ground truth correspondence annotations, existing methods can not be generalized to other categories, e.g., man-made objects. In this work, we focus on learning point cloud correspondences, which remains open challenge since it is inf",
    "2D images [ 4 ] or 3D point clouds [ 5, 6 ]. Without ground truth correspondence annotations, existing methods cannot be generalized to other categories. In this work, we focus on learning point cloud correspondences. Without ground truth correspondence annotations, existing methods can not be generalized to other categories, e.g., man-made objects. In this work, we focus on learning point cloud correspondences, which remains open challenge since it is inf",
    "2D images [ 4 ] or 3D point clouds [ 5, 6 ]. Without ground truth correspondence annotations, existing methods cannot be generalized to other categories. In this work, we focus on learning point cloud correspondences. Without ground truth correspondence annotations, existing methods can not be generalized to other categories, e.g., man-made objects. In this work, we focus on learning point cloud correspondences, which remains open challenge since it is inf",
    "2D images [ 4 ] or 3D point clouds [ 5, 6 ]. Without ground truth correspondence annotations, existing methods cannot be generalized to other categories. In this work, we focus on learning point cloud correspondences. Without ground truth correspondence annotations, existing methods can not be generalized to other categories, e.g., man-made objects. In this work, we focus on learning point cloud correspondences, which remains open challenge since it is inf",
    "domain generalization ( DG ) aims to address domain shift simulated by training and evaluating on different domains. Domain generalization ( DG ) aims to address domain shift simulated by training and evaluating on different domains. DG tasks assume that both task labels and domain labels are accessible. For example, a self-driving car should adapt to adverse weather or day-to-night shifts. For example, a self-driving car should adapt to adverse",
    "domain generalization ( DG ) aims to address domain shift simulated by training and evaluating on different domains. Domain generalization ( DG ) aims to address domain shift simulated by training and evaluating on different domains. DG tasks assume that both task labels and domain labels are accessible. For example, a self-driving car should adapt to adverse weather or day-to-night shifts. For example, a self-driving car should adapt to adverse",
    "domain generalization ( DG ) aims to address domain shift simulated by training and evaluating on different domains. Domain generalization ( DG ) aims to address domain shift simulated by training and evaluating on different domains. DG tasks assume that both task labels and domain labels are accessible. For example, a self-driving car should adapt to adverse weather or day-to-night shifts. For example, a self-driving car should adapt to adverse",
    "domain generalization ( DG ) aims to address domain shift simulated by training and evaluating on different domains. Domain generalization ( DG ) aims to address domain shift simulated by training and evaluating on different domains. DG tasks assume that both task labels and domain labels are accessible. For example, a self-driving car should adapt to adverse weather or day-to-night shifts. For example, a self-driving car should adapt to adverse",
    ". Neural architecture search ( NAS ) is a popular area of machine learning. It aims to automate the process of developing neural architectures for a given dataset. Since 2017, a wide variety of NAS techniques have been proposed [ 78, 45, 32, 49 ]. Recently, a few techniques have been introduced which are fast both in query time and initialization time. However, it is not known how methods from different families compare to one another",
    ". Neural architecture search ( NAS ) is a popular area of machine learning. It aims to automate the process of developing neural architectures for a given dataset. Since 2017, a wide variety of NAS techniques have been proposed [ 78, 45, 32, 49 ]. Recently, a few techniques have been introduced which are fast both in query time and initialization time. However, it is not known how methods from different families compare to one another",
    ". Neural architecture search ( NAS ) is a popular area of machine learning. It aims to automate the process of developing neural architectures for a given dataset. Since 2017, a wide variety of NAS techniques have been proposed [ 78, 45, 32, 49 ]. Recently, a few techniques have been introduced which are fast both in query time and initialization time. However, it is not known how methods from different families compare to one another",
    ". Neural architecture search ( NAS ) is a popular area of machine learning. It aims to automate the process of developing neural architectures for a given dataset. Since 2017, a wide variety of NAS techniques have been proposed [ 78, 45, 32, 49 ]. Recently, a few techniques have been introduced which are fast both in query time and initialization time. However, it is not known how methods from different families compare to one another",
    "we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior",
    "we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior",
    "we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior",
    "we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior sampling in Multinomial-8 Dirichlet sampling and private normalized histogram publishing. Specifically, we provide privacy guarantees of the Dirichlet posterior",
    "an efficient parallel local clustering algorithm. In particular, we show that our algorithm is both memory and round efficient. Finally, we complement our theoretical analysis with experimental results showing that our algorithm is significantly more scalable than previous approaches. Random walks are key components of many machine learning algorithms with several applications in clustering and semi-supervised learning. Despite their relevance, the first efficient parallel algorithm to compute random walks has been introduced very recently ( cki et al. ).",
    "an efficient parallel local clustering algorithm. In particular, we show that our algorithm is both memory and round efficient. Finally, we complement our theoretical analysis with experimental results showing that our algorithm is significantly more scalable than previous approaches. Random walks are key components of many machine learning algorithms with several applications in clustering and semi-supervised learning. Despite their relevance, the first efficient parallel algorithm to compute random walks has been introduced very recently ( cki et al. ).",
    "an efficient parallel local clustering algorithm. In particular, we show that our algorithm is both memory and round efficient. Finally, we complement our theoretical analysis with experimental results showing that our algorithm is significantly more scalable than previous approaches. Random walks are key components of many machine learning algorithms with several applications in clustering and semi-supervised learning. Despite their relevance, the first efficient parallel algorithm to compute random walks has been introduced very recently ( cki et al. ).",
    "an efficient parallel local clustering algorithm. In particular, we show that our algorithm is both memory and round efficient. Finally, we complement our theoretical analysis with experimental results showing that our algorithm is significantly more scalable than previous approaches. Random walks are key components of many machine learning algorithms with several applications in clustering and semi-supervised learning. Despite their relevance, the first efficient parallel algorithm to compute random walks has been introduced very recently ( cki et al. ).",
    "...  1-regularized linear regression (  1- LinR ) [ 18 ] and interaction screening ( IS ) [ 14, 15 ]. This paper focuses on one simpler linear estimator called  1-regularized linear regression (  1- LinR ) and theoretically investigate its typical learning performance using the powerful replica method [ 20, 21, 22, 23 ] from statistical mechanics.",
    "...  1-regularized linear regression (  1- LinR ) [ 18 ] and interaction screening ( IS ) [ 14, 15 ]. This paper focuses on one simpler linear estimator called  1-regularized linear regression (  1- LinR ) and theoretically investigate its typical learning performance using the powerful replica method [ 20, 21, 22, 23 ] from statistical mechanics.",
    "...  1-regularized linear regression (  1- LinR ) [ 18 ] and interaction screening ( IS ) [ 14, 15 ]. This paper focuses on one simpler linear estimator called  1-regularized linear regression (  1- LinR ) and theoretically investigate its typical learning performance using the powerful replica method [ 20, 21, 22, 23 ] from statistical mechanics.",
    "...  1-regularized linear regression (  1- LinR ) [ 18 ] and interaction screening ( IS ) [ 14, 15 ]. This paper focuses on one simpler linear estimator called  1-regularized linear regression (  1- LinR ) and theoretically investigate its typical learning performance using the powerful replica method [ 20, 21, 22, 23 ] from statistical mechanics.",
    "at most k. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Soft k-means is a",
    "at most k. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Soft k-means is a",
    "at most k. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Soft k-means is a",
    "at most k. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Hence, whatever is achievable with membership queries, can also be achieved by same cluster queries by asking at most k times as many queries. Soft k-means is a",
    "by additionally encouraging a learned model m and value function v to be jointly self-consistent. Our approach differs from classic planning methods such as Dyna, which only update values to be consistent with the model. Self-consistency, by contrast, jointly updates the model and value function to be consistent with each other.",
    "by additionally encouraging a learned model m and value function v to be jointly self-consistent. Our approach differs from classic planning methods such as Dyna, which only update values to be consistent with the model. Self-consistency, by contrast, jointly updates the model and value function to be consistent with each other.",
    "by additionally encouraging a learned model m and value function v to be jointly self-consistent. Our approach differs from classic planning methods such as Dyna, which only update values to be consistent with the model. Self-consistency, by contrast, jointly updates the model and value function to be consistent with each other.",
    "by additionally encouraging a learned model m and value function v to be jointly self-consistent. Our approach differs from classic planning methods such as Dyna, which only update values to be consistent with the model. Self-consistency, by contrast, jointly updates the model and value function to be consistent with each other.",
    "Equal contributions ; work done while at Amazon Web Services. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon",
    "Equal contributions ; work done while at Amazon Web Services. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon",
    "Equal contributions ; work done while at Amazon Web Services. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon",
    "Equal contributions ; work done while at Amazon Web Services. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon. Equal contributions ; work done while at Amazon",
    ". We present numerical simulations that corroborate our theoretical results. 1 Introduction. Linear bandits provide simple, yet commonly encountered, models for a variety of sequential decision-making problems under uncertainty. However, linear bandits fail to model a host of other applications. This has called for extensions of linear bandits to a broader range of reward structures beyond linear models.",
    ". We present numerical simulations that corroborate our theoretical results. 1 Introduction. Linear bandits provide simple, yet commonly encountered, models for a variety of sequential decision-making problems under uncertainty. However, linear bandits fail to model a host of other applications. This has called for extensions of linear bandits to a broader range of reward structures beyond linear models.",
    ". We present numerical simulations that corroborate our theoretical results. 1 Introduction. Linear bandits provide simple, yet commonly encountered, models for a variety of sequential decision-making problems under uncertainty. However, linear bandits fail to model a host of other applications. This has called for extensions of linear bandits to a broader range of reward structures beyond linear models.",
    ". We present numerical simulations that corroborate our theoretical results. 1 Introduction. Linear bandits provide simple, yet commonly encountered, models for a variety of sequential decision-making problems under uncertainty. However, linear bandits fail to model a host of other applications. This has called for extensions of linear bandits to a broader range of reward structures beyond linear models.",
    "...... to overcome the limitation of the soft actor-critic ( SAC ) algorithm implementing the maximum entropy RL in model-free sample-based learning with function approximation..... . , we propose a max-min entropy framework.  .. .",
    "...... to overcome the limitation of the soft actor-critic ( SAC ) algorithm implementing the maximum entropy RL in model-free sample-based learning with function approximation..... . , we propose a max-min entropy framework.  .. .",
    "...... to overcome the limitation of the soft actor-critic ( SAC ) algorithm implementing the maximum entropy RL in model-free sample-based learning with function approximation..... . , we propose a max-min entropy framework.  .. .",
    "...... to overcome the limitation of the soft actor-critic ( SAC ) algorithm implementing the maximum entropy RL in model-free sample-based learning with function approximation..... . , we propose a max-min entropy framework.  .. .",
    "the problem of learning a particular parametric family of continuous-time Markov chains. This paper focuses on the problem of learning a particular parametric family of continuous-time Markov chains. The problem is in general underspecified and has been shown to permeate a 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "the problem of learning a particular parametric family of continuous-time Markov chains. This paper focuses on the problem of learning a particular parametric family of continuous-time Markov chains. The problem is in general underspecified and has been shown to permeate a 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "the problem of learning a particular parametric family of continuous-time Markov chains. This paper focuses on the problem of learning a particular parametric family of continuous-time Markov chains. The problem is in general underspecified and has been shown to permeate a 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "the problem of learning a particular parametric family of continuous-time Markov chains. This paper focuses on the problem of learning a particular parametric family of continuous-time Markov chains. The problem is in general underspecified and has been shown to permeate a 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "complex data, font and style variations make automatic document understanding very challenging. Moreover, current transformer-based document pretraining models suffer from input length constraints. Moreover, current transformer-based document pretraining models suffer from input length constraints. ( 1 ) documents are composed of semantic regions. Most of the recent document pretraining works follow BERT and split documents into words. Moreover, current transformer-based document pretraining models suffer from input length constraints. ( 2 ) documents are composed of semantic",
    "complex data, font and style variations make automatic document understanding very challenging. Moreover, current transformer-based document pretraining models suffer from input length constraints. Moreover, current transformer-based document pretraining models suffer from input length constraints. ( 1 ) documents are composed of semantic regions. Most of the recent document pretraining works follow BERT and split documents into words. Moreover, current transformer-based document pretraining models suffer from input length constraints. ( 2 ) documents are composed of semantic",
    "complex data, font and style variations make automatic document understanding very challenging. Moreover, current transformer-based document pretraining models suffer from input length constraints. Moreover, current transformer-based document pretraining models suffer from input length constraints. ( 1 ) documents are composed of semantic regions. Most of the recent document pretraining works follow BERT and split documents into words. Moreover, current transformer-based document pretraining models suffer from input length constraints. ( 2 ) documents are composed of semantic",
    "complex data, font and style variations make automatic document understanding very challenging. Moreover, current transformer-based document pretraining models suffer from input length constraints. Moreover, current transformer-based document pretraining models suffer from input length constraints. ( 1 ) documents are composed of semantic regions. Most of the recent document pretraining works follow BERT and split documents into words. Moreover, current transformer-based document pretraining models suffer from input length constraints. ( 2 ) documents are composed of semantic",
    "the first body \u2019 s main focus in to understand what \u2018 fairness \u2019 means ( [ 26, 39, 38, 36, 14, 25 ] ) and the second body \u2019 s focus on addressing the algorithmic challenges brought forth by these considerations. In particular, we consider an individual fairness model proposed by Jung, Kannan, and Lutz [ 25 ] for a k-clustering problem. The rationale behind n/k",
    "the first body \u2019 s main focus in to understand what \u2018 fairness \u2019 means ( [ 26, 39, 38, 36, 14, 25 ] ) and the second body \u2019 s focus on addressing the algorithmic challenges brought forth by these considerations. In particular, we consider an individual fairness model proposed by Jung, Kannan, and Lutz [ 25 ] for a k-clustering problem. The rationale behind n/k",
    "the first body \u2019 s main focus in to understand what \u2018 fairness \u2019 means ( [ 26, 39, 38, 36, 14, 25 ] ) and the second body \u2019 s focus on addressing the algorithmic challenges brought forth by these considerations. In particular, we consider an individual fairness model proposed by Jung, Kannan, and Lutz [ 25 ] for a k-clustering problem. The rationale behind n/k",
    "the first body \u2019 s main focus in to understand what \u2018 fairness \u2019 means ( [ 26, 39, 38, 36, 14, 25 ] ) and the second body \u2019 s focus on addressing the algorithmic challenges brought forth by these considerations. In particular, we consider an individual fairness model proposed by Jung, Kannan, and Lutz [ 25 ] for a k-clustering problem. The rationale behind n/k",
    ". MAX-K-CUT and correlation clustering are fundamental graph partitioning problems. In this paper, we develop simple polynomial-time Gaussian sampling-based algorithms for these two problems. These algorithms use O ( n + |E| ) memory and nearly achieve the best existing approximation guarantees. For dense graphs arriving in a stream, we eliminate the dependence on |E| in the storage complexity at the cost of a slightly worse approximation ratio",
    ". MAX-K-CUT and correlation clustering are fundamental graph partitioning problems. In this paper, we develop simple polynomial-time Gaussian sampling-based algorithms for these two problems. These algorithms use O ( n + |E| ) memory and nearly achieve the best existing approximation guarantees. For dense graphs arriving in a stream, we eliminate the dependence on |E| in the storage complexity at the cost of a slightly worse approximation ratio",
    ". MAX-K-CUT and correlation clustering are fundamental graph partitioning problems. In this paper, we develop simple polynomial-time Gaussian sampling-based algorithms for these two problems. These algorithms use O ( n + |E| ) memory and nearly achieve the best existing approximation guarantees. For dense graphs arriving in a stream, we eliminate the dependence on |E| in the storage complexity at the cost of a slightly worse approximation ratio",
    ". MAX-K-CUT and correlation clustering are fundamental graph partitioning problems. In this paper, we develop simple polynomial-time Gaussian sampling-based algorithms for these two problems. These algorithms use O ( n + |E| ) memory and nearly achieve the best existing approximation guarantees. For dense graphs arriving in a stream, we eliminate the dependence on |E| in the storage complexity at the cost of a slightly worse approximation ratio",
    "both video prediction and early action recognition tasks. Experimental results show that the MAU outperforms the state-of-the-art methods on both tasks. Corresponding author : Shanshe Wang. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "both video prediction and early action recognition tasks. Experimental results show that the MAU outperforms the state-of-the-art methods on both tasks. Corresponding author : Shanshe Wang. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "both video prediction and early action recognition tasks. Experimental results show that the MAU outperforms the state-of-the-art methods on both tasks. Corresponding author : Shanshe Wang. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "both video prediction and early action recognition tasks. Experimental results show that the MAU outperforms the state-of-the-art methods on both tasks. Corresponding author : Shanshe Wang. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". In reinforcement learning ( RL ), an agent aims to learn the optimal decision-making rule by interacting with an unknown environment. In reinforcement learning ( RL ), an agent aims to learn the optimal decision-making rule by interacting with an unknown environment. However, the highly non-linear nature of neural networks renders challenges on their applicability to deep RL. For one thing, recent wisdoms in deep learning theory cast doubt on the ability of neural tangent kernel and random",
    ". In reinforcement learning ( RL ), an agent aims to learn the optimal decision-making rule by interacting with an unknown environment. In reinforcement learning ( RL ), an agent aims to learn the optimal decision-making rule by interacting with an unknown environment. However, the highly non-linear nature of neural networks renders challenges on their applicability to deep RL. For one thing, recent wisdoms in deep learning theory cast doubt on the ability of neural tangent kernel and random",
    ". In reinforcement learning ( RL ), an agent aims to learn the optimal decision-making rule by interacting with an unknown environment. In reinforcement learning ( RL ), an agent aims to learn the optimal decision-making rule by interacting with an unknown environment. However, the highly non-linear nature of neural networks renders challenges on their applicability to deep RL. For one thing, recent wisdoms in deep learning theory cast doubt on the ability of neural tangent kernel and random",
    ". In reinforcement learning ( RL ), an agent aims to learn the optimal decision-making rule by interacting with an unknown environment. In reinforcement learning ( RL ), an agent aims to learn the optimal decision-making rule by interacting with an unknown environment. However, the highly non-linear nature of neural networks renders challenges on their applicability to deep RL. For one thing, recent wisdoms in deep learning theory cast doubt on the ability of neural tangent kernel and random",
    ". In practice, achieving effective OOD generalization is more challenging than in-distribution [ 28, 12, 21, 49, 31, 55 ]. In practice, achieving effective OOD generalization is more challenging than in-distribution [ 28, 12, 21, 49, 31, 55 ]. In the case of zero-shot generalization, where train and test classes are completely distinct, ( i )",
    ". In practice, achieving effective OOD generalization is more challenging than in-distribution [ 28, 12, 21, 49, 31, 55 ]. In practice, achieving effective OOD generalization is more challenging than in-distribution [ 28, 12, 21, 49, 31, 55 ]. In the case of zero-shot generalization, where train and test classes are completely distinct, ( i )",
    ". In practice, achieving effective OOD generalization is more challenging than in-distribution [ 28, 12, 21, 49, 31, 55 ]. In practice, achieving effective OOD generalization is more challenging than in-distribution [ 28, 12, 21, 49, 31, 55 ]. In the case of zero-shot generalization, where train and test classes are completely distinct, ( i )",
    ". In practice, achieving effective OOD generalization is more challenging than in-distribution [ 28, 12, 21, 49, 31, 55 ]. In practice, achieving effective OOD generalization is more challenging than in-distribution [ 28, 12, 21, 49, 31, 55 ]. In the case of zero-shot generalization, where train and test classes are completely distinct, ( i )",
    ". Moreover, there is no universal objective function that can guide model selection. In contrast, in unsupervised OD, there is no universal objective function that can guide model selection. In this work, we introduce ( to the best of our knowledge ) the first UOMS approach that selects an effective outlier model for a new task. Moreover, we argue that model selection is exactly how one can \u201c break the performance ceiling \u201d for OD.",
    ". Moreover, there is no universal objective function that can guide model selection. In contrast, in unsupervised OD, there is no universal objective function that can guide model selection. In this work, we introduce ( to the best of our knowledge ) the first UOMS approach that selects an effective outlier model for a new task. Moreover, we argue that model selection is exactly how one can \u201c break the performance ceiling \u201d for OD.",
    ". Moreover, there is no universal objective function that can guide model selection. In contrast, in unsupervised OD, there is no universal objective function that can guide model selection. In this work, we introduce ( to the best of our knowledge ) the first UOMS approach that selects an effective outlier model for a new task. Moreover, we argue that model selection is exactly how one can \u201c break the performance ceiling \u201d for OD.",
    ". Moreover, there is no universal objective function that can guide model selection. In contrast, in unsupervised OD, there is no universal objective function that can guide model selection. In this work, we introduce ( to the best of our knowledge ) the first UOMS approach that selects an effective outlier model for a new task. Moreover, we argue that model selection is exactly how one can \u201c break the performance ceiling \u201d for OD.",
    ". Contributed during internship at Microsoft Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship",
    ". Contributed during internship at Microsoft Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship",
    ". Contributed during internship at Microsoft Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship",
    ". Contributed during internship at Microsoft Research. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship at Microsoft Research. Contributed during internship",
    "each node in the graph with a small probability p. This dropout technique increases the expressiveness of our GNNs dramatically. In this paper, we present a new approach to increase the expressiveness of GNNs, called Dropout Graph Neural Networks ( DropGNNs ). Our main idea is to execute not one but multiple different runs of the GNN. We then aggregate the results from these different runs into a final result. Thus by learning to identify the drop",
    "each node in the graph with a small probability p. This dropout technique increases the expressiveness of our GNNs dramatically. In this paper, we present a new approach to increase the expressiveness of GNNs, called Dropout Graph Neural Networks ( DropGNNs ). Our main idea is to execute not one but multiple different runs of the GNN. We then aggregate the results from these different runs into a final result. Thus by learning to identify the drop",
    "each node in the graph with a small probability p. This dropout technique increases the expressiveness of our GNNs dramatically. In this paper, we present a new approach to increase the expressiveness of GNNs, called Dropout Graph Neural Networks ( DropGNNs ). Our main idea is to execute not one but multiple different runs of the GNN. We then aggregate the results from these different runs into a final result. Thus by learning to identify the drop",
    "each node in the graph with a small probability p. This dropout technique increases the expressiveness of our GNNs dramatically. In this paper, we present a new approach to increase the expressiveness of GNNs, called Dropout Graph Neural Networks ( DropGNNs ). Our main idea is to execute not one but multiple different runs of the GNN. We then aggregate the results from these different runs into a final result. Thus by learning to identify the drop",
    ". Convolutional neural networks ( CNNs ) have dominated vision tasks in recent years. However, their limited receptive fields of convolutions inevitably neglect the global patterns in images. This hampers further improvement of CNNs. In [ 10, 55, 48, 4, 7, 45, 46, 27, 3, 54, 14, 15, 44, 53 ], many concurrent works, such as ContNet [",
    ". Convolutional neural networks ( CNNs ) have dominated vision tasks in recent years. However, their limited receptive fields of convolutions inevitably neglect the global patterns in images. This hampers further improvement of CNNs. In [ 10, 55, 48, 4, 7, 45, 46, 27, 3, 54, 14, 15, 44, 53 ], many concurrent works, such as ContNet [",
    ". Convolutional neural networks ( CNNs ) have dominated vision tasks in recent years. However, their limited receptive fields of convolutions inevitably neglect the global patterns in images. This hampers further improvement of CNNs. In [ 10, 55, 48, 4, 7, 45, 46, 27, 3, 54, 14, 15, 44, 53 ], many concurrent works, such as ContNet [",
    ". Convolutional neural networks ( CNNs ) have dominated vision tasks in recent years. However, their limited receptive fields of convolutions inevitably neglect the global patterns in images. This hampers further improvement of CNNs. In [ 10, 55, 48, 4, 7, 45, 46, 27, 3, 54, 14, 15, 44, 53 ], many concurrent works, such as ContNet [",
    "dynamic visual reasoning is essential for human intelligence. Given a raw video, humans can easily explain what has happened, predict what will happen next, and infer what will happen in counterfactual situations. Despite their high question-answering accuracy on CLEVRER, these black-box models neither learn concepts nor model objects \u2019 dynamics. Therefore, they lack transparency, interpretability, and generalizability to new concepts and scenarios.",
    "dynamic visual reasoning is essential for human intelligence. Given a raw video, humans can easily explain what has happened, predict what will happen next, and infer what will happen in counterfactual situations. Despite their high question-answering accuracy on CLEVRER, these black-box models neither learn concepts nor model objects \u2019 dynamics. Therefore, they lack transparency, interpretability, and generalizability to new concepts and scenarios.",
    "dynamic visual reasoning is essential for human intelligence. Given a raw video, humans can easily explain what has happened, predict what will happen next, and infer what will happen in counterfactual situations. Despite their high question-answering accuracy on CLEVRER, these black-box models neither learn concepts nor model objects \u2019 dynamics. Therefore, they lack transparency, interpretability, and generalizability to new concepts and scenarios.",
    "dynamic visual reasoning is essential for human intelligence. Given a raw video, humans can easily explain what has happened, predict what will happen next, and infer what will happen in counterfactual situations. Despite their high question-answering accuracy on CLEVRER, these black-box models neither learn concepts nor model objects \u2019 dynamics. Therefore, they lack transparency, interpretability, and generalizability to new concepts and scenarios.",
    ", e.g., Fig 1 ( a ) ) ). Active learning ( AL ) is a promising approach to solve this problem. It aims to select the most informative data points from an unlabeled dataset to be labeled in an adaptive manner with a human in the loop. The goal of AL is to achieve maximum accuracy of the model while minimizing the number of data points required to be labeled. However, real-world datasets are",
    ", e.g., Fig 1 ( a ) ) ). Active learning ( AL ) is a promising approach to solve this problem. It aims to select the most informative data points from an unlabeled dataset to be labeled in an adaptive manner with a human in the loop. The goal of AL is to achieve maximum accuracy of the model while minimizing the number of data points required to be labeled. However, real-world datasets are",
    ", e.g., Fig 1 ( a ) ) ). Active learning ( AL ) is a promising approach to solve this problem. It aims to select the most informative data points from an unlabeled dataset to be labeled in an adaptive manner with a human in the loop. The goal of AL is to achieve maximum accuracy of the model while minimizing the number of data points required to be labeled. However, real-world datasets are",
    ", e.g., Fig 1 ( a ) ) ). Active learning ( AL ) is a promising approach to solve this problem. It aims to select the most informative data points from an unlabeled dataset to be labeled in an adaptive manner with a human in the loop. The goal of AL is to achieve maximum accuracy of the model while minimizing the number of data points required to be labeled. However, real-world datasets are",
    "identity testing of discrete distributions [ 9, 11 ] is one of the most fundamental problems in data analysis. Identity testing is a central problem in analysing output of ranking systems where the goal is to 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). identity testing is a central problem in analysing output of ranking systems where the goal is to 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). identity testing is a central problem in analysing",
    "identity testing of discrete distributions [ 9, 11 ] is one of the most fundamental problems in data analysis. Identity testing is a central problem in analysing output of ranking systems where the goal is to 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). identity testing is a central problem in analysing output of ranking systems where the goal is to 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). identity testing is a central problem in analysing",
    "identity testing of discrete distributions [ 9, 11 ] is one of the most fundamental problems in data analysis. Identity testing is a central problem in analysing output of ranking systems where the goal is to 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). identity testing is a central problem in analysing output of ranking systems where the goal is to 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). identity testing is a central problem in analysing",
    "identity testing of discrete distributions [ 9, 11 ] is one of the most fundamental problems in data analysis. Identity testing is a central problem in analysing output of ranking systems where the goal is to 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). identity testing is a central problem in analysing output of ranking systems where the goal is to 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). identity testing is a central problem in analysing",
    "sparse camera views. This paper aims at a scalable solution for free-viewpoint human performance rendering that generalizes across different human performers and requires only sparse camera views. In particular, an effective solution needs to coherently aggregate appearance information from sparse multi-view observations across time as the body undergoes a 3D motion. However, naive solutions suffer from significant artifacts when details observed from multiple views differ due to heavy self occlusions",
    "sparse camera views. This paper aims at a scalable solution for free-viewpoint human performance rendering that generalizes across different human performers and requires only sparse camera views. In particular, an effective solution needs to coherently aggregate appearance information from sparse multi-view observations across time as the body undergoes a 3D motion. However, naive solutions suffer from significant artifacts when details observed from multiple views differ due to heavy self occlusions",
    "sparse camera views. This paper aims at a scalable solution for free-viewpoint human performance rendering that generalizes across different human performers and requires only sparse camera views. In particular, an effective solution needs to coherently aggregate appearance information from sparse multi-view observations across time as the body undergoes a 3D motion. However, naive solutions suffer from significant artifacts when details observed from multiple views differ due to heavy self occlusions",
    "sparse camera views. This paper aims at a scalable solution for free-viewpoint human performance rendering that generalizes across different human performers and requires only sparse camera views. In particular, an effective solution needs to coherently aggregate appearance information from sparse multi-view observations across time as the body undergoes a 3D motion. However, naive solutions suffer from significant artifacts when details observed from multiple views differ due to heavy self occlusions",
    ". In particular, we propose to Search the Search Space ( S3 ) by automatically refining the main changeable dimensions of transformer architectures. For the second question, we propose a new measurement called E-T Error for search space quality estimation and utilize a once-for-all supernet. Minghao, Kan, Bolin are interns of MSRA. Corresponding author. 35th Conference on Neural Information Processing Systems ( NeurIPS 20",
    ". In particular, we propose to Search the Search Space ( S3 ) by automatically refining the main changeable dimensions of transformer architectures. For the second question, we propose a new measurement called E-T Error for search space quality estimation and utilize a once-for-all supernet. Minghao, Kan, Bolin are interns of MSRA. Corresponding author. 35th Conference on Neural Information Processing Systems ( NeurIPS 20",
    ". In particular, we propose to Search the Search Space ( S3 ) by automatically refining the main changeable dimensions of transformer architectures. For the second question, we propose a new measurement called E-T Error for search space quality estimation and utilize a once-for-all supernet. Minghao, Kan, Bolin are interns of MSRA. Corresponding author. 35th Conference on Neural Information Processing Systems ( NeurIPS 20",
    ". In particular, we propose to Search the Search Space ( S3 ) by automatically refining the main changeable dimensions of transformer architectures. For the second question, we propose a new measurement called E-T Error for search space quality estimation and utilize a once-for-all supernet. Minghao, Kan, Bolin are interns of MSRA. Corresponding author. 35th Conference on Neural Information Processing Systems ( NeurIPS 20",
    "a linear threshold function ( LTF ) over the d-dimensional feature-vectors x is given by pos ( g ( x ) for some linear function g ( x1,.., xd ) = d i=1 cixi + cd+1. In this work we initiate an investigation into the proper learnability of LTFs in the framework of learning from label proportions ( LLP ).",
    "a linear threshold function ( LTF ) over the d-dimensional feature-vectors x is given by pos ( g ( x ) for some linear function g ( x1,.., xd ) = d i=1 cixi + cd+1. In this work we initiate an investigation into the proper learnability of LTFs in the framework of learning from label proportions ( LLP ).",
    "a linear threshold function ( LTF ) over the d-dimensional feature-vectors x is given by pos ( g ( x ) for some linear function g ( x1,.., xd ) = d i=1 cixi + cd+1. In this work we initiate an investigation into the proper learnability of LTFs in the framework of learning from label proportions ( LLP ).",
    "a linear threshold function ( LTF ) over the d-dimensional feature-vectors x is given by pos ( g ( x ) for some linear function g ( x1,.., xd ) = d i=1 cixi + cd+1. In this work we initiate an investigation into the proper learnability of LTFs in the framework of learning from label proportions ( LLP ).",
    "6 466 and 423 624, respectively. These benchmarks allow researchers to easily simulate NAS experiments. Since 2019, dozens of papers have used these NAS benchmarks to develop new algorithms. NAS-Bench-301 only contains the architectures \u2019 accuracy at epoch 100, Equal contribution. NAS-Bench-301 only contains the architectures \u2019 accuracy at epoch 100, Equal contribution. NAS-Bench",
    "6 466 and 423 624, respectively. These benchmarks allow researchers to easily simulate NAS experiments. Since 2019, dozens of papers have used these NAS benchmarks to develop new algorithms. NAS-Bench-301 only contains the architectures \u2019 accuracy at epoch 100, Equal contribution. NAS-Bench-301 only contains the architectures \u2019 accuracy at epoch 100, Equal contribution. NAS-Bench",
    "6 466 and 423 624, respectively. These benchmarks allow researchers to easily simulate NAS experiments. Since 2019, dozens of papers have used these NAS benchmarks to develop new algorithms. NAS-Bench-301 only contains the architectures \u2019 accuracy at epoch 100, Equal contribution. NAS-Bench-301 only contains the architectures \u2019 accuracy at epoch 100, Equal contribution. NAS-Bench",
    "6 466 and 423 624, respectively. These benchmarks allow researchers to easily simulate NAS experiments. Since 2019, dozens of papers have used these NAS benchmarks to develop new algorithms. NAS-Bench-301 only contains the architectures \u2019 accuracy at epoch 100, Equal contribution. NAS-Bench-301 only contains the architectures \u2019 accuracy at epoch 100, Equal contribution. NAS-Bench",
    "post-hoc explainability techniques. These methods aim at improving the interpretability of black-box models. In this way, it is possible to understand the prediction of a model without sacrificing its prediction accuracy. In this work, we rather focus on post-hoc explainability techniques. These methods aim at improving the interpretability of black-box models by complementing their predictions with various kinds of explanations. In fact, human subjects often find example-based explanations more insightful than feature importance explanations.",
    "post-hoc explainability techniques. These methods aim at improving the interpretability of black-box models. In this way, it is possible to understand the prediction of a model without sacrificing its prediction accuracy. In this work, we rather focus on post-hoc explainability techniques. These methods aim at improving the interpretability of black-box models by complementing their predictions with various kinds of explanations. In fact, human subjects often find example-based explanations more insightful than feature importance explanations.",
    "post-hoc explainability techniques. These methods aim at improving the interpretability of black-box models. In this way, it is possible to understand the prediction of a model without sacrificing its prediction accuracy. In this work, we rather focus on post-hoc explainability techniques. These methods aim at improving the interpretability of black-box models by complementing their predictions with various kinds of explanations. In fact, human subjects often find example-based explanations more insightful than feature importance explanations.",
    "post-hoc explainability techniques. These methods aim at improving the interpretability of black-box models. In this way, it is possible to understand the prediction of a model without sacrificing its prediction accuracy. In this work, we rather focus on post-hoc explainability techniques. These methods aim at improving the interpretability of black-box models by complementing their predictions with various kinds of explanations. In fact, human subjects often find example-based explanations more insightful than feature importance explanations.",
    ".. This paper was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). This work was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns. This work was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns.",
    ".. This paper was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). This work was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns. This work was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns.",
    ".. This paper was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). This work was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns. This work was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns.",
    ".. This paper was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). This work was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns. This work was performed when Hongwei Xue and Yupan Huang were visiting Microsoft Research as research interns.",
    ". We present a novel analysis for privacy dynamics of noisy gradient descent with smooth and strongly convex loss functions. We construct a pair of continuous-time Langevin diffusion [ 20 ] processes that trace the probability distributions over the model parameters of noisy GD. Subsequently, we derive differential inequalities bounding the rate of privacy loss of the released model after K training epochs. The open challenge, that we tackle in this paper, is to provide",
    ". We present a novel analysis for privacy dynamics of noisy gradient descent with smooth and strongly convex loss functions. We construct a pair of continuous-time Langevin diffusion [ 20 ] processes that trace the probability distributions over the model parameters of noisy GD. Subsequently, we derive differential inequalities bounding the rate of privacy loss of the released model after K training epochs. The open challenge, that we tackle in this paper, is to provide",
    ". We present a novel analysis for privacy dynamics of noisy gradient descent with smooth and strongly convex loss functions. We construct a pair of continuous-time Langevin diffusion [ 20 ] processes that trace the probability distributions over the model parameters of noisy GD. Subsequently, we derive differential inequalities bounding the rate of privacy loss of the released model after K training epochs. The open challenge, that we tackle in this paper, is to provide",
    ". We present a novel analysis for privacy dynamics of noisy gradient descent with smooth and strongly convex loss functions. We construct a pair of continuous-time Langevin diffusion [ 20 ] processes that trace the probability distributions over the model parameters of noisy GD. Subsequently, we derive differential inequalities bounding the rate of privacy loss of the released model after K training epochs. The open challenge, that we tackle in this paper, is to provide",
    "....  : S  A, parameterized by  ( e.g., the weights of a neural network ). An RL algorithm learns a policy  : S  A, parameterized by  ( e.g., the weights of a neural network ). An RL algorithm learns a policy  : S  A, parameterized",
    "....  : S  A, parameterized by  ( e.g., the weights of a neural network ). An RL algorithm learns a policy  : S  A, parameterized by  ( e.g., the weights of a neural network ). An RL algorithm learns a policy  : S  A, parameterized",
    "....  : S  A, parameterized by  ( e.g., the weights of a neural network ). An RL algorithm learns a policy  : S  A, parameterized by  ( e.g., the weights of a neural network ). An RL algorithm learns a policy  : S  A, parameterized",
    "....  : S  A, parameterized by  ( e.g., the weights of a neural network ). An RL algorithm learns a policy  : S  A, parameterized by  ( e.g., the weights of a neural network ). An RL algorithm learns a policy  : S  A, parameterized",
    "the PC-bias.8 We then compare9 our results to the spectral bias. We then compare9 our results to the PC-bias. We then discuss how the PC-bias may explain some benefits of early stopping and its connection to PCA,13 and why deep networks converge more slowly when given random labels. We then discuss how the PC-bias may explain some benefits of early stopping and its connection to PCA,14 and why deep networks converge more slowly when given random labels.",
    "the PC-bias.8 We then compare9 our results to the spectral bias. We then compare9 our results to the PC-bias. We then discuss how the PC-bias may explain some benefits of early stopping and its connection to PCA,13 and why deep networks converge more slowly when given random labels. We then discuss how the PC-bias may explain some benefits of early stopping and its connection to PCA,14 and why deep networks converge more slowly when given random labels.",
    "the PC-bias.8 We then compare9 our results to the spectral bias. We then compare9 our results to the PC-bias. We then discuss how the PC-bias may explain some benefits of early stopping and its connection to PCA,13 and why deep networks converge more slowly when given random labels. We then discuss how the PC-bias may explain some benefits of early stopping and its connection to PCA,14 and why deep networks converge more slowly when given random labels.",
    "the PC-bias.8 We then compare9 our results to the spectral bias. We then compare9 our results to the PC-bias. We then discuss how the PC-bias may explain some benefits of early stopping and its connection to PCA,13 and why deep networks converge more slowly when given random labels. We then discuss how the PC-bias may explain some benefits of early stopping and its connection to PCA,14 and why deep networks converge more slowly when given random labels.",
    ". A backdoor attack is a type of training-time data poisoning attack that implant backdoor triggers into machine learning models by injecting the trigger pattern ( s ) into a small proportion of the training data. Despite their promising results, it is still unclear in the current literature whether the underlying model learns clean and backdoor examples in the same way. Intuitively, if backdoored data can be identified during training, measures can be taken to prevent the model",
    ". A backdoor attack is a type of training-time data poisoning attack that implant backdoor triggers into machine learning models by injecting the trigger pattern ( s ) into a small proportion of the training data. Despite their promising results, it is still unclear in the current literature whether the underlying model learns clean and backdoor examples in the same way. Intuitively, if backdoored data can be identified during training, measures can be taken to prevent the model",
    ". A backdoor attack is a type of training-time data poisoning attack that implant backdoor triggers into machine learning models by injecting the trigger pattern ( s ) into a small proportion of the training data. Despite their promising results, it is still unclear in the current literature whether the underlying model learns clean and backdoor examples in the same way. Intuitively, if backdoored data can be identified during training, measures can be taken to prevent the model",
    ". A backdoor attack is a type of training-time data poisoning attack that implant backdoor triggers into machine learning models by injecting the trigger pattern ( s ) into a small proportion of the training data. Despite their promising results, it is still unclear in the current literature whether the underlying model learns clean and backdoor examples in the same way. Intuitively, if backdoored data can be identified during training, measures can be taken to prevent the model",
    "noisy and inaccurate. To overcome such limitations, we have proposed new deep generative models that represent 3D scenes as neural radiance fields. Such deep generative models allow explicit control of viewpoint while preserving 3D consistency during image synthesis. While producing impressive results, existing attempts for 3D-aware image synthesis tend to learn coarse 3D shapes that are inaccurate and noisy. In particular, small variations of shape could lead to similar RGB images that look equally plausible to the discriminator.",
    "noisy and inaccurate. To overcome such limitations, we have proposed new deep generative models that represent 3D scenes as neural radiance fields. Such deep generative models allow explicit control of viewpoint while preserving 3D consistency during image synthesis. While producing impressive results, existing attempts for 3D-aware image synthesis tend to learn coarse 3D shapes that are inaccurate and noisy. In particular, small variations of shape could lead to similar RGB images that look equally plausible to the discriminator.",
    "noisy and inaccurate. To overcome such limitations, we have proposed new deep generative models that represent 3D scenes as neural radiance fields. Such deep generative models allow explicit control of viewpoint while preserving 3D consistency during image synthesis. While producing impressive results, existing attempts for 3D-aware image synthesis tend to learn coarse 3D shapes that are inaccurate and noisy. In particular, small variations of shape could lead to similar RGB images that look equally plausible to the discriminator.",
    "noisy and inaccurate. To overcome such limitations, we have proposed new deep generative models that represent 3D scenes as neural radiance fields. Such deep generative models allow explicit control of viewpoint while preserving 3D consistency during image synthesis. While producing impressive results, existing attempts for 3D-aware image synthesis tend to learn coarse 3D shapes that are inaccurate and noisy. In particular, small variations of shape could lead to similar RGB images that look equally plausible to the discriminator.",
    "the residual u = y  f ( x ) is correlated with x due to the unobserved confounders. In the nonparametric setting, point estimators suffer from high variance. Consequently, uncertainty quantification is particularly important for IV regression.",
    "the residual u = y  f ( x ) is correlated with x due to the unobserved confounders. In the nonparametric setting, point estimators suffer from high variance. Consequently, uncertainty quantification is particularly important for IV regression.",
    "the residual u = y  f ( x ) is correlated with x due to the unobserved confounders. In the nonparametric setting, point estimators suffer from high variance. Consequently, uncertainty quantification is particularly important for IV regression.",
    "the residual u = y  f ( x ) is correlated with x due to the unobserved confounders. In the nonparametric setting, point estimators suffer from high variance. Consequently, uncertainty quantification is particularly important for IV regression.",
    "many-to-many QA is a multilingual open question answering ( QA ) task. Many-to-many QA is a multilingual open question answering ( QA ) task. In this paper, we introduce a unified many-to-many QA model that can answer questions in any target language by retrieving evidence from any language and generating answers in the target language. In this paper, we extend the retrieve-then-generate approach of English",
    "many-to-many QA is a multilingual open question answering ( QA ) task. Many-to-many QA is a multilingual open question answering ( QA ) task. In this paper, we introduce a unified many-to-many QA model that can answer questions in any target language by retrieving evidence from any language and generating answers in the target language. In this paper, we extend the retrieve-then-generate approach of English",
    "many-to-many QA is a multilingual open question answering ( QA ) task. Many-to-many QA is a multilingual open question answering ( QA ) task. In this paper, we introduce a unified many-to-many QA model that can answer questions in any target language by retrieving evidence from any language and generating answers in the target language. In this paper, we extend the retrieve-then-generate approach of English",
    "many-to-many QA is a multilingual open question answering ( QA ) task. Many-to-many QA is a multilingual open question answering ( QA ) task. In this paper, we introduce a unified many-to-many QA model that can answer questions in any target language by retrieving evidence from any language and generating answers in the target language. In this paper, we extend the retrieve-then-generate approach of English",
    "...., the test data, and the classifier. Networks. Networks. Networks. Networks. Networks. domain generalization... .. ; ; ; ; ; Arora et al., 2018 ; Arora et al., 2018.",
    "...., the test data, and the classifier. Networks. Networks. Networks. Networks. Networks. domain generalization... .. ; ; ; ; ; Arora et al., 2018 ; Arora et al., 2018.",
    "...., the test data, and the classifier. Networks. Networks. Networks. Networks. Networks. domain generalization... .. ; ; ; ; ; Arora et al., 2018 ; Arora et al., 2018.",
    "...., the test data, and the classifier. Networks. Networks. Networks. Networks. Networks. domain generalization... .. ; ; ; ; ; Arora et al., 2018 ; Arora et al., 2018.",
    "backdoor filtering and robust generalization are nearly equivalent. From a statistical standpoint, we identify a parameter we call the memorization capacity that captures the intrinsic vulnerability of a learning problem to a backdoor attack. This allows us to argue about the robustness of several natural learning problems to backdoor attacks. From a computational standpoint, we show that under certain assumptions, adversarial training can detect the presence of backdoors in a training set. This implies that it is both as",
    "backdoor filtering and robust generalization are nearly equivalent. From a statistical standpoint, we identify a parameter we call the memorization capacity that captures the intrinsic vulnerability of a learning problem to a backdoor attack. This allows us to argue about the robustness of several natural learning problems to backdoor attacks. From a computational standpoint, we show that under certain assumptions, adversarial training can detect the presence of backdoors in a training set. This implies that it is both as",
    "backdoor filtering and robust generalization are nearly equivalent. From a statistical standpoint, we identify a parameter we call the memorization capacity that captures the intrinsic vulnerability of a learning problem to a backdoor attack. This allows us to argue about the robustness of several natural learning problems to backdoor attacks. From a computational standpoint, we show that under certain assumptions, adversarial training can detect the presence of backdoors in a training set. This implies that it is both as",
    "backdoor filtering and robust generalization are nearly equivalent. From a statistical standpoint, we identify a parameter we call the memorization capacity that captures the intrinsic vulnerability of a learning problem to a backdoor attack. This allows us to argue about the robustness of several natural learning problems to backdoor attacks. From a computational standpoint, we show that under certain assumptions, adversarial training can detect the presence of backdoors in a training set. This implies that it is both as",
    "wide limits have been extended to deeper networks [ 56, 64 ], convolutional networks [ 38, 71 ], and other architectures [ 50, 88 ]. However, wide limits appear to confound opposing phenomenon : increased capacity makes them more expressive, yet the loss of hierarchical features seems to make them less expressive. This may explain the mixed empirical performance of limiting models : outperforming finite width models in some scenarios [ e.g.",
    "wide limits have been extended to deeper networks [ 56, 64 ], convolutional networks [ 38, 71 ], and other architectures [ 50, 88 ]. However, wide limits appear to confound opposing phenomenon : increased capacity makes them more expressive, yet the loss of hierarchical features seems to make them less expressive. This may explain the mixed empirical performance of limiting models : outperforming finite width models in some scenarios [ e.g.",
    "wide limits have been extended to deeper networks [ 56, 64 ], convolutional networks [ 38, 71 ], and other architectures [ 50, 88 ]. However, wide limits appear to confound opposing phenomenon : increased capacity makes them more expressive, yet the loss of hierarchical features seems to make them less expressive. This may explain the mixed empirical performance of limiting models : outperforming finite width models in some scenarios [ e.g.",
    "wide limits have been extended to deeper networks [ 56, 64 ], convolutional networks [ 38, 71 ], and other architectures [ 50, 88 ]. However, wide limits appear to confound opposing phenomenon : increased capacity makes them more expressive, yet the loss of hierarchical features seems to make them less expressive. This may explain the mixed empirical performance of limiting models : outperforming finite width models in some scenarios [ e.g.",
    ". S of clients periodically communicate with a central server to find a global statistical model. m is the number of clients, fi ( x ) is the global objective function of client i. f ( x ) is the global objective function of fi ( x ). FedAvg algorithm suffers from a \u201c client-drift phenomenon '' under objective heterogeneity [ 6\u201311 ]. FedAvg algorithm suffers from a",
    ". S of clients periodically communicate with a central server to find a global statistical model. m is the number of clients, fi ( x ) is the global objective function of client i. f ( x ) is the global objective function of fi ( x ). FedAvg algorithm suffers from a \u201c client-drift phenomenon '' under objective heterogeneity [ 6\u201311 ]. FedAvg algorithm suffers from a",
    ". S of clients periodically communicate with a central server to find a global statistical model. m is the number of clients, fi ( x ) is the global objective function of client i. f ( x ) is the global objective function of fi ( x ). FedAvg algorithm suffers from a \u201c client-drift phenomenon '' under objective heterogeneity [ 6\u201311 ]. FedAvg algorithm suffers from a",
    ". S of clients periodically communicate with a central server to find a global statistical model. m is the number of clients, fi ( x ) is the global objective function of client i. f ( x ) is the global objective function of fi ( x ). FedAvg algorithm suffers from a \u201c client-drift phenomenon '' under objective heterogeneity [ 6\u201311 ]. FedAvg algorithm suffers from a",
    "",
    "",
    "",
    "",
    "\u201c low-level \u201d or \u201c high-level \u201d. These words belies an unstated hypothesis about the nature of the space of language representations. In this work, we attempt to directly map the low-dimensional space of language representations by generating \u201c representation embeddings \u201d. This method is inspired by the work of Zamir et al. [ 44 ]. We then used this structure to explore the relationships between \u2013 and gain deeper insight about \u2013 frequently used language",
    "\u201c low-level \u201d or \u201c high-level \u201d. These words belies an unstated hypothesis about the nature of the space of language representations. In this work, we attempt to directly map the low-dimensional space of language representations by generating \u201c representation embeddings \u201d. This method is inspired by the work of Zamir et al. [ 44 ]. We then used this structure to explore the relationships between \u2013 and gain deeper insight about \u2013 frequently used language",
    "\u201c low-level \u201d or \u201c high-level \u201d. These words belies an unstated hypothesis about the nature of the space of language representations. In this work, we attempt to directly map the low-dimensional space of language representations by generating \u201c representation embeddings \u201d. This method is inspired by the work of Zamir et al. [ 44 ]. We then used this structure to explore the relationships between \u2013 and gain deeper insight about \u2013 frequently used language",
    "\u201c low-level \u201d or \u201c high-level \u201d. These words belies an unstated hypothesis about the nature of the space of language representations. In this work, we attempt to directly map the low-dimensional space of language representations by generating \u201c representation embeddings \u201d. This method is inspired by the work of Zamir et al. [ 44 ]. We then used this structure to explore the relationships between \u2013 and gain deeper insight about \u2013 frequently used language",
    ". On conditional image generation, D2C generations are two orders of magnitude faster to produce over StyleGAN2 ones. On conditional image manipulation, D2C generations are preferred by 50 %  60 % of the human evaluators in a double-blind study. D2C is a paradigm for training unconditional variational autoencoders ( VAEs ) for conditional image generation. However, downstream applications of generative models are often based on",
    ". On conditional image generation, D2C generations are two orders of magnitude faster to produce over StyleGAN2 ones. On conditional image manipulation, D2C generations are preferred by 50 %  60 % of the human evaluators in a double-blind study. D2C is a paradigm for training unconditional variational autoencoders ( VAEs ) for conditional image generation. However, downstream applications of generative models are often based on",
    ". On conditional image generation, D2C generations are two orders of magnitude faster to produce over StyleGAN2 ones. On conditional image manipulation, D2C generations are preferred by 50 %  60 % of the human evaluators in a double-blind study. D2C is a paradigm for training unconditional variational autoencoders ( VAEs ) for conditional image generation. However, downstream applications of generative models are often based on",
    ". On conditional image generation, D2C generations are two orders of magnitude faster to produce over StyleGAN2 ones. On conditional image manipulation, D2C generations are preferred by 50 %  60 % of the human evaluators in a double-blind study. D2C is a paradigm for training unconditional variational autoencoders ( VAEs ) for conditional image generation. However, downstream applications of generative models are often based on",
    "self-supervised learning. This paper presents a theoretical framework for self-supervised learning without requiring conditional independence. We demonstrate that, under a simple and realistic data assumption, linear classification using representations learned on a random pair of unlabeled data samples can recover the ground-truth labels of the data with high accuracy. This paper presents a theoretical framework for self-supervised learning without requiring conditional independence.",
    "self-supervised learning. This paper presents a theoretical framework for self-supervised learning without requiring conditional independence. We demonstrate that, under a simple and realistic data assumption, linear classification using representations learned on a random pair of unlabeled data samples can recover the ground-truth labels of the data with high accuracy. This paper presents a theoretical framework for self-supervised learning without requiring conditional independence.",
    "self-supervised learning. This paper presents a theoretical framework for self-supervised learning without requiring conditional independence. We demonstrate that, under a simple and realistic data assumption, linear classification using representations learned on a random pair of unlabeled data samples can recover the ground-truth labels of the data with high accuracy. This paper presents a theoretical framework for self-supervised learning without requiring conditional independence.",
    "self-supervised learning. This paper presents a theoretical framework for self-supervised learning without requiring conditional independence. We demonstrate that, under a simple and realistic data assumption, linear classification using representations learned on a random pair of unlabeled data samples can recover the ground-truth labels of the data with high accuracy. This paper presents a theoretical framework for self-supervised learning without requiring conditional independence.",
    "as follows : given a set of V of variables ( represented as vertices ), a family F of score functions which assign each variable v  V a score based on its parents, and a target value , determine if there exists a directed acyclic graph over V that achieves a total score of at least  1. To obtain a more refined understanding of the complexity of BNSL, past works have analyzed the problem not",
    "as follows : given a set of V of variables ( represented as vertices ), a family F of score functions which assign each variable v  V a score based on its parents, and a target value , determine if there exists a directed acyclic graph over V that achieves a total score of at least  1. To obtain a more refined understanding of the complexity of BNSL, past works have analyzed the problem not",
    "as follows : given a set of V of variables ( represented as vertices ), a family F of score functions which assign each variable v  V a score based on its parents, and a target value , determine if there exists a directed acyclic graph over V that achieves a total score of at least  1. To obtain a more refined understanding of the complexity of BNSL, past works have analyzed the problem not",
    "as follows : given a set of V of variables ( represented as vertices ), a family F of score functions which assign each variable v  V a score based on its parents, and a target value , determine if there exists a directed acyclic graph over V that achieves a total score of at least  1. To obtain a more refined understanding of the complexity of BNSL, past works have analyzed the problem not",
    "binary classification problems in the so-called streaming ( or online ) setting of active learning. In this paper, we are specifically interested in binary classification problems in the so-called streaming ( or online ) setting of active learning. In this and many other situations that arise in practice, the logistic link function p ( x ) = 1 1+eh ( x ) is often adopted to model conditional class probabilities where h is some ( unknown ) function in a given hypothesis class",
    "binary classification problems in the so-called streaming ( or online ) setting of active learning. In this paper, we are specifically interested in binary classification problems in the so-called streaming ( or online ) setting of active learning. In this and many other situations that arise in practice, the logistic link function p ( x ) = 1 1+eh ( x ) is often adopted to model conditional class probabilities where h is some ( unknown ) function in a given hypothesis class",
    "binary classification problems in the so-called streaming ( or online ) setting of active learning. In this paper, we are specifically interested in binary classification problems in the so-called streaming ( or online ) setting of active learning. In this and many other situations that arise in practice, the logistic link function p ( x ) = 1 1+eh ( x ) is often adopted to model conditional class probabilities where h is some ( unknown ) function in a given hypothesis class",
    "binary classification problems in the so-called streaming ( or online ) setting of active learning. In this paper, we are specifically interested in binary classification problems in the so-called streaming ( or online ) setting of active learning. In this and many other situations that arise in practice, the logistic link function p ( x ) = 1 1+eh ( x ) is often adopted to model conditional class probabilities where h is some ( unknown ) function in a given hypothesis class",
    ". Without the assumption of a structured ground truth label function, there is no universal learning algorithm which can generalize well over unseen data. However, deep neural networks have high complexity spaces with flexibility to learn any label assignment on any set of training datapoints. This was perhaps most clearly observed in [ 6 ], where even after random label assignments on the training data samples, the networks still were able to fit the training data labels with no errors.",
    ". Without the assumption of a structured ground truth label function, there is no universal learning algorithm which can generalize well over unseen data. However, deep neural networks have high complexity spaces with flexibility to learn any label assignment on any set of training datapoints. This was perhaps most clearly observed in [ 6 ], where even after random label assignments on the training data samples, the networks still were able to fit the training data labels with no errors.",
    ". Without the assumption of a structured ground truth label function, there is no universal learning algorithm which can generalize well over unseen data. However, deep neural networks have high complexity spaces with flexibility to learn any label assignment on any set of training datapoints. This was perhaps most clearly observed in [ 6 ], where even after random label assignments on the training data samples, the networks still were able to fit the training data labels with no errors.",
    ". Without the assumption of a structured ground truth label function, there is no universal learning algorithm which can generalize well over unseen data. However, deep neural networks have high complexity spaces with flexibility to learn any label assignment on any set of training datapoints. This was perhaps most clearly observed in [ 6 ], where even after random label assignments on the training data samples, the networks still were able to fit the training data labels with no errors.",
    ". They often require a mining procedure to search for offending samples from a memory bank. Information maximization methods tend to be costly, require large batch sizes or memory banks. They often require a mining procedure to search for offending samples from a memory bank. They often require a mining procedure to search for offending samples from a memory bank. They often require a mining procedure to search for offending samples from a memory bank. Information maximization methods tend to be expensive, require",
    ". They often require a mining procedure to search for offending samples from a memory bank. Information maximization methods tend to be costly, require large batch sizes or memory banks. They often require a mining procedure to search for offending samples from a memory bank. They often require a mining procedure to search for offending samples from a memory bank. They often require a mining procedure to search for offending samples from a memory bank. Information maximization methods tend to be expensive, require",
    ". They often require a mining procedure to search for offending samples from a memory bank. Information maximization methods tend to be costly, require large batch sizes or memory banks. They often require a mining procedure to search for offending samples from a memory bank. They often require a mining procedure to search for offending samples from a memory bank. They often require a mining procedure to search for offending samples from a memory bank. Information maximization methods tend to be expensive, require",
    ". They often require a mining procedure to search for offending samples from a memory bank. Information maximization methods tend to be costly, require large batch sizes or memory banks. They often require a mining procedure to search for offending samples from a memory bank. They often require a mining procedure to search for offending samples from a memory bank. They often require a mining procedure to search for offending samples from a memory bank. Information maximization methods tend to be expensive, require",
    ". Reinforcement learning ( RL) casts the problem of learning to perform complex tasks as an optimization problem. Since human feedback is expensive, active reward learning aims to minimize the number of queries. Since human feedback is expensive, active reward learning aims to minimize the number of queries. Figure 1: The robot wants to collect food for a human. It can only move 4 timesteps in the gridworld, can not pass through the black walls, and collecting more food is always better",
    ". Reinforcement learning ( RL) casts the problem of learning to perform complex tasks as an optimization problem. Since human feedback is expensive, active reward learning aims to minimize the number of queries. Since human feedback is expensive, active reward learning aims to minimize the number of queries. Figure 1: The robot wants to collect food for a human. It can only move 4 timesteps in the gridworld, can not pass through the black walls, and collecting more food is always better",
    ". Reinforcement learning ( RL) casts the problem of learning to perform complex tasks as an optimization problem. Since human feedback is expensive, active reward learning aims to minimize the number of queries. Since human feedback is expensive, active reward learning aims to minimize the number of queries. Figure 1: The robot wants to collect food for a human. It can only move 4 timesteps in the gridworld, can not pass through the black walls, and collecting more food is always better",
    ". Reinforcement learning ( RL) casts the problem of learning to perform complex tasks as an optimization problem. Since human feedback is expensive, active reward learning aims to minimize the number of queries. Since human feedback is expensive, active reward learning aims to minimize the number of queries. Figure 1: The robot wants to collect food for a human. It can only move 4 timesteps in the gridworld, can not pass through the black walls, and collecting more food is always better",
    "w N i=1 of inputs xi and targets yi. Equation 1 is usually minimized by iterative optimization. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to",
    "w N i=1 of inputs xi and targets yi. Equation 1 is usually minimized by iterative optimization. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to",
    "w N i=1 of inputs xi and targets yi. Equation 1 is usually minimized by iterative optimization. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to",
    "w N i=1 of inputs xi and targets yi. Equation 1 is usually minimized by iterative optimization. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to optimize the parameters for a new architecture a. HD is expected to leverage the knowledge of how to",
    "low distortion generally comes at the price of poor perceptual quality. In this paper, we derive a closed form expression for the distortion-perception ( DP ) function for the special case where distortion is measured by mean squared-error ( MSE ) and perception is measured by the Wasserstein-2 distance between the probability laws of the estimate and the estimand. ( i ) We prove that the DP function is always quadratic in the perception constraint P, regardless of the underlying",
    "low distortion generally comes at the price of poor perceptual quality. In this paper, we derive a closed form expression for the distortion-perception ( DP ) function for the special case where distortion is measured by mean squared-error ( MSE ) and perception is measured by the Wasserstein-2 distance between the probability laws of the estimate and the estimand. ( i ) We prove that the DP function is always quadratic in the perception constraint P, regardless of the underlying",
    "low distortion generally comes at the price of poor perceptual quality. In this paper, we derive a closed form expression for the distortion-perception ( DP ) function for the special case where distortion is measured by mean squared-error ( MSE ) and perception is measured by the Wasserstein-2 distance between the probability laws of the estimate and the estimand. ( i ) We prove that the DP function is always quadratic in the perception constraint P, regardless of the underlying",
    "low distortion generally comes at the price of poor perceptual quality. In this paper, we derive a closed form expression for the distortion-perception ( DP ) function for the special case where distortion is measured by mean squared-error ( MSE ) and perception is measured by the Wasserstein-2 distance between the probability laws of the estimate and the estimand. ( i ) We prove that the DP function is always quadratic in the perception constraint P, regardless of the underlying",
    ". The textual graph is a widely existed data format, where each node is annotated with its textual feature. In recent years, the breakthroughs in pretrained language models and graph neural networks contribute to the development of corresponding techniques. Work was done by 2021.01 during Junhan Yang and Shitao Xiao \u2019 s internship in MSRA 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". The textual graph is a widely existed data format, where each node is annotated with its textual feature. In recent years, the breakthroughs in pretrained language models and graph neural networks contribute to the development of corresponding techniques. Work was done by 2021.01 during Junhan Yang and Shitao Xiao \u2019 s internship in MSRA 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". The textual graph is a widely existed data format, where each node is annotated with its textual feature. In recent years, the breakthroughs in pretrained language models and graph neural networks contribute to the development of corresponding techniques. Work was done by 2021.01 during Junhan Yang and Shitao Xiao \u2019 s internship in MSRA 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". The textual graph is a widely existed data format, where each node is annotated with its textual feature. In recent years, the breakthroughs in pretrained language models and graph neural networks contribute to the development of corresponding techniques. Work was done by 2021.01 during Junhan Yang and Shitao Xiao \u2019 s internship in MSRA 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "m ) as users provide more samples. When increasing the number of users n, the privacy cost decreases at a faster O ( 1/n ) rate. To address this issue, we consider the notion of differential privacy ( DP ). In this paper, we demonstrate the minimax optimality of our algorithms for mean estimation in arbitrary dimension with error scaling as the concentration radius  of the distribution rather than the entire range. In contrast, when increasing the number of",
    "m ) as users provide more samples. When increasing the number of users n, the privacy cost decreases at a faster O ( 1/n ) rate. To address this issue, we consider the notion of differential privacy ( DP ). In this paper, we demonstrate the minimax optimality of our algorithms for mean estimation in arbitrary dimension with error scaling as the concentration radius  of the distribution rather than the entire range. In contrast, when increasing the number of",
    "m ) as users provide more samples. When increasing the number of users n, the privacy cost decreases at a faster O ( 1/n ) rate. To address this issue, we consider the notion of differential privacy ( DP ). In this paper, we demonstrate the minimax optimality of our algorithms for mean estimation in arbitrary dimension with error scaling as the concentration radius  of the distribution rather than the entire range. In contrast, when increasing the number of",
    "m ) as users provide more samples. When increasing the number of users n, the privacy cost decreases at a faster O ( 1/n ) rate. To address this issue, we consider the notion of differential privacy ( DP ). In this paper, we demonstrate the minimax optimality of our algorithms for mean estimation in arbitrary dimension with error scaling as the concentration radius  of the distribution rather than the entire range. In contrast, when increasing the number of",
    ". These correspondences have been instrumental in advancing our understanding of deep neural networks ( DNNs ). These correspondences carry over to a wide variety of architectures. These include convolutional neural networks ( CNNs ) [ 4, 36 ], recurrent neural networks ( RNNs ) [ 2 ] and attention networks ( RNNs ) [ 20 ].",
    ". These correspondences have been instrumental in advancing our understanding of deep neural networks ( DNNs ). These correspondences carry over to a wide variety of architectures. These include convolutional neural networks ( CNNs ) [ 4, 36 ], recurrent neural networks ( RNNs ) [ 2 ] and attention networks ( RNNs ) [ 20 ].",
    ". These correspondences have been instrumental in advancing our understanding of deep neural networks ( DNNs ). These correspondences carry over to a wide variety of architectures. These include convolutional neural networks ( CNNs ) [ 4, 36 ], recurrent neural networks ( RNNs ) [ 2 ] and attention networks ( RNNs ) [ 20 ].",
    ". These correspondences have been instrumental in advancing our understanding of deep neural networks ( DNNs ). These correspondences carry over to a wide variety of architectures. These include convolutional neural networks ( CNNs ) [ 4, 36 ], recurrent neural networks ( RNNs ) [ 2 ] and attention networks ( RNNs ) [ 20 ].",
    ". In a signaling game, one agent ( a sender ) communicates with another agent ( a receiver ). During this process, the agents develop a communication protocol. Compositionality is a crucial feature of natural languages and it has been studied extensively in cognitive science ( see e.g. Batali ( 1998 ) ; Kottur et al. ( 2017 ) ; Choi et al. ( 2018 ).",
    ". In a signaling game, one agent ( a sender ) communicates with another agent ( a receiver ). During this process, the agents develop a communication protocol. Compositionality is a crucial feature of natural languages and it has been studied extensively in cognitive science ( see e.g. Batali ( 1998 ) ; Kottur et al. ( 2017 ) ; Choi et al. ( 2018 ).",
    ". In a signaling game, one agent ( a sender ) communicates with another agent ( a receiver ). During this process, the agents develop a communication protocol. Compositionality is a crucial feature of natural languages and it has been studied extensively in cognitive science ( see e.g. Batali ( 1998 ) ; Kottur et al. ( 2017 ) ; Choi et al. ( 2018 ).",
    ". In a signaling game, one agent ( a sender ) communicates with another agent ( a receiver ). During this process, the agents develop a communication protocol. Compositionality is a crucial feature of natural languages and it has been studied extensively in cognitive science ( see e.g. Batali ( 1998 ) ; Kottur et al. ( 2017 ) ; Choi et al. ( 2018 ).",
    ". Finally, by adapting our8 model to machine translation we achieve surprisingly good results.1 1 Introduction. Recently, the transformer architecture [ 60 ], has achieved performance competitive with the state of the art on ImageNet-1k [ 50 ] when pre-trained with a sufficiently large amount of data. In this paper, we push this trend further, and propose ResMLP :25 a purely multi-layer perceptron ( MLP ) for image classification",
    ". Finally, by adapting our8 model to machine translation we achieve surprisingly good results.1 1 Introduction. Recently, the transformer architecture [ 60 ], has achieved performance competitive with the state of the art on ImageNet-1k [ 50 ] when pre-trained with a sufficiently large amount of data. In this paper, we push this trend further, and propose ResMLP :25 a purely multi-layer perceptron ( MLP ) for image classification",
    ". Finally, by adapting our8 model to machine translation we achieve surprisingly good results.1 1 Introduction. Recently, the transformer architecture [ 60 ], has achieved performance competitive with the state of the art on ImageNet-1k [ 50 ] when pre-trained with a sufficiently large amount of data. In this paper, we push this trend further, and propose ResMLP :25 a purely multi-layer perceptron ( MLP ) for image classification",
    ". Finally, by adapting our8 model to machine translation we achieve surprisingly good results.1 1 Introduction. Recently, the transformer architecture [ 60 ], has achieved performance competitive with the state of the art on ImageNet-1k [ 50 ] when pre-trained with a sufficiently large amount of data. In this paper, we push this trend further, and propose ResMLP :25 a purely multi-layer perceptron ( MLP ) for image classification",
    ". This paper presents an alternative to the traditional margin approaches. In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri ). In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri ). In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri",
    ". This paper presents an alternative to the traditional margin approaches. In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri ). In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri ). In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri",
    ". This paper presents an alternative to the traditional margin approaches. In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri ). In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri ). In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri",
    ". This paper presents an alternative to the traditional margin approaches. In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri ). In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri ). In our formulation assigning a query point q a label i incurs a loss of l ( q, Ri",
    ". In particular, a presence shift, caused by imperfect object detectors, leads to missing visual objects. We propose a new method for transferring reasoning patterns from models learned on perfect visual input to models trained on noisy visual representations. In particular, a presence shift, caused by imperfect object detectors, leads to missing visual objects. We conjecture, that reasoning on noisy visual representations involves additional functional components not necessary in the clean case due to different types of domain shifts",
    ". In particular, a presence shift, caused by imperfect object detectors, leads to missing visual objects. We propose a new method for transferring reasoning patterns from models learned on perfect visual input to models trained on noisy visual representations. In particular, a presence shift, caused by imperfect object detectors, leads to missing visual objects. We conjecture, that reasoning on noisy visual representations involves additional functional components not necessary in the clean case due to different types of domain shifts",
    ". In particular, a presence shift, caused by imperfect object detectors, leads to missing visual objects. We propose a new method for transferring reasoning patterns from models learned on perfect visual input to models trained on noisy visual representations. In particular, a presence shift, caused by imperfect object detectors, leads to missing visual objects. We conjecture, that reasoning on noisy visual representations involves additional functional components not necessary in the clean case due to different types of domain shifts",
    ". In particular, a presence shift, caused by imperfect object detectors, leads to missing visual objects. We propose a new method for transferring reasoning patterns from models learned on perfect visual input to models trained on noisy visual representations. In particular, a presence shift, caused by imperfect object detectors, leads to missing visual objects. We conjecture, that reasoning on noisy visual representations involves additional functional components not necessary in the clean case due to different types of domain shifts",
    "a Turing Machine ( UTM ). These proofs assumed a couple of neurons with unbounded precision that equals the number of symbols used in the Turing tape. Here we provide an alternative simulation of a UTM by RNNs with bounded-precision neurons only. Neurogenesis is the process by which new neurons are produced in the central nervous system ; it is most active during early development, but continues through life.",
    "a Turing Machine ( UTM ). These proofs assumed a couple of neurons with unbounded precision that equals the number of symbols used in the Turing tape. Here we provide an alternative simulation of a UTM by RNNs with bounded-precision neurons only. Neurogenesis is the process by which new neurons are produced in the central nervous system ; it is most active during early development, but continues through life.",
    "a Turing Machine ( UTM ). These proofs assumed a couple of neurons with unbounded precision that equals the number of symbols used in the Turing tape. Here we provide an alternative simulation of a UTM by RNNs with bounded-precision neurons only. Neurogenesis is the process by which new neurons are produced in the central nervous system ; it is most active during early development, but continues through life.",
    "a Turing Machine ( UTM ). These proofs assumed a couple of neurons with unbounded precision that equals the number of symbols used in the Turing tape. Here we provide an alternative simulation of a UTM by RNNs with bounded-precision neurons only. Neurogenesis is the process by which new neurons are produced in the central nervous system ; it is most active during early development, but continues through life.",
    "the problem of uncertainty estimation in regression problems. It is conceptually simple, and is 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). theoretically, it is observed that vanilla quantile regression often under-covers than the desired coverage level in practice. This paper is concerned with the problem of uncertainty estimation in regression problems. In particular, it is observed that vanilla quantile regression often under-covers than the desired coverage level in practice.",
    "the problem of uncertainty estimation in regression problems. It is conceptually simple, and is 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). theoretically, it is observed that vanilla quantile regression often under-covers than the desired coverage level in practice. This paper is concerned with the problem of uncertainty estimation in regression problems. In particular, it is observed that vanilla quantile regression often under-covers than the desired coverage level in practice.",
    "the problem of uncertainty estimation in regression problems. It is conceptually simple, and is 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). theoretically, it is observed that vanilla quantile regression often under-covers than the desired coverage level in practice. This paper is concerned with the problem of uncertainty estimation in regression problems. In particular, it is observed that vanilla quantile regression often under-covers than the desired coverage level in practice.",
    "the problem of uncertainty estimation in regression problems. It is conceptually simple, and is 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). theoretically, it is observed that vanilla quantile regression often under-covers than the desired coverage level in practice. This paper is concerned with the problem of uncertainty estimation in regression problems. In particular, it is observed that vanilla quantile regression often under-covers than the desired coverage level in practice.",
    "20 per old class vs. 1, 300 per new class for the ImageNet-Full dataset. In this paper, we propose to learn an optimal memory management policy for each incremental phase with continuously reinforced model performance. Detailed actions include 1 ) allocating the memory between the existing ( old ) and the coming ( new ) data for each phase. Detailed actions include 3 ) specifying the memory for each old class according to its recognition difficulty before abandoning any of the new classes.",
    "20 per old class vs. 1, 300 per new class for the ImageNet-Full dataset. In this paper, we propose to learn an optimal memory management policy for each incremental phase with continuously reinforced model performance. Detailed actions include 1 ) allocating the memory between the existing ( old ) and the coming ( new ) data for each phase. Detailed actions include 3 ) specifying the memory for each old class according to its recognition difficulty before abandoning any of the new classes.",
    "20 per old class vs. 1, 300 per new class for the ImageNet-Full dataset. In this paper, we propose to learn an optimal memory management policy for each incremental phase with continuously reinforced model performance. Detailed actions include 1 ) allocating the memory between the existing ( old ) and the coming ( new ) data for each phase. Detailed actions include 3 ) specifying the memory for each old class according to its recognition difficulty before abandoning any of the new classes.",
    "20 per old class vs. 1, 300 per new class for the ImageNet-Full dataset. In this paper, we propose to learn an optimal memory management policy for each incremental phase with continuously reinforced model performance. Detailed actions include 1 ) allocating the memory between the existing ( old ) and the coming ( new ) data for each phase. Detailed actions include 3 ) specifying the memory for each old class according to its recognition difficulty before abandoning any of the new classes.",
    ". Moreover, one-shot averaging can achieve the optimal convergence rate asymptotically. In particular, we show that  ( N ) communications are sufficient. In particular, we show that  ( N ) communications fail to achieve the optimal convergence rate asymptotically. Moreover, one-shot averaging which only uses a single round of communication can also achieve the optimal convergence rate asymptotically.",
    ". Moreover, one-shot averaging can achieve the optimal convergence rate asymptotically. In particular, we show that  ( N ) communications are sufficient. In particular, we show that  ( N ) communications fail to achieve the optimal convergence rate asymptotically. Moreover, one-shot averaging which only uses a single round of communication can also achieve the optimal convergence rate asymptotically.",
    ". Moreover, one-shot averaging can achieve the optimal convergence rate asymptotically. In particular, we show that  ( N ) communications are sufficient. In particular, we show that  ( N ) communications fail to achieve the optimal convergence rate asymptotically. Moreover, one-shot averaging which only uses a single round of communication can also achieve the optimal convergence rate asymptotically.",
    ". Moreover, one-shot averaging can achieve the optimal convergence rate asymptotically. In particular, we show that  ( N ) communications are sufficient. In particular, we show that  ( N ) communications fail to achieve the optimal convergence rate asymptotically. Moreover, one-shot averaging which only uses a single round of communication can also achieve the optimal convergence rate asymptotically.",
    "universal in the sense that it also achieves O ( logN ) expected regret against adversarial opponents. This improves upon the more complex metaalgorithm of Huang et al [ 20 ] that only gets O (  N ) regret. The first two are specialised to X the simplex. The latter works for any compact convex domain. The bulk of online linear optimisation is a repeated game with one opponent. On turn n we know the cost vectors",
    "universal in the sense that it also achieves O ( logN ) expected regret against adversarial opponents. This improves upon the more complex metaalgorithm of Huang et al [ 20 ] that only gets O (  N ) regret. The first two are specialised to X the simplex. The latter works for any compact convex domain. The bulk of online linear optimisation is a repeated game with one opponent. On turn n we know the cost vectors",
    "universal in the sense that it also achieves O ( logN ) expected regret against adversarial opponents. This improves upon the more complex metaalgorithm of Huang et al [ 20 ] that only gets O (  N ) regret. The first two are specialised to X the simplex. The latter works for any compact convex domain. The bulk of online linear optimisation is a repeated game with one opponent. On turn n we know the cost vectors",
    "universal in the sense that it also achieves O ( logN ) expected regret against adversarial opponents. This improves upon the more complex metaalgorithm of Huang et al [ 20 ] that only gets O (  N ) regret. The first two are specialised to X the simplex. The latter works for any compact convex domain. The bulk of online linear optimisation is a repeated game with one opponent. On turn n we know the cost vectors",
    "a Riemannian manifold [ 2, 16 ]. Riemannian metrics have been proposed for learning over the space of SPD matrices [ 2, 16 ]. Riemannian metrics have been proposed for learning over the space of SPD matrices [ 2, 16 ]. However, to the best of our knowledge, a systematic study comparing the different metrics for optimizing generic cost functions defined on Sn++ is missing.",
    "a Riemannian manifold [ 2, 16 ]. Riemannian metrics have been proposed for learning over the space of SPD matrices [ 2, 16 ]. Riemannian metrics have been proposed for learning over the space of SPD matrices [ 2, 16 ]. However, to the best of our knowledge, a systematic study comparing the different metrics for optimizing generic cost functions defined on Sn++ is missing.",
    "a Riemannian manifold [ 2, 16 ]. Riemannian metrics have been proposed for learning over the space of SPD matrices [ 2, 16 ]. Riemannian metrics have been proposed for learning over the space of SPD matrices [ 2, 16 ]. However, to the best of our knowledge, a systematic study comparing the different metrics for optimizing generic cost functions defined on Sn++ is missing.",
    "a Riemannian manifold [ 2, 16 ]. Riemannian metrics have been proposed for learning over the space of SPD matrices [ 2, 16 ]. Riemannian metrics have been proposed for learning over the space of SPD matrices [ 2, 16 ]. However, to the best of our knowledge, a systematic study comparing the different metrics for optimizing generic cost functions defined on Sn++ is missing.",
    "focusing on one standard metric, such as accuracy, lets researchers off the hook too much on other pressing issues. Reproducibility, accessibility, and backwards compatibility are important issues as well.",
    "focusing on one standard metric, such as accuracy, lets researchers off the hook too much on other pressing issues. Reproducibility, accessibility, and backwards compatibility are important issues as well.",
    "focusing on one standard metric, such as accuracy, lets researchers off the hook too much on other pressing issues. Reproducibility, accessibility, and backwards compatibility are important issues as well.",
    "focusing on one standard metric, such as accuracy, lets researchers off the hook too much on other pressing issues. Reproducibility, accessibility, and backwards compatibility are important issues as well.",
    "professional voice actors re-record each line to match the lip movement with proper prosody such as stress, intonation and rhythm, which allows their speech to be synchronized with the pre-recorded high-definition video. The main challenges of the task are two-fold : ( 1 ) temporal synchronization between synthesized speech ; ( 2 ) the content of the speech should be consistent with the input text. Text to speech ( TTS ) is",
    "professional voice actors re-record each line to match the lip movement with proper prosody such as stress, intonation and rhythm, which allows their speech to be synchronized with the pre-recorded high-definition video. The main challenges of the task are two-fold : ( 1 ) temporal synchronization between synthesized speech ; ( 2 ) the content of the speech should be consistent with the input text. Text to speech ( TTS ) is",
    "professional voice actors re-record each line to match the lip movement with proper prosody such as stress, intonation and rhythm, which allows their speech to be synchronized with the pre-recorded high-definition video. The main challenges of the task are two-fold : ( 1 ) temporal synchronization between synthesized speech ; ( 2 ) the content of the speech should be consistent with the input text. Text to speech ( TTS ) is",
    "professional voice actors re-record each line to match the lip movement with proper prosody such as stress, intonation and rhythm, which allows their speech to be synchronized with the pre-recorded high-definition video. The main challenges of the task are two-fold : ( 1 ) temporal synchronization between synthesized speech ; ( 2 ) the content of the speech should be consistent with the input text. Text to speech ( TTS ) is",
    "distributed machine learning ( FL ) enables model training on a large corpus of decentralized data. FL enables model training on a large corpus of decentralized data. SL enables model training under non-independent and non-identically distributed ( non-IID ) data. SL enables split learning ( SL ) which offers better privacy and requires lower computational resources of clients and the server. SL enables split learning on a large corpus of decentralized data.",
    "distributed machine learning ( FL ) enables model training on a large corpus of decentralized data. FL enables model training on a large corpus of decentralized data. SL enables model training under non-independent and non-identically distributed ( non-IID ) data. SL enables split learning ( SL ) which offers better privacy and requires lower computational resources of clients and the server. SL enables split learning on a large corpus of decentralized data.",
    "distributed machine learning ( FL ) enables model training on a large corpus of decentralized data. FL enables model training on a large corpus of decentralized data. SL enables model training under non-independent and non-identically distributed ( non-IID ) data. SL enables split learning ( SL ) which offers better privacy and requires lower computational resources of clients and the server. SL enables split learning on a large corpus of decentralized data.",
    "distributed machine learning ( FL ) enables model training on a large corpus of decentralized data. FL enables model training on a large corpus of decentralized data. SL enables model training under non-independent and non-identically distributed ( non-IID ) data. SL enables split learning ( SL ) which offers better privacy and requires lower computational resources of clients and the server. SL enables split learning on a large corpus of decentralized data.",
    "an indicator function from an oriented point cloud in a few milliseconds. Thanks to the differentiablility of our Poisson solver, gradients from a loss on the intermediate indicator grid can be efficiently backpropagated to update the indicator function. Compared to existing shape representations, Shape-As-Points ( SAP ) has the following advantages ( see also Table 1 ) : Efficiency : SAP only requires storing a small amount of data ( see also Table 1",
    "an indicator function from an oriented point cloud in a few milliseconds. Thanks to the differentiablility of our Poisson solver, gradients from a loss on the intermediate indicator grid can be efficiently backpropagated to update the indicator function. Compared to existing shape representations, Shape-As-Points ( SAP ) has the following advantages ( see also Table 1 ) : Efficiency : SAP only requires storing a small amount of data ( see also Table 1",
    "an indicator function from an oriented point cloud in a few milliseconds. Thanks to the differentiablility of our Poisson solver, gradients from a loss on the intermediate indicator grid can be efficiently backpropagated to update the indicator function. Compared to existing shape representations, Shape-As-Points ( SAP ) has the following advantages ( see also Table 1 ) : Efficiency : SAP only requires storing a small amount of data ( see also Table 1",
    "an indicator function from an oriented point cloud in a few milliseconds. Thanks to the differentiablility of our Poisson solver, gradients from a loss on the intermediate indicator grid can be efficiently backpropagated to update the indicator function. Compared to existing shape representations, Shape-As-Points ( SAP ) has the following advantages ( see also Table 1 ) : Efficiency : SAP only requires storing a small amount of data ( see also Table 1",
    "y = Ax + noise. Inverse problems involve reconstructing an unknown vector x from measurements y = A ( x ). Typically, the forward operator A corrupts the unknown vector x and reduces its dimension. Surprisingly, we can recover representations that are useful for downstream tasks. We introduce a robust encoder S that is trained to imitate the behavior of the pretrained CLIP encoder acting on clean images x. However, the input",
    "y = Ax + noise. Inverse problems involve reconstructing an unknown vector x from measurements y = A ( x ). Typically, the forward operator A corrupts the unknown vector x and reduces its dimension. Surprisingly, we can recover representations that are useful for downstream tasks. We introduce a robust encoder S that is trained to imitate the behavior of the pretrained CLIP encoder acting on clean images x. However, the input",
    "y = Ax + noise. Inverse problems involve reconstructing an unknown vector x from measurements y = A ( x ). Typically, the forward operator A corrupts the unknown vector x and reduces its dimension. Surprisingly, we can recover representations that are useful for downstream tasks. We introduce a robust encoder S that is trained to imitate the behavior of the pretrained CLIP encoder acting on clean images x. However, the input",
    "y = Ax + noise. Inverse problems involve reconstructing an unknown vector x from measurements y = A ( x ). Typically, the forward operator A corrupts the unknown vector x and reduces its dimension. Surprisingly, we can recover representations that are useful for downstream tasks. We introduce a robust encoder S that is trained to imitate the behavior of the pretrained CLIP encoder acting on clean images x. However, the input",
    "training neural networks involves structural credit assignment. attributing credit ( or blame ) to nodes in the network for correct ( or incorrect ) predictions. Moving beyond backprop provides more flexibility in training neural networks. to make progress towards this lofty goal, we revisit an old idea : treating each node as an agent. the work in CoANs 1 ) nicely formalizes the idea of a collection of agents\u2014each agent corresponding to a node or subset of nodes.",
    "training neural networks involves structural credit assignment. attributing credit ( or blame ) to nodes in the network for correct ( or incorrect ) predictions. Moving beyond backprop provides more flexibility in training neural networks. to make progress towards this lofty goal, we revisit an old idea : treating each node as an agent. the work in CoANs 1 ) nicely formalizes the idea of a collection of agents\u2014each agent corresponding to a node or subset of nodes.",
    "training neural networks involves structural credit assignment. attributing credit ( or blame ) to nodes in the network for correct ( or incorrect ) predictions. Moving beyond backprop provides more flexibility in training neural networks. to make progress towards this lofty goal, we revisit an old idea : treating each node as an agent. the work in CoANs 1 ) nicely formalizes the idea of a collection of agents\u2014each agent corresponding to a node or subset of nodes.",
    "training neural networks involves structural credit assignment. attributing credit ( or blame ) to nodes in the network for correct ( or incorrect ) predictions. Moving beyond backprop provides more flexibility in training neural networks. to make progress towards this lofty goal, we revisit an old idea : treating each node as an agent. the work in CoANs 1 ) nicely formalizes the idea of a collection of agents\u2014each agent corresponding to a node or subset of nodes.",
    "deep artificial neural networks ( ANNs ) have been shown to develop representations that map onto the ventral visual stream. however, to the best of our knowledge, no studies have examined the ability of deep ANNs to develop representations that match the dorsal hierarchy. one promising set of candidates are predictive self-supervised loss functions [ 45, 22, 38 ]. ANNs have 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "deep artificial neural networks ( ANNs ) have been shown to develop representations that map onto the ventral visual stream. however, to the best of our knowledge, no studies have examined the ability of deep ANNs to develop representations that match the dorsal hierarchy. one promising set of candidates are predictive self-supervised loss functions [ 45, 22, 38 ]. ANNs have 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "deep artificial neural networks ( ANNs ) have been shown to develop representations that map onto the ventral visual stream. however, to the best of our knowledge, no studies have examined the ability of deep ANNs to develop representations that match the dorsal hierarchy. one promising set of candidates are predictive self-supervised loss functions [ 45, 22, 38 ]. ANNs have 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "deep artificial neural networks ( ANNs ) have been shown to develop representations that map onto the ventral visual stream. however, to the best of our knowledge, no studies have examined the ability of deep ANNs to develop representations that match the dorsal hierarchy. one promising set of candidates are predictive self-supervised loss functions [ 45, 22, 38 ]. ANNs have 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". Topic models aim to learn a hierarchy, in which the latent topics exhibit an increasing level of abstraction when moving towards a deeper hidden layer. To address this issue, we assume a structured prior in the form of a predefined topic hierarchy. The other is how to construct a predefined topic hierarchy according to the user \u2019 s customization.",
    ". Topic models aim to learn a hierarchy, in which the latent topics exhibit an increasing level of abstraction when moving towards a deeper hidden layer. To address this issue, we assume a structured prior in the form of a predefined topic hierarchy. The other is how to construct a predefined topic hierarchy according to the user \u2019 s customization.",
    ". Topic models aim to learn a hierarchy, in which the latent topics exhibit an increasing level of abstraction when moving towards a deeper hidden layer. To address this issue, we assume a structured prior in the form of a predefined topic hierarchy. The other is how to construct a predefined topic hierarchy according to the user \u2019 s customization.",
    ". Topic models aim to learn a hierarchy, in which the latent topics exhibit an increasing level of abstraction when moving towards a deeper hidden layer. To address this issue, we assume a structured prior in the form of a predefined topic hierarchy. The other is how to construct a predefined topic hierarchy according to the user \u2019 s customization.",
    "self-supervised pretraining that is aligned to object detection. In this paper, we present an object-level self-supervised pretraining framework, called Selective Object COntrastive learning ( SoCo ). SoCo constructs object-level visual representations with properties that are compatible with object detection. In particular, SoCo constructs object-level views where the scales and translations are reflected by the location and size of the bounding boxes. In this paper, we",
    "self-supervised pretraining that is aligned to object detection. In this paper, we present an object-level self-supervised pretraining framework, called Selective Object COntrastive learning ( SoCo ). SoCo constructs object-level visual representations with properties that are compatible with object detection. In particular, SoCo constructs object-level views where the scales and translations are reflected by the location and size of the bounding boxes. In this paper, we",
    "self-supervised pretraining that is aligned to object detection. In this paper, we present an object-level self-supervised pretraining framework, called Selective Object COntrastive learning ( SoCo ). SoCo constructs object-level visual representations with properties that are compatible with object detection. In particular, SoCo constructs object-level views where the scales and translations are reflected by the location and size of the bounding boxes. In this paper, we",
    "self-supervised pretraining that is aligned to object detection. In this paper, we present an object-level self-supervised pretraining framework, called Selective Object COntrastive learning ( SoCo ). SoCo constructs object-level visual representations with properties that are compatible with object detection. In particular, SoCo constructs object-level views where the scales and translations are reflected by the location and size of the bounding boxes. In this paper, we",
    "........................................................",
    "........................................................",
    "........................................................",
    "........................................................",
    ". By contrast, biological neural networks can effectively learn a new experience by avoiding catastrophic forgetting. We propose to actively forget the old knowledge that interferes with the learning of new tasks without significantly increasing catastrophic forgetting. Specifically, we adopt Bayesian continual learning and actively forget the posterior distribution that absorbs all the information of the old tasks with a forgetting factor to better learn each new task. Then, we derive a novel method called Active Forgetting to improve continual learning",
    ". By contrast, biological neural networks can effectively learn a new experience by avoiding catastrophic forgetting. We propose to actively forget the old knowledge that interferes with the learning of new tasks without significantly increasing catastrophic forgetting. Specifically, we adopt Bayesian continual learning and actively forget the posterior distribution that absorbs all the information of the old tasks with a forgetting factor to better learn each new task. Then, we derive a novel method called Active Forgetting to improve continual learning",
    ". By contrast, biological neural networks can effectively learn a new experience by avoiding catastrophic forgetting. We propose to actively forget the old knowledge that interferes with the learning of new tasks without significantly increasing catastrophic forgetting. Specifically, we adopt Bayesian continual learning and actively forget the posterior distribution that absorbs all the information of the old tasks with a forgetting factor to better learn each new task. Then, we derive a novel method called Active Forgetting to improve continual learning",
    ". By contrast, biological neural networks can effectively learn a new experience by avoiding catastrophic forgetting. We propose to actively forget the old knowledge that interferes with the learning of new tasks without significantly increasing catastrophic forgetting. Specifically, we adopt Bayesian continual learning and actively forget the posterior distribution that absorbs all the information of the old tasks with a forgetting factor to better learn each new task. Then, we derive a novel method called Active Forgetting to improve continual learning",
    ". The second type is directed search, where the update only depends on comparison between function values at different points. The second type is directed search, where the update only depends on comparison between function values at different points. To improve, various attempts have been made to augment random search with ( extra ). J.Z. is the Corresponding Author. G.W. is now with School of Software, Shandong, China. G.W. is now with",
    ". The second type is directed search, where the update only depends on comparison between function values at different points. The second type is directed search, where the update only depends on comparison between function values at different points. To improve, various attempts have been made to augment random search with ( extra ). J.Z. is the Corresponding Author. G.W. is now with School of Software, Shandong, China. G.W. is now with",
    ". The second type is directed search, where the update only depends on comparison between function values at different points. The second type is directed search, where the update only depends on comparison between function values at different points. To improve, various attempts have been made to augment random search with ( extra ). J.Z. is the Corresponding Author. G.W. is now with School of Software, Shandong, China. G.W. is now with",
    ". The second type is directed search, where the update only depends on comparison between function values at different points. The second type is directed search, where the update only depends on comparison between function values at different points. To improve, various attempts have been made to augment random search with ( extra ). J.Z. is the Corresponding Author. G.W. is now with School of Software, Shandong, China. G.W. is now with",
    ". This paper provides the first systematic analysis of learning pruned neural networks with a finite number of training samples in the oracle-learn model. this paper. provides the first theoretical evidence that within a randomly initialized dense neural network, there exists a good sub-network. when trained in isolation, this winning ticket can achieve at least the same testing accuracy as that of the original network.",
    ". This paper provides the first systematic analysis of learning pruned neural networks with a finite number of training samples in the oracle-learn model. this paper. provides the first theoretical evidence that within a randomly initialized dense neural network, there exists a good sub-network. when trained in isolation, this winning ticket can achieve at least the same testing accuracy as that of the original network.",
    ". This paper provides the first systematic analysis of learning pruned neural networks with a finite number of training samples in the oracle-learn model. this paper. provides the first theoretical evidence that within a randomly initialized dense neural network, there exists a good sub-network. when trained in isolation, this winning ticket can achieve at least the same testing accuracy as that of the original network.",
    ". This paper provides the first systematic analysis of learning pruned neural networks with a finite number of training samples in the oracle-learn model. this paper. provides the first theoretical evidence that within a randomly initialized dense neural network, there exists a good sub-network. when trained in isolation, this winning ticket can achieve at least the same testing accuracy as that of the original network.",
    "Query release has been one of the most fundamental and practically relevant problems in differential privacy. In this paper, we study the problem of differentially private query release. given a large collection of statistical queries, the goal is to release approximate answers subject to the constraint of differential privacy. Compared to simple Gaussian or Laplace mechanisms that perturb the answers directly, synthetic data methods can provably answer an exponentially larger collection of queries with non-trivial accuracy.",
    "Query release has been one of the most fundamental and practically relevant problems in differential privacy. In this paper, we study the problem of differentially private query release. given a large collection of statistical queries, the goal is to release approximate answers subject to the constraint of differential privacy. Compared to simple Gaussian or Laplace mechanisms that perturb the answers directly, synthetic data methods can provably answer an exponentially larger collection of queries with non-trivial accuracy.",
    "Query release has been one of the most fundamental and practically relevant problems in differential privacy. In this paper, we study the problem of differentially private query release. given a large collection of statistical queries, the goal is to release approximate answers subject to the constraint of differential privacy. Compared to simple Gaussian or Laplace mechanisms that perturb the answers directly, synthetic data methods can provably answer an exponentially larger collection of queries with non-trivial accuracy.",
    "Query release has been one of the most fundamental and practically relevant problems in differential privacy. In this paper, we study the problem of differentially private query release. given a large collection of statistical queries, the goal is to release approximate answers subject to the constraint of differential privacy. Compared to simple Gaussian or Laplace mechanisms that perturb the answers directly, synthetic data methods can provably answer an exponentially larger collection of queries with non-trivial accuracy.",
    "mask classification is sufficiently general to solve both semantic- and instance-level segmentation tasks. Mask R-CNN [ 19 ] and DETR [ 3 ] yield a single class prediction per segment for instance and panoptic segmentation. In contrast, per-pixel classification assumes a static number of outputs and can not return a variable number of predicted regions/segments. To address both questions, we propose a simple MaskFormer approach that seamlessly converts any existing per-pixel classification",
    "mask classification is sufficiently general to solve both semantic- and instance-level segmentation tasks. Mask R-CNN [ 19 ] and DETR [ 3 ] yield a single class prediction per segment for instance and panoptic segmentation. In contrast, per-pixel classification assumes a static number of outputs and can not return a variable number of predicted regions/segments. To address both questions, we propose a simple MaskFormer approach that seamlessly converts any existing per-pixel classification",
    "mask classification is sufficiently general to solve both semantic- and instance-level segmentation tasks. Mask R-CNN [ 19 ] and DETR [ 3 ] yield a single class prediction per segment for instance and panoptic segmentation. In contrast, per-pixel classification assumes a static number of outputs and can not return a variable number of predicted regions/segments. To address both questions, we propose a simple MaskFormer approach that seamlessly converts any existing per-pixel classification",
    "mask classification is sufficiently general to solve both semantic- and instance-level segmentation tasks. Mask R-CNN [ 19 ] and DETR [ 3 ] yield a single class prediction per segment for instance and panoptic segmentation. In contrast, per-pixel classification assumes a static number of outputs and can not return a variable number of predicted regions/segments. To address both questions, we propose a simple MaskFormer approach that seamlessly converts any existing per-pixel classification",
    "f ( x ) | = O ( 1 ) with high probability. We say that 2 Rd is an adversarial perturbation at x 2 Rd if k k  kxk and sign ( f ( x + ) 6= sign ( f ( x + ) ). In this case, we call x+ an adversarial example. We prove this statement for networks of subexponential width k.",
    "f ( x ) | = O ( 1 ) with high probability. We say that 2 Rd is an adversarial perturbation at x 2 Rd if k k  kxk and sign ( f ( x + ) 6= sign ( f ( x + ) ). In this case, we call x+ an adversarial example. We prove this statement for networks of subexponential width k.",
    "f ( x ) | = O ( 1 ) with high probability. We say that 2 Rd is an adversarial perturbation at x 2 Rd if k k  kxk and sign ( f ( x + ) 6= sign ( f ( x + ) ). In this case, we call x+ an adversarial example. We prove this statement for networks of subexponential width k.",
    "f ( x ) | = O ( 1 ) with high probability. We say that 2 Rd is an adversarial perturbation at x 2 Rd if k k  kxk and sign ( f ( x + ) 6= sign ( f ( x + ) ). In this case, we call x+ an adversarial example. We prove this statement for networks of subexponential width k.",
    ".....................................................",
    ".....................................................",
    ".....................................................",
    ".....................................................",
    "a kernel-based neural network. In this work, we extend this theoretical investigation into the superiority of neural networks over linear learners. This line of reasoning, inspired by practical settings, proposes a new line of reasoning that we refer to as \u201c Local vs. Local \u201d. In this work, we extend this theoretical investigation into the superiority of neural networks over linear learners. This line of reasoning, inspired by practical settings, proposes a new line of reasoning that we refer",
    "a kernel-based neural network. In this work, we extend this theoretical investigation into the superiority of neural networks over linear learners. This line of reasoning, inspired by practical settings, proposes a new line of reasoning that we refer to as \u201c Local vs. Local \u201d. In this work, we extend this theoretical investigation into the superiority of neural networks over linear learners. This line of reasoning, inspired by practical settings, proposes a new line of reasoning that we refer",
    "a kernel-based neural network. In this work, we extend this theoretical investigation into the superiority of neural networks over linear learners. This line of reasoning, inspired by practical settings, proposes a new line of reasoning that we refer to as \u201c Local vs. Local \u201d. In this work, we extend this theoretical investigation into the superiority of neural networks over linear learners. This line of reasoning, inspired by practical settings, proposes a new line of reasoning that we refer",
    "a kernel-based neural network. In this work, we extend this theoretical investigation into the superiority of neural networks over linear learners. This line of reasoning, inspired by practical settings, proposes a new line of reasoning that we refer to as \u201c Local vs. Local \u201d. In this work, we extend this theoretical investigation into the superiority of neural networks over linear learners. This line of reasoning, inspired by practical settings, proposes a new line of reasoning that we refer",
    ". The work of Lian et al. [ 24 ] on decentralized stochastic gradient descent ( D-SGD ) has spurred the research on decentralized training methods for machine learning models. In contrast, certain methods can mitigate the impact of heterogeneous data in decentralized optimization. For instance, the gradient tracking ( GT ) methods developed by Lorenzo and Scutari [ 26 ] and Nedi et al. [ 34 ].",
    ". The work of Lian et al. [ 24 ] on decentralized stochastic gradient descent ( D-SGD ) has spurred the research on decentralized training methods for machine learning models. In contrast, certain methods can mitigate the impact of heterogeneous data in decentralized optimization. For instance, the gradient tracking ( GT ) methods developed by Lorenzo and Scutari [ 26 ] and Nedi et al. [ 34 ].",
    ". The work of Lian et al. [ 24 ] on decentralized stochastic gradient descent ( D-SGD ) has spurred the research on decentralized training methods for machine learning models. In contrast, certain methods can mitigate the impact of heterogeneous data in decentralized optimization. For instance, the gradient tracking ( GT ) methods developed by Lorenzo and Scutari [ 26 ] and Nedi et al. [ 34 ].",
    ". The work of Lian et al. [ 24 ] on decentralized stochastic gradient descent ( D-SGD ) has spurred the research on decentralized training methods for machine learning models. In contrast, certain methods can mitigate the impact of heterogeneous data in decentralized optimization. For instance, the gradient tracking ( GT ) methods developed by Lorenzo and Scutari [ 26 ] and Nedi et al. [ 34 ].",
    "the gap is arbitrarily \u201c small \u201d. This paper provides new results on the arm-sampling behavior of UCB. Among these, it is shown that arm-sampling rates under UCB are asymptotically deterministic. This discovery facilitates new sharp asymptotics and an alternative proof for the O p n log n minimax regret of UCB. Furthermore, the \u201c small \u201d gap worst-case lens adopted in this",
    "the gap is arbitrarily \u201c small \u201d. This paper provides new results on the arm-sampling behavior of UCB. Among these, it is shown that arm-sampling rates under UCB are asymptotically deterministic. This discovery facilitates new sharp asymptotics and an alternative proof for the O p n log n minimax regret of UCB. Furthermore, the \u201c small \u201d gap worst-case lens adopted in this",
    "the gap is arbitrarily \u201c small \u201d. This paper provides new results on the arm-sampling behavior of UCB. Among these, it is shown that arm-sampling rates under UCB are asymptotically deterministic. This discovery facilitates new sharp asymptotics and an alternative proof for the O p n log n minimax regret of UCB. Furthermore, the \u201c small \u201d gap worst-case lens adopted in this",
    "the gap is arbitrarily \u201c small \u201d. This paper provides new results on the arm-sampling behavior of UCB. Among these, it is shown that arm-sampling rates under UCB are asymptotically deterministic. This discovery facilitates new sharp asymptotics and an alternative proof for the O p n log n minimax regret of UCB. Furthermore, the \u201c small \u201d gap worst-case lens adopted in this",
    "Cold-Start Recommendation ( CDR ) is a long-standing problem in recommender systems. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or",
    "Cold-Start Recommendation ( CDR ) is a long-standing problem in recommender systems. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or",
    "Cold-Start Recommendation ( CDR ) is a long-standing problem in recommender systems. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or",
    "Cold-Start Recommendation ( CDR ) is a long-standing problem in recommender systems. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or domains for different purposes. With the development of internet techniques, most users always participate in many platforms or",
    "self-attention and pure multi-layer perceptrons ( MLP ). This design may limit the applications of downstream dense prediction tasks like detection and segmentation. In this paper, we present a new conceptually simple yet computationally efficient architecture called Global Filter Network ( GFNet ). This architecture follows the trend of removing inductive biases from vision models while enjoying the log-linear complexity in computation.",
    "self-attention and pure multi-layer perceptrons ( MLP ). This design may limit the applications of downstream dense prediction tasks like detection and segmentation. In this paper, we present a new conceptually simple yet computationally efficient architecture called Global Filter Network ( GFNet ). This architecture follows the trend of removing inductive biases from vision models while enjoying the log-linear complexity in computation.",
    "self-attention and pure multi-layer perceptrons ( MLP ). This design may limit the applications of downstream dense prediction tasks like detection and segmentation. In this paper, we present a new conceptually simple yet computationally efficient architecture called Global Filter Network ( GFNet ). This architecture follows the trend of removing inductive biases from vision models while enjoying the log-linear complexity in computation.",
    "self-attention and pure multi-layer perceptrons ( MLP ). This design may limit the applications of downstream dense prediction tasks like detection and segmentation. In this paper, we present a new conceptually simple yet computationally efficient architecture called Global Filter Network ( GFNet ). This architecture follows the trend of removing inductive biases from vision models while enjoying the log-linear complexity in computation.",
    ". Moreover, the data is relatively simple and easy-to-classify. As a result, the trustworthiness predictors are prone to classify incorrect predictions as trustworthy predictions. To further understand the prowess of predicting trustworthiness, we present a general illustration of predicting trustworthiness [ 9, 13 ]. The true class probability ( TCP ) is based on the confidence w.r.t. the ground-truth class",
    ". Moreover, the data is relatively simple and easy-to-classify. As a result, the trustworthiness predictors are prone to classify incorrect predictions as trustworthy predictions. To further understand the prowess of predicting trustworthiness, we present a general illustration of predicting trustworthiness [ 9, 13 ]. The true class probability ( TCP ) is based on the confidence w.r.t. the ground-truth class",
    ". Moreover, the data is relatively simple and easy-to-classify. As a result, the trustworthiness predictors are prone to classify incorrect predictions as trustworthy predictions. To further understand the prowess of predicting trustworthiness, we present a general illustration of predicting trustworthiness [ 9, 13 ]. The true class probability ( TCP ) is based on the confidence w.r.t. the ground-truth class",
    ". Moreover, the data is relatively simple and easy-to-classify. As a result, the trustworthiness predictors are prone to classify incorrect predictions as trustworthy predictions. To further understand the prowess of predicting trustworthiness, we present a general illustration of predicting trustworthiness [ 9, 13 ]. The true class probability ( TCP ) is based on the confidence w.r.t. the ground-truth class",
    "adversarial training variants [ 23, 32, 38, 33, 35, 36 ], by training a DNN after data augmentation with the worst-case adversarial examples. The non-linear components tend to be instance-wise. The benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation",
    "adversarial training variants [ 23, 32, 38, 33, 35, 36 ], by training a DNN after data augmentation with the worst-case adversarial examples. The non-linear components tend to be instance-wise. The benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation",
    "adversarial training variants [ 23, 32, 38, 33, 35, 36 ], by training a DNN after data augmentation with the worst-case adversarial examples. The non-linear components tend to be instance-wise. The benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation",
    "adversarial training variants [ 23, 32, 38, 33, 35, 36 ], by training a DNN after data augmentation with the worst-case adversarial examples. The non-linear components tend to be instance-wise. The benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation",
    "adversarial training variants [ 23, 32, 38, 33, 35, 36 ], by training a DNN after data augmentation with the worst-case adversarial examples. The non-linear components tend to be instance-wise. The benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation. and benign examples tend to present different patterns on activation",
    "( 1 ) is said to be well-posed if it has a unique solution varying continuously in y. The variational framework circumvents ill-posedness by encoding prior knowledge about x via a regularization functionalR : X R. The variational framework circumvents ill-posedness by encoding prior knowledge about x via a regularization functionalR : X R. The variational framework circumvents ill-posedness",
    "( 1 ) is said to be well-posed if it has a unique solution varying continuously in y. The variational framework circumvents ill-posedness by encoding prior knowledge about x via a regularization functionalR : X R. The variational framework circumvents ill-posedness by encoding prior knowledge about x via a regularization functionalR : X R. The variational framework circumvents ill-posedness",
    "( 1 ) is said to be well-posed if it has a unique solution varying continuously in y. The variational framework circumvents ill-posedness by encoding prior knowledge about x via a regularization functionalR : X R. The variational framework circumvents ill-posedness by encoding prior knowledge about x via a regularization functionalR : X R. The variational framework circumvents ill-posedness",
    "( 1 ) is said to be well-posed if it has a unique solution varying continuously in y. The variational framework circumvents ill-posedness by encoding prior knowledge about x via a regularization functionalR : X R. The variational framework circumvents ill-posedness by encoding prior knowledge about x via a regularization functionalR : X R. The variational framework circumvents ill-posedness",
    "( 1 ) is said to be well-posed if it has a unique solution varying continuously in y. The variational framework circumvents ill-posedness by encoding prior knowledge about x via a regularization functionalR : X R. The variational framework circumvents ill-posedness by encoding prior knowledge about x via a regularization functionalR : X R. The variational framework circumvents ill-posedness",
    "; ( 1 ) The object detector is both annotation-expensive and compute-expensive ; ( 2 ) The word token embeddings reside in their own spaces, which makes it difficult for the multimodal encoder to learn to model their interactions. We propose ALign BEfore Fuse ( ALBEF ), a new VLP framework to address these limitations. ( 1 ) it aligns the image features and the text features, making it easier for the multimodal",
    "; ( 1 ) The object detector is both annotation-expensive and compute-expensive ; ( 2 ) The word token embeddings reside in their own spaces, which makes it difficult for the multimodal encoder to learn to model their interactions. We propose ALign BEfore Fuse ( ALBEF ), a new VLP framework to address these limitations. ( 1 ) it aligns the image features and the text features, making it easier for the multimodal",
    "; ( 1 ) The object detector is both annotation-expensive and compute-expensive ; ( 2 ) The word token embeddings reside in their own spaces, which makes it difficult for the multimodal encoder to learn to model their interactions. We propose ALign BEfore Fuse ( ALBEF ), a new VLP framework to address these limitations. ( 1 ) it aligns the image features and the text features, making it easier for the multimodal",
    "; ( 1 ) The object detector is both annotation-expensive and compute-expensive ; ( 2 ) The word token embeddings reside in their own spaces, which makes it difficult for the multimodal encoder to learn to model their interactions. We propose ALign BEfore Fuse ( ALBEF ), a new VLP framework to address these limitations. ( 1 ) it aligns the image features and the text features, making it easier for the multimodal",
    "; ( 1 ) The object detector is both annotation-expensive and compute-expensive ; ( 2 ) The word token embeddings reside in their own spaces, which makes it difficult for the multimodal encoder to learn to model their interactions. We propose ALign BEfore Fuse ( ALBEF ), a new VLP framework to address these limitations. ( 1 ) it aligns the image features and the text features, making it easier for the multimodal",
    "the policy value J (  ) is then formalized as the maximization of the policy value J (  ) given a static dataset of previous interactions. The dataset is static ; No additional interaction with the environment is allowed. Third, the policies used to generate the dataset, i.e., the behavior policies, are often unknown and may be totally different from the target policies. This constraint poses several unique challenges to the problem. To address the issue of policy value estimation",
    "the policy value J (  ) is then formalized as the maximization of the policy value J (  ) given a static dataset of previous interactions. The dataset is static ; No additional interaction with the environment is allowed. Third, the policies used to generate the dataset, i.e., the behavior policies, are often unknown and may be totally different from the target policies. This constraint poses several unique challenges to the problem. To address the issue of policy value estimation",
    "the policy value J (  ) is then formalized as the maximization of the policy value J (  ) given a static dataset of previous interactions. The dataset is static ; No additional interaction with the environment is allowed. Third, the policies used to generate the dataset, i.e., the behavior policies, are often unknown and may be totally different from the target policies. This constraint poses several unique challenges to the problem. To address the issue of policy value estimation",
    "the policy value J (  ) is then formalized as the maximization of the policy value J (  ) given a static dataset of previous interactions. The dataset is static ; No additional interaction with the environment is allowed. Third, the policies used to generate the dataset, i.e., the behavior policies, are often unknown and may be totally different from the target policies. This constraint poses several unique challenges to the problem. To address the issue of policy value estimation",
    "the policy value J (  ) is then formalized as the maximization of the policy value J (  ) given a static dataset of previous interactions. The dataset is static ; No additional interaction with the environment is allowed. Third, the policies used to generate the dataset, i.e., the behavior policies, are often unknown and may be totally different from the target policies. This constraint poses several unique challenges to the problem. To address the issue of policy value estimation",
    "and the second method are optimal in the non-smooth setting. However, our results do not support this assumption in practice. Moreover, we propose novel stepsize rules for two stochastic methods with gradients. Moreover, our results imply that the first method is optimal in the non-smooth setting. Moreover, our results imply that the second method is optimal in the non-smooth setting. Moreover, our results imply that the first method is",
    "and the second method are optimal in the non-smooth setting. However, our results do not support this assumption in practice. Moreover, we propose novel stepsize rules for two stochastic methods with gradients. Moreover, our results imply that the first method is optimal in the non-smooth setting. Moreover, our results imply that the second method is optimal in the non-smooth setting. Moreover, our results imply that the first method is",
    "and the second method are optimal in the non-smooth setting. However, our results do not support this assumption in practice. Moreover, we propose novel stepsize rules for two stochastic methods with gradients. Moreover, our results imply that the first method is optimal in the non-smooth setting. Moreover, our results imply that the second method is optimal in the non-smooth setting. Moreover, our results imply that the first method is",
    "and the second method are optimal in the non-smooth setting. However, our results do not support this assumption in practice. Moreover, we propose novel stepsize rules for two stochastic methods with gradients. Moreover, our results imply that the first method is optimal in the non-smooth setting. Moreover, our results imply that the second method is optimal in the non-smooth setting. Moreover, our results imply that the first method is",
    "and the second method are optimal in the non-smooth setting. However, our results do not support this assumption in practice. Moreover, we propose novel stepsize rules for two stochastic methods with gradients. Moreover, our results imply that the first method is optimal in the non-smooth setting. Moreover, our results imply that the second method is optimal in the non-smooth setting. Moreover, our results imply that the first method is",
    "the long-term forecasting problem of time series. It is quite meaningful for the long-term planning and early warning. Thus, in this paper, we study the long-term forecasting problem of time series. To reason about the intricate temporal patterns, we try to take the idea of decomposition. It can be used to process the complex time series and extract more predictable components. However, under the forecasting context, it can only be used as the pre-processing of past series",
    "the long-term forecasting problem of time series. It is quite meaningful for the long-term planning and early warning. Thus, in this paper, we study the long-term forecasting problem of time series. To reason about the intricate temporal patterns, we try to take the idea of decomposition. It can be used to process the complex time series and extract more predictable components. However, under the forecasting context, it can only be used as the pre-processing of past series",
    "the long-term forecasting problem of time series. It is quite meaningful for the long-term planning and early warning. Thus, in this paper, we study the long-term forecasting problem of time series. To reason about the intricate temporal patterns, we try to take the idea of decomposition. It can be used to process the complex time series and extract more predictable components. However, under the forecasting context, it can only be used as the pre-processing of past series",
    "the long-term forecasting problem of time series. It is quite meaningful for the long-term planning and early warning. Thus, in this paper, we study the long-term forecasting problem of time series. To reason about the intricate temporal patterns, we try to take the idea of decomposition. It can be used to process the complex time series and extract more predictable components. However, under the forecasting context, it can only be used as the pre-processing of past series",
    "the long-term forecasting problem of time series. It is quite meaningful for the long-term planning and early warning. Thus, in this paper, we study the long-term forecasting problem of time series. To reason about the intricate temporal patterns, we try to take the idea of decomposition. It can be used to process the complex time series and extract more predictable components. However, under the forecasting context, it can only be used as the pre-processing of past series",
    ". \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 )",
    ". \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 )",
    ". \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 )",
    ". \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 )",
    ". \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 ) \u201d is the enumeration and specifies the number of letters in the answer. \u201c ( 4 )",
    "a recent breakthrough highlights a fundamental question : how are Vision Transformers solving these image based tasks? Do they act like convolutions, learning the same inductive biases from scratch? Or are they developing novel task representations? What is the role of scale in learning these representations? and are there ramifications for downstream tasks?",
    "a recent breakthrough highlights a fundamental question : how are Vision Transformers solving these image based tasks? Do they act like convolutions, learning the same inductive biases from scratch? Or are they developing novel task representations? What is the role of scale in learning these representations? and are there ramifications for downstream tasks?",
    "a recent breakthrough highlights a fundamental question : how are Vision Transformers solving these image based tasks? Do they act like convolutions, learning the same inductive biases from scratch? Or are they developing novel task representations? What is the role of scale in learning these representations? and are there ramifications for downstream tasks?",
    "a recent breakthrough highlights a fundamental question : how are Vision Transformers solving these image based tasks? Do they act like convolutions, learning the same inductive biases from scratch? Or are they developing novel task representations? What is the role of scale in learning these representations? and are there ramifications for downstream tasks?",
    "a recent breakthrough highlights a fundamental question : how are Vision Transformers solving these image based tasks? Do they act like convolutions, learning the same inductive biases from scratch? Or are they developing novel task representations? What is the role of scale in learning these representations? and are there ramifications for downstream tasks?",
    "the cumulative expected regret, which is defined as the cumulative difference between the expected reward of the optimal arm and the selected arms over T rounds. The learning agent has to balance the tradeoff between exploration and exploitation in each round. The UCB-type algorithms have been widely studied in the literature and provide theoretical guarantees with regret upper bound of order O ( log T/ ). Thompson sampling ( TS ) [ 3, 26 ] is another popular method to solve MAB problems. It is a",
    "the cumulative expected regret, which is defined as the cumulative difference between the expected reward of the optimal arm and the selected arms over T rounds. The learning agent has to balance the tradeoff between exploration and exploitation in each round. The UCB-type algorithms have been widely studied in the literature and provide theoretical guarantees with regret upper bound of order O ( log T/ ). Thompson sampling ( TS ) [ 3, 26 ] is another popular method to solve MAB problems. It is a",
    "the cumulative expected regret, which is defined as the cumulative difference between the expected reward of the optimal arm and the selected arms over T rounds. The learning agent has to balance the tradeoff between exploration and exploitation in each round. The UCB-type algorithms have been widely studied in the literature and provide theoretical guarantees with regret upper bound of order O ( log T/ ). Thompson sampling ( TS ) [ 3, 26 ] is another popular method to solve MAB problems. It is a",
    "the cumulative expected regret, which is defined as the cumulative difference between the expected reward of the optimal arm and the selected arms over T rounds. The learning agent has to balance the tradeoff between exploration and exploitation in each round. The UCB-type algorithms have been widely studied in the literature and provide theoretical guarantees with regret upper bound of order O ( log T/ ). Thompson sampling ( TS ) [ 3, 26 ] is another popular method to solve MAB problems. It is a",
    "the cumulative expected regret, which is defined as the cumulative difference between the expected reward of the optimal arm and the selected arms over T rounds. The learning agent has to balance the tradeoff between exploration and exploitation in each round. The UCB-type algorithms have been widely studied in the literature and provide theoretical guarantees with regret upper bound of order O ( log T/ ). Thompson sampling ( TS ) [ 3, 26 ] is another popular method to solve MAB problems. It is a",
    ".. privacy, data size, and data format are all possible reasons that would make transferring data not a reasonable solution. For example, consider patient medical data located at hospitals or student educational data at different schools. In each case, the individual agents may prefer to build a model using data from multiple agents : multiple hospitals or schools. However, privacy, data size, and data format are all possible reasons that would make transferring data not a reasonable solution. Federated",
    ".. privacy, data size, and data format are all possible reasons that would make transferring data not a reasonable solution. For example, consider patient medical data located at hospitals or student educational data at different schools. In each case, the individual agents may prefer to build a model using data from multiple agents : multiple hospitals or schools. However, privacy, data size, and data format are all possible reasons that would make transferring data not a reasonable solution. Federated",
    ".. privacy, data size, and data format are all possible reasons that would make transferring data not a reasonable solution. For example, consider patient medical data located at hospitals or student educational data at different schools. In each case, the individual agents may prefer to build a model using data from multiple agents : multiple hospitals or schools. However, privacy, data size, and data format are all possible reasons that would make transferring data not a reasonable solution. Federated",
    ".. privacy, data size, and data format are all possible reasons that would make transferring data not a reasonable solution. For example, consider patient medical data located at hospitals or student educational data at different schools. In each case, the individual agents may prefer to build a model using data from multiple agents : multiple hospitals or schools. However, privacy, data size, and data format are all possible reasons that would make transferring data not a reasonable solution. Federated",
    ".. privacy, data size, and data format are all possible reasons that would make transferring data not a reasonable solution. For example, consider patient medical data located at hospitals or student educational data at different schools. In each case, the individual agents may prefer to build a model using data from multiple agents : multiple hospitals or schools. However, privacy, data size, and data format are all possible reasons that would make transferring data not a reasonable solution. Federated",
    "3D deep representation learning is not entirely unsupervised. In particular, all 3D models in the popular ShapeNet dataset are \u201c object-centric \u201d \u2013 they are pre-canonicalized to a unit bounding box. Moreover, all 3D models in the ShapeNet [ 3 ] dataset are \u201c object-centric \u201d \u2013 they are pre-canonicalized to a unit bounding box. Moreover, all 3D models in the ShapeNet [ 3 ] dataset",
    "3D deep representation learning is not entirely unsupervised. In particular, all 3D models in the popular ShapeNet dataset are \u201c object-centric \u201d \u2013 they are pre-canonicalized to a unit bounding box. Moreover, all 3D models in the ShapeNet [ 3 ] dataset are \u201c object-centric \u201d \u2013 they are pre-canonicalized to a unit bounding box. Moreover, all 3D models in the ShapeNet [ 3 ] dataset",
    "3D deep representation learning is not entirely unsupervised. In particular, all 3D models in the popular ShapeNet dataset are \u201c object-centric \u201d \u2013 they are pre-canonicalized to a unit bounding box. Moreover, all 3D models in the ShapeNet [ 3 ] dataset are \u201c object-centric \u201d \u2013 they are pre-canonicalized to a unit bounding box. Moreover, all 3D models in the ShapeNet [ 3 ] dataset",
    "3D deep representation learning is not entirely unsupervised. In particular, all 3D models in the popular ShapeNet dataset are \u201c object-centric \u201d \u2013 they are pre-canonicalized to a unit bounding box. Moreover, all 3D models in the ShapeNet [ 3 ] dataset are \u201c object-centric \u201d \u2013 they are pre-canonicalized to a unit bounding box. Moreover, all 3D models in the ShapeNet [ 3 ] dataset",
    "3D deep representation learning is not entirely unsupervised. In particular, all 3D models in the popular ShapeNet dataset are \u201c object-centric \u201d \u2013 they are pre-canonicalized to a unit bounding box. Moreover, all 3D models in the ShapeNet [ 3 ] dataset are \u201c object-centric \u201d \u2013 they are pre-canonicalized to a unit bounding box. Moreover, all 3D models in the ShapeNet [ 3 ] dataset",
    ". ( 1 )  n+1. ( 2 ) a test point n+1. ( 1 ). ( 2 ).. ( 1 )... calibration data... calibration data.    . .. Third, n, . .",
    ". ( 1 )  n+1. ( 2 ) a test point n+1. ( 1 ). ( 2 ).. ( 1 )... calibration data... calibration data.    . .. Third, n, . .",
    ". ( 1 )  n+1. ( 2 ) a test point n+1. ( 1 ). ( 2 ).. ( 1 )... calibration data... calibration data.    . .. Third, n, . .",
    ". ( 1 )  n+1. ( 2 ) a test point n+1. ( 1 ). ( 2 ).. ( 1 )... calibration data... calibration data.    . .. Third, n, . .",
    ". ( 1 )  n+1. ( 2 ) a test point n+1. ( 1 ). ( 2 ).. ( 1 )... calibration data... calibration data.    . .. Third, n, . .",
    "we provide a precise characterisation of the generalisation benefit of invariance in kernel ridge regression. In contrast to [ 28, 24 ], this proves a provably strict generalisation benefit for invariant, feature-averaged models. In this work, we provide insights into the structure of reproducing kernel Hilbert spaces in relation to invariant functions that we believe will be useful for analysing invariance in other kernel algorithms.",
    "we provide a precise characterisation of the generalisation benefit of invariance in kernel ridge regression. In contrast to [ 28, 24 ], this proves a provably strict generalisation benefit for invariant, feature-averaged models. In this work, we provide insights into the structure of reproducing kernel Hilbert spaces in relation to invariant functions that we believe will be useful for analysing invariance in other kernel algorithms.",
    "we provide a precise characterisation of the generalisation benefit of invariance in kernel ridge regression. In contrast to [ 28, 24 ], this proves a provably strict generalisation benefit for invariant, feature-averaged models. In this work, we provide insights into the structure of reproducing kernel Hilbert spaces in relation to invariant functions that we believe will be useful for analysing invariance in other kernel algorithms.",
    "we provide a precise characterisation of the generalisation benefit of invariance in kernel ridge regression. In contrast to [ 28, 24 ], this proves a provably strict generalisation benefit for invariant, feature-averaged models. In this work, we provide insights into the structure of reproducing kernel Hilbert spaces in relation to invariant functions that we believe will be useful for analysing invariance in other kernel algorithms.",
    "we provide a precise characterisation of the generalisation benefit of invariance in kernel ridge regression. In contrast to [ 28, 24 ], this proves a provably strict generalisation benefit for invariant, feature-averaged models. In this work, we provide insights into the structure of reproducing kernel Hilbert spaces in relation to invariant functions that we believe will be useful for analysing invariance in other kernel algorithms.",
    "traditional hand-written computer programs are comprised of a computational graph of typed variables with associated semantic meaning. However, traditional software has its limitations : it is difficult to classify images or extract sentiment from natural language. In this paper, we propose to train a neural network classifier jointly with a generative model whose role is to map the classifier \u2019 s activations back to the input space. We aim to uncover new ways for practitioners to build and use neural networks by leveraging compositionality",
    "traditional hand-written computer programs are comprised of a computational graph of typed variables with associated semantic meaning. However, traditional software has its limitations : it is difficult to classify images or extract sentiment from natural language. In this paper, we propose to train a neural network classifier jointly with a generative model whose role is to map the classifier \u2019 s activations back to the input space. We aim to uncover new ways for practitioners to build and use neural networks by leveraging compositionality",
    "traditional hand-written computer programs are comprised of a computational graph of typed variables with associated semantic meaning. However, traditional software has its limitations : it is difficult to classify images or extract sentiment from natural language. In this paper, we propose to train a neural network classifier jointly with a generative model whose role is to map the classifier \u2019 s activations back to the input space. We aim to uncover new ways for practitioners to build and use neural networks by leveraging compositionality",
    "traditional hand-written computer programs are comprised of a computational graph of typed variables with associated semantic meaning. However, traditional software has its limitations : it is difficult to classify images or extract sentiment from natural language. In this paper, we propose to train a neural network classifier jointly with a generative model whose role is to map the classifier \u2019 s activations back to the input space. We aim to uncover new ways for practitioners to build and use neural networks by leveraging compositionality",
    "traditional hand-written computer programs are comprised of a computational graph of typed variables with associated semantic meaning. However, traditional software has its limitations : it is difficult to classify images or extract sentiment from natural language. In this paper, we propose to train a neural network classifier jointly with a generative model whose role is to map the classifier \u2019 s activations back to the input space. We aim to uncover new ways for practitioners to build and use neural networks by leveraging compositionality",
    ", d, d  1, has numerous applications in machine learning [ 34, 35, 38, 48, 61, 112 ]. In this paper, we will focus on the OT map T0 (  ) obtained using the standard squared Euclidean cost function, i.e., T ( X )   . In this paper, we will focus on the OT map obtained using",
    ", d, d  1, has numerous applications in machine learning [ 34, 35, 38, 48, 61, 112 ]. In this paper, we will focus on the OT map T0 (  ) obtained using the standard squared Euclidean cost function, i.e., T ( X )   . In this paper, we will focus on the OT map obtained using",
    ", d, d  1, has numerous applications in machine learning [ 34, 35, 38, 48, 61, 112 ]. In this paper, we will focus on the OT map T0 (  ) obtained using the standard squared Euclidean cost function, i.e., T ( X )   . In this paper, we will focus on the OT map obtained using",
    ", d, d  1, has numerous applications in machine learning [ 34, 35, 38, 48, 61, 112 ]. In this paper, we will focus on the OT map T0 (  ) obtained using the standard squared Euclidean cost function, i.e., T ( X )   . In this paper, we will focus on the OT map obtained using",
    ", d, d  1, has numerous applications in machine learning [ 34, 35, 38, 48, 61, 112 ]. In this paper, we will focus on the OT map T0 (  ) obtained using the standard squared Euclidean cost function, i.e., T ( X )   . In this paper, we will focus on the OT map obtained using",
    "coarse approximation of the full dataset. By contrast, dataset distillation is to synthesize datasets that are nevertheless informative. For nonparametric methods that scale poorly with the training dataset, having a reduced dataset decreases the associated memory and inference costs. For the training of neural networks, such distilled datasets have found several applications in the literature.",
    "coarse approximation of the full dataset. By contrast, dataset distillation is to synthesize datasets that are nevertheless informative. For nonparametric methods that scale poorly with the training dataset, having a reduced dataset decreases the associated memory and inference costs. For the training of neural networks, such distilled datasets have found several applications in the literature.",
    "coarse approximation of the full dataset. By contrast, dataset distillation is to synthesize datasets that are nevertheless informative. For nonparametric methods that scale poorly with the training dataset, having a reduced dataset decreases the associated memory and inference costs. For the training of neural networks, such distilled datasets have found several applications in the literature.",
    "coarse approximation of the full dataset. By contrast, dataset distillation is to synthesize datasets that are nevertheless informative. For nonparametric methods that scale poorly with the training dataset, having a reduced dataset decreases the associated memory and inference costs. For the training of neural networks, such distilled datasets have found several applications in the literature.",
    "coarse approximation of the full dataset. By contrast, dataset distillation is to synthesize datasets that are nevertheless informative. For nonparametric methods that scale poorly with the training dataset, having a reduced dataset decreases the associated memory and inference costs. For the training of neural networks, such distilled datasets have found several applications in the literature.",
    ". Unlabeled training data may contain novel categories unseen in the labeled training data. FixMatch [ 35 ] generates pseudo-labels using the model \u2019 s predictions on weakly augmented unlabeled images. FixMatch trains the model to match its predictions on strongly augmented unlabeled images with the pseudo-labels. FixMatch trains the model to match its predictions on strongly augmented unlabeled images with pseudo-labels",
    ". Unlabeled training data may contain novel categories unseen in the labeled training data. FixMatch [ 35 ] generates pseudo-labels using the model \u2019 s predictions on weakly augmented unlabeled images. FixMatch trains the model to match its predictions on strongly augmented unlabeled images with the pseudo-labels. FixMatch trains the model to match its predictions on strongly augmented unlabeled images with pseudo-labels",
    ". Unlabeled training data may contain novel categories unseen in the labeled training data. FixMatch [ 35 ] generates pseudo-labels using the model \u2019 s predictions on weakly augmented unlabeled images. FixMatch trains the model to match its predictions on strongly augmented unlabeled images with the pseudo-labels. FixMatch trains the model to match its predictions on strongly augmented unlabeled images with pseudo-labels",
    ". Unlabeled training data may contain novel categories unseen in the labeled training data. FixMatch [ 35 ] generates pseudo-labels using the model \u2019 s predictions on weakly augmented unlabeled images. FixMatch trains the model to match its predictions on strongly augmented unlabeled images with the pseudo-labels. FixMatch trains the model to match its predictions on strongly augmented unlabeled images with pseudo-labels",
    ". Unlabeled training data may contain novel categories unseen in the labeled training data. FixMatch [ 35 ] generates pseudo-labels using the model \u2019 s predictions on weakly augmented unlabeled images. FixMatch trains the model to match its predictions on strongly augmented unlabeled images with the pseudo-labels. FixMatch trains the model to match its predictions on strongly augmented unlabeled images with pseudo-labels",
    "how can we build an agent that learns to solve hundreds of tasks in complex visual environments? While traditional reinforcement learning ( RL ) has been successful for individual tasks, it requires a substantial amount of human effort for every new task. Instead, we approach learning hundreds of tasks through the paradigm of unsupervised goal-conditioned RL.",
    "how can we build an agent that learns to solve hundreds of tasks in complex visual environments? While traditional reinforcement learning ( RL ) has been successful for individual tasks, it requires a substantial amount of human effort for every new task. Instead, we approach learning hundreds of tasks through the paradigm of unsupervised goal-conditioned RL.",
    "how can we build an agent that learns to solve hundreds of tasks in complex visual environments? While traditional reinforcement learning ( RL ) has been successful for individual tasks, it requires a substantial amount of human effort for every new task. Instead, we approach learning hundreds of tasks through the paradigm of unsupervised goal-conditioned RL.",
    "how can we build an agent that learns to solve hundreds of tasks in complex visual environments? While traditional reinforcement learning ( RL ) has been successful for individual tasks, it requires a substantial amount of human effort for every new task. Instead, we approach learning hundreds of tasks through the paradigm of unsupervised goal-conditioned RL.",
    "how can we build an agent that learns to solve hundreds of tasks in complex visual environments? While traditional reinforcement learning ( RL ) has been successful for individual tasks, it requires a substantial amount of human effort for every new task. Instead, we approach learning hundreds of tasks through the paradigm of unsupervised goal-conditioned RL.",
    "the word embedding matrix, which adds another 10 million or more. The largest of the Switch Transformer [ 4 ] models has 1.5 trillion parameters. This explosion in the model size has led to increased interest in approaches for reducing model size. some approaches build on this observation to train a smaller model based on an already trained large model. for example a 66 million parameter DistillBERT [ 11 ] student has been distilled from 108 million parameter BERT-base [ 2 ] teacher",
    "the word embedding matrix, which adds another 10 million or more. The largest of the Switch Transformer [ 4 ] models has 1.5 trillion parameters. This explosion in the model size has led to increased interest in approaches for reducing model size. some approaches build on this observation to train a smaller model based on an already trained large model. for example a 66 million parameter DistillBERT [ 11 ] student has been distilled from 108 million parameter BERT-base [ 2 ] teacher",
    "the word embedding matrix, which adds another 10 million or more. The largest of the Switch Transformer [ 4 ] models has 1.5 trillion parameters. This explosion in the model size has led to increased interest in approaches for reducing model size. some approaches build on this observation to train a smaller model based on an already trained large model. for example a 66 million parameter DistillBERT [ 11 ] student has been distilled from 108 million parameter BERT-base [ 2 ] teacher",
    "the word embedding matrix, which adds another 10 million or more. The largest of the Switch Transformer [ 4 ] models has 1.5 trillion parameters. This explosion in the model size has led to increased interest in approaches for reducing model size. some approaches build on this observation to train a smaller model based on an already trained large model. for example a 66 million parameter DistillBERT [ 11 ] student has been distilled from 108 million parameter BERT-base [ 2 ] teacher",
    "the word embedding matrix, which adds another 10 million or more. The largest of the Switch Transformer [ 4 ] models has 1.5 trillion parameters. This explosion in the model size has led to increased interest in approaches for reducing model size. some approaches build on this observation to train a smaller model based on an already trained large model. for example a 66 million parameter DistillBERT [ 11 ] student has been distilled from 108 million parameter BERT-base [ 2 ] teacher",
    ".. On the other hand, several works leverage structured graph neural networks for modelling source code directly. For example, [ Zhou et al., 2019 ] leveraged a novel graph neural network with composite programming representation for vulnerability identification. However, mainly for computational reasons, GNNs rely on synchronous message passing, requiring message passing iterations to aggregate information. Besides, mainly for computational reasons, GNNs rely on synchronous",
    ".. On the other hand, several works leverage structured graph neural networks for modelling source code directly. For example, [ Zhou et al., 2019 ] leveraged a novel graph neural network with composite programming representation for vulnerability identification. However, mainly for computational reasons, GNNs rely on synchronous message passing, requiring message passing iterations to aggregate information. Besides, mainly for computational reasons, GNNs rely on synchronous",
    ".. On the other hand, several works leverage structured graph neural networks for modelling source code directly. For example, [ Zhou et al., 2019 ] leveraged a novel graph neural network with composite programming representation for vulnerability identification. However, mainly for computational reasons, GNNs rely on synchronous message passing, requiring message passing iterations to aggregate information. Besides, mainly for computational reasons, GNNs rely on synchronous",
    ".. On the other hand, several works leverage structured graph neural networks for modelling source code directly. For example, [ Zhou et al., 2019 ] leveraged a novel graph neural network with composite programming representation for vulnerability identification. However, mainly for computational reasons, GNNs rely on synchronous message passing, requiring message passing iterations to aggregate information. Besides, mainly for computational reasons, GNNs rely on synchronous",
    ".. On the other hand, several works leverage structured graph neural networks for modelling source code directly. For example, [ Zhou et al., 2019 ] leveraged a novel graph neural network with composite programming representation for vulnerability identification. However, mainly for computational reasons, GNNs rely on synchronous message passing, requiring message passing iterations to aggregate information. Besides, mainly for computational reasons, GNNs rely on synchronous",
    "HiT. HiT uses a hierarchical structure of Transformers. HiT divides the generative process into low-resolution and high-resolution stages. HiT focuses on feature decoding and pixel-level generating. This work was done while Long Zhao was a student researcher at the Google Brain team. 35th Conference on Neural Information Processing ( NIP).",
    "HiT. HiT uses a hierarchical structure of Transformers. HiT divides the generative process into low-resolution and high-resolution stages. HiT focuses on feature decoding and pixel-level generating. This work was done while Long Zhao was a student researcher at the Google Brain team. 35th Conference on Neural Information Processing ( NIP).",
    "HiT. HiT uses a hierarchical structure of Transformers. HiT divides the generative process into low-resolution and high-resolution stages. HiT focuses on feature decoding and pixel-level generating. This work was done while Long Zhao was a student researcher at the Google Brain team. 35th Conference on Neural Information Processing ( NIP).",
    "HiT. HiT uses a hierarchical structure of Transformers. HiT divides the generative process into low-resolution and high-resolution stages. HiT focuses on feature decoding and pixel-level generating. This work was done while Long Zhao was a student researcher at the Google Brain team. 35th Conference on Neural Information Processing ( NIP).",
    "HiT. HiT uses a hierarchical structure of Transformers. HiT divides the generative process into low-resolution and high-resolution stages. HiT focuses on feature decoding and pixel-level generating. This work was done while Long Zhao was a student researcher at the Google Brain team. 35th Conference on Neural Information Processing ( NIP).",
    ".. We systematically characterise active learning of geodesically convex halfspaces on graphs. While convex graphs are readily accessible, obtaining many labels is tedious and labour intensive. In this paper, we systematically characterise active learning of geodesically convex halfspaces on graphs. While active learning has been extensively investigated in the machine learning community for over half a century, geodesic convexity on graphs is understudied",
    ".. We systematically characterise active learning of geodesically convex halfspaces on graphs. While convex graphs are readily accessible, obtaining many labels is tedious and labour intensive. In this paper, we systematically characterise active learning of geodesically convex halfspaces on graphs. While active learning has been extensively investigated in the machine learning community for over half a century, geodesic convexity on graphs is understudied",
    ".. We systematically characterise active learning of geodesically convex halfspaces on graphs. While convex graphs are readily accessible, obtaining many labels is tedious and labour intensive. In this paper, we systematically characterise active learning of geodesically convex halfspaces on graphs. While active learning has been extensively investigated in the machine learning community for over half a century, geodesic convexity on graphs is understudied",
    ".. We systematically characterise active learning of geodesically convex halfspaces on graphs. While convex graphs are readily accessible, obtaining many labels is tedious and labour intensive. In this paper, we systematically characterise active learning of geodesically convex halfspaces on graphs. While active learning has been extensively investigated in the machine learning community for over half a century, geodesic convexity on graphs is understudied",
    ".. We systematically characterise active learning of geodesically convex halfspaces on graphs. While convex graphs are readily accessible, obtaining many labels is tedious and labour intensive. In this paper, we systematically characterise active learning of geodesically convex halfspaces on graphs. While active learning has been extensively investigated in the machine learning community for over half a century, geodesic convexity on graphs is understudied",
    ". TAL is based on deep convolutional neural networks ( CNNs ) composed of two modules : a video encoder and a TAL head. In standard optimization of a TAL model, a two-stage transfer learning pipeline is often involved : 1. First, the video encoder is optimized on a large source video classification dataset ( e.g., Kinetics [ 28 ] ) and, optionally, finetunned",
    ". TAL is based on deep convolutional neural networks ( CNNs ) composed of two modules : a video encoder and a TAL head. In standard optimization of a TAL model, a two-stage transfer learning pipeline is often involved : 1. First, the video encoder is optimized on a large source video classification dataset ( e.g., Kinetics [ 28 ] ) and, optionally, finetunned",
    ". TAL is based on deep convolutional neural networks ( CNNs ) composed of two modules : a video encoder and a TAL head. In standard optimization of a TAL model, a two-stage transfer learning pipeline is often involved : 1. First, the video encoder is optimized on a large source video classification dataset ( e.g., Kinetics [ 28 ] ) and, optionally, finetunned",
    ". TAL is based on deep convolutional neural networks ( CNNs ) composed of two modules : a video encoder and a TAL head. In standard optimization of a TAL model, a two-stage transfer learning pipeline is often involved : 1. First, the video encoder is optimized on a large source video classification dataset ( e.g., Kinetics [ 28 ] ) and, optionally, finetunned",
    ". TAL is based on deep convolutional neural networks ( CNNs ) composed of two modules : a video encoder and a TAL head. In standard optimization of a TAL model, a two-stage transfer learning pipeline is often involved : 1. First, the video encoder is optimized on a large source video classification dataset ( e.g., Kinetics [ 28 ] ) and, optionally, finetunned",
    "the residual ri = yix > i  in the intermediate high-dimensional9 regime. ( i ) Using these derivatives, we characterize9 the distribution of the residual ri = yix > i  in the intermediate high-dimensional9 regime. ( iv ) Using these derivatives, we characterize9 the distribution of the residuals ri = yix > i  in the intermediate high",
    "the residual ri = yix > i  in the intermediate high-dimensional9 regime. ( i ) Using these derivatives, we characterize9 the distribution of the residual ri = yix > i  in the intermediate high-dimensional9 regime. ( iv ) Using these derivatives, we characterize9 the distribution of the residuals ri = yix > i  in the intermediate high",
    "the residual ri = yix > i  in the intermediate high-dimensional9 regime. ( i ) Using these derivatives, we characterize9 the distribution of the residual ri = yix > i  in the intermediate high-dimensional9 regime. ( iv ) Using these derivatives, we characterize9 the distribution of the residuals ri = yix > i  in the intermediate high",
    "the residual ri = yix > i  in the intermediate high-dimensional9 regime. ( i ) Using these derivatives, we characterize9 the distribution of the residual ri = yix > i  in the intermediate high-dimensional9 regime. ( iv ) Using these derivatives, we characterize9 the distribution of the residuals ri = yix > i  in the intermediate high",
    "the residual ri = yix > i  in the intermediate high-dimensional9 regime. ( i ) Using these derivatives, we characterize9 the distribution of the residual ri = yix > i  in the intermediate high-dimensional9 regime. ( iv ) Using these derivatives, we characterize9 the distribution of the residuals ri = yix > i  in the intermediate high",
    "p ( gt )  p ( l >  |l ), and p ( g )  p ( l >  |l ). As the barriers exist from the auto-regressive design of neural probabilistic text generators to predicting the global optimum directly [ 30 ], the beam search suffers from a major limitation due to its local property. To cope with this limitation, this paper presents",
    "p ( gt )  p ( l >  |l ), and p ( g )  p ( l >  |l ). As the barriers exist from the auto-regressive design of neural probabilistic text generators to predicting the global optimum directly [ 30 ], the beam search suffers from a major limitation due to its local property. To cope with this limitation, this paper presents",
    "p ( gt )  p ( l >  |l ), and p ( g )  p ( l >  |l ). As the barriers exist from the auto-regressive design of neural probabilistic text generators to predicting the global optimum directly [ 30 ], the beam search suffers from a major limitation due to its local property. To cope with this limitation, this paper presents",
    "p ( gt )  p ( l >  |l ), and p ( g )  p ( l >  |l ). As the barriers exist from the auto-regressive design of neural probabilistic text generators to predicting the global optimum directly [ 30 ], the beam search suffers from a major limitation due to its local property. To cope with this limitation, this paper presents",
    "p ( gt )  p ( l >  |l ), and p ( g )  p ( l >  |l ). As the barriers exist from the auto-regressive design of neural probabilistic text generators to predicting the global optimum directly [ 30 ], the beam search suffers from a major limitation due to its local property. To cope with this limitation, this paper presents",
    "..... We first project xyz coordinates in a global coordinate system onto a local coordinate frame. To achieve rotation invariance, we first design equivariant transformers. To achieve rotation invariance, we first project xyz coordinates in a global coordinate system onto a local coordinate frame. To achieve rotation invariance, we first project xyz coordinates in a global coordinate system onto",
    "..... We first project xyz coordinates in a global coordinate system onto a local coordinate frame. To achieve rotation invariance, we first design equivariant transformers. To achieve rotation invariance, we first project xyz coordinates in a global coordinate system onto a local coordinate frame. To achieve rotation invariance, we first project xyz coordinates in a global coordinate system onto",
    "..... We first project xyz coordinates in a global coordinate system onto a local coordinate frame. To achieve rotation invariance, we first design equivariant transformers. To achieve rotation invariance, we first project xyz coordinates in a global coordinate system onto a local coordinate frame. To achieve rotation invariance, we first project xyz coordinates in a global coordinate system onto",
    "..... We first project xyz coordinates in a global coordinate system onto a local coordinate frame. To achieve rotation invariance, we first design equivariant transformers. To achieve rotation invariance, we first project xyz coordinates in a global coordinate system onto a local coordinate frame. To achieve rotation invariance, we first project xyz coordinates in a global coordinate system onto",
    "..... We first project xyz coordinates in a global coordinate system onto a local coordinate frame. To achieve rotation invariance, we first design equivariant transformers. To achieve rotation invariance, we first project xyz coordinates in a global coordinate system onto a local coordinate frame. To achieve rotation invariance, we first project xyz coordinates in a global coordinate system onto",
    ". traditional methods for unsupervised learning of finite mixture models require to evaluate the likelihood of all components of the mixture. This becomes computa- tionally prohibitive when the number of components is large. We propose an approach6 combining the expectation maximization and the Metropolis-Hastings algorithm to evaluate only a small number of components. The method can be used to train mixture models involving complex, and possibly nonlinear transformations. The computational cost of these methods typically scales",
    ". traditional methods for unsupervised learning of finite mixture models require to evaluate the likelihood of all components of the mixture. This becomes computa- tionally prohibitive when the number of components is large. We propose an approach6 combining the expectation maximization and the Metropolis-Hastings algorithm to evaluate only a small number of components. The method can be used to train mixture models involving complex, and possibly nonlinear transformations. The computational cost of these methods typically scales",
    ". traditional methods for unsupervised learning of finite mixture models require to evaluate the likelihood of all components of the mixture. This becomes computa- tionally prohibitive when the number of components is large. We propose an approach6 combining the expectation maximization and the Metropolis-Hastings algorithm to evaluate only a small number of components. The method can be used to train mixture models involving complex, and possibly nonlinear transformations. The computational cost of these methods typically scales",
    ". traditional methods for unsupervised learning of finite mixture models require to evaluate the likelihood of all components of the mixture. This becomes computa- tionally prohibitive when the number of components is large. We propose an approach6 combining the expectation maximization and the Metropolis-Hastings algorithm to evaluate only a small number of components. The method can be used to train mixture models involving complex, and possibly nonlinear transformations. The computational cost of these methods typically scales",
    ". traditional methods for unsupervised learning of finite mixture models require to evaluate the likelihood of all components of the mixture. This becomes computa- tionally prohibitive when the number of components is large. We propose an approach6 combining the expectation maximization and the Metropolis-Hastings algorithm to evaluate only a small number of components. The method can be used to train mixture models involving complex, and possibly nonlinear transformations. The computational cost of these methods typically scales",
    "sparse subnetwork with negligible degradation in accuracy. Moreover, sparse subnetwork can be sparsified dramatically by network pruning techniques. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be",
    "sparse subnetwork with negligible degradation in accuracy. Moreover, sparse subnetwork can be sparsified dramatically by network pruning techniques. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be",
    "sparse subnetwork with negligible degradation in accuracy. Moreover, sparse subnetwork can be sparsified dramatically by network pruning techniques. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be",
    "sparse subnetwork with negligible degradation in accuracy. Moreover, sparse subnetwork can be sparsified dramatically by network pruning techniques. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be",
    "sparse subnetwork with negligible degradation in accuracy. Moreover, sparse subnetwork can be sparsified dramatically by network pruning techniques. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be sparsified dramatically by network pruning. Moreover, sparse subnetwork can be",
    "....,  is the distribution of the discriminator-generator pair.., a novel family of importance samplers ( IS ) and Markov chain Monte Carlo ( MCMC ) is derived......  . ..  ..",
    "....,  is the distribution of the discriminator-generator pair.., a novel family of importance samplers ( IS ) and Markov chain Monte Carlo ( MCMC ) is derived......  . ..  ..",
    "....,  is the distribution of the discriminator-generator pair.., a novel family of importance samplers ( IS ) and Markov chain Monte Carlo ( MCMC ) is derived......  . ..  ..",
    "....,  is the distribution of the discriminator-generator pair.., a novel family of importance samplers ( IS ) and Markov chain Monte Carlo ( MCMC ) is derived......  . ..  ..",
    "....,  is the distribution of the discriminator-generator pair.., a novel family of importance samplers ( IS ) and Markov chain Monte Carlo ( MCMC ) is derived......  . ..  ..",
    ". Set Transformers [ 6 ] solve this problem by using Transformers [ 12 ] to model pairwise interactions between the elements of the sets. This set encoding is then used for downstream tasks such as reconstruction or classification. In many cases, the set size can be extremely large. Current encoding methods deal with this issue by sampling 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). sampling subsets of the full set ( as a data preprocessing step",
    ". Set Transformers [ 6 ] solve this problem by using Transformers [ 12 ] to model pairwise interactions between the elements of the sets. This set encoding is then used for downstream tasks such as reconstruction or classification. In many cases, the set size can be extremely large. Current encoding methods deal with this issue by sampling 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). sampling subsets of the full set ( as a data preprocessing step",
    ". Set Transformers [ 6 ] solve this problem by using Transformers [ 12 ] to model pairwise interactions between the elements of the sets. This set encoding is then used for downstream tasks such as reconstruction or classification. In many cases, the set size can be extremely large. Current encoding methods deal with this issue by sampling 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). sampling subsets of the full set ( as a data preprocessing step",
    ". Set Transformers [ 6 ] solve this problem by using Transformers [ 12 ] to model pairwise interactions between the elements of the sets. This set encoding is then used for downstream tasks such as reconstruction or classification. In many cases, the set size can be extremely large. Current encoding methods deal with this issue by sampling 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). sampling subsets of the full set ( as a data preprocessing step",
    ". Set Transformers [ 6 ] solve this problem by using Transformers [ 12 ] to model pairwise interactions between the elements of the sets. This set encoding is then used for downstream tasks such as reconstruction or classification. In many cases, the set size can be extremely large. Current encoding methods deal with this issue by sampling 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). sampling subsets of the full set ( as a data preprocessing step",
    ". In this paper, we describe an algorithm that trains agents through self play with no human data and can accommodate the large action space of Diplomacy. We show that our deep Nash value iteration algorithm, when initialized with a human-bootstrapped model, defeats multiple prior human-derived agents in no-press Diplomacy by a wide margin. In this paper, we describe an algorithm that trains agents through self play without any human data and can accommodate the large action space of",
    ". In this paper, we describe an algorithm that trains agents through self play with no human data and can accommodate the large action space of Diplomacy. We show that our deep Nash value iteration algorithm, when initialized with a human-bootstrapped model, defeats multiple prior human-derived agents in no-press Diplomacy by a wide margin. In this paper, we describe an algorithm that trains agents through self play without any human data and can accommodate the large action space of",
    ". In this paper, we describe an algorithm that trains agents through self play with no human data and can accommodate the large action space of Diplomacy. We show that our deep Nash value iteration algorithm, when initialized with a human-bootstrapped model, defeats multiple prior human-derived agents in no-press Diplomacy by a wide margin. In this paper, we describe an algorithm that trains agents through self play without any human data and can accommodate the large action space of",
    ". In this paper, we describe an algorithm that trains agents through self play with no human data and can accommodate the large action space of Diplomacy. We show that our deep Nash value iteration algorithm, when initialized with a human-bootstrapped model, defeats multiple prior human-derived agents in no-press Diplomacy by a wide margin. In this paper, we describe an algorithm that trains agents through self play without any human data and can accommodate the large action space of",
    ". In this paper, we describe an algorithm that trains agents through self play with no human data and can accommodate the large action space of Diplomacy. We show that our deep Nash value iteration algorithm, when initialized with a human-bootstrapped model, defeats multiple prior human-derived agents in no-press Diplomacy by a wide margin. In this paper, we describe an algorithm that trains agents through self play without any human data and can accommodate the large action space of",
    "multi-head attention computes attention over inputs by multiple heads independently. With each head attending to different information, multi-head attention captures more complex data patterns and extracts sophisticated knowledge. Despite the positive knowledge transfer, interference has also been observed in multilingual ( or multi-domain ) training especially when languages ( or domains ) are dissimilar. This is a promising direction for interference 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "multi-head attention computes attention over inputs by multiple heads independently. With each head attending to different information, multi-head attention captures more complex data patterns and extracts sophisticated knowledge. Despite the positive knowledge transfer, interference has also been observed in multilingual ( or multi-domain ) training especially when languages ( or domains ) are dissimilar. This is a promising direction for interference 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "multi-head attention computes attention over inputs by multiple heads independently. With each head attending to different information, multi-head attention captures more complex data patterns and extracts sophisticated knowledge. Despite the positive knowledge transfer, interference has also been observed in multilingual ( or multi-domain ) training especially when languages ( or domains ) are dissimilar. This is a promising direction for interference 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "multi-head attention computes attention over inputs by multiple heads independently. With each head attending to different information, multi-head attention captures more complex data patterns and extracts sophisticated knowledge. Despite the positive knowledge transfer, interference has also been observed in multilingual ( or multi-domain ) training especially when languages ( or domains ) are dissimilar. This is a promising direction for interference 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "multi-head attention computes attention over inputs by multiple heads independently. With each head attending to different information, multi-head attention captures more complex data patterns and extracts sophisticated knowledge. Despite the positive knowledge transfer, interference has also been observed in multilingual ( or multi-domain ) training especially when languages ( or domains ) are dissimilar. This is a promising direction for interference 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    ".......................................................",
    "Massachusetts Institute of Technology, msimchow @ mit.edu Columbia University Microsoft Research NYC NeurIPS 2021 ]. This raises a critical question : how sensitive are Bayesian decision-making algorithms to prior misspecification? For decision-making problems with a very large horizon, it suffices that the misspecified prior places a vanishingly small probability mass on the ground truth",
    "Massachusetts Institute of Technology, msimchow @ mit.edu Columbia University Microsoft Research NYC NeurIPS 2021 ]. This raises a critical question : how sensitive are Bayesian decision-making algorithms to prior misspecification? For decision-making problems with a very large horizon, it suffices that the misspecified prior places a vanishingly small probability mass on the ground truth",
    "Massachusetts Institute of Technology, msimchow @ mit.edu Columbia University Microsoft Research NYC NeurIPS 2021 ]. This raises a critical question : how sensitive are Bayesian decision-making algorithms to prior misspecification? For decision-making problems with a very large horizon, it suffices that the misspecified prior places a vanishingly small probability mass on the ground truth",
    "Massachusetts Institute of Technology, msimchow @ mit.edu Columbia University Microsoft Research NYC NeurIPS 2021 ]. This raises a critical question : how sensitive are Bayesian decision-making algorithms to prior misspecification? For decision-making problems with a very large horizon, it suffices that the misspecified prior places a vanishingly small probability mass on the ground truth",
    "Massachusetts Institute of Technology, msimchow @ mit.edu Columbia University Microsoft Research NYC NeurIPS 2021 ]. This raises a critical question : how sensitive are Bayesian decision-making algorithms to prior misspecification? For decision-making problems with a very large horizon, it suffices that the misspecified prior places a vanishingly small probability mass on the ground truth",
    ". In the second model we consider a version of Equivalence-Query-learning ( EQ-learning ). In this model the learner is given i.i.d. samples from an unknown distribution and is tasked with finding a hypothesis with low generalization error. In the third model we consider an exponential separation for the sample/query complexity of two learning models. This result provides a theoretical confirmation for the experimental observations in Stutz et al. [ 2019 ]",
    ". In the second model we consider a version of Equivalence-Query-learning ( EQ-learning ). In this model the learner is given i.i.d. samples from an unknown distribution and is tasked with finding a hypothesis with low generalization error. In the third model we consider an exponential separation for the sample/query complexity of two learning models. This result provides a theoretical confirmation for the experimental observations in Stutz et al. [ 2019 ]",
    ". In the second model we consider a version of Equivalence-Query-learning ( EQ-learning ). In this model the learner is given i.i.d. samples from an unknown distribution and is tasked with finding a hypothesis with low generalization error. In the third model we consider an exponential separation for the sample/query complexity of two learning models. This result provides a theoretical confirmation for the experimental observations in Stutz et al. [ 2019 ]",
    ". In the second model we consider a version of Equivalence-Query-learning ( EQ-learning ). In this model the learner is given i.i.d. samples from an unknown distribution and is tasked with finding a hypothesis with low generalization error. In the third model we consider an exponential separation for the sample/query complexity of two learning models. This result provides a theoretical confirmation for the experimental observations in Stutz et al. [ 2019 ]",
    ". In the second model we consider a version of Equivalence-Query-learning ( EQ-learning ). In this model the learner is given i.i.d. samples from an unknown distribution and is tasked with finding a hypothesis with low generalization error. In the third model we consider an exponential separation for the sample/query complexity of two learning models. This result provides a theoretical confirmation for the experimental observations in Stutz et al. [ 2019 ]",
    ",, and training time, limiting the accessibility of deep learning for computer vision. This motivates the need for a model selection method that could query a large bank of existing pretrained models with a small subset of the target data. Because of the sheer quantity of pretrained models available to download off the internet today, such a massive library of weights has the potential to be massive and cover a wide variety of tasks, datasets, training methods, and architectures.",
    ",, and training time, limiting the accessibility of deep learning for computer vision. This motivates the need for a model selection method that could query a large bank of existing pretrained models with a small subset of the target data. Because of the sheer quantity of pretrained models available to download off the internet today, such a massive library of weights has the potential to be massive and cover a wide variety of tasks, datasets, training methods, and architectures.",
    ",, and training time, limiting the accessibility of deep learning for computer vision. This motivates the need for a model selection method that could query a large bank of existing pretrained models with a small subset of the target data. Because of the sheer quantity of pretrained models available to download off the internet today, such a massive library of weights has the potential to be massive and cover a wide variety of tasks, datasets, training methods, and architectures.",
    ",, and training time, limiting the accessibility of deep learning for computer vision. This motivates the need for a model selection method that could query a large bank of existing pretrained models with a small subset of the target data. Because of the sheer quantity of pretrained models available to download off the internet today, such a massive library of weights has the potential to be massive and cover a wide variety of tasks, datasets, training methods, and architectures.",
    ",, and training time, limiting the accessibility of deep learning for computer vision. This motivates the need for a model selection method that could query a large bank of existing pretrained models with a small subset of the target data. Because of the sheer quantity of pretrained models available to download off the internet today, such a massive library of weights has the potential to be massive and cover a wide variety of tasks, datasets, training methods, and architectures.",
    "no side-information, like annotated attributes or label meta-data. Finally, our learnt binary codes can perform OOD detection, out-of-the-box, as accurately as a baseline that needs  3000 samples to tune its threshold. In this work, we propose a novel method for Learning Low-dimensional binary Codes ( LLC ) for instances as well as classes. Our method does not require any side-information, like annotated attributes or label meta-",
    "no side-information, like annotated attributes or label meta-data. Finally, our learnt binary codes can perform OOD detection, out-of-the-box, as accurately as a baseline that needs  3000 samples to tune its threshold. In this work, we propose a novel method for Learning Low-dimensional binary Codes ( LLC ) for instances as well as classes. Our method does not require any side-information, like annotated attributes or label meta-",
    "no side-information, like annotated attributes or label meta-data. Finally, our learnt binary codes can perform OOD detection, out-of-the-box, as accurately as a baseline that needs  3000 samples to tune its threshold. In this work, we propose a novel method for Learning Low-dimensional binary Codes ( LLC ) for instances as well as classes. Our method does not require any side-information, like annotated attributes or label meta-",
    "no side-information, like annotated attributes or label meta-data. Finally, our learnt binary codes can perform OOD detection, out-of-the-box, as accurately as a baseline that needs  3000 samples to tune its threshold. In this work, we propose a novel method for Learning Low-dimensional binary Codes ( LLC ) for instances as well as classes. Our method does not require any side-information, like annotated attributes or label meta-",
    "no side-information, like annotated attributes or label meta-data. Finally, our learnt binary codes can perform OOD detection, out-of-the-box, as accurately as a baseline that needs  3000 samples to tune its threshold. In this work, we propose a novel method for Learning Low-dimensional binary Codes ( LLC ) for instances as well as classes. Our method does not require any side-information, like annotated attributes or label meta-",
    "high throughput ( FPS ) or compromise significantly on robustness. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). design deep nets that are both adversarially robust and achieve high throughput when mapped to real hardware. To address this need, we propose Generalized Depthwise-Separable ( GDWS ) convolutions. GDWS is a universal post-training approximation of a standard 2D convolution.",
    "high throughput ( FPS ) or compromise significantly on robustness. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). design deep nets that are both adversarially robust and achieve high throughput when mapped to real hardware. To address this need, we propose Generalized Depthwise-Separable ( GDWS ) convolutions. GDWS is a universal post-training approximation of a standard 2D convolution.",
    "high throughput ( FPS ) or compromise significantly on robustness. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). design deep nets that are both adversarially robust and achieve high throughput when mapped to real hardware. To address this need, we propose Generalized Depthwise-Separable ( GDWS ) convolutions. GDWS is a universal post-training approximation of a standard 2D convolution.",
    "high throughput ( FPS ) or compromise significantly on robustness. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). design deep nets that are both adversarially robust and achieve high throughput when mapped to real hardware. To address this need, we propose Generalized Depthwise-Separable ( GDWS ) convolutions. GDWS is a universal post-training approximation of a standard 2D convolution.",
    "high throughput ( FPS ) or compromise significantly on robustness. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). design deep nets that are both adversarially robust and achieve high throughput when mapped to real hardware. To address this need, we propose Generalized Depthwise-Separable ( GDWS ) convolutions. GDWS is a universal post-training approximation of a standard 2D convolution.",
    "a top-1 accuracy of 53.7 %. The model first predicts the set of graph edits transforming the target into incomplete molecules called synthons. Next, the model learns to expand synthons into complete molecules by attaching relevant leaving groups. Our model achieves a top-1 accuracy of 53.7 %, outperforming previous template-free and semi-template-based methods. Corey and Wipke, 1969 ]. Corey and Wipke,",
    "a top-1 accuracy of 53.7 %. The model first predicts the set of graph edits transforming the target into incomplete molecules called synthons. Next, the model learns to expand synthons into complete molecules by attaching relevant leaving groups. Our model achieves a top-1 accuracy of 53.7 %, outperforming previous template-free and semi-template-based methods. Corey and Wipke, 1969 ]. Corey and Wipke,",
    "a top-1 accuracy of 53.7 %. The model first predicts the set of graph edits transforming the target into incomplete molecules called synthons. Next, the model learns to expand synthons into complete molecules by attaching relevant leaving groups. Our model achieves a top-1 accuracy of 53.7 %, outperforming previous template-free and semi-template-based methods. Corey and Wipke, 1969 ]. Corey and Wipke,",
    "a top-1 accuracy of 53.7 %. The model first predicts the set of graph edits transforming the target into incomplete molecules called synthons. Next, the model learns to expand synthons into complete molecules by attaching relevant leaving groups. Our model achieves a top-1 accuracy of 53.7 %, outperforming previous template-free and semi-template-based methods. Corey and Wipke, 1969 ]. Corey and Wipke,",
    "a top-1 accuracy of 53.7 %. The model first predicts the set of graph edits transforming the target into incomplete molecules called synthons. Next, the model learns to expand synthons into complete molecules by attaching relevant leaving groups. Our model achieves a top-1 accuracy of 53.7 %, outperforming previous template-free and semi-template-based methods. Corey and Wipke, 1969 ]. Corey and Wipke,",
    "..... > 35th Conference on Neural Information Processing Systems ( NeurIPS ) >) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS",
    "..... > 35th Conference on Neural Information Processing Systems ( NeurIPS ) >) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS",
    "..... > 35th Conference on Neural Information Processing Systems ( NeurIPS ) >) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS",
    "..... > 35th Conference on Neural Information Processing Systems ( NeurIPS ) >) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS",
    "..... > 35th Conference on Neural Information Processing Systems ( NeurIPS ) >) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS ) > 35th Conference on Neural Information Processing Systems ( NeurIPS",
    "the deep sparse network ( DSN ) [ 9, 4 ] is a special type of deep networks. It targets learning from sparse and categorical features. Such a learning problem frequently appears in many industrial applications. For example, in advertisement recommendation [ 27 ], there are sparse features such as category, brand, etc. In fraud detection [ 23 ], there are sparse features such as income level, region, etc.",
    "the deep sparse network ( DSN ) [ 9, 4 ] is a special type of deep networks. It targets learning from sparse and categorical features. Such a learning problem frequently appears in many industrial applications. For example, in advertisement recommendation [ 27 ], there are sparse features such as category, brand, etc. In fraud detection [ 23 ], there are sparse features such as income level, region, etc.",
    "the deep sparse network ( DSN ) [ 9, 4 ] is a special type of deep networks. It targets learning from sparse and categorical features. Such a learning problem frequently appears in many industrial applications. For example, in advertisement recommendation [ 27 ], there are sparse features such as category, brand, etc. In fraud detection [ 23 ], there are sparse features such as income level, region, etc.",
    "the deep sparse network ( DSN ) [ 9, 4 ] is a special type of deep networks. It targets learning from sparse and categorical features. Such a learning problem frequently appears in many industrial applications. For example, in advertisement recommendation [ 27 ], there are sparse features such as category, brand, etc. In fraud detection [ 23 ], there are sparse features such as income level, region, etc.",
    "the deep sparse network ( DSN ) [ 9, 4 ] is a special type of deep networks. It targets learning from sparse and categorical features. Such a learning problem frequently appears in many industrial applications. For example, in advertisement recommendation [ 27 ], there are sparse features such as category, brand, etc. In fraud detection [ 23 ], there are sparse features such as income level, region, etc.",
    ". In this paper, we analyze regularization methods for fine-tuning from both theoretical and empirical perspectives. Based on the analysis, we propose a regularized self-labeling approach that improves the generalization and robustness properties of fine-tuning. In this paper, we analyze regularization methods for fine-tuning from both theoretical and empirical perspectives. This paper focuses on settings where there is no label noise in the target data set.",
    ". In this paper, we analyze regularization methods for fine-tuning from both theoretical and empirical perspectives. Based on the analysis, we propose a regularized self-labeling approach that improves the generalization and robustness properties of fine-tuning. In this paper, we analyze regularization methods for fine-tuning from both theoretical and empirical perspectives. This paper focuses on settings where there is no label noise in the target data set.",
    ". In this paper, we analyze regularization methods for fine-tuning from both theoretical and empirical perspectives. Based on the analysis, we propose a regularized self-labeling approach that improves the generalization and robustness properties of fine-tuning. In this paper, we analyze regularization methods for fine-tuning from both theoretical and empirical perspectives. This paper focuses on settings where there is no label noise in the target data set.",
    ". In this paper, we analyze regularization methods for fine-tuning from both theoretical and empirical perspectives. Based on the analysis, we propose a regularized self-labeling approach that improves the generalization and robustness properties of fine-tuning. In this paper, we analyze regularization methods for fine-tuning from both theoretical and empirical perspectives. This paper focuses on settings where there is no label noise in the target data set.",
    ". In this paper, we analyze regularization methods for fine-tuning from both theoretical and empirical perspectives. Based on the analysis, we propose a regularized self-labeling approach that improves the generalization and robustness properties of fine-tuning. In this paper, we analyze regularization methods for fine-tuning from both theoretical and empirical perspectives. This paper focuses on settings where there is no label noise in the target data set.",
    ". [ 44 ]. Tail risk is a common term used to quantify losses occurring due to rare events. Informally, for a probability measure , CVaR at level   is the conditional expectation of , conditioned on values beyond the VaR at level . As opposed to VaR, CVaR is a coherent risk-measure, and is preferable metric ( see, [ 50, 46 ] ).",
    ". [ 44 ]. Tail risk is a common term used to quantify losses occurring due to rare events. Informally, for a probability measure , CVaR at level   is the conditional expectation of , conditioned on values beyond the VaR at level . As opposed to VaR, CVaR is a coherent risk-measure, and is preferable metric ( see, [ 50, 46 ] ).",
    ". [ 44 ]. Tail risk is a common term used to quantify losses occurring due to rare events. Informally, for a probability measure , CVaR at level   is the conditional expectation of , conditioned on values beyond the VaR at level . As opposed to VaR, CVaR is a coherent risk-measure, and is preferable metric ( see, [ 50, 46 ] ).",
    ". [ 44 ]. Tail risk is a common term used to quantify losses occurring due to rare events. Informally, for a probability measure , CVaR at level   is the conditional expectation of , conditioned on values beyond the VaR at level . As opposed to VaR, CVaR is a coherent risk-measure, and is preferable metric ( see, [ 50, 46 ] ).",
    ". [ 44 ]. Tail risk is a common term used to quantify losses occurring due to rare events. Informally, for a probability measure , CVaR at level   is the conditional expectation of , conditioned on values beyond the VaR at level . As opposed to VaR, CVaR is a coherent risk-measure, and is preferable metric ( see, [ 50, 46 ] ).",
    "ViT [ 19 ] is the pioneering pure transformer model that embeds images into a sequence of visual tokens and models the global dependencies among them. Unlike vision transformers, Convolution Neural Networks ( CNNs ) naturally equip with intrinsic IBs of locality and scale-invariance. Moreover, CNNs have a hierarchy structure to extract multi-scale features at different layers. Moreover, CNNs have a hierarchy structure to extract multi-scale features at different",
    "ViT [ 19 ] is the pioneering pure transformer model that embeds images into a sequence of visual tokens and models the global dependencies among them. Unlike vision transformers, Convolution Neural Networks ( CNNs ) naturally equip with intrinsic IBs of locality and scale-invariance. Moreover, CNNs have a hierarchy structure to extract multi-scale features at different layers. Moreover, CNNs have a hierarchy structure to extract multi-scale features at different",
    "ViT [ 19 ] is the pioneering pure transformer model that embeds images into a sequence of visual tokens and models the global dependencies among them. Unlike vision transformers, Convolution Neural Networks ( CNNs ) naturally equip with intrinsic IBs of locality and scale-invariance. Moreover, CNNs have a hierarchy structure to extract multi-scale features at different layers. Moreover, CNNs have a hierarchy structure to extract multi-scale features at different",
    "ViT [ 19 ] is the pioneering pure transformer model that embeds images into a sequence of visual tokens and models the global dependencies among them. Unlike vision transformers, Convolution Neural Networks ( CNNs ) naturally equip with intrinsic IBs of locality and scale-invariance. Moreover, CNNs have a hierarchy structure to extract multi-scale features at different layers. Moreover, CNNs have a hierarchy structure to extract multi-scale features at different",
    "ViT [ 19 ] is the pioneering pure transformer model that embeds images into a sequence of visual tokens and models the global dependencies among them. Unlike vision transformers, Convolution Neural Networks ( CNNs ) naturally equip with intrinsic IBs of locality and scale-invariance. Moreover, CNNs have a hierarchy structure to extract multi-scale features at different layers. Moreover, CNNs have a hierarchy structure to extract multi-scale features at different",
    "adversarial defense aims at building robustness against adversarial examples. In contrast, adversarial fine-tuning may not directly fit the current NLP paradigm, the fine-tuning of pre-trained language models. First, adversarial fine-tuning suffers from catastrophic forgetting. Second, adversarial fine-tuning fails to memorize all the robust and generic. adversarial defense aims at building robustness against adversarial examples",
    "adversarial defense aims at building robustness against adversarial examples. In contrast, adversarial fine-tuning may not directly fit the current NLP paradigm, the fine-tuning of pre-trained language models. First, adversarial fine-tuning suffers from catastrophic forgetting. Second, adversarial fine-tuning fails to memorize all the robust and generic. adversarial defense aims at building robustness against adversarial examples",
    "adversarial defense aims at building robustness against adversarial examples. In contrast, adversarial fine-tuning may not directly fit the current NLP paradigm, the fine-tuning of pre-trained language models. First, adversarial fine-tuning suffers from catastrophic forgetting. Second, adversarial fine-tuning fails to memorize all the robust and generic. adversarial defense aims at building robustness against adversarial examples",
    "adversarial defense aims at building robustness against adversarial examples. In contrast, adversarial fine-tuning may not directly fit the current NLP paradigm, the fine-tuning of pre-trained language models. First, adversarial fine-tuning suffers from catastrophic forgetting. Second, adversarial fine-tuning fails to memorize all the robust and generic. adversarial defense aims at building robustness against adversarial examples",
    "adversarial defense aims at building robustness against adversarial examples. In contrast, adversarial fine-tuning may not directly fit the current NLP paradigm, the fine-tuning of pre-trained language models. First, adversarial fine-tuning suffers from catastrophic forgetting. Second, adversarial fine-tuning fails to memorize all the robust and generic. adversarial defense aims at building robustness against adversarial examples",
    "( 1 ) or ( 2 ) with rigorous theoretical analysis is a challenging task. Stochastic optimization is important in various areas such as statistics [ 15 ], machine learning [ 4, 54 ] and power systems [ 25 ]. In this paper, we consider the following stochastic optimization problem : min xRd f ( x ) = E [ F ( x ;  ), ( 1 ) where F : Rd",
    "( 1 ) or ( 2 ) with rigorous theoretical analysis is a challenging task. Stochastic optimization is important in various areas such as statistics [ 15 ], machine learning [ 4, 54 ] and power systems [ 25 ]. In this paper, we consider the following stochastic optimization problem : min xRd f ( x ) = E [ F ( x ;  ), ( 1 ) where F : Rd",
    "( 1 ) or ( 2 ) with rigorous theoretical analysis is a challenging task. Stochastic optimization is important in various areas such as statistics [ 15 ], machine learning [ 4, 54 ] and power systems [ 25 ]. In this paper, we consider the following stochastic optimization problem : min xRd f ( x ) = E [ F ( x ;  ), ( 1 ) where F : Rd",
    "( 1 ) or ( 2 ) with rigorous theoretical analysis is a challenging task. Stochastic optimization is important in various areas such as statistics [ 15 ], machine learning [ 4, 54 ] and power systems [ 25 ]. In this paper, we consider the following stochastic optimization problem : min xRd f ( x ) = E [ F ( x ;  ), ( 1 ) where F : Rd",
    "( 1 ) or ( 2 ) with rigorous theoretical analysis is a challenging task. Stochastic optimization is important in various areas such as statistics [ 15 ], machine learning [ 4, 54 ] and power systems [ 25 ]. In this paper, we consider the following stochastic optimization problem : min xRd f ( x ) = E [ F ( x ;  ), ( 1 ) where F : Rd",
    "a linear degradation operator H and a contaminating noise, being additive, white and Gaussian, z  N ( 0, 20I ). In this work, we aim to recover a signal x from its measurement y, given through a linear degradation operator H and a contaminating noise, being additive, white and Gaussian, z  N ( 0, 20I ). In",
    "a linear degradation operator H and a contaminating noise, being additive, white and Gaussian, z  N ( 0, 20I ). In this work, we aim to recover a signal x from its measurement y, given through a linear degradation operator H and a contaminating noise, being additive, white and Gaussian, z  N ( 0, 20I ). In",
    "a linear degradation operator H and a contaminating noise, being additive, white and Gaussian, z  N ( 0, 20I ). In this work, we aim to recover a signal x from its measurement y, given through a linear degradation operator H and a contaminating noise, being additive, white and Gaussian, z  N ( 0, 20I ). In",
    "a linear degradation operator H and a contaminating noise, being additive, white and Gaussian, z  N ( 0, 20I ). In this work, we aim to recover a signal x from its measurement y, given through a linear degradation operator H and a contaminating noise, being additive, white and Gaussian, z  N ( 0, 20I ). In",
    "a linear degradation operator H and a contaminating noise, being additive, white and Gaussian, z  N ( 0, 20I ). In this work, we aim to recover a signal x from its measurement y, given through a linear degradation operator H and a contaminating noise, being additive, white and Gaussian, z  N ( 0, 20I ). In",
    "the practice of illicit drug trade has never stopped but co-evolved with the advance of modern technologies. As the market of illicit drugs ( a.k.a. illicit drug trading ) is considerably lucrative, the crime of drug trafficking has never stopped but co-evolved with the advance of modern technologies. as the market of illicit drugs ( e.g., heroin, synthetic opioids such as Fentanyl ) is considerably lucrative, the crime of drug trafficking",
    "the practice of illicit drug trade has never stopped but co-evolved with the advance of modern technologies. As the market of illicit drugs ( a.k.a. illicit drug trading ) is considerably lucrative, the crime of drug trafficking has never stopped but co-evolved with the advance of modern technologies. as the market of illicit drugs ( e.g., heroin, synthetic opioids such as Fentanyl ) is considerably lucrative, the crime of drug trafficking",
    "the practice of illicit drug trade has never stopped but co-evolved with the advance of modern technologies. As the market of illicit drugs ( a.k.a. illicit drug trading ) is considerably lucrative, the crime of drug trafficking has never stopped but co-evolved with the advance of modern technologies. as the market of illicit drugs ( e.g., heroin, synthetic opioids such as Fentanyl ) is considerably lucrative, the crime of drug trafficking",
    "the practice of illicit drug trade has never stopped but co-evolved with the advance of modern technologies. As the market of illicit drugs ( a.k.a. illicit drug trading ) is considerably lucrative, the crime of drug trafficking has never stopped but co-evolved with the advance of modern technologies. as the market of illicit drugs ( e.g., heroin, synthetic opioids such as Fentanyl ) is considerably lucrative, the crime of drug trafficking",
    "the practice of illicit drug trade has never stopped but co-evolved with the advance of modern technologies. As the market of illicit drugs ( a.k.a. illicit drug trading ) is considerably lucrative, the crime of drug trafficking has never stopped but co-evolved with the advance of modern technologies. as the market of illicit drugs ( e.g., heroin, synthetic opioids such as Fentanyl ) is considerably lucrative, the crime of drug trafficking",
    "the \u201c bias \u201d decreases as the class of functions becomes more expressive. As one increases these parameters, the \u201c variance \u201d or \u201c complexity \u201d increases. In terms of the bias-variance trade-off, the \u201c bias \u201d decreases as the class of functions becomes more expressive. In terms of the bias-variance trade-off, the \u201c bias \u201d decreases as the class of functions becomes more expressive. In terms of the bias-variance trade-off, the \u201c",
    "the \u201c bias \u201d decreases as the class of functions becomes more expressive. As one increases these parameters, the \u201c variance \u201d or \u201c complexity \u201d increases. In terms of the bias-variance trade-off, the \u201c bias \u201d decreases as the class of functions becomes more expressive. In terms of the bias-variance trade-off, the \u201c bias \u201d decreases as the class of functions becomes more expressive. In terms of the bias-variance trade-off, the \u201c",
    "the \u201c bias \u201d decreases as the class of functions becomes more expressive. As one increases these parameters, the \u201c variance \u201d or \u201c complexity \u201d increases. In terms of the bias-variance trade-off, the \u201c bias \u201d decreases as the class of functions becomes more expressive. In terms of the bias-variance trade-off, the \u201c bias \u201d decreases as the class of functions becomes more expressive. In terms of the bias-variance trade-off, the \u201c",
    "the \u201c bias \u201d decreases as the class of functions becomes more expressive. As one increases these parameters, the \u201c variance \u201d or \u201c complexity \u201d increases. In terms of the bias-variance trade-off, the \u201c bias \u201d decreases as the class of functions becomes more expressive. In terms of the bias-variance trade-off, the \u201c bias \u201d decreases as the class of functions becomes more expressive. In terms of the bias-variance trade-off, the \u201c",
    "the \u201c bias \u201d decreases as the class of functions becomes more expressive. As one increases these parameters, the \u201c variance \u201d or \u201c complexity \u201d increases. In terms of the bias-variance trade-off, the \u201c bias \u201d decreases as the class of functions becomes more expressive. In terms of the bias-variance trade-off, the \u201c bias \u201d decreases as the class of functions becomes more expressive. In terms of the bias-variance trade-off, the \u201c",
    "based on a general formulation of min-max training ( AT ). The maximization step learns model weights under the adversarial loss constructed at the maximization step. Moreover, we show that many problem setups in adversarial attack can in fact be reformulated under this general min-max framework. In this paper, we give an affirmative answer corroborated by the substantial performance gain and the ability of self-learned risk interpretation using our proposed min-max formulation.",
    "based on a general formulation of min-max training ( AT ). The maximization step learns model weights under the adversarial loss constructed at the maximization step. Moreover, we show that many problem setups in adversarial attack can in fact be reformulated under this general min-max framework. In this paper, we give an affirmative answer corroborated by the substantial performance gain and the ability of self-learned risk interpretation using our proposed min-max formulation.",
    "based on a general formulation of min-max training ( AT ). The maximization step learns model weights under the adversarial loss constructed at the maximization step. Moreover, we show that many problem setups in adversarial attack can in fact be reformulated under this general min-max framework. In this paper, we give an affirmative answer corroborated by the substantial performance gain and the ability of self-learned risk interpretation using our proposed min-max formulation.",
    "based on a general formulation of min-max training ( AT ). The maximization step learns model weights under the adversarial loss constructed at the maximization step. Moreover, we show that many problem setups in adversarial attack can in fact be reformulated under this general min-max framework. In this paper, we give an affirmative answer corroborated by the substantial performance gain and the ability of self-learned risk interpretation using our proposed min-max formulation.",
    "based on a general formulation of min-max training ( AT ). The maximization step learns model weights under the adversarial loss constructed at the maximization step. Moreover, we show that many problem setups in adversarial attack can in fact be reformulated under this general min-max framework. In this paper, we give an affirmative answer corroborated by the substantial performance gain and the ability of self-learned risk interpretation using our proposed min-max formulation.",
    ". Finally, by analyzing the low-degree likelihood ratio, we complement these algorithmic results with rigorous evidence. 1 Introduction. Sparse tensor principal component analysis is a statistical primitive generalizing both sparse PCA2 and tensor PCA3. We are given multi-linear measurements in the form of a tensor Y = W + xp  pRn ( SSTM ) for a Gaussian",
    ". Finally, by analyzing the low-degree likelihood ratio, we complement these algorithmic results with rigorous evidence. 1 Introduction. Sparse tensor principal component analysis is a statistical primitive generalizing both sparse PCA2 and tensor PCA3. We are given multi-linear measurements in the form of a tensor Y = W + xp  pRn ( SSTM ) for a Gaussian",
    ". Finally, by analyzing the low-degree likelihood ratio, we complement these algorithmic results with rigorous evidence. 1 Introduction. Sparse tensor principal component analysis is a statistical primitive generalizing both sparse PCA2 and tensor PCA3. We are given multi-linear measurements in the form of a tensor Y = W + xp  pRn ( SSTM ) for a Gaussian",
    ". Finally, by analyzing the low-degree likelihood ratio, we complement these algorithmic results with rigorous evidence. 1 Introduction. Sparse tensor principal component analysis is a statistical primitive generalizing both sparse PCA2 and tensor PCA3. We are given multi-linear measurements in the form of a tensor Y = W + xp  pRn ( SSTM ) for a Gaussian",
    ". Finally, by analyzing the low-degree likelihood ratio, we complement these algorithmic results with rigorous evidence. 1 Introduction. Sparse tensor principal component analysis is a statistical primitive generalizing both sparse PCA2 and tensor PCA3. We are given multi-linear measurements in the form of a tensor Y = W + xp  pRn ( SSTM ) for a Gaussian",
    ". Signals with high frequencies have recently emerged as a powerful representation paradigm for modeling complex signals. In this paper, we use the term \u201c positional encodings \u201d in lower case letters to denote the family of encoding methods that map coordinates to a higher dimensional space. In particular, they present compelling arguments for the use of these sinusoidal encodings in obtaining high quality signal reconstructions.",
    ". Signals with high frequencies have recently emerged as a powerful representation paradigm for modeling complex signals. In this paper, we use the term \u201c positional encodings \u201d in lower case letters to denote the family of encoding methods that map coordinates to a higher dimensional space. In particular, they present compelling arguments for the use of these sinusoidal encodings in obtaining high quality signal reconstructions.",
    ". Signals with high frequencies have recently emerged as a powerful representation paradigm for modeling complex signals. In this paper, we use the term \u201c positional encodings \u201d in lower case letters to denote the family of encoding methods that map coordinates to a higher dimensional space. In particular, they present compelling arguments for the use of these sinusoidal encodings in obtaining high quality signal reconstructions.",
    ". Signals with high frequencies have recently emerged as a powerful representation paradigm for modeling complex signals. In this paper, we use the term \u201c positional encodings \u201d in lower case letters to denote the family of encoding methods that map coordinates to a higher dimensional space. In particular, they present compelling arguments for the use of these sinusoidal encodings in obtaining high quality signal reconstructions.",
    ". Signals with high frequencies have recently emerged as a powerful representation paradigm for modeling complex signals. In this paper, we use the term \u201c positional encodings \u201d in lower case letters to denote the family of encoding methods that map coordinates to a higher dimensional space. In particular, they present compelling arguments for the use of these sinusoidal encodings in obtaining high quality signal reconstructions.",
    "the equilibrium policies of both players, which are often unavailable due to privacy constraints. 1.1 Last-iterate convergence in competitive games. In recent years, there have been significant advances in understanding the last-iterate convergence of simple iterative algorithms for unconstrained saddle-point optimization. This shift of focus is motivated, for example, by the ergodic iterate \u2014 which is the average of all the iterations \u2014 that are commonly studied in the earlier literature.",
    "the equilibrium policies of both players, which are often unavailable due to privacy constraints. 1.1 Last-iterate convergence in competitive games. In recent years, there have been significant advances in understanding the last-iterate convergence of simple iterative algorithms for unconstrained saddle-point optimization. This shift of focus is motivated, for example, by the ergodic iterate \u2014 which is the average of all the iterations \u2014 that are commonly studied in the earlier literature.",
    "the equilibrium policies of both players, which are often unavailable due to privacy constraints. 1.1 Last-iterate convergence in competitive games. In recent years, there have been significant advances in understanding the last-iterate convergence of simple iterative algorithms for unconstrained saddle-point optimization. This shift of focus is motivated, for example, by the ergodic iterate \u2014 which is the average of all the iterations \u2014 that are commonly studied in the earlier literature.",
    "the equilibrium policies of both players, which are often unavailable due to privacy constraints. 1.1 Last-iterate convergence in competitive games. In recent years, there have been significant advances in understanding the last-iterate convergence of simple iterative algorithms for unconstrained saddle-point optimization. This shift of focus is motivated, for example, by the ergodic iterate \u2014 which is the average of all the iterations \u2014 that are commonly studied in the earlier literature.",
    "the equilibrium policies of both players, which are often unavailable due to privacy constraints. 1.1 Last-iterate convergence in competitive games. In recent years, there have been significant advances in understanding the last-iterate convergence of simple iterative algorithms for unconstrained saddle-point optimization. This shift of focus is motivated, for example, by the ergodic iterate \u2014 which is the average of all the iterations \u2014 that are commonly studied in the earlier literature.",
    ". In contrast, the natural scene images are dominated by the contents generated or rendered by computers. In contrast, the natural scene images are relatively smooth. However, conventional image SR methods are designed for discrete ( i.e., several fixed ) magnification ratios. In addition, they utilize previous frames to help reconstruct the current frame. In addition, they utilize previous frames to help reconstruct the current frame. In addition, they utilize previous frames to help reconstruct the",
    ". In contrast, the natural scene images are dominated by the contents generated or rendered by computers. In contrast, the natural scene images are relatively smooth. However, conventional image SR methods are designed for discrete ( i.e., several fixed ) magnification ratios. In addition, they utilize previous frames to help reconstruct the current frame. In addition, they utilize previous frames to help reconstruct the current frame. In addition, they utilize previous frames to help reconstruct the",
    ". In contrast, the natural scene images are dominated by the contents generated or rendered by computers. In contrast, the natural scene images are relatively smooth. However, conventional image SR methods are designed for discrete ( i.e., several fixed ) magnification ratios. In addition, they utilize previous frames to help reconstruct the current frame. In addition, they utilize previous frames to help reconstruct the current frame. In addition, they utilize previous frames to help reconstruct the",
    ". In contrast, the natural scene images are dominated by the contents generated or rendered by computers. In contrast, the natural scene images are relatively smooth. However, conventional image SR methods are designed for discrete ( i.e., several fixed ) magnification ratios. In addition, they utilize previous frames to help reconstruct the current frame. In addition, they utilize previous frames to help reconstruct the current frame. In addition, they utilize previous frames to help reconstruct the",
    ". In contrast, the natural scene images are dominated by the contents generated or rendered by computers. In contrast, the natural scene images are relatively smooth. However, conventional image SR methods are designed for discrete ( i.e., several fixed ) magnification ratios. In addition, they utilize previous frames to help reconstruct the current frame. In addition, they utilize previous frames to help reconstruct the current frame. In addition, they utilize previous frames to help reconstruct the",
    ", 2018 ]. Identifying causal relationships between variables in observational data is one of the fundamental and well-studied problems in machine learning. While successful, classical probabilistic models are difficult to scale. Recently, tractable probabilistic models such as probabilistic sentential decision diagrams [ Poon and Domingos, 2011 ] have emerged. Zhao et al. [ 2015 ] showed how to compile back and forth between sum-product networks [ Poon and Doming",
    ", 2018 ]. Identifying causal relationships between variables in observational data is one of the fundamental and well-studied problems in machine learning. While successful, classical probabilistic models are difficult to scale. Recently, tractable probabilistic models such as probabilistic sentential decision diagrams [ Poon and Domingos, 2011 ] have emerged. Zhao et al. [ 2015 ] showed how to compile back and forth between sum-product networks [ Poon and Doming",
    ", 2018 ]. Identifying causal relationships between variables in observational data is one of the fundamental and well-studied problems in machine learning. While successful, classical probabilistic models are difficult to scale. Recently, tractable probabilistic models such as probabilistic sentential decision diagrams [ Poon and Domingos, 2011 ] have emerged. Zhao et al. [ 2015 ] showed how to compile back and forth between sum-product networks [ Poon and Doming",
    ", 2018 ]. Identifying causal relationships between variables in observational data is one of the fundamental and well-studied problems in machine learning. While successful, classical probabilistic models are difficult to scale. Recently, tractable probabilistic models such as probabilistic sentential decision diagrams [ Poon and Domingos, 2011 ] have emerged. Zhao et al. [ 2015 ] showed how to compile back and forth between sum-product networks [ Poon and Doming",
    ", 2018 ]. Identifying causal relationships between variables in observational data is one of the fundamental and well-studied problems in machine learning. While successful, classical probabilistic models are difficult to scale. Recently, tractable probabilistic models such as probabilistic sentential decision diagrams [ Poon and Domingos, 2011 ] have emerged. Zhao et al. [ 2015 ] showed how to compile back and forth between sum-product networks [ Poon and Doming",
    ". Moreover, averaging across many voxels could wash out signals from non-activated voxels with noise from non-activated voxels. Thus, averaging across many voxels could wash out signals from small number of task-relevant voxels with noise from non-activated voxels. Thus, averaging across many voxels could wash out signals from small number of task-relevant voxels with noise from non",
    ". Moreover, averaging across many voxels could wash out signals from non-activated voxels with noise from non-activated voxels. Thus, averaging across many voxels could wash out signals from small number of task-relevant voxels with noise from non-activated voxels. Thus, averaging across many voxels could wash out signals from small number of task-relevant voxels with noise from non",
    ". Moreover, averaging across many voxels could wash out signals from non-activated voxels with noise from non-activated voxels. Thus, averaging across many voxels could wash out signals from small number of task-relevant voxels with noise from non-activated voxels. Thus, averaging across many voxels could wash out signals from small number of task-relevant voxels with noise from non",
    ". Moreover, averaging across many voxels could wash out signals from non-activated voxels with noise from non-activated voxels. Thus, averaging across many voxels could wash out signals from small number of task-relevant voxels with noise from non-activated voxels. Thus, averaging across many voxels could wash out signals from small number of task-relevant voxels with noise from non",
    ". Moreover, averaging across many voxels could wash out signals from non-activated voxels with noise from non-activated voxels. Thus, averaging across many voxels could wash out signals from small number of task-relevant voxels with noise from non-activated voxels. Thus, averaging across many voxels could wash out signals from small number of task-relevant voxels with noise from non",
    ". However, existing generative models can not be effectively applied in these domains. For example, generative models can be extended for generative modeling over Riemannian manifolds. CNFs have the advantage that the neural 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). CNFs have the advantage that the neural 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). CNFs have the advantage that the neural 35th",
    ". However, existing generative models can not be effectively applied in these domains. For example, generative models can be extended for generative modeling over Riemannian manifolds. CNFs have the advantage that the neural 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). CNFs have the advantage that the neural 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). CNFs have the advantage that the neural 35th",
    ". However, existing generative models can not be effectively applied in these domains. For example, generative models can be extended for generative modeling over Riemannian manifolds. CNFs have the advantage that the neural 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). CNFs have the advantage that the neural 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). CNFs have the advantage that the neural 35th",
    ". However, existing generative models can not be effectively applied in these domains. For example, generative models can be extended for generative modeling over Riemannian manifolds. CNFs have the advantage that the neural 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). CNFs have the advantage that the neural 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). CNFs have the advantage that the neural 35th",
    ". However, existing generative models can not be effectively applied in these domains. For example, generative models can be extended for generative modeling over Riemannian manifolds. CNFs have the advantage that the neural 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). CNFs have the advantage that the neural 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). CNFs have the advantage that the neural 35th",
    "identifiability [ 55 ] formalises this desideratum [ 17, 40 ]. In the present work, we investigate a different route to identifiability. We draw inspiration from the field of causal inference [ 71, 78 ], which has provided useful insights for a number of machine learning tasks. To this end, we investigate a different route to identifiability by drawing inspiration from the field of causal inference.",
    "identifiability [ 55 ] formalises this desideratum [ 17, 40 ]. In the present work, we investigate a different route to identifiability. We draw inspiration from the field of causal inference [ 71, 78 ], which has provided useful insights for a number of machine learning tasks. To this end, we investigate a different route to identifiability by drawing inspiration from the field of causal inference.",
    "identifiability [ 55 ] formalises this desideratum [ 17, 40 ]. In the present work, we investigate a different route to identifiability. We draw inspiration from the field of causal inference [ 71, 78 ], which has provided useful insights for a number of machine learning tasks. To this end, we investigate a different route to identifiability by drawing inspiration from the field of causal inference.",
    "identifiability [ 55 ] formalises this desideratum [ 17, 40 ]. In the present work, we investigate a different route to identifiability. We draw inspiration from the field of causal inference [ 71, 78 ], which has provided useful insights for a number of machine learning tasks. To this end, we investigate a different route to identifiability by drawing inspiration from the field of causal inference.",
    "identifiability [ 55 ] formalises this desideratum [ 17, 40 ]. In the present work, we investigate a different route to identifiability. We draw inspiration from the field of causal inference [ 71, 78 ], which has provided useful insights for a number of machine learning tasks. To this end, we investigate a different route to identifiability by drawing inspiration from the field of causal inference.",
    "logZ.. our method yields better performances than other competing approaches. Our method leads to tight and differentiable lower bounds on logZ.......aled Importance Sampling ( AIS ) with Hamiltonian MCMC is powerful....   .. .",
    "logZ.. our method yields better performances than other competing approaches. Our method leads to tight and differentiable lower bounds on logZ.......aled Importance Sampling ( AIS ) with Hamiltonian MCMC is powerful....   .. .",
    "logZ.. our method yields better performances than other competing approaches. Our method leads to tight and differentiable lower bounds on logZ.......aled Importance Sampling ( AIS ) with Hamiltonian MCMC is powerful....   .. .",
    "logZ.. our method yields better performances than other competing approaches. Our method leads to tight and differentiable lower bounds on logZ.......aled Importance Sampling ( AIS ) with Hamiltonian MCMC is powerful....   .. .",
    "logZ.. our method yields better performances than other competing approaches. Our method leads to tight and differentiable lower bounds on logZ.......aled Importance Sampling ( AIS ) with Hamiltonian MCMC is powerful....   .. .",
    ". In contrast, certified defenses give formal robustness guarantees. Bounding the global Lipschitz constant of a neural network is a computationally efficient and scalable approach to provide certifiable robustness guarantees. However, many existing certified defense methods have achieved success by using a training-based approach with a relatively weak but efficient bound.",
    ". In contrast, certified defenses give formal robustness guarantees. Bounding the global Lipschitz constant of a neural network is a computationally efficient and scalable approach to provide certifiable robustness guarantees. However, many existing certified defense methods have achieved success by using a training-based approach with a relatively weak but efficient bound.",
    ". In contrast, certified defenses give formal robustness guarantees. Bounding the global Lipschitz constant of a neural network is a computationally efficient and scalable approach to provide certifiable robustness guarantees. However, many existing certified defense methods have achieved success by using a training-based approach with a relatively weak but efficient bound.",
    ". In contrast, certified defenses give formal robustness guarantees. Bounding the global Lipschitz constant of a neural network is a computationally efficient and scalable approach to provide certifiable robustness guarantees. However, many existing certified defense methods have achieved success by using a training-based approach with a relatively weak but efficient bound.",
    ". In contrast, certified defenses give formal robustness guarantees. Bounding the global Lipschitz constant of a neural network is a computationally efficient and scalable approach to provide certifiable robustness guarantees. However, many existing certified defense methods have achieved success by using a training-based approach with a relatively weak but efficient bound.",
    "(  | Z1 : n ) d, ( 1 ) where  (  | Z1 : n ) is the Bayesian posterior. Alternatively, one can construct the highest density 100 ( 1 ) % posterior predictive credible intervals. Alternatively, the central 100 ( 1 ) % posterior predictive credible intervals can be computed using the /2 and 1 /2 quantiles.",
    "(  | Z1 : n ) d, ( 1 ) where  (  | Z1 : n ) is the Bayesian posterior. Alternatively, one can construct the highest density 100 ( 1 ) % posterior predictive credible intervals. Alternatively, the central 100 ( 1 ) % posterior predictive credible intervals can be computed using the /2 and 1 /2 quantiles.",
    "(  | Z1 : n ) d, ( 1 ) where  (  | Z1 : n ) is the Bayesian posterior. Alternatively, one can construct the highest density 100 ( 1 ) % posterior predictive credible intervals. Alternatively, the central 100 ( 1 ) % posterior predictive credible intervals can be computed using the /2 and 1 /2 quantiles.",
    "(  | Z1 : n ) d, ( 1 ) where  (  | Z1 : n ) is the Bayesian posterior. Alternatively, one can construct the highest density 100 ( 1 ) % posterior predictive credible intervals. Alternatively, the central 100 ( 1 ) % posterior predictive credible intervals can be computed using the /2 and 1 /2 quantiles.",
    "(  | Z1 : n ) d, ( 1 ) where  (  | Z1 : n ) is the Bayesian posterior. Alternatively, one can construct the highest density 100 ( 1 ) % posterior predictive credible intervals. Alternatively, the central 100 ( 1 ) % posterior predictive credible intervals can be computed using the /2 and 1 /2 quantiles.",
    ". General Recovery Inverse problems aim to recover an unknown signal from its observed corrupted or compressed version. This task requires the incorporation of additional knowledge of the desired 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). General Recovery Inverse problems aim to recover an unknown signal from its observed corrupted or compressed version. RED and PnP RED and PnP RED and PnP RED and PnP RED and PnP RED and Pn",
    ". General Recovery Inverse problems aim to recover an unknown signal from its observed corrupted or compressed version. This task requires the incorporation of additional knowledge of the desired 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). General Recovery Inverse problems aim to recover an unknown signal from its observed corrupted or compressed version. RED and PnP RED and PnP RED and PnP RED and PnP RED and PnP RED and Pn",
    ". General Recovery Inverse problems aim to recover an unknown signal from its observed corrupted or compressed version. This task requires the incorporation of additional knowledge of the desired 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). General Recovery Inverse problems aim to recover an unknown signal from its observed corrupted or compressed version. RED and PnP RED and PnP RED and PnP RED and PnP RED and PnP RED and Pn",
    ". General Recovery Inverse problems aim to recover an unknown signal from its observed corrupted or compressed version. This task requires the incorporation of additional knowledge of the desired 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). General Recovery Inverse problems aim to recover an unknown signal from its observed corrupted or compressed version. RED and PnP RED and PnP RED and PnP RED and PnP RED and PnP RED and Pn",
    ". General Recovery Inverse problems aim to recover an unknown signal from its observed corrupted or compressed version. This task requires the incorporation of additional knowledge of the desired 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). General Recovery Inverse problems aim to recover an unknown signal from its observed corrupted or compressed version. RED and PnP RED and PnP RED and PnP RED and PnP RED and PnP RED and Pn",
    ". When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues such as semantic association of events. When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues. When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues. In this work, we explore automatic generation of rhythmic music correlated with human body movements.",
    ". When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues such as semantic association of events. When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues. When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues. In this work, we explore automatic generation of rhythmic music correlated with human body movements.",
    ". When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues such as semantic association of events. When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues. When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues. In this work, we explore automatic generation of rhythmic music correlated with human body movements.",
    ". When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues such as semantic association of events. When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues. When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues. In this work, we explore automatic generation of rhythmic music correlated with human body movements.",
    ". When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues such as semantic association of events. When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues. When sounds accompany visual scenes, they enhance the perception of the scene by complementing it with additional cues. In this work, we explore automatic generation of rhythmic music correlated with human body movements.",
    "in this paper, we challenge the dominant paradigm in the deep offline RL literature that relies heavily on actor-critic style algorithms. all these algorithms rely heavily on off-policy evaluation to learn the critic. instead, a simple baseline which only performs one step of policy improvement using the behavior Q function often outperforms the more complicated iterative algorithms.",
    "in this paper, we challenge the dominant paradigm in the deep offline RL literature that relies heavily on actor-critic style algorithms. all these algorithms rely heavily on off-policy evaluation to learn the critic. instead, a simple baseline which only performs one step of policy improvement using the behavior Q function often outperforms the more complicated iterative algorithms.",
    "in this paper, we challenge the dominant paradigm in the deep offline RL literature that relies heavily on actor-critic style algorithms. all these algorithms rely heavily on off-policy evaluation to learn the critic. instead, a simple baseline which only performs one step of policy improvement using the behavior Q function often outperforms the more complicated iterative algorithms.",
    "in this paper, we challenge the dominant paradigm in the deep offline RL literature that relies heavily on actor-critic style algorithms. all these algorithms rely heavily on off-policy evaluation to learn the critic. instead, a simple baseline which only performs one step of policy improvement using the behavior Q function often outperforms the more complicated iterative algorithms.",
    "in this paper, we challenge the dominant paradigm in the deep offline RL literature that relies heavily on actor-critic style algorithms. all these algorithms rely heavily on off-policy evaluation to learn the critic. instead, a simple baseline which only performs one step of policy improvement using the behavior Q function often outperforms the more complicated iterative algorithms.",
    "nonsmooth matrix optimization problems have many important applications in statistics, machine learning, and related fields. For many of these problems, convex relaxations, in which one replaces the nonconvex low-rank constraint with a trace-norm constraint, have been demonstrated in numerous papers. In this paper, we present a nonsmooth optimization problem ( 1 ), where min XSn g ( X ), ( 1",
    "nonsmooth matrix optimization problems have many important applications in statistics, machine learning, and related fields. For many of these problems, convex relaxations, in which one replaces the nonconvex low-rank constraint with a trace-norm constraint, have been demonstrated in numerous papers. In this paper, we present a nonsmooth optimization problem ( 1 ), where min XSn g ( X ), ( 1",
    "nonsmooth matrix optimization problems have many important applications in statistics, machine learning, and related fields. For many of these problems, convex relaxations, in which one replaces the nonconvex low-rank constraint with a trace-norm constraint, have been demonstrated in numerous papers. In this paper, we present a nonsmooth optimization problem ( 1 ), where min XSn g ( X ), ( 1",
    "nonsmooth matrix optimization problems have many important applications in statistics, machine learning, and related fields. For many of these problems, convex relaxations, in which one replaces the nonconvex low-rank constraint with a trace-norm constraint, have been demonstrated in numerous papers. In this paper, we present a nonsmooth optimization problem ( 1 ), where min XSn g ( X ), ( 1",
    "nonsmooth matrix optimization problems have many important applications in statistics, machine learning, and related fields. For many of these problems, convex relaxations, in which one replaces the nonconvex low-rank constraint with a trace-norm constraint, have been demonstrated in numerous papers. In this paper, we present a nonsmooth optimization problem ( 1 ), where min XSn g ( X ), ( 1",
    "( ii ) capacity to work with many treatments, and ( iii ) generalizing to unseen treatments during test time. In many cases, treatments are naturally structured. For instance, a drug is commonly represented by its molecular structure ( graph ), the nutritional content of a meal as a food label ( text ), and geographic regions affected by a new policy as a map ( image ). To estimate CATEs with structured interventions",
    "( ii ) capacity to work with many treatments, and ( iii ) generalizing to unseen treatments during test time. In many cases, treatments are naturally structured. For instance, a drug is commonly represented by its molecular structure ( graph ), the nutritional content of a meal as a food label ( text ), and geographic regions affected by a new policy as a map ( image ). To estimate CATEs with structured interventions",
    "( ii ) capacity to work with many treatments, and ( iii ) generalizing to unseen treatments during test time. In many cases, treatments are naturally structured. For instance, a drug is commonly represented by its molecular structure ( graph ), the nutritional content of a meal as a food label ( text ), and geographic regions affected by a new policy as a map ( image ). To estimate CATEs with structured interventions",
    "( ii ) capacity to work with many treatments, and ( iii ) generalizing to unseen treatments during test time. In many cases, treatments are naturally structured. For instance, a drug is commonly represented by its molecular structure ( graph ), the nutritional content of a meal as a food label ( text ), and geographic regions affected by a new policy as a map ( image ). To estimate CATEs with structured interventions",
    "( ii ) capacity to work with many treatments, and ( iii ) generalizing to unseen treatments during test time. In many cases, treatments are naturally structured. For instance, a drug is commonly represented by its molecular structure ( graph ), the nutritional content of a meal as a food label ( text ), and geographic regions affected by a new policy as a map ( image ). To estimate CATEs with structured interventions",
    ".. There are different lines of investigation that aims to establish the quantity Px ( y ) ( i ). For instance, Pearl \u2019 s celebrated method known as do-calculus provides a symbolic way of determining whether the quantity Px ( y ) ( i ) can be uniquely computable from observational data. For instance, Pearl \u2019 s celebrated method known as do-calculus provides a symbolic way of determining whether",
    ".. There are different lines of investigation that aims to establish the quantity Px ( y ) ( i ). For instance, Pearl \u2019 s celebrated method known as do-calculus provides a symbolic way of determining whether the quantity Px ( y ) ( i ) can be uniquely computable from observational data. For instance, Pearl \u2019 s celebrated method known as do-calculus provides a symbolic way of determining whether",
    ".. There are different lines of investigation that aims to establish the quantity Px ( y ) ( i ). For instance, Pearl \u2019 s celebrated method known as do-calculus provides a symbolic way of determining whether the quantity Px ( y ) ( i ) can be uniquely computable from observational data. For instance, Pearl \u2019 s celebrated method known as do-calculus provides a symbolic way of determining whether",
    ".. There are different lines of investigation that aims to establish the quantity Px ( y ) ( i ). For instance, Pearl \u2019 s celebrated method known as do-calculus provides a symbolic way of determining whether the quantity Px ( y ) ( i ) can be uniquely computable from observational data. For instance, Pearl \u2019 s celebrated method known as do-calculus provides a symbolic way of determining whether",
    ".. There are different lines of investigation that aims to establish the quantity Px ( y ) ( i ). For instance, Pearl \u2019 s celebrated method known as do-calculus provides a symbolic way of determining whether the quantity Px ( y ) ( i ) can be uniquely computable from observational data. For instance, Pearl \u2019 s celebrated method known as do-calculus provides a symbolic way of determining whether",
    "[ 8 ]. The second method, Protagonist Antagonist Induced Regret Environment Design ( PAIRED ) [ 10, 17 ]. introduces a self-supervised RL paradigm called Unsupervised Environment Design ( UED ). Here, an environment generator ( a teacher ) is co-evolved with a student policy that trains on levels actively proposed by the teacher. The goal is for the teacher to gradually learn to generate environments that exemp",
    "[ 8 ]. The second method, Protagonist Antagonist Induced Regret Environment Design ( PAIRED ) [ 10, 17 ]. introduces a self-supervised RL paradigm called Unsupervised Environment Design ( UED ). Here, an environment generator ( a teacher ) is co-evolved with a student policy that trains on levels actively proposed by the teacher. The goal is for the teacher to gradually learn to generate environments that exemp",
    "[ 8 ]. The second method, Protagonist Antagonist Induced Regret Environment Design ( PAIRED ) [ 10, 17 ]. introduces a self-supervised RL paradigm called Unsupervised Environment Design ( UED ). Here, an environment generator ( a teacher ) is co-evolved with a student policy that trains on levels actively proposed by the teacher. The goal is for the teacher to gradually learn to generate environments that exemp",
    "[ 8 ]. The second method, Protagonist Antagonist Induced Regret Environment Design ( PAIRED ) [ 10, 17 ]. introduces a self-supervised RL paradigm called Unsupervised Environment Design ( UED ). Here, an environment generator ( a teacher ) is co-evolved with a student policy that trains on levels actively proposed by the teacher. The goal is for the teacher to gradually learn to generate environments that exemp",
    "[ 8 ]. The second method, Protagonist Antagonist Induced Regret Environment Design ( PAIRED ) [ 10, 17 ]. introduces a self-supervised RL paradigm called Unsupervised Environment Design ( UED ). Here, an environment generator ( a teacher ) is co-evolved with a student policy that trains on levels actively proposed by the teacher. The goal is for the teacher to gradually learn to generate environments that exemp",
    "our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the local model. Our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the centralized model.",
    "our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the local model. Our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the centralized model.",
    "our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the local model. Our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the centralized model.",
    "our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the local model. Our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the centralized model.",
    "our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the local model. Our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the centralized model. Our upper bound almost matches the regret of the best known algorithms for the centralized model.",
    "decision loss \u2013 the loss incurred under a decision rule based on the predictions \u2013 summarizes the consequences of these decisions. Probabilistic forecasts ( probabilistic forecasts ) can be used to estimate decision loss prior to deployment. In this work, we consider the regression setup, where a forecast is represented by a cumulative distribution function over the possible outcomes. if the forecasted probabilities of 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). incorrect decisions match",
    "decision loss \u2013 the loss incurred under a decision rule based on the predictions \u2013 summarizes the consequences of these decisions. Probabilistic forecasts ( probabilistic forecasts ) can be used to estimate decision loss prior to deployment. In this work, we consider the regression setup, where a forecast is represented by a cumulative distribution function over the possible outcomes. if the forecasted probabilities of 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). incorrect decisions match",
    "decision loss \u2013 the loss incurred under a decision rule based on the predictions \u2013 summarizes the consequences of these decisions. Probabilistic forecasts ( probabilistic forecasts ) can be used to estimate decision loss prior to deployment. In this work, we consider the regression setup, where a forecast is represented by a cumulative distribution function over the possible outcomes. if the forecasted probabilities of 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). incorrect decisions match",
    "decision loss \u2013 the loss incurred under a decision rule based on the predictions \u2013 summarizes the consequences of these decisions. Probabilistic forecasts ( probabilistic forecasts ) can be used to estimate decision loss prior to deployment. In this work, we consider the regression setup, where a forecast is represented by a cumulative distribution function over the possible outcomes. if the forecasted probabilities of 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). incorrect decisions match",
    "decision loss \u2013 the loss incurred under a decision rule based on the predictions \u2013 summarizes the consequences of these decisions. Probabilistic forecasts ( probabilistic forecasts ) can be used to estimate decision loss prior to deployment. In this work, we consider the regression setup, where a forecast is represented by a cumulative distribution function over the possible outcomes. if the forecasted probabilities of 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). incorrect decisions match",
    "a random function f (  ) where  is a variable of interest. In particular, we want to find a set of \u201c centroid points \u201d  i  ni=1, whose empirical measure is close to  in terms of Wasserstein distance. In particular, we want to find a set of \u201c centroid points \u201d  =  i  ni=1, whose empirical measure is",
    "a random function f (  ) where  is a variable of interest. In particular, we want to find a set of \u201c centroid points \u201d  i  ni=1, whose empirical measure is close to  in terms of Wasserstein distance. In particular, we want to find a set of \u201c centroid points \u201d  =  i  ni=1, whose empirical measure is",
    "a random function f (  ) where  is a variable of interest. In particular, we want to find a set of \u201c centroid points \u201d  i  ni=1, whose empirical measure is close to  in terms of Wasserstein distance. In particular, we want to find a set of \u201c centroid points \u201d  =  i  ni=1, whose empirical measure is",
    "a random function f (  ) where  is a variable of interest. In particular, we want to find a set of \u201c centroid points \u201d  i  ni=1, whose empirical measure is close to  in terms of Wasserstein distance. In particular, we want to find a set of \u201c centroid points \u201d  =  i  ni=1, whose empirical measure is",
    "a random function f (  ) where  is a variable of interest. In particular, we want to find a set of \u201c centroid points \u201d  i  ni=1, whose empirical measure is close to  in terms of Wasserstein distance. In particular, we want to find a set of \u201c centroid points \u201d  =  i  ni=1, whose empirical measure is",
    "d is the number of objectives, S is the number of states, A is the number of actions, H is the length of the horizon, and K is the number of episodes. Furthermore, our proposed algorithm is provably efficient with a nearly optimal trajectory complexity  ( min  d, S  H3SA/ 2 ). This result partly resolves an open problem raised by Jin et al. [ 2020 ].",
    "d is the number of objectives, S is the number of states, A is the number of actions, H is the length of the horizon, and K is the number of episodes. Furthermore, our proposed algorithm is provably efficient with a nearly optimal trajectory complexity  ( min  d, S  H3SA/ 2 ). This result partly resolves an open problem raised by Jin et al. [ 2020 ].",
    "d is the number of objectives, S is the number of states, A is the number of actions, H is the length of the horizon, and K is the number of episodes. Furthermore, our proposed algorithm is provably efficient with a nearly optimal trajectory complexity  ( min  d, S  H3SA/ 2 ). This result partly resolves an open problem raised by Jin et al. [ 2020 ].",
    "d is the number of objectives, S is the number of states, A is the number of actions, H is the length of the horizon, and K is the number of episodes. Furthermore, our proposed algorithm is provably efficient with a nearly optimal trajectory complexity  ( min  d, S  H3SA/ 2 ). This result partly resolves an open problem raised by Jin et al. [ 2020 ].",
    "d is the number of objectives, S is the number of states, A is the number of actions, H is the length of the horizon, and K is the number of episodes. Furthermore, our proposed algorithm is provably efficient with a nearly optimal trajectory complexity  ( min  d, S  H3SA/ 2 ). This result partly resolves an open problem raised by Jin et al. [ 2020 ].",
    "local explanations. Local explanations are a sub-field of explainable artificial intelligence ( XAI ) [ 2, 17, 36 ]. These methods have the advantage of being model-agnostic and locally interpretable. In this paper, we study explanations over a set of representative conditional text generation models \u2013 dialogue response generation models [ 45, 55 ]. These models typically aim to produce an engaging and informative [ 3, 24 ] response to an input",
    "local explanations. Local explanations are a sub-field of explainable artificial intelligence ( XAI ) [ 2, 17, 36 ]. These methods have the advantage of being model-agnostic and locally interpretable. In this paper, we study explanations over a set of representative conditional text generation models \u2013 dialogue response generation models [ 45, 55 ]. These models typically aim to produce an engaging and informative [ 3, 24 ] response to an input",
    "local explanations. Local explanations are a sub-field of explainable artificial intelligence ( XAI ) [ 2, 17, 36 ]. These methods have the advantage of being model-agnostic and locally interpretable. In this paper, we study explanations over a set of representative conditional text generation models \u2013 dialogue response generation models [ 45, 55 ]. These models typically aim to produce an engaging and informative [ 3, 24 ] response to an input",
    "local explanations. Local explanations are a sub-field of explainable artificial intelligence ( XAI ) [ 2, 17, 36 ]. These methods have the advantage of being model-agnostic and locally interpretable. In this paper, we study explanations over a set of representative conditional text generation models \u2013 dialogue response generation models [ 45, 55 ]. These models typically aim to produce an engaging and informative [ 3, 24 ] response to an input",
    "local explanations. Local explanations are a sub-field of explainable artificial intelligence ( XAI ) [ 2, 17, 36 ]. These methods have the advantage of being model-agnostic and locally interpretable. In this paper, we study explanations over a set of representative conditional text generation models \u2013 dialogue response generation models [ 45, 55 ]. These models typically aim to produce an engaging and informative [ 3, 24 ] response to an input",
    "] and communication compression ( e.g., quantization and sparsification ) ( see also recent surveys. Communication compression. In this work, we focus on the last of these techniques : communication compression. The key idea here is to apply a lossy compression transformation/operator to the messages before they are communicated. While compression reduces the communicated bits in each communication round, it introduces errors. While compression reduces the communicated bits in each communication round,",
    "] and communication compression ( e.g., quantization and sparsification ) ( see also recent surveys. Communication compression. In this work, we focus on the last of these techniques : communication compression. The key idea here is to apply a lossy compression transformation/operator to the messages before they are communicated. While compression reduces the communicated bits in each communication round, it introduces errors. While compression reduces the communicated bits in each communication round,",
    "] and communication compression ( e.g., quantization and sparsification ) ( see also recent surveys. Communication compression. In this work, we focus on the last of these techniques : communication compression. The key idea here is to apply a lossy compression transformation/operator to the messages before they are communicated. While compression reduces the communicated bits in each communication round, it introduces errors. While compression reduces the communicated bits in each communication round,",
    "] and communication compression ( e.g., quantization and sparsification ) ( see also recent surveys. Communication compression. In this work, we focus on the last of these techniques : communication compression. The key idea here is to apply a lossy compression transformation/operator to the messages before they are communicated. While compression reduces the communicated bits in each communication round, it introduces errors. While compression reduces the communicated bits in each communication round,",
    "] and communication compression ( e.g., quantization and sparsification ) ( see also recent surveys. Communication compression. In this work, we focus on the last of these techniques : communication compression. The key idea here is to apply a lossy compression transformation/operator to the messages before they are communicated. While compression reduces the communicated bits in each communication round, it introduces errors. While compression reduces the communicated bits in each communication round,",
    "....... a branching process [ 25, 28 ].........................................",
    "....... a branching process [ 25, 28 ].........................................",
    "....... a branching process [ 25, 28 ].........................................",
    "....... a branching process [ 25, 28 ].........................................",
    "....... a branching process [ 25, 28 ].........................................",
    "TINL explores the imbalance caused by the asymmetric and uneven topology of labeled nodes. The asymmetric topology of labeled nodes in different categories decays with the topology distance. TINL is a graph-specific imbalance learning topic, which mainly focus on the graph-structured data. The code is available at https : //github.com/victorchen96/ReNode. 35th Conference on Neural Information Processing Systems ( NeurIPS",
    "TINL explores the imbalance caused by the asymmetric and uneven topology of labeled nodes. The asymmetric topology of labeled nodes in different categories decays with the topology distance. TINL is a graph-specific imbalance learning topic, which mainly focus on the graph-structured data. The code is available at https : //github.com/victorchen96/ReNode. 35th Conference on Neural Information Processing Systems ( NeurIPS",
    "TINL explores the imbalance caused by the asymmetric and uneven topology of labeled nodes. The asymmetric topology of labeled nodes in different categories decays with the topology distance. TINL is a graph-specific imbalance learning topic, which mainly focus on the graph-structured data. The code is available at https : //github.com/victorchen96/ReNode. 35th Conference on Neural Information Processing Systems ( NeurIPS",
    "TINL explores the imbalance caused by the asymmetric and uneven topology of labeled nodes. The asymmetric topology of labeled nodes in different categories decays with the topology distance. TINL is a graph-specific imbalance learning topic, which mainly focus on the graph-structured data. The code is available at https : //github.com/victorchen96/ReNode. 35th Conference on Neural Information Processing Systems ( NeurIPS",
    "TINL explores the imbalance caused by the asymmetric and uneven topology of labeled nodes. The asymmetric topology of labeled nodes in different categories decays with the topology distance. TINL is a graph-specific imbalance learning topic, which mainly focus on the graph-structured data. The code is available at https : //github.com/victorchen96/ReNode. 35th Conference on Neural Information Processing Systems ( NeurIPS",
    "i + i, ( 1 ).   i + i, ( 1 )..... Rl   Ld, n....    .  . are., ],. .",
    "i + i, ( 1 ).   i + i, ( 1 )..... Rl   Ld, n....    .  . are., ],. .",
    "i + i, ( 1 ).   i + i, ( 1 )..... Rl   Ld, n....    .  . are., ],. .",
    "i + i, ( 1 ).   i + i, ( 1 )..... Rl   Ld, n....    .  . are., ],. .",
    "i + i, ( 1 ).   i + i, ( 1 )..... Rl   Ld, n....    .  . are., ],. .",
    ". In image captioning, a phenomenon called object hallucination is observed where models tend to include nonexistent objects in a caption based on their common association with other objects. Deep neural networks have been tremendously successful across a variety of tasks and domains in recent years. However, it is usually impractical to identify and disentangle all of the potential sources of spurious correlations. Various training algorithms have been proposed to reduce the influence of spurious correlations by learning the underlying",
    ". In image captioning, a phenomenon called object hallucination is observed where models tend to include nonexistent objects in a caption based on their common association with other objects. Deep neural networks have been tremendously successful across a variety of tasks and domains in recent years. However, it is usually impractical to identify and disentangle all of the potential sources of spurious correlations. Various training algorithms have been proposed to reduce the influence of spurious correlations by learning the underlying",
    ". In image captioning, a phenomenon called object hallucination is observed where models tend to include nonexistent objects in a caption based on their common association with other objects. Deep neural networks have been tremendously successful across a variety of tasks and domains in recent years. However, it is usually impractical to identify and disentangle all of the potential sources of spurious correlations. Various training algorithms have been proposed to reduce the influence of spurious correlations by learning the underlying",
    ". In image captioning, a phenomenon called object hallucination is observed where models tend to include nonexistent objects in a caption based on their common association with other objects. Deep neural networks have been tremendously successful across a variety of tasks and domains in recent years. However, it is usually impractical to identify and disentangle all of the potential sources of spurious correlations. Various training algorithms have been proposed to reduce the influence of spurious correlations by learning the underlying",
    ". In image captioning, a phenomenon called object hallucination is observed where models tend to include nonexistent objects in a caption based on their common association with other objects. Deep neural networks have been tremendously successful across a variety of tasks and domains in recent years. However, it is usually impractical to identify and disentangle all of the potential sources of spurious correlations. Various training algorithms have been proposed to reduce the influence of spurious correlations by learning the underlying",
    "multi-task learning ( MTL ) refers to learning a single model that can tackle multiple different tasks simultaneously. However, existing work often lacks convergence guarantees or only provably converges to any point on the Pareto set of objectives. As a result, it is possible that these methods over-optimize one objective while overlooking the others ( See Fig. 1 ).",
    "multi-task learning ( MTL ) refers to learning a single model that can tackle multiple different tasks simultaneously. However, existing work often lacks convergence guarantees or only provably converges to any point on the Pareto set of objectives. As a result, it is possible that these methods over-optimize one objective while overlooking the others ( See Fig. 1 ).",
    "multi-task learning ( MTL ) refers to learning a single model that can tackle multiple different tasks simultaneously. However, existing work often lacks convergence guarantees or only provably converges to any point on the Pareto set of objectives. As a result, it is possible that these methods over-optimize one objective while overlooking the others ( See Fig. 1 ).",
    "multi-task learning ( MTL ) refers to learning a single model that can tackle multiple different tasks simultaneously. However, existing work often lacks convergence guarantees or only provably converges to any point on the Pareto set of objectives. As a result, it is possible that these methods over-optimize one objective while overlooking the others ( See Fig. 1 ).",
    "multi-task learning ( MTL ) refers to learning a single model that can tackle multiple different tasks simultaneously. However, existing work often lacks convergence guarantees or only provably converges to any point on the Pareto set of objectives. As a result, it is possible that these methods over-optimize one objective while overlooking the others ( See Fig. 1 ).",
    ". The former depends on an abstract pattern intrinsic to the sequence ( a simple algorithmic sequence alternating \u201c on \u201d and \u201c off \u201d ), while the latter depends on an abstract pattern extrinsic to the sequence ( common use in the English language because of a popular song ). However, it is only recently, with systems such as BERT ( Devlin et al., 2018 ), GPT-3 ( Brown et al.,",
    ". The former depends on an abstract pattern intrinsic to the sequence ( a simple algorithmic sequence alternating \u201c on \u201d and \u201c off \u201d ), while the latter depends on an abstract pattern extrinsic to the sequence ( common use in the English language because of a popular song ). However, it is only recently, with systems such as BERT ( Devlin et al., 2018 ), GPT-3 ( Brown et al.,",
    ". The former depends on an abstract pattern intrinsic to the sequence ( a simple algorithmic sequence alternating \u201c on \u201d and \u201c off \u201d ), while the latter depends on an abstract pattern extrinsic to the sequence ( common use in the English language because of a popular song ). However, it is only recently, with systems such as BERT ( Devlin et al., 2018 ), GPT-3 ( Brown et al.,",
    ". The former depends on an abstract pattern intrinsic to the sequence ( a simple algorithmic sequence alternating \u201c on \u201d and \u201c off \u201d ), while the latter depends on an abstract pattern extrinsic to the sequence ( common use in the English language because of a popular song ). However, it is only recently, with systems such as BERT ( Devlin et al., 2018 ), GPT-3 ( Brown et al.,",
    ". The former depends on an abstract pattern intrinsic to the sequence ( a simple algorithmic sequence alternating \u201c on \u201d and \u201c off \u201d ), while the latter depends on an abstract pattern extrinsic to the sequence ( common use in the English language because of a popular song ). However, it is only recently, with systems such as BERT ( Devlin et al., 2018 ), GPT-3 ( Brown et al.,",
    "adversarial examples are inevitable results of standard supervised training. In recent years, Tsipras et al. [ 14 ] have suggested an intriguing analysis that the disagreement between standard and adversarial accuracy stems from differently trained feature representation. In this literature, Ilyas et al. [ 16 ] have demonstrated the adversarial examples are originated from brittle and unintelligible features that are arbitrarily manipulated with imperceptible noise.",
    "adversarial examples are inevitable results of standard supervised training. In recent years, Tsipras et al. [ 14 ] have suggested an intriguing analysis that the disagreement between standard and adversarial accuracy stems from differently trained feature representation. In this literature, Ilyas et al. [ 16 ] have demonstrated the adversarial examples are originated from brittle and unintelligible features that are arbitrarily manipulated with imperceptible noise.",
    "adversarial examples are inevitable results of standard supervised training. In recent years, Tsipras et al. [ 14 ] have suggested an intriguing analysis that the disagreement between standard and adversarial accuracy stems from differently trained feature representation. In this literature, Ilyas et al. [ 16 ] have demonstrated the adversarial examples are originated from brittle and unintelligible features that are arbitrarily manipulated with imperceptible noise.",
    "adversarial examples are inevitable results of standard supervised training. In recent years, Tsipras et al. [ 14 ] have suggested an intriguing analysis that the disagreement between standard and adversarial accuracy stems from differently trained feature representation. In this literature, Ilyas et al. [ 16 ] have demonstrated the adversarial examples are originated from brittle and unintelligible features that are arbitrarily manipulated with imperceptible noise.",
    "adversarial examples are inevitable results of standard supervised training. In recent years, Tsipras et al. [ 14 ] have suggested an intriguing analysis that the disagreement between standard and adversarial accuracy stems from differently trained feature representation. In this literature, Ilyas et al. [ 16 ] have demonstrated the adversarial examples are originated from brittle and unintelligible features that are arbitrarily manipulated with imperceptible noise.",
    "the training data ( x1, y1 ),..., ( xn, yn )  Rd   1  are linearly separable. In this paper, we consider the case in which the models return exactly the same hypothesis for sufficiently high-dimensional data. wOLS is the solution to the following optimization problem : wOLS = argminwRd w",
    "the training data ( x1, y1 ),..., ( xn, yn )  Rd   1  are linearly separable. In this paper, we consider the case in which the models return exactly the same hypothesis for sufficiently high-dimensional data. wOLS is the solution to the following optimization problem : wOLS = argminwRd w",
    "the training data ( x1, y1 ),..., ( xn, yn )  Rd   1  are linearly separable. In this paper, we consider the case in which the models return exactly the same hypothesis for sufficiently high-dimensional data. wOLS is the solution to the following optimization problem : wOLS = argminwRd w",
    "the training data ( x1, y1 ),..., ( xn, yn )  Rd   1  are linearly separable. In this paper, we consider the case in which the models return exactly the same hypothesis for sufficiently high-dimensional data. wOLS is the solution to the following optimization problem : wOLS = argminwRd w",
    "the training data ( x1, y1 ),..., ( xn, yn )  Rd   1  are linearly separable. In this paper, we consider the case in which the models return exactly the same hypothesis for sufficiently high-dimensional data. wOLS is the solution to the following optimization problem : wOLS = argminwRd w",
    ".. the best policy identification ( BPI ) problem for infinite-horizon discounted MDPs. This framework was introduced by [ Fie94 ] under the name PAC-RL. In this work, we are interested in the best policy identification ( BPI ) problem for infinite-horizon discounted MDPs. This framework was introduced by [ Fie94 ] under the name PAC-RL. In this work, we are interested in the best policy identification ( BPI",
    ".. the best policy identification ( BPI ) problem for infinite-horizon discounted MDPs. This framework was introduced by [ Fie94 ] under the name PAC-RL. In this work, we are interested in the best policy identification ( BPI ) problem for infinite-horizon discounted MDPs. This framework was introduced by [ Fie94 ] under the name PAC-RL. In this work, we are interested in the best policy identification ( BPI",
    ".. the best policy identification ( BPI ) problem for infinite-horizon discounted MDPs. This framework was introduced by [ Fie94 ] under the name PAC-RL. In this work, we are interested in the best policy identification ( BPI ) problem for infinite-horizon discounted MDPs. This framework was introduced by [ Fie94 ] under the name PAC-RL. In this work, we are interested in the best policy identification ( BPI",
    ".. the best policy identification ( BPI ) problem for infinite-horizon discounted MDPs. This framework was introduced by [ Fie94 ] under the name PAC-RL. In this work, we are interested in the best policy identification ( BPI ) problem for infinite-horizon discounted MDPs. This framework was introduced by [ Fie94 ] under the name PAC-RL. In this work, we are interested in the best policy identification ( BPI",
    ".. the best policy identification ( BPI ) problem for infinite-horizon discounted MDPs. This framework was introduced by [ Fie94 ] under the name PAC-RL. In this work, we are interested in the best policy identification ( BPI ) problem for infinite-horizon discounted MDPs. This framework was introduced by [ Fie94 ] under the name PAC-RL. In this work, we are interested in the best policy identification ( BPI",
    ". First, when some links are missing in KGs, it has difficulties in identifying the correct answers. Second, when some links are missing in KGs, it has difficulties in identifying the correct answers. To address these challenges, researchers have paid increasing attention to the query embedding ( QE ) technique, which embeds entities and FOL queries in low-dimensional spaces. For example, Query2Box [ 22 ] represents entity sets as  regions",
    ". First, when some links are missing in KGs, it has difficulties in identifying the correct answers. Second, when some links are missing in KGs, it has difficulties in identifying the correct answers. To address these challenges, researchers have paid increasing attention to the query embedding ( QE ) technique, which embeds entities and FOL queries in low-dimensional spaces. For example, Query2Box [ 22 ] represents entity sets as  regions",
    ". First, when some links are missing in KGs, it has difficulties in identifying the correct answers. Second, when some links are missing in KGs, it has difficulties in identifying the correct answers. To address these challenges, researchers have paid increasing attention to the query embedding ( QE ) technique, which embeds entities and FOL queries in low-dimensional spaces. For example, Query2Box [ 22 ] represents entity sets as  regions",
    ". First, when some links are missing in KGs, it has difficulties in identifying the correct answers. Second, when some links are missing in KGs, it has difficulties in identifying the correct answers. To address these challenges, researchers have paid increasing attention to the query embedding ( QE ) technique, which embeds entities and FOL queries in low-dimensional spaces. For example, Query2Box [ 22 ] represents entity sets as  regions",
    ". First, when some links are missing in KGs, it has difficulties in identifying the correct answers. Second, when some links are missing in KGs, it has difficulties in identifying the correct answers. To address these challenges, researchers have paid increasing attention to the query embedding ( QE ) technique, which embeds entities and FOL queries in low-dimensional spaces. For example, Query2Box [ 22 ] represents entity sets as  regions",
    "EJ ( xt+1 )",
    "EJ ( xt+1 )",
    "EJ ( xt+1 )",
    "EJ ( xt+1 )",
    "EJ ( xt+1 )",
    ".. [ 23, 70, 71 ]. [ 9, 5 ]......... [ 53, 51 ]....... [ 25 ]. [ 22 ]. This work delivered a compelling message that \u201c. .",
    ".. [ 23, 70, 71 ]. [ 9, 5 ]......... [ 53, 51 ]....... [ 25 ]. [ 22 ]. This work delivered a compelling message that \u201c. .",
    ".. [ 23, 70, 71 ]. [ 9, 5 ]......... [ 53, 51 ]....... [ 25 ]. [ 22 ]. This work delivered a compelling message that \u201c. .",
    ".. [ 23, 70, 71 ]. [ 9, 5 ]......... [ 53, 51 ]....... [ 25 ]. [ 22 ]. This work delivered a compelling message that \u201c. .",
    ".. [ 23, 70, 71 ]. [ 9, 5 ]......... [ 53, 51 ]....... [ 25 ]. [ 22 ]. This work delivered a compelling message that \u201c. .",
    "n is the input sequence length, which makes the approximation error of each method infeasible. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources.",
    "n is the input sequence length, which makes the approximation error of each method infeasible. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources.",
    "n is the input sequence length, which makes the approximation error of each method infeasible. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources.",
    "n is the input sequence length, which makes the approximation error of each method infeasible. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources.",
    "n is the input sequence length, which makes the approximation error of each method infeasible. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources. Moreover, Transformers can not support long sequence processing and large batch size with limited resources.",
    "high-DoF behavior from an expert to a student policy.16 1 Introduction1 We present a simple, yet powerful data-augmentation technique to enable data-1 efficient learning from parametric experts. Whereas behavioral cloning refers to learning from samples of an expert, we focus here on what we refer to as the policy4 cloning setting. This setting arises naturally in a number of control and reinforcement learning settings. We also show that our method increases data-efficiency of policy",
    "high-DoF behavior from an expert to a student policy.16 1 Introduction1 We present a simple, yet powerful data-augmentation technique to enable data-1 efficient learning from parametric experts. Whereas behavioral cloning refers to learning from samples of an expert, we focus here on what we refer to as the policy4 cloning setting. This setting arises naturally in a number of control and reinforcement learning settings. We also show that our method increases data-efficiency of policy",
    "high-DoF behavior from an expert to a student policy.16 1 Introduction1 We present a simple, yet powerful data-augmentation technique to enable data-1 efficient learning from parametric experts. Whereas behavioral cloning refers to learning from samples of an expert, we focus here on what we refer to as the policy4 cloning setting. This setting arises naturally in a number of control and reinforcement learning settings. We also show that our method increases data-efficiency of policy",
    "high-DoF behavior from an expert to a student policy.16 1 Introduction1 We present a simple, yet powerful data-augmentation technique to enable data-1 efficient learning from parametric experts. Whereas behavioral cloning refers to learning from samples of an expert, we focus here on what we refer to as the policy4 cloning setting. This setting arises naturally in a number of control and reinforcement learning settings. We also show that our method increases data-efficiency of policy",
    "high-DoF behavior from an expert to a student policy.16 1 Introduction1 We present a simple, yet powerful data-augmentation technique to enable data-1 efficient learning from parametric experts. Whereas behavioral cloning refers to learning from samples of an expert, we focus here on what we refer to as the policy4 cloning setting. This setting arises naturally in a number of control and reinforcement learning settings. We also show that our method increases data-efficiency of policy",
    ". In particular, when an adversary is allowed to modify inputs, standard vision models can be manipulated into predicting arbitrary outputs. In particular, we propose a new approach to image recognition in the face of unforeseen corruptions or distribution shifts. This approach is rooted in a reconsideration of the problem setup itself. In particular, it allows us to turn the input-sensitivity of modern vision systems from a weakness into a strength.",
    ". In particular, when an adversary is allowed to modify inputs, standard vision models can be manipulated into predicting arbitrary outputs. In particular, we propose a new approach to image recognition in the face of unforeseen corruptions or distribution shifts. This approach is rooted in a reconsideration of the problem setup itself. In particular, it allows us to turn the input-sensitivity of modern vision systems from a weakness into a strength.",
    ". In particular, when an adversary is allowed to modify inputs, standard vision models can be manipulated into predicting arbitrary outputs. In particular, we propose a new approach to image recognition in the face of unforeseen corruptions or distribution shifts. This approach is rooted in a reconsideration of the problem setup itself. In particular, it allows us to turn the input-sensitivity of modern vision systems from a weakness into a strength.",
    ". In particular, when an adversary is allowed to modify inputs, standard vision models can be manipulated into predicting arbitrary outputs. In particular, we propose a new approach to image recognition in the face of unforeseen corruptions or distribution shifts. This approach is rooted in a reconsideration of the problem setup itself. In particular, it allows us to turn the input-sensitivity of modern vision systems from a weakness into a strength.",
    ". In particular, when an adversary is allowed to modify inputs, standard vision models can be manipulated into predicting arbitrary outputs. In particular, we propose a new approach to image recognition in the face of unforeseen corruptions or distribution shifts. This approach is rooted in a reconsideration of the problem setup itself. In particular, it allows us to turn the input-sensitivity of modern vision systems from a weakness into a strength.",
    ". Moreover, data augmentation can reduce sample efficiency and divergence. In this paper, we illuminate causes of instability when applying data augmentation to common off-policy RL algorithms. Based on our findings, we propose SVEA : Stabilized Q-Value Estimation under Use of Strong Data augmentation. Website and code is available at : https : //nicklashansen.github.io/SVEA. 35th Conference",
    ". Moreover, data augmentation can reduce sample efficiency and divergence. In this paper, we illuminate causes of instability when applying data augmentation to common off-policy RL algorithms. Based on our findings, we propose SVEA : Stabilized Q-Value Estimation under Use of Strong Data augmentation. Website and code is available at : https : //nicklashansen.github.io/SVEA. 35th Conference",
    ". Moreover, data augmentation can reduce sample efficiency and divergence. In this paper, we illuminate causes of instability when applying data augmentation to common off-policy RL algorithms. Based on our findings, we propose SVEA : Stabilized Q-Value Estimation under Use of Strong Data augmentation. Website and code is available at : https : //nicklashansen.github.io/SVEA. 35th Conference",
    ". Moreover, data augmentation can reduce sample efficiency and divergence. In this paper, we illuminate causes of instability when applying data augmentation to common off-policy RL algorithms. Based on our findings, we propose SVEA : Stabilized Q-Value Estimation under Use of Strong Data augmentation. Website and code is available at : https : //nicklashansen.github.io/SVEA. 35th Conference",
    ". Moreover, data augmentation can reduce sample efficiency and divergence. In this paper, we illuminate causes of instability when applying data augmentation to common off-policy RL algorithms. Based on our findings, we propose SVEA : Stabilized Q-Value Estimation under Use of Strong Data augmentation. Website and code is available at : https : //nicklashansen.github.io/SVEA. 35th Conference",
    "referred to as the heterogeneous data setting. f ( k ) ( x ) = 1 K KX k=1 E ( k ) D ( k ) [ f ( k ) ( x ) : = 1 K KX k=1 E ( k ) D ( k ) [ f ( k ) ( x ;  ( k ) )",
    "referred to as the heterogeneous data setting. f ( k ) ( x ) = 1 K KX k=1 E ( k ) D ( k ) [ f ( k ) ( x ) : = 1 K KX k=1 E ( k ) D ( k ) [ f ( k ) ( x ;  ( k ) )",
    "referred to as the heterogeneous data setting. f ( k ) ( x ) = 1 K KX k=1 E ( k ) D ( k ) [ f ( k ) ( x ) : = 1 K KX k=1 E ( k ) D ( k ) [ f ( k ) ( x ;  ( k ) )",
    "referred to as the heterogeneous data setting. f ( k ) ( x ) = 1 K KX k=1 E ( k ) D ( k ) [ f ( k ) ( x ) : = 1 K KX k=1 E ( k ) D ( k ) [ f ( k ) ( x ;  ( k ) )",
    "referred to as the heterogeneous data setting. f ( k ) ( x ) = 1 K KX k=1 E ( k ) D ( k ) [ f ( k ) ( x ) : = 1 K KX k=1 E ( k ) D ( k ) [ f ( k ) ( x ;  ( k ) )",
    "Corresponding Author 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). This framework can perform a step-wise analysis of Stochastic Gradient Langevin Dynamics ( SGLD ) [ 33, 29 ]. However, the test accuracy of SGLD with isotropic noise has a considerable gap compared to that of the widely-used Stochastic Gradient Descent ( SGD ) [ 40 ].",
    "Corresponding Author 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). This framework can perform a step-wise analysis of Stochastic Gradient Langevin Dynamics ( SGLD ) [ 33, 29 ]. However, the test accuracy of SGLD with isotropic noise has a considerable gap compared to that of the widely-used Stochastic Gradient Descent ( SGD ) [ 40 ].",
    "Corresponding Author 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). This framework can perform a step-wise analysis of Stochastic Gradient Langevin Dynamics ( SGLD ) [ 33, 29 ]. However, the test accuracy of SGLD with isotropic noise has a considerable gap compared to that of the widely-used Stochastic Gradient Descent ( SGD ) [ 40 ].",
    "Corresponding Author 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). This framework can perform a step-wise analysis of Stochastic Gradient Langevin Dynamics ( SGLD ) [ 33, 29 ]. However, the test accuracy of SGLD with isotropic noise has a considerable gap compared to that of the widely-used Stochastic Gradient Descent ( SGD ) [ 40 ].",
    "Corresponding Author 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). This framework can perform a step-wise analysis of Stochastic Gradient Langevin Dynamics ( SGLD ) [ 33, 29 ]. However, the test accuracy of SGLD with isotropic noise has a considerable gap compared to that of the widely-used Stochastic Gradient Descent ( SGD ) [ 40 ].",
    "multi-reference-frame predic-12 tion. We show that the flow prediction module can largely13 reduce the transmission cost of voxel flows. In this paper, we propose a versatile learned video compression ( VLVC ) framework that uses one model to support all possible prediction modes. We show that our proposed VLVC not only supports versatile compression in various settings but also achieves comparable R-D performance with the latest video coding standard in terms of MS-SSIM.",
    "multi-reference-frame predic-12 tion. We show that the flow prediction module can largely13 reduce the transmission cost of voxel flows. In this paper, we propose a versatile learned video compression ( VLVC ) framework that uses one model to support all possible prediction modes. We show that our proposed VLVC not only supports versatile compression in various settings but also achieves comparable R-D performance with the latest video coding standard in terms of MS-SSIM.",
    "multi-reference-frame predic-12 tion. We show that the flow prediction module can largely13 reduce the transmission cost of voxel flows. In this paper, we propose a versatile learned video compression ( VLVC ) framework that uses one model to support all possible prediction modes. We show that our proposed VLVC not only supports versatile compression in various settings but also achieves comparable R-D performance with the latest video coding standard in terms of MS-SSIM.",
    "multi-reference-frame predic-12 tion. We show that the flow prediction module can largely13 reduce the transmission cost of voxel flows. In this paper, we propose a versatile learned video compression ( VLVC ) framework that uses one model to support all possible prediction modes. We show that our proposed VLVC not only supports versatile compression in various settings but also achieves comparable R-D performance with the latest video coding standard in terms of MS-SSIM.",
    "multi-reference-frame predic-12 tion. We show that the flow prediction module can largely13 reduce the transmission cost of voxel flows. In this paper, we propose a versatile learned video compression ( VLVC ) framework that uses one model to support all possible prediction modes. We show that our proposed VLVC not only supports versatile compression in various settings but also achieves comparable R-D performance with the latest video coding standard in terms of MS-SSIM.",
    ". Finally, we provide numerical experiments on several real-world datasets which support our theoretical findings. In this work, we introduce and analyze MT-OMD, a multitask generalization of Online Mirror1 Descent ( OMD ) which operates by sharing updates between tasks. We prove that the regret of MT-OMD is of order  1 + 2 ( N  1 )  T. Finally, we provide numerical experiments on several real-world datasets",
    ". Finally, we provide numerical experiments on several real-world datasets which support our theoretical findings. In this work, we introduce and analyze MT-OMD, a multitask generalization of Online Mirror1 Descent ( OMD ) which operates by sharing updates between tasks. We prove that the regret of MT-OMD is of order  1 + 2 ( N  1 )  T. Finally, we provide numerical experiments on several real-world datasets",
    ". Finally, we provide numerical experiments on several real-world datasets which support our theoretical findings. In this work, we introduce and analyze MT-OMD, a multitask generalization of Online Mirror1 Descent ( OMD ) which operates by sharing updates between tasks. We prove that the regret of MT-OMD is of order  1 + 2 ( N  1 )  T. Finally, we provide numerical experiments on several real-world datasets",
    ". Finally, we provide numerical experiments on several real-world datasets which support our theoretical findings. In this work, we introduce and analyze MT-OMD, a multitask generalization of Online Mirror1 Descent ( OMD ) which operates by sharing updates between tasks. We prove that the regret of MT-OMD is of order  1 + 2 ( N  1 )  T. Finally, we provide numerical experiments on several real-world datasets",
    ". Finally, we provide numerical experiments on several real-world datasets which support our theoretical findings. In this work, we introduce and analyze MT-OMD, a multitask generalization of Online Mirror1 Descent ( OMD ) which operates by sharing updates between tasks. We prove that the regret of MT-OMD is of order  1 + 2 ( N  1 )  T. Finally, we provide numerical experiments on several real-world datasets",
    ". In particular, we apply our method to sample the strongly-log-concave distribution and obtain gradient complexity better than all existing gradient based sampling algorithms. Moreover, we prove a lower bound of gradient complexity as  ( N + d 1 3N 2 3 / 2 3 ) for approximating d-dimensional ULD. In particular, we apply our method to sample the stronglylog-concave distribution and obtain gradient complexity better than all existing gradient based sampling",
    ". In particular, we apply our method to sample the strongly-log-concave distribution and obtain gradient complexity better than all existing gradient based sampling algorithms. Moreover, we prove a lower bound of gradient complexity as  ( N + d 1 3N 2 3 / 2 3 ) for approximating d-dimensional ULD. In particular, we apply our method to sample the stronglylog-concave distribution and obtain gradient complexity better than all existing gradient based sampling",
    ". In particular, we apply our method to sample the strongly-log-concave distribution and obtain gradient complexity better than all existing gradient based sampling algorithms. Moreover, we prove a lower bound of gradient complexity as  ( N + d 1 3N 2 3 / 2 3 ) for approximating d-dimensional ULD. In particular, we apply our method to sample the stronglylog-concave distribution and obtain gradient complexity better than all existing gradient based sampling",
    ". In particular, we apply our method to sample the strongly-log-concave distribution and obtain gradient complexity better than all existing gradient based sampling algorithms. Moreover, we prove a lower bound of gradient complexity as  ( N + d 1 3N 2 3 / 2 3 ) for approximating d-dimensional ULD. In particular, we apply our method to sample the stronglylog-concave distribution and obtain gradient complexity better than all existing gradient based sampling",
    ". In particular, we apply our method to sample the strongly-log-concave distribution and obtain gradient complexity better than all existing gradient based sampling algorithms. Moreover, we prove a lower bound of gradient complexity as  ( N + d 1 3N 2 3 / 2 3 ) for approximating d-dimensional ULD. In particular, we apply our method to sample the stronglylog-concave distribution and obtain gradient complexity better than all existing gradient based sampling",
    "based on trust region optimization. This leads to improved performance compared to existing methods. This is consistent with experimental findings that neural dynamics often occupy orthogonal subspaces across contexts in biological circuits. In this work, we address these shortcomings by developing a continual learning algorithm that not only encourages good performance across tasks at convergence but also regularizes the optimization path itself. This is consistent with experimental findings that neural dynamics often occupy orthogonal subspaces across contexts in biological circuits",
    "based on trust region optimization. This leads to improved performance compared to existing methods. This is consistent with experimental findings that neural dynamics often occupy orthogonal subspaces across contexts in biological circuits. In this work, we address these shortcomings by developing a continual learning algorithm that not only encourages good performance across tasks at convergence but also regularizes the optimization path itself. This is consistent with experimental findings that neural dynamics often occupy orthogonal subspaces across contexts in biological circuits",
    "based on trust region optimization. This leads to improved performance compared to existing methods. This is consistent with experimental findings that neural dynamics often occupy orthogonal subspaces across contexts in biological circuits. In this work, we address these shortcomings by developing a continual learning algorithm that not only encourages good performance across tasks at convergence but also regularizes the optimization path itself. This is consistent with experimental findings that neural dynamics often occupy orthogonal subspaces across contexts in biological circuits",
    "based on trust region optimization. This leads to improved performance compared to existing methods. This is consistent with experimental findings that neural dynamics often occupy orthogonal subspaces across contexts in biological circuits. In this work, we address these shortcomings by developing a continual learning algorithm that not only encourages good performance across tasks at convergence but also regularizes the optimization path itself. This is consistent with experimental findings that neural dynamics often occupy orthogonal subspaces across contexts in biological circuits",
    "based on trust region optimization. This leads to improved performance compared to existing methods. This is consistent with experimental findings that neural dynamics often occupy orthogonal subspaces across contexts in biological circuits. In this work, we address these shortcomings by developing a continual learning algorithm that not only encourages good performance across tasks at convergence but also regularizes the optimization path itself. This is consistent with experimental findings that neural dynamics often occupy orthogonal subspaces across contexts in biological circuits",
    ". In recent years, NFs have become a staple of generative modelling. In particular, the resulting distribution has support homeomorphic to RD. This is not a realistic assumption in practice, as it directly contradicts the manifold hypothesis [ 6 ]. Authors contributed equally. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Authors contributed equally. Authors contributed equally",
    ". In recent years, NFs have become a staple of generative modelling. In particular, the resulting distribution has support homeomorphic to RD. This is not a realistic assumption in practice, as it directly contradicts the manifold hypothesis [ 6 ]. Authors contributed equally. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Authors contributed equally. Authors contributed equally",
    ". In recent years, NFs have become a staple of generative modelling. In particular, the resulting distribution has support homeomorphic to RD. This is not a realistic assumption in practice, as it directly contradicts the manifold hypothesis [ 6 ]. Authors contributed equally. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Authors contributed equally. Authors contributed equally",
    ". In recent years, NFs have become a staple of generative modelling. In particular, the resulting distribution has support homeomorphic to RD. This is not a realistic assumption in practice, as it directly contradicts the manifold hypothesis [ 6 ]. Authors contributed equally. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Authors contributed equally. Authors contributed equally",
    ". In recent years, NFs have become a staple of generative modelling. In particular, the resulting distribution has support homeomorphic to RD. This is not a realistic assumption in practice, as it directly contradicts the manifold hypothesis [ 6 ]. Authors contributed equally. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ). Authors contributed equally. Authors contributed equally",
    ". For one, the inference speed in hierarchically organized neural networks decreases with depth. In turn, this induces timing mismatches between instructive signals and neural activity. In turn, this disrupts learning. To deal with this inherent property of physical dynamical systems, two approaches have been suggested : either phased plasticity that is active only following a certain relaxation period, or long stimulus presentation times with small learning rates.",
    ". For one, the inference speed in hierarchically organized neural networks decreases with depth. In turn, this induces timing mismatches between instructive signals and neural activity. In turn, this disrupts learning. To deal with this inherent property of physical dynamical systems, two approaches have been suggested : either phased plasticity that is active only following a certain relaxation period, or long stimulus presentation times with small learning rates.",
    ". For one, the inference speed in hierarchically organized neural networks decreases with depth. In turn, this induces timing mismatches between instructive signals and neural activity. In turn, this disrupts learning. To deal with this inherent property of physical dynamical systems, two approaches have been suggested : either phased plasticity that is active only following a certain relaxation period, or long stimulus presentation times with small learning rates.",
    ". For one, the inference speed in hierarchically organized neural networks decreases with depth. In turn, this induces timing mismatches between instructive signals and neural activity. In turn, this disrupts learning. To deal with this inherent property of physical dynamical systems, two approaches have been suggested : either phased plasticity that is active only following a certain relaxation period, or long stimulus presentation times with small learning rates.",
    ". For one, the inference speed in hierarchically organized neural networks decreases with depth. In turn, this induces timing mismatches between instructive signals and neural activity. In turn, this disrupts learning. To deal with this inherent property of physical dynamical systems, two approaches have been suggested : either phased plasticity that is active only following a certain relaxation period, or long stimulus presentation times with small learning rates.",
    ". Graph neural networks ( GNNs ) can learn node representations encoding their local structure and feature information. These node representations can be further pooled into a graph representation. In this paper, we will use message passing GNNs to denote this class. Pan Li contributes Sec. 3.3 that proves the Theorem 1 and some implementation ideas. Corresponding author : Muhan Zhang ( muhan @ pku",
    ". Graph neural networks ( GNNs ) can learn node representations encoding their local structure and feature information. These node representations can be further pooled into a graph representation. In this paper, we will use message passing GNNs to denote this class. Pan Li contributes Sec. 3.3 that proves the Theorem 1 and some implementation ideas. Corresponding author : Muhan Zhang ( muhan @ pku",
    ". Graph neural networks ( GNNs ) can learn node representations encoding their local structure and feature information. These node representations can be further pooled into a graph representation. In this paper, we will use message passing GNNs to denote this class. Pan Li contributes Sec. 3.3 that proves the Theorem 1 and some implementation ideas. Corresponding author : Muhan Zhang ( muhan @ pku",
    ". Graph neural networks ( GNNs ) can learn node representations encoding their local structure and feature information. These node representations can be further pooled into a graph representation. In this paper, we will use message passing GNNs to denote this class. Pan Li contributes Sec. 3.3 that proves the Theorem 1 and some implementation ideas. Corresponding author : Muhan Zhang ( muhan @ pku",
    ". Graph neural networks ( GNNs ) can learn node representations encoding their local structure and feature information. These node representations can be further pooled into a graph representation. In this paper, we will use message passing GNNs to denote this class. Pan Li contributes Sec. 3.3 that proves the Theorem 1 and some implementation ideas. Corresponding author : Muhan Zhang ( muhan @ pku",
    ". Deep generative models provide a mechanism for incorporating priors into methods for unsupervised representation learning. In recent years, a range of strategies for improving upon standard reparameterized variational inference have been put forward. These include wake-sleep style variational methods that minimize the forward KL-divergence [ Bornschein, Bengio, 2015 ; Le et al., 2019 ]. Nested importance sampling formalizes the construction of proposals by",
    ". Deep generative models provide a mechanism for incorporating priors into methods for unsupervised representation learning. In recent years, a range of strategies for improving upon standard reparameterized variational inference have been put forward. These include wake-sleep style variational methods that minimize the forward KL-divergence [ Bornschein, Bengio, 2015 ; Le et al., 2019 ]. Nested importance sampling formalizes the construction of proposals by",
    ". Deep generative models provide a mechanism for incorporating priors into methods for unsupervised representation learning. In recent years, a range of strategies for improving upon standard reparameterized variational inference have been put forward. These include wake-sleep style variational methods that minimize the forward KL-divergence [ Bornschein, Bengio, 2015 ; Le et al., 2019 ]. Nested importance sampling formalizes the construction of proposals by",
    ". Deep generative models provide a mechanism for incorporating priors into methods for unsupervised representation learning. In recent years, a range of strategies for improving upon standard reparameterized variational inference have been put forward. These include wake-sleep style variational methods that minimize the forward KL-divergence [ Bornschein, Bengio, 2015 ; Le et al., 2019 ]. Nested importance sampling formalizes the construction of proposals by",
    ". Deep generative models provide a mechanism for incorporating priors into methods for unsupervised representation learning. In recent years, a range of strategies for improving upon standard reparameterized variational inference have been put forward. These include wake-sleep style variational methods that minimize the forward KL-divergence [ Bornschein, Bengio, 2015 ; Le et al., 2019 ]. Nested importance sampling formalizes the construction of proposals by",
    "an open problem dating back to 1991. Our upper bound relies on a packing bound by Bouttier et al. ( 2020 ) for the Piyavskii-Shubert algorithm that we link to the above integral. Our instance-dependent lower bound differs from traditional worst-case lower bounds in the Lipschitz setting. In this paper, we formally define the setting. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "an open problem dating back to 1991. Our upper bound relies on a packing bound by Bouttier et al. ( 2020 ) for the Piyavskii-Shubert algorithm that we link to the above integral. Our instance-dependent lower bound differs from traditional worst-case lower bounds in the Lipschitz setting. In this paper, we formally define the setting. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "an open problem dating back to 1991. Our upper bound relies on a packing bound by Bouttier et al. ( 2020 ) for the Piyavskii-Shubert algorithm that we link to the above integral. Our instance-dependent lower bound differs from traditional worst-case lower bounds in the Lipschitz setting. In this paper, we formally define the setting. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "an open problem dating back to 1991. Our upper bound relies on a packing bound by Bouttier et al. ( 2020 ) for the Piyavskii-Shubert algorithm that we link to the above integral. Our instance-dependent lower bound differs from traditional worst-case lower bounds in the Lipschitz setting. In this paper, we formally define the setting. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "an open problem dating back to 1991. Our upper bound relies on a packing bound by Bouttier et al. ( 2020 ) for the Piyavskii-Shubert algorithm that we link to the above integral. Our instance-dependent lower bound differs from traditional worst-case lower bounds in the Lipschitz setting. In this paper, we formally define the setting. 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "black-box ( where the attacker can only query the attacked model for predicted labels ) and white-box ( where the attacker has complete knowledge about the attacked model ) settings. In this paper we show that all these well-known uncertainty estimation techniques are vulnerable to a new and different type of attack that can completely destroy their usefulness. To demonstrate the relevance of our findings, we test ACE on modern architectures, such 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "black-box ( where the attacker can only query the attacked model for predicted labels ) and white-box ( where the attacker has complete knowledge about the attacked model ) settings. In this paper we show that all these well-known uncertainty estimation techniques are vulnerable to a new and different type of attack that can completely destroy their usefulness. To demonstrate the relevance of our findings, we test ACE on modern architectures, such 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "black-box ( where the attacker can only query the attacked model for predicted labels ) and white-box ( where the attacker has complete knowledge about the attacked model ) settings. In this paper we show that all these well-known uncertainty estimation techniques are vulnerable to a new and different type of attack that can completely destroy their usefulness. To demonstrate the relevance of our findings, we test ACE on modern architectures, such 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "black-box ( where the attacker can only query the attacked model for predicted labels ) and white-box ( where the attacker has complete knowledge about the attacked model ) settings. In this paper we show that all these well-known uncertainty estimation techniques are vulnerable to a new and different type of attack that can completely destroy their usefulness. To demonstrate the relevance of our findings, we test ACE on modern architectures, such 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    "black-box ( where the attacker can only query the attacked model for predicted labels ) and white-box ( where the attacker has complete knowledge about the attacked model ) settings. In this paper we show that all these well-known uncertainty estimation techniques are vulnerable to a new and different type of attack that can completely destroy their usefulness. To demonstrate the relevance of our findings, we test ACE on modern architectures, such 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ).",
    ". This paper aims at characterizing the fundamental statistical limits of community detection in the dynamic setting. Several groups have developed algorithms of this type in the recent past [ HS12, CSG16, ZWCY19, MKV+20 ]. As usual, characterizations have only been achieved recently for a simple network model, namely the stochastic block model ( SBM ) [ HLL83, ABFX08, KN11, R",
    ". This paper aims at characterizing the fundamental statistical limits of community detection in the dynamic setting. Several groups have developed algorithms of this type in the recent past [ HS12, CSG16, ZWCY19, MKV+20 ]. As usual, characterizations have only been achieved recently for a simple network model, namely the stochastic block model ( SBM ) [ HLL83, ABFX08, KN11, R",
    ". This paper aims at characterizing the fundamental statistical limits of community detection in the dynamic setting. Several groups have developed algorithms of this type in the recent past [ HS12, CSG16, ZWCY19, MKV+20 ]. As usual, characterizations have only been achieved recently for a simple network model, namely the stochastic block model ( SBM ) [ HLL83, ABFX08, KN11, R",
    ". This paper aims at characterizing the fundamental statistical limits of community detection in the dynamic setting. Several groups have developed algorithms of this type in the recent past [ HS12, CSG16, ZWCY19, MKV+20 ]. As usual, characterizations have only been achieved recently for a simple network model, namely the stochastic block model ( SBM ) [ HLL83, ABFX08, KN11, R",
    ". This paper aims at characterizing the fundamental statistical limits of community detection in the dynamic setting. Several groups have developed algorithms of this type in the recent past [ HS12, CSG16, ZWCY19, MKV+20 ]. As usual, characterizations have only been achieved recently for a simple network model, namely the stochastic block model ( SBM ) [ HLL83, ABFX08, KN11, R",
    ": = f ( x ; w ) : = f ( x ; w ). In this paper, we study how different parameterizations induce different complexity measures. We consider parameterized mappings f : X  Rp  Rm, from input x  X and parameters w  Rp to predictions f ( x ; w ). Then image ( F ) is the set of",
    ": = f ( x ; w ) : = f ( x ; w ). In this paper, we study how different parameterizations induce different complexity measures. We consider parameterized mappings f : X  Rp  Rm, from input x  X and parameters w  Rp to predictions f ( x ; w ). Then image ( F ) is the set of",
    ": = f ( x ; w ) : = f ( x ; w ). In this paper, we study how different parameterizations induce different complexity measures. We consider parameterized mappings f : X  Rp  Rm, from input x  X and parameters w  Rp to predictions f ( x ; w ). Then image ( F ) is the set of",
    ": = f ( x ; w ) : = f ( x ; w ). In this paper, we study how different parameterizations induce different complexity measures. We consider parameterized mappings f : X  Rp  Rm, from input x  X and parameters w  Rp to predictions f ( x ; w ). Then image ( F ) is the set of",
    ": = f ( x ; w ) : = f ( x ; w ). In this paper, we study how different parameterizations induce different complexity measures. We consider parameterized mappings f : X  Rp  Rm, from input x  X and parameters w  Rp to predictions f ( x ; w ). Then image ( F ) is the set of",
    "requires no training, and is reminiscent of case-based reasoning in classical artificial intelligence ( AI ). Our non-parametric approach derives crisp logical rules for each query by finding multiple graph path patterns that connect similar source entities through the given relation. Using our method, we obtain new state-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122. Our model is robust in low data settings, outperforming recently proposed meta-learning approaches1",
    "requires no training, and is reminiscent of case-based reasoning in classical artificial intelligence ( AI ). Our non-parametric approach derives crisp logical rules for each query by finding multiple graph path patterns that connect similar source entities through the given relation. Using our method, we obtain new state-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122. Our model is robust in low data settings, outperforming recently proposed meta-learning approaches1",
    "a detailed analysis of significant design choices. When no alias table is used for the downstream task, ensuring candidates are random improves the model ability to distinguish the right entity among all possible entities. ( 1 ) given the abundance of supervision from Wikipedia links, we did not get any gains in performance. ( 2 ) given the abundance of supervision from Wikipedia links, we did not get any gains in performance. ( 3 ) given the abundance of supervision from Wikipedia links, we did not get any",
    "a detailed analysis of significant design choices. When no alias table is used for the downstream task, ensuring candidates are random improves the model ability to distinguish the right entity among all possible entities. ( 1 ) given the abundance of supervision from Wikipedia links, we did not get any gains in performance. ( 2 ) given the abundance of supervision from Wikipedia links, we did not get any gains in performance. ( 3 ) given the abundance of supervision from Wikipedia links, we did not get any",
    "the training data subset search is still performed by experts. With the rapid growth in the availability of labeled data for large-scale vision tasks, automating the end-to-end process would make the application of DNNs much easier for non-experts. With the rapid growth in the availability of labeled data for large-scale vision tasks, automating the end-to-end process would make the application of DNNs much easier for non-experts.",
    "the training data subset search is still performed by experts. With the rapid growth in the availability of labeled data for large-scale vision tasks, automating the end-to-end process would make the application of DNNs much easier for non-experts. With the rapid growth in the availability of labeled data for large-scale vision tasks, automating the end-to-end process would make the application of DNNs much easier for non-experts.",
    "the lower-level ( parent ) capsule. The higher-level ( lower-level ) capsule aggregates the votes, updates its state, and uses the updated state to explain each lower-level ( parent ) capsule. The ones that are well-explained end up routing more towards that parent. Thus, capsule routing has the potential to produce an interpretable hierarchical parsing of a visual scene. Dynamic Routing ( Sabour et al., 2017",
    "the lower-level ( parent ) capsule. The higher-level ( lower-level ) capsule aggregates the votes, updates its state, and uses the updated state to explain each lower-level ( parent ) capsule. The ones that are well-explained end up routing more towards that parent. Thus, capsule routing has the potential to produce an interpretable hierarchical parsing of a visual scene. Dynamic Routing ( Sabour et al., 2017",
    "HO is a double loop of optimizations. the inner loop is responsible for finding the best model weights. the outer loop is responsible for finding the optimal hyperparameters. this is additionally complicated by the fact that computational resources and time are usually limited. the high computational cost of evaluation inspires additional strategies, for instance bandit methods, to leverage cheaper but cruder results. a number of HO approaches have been developed ( Bergstra et al., 2011 ).",
    "HO is a double loop of optimizations. the inner loop is responsible for finding the best model weights. the outer loop is responsible for finding the optimal hyperparameters. this is additionally complicated by the fact that computational resources and time are usually limited. the high computational cost of evaluation inspires additional strategies, for instance bandit methods, to leverage cheaper but cruder results. a number of HO approaches have been developed ( Bergstra et al., 2011 ).",
    ". However, little is known about what accounts for these performance gains. In 3, we discuss this peakiness effect ( PKE ). Fourth, we show that promoting the target token to the most probable increases the performance gains observed in the literature. In 4, we discuss this peakiness effect ( PKE ). Fourth, we show that promoting the target token to the most probable increases the performance gains observed in the literature. In 4, we discuss this peakiness effect (",
    ". However, little is known about what accounts for these performance gains. In 3, we discuss this peakiness effect ( PKE ). Fourth, we show that promoting the target token to the most probable increases the performance gains observed in the literature. In 4, we discuss this peakiness effect ( PKE ). Fourth, we show that promoting the target token to the most probable increases the performance gains observed in the literature. In 4, we discuss this peakiness effect (",
    ". Third, our results complement some finite-sample error bounds developed in the literature. These asymptotic statements allow us to construct accurate confidence regions for quantities related to the optimal policy. Fourth, our results complement a closed-form asymptotic variance that often shows up in the first-order terms in these bounds. Finally, our motivation is to design good exploration policies by directly using our tight error estimates.",
    ". Third, our results complement some finite-sample error bounds developed in the literature. These asymptotic statements allow us to construct accurate confidence regions for quantities related to the optimal policy. Fourth, our results complement a closed-form asymptotic variance that often shows up in the first-order terms in these bounds. Finally, our motivation is to design good exploration policies by directly using our tight error estimates.",
    "low efficiency for the online recommendation with the increasing scale of datasets. However, most of new e-commerce vendors do not have enough interactive data. This leads to low efficiency for the online recommendation with the increasing scale of datasets. Recent studies show the promising of hashing based methods to tackle the efficiency challenge by representing users and items with binary codes ( Zhang et al., 2014 ; Zhou & Zha, 2012 ; Liu et al., 2016 )",
    "low efficiency for the online recommendation with the increasing scale of datasets. However, most of new e-commerce vendors do not have enough interactive data. This leads to low efficiency for the online recommendation with the increasing scale of datasets. Recent studies show the promising of hashing based methods to tackle the efficiency challenge by representing users and items with binary codes ( Zhang et al., 2014 ; Zhou & Zha, 2012 ; Liu et al., 2016 )",
    ". Inductive transfer learning ( e.g. few-shot learning ) uses a labeled source domain to improve generalization on a labeled target domain. While transductive transfer learning ( e.g. domain adaptation ) uses a labeled source domain to improve generalization on a labeled target domain. Inductive transfer learning ( e.g. few-shot learning ) uses a labeled source domain to improve generalization on a label",
    ". Inductive transfer learning ( e.g. few-shot learning ) uses a labeled source domain to improve generalization on a labeled target domain. While transductive transfer learning ( e.g. domain adaptation ) uses a labeled source domain to improve generalization on a labeled target domain. Inductive transfer learning ( e.g. few-shot learning ) uses a labeled source domain to improve generalization on a label",
    ",. In contrast, model-based RL can be significantly more data efficient... ( 2016 ), Gu et al. ( 2016 ).. a value function.... In    .    ), ( ),,,,. (",
    ",. In contrast, model-based RL can be significantly more data efficient... ( 2016 ), Gu et al. ( 2016 ).. a value function.... In    .    ), ( ),,,,. (",
    ". The cycle of attacks and defenses motivates us to rethink how we can improve the general robustness of neural networks. Adversarial examples ( Szegedy et al., 2013 ) are inputs that are designed by an adversary to cause a machine learning system to make a misclassification. In this paper, we develop methods for detecting adversarial inputs, instead of attempting to accurately classify them.",
    ". The cycle of attacks and defenses motivates us to rethink how we can improve the general robustness of neural networks. Adversarial examples ( Szegedy et al., 2013 ) are inputs that are designed by an adversary to cause a machine learning system to make a misclassification. In this paper, we develop methods for detecting adversarial inputs, instead of attempting to accurately classify them.",
    "for deep ReLU networks ( ( Zou et al., 2018a ) ). In addition, Yang et al. ( 2019 ) gave an efficient algorithm to approximate the NTK for convolutional architectures. In all of these papers, authors studied only the effect of infinite width on the NTK.",
    "for deep ReLU networks ( ( Zou et al., 2018a ) ). In addition, Yang et al. ( 2019 ) gave an efficient algorithm to approximate the NTK for convolutional architectures. In all of these papers, authors studied only the effect of infinite width on the NTK.",
    ". We consider the dependency trees, a linguistic framework that describes the compositional structure of a sentence. This framework aims at mapping close input sentences to close representations while separating unrelated sentences. As illustrated in Figure 1, we train our model with a contrastive framework which aims at mapping close input sentences to close representations. As illustrated in Figure 3, the model is structured in two-steps : ( B ) a representation is learned using a discriminating objective on",
    ". We consider the dependency trees, a linguistic framework that describes the compositional structure of a sentence. This framework aims at mapping close input sentences to close representations while separating unrelated sentences. As illustrated in Figure 1, we train our model with a contrastive framework which aims at mapping close input sentences to close representations. As illustrated in Figure 3, the model is structured in two-steps : ( B ) a representation is learned using a discriminating objective on",
    ". 2 ) The most sophisticated NLP methods require vast amounts of labeled data and expensive expertise. 3 INTRODUCTION. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT.",
    ". 2 ) The most sophisticated NLP methods require vast amounts of labeled data and expensive expertise. 3 INTRODUCTION. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT. FinBERT.",
    "singing voice synthesis ( SVS ) has followed closely with that in text-to-speech ( TTS ) synthesis ( Cook, 1996 ). Moreover, the machine has to sing without pre-assigned musical scores and lyrics as well even in the inference ( generation ) time. This task is challenging in that, as the machine sees no lyrics at all, it hardly has any knowledge of the human language to articulate either voiced or unvoiced sounds.",
    "singing voice synthesis ( SVS ) has followed closely with that in text-to-speech ( TTS ) synthesis ( Cook, 1996 ). Moreover, the machine has to sing without pre-assigned musical scores and lyrics as well even in the inference ( generation ) time. This task is challenging in that, as the machine sees no lyrics at all, it hardly has any knowledge of the human language to articulate either voiced or unvoiced sounds.",
    ". Small and imperceptible perturbations of the input data lead to incorrect predictions by the networks. This vulnerability has led to a large volume of work that attempts to design robust DNNs. These weaknesses pose an obstacle in wide-scale adoption of DNNs and expose an inherent weakness in their reliability. These weaknesses have led to a large volume of work that attempts to design robust DNNs.",
    ". Small and imperceptible perturbations of the input data lead to incorrect predictions by the networks. This vulnerability has led to a large volume of work that attempts to design robust DNNs. These weaknesses pose an obstacle in wide-scale adoption of DNNs and expose an inherent weakness in their reliability. These weaknesses have led to a large volume of work that attempts to design robust DNNs.",
    ". For example, rush-hour traffic surge is temporally unsmoothed, while it occurs in many regions in a city. This paper aims to use urban data to study urban spatio-temporal prediction problems. Specifically, S1, S2 and S3 denote business, residential, and recreational areas, respectively. Traffic observations in the interior areas of S1, S2 and S3 denote business, residential, and recreational areas.",
    ". For example, rush-hour traffic surge is temporally unsmoothed, while it occurs in many regions in a city. This paper aims to use urban data to study urban spatio-temporal prediction problems. Specifically, S1, S2 and S3 denote business, residential, and recreational areas, respectively. Traffic observations in the interior areas of S1, S2 and S3 denote business, residential, and recreational areas.",
    ". In particular, the statistical error characterizes the bias and variance that arise from approximating the action-value function using deep neural network. In particular, the statistical error characterizes the bias and variance that arise from approximating the action-value function using deep neural network. In particular, the statistical error characterizes the bias and variance that arise from approximating the action-value function using deep neural network. As a byproduct, our analysis provides justifications for",
    ". In particular, the statistical error characterizes the bias and variance that arise from approximating the action-value function using deep neural network. In particular, the statistical error characterizes the bias and variance that arise from approximating the action-value function using deep neural network. In particular, the statistical error characterizes the bias and variance that arise from approximating the action-value function using deep neural network. As a byproduct, our analysis provides justifications for",
    "nEmb ( her ) + nEmb ( for ) +nEmb ( her ). In this paper, we introduce hypernodes to represent the candidate phrases in attention. In this paper, the BLEU increases from 20.90 ( by Transformer ) to 34.61 ( by PhraseTransformer ). Secondly, it is unfeasible to incorporate the semantics of phrases in the attention. For example, in figure 1",
    "nEmb ( her ) + nEmb ( for ) +nEmb ( her ). In this paper, we introduce hypernodes to represent the candidate phrases in attention. In this paper, the BLEU increases from 20.90 ( by Transformer ) to 34.61 ( by PhraseTransformer ). Secondly, it is unfeasible to incorporate the semantics of phrases in the attention. For example, in figure 1",
    "; ( ii ) control flow constructs such as branching and loops to compose and combine intermediate results. In this paper, we present a new architecture MAIN ( short for Modular Algorithm Induction Network ) for neural algorithm induction. Our architecture consists of a neural Turing machine ( Graves et al., 2014 ) and its successor the Differentiable Neural Computer ( Kurach et al., 2016 ).",
    "; ( ii ) control flow constructs such as branching and loops to compose and combine intermediate results. In this paper, we present a new architecture MAIN ( short for Modular Algorithm Induction Network ) for neural algorithm induction. Our architecture consists of a neural Turing machine ( Graves et al., 2014 ) and its successor the Differentiable Neural Computer ( Kurach et al., 2016 ).",
    ". In particular, quantized floating point ( Q-FP ) arithmetic has been extensively studied. In particular, quantized floating point ( Q-FP ) arithmetic has the advantage of higher dynamic range compared to equivalent Q-FP representations. In particular, quantized floating point ( Q-FP ) arithmetic has the advantage of higher dynamic range compared to equivalent Q-FP representations. In particular, quantized floating point ( Q-",
    ". In particular, quantized floating point ( Q-FP ) arithmetic has been extensively studied. In particular, quantized floating point ( Q-FP ) arithmetic has the advantage of higher dynamic range compared to equivalent Q-FP representations. In particular, quantized floating point ( Q-FP ) arithmetic has the advantage of higher dynamic range compared to equivalent Q-FP representations. In particular, quantized floating point ( Q-",
    "e.g., Hafner et al. ( 2018 ) ; Wang and Ba ( 2019 ) ). MBRL is a popular approach for learning to control nonlinear systems that can not be expressed analytically. In this paper, we : 1 ) identify and formalize the problem of objective mismatch in MBRL ; 2 ) examine the signs of and the effects of objective mismatch on MBRL performance.",
    "e.g., Hafner et al. ( 2018 ) ; Wang and Ba ( 2019 ) ). MBRL is a popular approach for learning to control nonlinear systems that can not be expressed analytically. In this paper, we : 1 ) identify and formalize the problem of objective mismatch in MBRL ; 2 ) examine the signs of and the effects of objective mismatch on MBRL performance.",
    "..... f is a class-wise feature distribution model. f is a layer-wise feature representation model. f is a layer-wise feature representation model. f is a layer-wise feature representation model. f is a layer-wise feature representation model. f is a layer-wise feature representation model. f is a layer-wise feature representation model. Figure 1 ( bottom ) illustrate",
    "..... f is a class-wise feature distribution model. f is a layer-wise feature representation model. f is a layer-wise feature representation model. f is a layer-wise feature representation model. f is a layer-wise feature representation model. f is a layer-wise feature representation model. f is a layer-wise feature representation model. Figure 1 ( bottom ) illustrate",
    "two policies may perform similar actions at a local level but result in very different global behaviors. We propose to define behaviors via so-called Behavioral Embedding Maps ( BEMs ). BEMs enable us to identify policies with their Probabilistic Policy Embeddings ( PPEs ). PPEs provide us a way to rigorously define dissimilarity between policies. We do this by equipping them with metrics defined on the manifold of probabilistic measures.",
    "two policies may perform similar actions at a local level but result in very different global behaviors. We propose to define behaviors via so-called Behavioral Embedding Maps ( BEMs ). BEMs enable us to identify policies with their Probabilistic Policy Embeddings ( PPEs ). PPEs provide us a way to rigorously define dissimilarity between policies. We do this by equipping them with metrics defined on the manifold of probabilistic measures.",
    "the interpolation property ALI-G ( Adaptive Learning-rates for Interpolation with Gradients ). This property is usually satisfied in supervised deep learning. In this work, we open a different line of enquiry : can the interpolation property be used to design a robust and efficient optimization algorithm for deep learning? First, an adaptive learning-rate can be computed for the non-stochastic gradient direction when the minimum value of the objective function is known",
    "the interpolation property ALI-G ( Adaptive Learning-rates for Interpolation with Gradients ). This property is usually satisfied in supervised deep learning. In this work, we open a different line of enquiry : can the interpolation property be used to design a robust and efficient optimization algorithm for deep learning? First, an adaptive learning-rate can be computed for the non-stochastic gradient direction when the minimum value of the objective function is known",
    ", 2012 ; Freeman et al., 2012 ; Freeman et al., 2010 ). Perceptual grouping is a fundamental component of visual intelligence. Feedforward processes group scenes by encoding increasingly complex feature conjunctions. Feedback computations can be recurrent, or bottom-up, or recurrent, processes. Fig. 1b, top ; Nothdurft et al., 1986",
    ", 2012 ; Freeman et al., 2012 ; Freeman et al., 2010 ). Perceptual grouping is a fundamental component of visual intelligence. Feedforward processes group scenes by encoding increasingly complex feature conjunctions. Feedback computations can be recurrent, or bottom-up, or recurrent, processes. Fig. 1b, top ; Nothdurft et al., 1986",
    "a large number of parameters and computation load, which makes the deployment and real-time processing on embedded and edge devices extremely difficult. Thus, model compression techniques, especially pruning methods that increase sparsity of weight matrices, have been extensively studied to reduce the memory consumption and computation load of DNNs. The sparsity-inducing regularizer, originally proposed by Tibshirani ( 1996 ), can be easily optimized through gradient descent for its convex and almost everywhere",
    "a large number of parameters and computation load, which makes the deployment and real-time processing on embedded and edge devices extremely difficult. Thus, model compression techniques, especially pruning methods that increase sparsity of weight matrices, have been extensively studied to reduce the memory consumption and computation load of DNNs. The sparsity-inducing regularizer, originally proposed by Tibshirani ( 1996 ), can be easily optimized through gradient descent for its convex and almost everywhere",
    ". Whether vexity can be utilized to further improve the performance remains an open problem. However, whether vexity can be utilized to further improve the performance remains an open problem. In this paper, we give an affirmative answer by developing a variant of Adam ( referred to as SAdam ) which achieves a data-dependent O ( log T ) regret bound. In addition, under a special configuration of hyperparameters, our SAdam reduces to SC",
    ". Whether vexity can be utilized to further improve the performance remains an open problem. However, whether vexity can be utilized to further improve the performance remains an open problem. In this paper, we give an affirmative answer by developing a variant of Adam ( referred to as SAdam ) which achieves a data-dependent O ( log T ) regret bound. In addition, under a special configuration of hyperparameters, our SAdam reduces to SC",
    ". The pre-training and fine-tuning paradigm, exemplified by methods like ELMo, GPT-2, BERT ( Devlin et al., 2019 ), XLNet ( Yang et al., 2019 ), has drastically reshaped the landscape of the natural language processing research. Despite its conceptual simplicity, the pre-training and fine-tuning paradigm has drastically reshaped the landscape of the",
    ". The pre-training and fine-tuning paradigm, exemplified by methods like ELMo, GPT-2, BERT ( Devlin et al., 2019 ), XLNet ( Yang et al., 2019 ), has drastically reshaped the landscape of the natural language processing research. Despite its conceptual simplicity, the pre-training and fine-tuning paradigm has drastically reshaped the landscape of the",
    "2017 ;, 2017 ; Louizos et al., 2017 ; You et al., 2018 ). Pruning weights and/or convolutional filters from deep neural networks ( DNNs ) can substantially shrink parameter counts with minimal loss of accuracy. Moreover, pruning methods have been found to actually improve generalization ( measured by model accuracy when moving from previously seen to previously unseen inputs ), enabling broader application of DNN",
    "2017 ;, 2017 ; Louizos et al., 2017 ; You et al., 2018 ). Pruning weights and/or convolutional filters from deep neural networks ( DNNs ) can substantially shrink parameter counts with minimal loss of accuracy. Moreover, pruning methods have been found to actually improve generalization ( measured by model accuracy when moving from previously seen to previously unseen inputs ), enabling broader application of DNN",
    ". If a vector that can represent network architecture without discrete values is determined, then the noncontinuous aforementioned disadvantages can be addressed. In this study, we proposed the neural architecture search ( NAS ), an automated architecture engineering. To learn and search on the embedding space, we developed a mechanism to generate architecture encoder and decoder to promote origin architecture communication with the embedding space. In addition, the architecture simulator simulates the embedding space",
    ". If a vector that can represent network architecture without discrete values is determined, then the noncontinuous aforementioned disadvantages can be addressed. In this study, we proposed the neural architecture search ( NAS ), an automated architecture engineering. To learn and search on the embedding space, we developed a mechanism to generate architecture encoder and decoder to promote origin architecture communication with the embedding space. In addition, the architecture simulator simulates the embedding space",
    ". In addition, as the size of new state-of-the-art models keeps growing, they rely more and more heavily on efficient algorithms for training and making inferences from such models. In this paper, we will present a new training algorithm based on homotopy continuation method Bates et al. ( 2011 ; 2008 ) ; Morgan & Sommese ( 1987 ) which has been successfully used to solve nonlinear problems. In this paper,",
    ". In addition, as the size of new state-of-the-art models keeps growing, they rely more and more heavily on efficient algorithms for training and making inferences from such models. In this paper, we will present a new training algorithm based on homotopy continuation method Bates et al. ( 2011 ; 2008 ) ; Morgan & Sommese ( 1987 ) which has been successfully used to solve nonlinear problems. In this paper,",
    "Figure 1 INTRODUCTION. Deep learning contains many differentiable algorithms for computing with learned representations. In this paper, we introduce a generalisation of the Transformer architecture, the 2-simplicial Transformer. In our situation, an appropriate algebra is the Clifford algebra Cl ( H ) of the space H of queries and keys. This space contains that space H  Cl ( H ) and in which queries and keys can be multiplied. Figure 1 INTRODUC",
    "Figure 1 INTRODUCTION. Deep learning contains many differentiable algorithms for computing with learned representations. In this paper, we introduce a generalisation of the Transformer architecture, the 2-simplicial Transformer. In our situation, an appropriate algebra is the Clifford algebra Cl ( H ) of the space H of queries and keys. This space contains that space H  Cl ( H ) and in which queries and keys can be multiplied. Figure 1 INTRODUC",
    "labelled labels and images. Compared to other computer vision tasks such as classification, the labelling process is cumbersome and prone to errors. Therefore, the need for a method to train with a limited amount of labelled data. The work presented in this paper proposes a semi-supervised probabilistic method for pose estimation that incorporates the geometry of an object. The method is based on a semi-supervised probabilistic method that incorporates the geometry of an object. This method is",
    "labelled labels and images. Compared to other computer vision tasks such as classification, the labelling process is cumbersome and prone to errors. Therefore, the need for a method to train with a limited amount of labelled data. The work presented in this paper proposes a semi-supervised probabilistic method for pose estimation that incorporates the geometry of an object. The method is based on a semi-supervised probabilistic method that incorporates the geometry of an object. This method is",
    "). In recent years, it has become popular to apply deep reinforcement learning ( MARL ) into multi-agent applications. In particular, many real-world problems involve interactions between multiple agents. However, the problem becomes significantly harder when there exist complex cooperation and competition among agents. For example, when using deep reinforcement learning ( MARL ) to complex games with a large number of agents, the problem becomes significantly more complex and the variance of policy gradients can grow exponentially",
    "). In recent years, it has become popular to apply deep reinforcement learning ( MARL ) into multi-agent applications. In particular, many real-world problems involve interactions between multiple agents. However, the problem becomes significantly harder when there exist complex cooperation and competition among agents. For example, when using deep reinforcement learning ( MARL ) to complex games with a large number of agents, the problem becomes significantly more complex and the variance of policy gradients can grow exponentially",
    "MXGNet summarises the multiplex graphs extracted from the diagrams of the task. For both tasks, MXGNet outperforms the state-of-the-art models by a considerable margin. For an Euler Diagram Syllogism task, MXGNet achieves state-of-the-art accuracy of 99.8 %. For Raven Progressive Matrices ( RPM ), MXGNet outperforms the state-of-",
    "MXGNet summarises the multiplex graphs extracted from the diagrams of the task. For both tasks, MXGNet outperforms the state-of-the-art models by a considerable margin. For an Euler Diagram Syllogism task, MXGNet achieves state-of-the-art accuracy of 99.8 %. For Raven Progressive Matrices ( RPM ), MXGNet outperforms the state-of-",
    "ATMC outperforms a strong optimization baseline in terms of classification accuracy and test log-likelihood. ATMC is an adaptive noise MCMC algorithm that estimates and is able to sample from the posterior of a neural network. ATMC is robust to overfitting, to simplify the training procedure and the space of hyperparameters. ATMC outperforms a strong optimization baseline in terms of classification accuracy and test log-likelihood.",
    "ATMC outperforms a strong optimization baseline in terms of classification accuracy and test log-likelihood. ATMC is an adaptive noise MCMC algorithm that estimates and is able to sample from the posterior of a neural network. ATMC is robust to overfitting, to simplify the training procedure and the space of hyperparameters. ATMC outperforms a strong optimization baseline in terms of classification accuracy and test log-likelihood.",
    ". For example, one forward pass of the ResNet50 requires 4 GFLOPs and training requires 1018 FLOPs, which takes 14 days on one state-of-the-art NVIDIA M40 GPU. As an example, a recent report shows that training a single DNN can cost over $ 10K US dollars and emit as much carbon as five cars in their lifetimes. As an example, a recent report shows that training a single DNN can cost over $ 10",
    ". For example, one forward pass of the ResNet50 requires 4 GFLOPs and training requires 1018 FLOPs, which takes 14 days on one state-of-the-art NVIDIA M40 GPU. As an example, a recent report shows that training a single DNN can cost over $ 10K US dollars and emit as much carbon as five cars in their lifetimes. As an example, a recent report shows that training a single DNN can cost over $ 10",
    "the model \u2019 s weights. In the white-box setting, the attacker can provide any inputs and receive the corresponding predictions. However, the adversarial perturbations can arbitrarily change the network \u2019 s prediction but often too small to affect human recognition. Therefore, carefully reducing the data dimension may help improve the robustness of neural networks.",
    "the model \u2019 s weights. In the white-box setting, the attacker can provide any inputs and receive the corresponding predictions. However, the adversarial perturbations can arbitrarily change the network \u2019 s prediction but often too small to affect human recognition. Therefore, carefully reducing the data dimension may help improve the robustness of neural networks.",
    "). In the biomedical domain, NER and RE facilitate large-scale biomedical data analysis. In the clinical domain, NER and RE can aid in disease and treatment prediction, readmission prediction, and patient cohort identification ( Miotto et al., 2017 ). In the biomedical domain, NER and RE facilitate large-scale biomedical data analysis. In the biomedical domain, NER and RE facilitate large-scale bio",
    "). In the biomedical domain, NER and RE facilitate large-scale biomedical data analysis. In the clinical domain, NER and RE can aid in disease and treatment prediction, readmission prediction, and patient cohort identification ( Miotto et al., 2017 ). In the biomedical domain, NER and RE facilitate large-scale biomedical data analysis. In the biomedical domain, NER and RE facilitate large-scale bio",
    ", 2015 ; Ren et al., 2015 ). The raw data is fed to a network, together with class label information, and then the network is trained to perform some supervised classification. As a by-product it discovers a condensed data representation in the last hidden layers of the network that turns out to be useful for other computer vision tasks such as semantic segmentation. In contrastive representation learning, similarity information is provided in terms of contrastive triplets",
    ", 2015 ; Ren et al., 2015 ). The raw data is fed to a network, together with class label information, and then the network is trained to perform some supervised classification. As a by-product it discovers a condensed data representation in the last hidden layers of the network that turns out to be useful for other computer vision tasks such as semantic segmentation. In contrastive representation learning, similarity information is provided in terms of contrastive triplets",
    ". Instead of treating all data samples equally, lower priority can be assigned for a datum to obtain a higher performance model. Accurately quantifying the value of data has a great potential for improving model performance for real-world training datasets. In addition to improving performance in such scenarios, data valuation also enables many new use cases.",
    ". Instead of treating all data samples equally, lower priority can be assigned for a datum to obtain a higher performance model. Accurately quantifying the value of data has a great potential for improving model performance for real-world training datasets. In addition to improving performance in such scenarios, data valuation also enables many new use cases.",
    ". In this work, we perform a rigorous analysis of the norm, of both the activations and the gradients of each layer, at the point of initialization. the norm is preserved through arbitrary depths, preventing exploding or decaying gradients in deep networks.",
    ". In this work, we perform a rigorous analysis of the norm, of both the activations and the gradients of each layer, at the point of initialization. the norm is preserved through arbitrary depths, preventing exploding or decaying gradients in deep networks.",
    ". The enormous computational intensity of Deep Neural Networks ( DNNs ) has resulted in either hand-optimized kernels, such as NVIDIA cuDNN or Intel MKL. However, the complexity of the tensor operations in DNNs and the volatility of algorithms, which has led to unprecedented rate of innovation, calls for developing automated compilation frameworks. To solve this problem, we first question the very statistical guarantees which the aforementioned optimization passes rely",
    ". The enormous computational intensity of Deep Neural Networks ( DNNs ) has resulted in either hand-optimized kernels, such as NVIDIA cuDNN or Intel MKL. However, the complexity of the tensor operations in DNNs and the volatility of algorithms, which has led to unprecedented rate of innovation, calls for developing automated compilation frameworks. To solve this problem, we first question the very statistical guarantees which the aforementioned optimization passes rely",
    ". In particular, an attacker can carefully craft a perturbation  such that f makes predictions for x +  as the attacker desires. As a response, certified robustness ( e.g., Wong & Kolter ( 2018 ) ) against adversarial perturbations has been developed. In particular, a robust classifier verifiably predicts the same top-1 label for data points in a certain region around any example x.",
    ". In particular, an attacker can carefully craft a perturbation  such that f makes predictions for x +  as the attacker desires. As a response, certified robustness ( e.g., Wong & Kolter ( 2018 ) ) against adversarial perturbations has been developed. In particular, a robust classifier verifiably predicts the same top-1 label for data points in a certain region around any example x.",
    ". Deep neural networks typically contain far more trainable parameters than training samples. However, their generalization performance can not be found analytically. In this work, we attempt to understand the generalization behavior of DNNs through GSNR and reveal how GSNR affects the training dynamics of gradient descent optimization. Stanislav Fort ( 2019 ) studied a new gradient alignment measure called stiffness in deep neural networks.",
    ". Deep neural networks typically contain far more trainable parameters than training samples. However, their generalization performance can not be found analytically. In this work, we attempt to understand the generalization behavior of DNNs through GSNR and reveal how GSNR affects the training dynamics of gradient descent optimization. Stanislav Fort ( 2019 ) studied a new gradient alignment measure called stiffness in deep neural networks.",
    ". QUERY2BOX. QUERY2BOX. QUERY2BOX....... previous work has been to model queries as single points in a vector space... .............",
    ". QUERY2BOX. QUERY2BOX. QUERY2BOX....... previous work has been to model queries as single points in a vector space... .............",
    "i = ( xi, yi ), i = 1,..., n i=1  ( w ; i ). ( 1 ). ( 2 ). ( 3 ). ( 4 ). ( 4 ). ( 4 ). ( 4 ). ( 4 ). ( 4 ). ( 4 ).",
    "i = ( xi, yi ), i = 1,..., n i=1  ( w ; i ). ( 1 ). ( 2 ). ( 3 ). ( 4 ). ( 4 ). ( 4 ). ( 4 ). ( 4 ). ( 4 ). ( 4 ).",
    ",, or NAS... 0 20 40 60 80 16x1300x reduction direct deploy ( no retrain ) train a once-for-all network specialized sub-nets cpu F P G A Different Hardware / Constraint Deployment Scenarios 0 20 40 60 80 16x1300x reduction direct deploy ( no retrain ) train a once-for-all network specialized sub-",
    ",, or NAS... 0 20 40 60 80 16x1300x reduction direct deploy ( no retrain ) train a once-for-all network specialized sub-nets cpu F P G A Different Hardware / Constraint Deployment Scenarios 0 20 40 60 80 16x1300x reduction direct deploy ( no retrain ) train a once-for-all network specialized sub-",
    ". QA is becoming a proxy for gauging a model \u2019 s natural language understanding capability. Semantic parsing techniques, which map natural language utterances to executable programs, have been used for compositional QA. NMNs perform well on synthetic visual question answering ( VQA ) domains such as CLEVR ( Johnson et al., 2017 ) and it is appealing to apply them to answer questions over text due to their interpretable",
    ". QA is becoming a proxy for gauging a model \u2019 s natural language understanding capability. Semantic parsing techniques, which map natural language utterances to executable programs, have been used for compositional QA. NMNs perform well on synthetic visual question answering ( VQA ) domains such as CLEVR ( Johnson et al., 2017 ) and it is appealing to apply them to answer questions over text due to their interpretable",
    ", and thus, pruning results. In this work, we first look into the effect of initialization on pruning. As long as initial weights are drawn from appropriately scaled Gaussians, pruning can be done on deep neural networks in a single-shot prior to training. In this work, we first look into the effect of initialization on pruning. We find that initial weights have critical impact on connection sensitivity, and therefore, pruning results. This result leads us to develop",
    ", and thus, pruning results. In this work, we first look into the effect of initialization on pruning. As long as initial weights are drawn from appropriately scaled Gaussians, pruning can be done on deep neural networks in a single-shot prior to training. In this work, we first look into the effect of initialization on pruning. We find that initial weights have critical impact on connection sensitivity, and therefore, pruning results. This result leads us to develop",
    ". doubling the size of layer inputs and outputs quadruples the size of the layer. This causes most of the networks to be memory-bound. Batching reduces the energy consumption due to the excessive memory and storage requirements of modern DNNs. In this work, we seek a method to decouple the information bandwidth from layer expressivity. This method would allow us to ( 1 ) speed up training networks by storing them in on-chip memory, ( 2 ) remove",
    ". doubling the size of layer inputs and outputs quadruples the size of the layer. This causes most of the networks to be memory-bound. Batching reduces the energy consumption due to the excessive memory and storage requirements of modern DNNs. In this work, we seek a method to decouple the information bandwidth from layer expressivity. This method would allow us to ( 1 ) speed up training networks by storing them in on-chip memory, ( 2 ) remove",
    ". In particular, we identify precise conditions on the hyperparameters governing the initial weight and bias distributions that are necessary to ensure trainability. In particular, we identify precise conditions on the hyperparameters governing the initial weight and bias distributions that are necessary to ensure trainability. In particular, we identify precise conditions on the initialization hyperparameters governing the initial weight and bias distributions that are necessary to ensure trainability.",
    ". In particular, we identify precise conditions on the hyperparameters governing the initial weight and bias distributions that are necessary to ensure trainability. In particular, we identify precise conditions on the hyperparameters governing the initial weight and bias distributions that are necessary to ensure trainability. In particular, we identify precise conditions on the initialization hyperparameters governing the initial weight and bias distributions that are necessary to ensure trainability.",
    "li is label for image patch si. This formulation is sufficient for problems where spatial situatedness of a scene is not important. However, for problems which require knowledge of neighborhood the formulation in Eq. 1 becomes inadequate. In Mnih ( 2013 ), a post-processing architecture is suggested for incorporating structure into image patch prediction. It involves stacking neural networks such that the output from previous one becomes input for the next. While improved model performance was achieved by these methods",
    "li is label for image patch si. This formulation is sufficient for problems where spatial situatedness of a scene is not important. However, for problems which require knowledge of neighborhood the formulation in Eq. 1 becomes inadequate. In Mnih ( 2013 ), a post-processing architecture is suggested for incorporating structure into image patch prediction. It involves stacking neural networks such that the output from previous one becomes input for the next. While improved model performance was achieved by these methods",
    ", 2019 ). Self-supervised methods can be used to improve depth estimation. For instance, a car 25 meters away appears smaller ( on the image plane ) than a truck 50 meters away. In this paper, we explore how we can leverage semantic information to improve monocular depth prediction in a self-supervised way. Our main contribution is a novel architecture that uses a fixed pre-defined pre-defined pre-defined pre-defined pre-defined pre-defined pre-defined pre-",
    ", 2019 ). Self-supervised methods can be used to improve depth estimation. For instance, a car 25 meters away appears smaller ( on the image plane ) than a truck 50 meters away. In this paper, we explore how we can leverage semantic information to improve monocular depth prediction in a self-supervised way. Our main contribution is a novel architecture that uses a fixed pre-defined pre-defined pre-defined pre-defined pre-defined pre-defined pre-defined pre-",
    "; general data poisoning, where both the training inputs and labels can be manipulated ; and backdoor attacks. In this paper, we propose a strategy for building classifiers that are certifiably robust to targeted data poisoning attacks. In particular, we propose a pointwise certified defense. In this paper, we consider the threat of \u201c data poisoning \u201d attacks, where a determined adversary could still cause a specific test point to be misclassified.",
    "; general data poisoning, where both the training inputs and labels can be manipulated ; and backdoor attacks. In this paper, we propose a strategy for building classifiers that are certifiably robust to targeted data poisoning attacks. In particular, we propose a pointwise certified defense. In this paper, we consider the threat of \u201c data poisoning \u201d attacks, where a determined adversary could still cause a specific test point to be misclassified.",
    "poisoning samples that are intentionally added by attackers to achieve backdoor attacks. Differential privacy has been proposed to avoid leaking any individual \u2019 s information. It is typically achieved by adding random noise, either directly to the input dataset, or to intermediate results of the aggregation mechanism. In both cases, the machine learning model is not supposed to learn from the outliers in the training dataset.",
    "poisoning samples that are intentionally added by attackers to achieve backdoor attacks. Differential privacy has been proposed to avoid leaking any individual \u2019 s information. It is typically achieved by adding random noise, either directly to the input dataset, or to intermediate results of the aggregation mechanism. In both cases, the machine learning model is not supposed to learn from the outliers in the training dataset.",
    "( Gal, 2016 ; Gal & Ghahramani, 2016 ). Regression problems arise in many real-world machine learning tasks. Many of these tasks are solved by deep neural networks used within decision making pipelines. These include : Depth from a single image ( Eigen et al., 2014 ), Object localization and Acoustic localization ( Vera-Diaz et al., 2018 ). To provide uncertainty estimation, each",
    "( Gal, 2016 ; Gal & Ghahramani, 2016 ). Regression problems arise in many real-world machine learning tasks. Many of these tasks are solved by deep neural networks used within decision making pipelines. These include : Depth from a single image ( Eigen et al., 2014 ), Object localization and Acoustic localization ( Vera-Diaz et al., 2018 ). To provide uncertainty estimation, each",
    "Symbolic computation over structured symbolic representations has long been used to formalize linguistic knowledge. BERT representations carry considerable information about grammatical structure, which, by design, is a deep and general encapsulation of linguistic information. BERT representations support the important distinction between content and form information.",
    "Symbolic computation over structured symbolic representations has long been used to formalize linguistic knowledge. BERT representations carry considerable information about grammatical structure, which, by design, is a deep and general encapsulation of linguistic information. BERT representations support the important distinction between content and form information.",
    ". This is due to the non-stationary optimization of multiple changing policies. By using recurrent policies, significant computational power, and constraints on the amount the policy is allowed to change between updates, it is possible to beat the best humans at the multi-agent game of Dota ( OpenAI, 2018 ). In this work, we propose the integration of MARL with Hierarchical Reinforcement Learning ( HRL ) to produce heterogeneous humanoid agents",
    ". This is due to the non-stationary optimization of multiple changing policies. By using recurrent policies, significant computational power, and constraints on the amount the policy is allowed to change between updates, it is possible to beat the best humans at the multi-agent game of Dota ( OpenAI, 2018 ). In this work, we propose the integration of MARL with Hierarchical Reinforcement Learning ( HRL ) to produce heterogeneous humanoid agents",
    ". When the nodes are not labeled/attributed, the spatial graph convolution only propagates information about the degree of the nodes. In addition, when the nodes are not labeled/attributed, the spatial graph convolution only propagates information about the degree of the nodes. In addition, when the nodes are not labeled/attributed, the spatial graph convolution only propagates information about the degree of the nodes. Thus, it is important to design neural",
    ". When the nodes are not labeled/attributed, the spatial graph convolution only propagates information about the degree of the nodes. In addition, when the nodes are not labeled/attributed, the spatial graph convolution only propagates information about the degree of the nodes. In addition, when the nodes are not labeled/attributed, the spatial graph convolution only propagates information about the degree of the nodes. Thus, it is important to design neural",
    ". Pooling is an expected property of pooling. Otherwise, it will destroy the shift-equivalent prior of signals. Pooling is also used to reduce spatial resolution of feature maps. Pooling is also used to reduce spatial resolution of feature maps. Pooling is also used to reduce computational and memory cost.",
    ". Pooling is an expected property of pooling. Otherwise, it will destroy the shift-equivalent prior of signals. Pooling is also used to reduce spatial resolution of feature maps. Pooling is also used to reduce spatial resolution of feature maps. Pooling is also used to reduce computational and memory cost.",
    "), and robotics control tasks ( Tobin et al., 2017 ). Deep reinforcement learning ( RL ) has been applied to various applications, including board games ( Silver et al., 2017 ), video games ( Mnih et al., 2015 ) and StarCraft ( Vinyals et al., 2015 ) ). However, deep RL agents often struggle to generalize to new environments",
    "), and robotics control tasks ( Tobin et al., 2017 ). Deep reinforcement learning ( RL ) has been applied to various applications, including board games ( Silver et al., 2017 ), video games ( Mnih et al., 2015 ) and StarCraft ( Vinyals et al., 2015 ) ). However, deep RL agents often struggle to generalize to new environments",
    ",. Similarity models can be explained by learning some feature embedding. For example, saliency maps can be used to measure saliency between two images. The interaction between the two images determines which features are more important. In addition, saliency maps can also be used to explain classification models. However, prior work on explaining similarity models has primarily focused on classification models ( e.g. ( Fong & Vedaldi, 2017b",
    ",. Similarity models can be explained by learning some feature embedding. For example, saliency maps can be used to measure saliency between two images. The interaction between the two images determines which features are more important. In addition, saliency maps can also be used to explain classification models. However, prior work on explaining similarity models has primarily focused on classification models ( e.g. ( Fong & Vedaldi, 2017b",
    ", 2018 ). 3 GENERATION. Deep generative models have obtained noticeable successes for modeling raw audio in high-fidelity speech synthesis and music generation ( van den Oord et al., 2016 ; Dieleman et al., 2018 ). 3 Flow-based models ( Kingma et al., 2016 ; Papamakarios et al., 2017 ; Huang et al., 2018 )",
    ", 2018 ). 3 GENERATION. Deep generative models have obtained noticeable successes for modeling raw audio in high-fidelity speech synthesis and music generation ( van den Oord et al., 2016 ; Dieleman et al., 2018 ). 3 Flow-based models ( Kingma et al., 2016 ; Papamakarios et al., 2017 ; Huang et al., 2018 )",
    ") and graph-level classification ( Niepert et al., 2016 ; Atwood et al., 2016 ; Hamilton et al., 2017 ). This has led to many recent advances in deep graph generative models. First, one significant limitation of the existing approaches is that most of these approaches are only suitable for small graphs with 40 or fewer nodes. Second, most of the existing deep graph generative models are unconditioned and therefore ignore rich",
    ") and graph-level classification ( Niepert et al., 2016 ; Atwood et al., 2016 ; Hamilton et al., 2017 ). This has led to many recent advances in deep graph generative models. First, one significant limitation of the existing approaches is that most of these approaches are only suitable for small graphs with 40 or fewer nodes. Second, most of the existing deep graph generative models are unconditioned and therefore ignore rich",
    "recursively parameterizes the recurrent unit. More concretely, the gating functions of our model are now parameterized repeatedly by instances of itself. To achieve the latter, we propose a new sequence model that recursively parameterizes the recurrent unit. Notably, our proposed method, Meta Gated Recursive Controller Units ( METAGROSS ), marries the benefits of recursive reasoning with recurrent models. Notably",
    "recursively parameterizes the recurrent unit. More concretely, the gating functions of our model are now parameterized repeatedly by instances of itself. To achieve the latter, we propose a new sequence model that recursively parameterizes the recurrent unit. Notably, our proposed method, Meta Gated Recursive Controller Units ( METAGROSS ), marries the benefits of recursive reasoning with recurrent models. Notably",
    "self-supervised learning framework termed local prior matching ( LPM ). Given an unlabeled utterance, the ASR model proposes multiple hypotheses. The language model provides a learning signal by evaluating the plausibility of each hypothese. Using 360 hours of additional labeled data reduces the word error rate ( WER ) by 3.8 % and 13.1 % absolute.",
    "self-supervised learning framework termed local prior matching ( LPM ). Given an unlabeled utterance, the ASR model proposes multiple hypotheses. The language model provides a learning signal by evaluating the plausibility of each hypothese. Using 360 hours of additional labeled data reduces the word error rate ( WER ) by 3.8 % and 13.1 % absolute.",
    "fairness. As machine learning becomes widespread in the Software 2.0 era ( Karpathy, 2017 ), there is an urgent need to address the issues of fairness and robustness. As machine learning becomes widespread in the Software 2.0 era ( Karpathy, 2017 ), there is an urgent need to address the issues of fairness and robustness. As machine learning becomes widespread in the Software 2.0 era ( Karpathy, 2017 ), there is an urgent need to address the issues of fair",
    "fairness. As machine learning becomes widespread in the Software 2.0 era ( Karpathy, 2017 ), there is an urgent need to address the issues of fairness and robustness. As machine learning becomes widespread in the Software 2.0 era ( Karpathy, 2017 ), there is an urgent need to address the issues of fairness and robustness. As machine learning becomes widespread in the Software 2.0 era ( Karpathy, 2017 ), there is an urgent need to address the issues of fair",
    ". On another front, machine learning and physics simulation have been connecting machine learning and physics simulation. On one front, machine learning and physics simulation have been connecting machine learning and physics simulation. The two main challenges : to build effective convolution stencils and to evolve learned nonlinear features ( Qi et al., 2016a ; xingzhe.he @ rutgers.edu ). The two main challenges : to build effective convolution",
    ". On another front, machine learning and physics simulation have been connecting machine learning and physics simulation. On one front, machine learning and physics simulation have been connecting machine learning and physics simulation. The two main challenges : to build effective convolution stencils and to evolve learned nonlinear features ( Qi et al., 2016a ; xingzhe.he @ rutgers.edu ). The two main challenges : to build effective convolution",
    ", 2018 ; Gehring et al., 2017 ; Merity et al., 2018 ). In this paper, we propose a new lens with which to study gradient clipping. Robustness : intuitively, clipping the gradient prevents over-confident descent steps, which is plausibly beneficial in the presence of noise. In this paper, we explore whether gradient clipping can mitigate the problem of label noise in classification, which has",
    ", 2018 ; Gehring et al., 2017 ; Merity et al., 2018 ). In this paper, we propose a new lens with which to study gradient clipping. Robustness : intuitively, clipping the gradient prevents over-confident descent steps, which is plausibly beneficial in the presence of noise. In this paper, we explore whether gradient clipping can mitigate the problem of label noise in classification, which has",
    "inverse reinforcement learning ( IRL ) and behavior cloning ( Ross et al., 2011b ) are the recently proposed IRL-based methods. they use a GAN-based reward function to align the distribution of stateaction pairs between the expert and the imitator.",
    "inverse reinforcement learning ( IRL ) and behavior cloning ( Ross et al., 2011b ) are the recently proposed IRL-based methods. they use a GAN-based reward function to align the distribution of stateaction pairs between the expert and the imitator.",
    "AdaBoost performs a gradient descent in functional space. Friedman ( 2001 ) went on to define a general statistical framework for training boosting-like classifiers and regressors using arbitrary loss functions. Boosting, along with deep learning, has been a very successful machine learning technique that consistently outperforms other methods on numerous data science challenges.",
    "AdaBoost performs a gradient descent in functional space. Friedman ( 2001 ) went on to define a general statistical framework for training boosting-like classifiers and regressors using arbitrary loss functions. Boosting, along with deep learning, has been a very successful machine learning technique that consistently outperforms other methods on numerous data science challenges.",
    "an error rate of 2.57 % on CIFAR10, and a state-of-the-art top-1 error rate of 24.2 % on ImageNet ( under the mobile setting ) using 3.8 GPU-days for search. Previously, DARTS provided a fast solution in finding effective network architectures, but suffered from large memory and computing overheads. In this paper, we present a novel approach, namely, Partially-Connected DART",
    "an error rate of 2.57 % on CIFAR10, and a state-of-the-art top-1 error rate of 24.2 % on ImageNet ( under the mobile setting ) using 3.8 GPU-days for search. Previously, DARTS provided a fast solution in finding effective network architectures, but suffered from large memory and computing overheads. In this paper, we present a novel approach, namely, Partially-Connected DART",
    ". Second, in order to be generally applicable to any model-free environment, underlying dynamical gradients are not used. Third, in order to be generally applicable to any model-free environment, underlying dynamical gradients are not used. In other words, valuable information that could greatly aid control tasks is not taken advantage of in these schemes. In recent years, deep reinforcement learning ( DRL ) has emerged as a flexible and robust means of teaching simulated robots to complete complex",
    ". Second, in order to be generally applicable to any model-free environment, underlying dynamical gradients are not used. Third, in order to be generally applicable to any model-free environment, underlying dynamical gradients are not used. In other words, valuable information that could greatly aid control tasks is not taken advantage of in these schemes. In recent years, deep reinforcement learning ( DRL ) has emerged as a flexible and robust means of teaching simulated robots to complete complex",
    "a task-agnostic abstraction in the form of a world graph. World graph nodes are waypoint states, a set of salient states that can summarize agent trajectories. Intuitively, an agent could learn more efficiently by focusing its exploration in task-relevant regions. In the task-agnostic phase, we obtain world graphs by training a recurrent variational auto-encoder ( VAE ) with binary latent variables",
    "a task-agnostic abstraction in the form of a world graph. World graph nodes are waypoint states, a set of salient states that can summarize agent trajectories. Intuitively, an agent could learn more efficiently by focusing its exploration in task-relevant regions. In the task-agnostic phase, we obtain world graphs by training a recurrent variational auto-encoder ( VAE ) with binary latent variables",
    ". Deep learning has allowed us to approximate various functions in regression tasks. This can cause large errors when certain data are used. Third, deep learning approximates the target function and does not reveal the actual design and architecture of the device. Our WBN is different from the normal neural network because the model architecture is discretized. Because discretization is interpretable ( Chen et al., 2016 ), our WBN can reconstruct the target function.",
    ". Deep learning has allowed us to approximate various functions in regression tasks. This can cause large errors when certain data are used. Third, deep learning approximates the target function and does not reveal the actual design and architecture of the device. Our WBN is different from the normal neural network because the model architecture is discretized. Because discretization is interpretable ( Chen et al., 2016 ), our WBN can reconstruct the target function.",
    "the task itself must be specified in a form that the RL algorithm can interpret and optimize. These challenges prompt us to consider whether there might exist a general method for learning behaviors without the algorithmic complexities and optimization challenges of RL. Imitation learning is an alternative paradigm to RL that provides a simple and straightforward approach for training control policies. Moreover, imitation learning methods require an expert demonstrator \u2013 typically a human \u2013 to provide a number of demonstrations of optimal behavior.",
    "the task itself must be specified in a form that the RL algorithm can interpret and optimize. These challenges prompt us to consider whether there might exist a general method for learning behaviors without the algorithmic complexities and optimization challenges of RL. Imitation learning is an alternative paradigm to RL that provides a simple and straightforward approach for training control policies. Moreover, imitation learning methods require an expert demonstrator \u2013 typically a human \u2013 to provide a number of demonstrations of optimal behavior.",
    ". For asynchronous training, the global updates at the server are blocked until all the workers respond. For asynchronous training, the global updates are updated as soon as a new gradient is received from any worker. In this paper, we focus on asynchronous training. Synchronous and asynchronous training are the two most common paradigms of distributed machine learning. Byzantine failures are well-studied for the distributed systems ( Lamport et al., 1982a",
    ". For asynchronous training, the global updates at the server are blocked until all the workers respond. For asynchronous training, the global updates are updated as soon as a new gradient is received from any worker. In this paper, we focus on asynchronous training. Synchronous and asynchronous training are the two most common paradigms of distributed machine learning. Byzantine failures are well-studied for the distributed systems ( Lamport et al., 1982a",
    "\u201c unrestricted \u201d perturbations that manipulate semantically meaningful image-based visual descriptors \u2013 color and texture \u2013 in order to generate effective and photorealistic adversarial examples. In addition, we conduct comprehensive user studies to show that our generated semantic adversarial examples are photorealistic to humans despite large magnitude perturbations.",
    "\u201c unrestricted \u201d perturbations that manipulate semantically meaningful image-based visual descriptors \u2013 color and texture \u2013 in order to generate effective and photorealistic adversarial examples. In addition, we conduct comprehensive user studies to show that our generated semantic adversarial examples are photorealistic to humans despite large magnitude perturbations.",
    "humans excel in continuously learning with small data without forgetting how to solve old problems. However, neural networks require large datasets to compute latent representations across different tasks. Our approach is named Learning to Control ( LTC ) and allows few-shot learning with two degrees of memory plasticity. We experimentally show that our system obtains accurate results for few-shot learning of entity recognition in the Stanford Task-Oriented Dialogue dataset.",
    "humans excel in continuously learning with small data without forgetting how to solve old problems. However, neural networks require large datasets to compute latent representations across different tasks. Our approach is named Learning to Control ( LTC ) and allows few-shot learning with two degrees of memory plasticity. We experimentally show that our system obtains accurate results for few-shot learning of entity recognition in the Stanford Task-Oriented Dialogue dataset.",
    "humans excel in continuously learning with small data without forgetting how to solve old problems. However, neural networks require large datasets to compute latent representations across different tasks. Our approach is named Learning to Control ( LTC ) and allows few-shot learning with two degrees of memory plasticity. We experimentally show that our system obtains accurate results for few-shot learning of entity recognition in the Stanford Task-Oriented Dialogue dataset.",
    "Agrawal et al., 2016 ; Pinto et al., 2016 ; Levine et al., 2016 ). However, we humans are adept at a variety of basic manipulation skills e.g. picking, pushing, grasping etc.. We can begin by not treating these tasks independently, but by building similar unified manipulation systems. One such commonality relates to the low and mid-level motor programs executed to accomplish the",
    "Agrawal et al., 2016 ; Pinto et al., 2016 ; Levine et al., 2016 ). However, we humans are adept at a variety of basic manipulation skills e.g. picking, pushing, grasping etc.. We can begin by not treating these tasks independently, but by building similar unified manipulation systems. One such commonality relates to the low and mid-level motor programs executed to accomplish the",
    "Agrawal et al., 2016 ; Pinto et al., 2016 ; Levine et al., 2016 ). However, we humans are adept at a variety of basic manipulation skills e.g. picking, pushing, grasping etc.. We can begin by not treating these tasks independently, but by building similar unified manipulation systems. One such commonality relates to the low and mid-level motor programs executed to accomplish the",
    ". In this paper, we propose a general algorithm for near-optimal test-time performance in a family of environments where differences in dynamics can be ascertained early during an episode. Our approach combines the advantages of robust transfer and adaptation-based transfer in reinforcement learning ( RL ). As a first step to address single episode transfer in reinforcement learning ( RL ), we propose a general algorithm for near-optimal test-time performance in a family of environments where differences in dynamics",
    ". In this paper, we propose a general algorithm for near-optimal test-time performance in a family of environments where differences in dynamics can be ascertained early during an episode. Our approach combines the advantages of robust transfer and adaptation-based transfer in reinforcement learning ( RL ). As a first step to address single episode transfer in reinforcement learning ( RL ), we propose a general algorithm for near-optimal test-time performance in a family of environments where differences in dynamics",
    ". In this paper, we propose a general algorithm for near-optimal test-time performance in a family of environments where differences in dynamics can be ascertained early during an episode. Our approach combines the advantages of robust transfer and adaptation-based transfer in reinforcement learning ( RL ). As a first step to address single episode transfer in reinforcement learning ( RL ), we propose a general algorithm for near-optimal test-time performance in a family of environments where differences in dynamics",
    ", and AlphaGo ( Silver et al., 2017b ), and AlphaZero ( Silver et al., 2017b ), represent a result of continual effort from two lines of research directions. The combination of both learning and search techniques dates back to Samuel \u2019 s studies in checkers ( Samuel, 1959 ), where two learning methods, rote learning and generalization learning, were studied and integrated into a look-ahead",
    ", and AlphaGo ( Silver et al., 2017b ), and AlphaZero ( Silver et al., 2017b ), represent a result of continual effort from two lines of research directions. The combination of both learning and search techniques dates back to Samuel \u2019 s studies in checkers ( Samuel, 1959 ), where two learning methods, rote learning and generalization learning, were studied and integrated into a look-ahead",
    ", and AlphaGo ( Silver et al., 2017b ), and AlphaZero ( Silver et al., 2017b ), represent a result of continual effort from two lines of research directions. The combination of both learning and search techniques dates back to Samuel \u2019 s studies in checkers ( Samuel, 1959 ), where two learning methods, rote learning and generalization learning, were studied and integrated into a look-ahead",
    "lack of principled mechanisms to quickly and efficiently transfer policies learned between domains has become the major bottleneck in Reinforcement Learning ( RL). Since RL agents can not quickly transfer policies, the agent is forced to learn every task from scratch. Since RL agents can not quickly transfer policies, the agent is forced to learn every task from scratch. Since RL agents can not quickly transfer policies, the agent is forced to learn every task from scratch.",
    "lack of principled mechanisms to quickly and efficiently transfer policies learned between domains has become the major bottleneck in Reinforcement Learning ( RL). Since RL agents can not quickly transfer policies, the agent is forced to learn every task from scratch. Since RL agents can not quickly transfer policies, the agent is forced to learn every task from scratch. Since RL agents can not quickly transfer policies, the agent is forced to learn every task from scratch.",
    "lack of principled mechanisms to quickly and efficiently transfer policies learned between domains has become the major bottleneck in Reinforcement Learning ( RL). Since RL agents can not quickly transfer policies, the agent is forced to learn every task from scratch. Since RL agents can not quickly transfer policies, the agent is forced to learn every task from scratch. Since RL agents can not quickly transfer policies, the agent is forced to learn every task from scratch.",
    ". Scale transformations occur in many image and video analysis tasks. These transformations can reach factors of 10 or more. CNNs demonstrate state-of-the-art performance in a wide range of tasks. However, they do not have a particular mechanism for dealing with scale changes.",
    ". Scale transformations occur in many image and video analysis tasks. These transformations can reach factors of 10 or more. CNNs demonstrate state-of-the-art performance in a wide range of tasks. However, they do not have a particular mechanism for dealing with scale changes.",
    ". Scale transformations occur in many image and video analysis tasks. These transformations can reach factors of 10 or more. CNNs demonstrate state-of-the-art performance in a wide range of tasks. However, they do not have a particular mechanism for dealing with scale changes.",
    ", e.g., ShapeNet Dai et al. ( 2017a ; Chang et al. ( 2015 ) ). In this work, we propose an unpaired point-based scan completion method that can be trained without requiring explicit correspondence between partial point sets ( e.g., raw scans ) and example complete shape models ( e.g., synthetic models ). Note that the network does not require explicit examples of real complete",
    ", e.g., ShapeNet Dai et al. ( 2017a ; Chang et al. ( 2015 ) ). In this work, we propose an unpaired point-based scan completion method that can be trained without requiring explicit correspondence between partial point sets ( e.g., raw scans ) and example complete shape models ( e.g., synthetic models ). Note that the network does not require explicit examples of real complete",
    ", e.g., ShapeNet Dai et al. ( 2017a ; Chang et al. ( 2015 ) ). In this work, we propose an unpaired point-based scan completion method that can be trained without requiring explicit correspondence between partial point sets ( e.g., raw scans ) and example complete shape models ( e.g., synthetic models ). Note that the network does not require explicit examples of real complete",
    "GANs can be used to generate \u201c normal \u201d looking data instances. The latter is a new form of a man-in-the-middle attack. Our goal is to construct a theoretical framework for studying the security risk arising from generative models and explore its practical implications. Specifically, we cast the authentication setting as a two-player maximin game ( authenticator vs. attacker ) where all observations are finite.",
    "GANs can be used to generate \u201c normal \u201d looking data instances. The latter is a new form of a man-in-the-middle attack. Our goal is to construct a theoretical framework for studying the security risk arising from generative models and explore its practical implications. Specifically, we cast the authentication setting as a two-player maximin game ( authenticator vs. attacker ) where all observations are finite.",
    "GANs can be used to generate \u201c normal \u201d looking data instances. The latter is a new form of a man-in-the-middle attack. Our goal is to construct a theoretical framework for studying the security risk arising from generative models and explore its practical implications. Specifically, we cast the authentication setting as a two-player maximin game ( authenticator vs. attacker ) where all observations are finite.",
    "an adversarial risk of adversarial perturbations. Let ( X, y )  X  Y be from some unknown distribution PX, Y. Madry et al. ( 2017 ) formalize the adversarial learning against this class of perturbations as a minimization problem of adversarial risk defined in a following way. Second, it costs natural accuracy. A network trained with adversarial examples tends to have a higher",
    "an adversarial risk of adversarial perturbations. Let ( X, y )  X  Y be from some unknown distribution PX, Y. Madry et al. ( 2017 ) formalize the adversarial learning against this class of perturbations as a minimization problem of adversarial risk defined in a following way. Second, it costs natural accuracy. A network trained with adversarial examples tends to have a higher",
    "an adversarial risk of adversarial perturbations. Let ( X, y )  X  Y be from some unknown distribution PX, Y. Madry et al. ( 2017 ) formalize the adversarial learning against this class of perturbations as a minimization problem of adversarial risk defined in a following way. Second, it costs natural accuracy. A network trained with adversarial examples tends to have a higher",
    "distinguish the feature map distributions of different networks. We train multiple networks simultaneously by employing discriminators to distinguish the feature map distributions of different networks. We have applied our method to various network architectures on the classification task and discovered a significant improvement of performance. In this paper, we propose an online knowledge distillation method that transfers not only the knowledge of the class probabilities but also that of the feature map distribution. We train multiple networks simultaneously by employing discriminators to distinguish the feature map distributions of different networks",
    "distinguish the feature map distributions of different networks. We train multiple networks simultaneously by employing discriminators to distinguish the feature map distributions of different networks. We have applied our method to various network architectures on the classification task and discovered a significant improvement of performance. In this paper, we propose an online knowledge distillation method that transfers not only the knowledge of the class probabilities but also that of the feature map distribution. We train multiple networks simultaneously by employing discriminators to distinguish the feature map distributions of different networks",
    "distinguish the feature map distributions of different networks. We train multiple networks simultaneously by employing discriminators to distinguish the feature map distributions of different networks. We have applied our method to various network architectures on the classification task and discovered a significant improvement of performance. In this paper, we propose an online knowledge distillation method that transfers not only the knowledge of the class probabilities but also that of the feature map distribution. We train multiple networks simultaneously by employing discriminators to distinguish the feature map distributions of different networks",
    ". Besides, the pre-trained word embeddings still hold a great promise in handling complicated natural language processing tasks. In this way, the pre-trained word embeddings still hold a great promise in handling complicated natural language processing tasks. In this way, the pre-trained word embeddings still hold a great promise in handling complicated natural language processing tasks. In this way, the pre-trained word embeddings still hold a great promise",
    ". Besides, the pre-trained word embeddings still hold a great promise in handling complicated natural language processing tasks. In this way, the pre-trained word embeddings still hold a great promise in handling complicated natural language processing tasks. In this way, the pre-trained word embeddings still hold a great promise in handling complicated natural language processing tasks. In this way, the pre-trained word embeddings still hold a great promise",
    ". Besides, the pre-trained word embeddings still hold a great promise in handling complicated natural language processing tasks. In this way, the pre-trained word embeddings still hold a great promise in handling complicated natural language processing tasks. In this way, the pre-trained word embeddings still hold a great promise in handling complicated natural language processing tasks. In this way, the pre-trained word embeddings still hold a great promise",
    "difficult to train a DNN robustly even when noisy labels exist in the training data. In particular, Zhang et al. ( 2017 ) empirically proved that training on such small-loss training samples yields a much better generalization performance. In particular, Zhang et al. ( 2017 ) empirically proved that training on such small-loss samples yields a much better generalization performance. In particular, Song et al. ( 2019 )",
    "difficult to train a DNN robustly even when noisy labels exist in the training data. In particular, Zhang et al. ( 2017 ) empirically proved that training on such small-loss training samples yields a much better generalization performance. In particular, Zhang et al. ( 2017 ) empirically proved that training on such small-loss samples yields a much better generalization performance. In particular, Song et al. ( 2019 )",
    "difficult to train a DNN robustly even when noisy labels exist in the training data. In particular, Zhang et al. ( 2017 ) empirically proved that training on such small-loss training samples yields a much better generalization performance. In particular, Zhang et al. ( 2017 ) empirically proved that training on such small-loss samples yields a much better generalization performance. In particular, Song et al. ( 2019 )",
    "an unseen sponge for a known task of cleaning the table. Later during cooking, you can select that sponge since you can relate its absorbing characteristics with another tool you have used for cleaning. In this case, you can select that sponge since you can relate its absorbing characteristics with another tool you have used for cleaning. Hence, the primary challenge is to develop a generalizable unsupervised learning method which can extract an action \u2019 s characteristics from a dataset constituting its diverse effects",
    "an unseen sponge for a known task of cleaning the table. Later during cooking, you can select that sponge since you can relate its absorbing characteristics with another tool you have used for cleaning. In this case, you can select that sponge since you can relate its absorbing characteristics with another tool you have used for cleaning. Hence, the primary challenge is to develop a generalizable unsupervised learning method which can extract an action \u2019 s characteristics from a dataset constituting its diverse effects",
    "an unseen sponge for a known task of cleaning the table. Later during cooking, you can select that sponge since you can relate its absorbing characteristics with another tool you have used for cleaning. In this case, you can select that sponge since you can relate its absorbing characteristics with another tool you have used for cleaning. Hence, the primary challenge is to develop a generalizable unsupervised learning method which can extract an action \u2019 s characteristics from a dataset constituting its diverse effects",
    "p, not d, is used to represent words. The embedding matrix is a substantial, often dominating, part of the parameter space of a learning model. Modern deep learning approaches for natural language processing ( NLP ) often rely on vector representation of words to convert discrete space of human language into continuous space best suited for further processing. d  p embedding matrix can be trained on large text corpora to capture the semantic relationship between words.",
    "p, not d, is used to represent words. The embedding matrix is a substantial, often dominating, part of the parameter space of a learning model. Modern deep learning approaches for natural language processing ( NLP ) often rely on vector representation of words to convert discrete space of human language into continuous space best suited for further processing. d  p embedding matrix can be trained on large text corpora to capture the semantic relationship between words.",
    "p, not d, is used to represent words. The embedding matrix is a substantial, often dominating, part of the parameter space of a learning model. Modern deep learning approaches for natural language processing ( NLP ) often rely on vector representation of words to convert discrete space of human language into continuous space best suited for further processing. d  p embedding matrix can be trained on large text corpora to capture the semantic relationship between words.",
    "reinforcement learning ( RL ) has critical shortcomings when reward signals are sparse or interactions with the environment are expensive. In this paper, we focus on Imitation Learning ( IL ), wherein the goal is to learn a policy from a dataset of demonstrations, possibly coming from a human, another artificial system, or a collection of different entities. BRIL is inspired by Quality-Diversity ( QD ) algorithms ( Pugh et al.",
    "reinforcement learning ( RL ) has critical shortcomings when reward signals are sparse or interactions with the environment are expensive. In this paper, we focus on Imitation Learning ( IL ), wherein the goal is to learn a policy from a dataset of demonstrations, possibly coming from a human, another artificial system, or a collection of different entities. BRIL is inspired by Quality-Diversity ( QD ) algorithms ( Pugh et al.",
    "reinforcement learning ( RL ) has critical shortcomings when reward signals are sparse or interactions with the environment are expensive. In this paper, we focus on Imitation Learning ( IL ), wherein the goal is to learn a policy from a dataset of demonstrations, possibly coming from a human, another artificial system, or a collection of different entities. BRIL is inspired by Quality-Diversity ( QD ) algorithms ( Pugh et al.",
    "the  lottery ticket hypothesis '' by Frankle & Carbin ( 2018 ). The lottery ticket hypothesis is based on the  lottery ticket hypothesis '' by Frankle & Carbin ( 2019 ). The lottery ticket hypothesis is based on the  lottery ticket hypothesis '' by Zhou et al. ( 2019 ). The lottery ticket hypothesis is based on the  lottery ticket hypothesis '' by Frankle & Carbin ( 2018 )",
    "the  lottery ticket hypothesis '' by Frankle & Carbin ( 2018 ). The lottery ticket hypothesis is based on the  lottery ticket hypothesis '' by Frankle & Carbin ( 2019 ). The lottery ticket hypothesis is based on the  lottery ticket hypothesis '' by Zhou et al. ( 2019 ). The lottery ticket hypothesis is based on the  lottery ticket hypothesis '' by Frankle & Carbin ( 2018 )",
    "the  lottery ticket hypothesis '' by Frankle & Carbin ( 2018 ). The lottery ticket hypothesis is based on the  lottery ticket hypothesis '' by Frankle & Carbin ( 2019 ). The lottery ticket hypothesis is based on the  lottery ticket hypothesis '' by Zhou et al. ( 2019 ). The lottery ticket hypothesis is based on the  lottery ticket hypothesis '' by Frankle & Carbin ( 2018 )",
    "a seizure detector that classifies patients into different types of seizures based on EEG signals collected during clinical observation of 4,000 patients. When deployed, the CNN classifier may encounter patients who have types of seizures that do not exist in the training data because they are rare or even unknown by the medical community. Ideally, the unknowns would be recognized and rejected by the classifier. In this work, we describe a deep neural network that not only accurately classifies test objects into known target classes,",
    "a seizure detector that classifies patients into different types of seizures based on EEG signals collected during clinical observation of 4,000 patients. When deployed, the CNN classifier may encounter patients who have types of seizures that do not exist in the training data because they are rare or even unknown by the medical community. Ideally, the unknowns would be recognized and rejected by the classifier. In this work, we describe a deep neural network that not only accurately classifies test objects into known target classes,",
    "a seizure detector that classifies patients into different types of seizures based on EEG signals collected during clinical observation of 4,000 patients. When deployed, the CNN classifier may encounter patients who have types of seizures that do not exist in the training data because they are rare or even unknown by the medical community. Ideally, the unknowns would be recognized and rejected by the classifier. In this work, we describe a deep neural network that not only accurately classifies test objects into known target classes,",
    "Bayesian inference provides a principled approach to capturing model uncertainty. This paper describes a novel method for training highly flexible posterior approximations. The idea is to start with a coarse, mean-field approximation q ( w ) and make iterative, local refinements to it. The model parameters q ( w ) are expressed using a number of additive auxiliary variables ak ( k ). The regions of the local refinements",
    "Bayesian inference provides a principled approach to capturing model uncertainty. This paper describes a novel method for training highly flexible posterior approximations. The idea is to start with a coarse, mean-field approximation q ( w ) and make iterative, local refinements to it. The model parameters q ( w ) are expressed using a number of additive auxiliary variables ak ( k ). The regions of the local refinements",
    "Bayesian inference provides a principled approach to capturing model uncertainty. This paper describes a novel method for training highly flexible posterior approximations. The idea is to start with a coarse, mean-field approximation q ( w ) and make iterative, local refinements to it. The model parameters q ( w ) are expressed using a number of additive auxiliary variables ak ( k ). The regions of the local refinements",
    ". During training, ground truth tokens are used as inputs. During generation, the decoder generates categorical tokens in a consecutive manner. During training, ground truth tokens are used as inputs. During generation, the decoder generates categorical tokens in a consecutive manner. Moreover, for many scenarios in task-oriented dialogue ( Williams & Young, 2007 ), only the final rewards are available.",
    ". During training, ground truth tokens are used as inputs. During generation, the decoder generates categorical tokens in a consecutive manner. During training, ground truth tokens are used as inputs. During generation, the decoder generates categorical tokens in a consecutive manner. Moreover, for many scenarios in task-oriented dialogue ( Williams & Young, 2007 ), only the final rewards are available.",
    ". During training, ground truth tokens are used as inputs. During generation, the decoder generates categorical tokens in a consecutive manner. During training, ground truth tokens are used as inputs. During generation, the decoder generates categorical tokens in a consecutive manner. Moreover, for many scenarios in task-oriented dialogue ( Williams & Young, 2007 ), only the final rewards are available.",
    "goal recognition based on the observations of the behaviors collected online has been used to model some potential applications. In this paper, we propose the stochastic goal recognition control ( S-GRC ) problem with two main stages : ( 1 ) deceptive opponent modeling based on maximum entropy regularized Markov decision processes ( MDPs ) and ( 2 ) goal recognition control under proactively static interdiction. In this paper, we empirically demonstrate that our proposed approach control the goal recognition",
    "goal recognition based on the observations of the behaviors collected online has been used to model some potential applications. In this paper, we propose the stochastic goal recognition control ( S-GRC ) problem with two main stages : ( 1 ) deceptive opponent modeling based on maximum entropy regularized Markov decision processes ( MDPs ) and ( 2 ) goal recognition control under proactively static interdiction. In this paper, we empirically demonstrate that our proposed approach control the goal recognition",
    "goal recognition based on the observations of the behaviors collected online has been used to model some potential applications. In this paper, we propose the stochastic goal recognition control ( S-GRC ) problem with two main stages : ( 1 ) deceptive opponent modeling based on maximum entropy regularized Markov decision processes ( MDPs ) and ( 2 ) goal recognition control under proactively static interdiction. In this paper, we empirically demonstrate that our proposed approach control the goal recognition",
    "), domain transfer learning ( Zhu et al., 2017 ; Zhang et al., 2017 ), and domain transfer learning ( Isola et al., 2017 ). Recently, Brock et al. ( 2018 ) significantly improved the results of Zhang et al. ( 2017 ) by making the batch eight times larger. In fact, the results of Brock et al. ( 2018 ) suggest",
    "), domain transfer learning ( Zhu et al., 2017 ; Zhang et al., 2017 ), and domain transfer learning ( Isola et al., 2017 ). Recently, Brock et al. ( 2018 ) significantly improved the results of Zhang et al. ( 2017 ) by making the batch eight times larger. In fact, the results of Brock et al. ( 2018 ) suggest",
    "), domain transfer learning ( Zhu et al., 2017 ; Zhang et al., 2017 ), and domain transfer learning ( Isola et al., 2017 ). Recently, Brock et al. ( 2018 ) significantly improved the results of Zhang et al. ( 2017 ) by making the batch eight times larger. In fact, the results of Brock et al. ( 2018 ) suggest",
    "in this work, we aim to answer this question by measuring artificial recurrent neural networks \u2019 ( RNNs ) capacity to compress the past while retaining relevant information about the future. Intriguingly, certain biological neurons extract representations that efficiently capture the predictive information in sequential stimuli. in Palmer et al. ( 2015 ), spiking responses of neurons in salamander retina had near optimal mutual information with the future states of sequential stimuli they were exposed to.",
    "in this work, we aim to answer this question by measuring artificial recurrent neural networks \u2019 ( RNNs ) capacity to compress the past while retaining relevant information about the future. Intriguingly, certain biological neurons extract representations that efficiently capture the predictive information in sequential stimuli. in Palmer et al. ( 2015 ), spiking responses of neurons in salamander retina had near optimal mutual information with the future states of sequential stimuli they were exposed to.",
    "in this work, we aim to answer this question by measuring artificial recurrent neural networks \u2019 ( RNNs ) capacity to compress the past while retaining relevant information about the future. Intriguingly, certain biological neurons extract representations that efficiently capture the predictive information in sequential stimuli. in Palmer et al. ( 2015 ), spiking responses of neurons in salamander retina had near optimal mutual information with the future states of sequential stimuli they were exposed to.",
    ". Q-learning lies at the heart of many of the recent successes of deep reinforcement learning ( RL ) ( Watkins & Dayan, 1992 ; Sutton & Barto, 2018 ). Despite these successes, many properties of deep Q-learning are poorly understood. When combined with function approximation, Q-learning can become unstable. To handle delusional bias, the authors propose a policy-consistent backup operator that maintains multiple Q-",
    ". Q-learning lies at the heart of many of the recent successes of deep reinforcement learning ( RL ) ( Watkins & Dayan, 1992 ; Sutton & Barto, 2018 ). Despite these successes, many properties of deep Q-learning are poorly understood. When combined with function approximation, Q-learning can become unstable. To handle delusional bias, the authors propose a policy-consistent backup operator that maintains multiple Q-",
    ". Q-learning lies at the heart of many of the recent successes of deep reinforcement learning ( RL ) ( Watkins & Dayan, 1992 ; Sutton & Barto, 2018 ). Despite these successes, many properties of deep Q-learning are poorly understood. When combined with function approximation, Q-learning can become unstable. To handle delusional bias, the authors propose a policy-consistent backup operator that maintains multiple Q-",
    "unsupervised object-oriented scene representation can be categorized into two types : scene-mixture models and spatial-attention models. In scenemixture models, a finite number of component images are mixed together. Since each component corresponds to a full-scale image, important physical features of objects like position and scale are only implicitly encoded in the scale of a full-scale image. in spatial-attention models, the resulting component representation is not necessarily a representation of a local area",
    "unsupervised object-oriented scene representation can be categorized into two types : scene-mixture models and spatial-attention models. In scenemixture models, a finite number of component images are mixed together. Since each component corresponds to a full-scale image, important physical features of objects like position and scale are only implicitly encoded in the scale of a full-scale image. in spatial-attention models, the resulting component representation is not necessarily a representation of a local area",
    "unsupervised object-oriented scene representation can be categorized into two types : scene-mixture models and spatial-attention models. In scenemixture models, a finite number of component images are mixed together. Since each component corresponds to a full-scale image, important physical features of objects like position and scale are only implicitly encoded in the scale of a full-scale image. in spatial-attention models, the resulting component representation is not necessarily a representation of a local area",
    ". Several recent methods ( Howard et al. ( 2017 ) ) based on depthwise separable convolution show reasonable performance in terms of compression and computation reduction. However, their accuracy is not sufficient compared to that of standard-convolution-based models. In this paper, we propose FALCON, an accurate and lightweight method for compressing CNN.",
    ". Several recent methods ( Howard et al. ( 2017 ) ) based on depthwise separable convolution show reasonable performance in terms of compression and computation reduction. However, their accuracy is not sufficient compared to that of standard-convolution-based models. In this paper, we propose FALCON, an accurate and lightweight method for compressing CNN.",
    ". Several recent methods ( Howard et al. ( 2017 ) ) based on depthwise separable convolution show reasonable performance in terms of compression and computation reduction. However, their accuracy is not sufficient compared to that of standard-convolution-based models. In this paper, we propose FALCON, an accurate and lightweight method for compressing CNN.",
    ". In short, normalization layers make neural networks train faster and generalize better. In short, normalization layers make neural networks train faster and generalize better. In short, normalization layers make neural networks train faster and generalize better. In this work, we identify four techniques that everyone should know to improve their usage of Batch Normalization. Among them : Batch Normalization, Batch Normalization, Batch Normalization, Batch Normalization, Batch Normalization, Batch Normalization",
    ". In short, normalization layers make neural networks train faster and generalize better. In short, normalization layers make neural networks train faster and generalize better. In short, normalization layers make neural networks train faster and generalize better. In this work, we identify four techniques that everyone should know to improve their usage of Batch Normalization. Among them : Batch Normalization, Batch Normalization, Batch Normalization, Batch Normalization, Batch Normalization, Batch Normalization",
    ". In short, normalization layers make neural networks train faster and generalize better. In short, normalization layers make neural networks train faster and generalize better. In short, normalization layers make neural networks train faster and generalize better. In this work, we identify four techniques that everyone should know to improve their usage of Batch Normalization. Among them : Batch Normalization, Batch Normalization, Batch Normalization, Batch Normalization, Batch Normalization, Batch Normalization",
    "privacy-sensitive data. But in other settings\u2014including federated learning ( FL ), the data can not be inspected. This paper combines ideas from deep generative models, FL, and user-level differential privacy ( DP ). Our contributions include : \u2022 Identifying key privacy-sensitive data. \u2022 Identifying key privacy-sensitive data. \u2022 Identifying key privacy-sensitive data. \u2022 Identifying key privacy-sensitive data. \u2022 Identifying",
    "privacy-sensitive data. But in other settings\u2014including federated learning ( FL ), the data can not be inspected. This paper combines ideas from deep generative models, FL, and user-level differential privacy ( DP ). Our contributions include : \u2022 Identifying key privacy-sensitive data. \u2022 Identifying key privacy-sensitive data. \u2022 Identifying key privacy-sensitive data. \u2022 Identifying key privacy-sensitive data. \u2022 Identifying",
    "privacy-sensitive data. But in other settings\u2014including federated learning ( FL ), the data can not be inspected. This paper combines ideas from deep generative models, FL, and user-level differential privacy ( DP ). Our contributions include : \u2022 Identifying key privacy-sensitive data. \u2022 Identifying key privacy-sensitive data. \u2022 Identifying key privacy-sensitive data. \u2022 Identifying key privacy-sensitive data. \u2022 Identifying",
    "a policy for a physical simulator. In this paper, we take a step toward generating long-range, diverse and physically plausible motion sequences given starting and ending states. Meanwhile, we expect the model could generate novel behaviour. This has several valuable applications : ( 1 ) Synthesised vivid motion for animation production without excessive human labor. ( 2 ) Generated novel behaviours for player customization of action skills in video games. ( 3 ) Generated novel behaviours for player",
    "a policy for a physical simulator. In this paper, we take a step toward generating long-range, diverse and physically plausible motion sequences given starting and ending states. Meanwhile, we expect the model could generate novel behaviour. This has several valuable applications : ( 1 ) Synthesised vivid motion for animation production without excessive human labor. ( 2 ) Generated novel behaviours for player customization of action skills in video games. ( 3 ) Generated novel behaviours for player",
    "a policy for a physical simulator. In this paper, we take a step toward generating long-range, diverse and physically plausible motion sequences given starting and ending states. Meanwhile, we expect the model could generate novel behaviour. This has several valuable applications : ( 1 ) Synthesised vivid motion for animation production without excessive human labor. ( 2 ) Generated novel behaviours for player customization of action skills in video games. ( 3 ) Generated novel behaviours for player",
    ", 2019a ; Guidotti et al., 2018 ). However, interpretability of model predictions has always been a limiting factor for use cases that require explanations of the features involved in modeling. Towards post-hoc explanation, a major line of work, additive feature attribution methods ( additive feature attribution ) ( Murdoch et al., 2018 ), explain a model prediction by assigning importance scores to individual input variables.",
    ", 2019a ; Guidotti et al., 2018 ). However, interpretability of model predictions has always been a limiting factor for use cases that require explanations of the features involved in modeling. Towards post-hoc explanation, a major line of work, additive feature attribution methods ( additive feature attribution ) ( Murdoch et al., 2018 ), explain a model prediction by assigning importance scores to individual input variables.",
    ", 2019a ; Guidotti et al., 2018 ). However, interpretability of model predictions has always been a limiting factor for use cases that require explanations of the features involved in modeling. Towards post-hoc explanation, a major line of work, additive feature attribution methods ( additive feature attribution ) ( Murdoch et al., 2018 ), explain a model prediction by assigning importance scores to individual input variables.",
    "97x faster than Guided Backprop and much more accurate. Finally, we visualize individual scale/layer contributions by using a Layer Ordered Visualization of Information. In this paper, we describe an explainable AI saliency map method for use with deep convolutional neural networks ( CNN ) that is much more efficient than popular gradient methods. Our method is quantitatively similar and better in accuracy.",
    "97x faster than Guided Backprop and much more accurate. Finally, we visualize individual scale/layer contributions by using a Layer Ordered Visualization of Information. In this paper, we describe an explainable AI saliency map method for use with deep convolutional neural networks ( CNN ) that is much more efficient than popular gradient methods. Our method is quantitatively similar and better in accuracy.",
    "97x faster than Guided Backprop and much more accurate. Finally, we visualize individual scale/layer contributions by using a Layer Ordered Visualization of Information. In this paper, we describe an explainable AI saliency map method for use with deep convolutional neural networks ( CNN ) that is much more efficient than popular gradient methods. Our method is quantitatively similar and better in accuracy.",
    "the output sentence becomes larger ( Wei et al., 2019 ). However, the auto-regressive property of Transformer has been a bottleneck. Intuitively, NAT abandons feeding previous predicted words into decoder state at the next time step. However, without the auto-regressive constrain, the search space of the output sentence becomes larger ( Wei et al., 2019 ). We argue that position prediction is an essential",
    "the output sentence becomes larger ( Wei et al., 2019 ). However, the auto-regressive property of Transformer has been a bottleneck. Intuitively, NAT abandons feeding previous predicted words into decoder state at the next time step. However, without the auto-regressive constrain, the search space of the output sentence becomes larger ( Wei et al., 2019 ). We argue that position prediction is an essential",
    "the output sentence becomes larger ( Wei et al., 2019 ). However, the auto-regressive property of Transformer has been a bottleneck. Intuitively, NAT abandons feeding previous predicted words into decoder state at the next time step. However, without the auto-regressive constrain, the search space of the output sentence becomes larger ( Wei et al., 2019 ). We argue that position prediction is an essential",
    "random paths in a generator network. This design allows to understand factors of variation, captured by different generator layers. Aside from interpretability, the RPGAN model also provides competitive generation quality and allows efficient incremental learning on new data. In this paper, we introduce Random Path Generative Adversarial Network ( RPGAN ), an alternative design of GANs that can serve as a tool for generative model analysis. While the latent space of a typical GAN consists",
    "random paths in a generator network. This design allows to understand factors of variation, captured by different generator layers. Aside from interpretability, the RPGAN model also provides competitive generation quality and allows efficient incremental learning on new data. In this paper, we introduce Random Path Generative Adversarial Network ( RPGAN ), an alternative design of GANs that can serve as a tool for generative model analysis. While the latent space of a typical GAN consists",
    "random paths in a generator network. This design allows to understand factors of variation, captured by different generator layers. Aside from interpretability, the RPGAN model also provides competitive generation quality and allows efficient incremental learning on new data. In this paper, we introduce Random Path Generative Adversarial Network ( RPGAN ), an alternative design of GANs that can serve as a tool for generative model analysis. While the latent space of a typical GAN consists",
    ". Third, we evaluate DeepSphere on relevant problems. Our code is available at https : //github.com/deepsphere. 1 INTRODUCTION. Spherical data is found in many applications. As neural networks ( NNs ) have proved great tools for inference, variants have been developed to handle spherical data. As neural networks ( NNs ) have proved great tools for inference, variants have been developed to handle sp",
    ". Third, we evaluate DeepSphere on relevant problems. Our code is available at https : //github.com/deepsphere. 1 INTRODUCTION. Spherical data is found in many applications. As neural networks ( NNs ) have proved great tools for inference, variants have been developed to handle spherical data. As neural networks ( NNs ) have proved great tools for inference, variants have been developed to handle sp",
    ". Third, we evaluate DeepSphere on relevant problems. Our code is available at https : //github.com/deepsphere. 1 INTRODUCTION. Spherical data is found in many applications. As neural networks ( NNs ) have proved great tools for inference, variants have been developed to handle spherical data. As neural networks ( NNs ) have proved great tools for inference, variants have been developed to handle sp",
    "...... ( 2018 ) ).. ( 2018 ) ).. ( 2017 ) ). ( 2017 ) ).. ( 2016 ) )..  ( 2017 ) )....  )......",
    "...... ( 2018 ) ).. ( 2018 ) ).. ( 2017 ) ). ( 2017 ) ).. ( 2016 ) )..  ( 2017 ) )....  )......",
    "...... ( 2018 ) ).. ( 2018 ) ).. ( 2017 ) ). ( 2017 ) ).. ( 2016 ) )..  ( 2017 ) )....  )......",
    ",, a new domain of inferring an implementation of an user interface component from an image. In this work, we focus on the pixel-accurate implementation. Compared to previous work, we focus on the pixel-accurate implementation. In this work, we explore a new domain of inferring an implementation from an image. These include both symbolic synthesis approaches such as InferUI ( Microsoft, 2018 ), which transforms images into",
    ",, a new domain of inferring an implementation of an user interface component from an image. In this work, we focus on the pixel-accurate implementation. Compared to previous work, we focus on the pixel-accurate implementation. In this work, we explore a new domain of inferring an implementation from an image. These include both symbolic synthesis approaches such as InferUI ( Microsoft, 2018 ), which transforms images into",
    ",, a new domain of inferring an implementation of an user interface component from an image. In this work, we focus on the pixel-accurate implementation. Compared to previous work, we focus on the pixel-accurate implementation. In this work, we explore a new domain of inferring an implementation from an image. These include both symbolic synthesis approaches such as InferUI ( Microsoft, 2018 ), which transforms images into",
    "adversarial examples are crafted on-the-fly during network training. These adversarial examples are then injected into the training set. In this paper, we study the adversarial robustness of models produced by transfer learning. We begin by observing that robust networks contain robust feature extractors, which are resistant to adversarial perturbations in different domains. We conclude by observing that robust networks contain robust feature extractors, which are resistant to adversarial perturbations in different",
    "adversarial examples are crafted on-the-fly during network training. These adversarial examples are then injected into the training set. In this paper, we study the adversarial robustness of models produced by transfer learning. We begin by observing that robust networks contain robust feature extractors, which are resistant to adversarial perturbations in different domains. We conclude by observing that robust networks contain robust feature extractors, which are resistant to adversarial perturbations in different",
    "adversarial examples are crafted on-the-fly during network training. These adversarial examples are then injected into the training set. In this paper, we study the adversarial robustness of models produced by transfer learning. We begin by observing that robust networks contain robust feature extractors, which are resistant to adversarial perturbations in different domains. We conclude by observing that robust networks contain robust feature extractors, which are resistant to adversarial perturbations in different",
    ",. This research is often practiced through the development of neural agents. During this process, the agents build mappings between the concepts they wish to communicate about and the symbols used to represent them. While related to NLU, it focuses on the pragmatics of learning natural language. While the best way to design games to favour language emergence is still open to debate, there is a consensus on the fact that we should gear these emergent languages towards sharing similarities with natural language.",
    ",. This research is often practiced through the development of neural agents. During this process, the agents build mappings between the concepts they wish to communicate about and the symbols used to represent them. While related to NLU, it focuses on the pragmatics of learning natural language. While the best way to design games to favour language emergence is still open to debate, there is a consensus on the fact that we should gear these emergent languages towards sharing similarities with natural language.",
    ",. This research is often practiced through the development of neural agents. During this process, the agents build mappings between the concepts they wish to communicate about and the symbols used to represent them. While related to NLU, it focuses on the pragmatics of learning natural language. While the best way to design games to favour language emergence is still open to debate, there is a consensus on the fact that we should gear these emergent languages towards sharing similarities with natural language.",
    "). In particular, conditional random fields ( MRFs ) find applications in a variety of machine learning areas ( Meng & Wong, 1996 ; Neal, 2001 ; Hinton, 2002 ; Tieleman, 2008 ; Wainwright et al., 2005 ; Wainwright et al., 2005 ). However, there is no black-box inference and learning method for general MRFs",
    "). In particular, conditional random fields ( MRFs ) find applications in a variety of machine learning areas ( Meng & Wong, 1996 ; Neal, 2001 ; Hinton, 2002 ; Tieleman, 2008 ; Wainwright et al., 2005 ; Wainwright et al., 2005 ). However, there is no black-box inference and learning method for general MRFs",
    "). In particular, conditional random fields ( MRFs ) find applications in a variety of machine learning areas ( Meng & Wong, 1996 ; Neal, 2001 ; Hinton, 2002 ; Tieleman, 2008 ; Wainwright et al., 2005 ; Wainwright et al., 2005 ). However, there is no black-box inference and learning method for general MRFs",
    ". In reinforcement learning, a low dimensional state of the environment is estimated. In reinforcement learning, this state is also used to compute the reward function. However, without a state estimator, it is hard to specify a reward function based on raw ( e.g. high-dimensional and continuous ) observations. In this paper, we present an alternative approach for goal-conditioned reinforcement learning for specifying rewards using raw ( e.g. high-dimensional and continuous )",
    ". In reinforcement learning, a low dimensional state of the environment is estimated. In reinforcement learning, this state is also used to compute the reward function. However, without a state estimator, it is hard to specify a reward function based on raw ( e.g. high-dimensional and continuous ) observations. In this paper, we present an alternative approach for goal-conditioned reinforcement learning for specifying rewards using raw ( e.g. high-dimensional and continuous )",
    ". In reinforcement learning, a low dimensional state of the environment is estimated. In reinforcement learning, this state is also used to compute the reward function. However, without a state estimator, it is hard to specify a reward function based on raw ( e.g. high-dimensional and continuous ) observations. In this paper, we present an alternative approach for goal-conditioned reinforcement learning for specifying rewards using raw ( e.g. high-dimensional and continuous )",
    "). Moreover, neural network verification has become an important tool for analyzing and understanding the behavior of deep neural networks. For example, given a K-way classification model f : Rd  RK, where fi ( x ) stands for the predicted score of class i, we can verify some linear specification ( defined by a vector c ) as below : min x  i cifi ( x ) s.t",
    "). Moreover, neural network verification has become an important tool for analyzing and understanding the behavior of deep neural networks. For example, given a K-way classification model f : Rd  RK, where fi ( x ) stands for the predicted score of class i, we can verify some linear specification ( defined by a vector c ) as below : min x  i cifi ( x ) s.t",
    "). Moreover, neural network verification has become an important tool for analyzing and understanding the behavior of deep neural networks. For example, given a K-way classification model f : Rd  RK, where fi ( x ) stands for the predicted score of class i, we can verify some linear specification ( defined by a vector c ) as below : min x  i cifi ( x ) s.t",
    ". Large-scale pretraining over text data holds the promise of simultaneously learning syntax, semantics and connecting them with knowledge about the real world. However, existing pretraining objectives are usually defined at the token level and do not explicitly model entity-centric knowledge. In this work, we investigate whether we can further enforce pretrained models to focus on encyclopedic knowledge about real-world entities.",
    ". Large-scale pretraining over text data holds the promise of simultaneously learning syntax, semantics and connecting them with knowledge about the real world. However, existing pretraining objectives are usually defined at the token level and do not explicitly model entity-centric knowledge. In this work, we investigate whether we can further enforce pretrained models to focus on encyclopedic knowledge about real-world entities.",
    ". Large-scale pretraining over text data holds the promise of simultaneously learning syntax, semantics and connecting them with knowledge about the real world. However, existing pretraining objectives are usually defined at the token level and do not explicitly model entity-centric knowledge. In this work, we investigate whether we can further enforce pretrained models to focus on encyclopedic knowledge about real-world entities.",
    "labelled with unlabelled data. However, this does not mean that the learned features are useful as a representation of the new classes. In this paper, we introduce a novel approach that combines three key ideas ( section 2 and fig. 1 ). The first idea is to pre-train the image representation using all available images, both labelled and unlabelled. The second idea is to pre-train the image representation using all available images, both labelled and unlabelled. This",
    "labelled with unlabelled data. However, this does not mean that the learned features are useful as a representation of the new classes. In this paper, we introduce a novel approach that combines three key ideas ( section 2 and fig. 1 ). The first idea is to pre-train the image representation using all available images, both labelled and unlabelled. The second idea is to pre-train the image representation using all available images, both labelled and unlabelled. This",
    "labelled with unlabelled data. However, this does not mean that the learned features are useful as a representation of the new classes. In this paper, we introduce a novel approach that combines three key ideas ( section 2 and fig. 1 ). The first idea is to pre-train the image representation using all available images, both labelled and unlabelled. The second idea is to pre-train the image representation using all available images, both labelled and unlabelled. This",
    ". For example, before executing a potentially dangerous task, it would be desirable to visualize what the robot is planning to do step by step. In SPTM, an image classifier is trained to predict whether pairs of images were \u2018 close \u2019 in the data or not. The graph can then be used to generate a visual plan from the current state to the goal. In SPTM, an image classifier is trained to predict whether pairs of images were \u2018 close \u2019 in the data or not",
    ". For example, before executing a potentially dangerous task, it would be desirable to visualize what the robot is planning to do step by step. In SPTM, an image classifier is trained to predict whether pairs of images were \u2018 close \u2019 in the data or not. The graph can then be used to generate a visual plan from the current state to the goal. In SPTM, an image classifier is trained to predict whether pairs of images were \u2018 close \u2019 in the data or not",
    ". For example, before executing a potentially dangerous task, it would be desirable to visualize what the robot is planning to do step by step. In SPTM, an image classifier is trained to predict whether pairs of images were \u2018 close \u2019 in the data or not. The graph can then be used to generate a visual plan from the current state to the goal. In SPTM, an image classifier is trained to predict whether pairs of images were \u2018 close \u2019 in the data or not",
    "existing benchmarks are overly populated with similar ( thus non-tail ) problems. This in turn leads to a major overestimation of true AI performance. To address this challenge, we propose AFLITE, an iterative greedy algorithm that adversarially filters out data points to identify a reduced dataset with more realistic problem distributions. Finally, we introduce new measures of dataset biases based on K-nearest-neighbors to help guide future research on dataset",
    "existing benchmarks are overly populated with similar ( thus non-tail ) problems. This in turn leads to a major overestimation of true AI performance. To address this challenge, we propose AFLITE, an iterative greedy algorithm that adversarially filters out data points to identify a reduced dataset with more realistic problem distributions. Finally, we introduce new measures of dataset biases based on K-nearest-neighbors to help guide future research on dataset",
    "existing benchmarks are overly populated with similar ( thus non-tail ) problems. This in turn leads to a major overestimation of true AI performance. To address this challenge, we propose AFLITE, an iterative greedy algorithm that adversarially filters out data points to identify a reduced dataset with more realistic problem distributions. Finally, we introduce new measures of dataset biases based on K-nearest-neighbors to help guide future research on dataset",
    ".8 on unmatched MNIST data. On the more complex MiniImageNet data set, test accuracy is.8. In addition, we propose a novel Gaussian layer for distance calculation in a prototypical network. One- or few-shot learning is an active area of research that focuses on modeling semantic concepts with very little training data. This concept is inspired by human learning ; humans can generalize to a new concept from just one or very few examples.",
    ".8 on unmatched MNIST data. On the more complex MiniImageNet data set, test accuracy is.8. In addition, we propose a novel Gaussian layer for distance calculation in a prototypical network. One- or few-shot learning is an active area of research that focuses on modeling semantic concepts with very little training data. This concept is inspired by human learning ; humans can generalize to a new concept from just one or very few examples.",
    ".8 on unmatched MNIST data. On the more complex MiniImageNet data set, test accuracy is.8. In addition, we propose a novel Gaussian layer for distance calculation in a prototypical network. One- or few-shot learning is an active area of research that focuses on modeling semantic concepts with very little training data. This concept is inspired by human learning ; humans can generalize to a new concept from just one or very few examples.",
    "the embedding quality. Equal contributions 1Source code of GraphZoom is freely available at : github.com/cornell-zhang/GraphZoom. the embedding quality ( Maehara, 2019 ). the embedding power. Equal contributions 1Source code of GraphZoom is freely available at : github.com/cornell-zhang/GraphZoom. the embedding quality ( Maehara",
    "the embedding quality. Equal contributions 1Source code of GraphZoom is freely available at : github.com/cornell-zhang/GraphZoom. the embedding quality ( Maehara, 2019 ). the embedding power. Equal contributions 1Source code of GraphZoom is freely available at : github.com/cornell-zhang/GraphZoom. the embedding quality ( Maehara",
    "the embedding quality. Equal contributions 1Source code of GraphZoom is freely available at : github.com/cornell-zhang/GraphZoom. the embedding quality ( Maehara, 2019 ). the embedding power. Equal contributions 1Source code of GraphZoom is freely available at : github.com/cornell-zhang/GraphZoom. the embedding quality ( Maehara",
    "the mean at 255 and the marginal distribution of absolute sub-pixel intensities. In contrast, the absolute sub-pixel values are distributed non-trivially across the whole range of possible sub-pixel values. Autoregressive models are one of the main forces driving research in image generation ( van den Oord et al., 2017 ). Autoregressive models have a tractable likelihood function that decomposes image generation into a sequence of conditionally dependent pixel predictions",
    "the mean at 255 and the marginal distribution of absolute sub-pixel intensities. In contrast, the absolute sub-pixel values are distributed non-trivially across the whole range of possible sub-pixel values. Autoregressive models are one of the main forces driving research in image generation ( van den Oord et al., 2017 ). Autoregressive models have a tractable likelihood function that decomposes image generation into a sequence of conditionally dependent pixel predictions",
    "the mean at 255 and the marginal distribution of absolute sub-pixel intensities. In contrast, the absolute sub-pixel values are distributed non-trivially across the whole range of possible sub-pixel values. Autoregressive models are one of the main forces driving research in image generation ( van den Oord et al., 2017 ). Autoregressive models have a tractable likelihood function that decomposes image generation into a sequence of conditionally dependent pixel predictions",
    "stationary distribution quantities are of fundamental importance in reinforcement learning ( RL ). In many areas of machine learning, Markov chain Monte Carlo ( MCMC ) methods are used to conduct approximate Bayesian inference by considering Markov chains whose equilibrium distribution is a desired posterior. However, these classical approaches are inapplicable when direct access to the environment is not available. In this paper, we examine the problem of off-line estimation of stationary quantities via a stationary distribution corrector.",
    "stationary distribution quantities are of fundamental importance in reinforcement learning ( RL ). In many areas of machine learning, Markov chain Monte Carlo ( MCMC ) methods are used to conduct approximate Bayesian inference by considering Markov chains whose equilibrium distribution is a desired posterior. However, these classical approaches are inapplicable when direct access to the environment is not available. In this paper, we examine the problem of off-line estimation of stationary quantities via a stationary distribution corrector.",
    "stationary distribution quantities are of fundamental importance in reinforcement learning ( RL ). In many areas of machine learning, Markov chain Monte Carlo ( MCMC ) methods are used to conduct approximate Bayesian inference by considering Markov chains whose equilibrium distribution is a desired posterior. However, these classical approaches are inapplicable when direct access to the environment is not available. In this paper, we examine the problem of off-line estimation of stationary quantities via a stationary distribution corrector.",
    "......... be able to answer these questions. For example, some models for question-answering tasks may not be able to answer these questions. For example, some models for question-answering tasks may not be able to answer these questions. For example, when does a photograph truly depict a dolphin? When does a photograph truly depict a seagull",
    "......... be able to answer these questions. For example, some models for question-answering tasks may not be able to answer these questions. For example, some models for question-answering tasks may not be able to answer these questions. For example, when does a photograph truly depict a dolphin? When does a photograph truly depict a seagull",
    "......... be able to answer these questions. For example, some models for question-answering tasks may not be able to answer these questions. For example, some models for question-answering tasks may not be able to answer these questions. For example, when does a photograph truly depict a dolphin? When does a photograph truly depict a seagull",
    "perceptual quality. Johnson et al. ( 2016 ) demonstrated how effective the feature representations of pre-trained CNNs could be as features of full-reference perceptual quality. More recently, Blau et al. ( 2018 ) and Blau et al. ( 2018 ) demonstrate how effective deep CNN features can be as features of perceptual quality.",
    "perceptual quality. Johnson et al. ( 2016 ) demonstrated how effective the feature representations of pre-trained CNNs could be as features of full-reference perceptual quality. More recently, Blau et al. ( 2018 ) and Blau et al. ( 2018 ) demonstrate how effective deep CNN features can be as features of perceptual quality.",
    "perceptual quality. Johnson et al. ( 2016 ) demonstrated how effective the feature representations of pre-trained CNNs could be as features of full-reference perceptual quality. More recently, Blau et al. ( 2018 ) and Blau et al. ( 2018 ) demonstrate how effective deep CNN features can be as features of perceptual quality.",
    ". In Fig. 1, DDI types are represented as link types. These link types are correlated since they are all bleeding related DDIs caused by the increase of Warfarin \u2019 s effect. These DDI types are correlated since they are all bleeding related DDIs caused by the increase of Warfarin \u2019 s effect. GENN, a new deep learning architecture that predicts DDIs in the graph setting. GENN",
    ". In Fig. 1, DDI types are represented as link types. These link types are correlated since they are all bleeding related DDIs caused by the increase of Warfarin \u2019 s effect. These DDI types are correlated since they are all bleeding related DDIs caused by the increase of Warfarin \u2019 s effect. GENN, a new deep learning architecture that predicts DDIs in the graph setting. GENN",
    ". In Fig. 1, DDI types are represented as link types. These link types are correlated since they are all bleeding related DDIs caused by the increase of Warfarin \u2019 s effect. These DDI types are correlated since they are all bleeding related DDIs caused by the increase of Warfarin \u2019 s effect. GENN, a new deep learning architecture that predicts DDIs in the graph setting. GENN",
    ". Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency.",
    ". Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency.",
    ". Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency. Work done during a Facebook AI residency.",
    ". Moreover, a growing body of literature has proposed non-linear extensions of LVMs. ( 2018 ). Among them, variational autoencoders ( VAEs ) have been proposed as non-linear extensions of LVMs. ( Liang et al., 2018 ). As shown below, the VAE is trained to maximize the likelihood of observations. However, this does not necessarily result in higher ranking-based scores",
    ". Moreover, a growing body of literature has proposed non-linear extensions of LVMs. ( 2018 ). Among them, variational autoencoders ( VAEs ) have been proposed as non-linear extensions of LVMs. ( Liang et al., 2018 ). As shown below, the VAE is trained to maximize the likelihood of observations. However, this does not necessarily result in higher ranking-based scores",
    ". Moreover, a growing body of literature has proposed non-linear extensions of LVMs. ( 2018 ). Among them, variational autoencoders ( VAEs ) have been proposed as non-linear extensions of LVMs. ( Liang et al., 2018 ). As shown below, the VAE is trained to maximize the likelihood of observations. However, this does not necessarily result in higher ranking-based scores",
    "). In this work, we describe a method called n-step returns. n-step returns are based on a Monte Carlo rollout of length n. This method is called TD (  ). In this work, we describe a method called n-step returns. n-step returns are based on a Monte Carlo rollout of length n. n-step returns are based on n-step returns",
    "). In this work, we describe a method called n-step returns. n-step returns are based on a Monte Carlo rollout of length n. This method is called TD (  ). In this work, we describe a method called n-step returns. n-step returns are based on a Monte Carlo rollout of length n. n-step returns are based on n-step returns",
    "). In this work, we describe a method called n-step returns. n-step returns are based on a Monte Carlo rollout of length n. This method is called TD (  ). In this work, we describe a method called n-step returns. n-step returns are based on a Monte Carlo rollout of length n. n-step returns are based on n-step returns",
    "able to ( 1 ) learn from their own raw sensory inputs, ( 2 ) assign rewards to their own trials without hand-designed perception systems or instrumentation, and ( 3 ) learn continuously in non-episodic settings without requiring human intervention to manually reset the environment. In this paper, we propose that overcoming these challenges in a scalable way requires designing robotic systems that possess three capabilities. This would lift a major constraint that stands between current reinforcement learning algorithms and the ability",
    "able to ( 1 ) learn from their own raw sensory inputs, ( 2 ) assign rewards to their own trials without hand-designed perception systems or instrumentation, and ( 3 ) learn continuously in non-episodic settings without requiring human intervention to manually reset the environment. In this paper, we propose that overcoming these challenges in a scalable way requires designing robotic systems that possess three capabilities. This would lift a major constraint that stands between current reinforcement learning algorithms and the ability",
    "able to ( 1 ) learn from their own raw sensory inputs, ( 2 ) assign rewards to their own trials without hand-designed perception systems or instrumentation, and ( 3 ) learn continuously in non-episodic settings without requiring human intervention to manually reset the environment. In this paper, we propose that overcoming these challenges in a scalable way requires designing robotic systems that possess three capabilities. This would lift a major constraint that stands between current reinforcement learning algorithms and the ability",
    ". An attacker has no access to the model parameters or even architecture, but can still easily fool a machine learning system. Deep learning ( LeCun et al., 2015 ), especially deep Convolutional Neural Network ( CNN ) ( LeCun et al., 1998 ), has led to state-of-the-art results spanning many machine learning fields. Recent studies show that deep CNNs are vulnerable to some well-designed adversarial examples",
    ". An attacker has no access to the model parameters or even architecture, but can still easily fool a machine learning system. Deep learning ( LeCun et al., 2015 ), especially deep Convolutional Neural Network ( CNN ) ( LeCun et al., 1998 ), has led to state-of-the-art results spanning many machine learning fields. Recent studies show that deep CNNs are vulnerable to some well-designed adversarial examples",
    ". An attacker has no access to the model parameters or even architecture, but can still easily fool a machine learning system. Deep learning ( LeCun et al., 2015 ), especially deep Convolutional Neural Network ( CNN ) ( LeCun et al., 1998 ), has led to state-of-the-art results spanning many machine learning fields. Recent studies show that deep CNNs are vulnerable to some well-designed adversarial examples",
    "ads are more persuasive if there is a regulatory fit. For example, Lee & Aaker ( 2004 ) showed that ads are more persuasive if there is a regulatory fit. Furthermore, the regulatory fit theory proposes that when people pursue a goal in a manner that fits their regulatory orientation, they are stronger motivated during goal pursuit. We study the phenomenon of regulatory fit in the context of reinforcement learning ( RL ). Be aware that humans own real emotions and are fundamentally more",
    "ads are more persuasive if there is a regulatory fit. For example, Lee & Aaker ( 2004 ) showed that ads are more persuasive if there is a regulatory fit. Furthermore, the regulatory fit theory proposes that when people pursue a goal in a manner that fits their regulatory orientation, they are stronger motivated during goal pursuit. We study the phenomenon of regulatory fit in the context of reinforcement learning ( RL ). Be aware that humans own real emotions and are fundamentally more",
    "ads are more persuasive if there is a regulatory fit. For example, Lee & Aaker ( 2004 ) showed that ads are more persuasive if there is a regulatory fit. Furthermore, the regulatory fit theory proposes that when people pursue a goal in a manner that fits their regulatory orientation, they are stronger motivated during goal pursuit. We study the phenomenon of regulatory fit in the context of reinforcement learning ( RL ). Be aware that humans own real emotions and are fundamentally more",
    ".. precision gating ( PG ). PG is an end-to-end trainable dynamic dual-precision quantization technique for deep neural networks. PG achieves excellent results on CNNs. PG achieves a 1.2 % improvement in perplexity per word with 2.7 computational cost reduction on LSTM on the Penn Tree Bank dataset. PG is applicable to a variety of DNN architectures and significantly reduces the computational cost of execution",
    ".. precision gating ( PG ). PG is an end-to-end trainable dynamic dual-precision quantization technique for deep neural networks. PG achieves excellent results on CNNs. PG achieves a 1.2 % improvement in perplexity per word with 2.7 computational cost reduction on LSTM on the Penn Tree Bank dataset. PG is applicable to a variety of DNN architectures and significantly reduces the computational cost of execution",
    ".. precision gating ( PG ). PG is an end-to-end trainable dynamic dual-precision quantization technique for deep neural networks. PG achieves excellent results on CNNs. PG achieves a 1.2 % improvement in perplexity per word with 2.7 computational cost reduction on LSTM on the Penn Tree Bank dataset. PG is applicable to a variety of DNN architectures and significantly reduces the computational cost of execution",
    "supervised DA ( Tzeng et al., 2015 ) ; semi-supervised DA ( Guo and Xiao, 2012 ) and unsupervised DA ( UDA ) ( Saito et al., 2017 ). Domain adaptation ( DA ) aims to learn a discriminative classifier in the presence of a shift between training data in source domain and test data in target domain ( TD ). Currently,",
    "supervised DA ( Tzeng et al., 2015 ) ; semi-supervised DA ( Guo and Xiao, 2012 ) and unsupervised DA ( UDA ) ( Saito et al., 2017 ). Domain adaptation ( DA ) aims to learn a discriminative classifier in the presence of a shift between training data in source domain and test data in target domain ( TD ). Currently,",
    "supervised DA ( Tzeng et al., 2015 ) ; semi-supervised DA ( Guo and Xiao, 2012 ) and unsupervised DA ( UDA ) ( Saito et al., 2017 ). Domain adaptation ( DA ) aims to learn a discriminative classifier in the presence of a shift between training data in source domain and test data in target domain ( TD ). Currently,",
    "... a pixel reconstruction objective. This allows for additional stability by circumventing dueling training objectives but leads to suboptimal policies. Thus, a wide range of real world problems can be addressed. 1 INTRODUCTION. 1 INTRODUCTION. 2 INTRODUCTION. 3 INTRODUCTION. 4 INTRODUCTION. 5 INTRODUCTION. 5 INTRODUCTION.",
    "... a pixel reconstruction objective. This allows for additional stability by circumventing dueling training objectives but leads to suboptimal policies. Thus, a wide range of real world problems can be addressed. 1 INTRODUCTION. 1 INTRODUCTION. 2 INTRODUCTION. 3 INTRODUCTION. 4 INTRODUCTION. 5 INTRODUCTION. 5 INTRODUCTION.",
    "... a pixel reconstruction objective. This allows for additional stability by circumventing dueling training objectives but leads to suboptimal policies. Thus, a wide range of real world problems can be addressed. 1 INTRODUCTION. 1 INTRODUCTION. 2 INTRODUCTION. 3 INTRODUCTION. 4 INTRODUCTION. 5 INTRODUCTION. 5 INTRODUCTION.",
    ". Dropout is one of the key regularization techniques for improving the generalization of deep convolutional neural networks ( DNNs ). Dropout is one of the key regularization techniques for improving the generalization of deep convolutional neural networks ( DNNs ). Because of its simplicity and efficiency, dropout is one of the key regularization techniques for improving the generalization of deep convolutional neural networks ( DNNs ). The original dropout creates a randomly selected subset",
    ". Dropout is one of the key regularization techniques for improving the generalization of deep convolutional neural networks ( DNNs ). Dropout is one of the key regularization techniques for improving the generalization of deep convolutional neural networks ( DNNs ). Because of its simplicity and efficiency, dropout is one of the key regularization techniques for improving the generalization of deep convolutional neural networks ( DNNs ). The original dropout creates a randomly selected subset",
    ". Dropout is one of the key regularization techniques for improving the generalization of deep convolutional neural networks ( DNNs ). Dropout is one of the key regularization techniques for improving the generalization of deep convolutional neural networks ( DNNs ). Because of its simplicity and efficiency, dropout is one of the key regularization techniques for improving the generalization of deep convolutional neural networks ( DNNs ). The original dropout creates a randomly selected subset",
    "filter ambiguity is one of the most critical reasons that hampers the interpretability of CNNs. In this paper, we argue that filter ambiguity is one of the most critical reasons that hampers the interpretability of CNNs. Moreover, the redundant overlap between features extracted by different filters leads to under-utilization of a model \u2019 s expressiveness ( Prakash et al., 2019 ).",
    "filter ambiguity is one of the most critical reasons that hampers the interpretability of CNNs. In this paper, we argue that filter ambiguity is one of the most critical reasons that hampers the interpretability of CNNs. Moreover, the redundant overlap between features extracted by different filters leads to under-utilization of a model \u2019 s expressiveness ( Prakash et al., 2019 ).",
    "filter ambiguity is one of the most critical reasons that hampers the interpretability of CNNs. In this paper, we argue that filter ambiguity is one of the most critical reasons that hampers the interpretability of CNNs. Moreover, the redundant overlap between features extracted by different filters leads to under-utilization of a model \u2019 s expressiveness ( Prakash et al., 2019 ).",
    ". Equal Contribution. In this paper, we present a scalable multi-agent learning framework for learning nearly decomposable Q-functions ( NDQ ) via communication minimization. In this paper, we present a scalable multi-agent learning framework for learning nearly decomposable Q-functions ( NDQ ) via communication minimization. Equal Contribution. In this paper, we present a scalable multi-a",
    ". Equal Contribution. In this paper, we present a scalable multi-agent learning framework for learning nearly decomposable Q-functions ( NDQ ) via communication minimization. In this paper, we present a scalable multi-agent learning framework for learning nearly decomposable Q-functions ( NDQ ) via communication minimization. Equal Contribution. In this paper, we present a scalable multi-a",
    ". Equal Contribution. In this paper, we present a scalable multi-agent learning framework for learning nearly decomposable Q-functions ( NDQ ) via communication minimization. In this paper, we present a scalable multi-agent learning framework for learning nearly decomposable Q-functions ( NDQ ) via communication minimization. Equal Contribution. In this paper, we present a scalable multi-a",
    "the second question is, how should one represent programming problems to teach computers? In general, the ideal programming problem representation should be : Objective : a candidate solution ought to be unambiguously validated. Complex : Capture a rich range of useful programming problems from easy to hard. Unbiased : Avoid dependence on human priors. Programming Puzzles As a better standard for evaluating and advancing artificial reasoning, we refer to the ideal programming problem representation as : Objective :",
    "the second question is, how should one represent programming problems to teach computers? In general, the ideal programming problem representation should be : Objective : a candidate solution ought to be unambiguously validated. Complex : Capture a rich range of useful programming problems from easy to hard. Unbiased : Avoid dependence on human priors. Programming Puzzles As a better standard for evaluating and advancing artificial reasoning, we refer to the ideal programming problem representation as : Objective :",
    "the second question is, how should one represent programming problems to teach computers? In general, the ideal programming problem representation should be : Objective : a candidate solution ought to be unambiguously validated. Complex : Capture a rich range of useful programming problems from easy to hard. Unbiased : Avoid dependence on human priors. Programming Puzzles As a better standard for evaluating and advancing artificial reasoning, we refer to the ideal programming problem representation as : Objective :",
    "). Hierarchical reinforcement learning ( HRL ) approaches focus on learning representations at multiple spatial and temporal scales. This is addressed to some extent by the hierarchical reinforcement learning ( HRL ) methods. As the master policy is trained, it should provide optimal behavior for the entire accessible state space. As the master policy is trained, it needs to know how to deal with any given state. That is, it should provide optimal behavior for the entire accessible state space.",
    "). Hierarchical reinforcement learning ( HRL ) approaches focus on learning representations at multiple spatial and temporal scales. This is addressed to some extent by the hierarchical reinforcement learning ( HRL ) methods. As the master policy is trained, it should provide optimal behavior for the entire accessible state space. As the master policy is trained, it needs to know how to deal with any given state. That is, it should provide optimal behavior for the entire accessible state space.",
    "). Hierarchical reinforcement learning ( HRL ) approaches focus on learning representations at multiple spatial and temporal scales. This is addressed to some extent by the hierarchical reinforcement learning ( HRL ) methods. As the master policy is trained, it should provide optimal behavior for the entire accessible state space. As the master policy is trained, it needs to know how to deal with any given state. That is, it should provide optimal behavior for the entire accessible state space.",
    ", 2013 ; Finn & Levine, 2017 ; Williams et al., 2017 ). Deep reinforcement learning ( DRL ) has demonstrated some of the most impressive results on several complex, high-dimensional sequential decision-making tasks such as video games ( Mnih et al., 2015 ) and board games ( Silver et al., 2018 ). However, model-based approaches can achieve state-of-the-art performance.",
    ", 2013 ; Finn & Levine, 2017 ; Williams et al., 2017 ). Deep reinforcement learning ( DRL ) has demonstrated some of the most impressive results on several complex, high-dimensional sequential decision-making tasks such as video games ( Mnih et al., 2015 ) and board games ( Silver et al., 2018 ). However, model-based approaches can achieve state-of-the-art performance.",
    ", 2013 ; Finn & Levine, 2017 ; Williams et al., 2017 ). Deep reinforcement learning ( DRL ) has demonstrated some of the most impressive results on several complex, high-dimensional sequential decision-making tasks such as video games ( Mnih et al., 2015 ) and board games ( Silver et al., 2018 ). However, model-based approaches can achieve state-of-the-art performance.",
    "the latest published result reports their model performance at 83.2 %. Given the importance of model size, we ask : Is having better NLP models as easy as having larger models? Given the importance of model size, we ask : Is having better NLP models as easy as having larger models? Given that current state-of-the-art models often have hundreds of millions or even billions of parameters, it is easy to hit these limitations as we try to scale our models.",
    "the latest published result reports their model performance at 83.2 %. Given the importance of model size, we ask : Is having better NLP models as easy as having larger models? Given the importance of model size, we ask : Is having better NLP models as easy as having larger models? Given that current state-of-the-art models often have hundreds of millions or even billions of parameters, it is easy to hit these limitations as we try to scale our models.",
    "the latest published result reports their model performance at 83.2 %. Given the importance of model size, we ask : Is having better NLP models as easy as having larger models? Given the importance of model size, we ask : Is having better NLP models as easy as having larger models? Given that current state-of-the-art models often have hundreds of millions or even billions of parameters, it is easy to hit these limitations as we try to scale our models.",
    ". Transfer learning ( Battenberg et al., 2018 ) is another popular paradigm used to adapt the model to learn a related task with similar input domain. To address this gap, we extend Transformer towards a unified architecture, namely OmniNet. OmniNet is a unified architecture that is able to learn shared representations from multiple input domains. In fact, OmniNet is a unified architecture that is able to learn shared representations from multiple input domains",
    ". Transfer learning ( Battenberg et al., 2018 ) is another popular paradigm used to adapt the model to learn a related task with similar input domain. To address this gap, we extend Transformer towards a unified architecture, namely OmniNet. OmniNet is a unified architecture that is able to learn shared representations from multiple input domains. In fact, OmniNet is a unified architecture that is able to learn shared representations from multiple input domains",
    ". Transfer learning ( Battenberg et al., 2018 ) is another popular paradigm used to adapt the model to learn a related task with similar input domain. To address this gap, we extend Transformer towards a unified architecture, namely OmniNet. OmniNet is a unified architecture that is able to learn shared representations from multiple input domains. In fact, OmniNet is a unified architecture that is able to learn shared representations from multiple input domains",
    ". The second requirement, frequentist coverage, is particularly relevant in high-stakes applications where predictive uncertainty is incorporated in a decision-theoretic framework ( e.g., administering medical treatments ( Dusenberry et al. ( 2019a ) ) ). The third requirement, discrimination, is crucial for auditing model reliability ( Barber et al. ( 2019a ) ). Figure 1 INTRODUCTION",
    ". The second requirement, frequentist coverage, is particularly relevant in high-stakes applications where predictive uncertainty is incorporated in a decision-theoretic framework ( e.g., administering medical treatments ( Dusenberry et al. ( 2019a ) ) ). The third requirement, discrimination, is crucial for auditing model reliability ( Barber et al. ( 2019a ) ). Figure 1 INTRODUCTION",
    ". The second requirement, frequentist coverage, is particularly relevant in high-stakes applications where predictive uncertainty is incorporated in a decision-theoretic framework ( e.g., administering medical treatments ( Dusenberry et al. ( 2019a ) ) ). The third requirement, discrimination, is crucial for auditing model reliability ( Barber et al. ( 2019a ) ). Figure 1 INTRODUCTION",
    "DVD-GAN, is able to generate temporally coherent, high-resolution videos of relatively high fidelity ( Figure 1 ). 1 INTRODUCTION We focus on the tasks of video synthesis and video prediction ( defined in Section 2.1 ). At one extreme lies unconditional video synthesis where the task is to generate any video following the training distribution. At another extreme lies class-conditional video synthesis where the task is to generate any video following the training distribution. Another extreme is",
    "DVD-GAN, is able to generate temporally coherent, high-resolution videos of relatively high fidelity ( Figure 1 ). 1 INTRODUCTION We focus on the tasks of video synthesis and video prediction ( defined in Section 2.1 ). At one extreme lies unconditional video synthesis where the task is to generate any video following the training distribution. At another extreme lies class-conditional video synthesis where the task is to generate any video following the training distribution. Another extreme is",
    "DVD-GAN, is able to generate temporally coherent, high-resolution videos of relatively high fidelity ( Figure 1 ). 1 INTRODUCTION We focus on the tasks of video synthesis and video prediction ( defined in Section 2.1 ). At one extreme lies unconditional video synthesis where the task is to generate any video following the training distribution. At another extreme lies class-conditional video synthesis where the task is to generate any video following the training distribution. Another extreme is",
    ". This problem is often motivated by the ability of humans to learn new tasks from few examples. This problem is often motivated by the ability of humans to learn new tasks using only a small labeled training set. On the other hand, for the sake of simplicity in experiments, the base class datasets are treated as a collection of small labeled examples. However, there is a huge gap between the motivating example of humans learning new tasks and how the few-shot classification task is set up",
    ". This problem is often motivated by the ability of humans to learn new tasks from few examples. This problem is often motivated by the ability of humans to learn new tasks using only a small labeled training set. On the other hand, for the sake of simplicity in experiments, the base class datasets are treated as a collection of small labeled examples. However, there is a huge gap between the motivating example of humans learning new tasks and how the few-shot classification task is set up",
    ". This problem is often motivated by the ability of humans to learn new tasks from few examples. This problem is often motivated by the ability of humans to learn new tasks using only a small labeled training set. On the other hand, for the sake of simplicity in experiments, the base class datasets are treated as a collection of small labeled examples. However, there is a huge gap between the motivating example of humans learning new tasks and how the few-shot classification task is set up",
    "valid structures. This is achieved by augmenting the standard GAN loss with a penalty term that discourages the model from producing infeasible structures. This is achieved by augmenting the standard GAN loss with a penalty term that discourages the model from producing infeasible structures. In this paper, we propose Constrained Adversarial Networks ( CANs ), a class of generative models that extend GANs to structured domains.",
    "valid structures. This is achieved by augmenting the standard GAN loss with a penalty term that discourages the model from producing infeasible structures. This is achieved by augmenting the standard GAN loss with a penalty term that discourages the model from producing infeasible structures. In this paper, we propose Constrained Adversarial Networks ( CANs ), a class of generative models that extend GANs to structured domains.",
    "valid structures. This is achieved by augmenting the standard GAN loss with a penalty term that discourages the model from producing infeasible structures. This is achieved by augmenting the standard GAN loss with a penalty term that discourages the model from producing infeasible structures. In this paper, we propose Constrained Adversarial Networks ( CANs ), a class of generative models that extend GANs to structured domains.",
    ". In this paper, we propose the Symmetric Adaptive Piecewise Linear unit ( SAPL ; pronounced as Symmetric apple :  p. @ l ) as a new adaptive activation function which builds upon the adaptive piecewise linear unit ( APL ) ( Agostinelli et al., 2014 ; He et al., 2015 ; Jin et al., 2016 ). In this paper",
    ". In this paper, we propose the Symmetric Adaptive Piecewise Linear unit ( SAPL ; pronounced as Symmetric apple :  p. @ l ) as a new adaptive activation function which builds upon the adaptive piecewise linear unit ( APL ) ( Agostinelli et al., 2014 ; He et al., 2015 ; Jin et al., 2016 ). In this paper",
    ". In this paper, we propose the Symmetric Adaptive Piecewise Linear unit ( SAPL ; pronounced as Symmetric apple :  p. @ l ) as a new adaptive activation function which builds upon the adaptive piecewise linear unit ( APL ) ( Agostinelli et al., 2014 ; He et al., 2015 ; Jin et al., 2016 ). In this paper",
    ".. a deep learning wrapper algorithm that equips any black-box model with uncertainty prediction. This wrapper algorithm is model agnostic and can be used on top of any other algorithm. Because it does not have access to the internals, parameters, or architecture of the model it is wrapping, the wrapper is model agnostic and can be used on top of any other algorithm as long as it satisfies some criteria. 1 INTRODUC",
    ".. a deep learning wrapper algorithm that equips any black-box model with uncertainty prediction. This wrapper algorithm is model agnostic and can be used on top of any other algorithm. Because it does not have access to the internals, parameters, or architecture of the model it is wrapping, the wrapper is model agnostic and can be used on top of any other algorithm as long as it satisfies some criteria. 1 INTRODUC",
    ".. a deep learning wrapper algorithm that equips any black-box model with uncertainty prediction. This wrapper algorithm is model agnostic and can be used on top of any other algorithm. Because it does not have access to the internals, parameters, or architecture of the model it is wrapping, the wrapper is model agnostic and can be used on top of any other algorithm as long as it satisfies some criteria. 1 INTRODUC",
    ". However, its generalization performance is often poorer than SGD. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks",
    ". However, its generalization performance is often poorer than SGD. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks",
    ". However, its generalization performance is often poorer than SGD. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks. In this paper, we introduce a new approach to deep networks",
    "video descriptors have struggled to outperform classic hand-crafted descriptors. While deep features have revolutionized static image analysis, video descriptors have struggled to outperform classic hand-crafted descriptors.",
    "video descriptors have struggled to outperform classic hand-crafted descriptors. While deep features have revolutionized static image analysis, video descriptors have struggled to outperform classic hand-crafted descriptors.",
    "video descriptors have struggled to outperform classic hand-crafted descriptors. While deep features have revolutionized static image analysis, video descriptors have struggled to outperform classic hand-crafted descriptors.",
    ". Generative Adversarial Networks ( GANs ) is a powerful family of models that learn an underlying distribution to generate synthetic data. In particular, we propose Boundary-Calibration GANs ( BCGANs ), which leverage the boundary information from a set of pre-trained classifiers using the original data. In particular, we introduce an auxiliary Boundary-Calibration loss ( BC-loss ) into",
    ". Generative Adversarial Networks ( GANs ) is a powerful family of models that learn an underlying distribution to generate synthetic data. In particular, we propose Boundary-Calibration GANs ( BCGANs ), which leverage the boundary information from a set of pre-trained classifiers using the original data. In particular, we introduce an auxiliary Boundary-Calibration loss ( BC-loss ) into",
    ". Generative Adversarial Networks ( GANs ) is a powerful family of models that learn an underlying distribution to generate synthetic data. In particular, we propose Boundary-Calibration GANs ( BCGANs ), which leverage the boundary information from a set of pre-trained classifiers using the original data. In particular, we introduce an auxiliary Boundary-Calibration loss ( BC-loss ) into",
    ", 2016 ; Madry et al., 2017 ). In contrast, adversarial examples can be generated by injecting a small perturbation to a normal sample. The adversarial example is semantically indistinguishable from the normal one. However, the adversarial example can fool deep learning models and undermine the security of deep learning. As for defense, Madry et al. ( 2017 ) formalize the adversarial training as the",
    ", 2016 ; Madry et al., 2017 ). In contrast, adversarial examples can be generated by injecting a small perturbation to a normal sample. The adversarial example is semantically indistinguishable from the normal one. However, the adversarial example can fool deep learning models and undermine the security of deep learning. As for defense, Madry et al. ( 2017 ) formalize the adversarial training as the",
    ", 2016 ; Madry et al., 2017 ). In contrast, adversarial examples can be generated by injecting a small perturbation to a normal sample. The adversarial example is semantically indistinguishable from the normal one. However, the adversarial example can fool deep learning models and undermine the security of deep learning. As for defense, Madry et al. ( 2017 ) formalize the adversarial training as the",
    ", 2018 ). However, they are ill suited to problem domains with hard constraints or non-Markovian objectives. For example, an autonomous vehicle avoiding collisions with pedestrians is more naturally expressed as hard constraints than as soft reward penalties. Inverse Reinforcement Learning ( IRL ) techniques can help alleviate this burden by automatically identifying the objectives driving certain behavior.",
    ", 2018 ). However, they are ill suited to problem domains with hard constraints or non-Markovian objectives. For example, an autonomous vehicle avoiding collisions with pedestrians is more naturally expressed as hard constraints than as soft reward penalties. Inverse Reinforcement Learning ( IRL ) techniques can help alleviate this burden by automatically identifying the objectives driving certain behavior.",
    ", 2018 ). However, they are ill suited to problem domains with hard constraints or non-Markovian objectives. For example, an autonomous vehicle avoiding collisions with pedestrians is more naturally expressed as hard constraints than as soft reward penalties. Inverse Reinforcement Learning ( IRL ) techniques can help alleviate this burden by automatically identifying the objectives driving certain behavior.",
    "the orientation-tilt illusion. When the two orientations are similar, the central grating appears tilted slightly away from the surround ( Fig. 1a ). When the two orientations are dissimilar, the central grating appears tilted slightly towards the surround ( Fig. 1a, bottom ). M\u00e9ly et al. ( 2018 ) proposed a cortical circuit, constrained by physiology of primate visual cortex",
    "the orientation-tilt illusion. When the two orientations are similar, the central grating appears tilted slightly away from the surround ( Fig. 1a ). When the two orientations are dissimilar, the central grating appears tilted slightly towards the surround ( Fig. 1a, bottom ). M\u00e9ly et al. ( 2018 ) proposed a cortical circuit, constrained by physiology of primate visual cortex",
    "the orientation-tilt illusion. When the two orientations are similar, the central grating appears tilted slightly away from the surround ( Fig. 1a ). When the two orientations are dissimilar, the central grating appears tilted slightly towards the surround ( Fig. 1a, bottom ). M\u00e9ly et al. ( 2018 ) proposed a cortical circuit, constrained by physiology of primate visual cortex",
    "\u201c tooth brush \u201d, \u201c human \u201d, and \u201c baseball glove \u201d. However, this object of \u201c tooth brush \u201d does not fit into the semantic context with other objects in the scene. In this work, we propose a context-aware object detection strategy called conCNN to address the above shortcoming. ConCNN is inspired by our observation that probabilistic graphical models, in particular, Conditional Random Fields (CRFs), are more effective in object",
    "\u201c tooth brush \u201d, \u201c human \u201d, and \u201c baseball glove \u201d. However, this object of \u201c tooth brush \u201d does not fit into the semantic context with other objects in the scene. In this work, we propose a context-aware object detection strategy called conCNN to address the above shortcoming. ConCNN is inspired by our observation that probabilistic graphical models, in particular, Conditional Random Fields (CRFs), are more effective in object",
    "\u201c tooth brush \u201d, \u201c human \u201d, and \u201c baseball glove \u201d. However, this object of \u201c tooth brush \u201d does not fit into the semantic context with other objects in the scene. In this work, we propose a context-aware object detection strategy called conCNN to address the above shortcoming. ConCNN is inspired by our observation that probabilistic graphical models, in particular, Conditional Random Fields (CRFs), are more effective in object",
    ", 2017 ). Batch Normalization ( BatchNorm or BN ) has proliferated throughout all areas of deep learning. BatchNorm enables stable training, higher convergence, and higher generalization accuracy. However, a recent study by Galloway et al. ( 2019 ) showed that removing the BatchNorm layer enhances robustness against adversarial perturbations. Specifically, they showed that removing the BatchNorm layer enhances robustness against adversarial perturb",
    ", 2017 ). Batch Normalization ( BatchNorm or BN ) has proliferated throughout all areas of deep learning. BatchNorm enables stable training, higher convergence, and higher generalization accuracy. However, a recent study by Galloway et al. ( 2019 ) showed that removing the BatchNorm layer enhances robustness against adversarial perturbations. Specifically, they showed that removing the BatchNorm layer enhances robustness against adversarial perturb",
    ", 2017 ). Batch Normalization ( BatchNorm or BN ) has proliferated throughout all areas of deep learning. BatchNorm enables stable training, higher convergence, and higher generalization accuracy. However, a recent study by Galloway et al. ( 2019 ) showed that removing the BatchNorm layer enhances robustness against adversarial perturbations. Specifically, they showed that removing the BatchNorm layer enhances robustness against adversarial perturb",
    "a generalization guarantee on clean data distribution despite being trained using noisy labels. This paper proposes and analyzes two simple and intuitive regularization methods. ( i ) regularization by the distance between the network parameters to initialization, and ( ii ) adding a trainable auxiliary variable to the network output for each training example. ( i ) regularization by the distance between the network parameters to initialization. ( ii ) regularization by the distance between the network parameters",
    "a generalization guarantee on clean data distribution despite being trained using noisy labels. This paper proposes and analyzes two simple and intuitive regularization methods. ( i ) regularization by the distance between the network parameters to initialization, and ( ii ) adding a trainable auxiliary variable to the network output for each training example. ( i ) regularization by the distance between the network parameters to initialization. ( ii ) regularization by the distance between the network parameters",
    "a generalization guarantee on clean data distribution despite being trained using noisy labels. This paper proposes and analyzes two simple and intuitive regularization methods. ( i ) regularization by the distance between the network parameters to initialization, and ( ii ) adding a trainable auxiliary variable to the network output for each training example. ( i ) regularization by the distance between the network parameters to initialization. ( ii ) regularization by the distance between the network parameters",
    ". ( 1 ) Modifying the kernel using a new operation called Local Average Pooling ( LAP ). ( 2 ) Representing the input image using a pre-processing technique proposed by Coates et al. ( 2011 ). ( 3 ) Modifying the kernel using a new operation called Local Average Pooling ( LAP ). ( 4 ) Representing the input image using a pre-processing technique proposed by Coates et al.",
    ". ( 1 ) Modifying the kernel using a new operation called Local Average Pooling ( LAP ). ( 2 ) Representing the input image using a pre-processing technique proposed by Coates et al. ( 2011 ). ( 3 ) Modifying the kernel using a new operation called Local Average Pooling ( LAP ). ( 4 ) Representing the input image using a pre-processing technique proposed by Coates et al.",
    ". ( 1 ) Modifying the kernel using a new operation called Local Average Pooling ( LAP ). ( 2 ) Representing the input image using a pre-processing technique proposed by Coates et al. ( 2011 ). ( 3 ) Modifying the kernel using a new operation called Local Average Pooling ( LAP ). ( 4 ) Representing the input image using a pre-processing technique proposed by Coates et al.",
    "; Hamrick, 2019 ; Wang et al., 2019 ). Yet, model-based methods hold the promise of allowing agents to more flexibly adapt to new situations and efficiently reason about what will happen. Despite the success of model-free RL, model-based methods hold the promise of allowing agents to more flexibly adapt to new situations and avoid potentially bad outcomes.",
    "; Hamrick, 2019 ; Wang et al., 2019 ). Yet, model-based methods hold the promise of allowing agents to more flexibly adapt to new situations and efficiently reason about what will happen. Despite the success of model-free RL, model-based methods hold the promise of allowing agents to more flexibly adapt to new situations and avoid potentially bad outcomes.",
    "; Hamrick, 2019 ; Wang et al., 2019 ). Yet, model-based methods hold the promise of allowing agents to more flexibly adapt to new situations and efficiently reason about what will happen. Despite the success of model-free RL, model-based methods hold the promise of allowing agents to more flexibly adapt to new situations and avoid potentially bad outcomes.",
    "..., we define \u201c panning \u201d in the context of 3D modeling. Figure 1 shows some generated stereo images for a given single input view. Additionally, arbitrary panning allows our proposed model to adjust the baseline for different levels of 3D sensation. Furthermore, arbitrary panning allows our proposed model to adjust for different inter-pupillary distances of various persons. In this paper, we define \u201c panning \u201d in the context of 3D",
    "..., we define \u201c panning \u201d in the context of 3D modeling. Figure 1 shows some generated stereo images for a given single input view. Additionally, arbitrary panning allows our proposed model to adjust the baseline for different levels of 3D sensation. Furthermore, arbitrary panning allows our proposed model to adjust for different inter-pupillary distances of various persons. In this paper, we define \u201c panning \u201d in the context of 3D",
    "..., we define \u201c panning \u201d in the context of 3D modeling. Figure 1 shows some generated stereo images for a given single input view. Additionally, arbitrary panning allows our proposed model to adjust the baseline for different levels of 3D sensation. Furthermore, arbitrary panning allows our proposed model to adjust for different inter-pupillary distances of various persons. In this paper, we define \u201c panning \u201d in the context of 3D",
    "unsupervised representation learning research is to find a representation z of the generative factor o living in a known space Z describing, as well as o, the visible data x  X. In order to solve this problem, it was proposed to consider a dual problem : define a priori z and find a generator map g, such that for any z, g ( z ) is an element of X. In particular",
    "unsupervised representation learning research is to find a representation z of the generative factor o living in a known space Z describing, as well as o, the visible data x  X. In order to solve this problem, it was proposed to consider a dual problem : define a priori z and find a generator map g, such that for any z, g ( z ) is an element of X. In particular",
    "unsupervised representation learning research is to find a representation z of the generative factor o living in a known space Z describing, as well as o, the visible data x  X. In order to solve this problem, it was proposed to consider a dual problem : define a priori z and find a generator map g, such that for any z, g ( z ) is an element of X. In particular",
    "Node2Vec ( Grover & Leskovec, 2016 ) and Walklets ( Perozzi et al., 2017 ). Node embedding is a fundamental technique in network analysis that serves as precursor to numerous downstream machine learning and optimisation tasks. In a social network, near neighbors may represent a person \u2019 s interests, habits, history or preferences. The neighbourhood of a node can be considered at different path lengths",
    "Node2Vec ( Grover & Leskovec, 2016 ) and Walklets ( Perozzi et al., 2017 ). Node embedding is a fundamental technique in network analysis that serves as precursor to numerous downstream machine learning and optimisation tasks. In a social network, near neighbors may represent a person \u2019 s interests, habits, history or preferences. The neighbourhood of a node can be considered at different path lengths",
    "Node2Vec ( Grover & Leskovec, 2016 ) and Walklets ( Perozzi et al., 2017 ). Node embedding is a fundamental technique in network analysis that serves as precursor to numerous downstream machine learning and optimisation tasks. In a social network, near neighbors may represent a person \u2019 s interests, habits, history or preferences. The neighbourhood of a node can be considered at different path lengths",
    ". The IB objective ( Tishby et al., 2000 ) : IB [ p ( z|x ) : = I ( X ; Z )  I ( Y ; Z ) ( 1 ) ( 1 ). In Wu et al. ( 2019 ), the authors observe and study the learnability transition, i.e. the  value such that the IB objective transitions",
    ". The IB objective ( Tishby et al., 2000 ) : IB [ p ( z|x ) : = I ( X ; Z )  I ( Y ; Z ) ( 1 ) ( 1 ). In Wu et al. ( 2019 ), the authors observe and study the learnability transition, i.e. the  value such that the IB objective transitions",
    ". The IB objective ( Tishby et al., 2000 ) : IB [ p ( z|x ) : = I ( X ; Z )  I ( Y ; Z ) ( 1 ) ( 1 ). In Wu et al. ( 2019 ), the authors observe and study the learnability transition, i.e. the  value such that the IB objective transitions",
    ". However, it suffers from the high variance associated with vanilla policy gradient estimator. For example, consider a simple multi-round game where at the end of each round the agent will be assigned a reward. In this example, the agent will be assigned a reward, representing whether it wins this round. In this example, the agent will be assigned a reward, representing whether it wins this round. In this example, the agent will be assigned a reward, representing",
    ". However, it suffers from the high variance associated with vanilla policy gradient estimator. For example, consider a simple multi-round game where at the end of each round the agent will be assigned a reward. In this example, the agent will be assigned a reward, representing whether it wins this round. In this example, the agent will be assigned a reward, representing whether it wins this round. In this example, the agent will be assigned a reward, representing",
    ". However, it suffers from the high variance associated with vanilla policy gradient estimator. For example, consider a simple multi-round game where at the end of each round the agent will be assigned a reward. In this example, the agent will be assigned a reward, representing whether it wins this round. In this example, the agent will be assigned a reward, representing whether it wins this round. In this example, the agent will be assigned a reward, representing",
    ". The second approach is to build a simulator that mimics the reward and next-state transitions of the real environment. While straightforward, this approach strongly relies on the model assumptions in building the simulator. The third approach is to use importance sampling to correct the sampling bias in off-policy data. This can become inaccurate due to high variance. Liu et al. ( 2018a ) proposes a new estimator for infinite-horizon problems.",
    ". The second approach is to build a simulator that mimics the reward and next-state transitions of the real environment. While straightforward, this approach strongly relies on the model assumptions in building the simulator. The third approach is to use importance sampling to correct the sampling bias in off-policy data. This can become inaccurate due to high variance. Liu et al. ( 2018a ) proposes a new estimator for infinite-horizon problems.",
    ". The second approach is to build a simulator that mimics the reward and next-state transitions of the real environment. While straightforward, this approach strongly relies on the model assumptions in building the simulator. The third approach is to use importance sampling to correct the sampling bias in off-policy data. This can become inaccurate due to high variance. Liu et al. ( 2018a ) proposes a new estimator for infinite-horizon problems.",
    "task-agnostic feature than episodic training. Besides, the Metric-Softmax classifier can be applied to base and novel classes in a consistent manner. In the third stage, we design a task-adaptive transformation which adapts the classifier to each few-shot setting very fast within a few tuning epochs. Our approach outperforms current state-of-the-arts by a large margin on the commonly used mini-ImageNet benchmarks",
    "task-agnostic feature than episodic training. Besides, the Metric-Softmax classifier can be applied to base and novel classes in a consistent manner. In the third stage, we design a task-adaptive transformation which adapts the classifier to each few-shot setting very fast within a few tuning epochs. Our approach outperforms current state-of-the-arts by a large margin on the commonly used mini-ImageNet benchmarks",
    "task-agnostic feature than episodic training. Besides, the Metric-Softmax classifier can be applied to base and novel classes in a consistent manner. In the third stage, we design a task-adaptive transformation which adapts the classifier to each few-shot setting very fast within a few tuning epochs. Our approach outperforms current state-of-the-arts by a large margin on the commonly used mini-ImageNet benchmarks",
    "an unsupervised version with a differentiable PDE solver. In all cases, our learned assistance function lets a coarse simulation reproduce the behavior of the reference data more closely. To this end, we introduce a first learning-based approach that \u201c assists\u201d a given numerical method to improve its accuracy. To this end, we introduce a first learning-based approach that \u201c assists\u201d a given numerical method to improve its accuracy. To this end, we introduce a first learning-based",
    "an unsupervised version with a differentiable PDE solver. In all cases, our learned assistance function lets a coarse simulation reproduce the behavior of the reference data more closely. To this end, we introduce a first learning-based approach that \u201c assists\u201d a given numerical method to improve its accuracy. To this end, we introduce a first learning-based approach that \u201c assists\u201d a given numerical method to improve its accuracy. To this end, we introduce a first learning-based",
    "an unsupervised version with a differentiable PDE solver. In all cases, our learned assistance function lets a coarse simulation reproduce the behavior of the reference data more closely. To this end, we introduce a first learning-based approach that \u201c assists\u201d a given numerical method to improve its accuracy. To this end, we introduce a first learning-based approach that \u201c assists\u201d a given numerical method to improve its accuracy. To this end, we introduce a first learning-based",
    "......, 2018 ). In the field of continual/lifelong learning ( Thrun & Mitchell, 1995 ), approaches based on storing memories for later use have emerged as some of the most effective in online settings. In general, learned compression has become a topic of great interest. Yet its application in reducing the size of datasets bound for machine learning has been limited. In general al",
    "......, 2018 ). In the field of continual/lifelong learning ( Thrun & Mitchell, 1995 ), approaches based on storing memories for later use have emerged as some of the most effective in online settings. In general, learned compression has become a topic of great interest. Yet its application in reducing the size of datasets bound for machine learning has been limited. In general al",
    "......, 2018 ). In the field of continual/lifelong learning ( Thrun & Mitchell, 1995 ), approaches based on storing memories for later use have emerged as some of the most effective in online settings. In general, learned compression has become a topic of great interest. Yet its application in reducing the size of datasets bound for machine learning has been limited. In general al",
    "the problem of multi-label classification. For example, in document classification, one document can contain multiple semantic classes like mountain, beach and sea. We address the problem via metric learning approach. After the metric learning is completed, the problem is reduced as easy memory-based learning. Thus, the k nearest neighbor ( KNN ), one of popular and simple methods, can easily handle the multi-label classification. However, it still suffers following limitations :",
    "the problem of multi-label classification. For example, in document classification, one document can contain multiple semantic classes like mountain, beach and sea. We address the problem via metric learning approach. After the metric learning is completed, the problem is reduced as easy memory-based learning. Thus, the k nearest neighbor ( KNN ), one of popular and simple methods, can easily handle the multi-label classification. However, it still suffers following limitations :",
    "the problem of multi-label classification. For example, in document classification, one document can contain multiple semantic classes like mountain, beach and sea. We address the problem via metric learning approach. After the metric learning is completed, the problem is reduced as easy memory-based learning. Thus, the k nearest neighbor ( KNN ), one of popular and simple methods, can easily handle the multi-label classification. However, it still suffers following limitations :",
    "synchronization becomes a prominent bottleneck ( Li, 2014 ). This phenomenon is called gradient staleness or delay. Unless the learning rate is significantly decreased, we can see a deterioration in the generalization performance when using A-SGD. Equal contribution. Equal contribution. Equal contribution. Equal contribution. Equal contribution. Equal contribution. Equal contribution.",
    "synchronization becomes a prominent bottleneck ( Li, 2014 ). This phenomenon is called gradient staleness or delay. Unless the learning rate is significantly decreased, we can see a deterioration in the generalization performance when using A-SGD. Equal contribution. Equal contribution. Equal contribution. Equal contribution. Equal contribution. Equal contribution. Equal contribution.",
    "synchronization becomes a prominent bottleneck ( Li, 2014 ). This phenomenon is called gradient staleness or delay. Unless the learning rate is significantly decreased, we can see a deterioration in the generalization performance when using A-SGD. Equal contribution. Equal contribution. Equal contribution. Equal contribution. Equal contribution. Equal contribution. Equal contribution.",
    "model-free methods directly leverage the quantity of interest from the future but have to compose with a potentially weak scalar signal ( an estimate of the return ). To this end, we determine which features of the future trajectory provide useful information to predict the associated return. This provides tractable prediction targets that are directly relevant for a task. We then test our approach at scale in challenging domains. 1 INTRODUCTION. To intuitively understand how such information could help value prediction, consider",
    "model-free methods directly leverage the quantity of interest from the future but have to compose with a potentially weak scalar signal ( an estimate of the return ). To this end, we determine which features of the future trajectory provide useful information to predict the associated return. This provides tractable prediction targets that are directly relevant for a task. We then test our approach at scale in challenging domains. 1 INTRODUCTION. To intuitively understand how such information could help value prediction, consider",
    "model-free methods directly leverage the quantity of interest from the future but have to compose with a potentially weak scalar signal ( an estimate of the return ). To this end, we determine which features of the future trajectory provide useful information to predict the associated return. This provides tractable prediction targets that are directly relevant for a task. We then test our approach at scale in challenging domains. 1 INTRODUCTION. To intuitively understand how such information could help value prediction, consider",
    ". Recently, increasing effort has been devoted towards developing deep neural networks on graph structured data. This stream of works has shown to enhance the performance in many graph related tasks such as node classification. A greedy algorithm is proposed to attack both node classification and graph classification task by only modifying the graph structure and node features. A meta-learning based attack method is designed to impair the overall performance of the node classification task ( Z\u00fcgner & G\u00fcnn, 2018 )",
    ". Recently, increasing effort has been devoted towards developing deep neural networks on graph structured data. This stream of works has shown to enhance the performance in many graph related tasks such as node classification. A greedy algorithm is proposed to attack both node classification and graph classification task by only modifying the graph structure and node features. A meta-learning based attack method is designed to impair the overall performance of the node classification task ( Z\u00fcgner & G\u00fcnn, 2018 )",
    ". Recently, increasing effort has been devoted towards developing deep neural networks on graph structured data. This stream of works has shown to enhance the performance in many graph related tasks such as node classification. A greedy algorithm is proposed to attack both node classification and graph classification task by only modifying the graph structure and node features. A meta-learning based attack method is designed to impair the overall performance of the node classification task ( Z\u00fcgner & G\u00fcnn, 2018 )",
    "x  F ( x ) 2, ( 2 ). This paper is particularly interested in estimating the prediction error of encoder-decoder convolutional neural networks ( E-D CNNs ) such as U-Net ( Ronneberger et al., 2015 ; Han et al., 2018 ; Ye & Sung, 2019 ). The problem of estimating the prediction error is closely related to the generalizability",
    "x  F ( x ) 2, ( 2 ). This paper is particularly interested in estimating the prediction error of encoder-decoder convolutional neural networks ( E-D CNNs ) such as U-Net ( Ronneberger et al., 2015 ; Han et al., 2018 ; Ye & Sung, 2019 ). The problem of estimating the prediction error is closely related to the generalizability",
    "x  F ( x ) 2, ( 2 ). This paper is particularly interested in estimating the prediction error of encoder-decoder convolutional neural networks ( E-D CNNs ) such as U-Net ( Ronneberger et al., 2015 ; Han et al., 2018 ; Ye & Sung, 2019 ). The problem of estimating the prediction error is closely related to the generalizability",
    ". Moreover, within each task, the number of training instances per class may largely vary ( class imbalance ). Thus, the meta-knowledge may have a varying degree of utility to each task. For multi-class classification, we may want to treat the learning for each task in a task-specific Equal contribution manner. Moreover, for multi-class classification, we may want to treat the learning for each task in a task-specific E",
    ". Moreover, within each task, the number of training instances per class may largely vary ( class imbalance ). Thus, the meta-knowledge may have a varying degree of utility to each task. For multi-class classification, we may want to treat the learning for each task in a task-specific Equal contribution manner. Moreover, for multi-class classification, we may want to treat the learning for each task in a task-specific E",
    ". Moreover, within each task, the number of training instances per class may largely vary ( class imbalance ). Thus, the meta-knowledge may have a varying degree of utility to each task. For multi-class classification, we may want to treat the learning for each task in a task-specific Equal contribution manner. Moreover, for multi-class classification, we may want to treat the learning for each task in a task-specific E",
    "the agent does not observe a reward signal or query the expert. When the agent drifts away from the demonstrated states, the agent does not know how to return to the demonstrated states. Intuitively, an agent imitates an expert, given expert action demonstrations and the ability to interact with the environment. Intuitively, an agent imitates an expert, given expert action demonstrations and the ability to interact with the environment. Intuitively, an agent",
    "the agent does not observe a reward signal or query the expert. When the agent drifts away from the demonstrated states, the agent does not know how to return to the demonstrated states. Intuitively, an agent imitates an expert, given expert action demonstrations and the ability to interact with the environment. Intuitively, an agent imitates an expert, given expert action demonstrations and the ability to interact with the environment. Intuitively, an agent",
    "the agent does not observe a reward signal or query the expert. When the agent drifts away from the demonstrated states, the agent does not know how to return to the demonstrated states. Intuitively, an agent imitates an expert, given expert action demonstrations and the ability to interact with the environment. Intuitively, an agent imitates an expert, given expert action demonstrations and the ability to interact with the environment. Intuitively, an agent",
    ".. a method to learn stable and temporally coherent feature spaces for points clouds that change over time. We show that our method works for large, deforming point sets from different sources to demonstrate its flexibility. Several powerful approaches for point-based convolutions, which are easy to perform for Eulerian data, are proposed.",
    ".. a method to learn stable and temporally coherent feature spaces for points clouds that change over time. We show that our method works for large, deforming point sets from different sources to demonstrate its flexibility. Several powerful approaches for point-based convolutions, which are easy to perform for Eulerian data, are proposed.",
    ".. a method to learn stable and temporally coherent feature spaces for points clouds that change over time. We show that our method works for large, deforming point sets from different sources to demonstrate its flexibility. Several powerful approaches for point-based convolutions, which are easy to perform for Eulerian data, are proposed.",
    ". Optimal transport is an approach for taking two datasets, and computing a mapping between them in the form of a  transport plan '' . The mapping is optimal in the sense that among all reasonable mappings, it minimizes the cost of aligning the two datasets. For example, we might have single-cell RNA-seq datasets generated for the same tissue type from two different labs. Since data come from the same tissue type, we would",
    ". Optimal transport is an approach for taking two datasets, and computing a mapping between them in the form of a  transport plan '' . The mapping is optimal in the sense that among all reasonable mappings, it minimizes the cost of aligning the two datasets. For example, we might have single-cell RNA-seq datasets generated for the same tissue type from two different labs. Since data come from the same tissue type, we would",
    ". Optimal transport is an approach for taking two datasets, and computing a mapping between them in the form of a  transport plan '' . The mapping is optimal in the sense that among all reasonable mappings, it minimizes the cost of aligning the two datasets. For example, we might have single-cell RNA-seq datasets generated for the same tissue type from two different labs. Since data come from the same tissue type, we would",
    "difficult to define mathematically. We propose a solution in which anomalies can be defined using approximately correct features. This hypothesis provides a reliable starting point for normal data selection. The anomalies are rejected and the autoencoder retrained ( Mishne et al. ( 2017 ) ). The anomalies can be identified using a distribution-clustering framework. The autoencoder is retrained from the normal data subset. The autoencoder is",
    "difficult to define mathematically. We propose a solution in which anomalies can be defined using approximately correct features. This hypothesis provides a reliable starting point for normal data selection. The anomalies are rejected and the autoencoder retrained ( Mishne et al. ( 2017 ) ). The anomalies can be identified using a distribution-clustering framework. The autoencoder is retrained from the normal data subset. The autoencoder is",
    "difficult to define mathematically. We propose a solution in which anomalies can be defined using approximately correct features. This hypothesis provides a reliable starting point for normal data selection. The anomalies are rejected and the autoencoder retrained ( Mishne et al. ( 2017 ) ). The anomalies can be identified using a distribution-clustering framework. The autoencoder is retrained from the normal data subset. The autoencoder is",
    "autonomous vehicles. In this work, we address the problem of learning control policies that optimize a reward function while satisfying predefined constraints. To address the above issues, we propose projection-based constrained policy optimization ( PCPO ). The second stage maximizes reward using a trust region optimization method ( e.g., TRPO ( Schulman et al., 2018 ) ). The second stage minimizes reward using a trust region optimization method ( e.g.",
    "autonomous vehicles. In this work, we address the problem of learning control policies that optimize a reward function while satisfying predefined constraints. To address the above issues, we propose projection-based constrained policy optimization ( PCPO ). The second stage maximizes reward using a trust region optimization method ( e.g., TRPO ( Schulman et al., 2018 ) ). The second stage minimizes reward using a trust region optimization method ( e.g.",
    "autonomous vehicles. In this work, we address the problem of learning control policies that optimize a reward function while satisfying predefined constraints. To address the above issues, we propose projection-based constrained policy optimization ( PCPO ). The second stage maximizes reward using a trust region optimization method ( e.g., TRPO ( Schulman et al., 2018 ) ). The second stage minimizes reward using a trust region optimization method ( e.g.",
    "the word similarity such that words with similar semantic meaning are embedded closely in the embedding space. ( 1 ) Levy & Goldberg ( 2014b ) showes many different kinds of word embeddings. ( 2 ) Levy et al. ( 2015 ) ; Tian et al. ( 2016 ), empirically observe that  in word embedding E = Ud d 1 has an important influence on the quality of",
    "the word similarity such that words with similar semantic meaning are embedded closely in the embedding space. ( 1 ) Levy & Goldberg ( 2014b ) showes many different kinds of word embeddings. ( 2 ) Levy et al. ( 2015 ) ; Tian et al. ( 2016 ), empirically observe that  in word embedding E = Ud d 1 has an important influence on the quality of",
    "the word similarity such that words with similar semantic meaning are embedded closely in the embedding space. ( 1 ) Levy & Goldberg ( 2014b ) showes many different kinds of word embeddings. ( 2 ) Levy et al. ( 2015 ) ; Tian et al. ( 2016 ), empirically observe that  in word embedding E = Ud d 1 has an important influence on the quality of",
    ". The second design goal is to achieve efficient similarity measurement. 1.2 Prior art and their limitations. Similarity measurement is to measure the similarity between every pair of items in a given dataset. Currently the prevailing approaches belong to the first kind of solutions : mathematical distance-based similarity, Fidelity or Squared-chord family, Shannon \u2019 s entropy, Shannon \u2019 s entropy. Currently the prevailing approaches belong to the",
    ". The second design goal is to achieve efficient similarity measurement. 1.2 Prior art and their limitations. Similarity measurement is to measure the similarity between every pair of items in a given dataset. Currently the prevailing approaches belong to the first kind of solutions : mathematical distance-based similarity, Fidelity or Squared-chord family, Shannon \u2019 s entropy, Shannon \u2019 s entropy. Currently the prevailing approaches belong to the",
    ". The second design goal is to achieve efficient similarity measurement. 1.2 Prior art and their limitations. Similarity measurement is to measure the similarity between every pair of items in a given dataset. Currently the prevailing approaches belong to the first kind of solutions : mathematical distance-based similarity, Fidelity or Squared-chord family, Shannon \u2019 s entropy, Shannon \u2019 s entropy. Currently the prevailing approaches belong to the",
    ".. ergodic inference ( EI ). ergodic inference ( EI ). EI offers an appealing option to balance computational complexity vs. bias. \u2022 EI \u2019 s hyperparameter tuning produces a tractable objective function. \u2022 EI \u2019 s hyperparameter tuning produces a tractable objective function. \u2022 EI \u2019 s hyperparameter tuning produces a tractable objective function. \u2022 EI",
    ".. ergodic inference ( EI ). ergodic inference ( EI ). EI offers an appealing option to balance computational complexity vs. bias. \u2022 EI \u2019 s hyperparameter tuning produces a tractable objective function. \u2022 EI \u2019 s hyperparameter tuning produces a tractable objective function. \u2022 EI \u2019 s hyperparameter tuning produces a tractable objective function. \u2022 EI",
    ".. ergodic inference ( EI ). ergodic inference ( EI ). EI offers an appealing option to balance computational complexity vs. bias. \u2022 EI \u2019 s hyperparameter tuning produces a tractable objective function. \u2022 EI \u2019 s hyperparameter tuning produces a tractable objective function. \u2022 EI \u2019 s hyperparameter tuning produces a tractable objective function. \u2022 EI",
    "2018 ), predict the counterfactuals with GANs ( Athey et al., 2019 ). In particular, they rarely consider the possibility that covariates have missing values. This is ubiquitous in many real-world situations. In particular, they rarely consider the possibility that covariates have missing values.",
    "2018 ), predict the counterfactuals with GANs ( Athey et al., 2019 ). In particular, they rarely consider the possibility that covariates have missing values. This is ubiquitous in many real-world situations. In particular, they rarely consider the possibility that covariates have missing values.",
    "2018 ), predict the counterfactuals with GANs ( Athey et al., 2019 ). In particular, they rarely consider the possibility that covariates have missing values. This is ubiquitous in many real-world situations. In particular, they rarely consider the possibility that covariates have missing values.",
    "a fixed Markov Decision Process ( MDP ) M and an agent aiming to maximize its total expected/discounted reward obtained in the environment E governed byM. An agent is looking for a sequence of actions a0,..., aT1 leading to a series of steps maximizing this reward. We show that finding compact representations is a nontrivial optimization problem despite recent observations that some hardcoded structured families provide certain levels of compactification.",
    "a fixed Markov Decision Process ( MDP ) M and an agent aiming to maximize its total expected/discounted reward obtained in the environment E governed byM. An agent is looking for a sequence of actions a0,..., aT1 leading to a series of steps maximizing this reward. We show that finding compact representations is a nontrivial optimization problem despite recent observations that some hardcoded structured families provide certain levels of compactification.",
    "a fixed Markov Decision Process ( MDP ) M and an agent aiming to maximize its total expected/discounted reward obtained in the environment E governed byM. An agent is looking for a sequence of actions a0,..., aT1 leading to a series of steps maximizing this reward. We show that finding compact representations is a nontrivial optimization problem despite recent observations that some hardcoded structured families provide certain levels of compactification.",
    ". The selection of the time-frequency representation for analyzing, classifying, and predicting time-series has long been studied. However, an inherent drawback is that the selection of the time-frequency transform is often achieved with criteria that do not align with the task. For instance, a selection based on the sparsity of the representation while the task is the classification of the signals. Besides, these selection methods and transformations require substantial cross-validations of a large number",
    ". The selection of the time-frequency representation for analyzing, classifying, and predicting time-series has long been studied. However, an inherent drawback is that the selection of the time-frequency transform is often achieved with criteria that do not align with the task. For instance, a selection based on the sparsity of the representation while the task is the classification of the signals. Besides, these selection methods and transformations require substantial cross-validations of a large number",
    ". The selection of the time-frequency representation for analyzing, classifying, and predicting time-series has long been studied. However, an inherent drawback is that the selection of the time-frequency transform is often achieved with criteria that do not align with the task. For instance, a selection based on the sparsity of the representation while the task is the classification of the signals. Besides, these selection methods and transformations require substantial cross-validations of a large number",
    ". Graph Convolutional Networks. The success of convolutional networks and deep learning for image data has inspired generalizations for graphs. In machine learning ( ML ), data is most often represented in a Euclidean space. Third, some data is intrinsically Euclidean. Fourth, intuition is easier in such spaces. Finally, a lot of quantities of interest such as positions in 3D space in classical mechanics are represented in such spaces.",
    ". Graph Convolutional Networks. The success of convolutional networks and deep learning for image data has inspired generalizations for graphs. In machine learning ( ML ), data is most often represented in a Euclidean space. Third, some data is intrinsically Euclidean. Fourth, intuition is easier in such spaces. Finally, a lot of quantities of interest such as positions in 3D space in classical mechanics are represented in such spaces.",
    ". Graph Convolutional Networks. The success of convolutional networks and deep learning for image data has inspired generalizations for graphs. In machine learning ( ML ), data is most often represented in a Euclidean space. Third, some data is intrinsically Euclidean. Fourth, intuition is easier in such spaces. Finally, a lot of quantities of interest such as positions in 3D space in classical mechanics are represented in such spaces."
][
    "This paper studies FL under local differential privacy constraints. They identify two major concerns in designing practical privacy-preserving FL algorithms: communication efficiency and high\u0002dimensional compatibility, and develop a gradient-based learning algorithm sqSGD that addresses both concerns. They improve the base algorithm in two ways: First, apply a gradient subsampling strategy that offers simultaneously better training performance and smaller communication costs. Secondly, utilize randomized rotation as a preprocessing step to reduce quantization error. ",
    "This paper studies a low communication algorithm for multivariate mean estimation in the federated learning setting with differentially private communication. The algorithm uses quantization and dimension subsampling (only reporting some coordinates of the vector) to lower communication and randomized rotation (essentially applying a random orthogonal matrix) to reduce quantization error. They then apply this algorithm to ERM, using it as a subroutine in SGD. They experimentally explore the behavior of their algorithm on a number of benchmark datasets. They consider how the performance changes as they vary epsilon, the discretization parameter and the number of epochs (in SGD). ",
    "The paper proposed a differentially private training algorithm for federated learning. The target is to achieve communication reduction while keeping differential privacy during training. The proposed algorithm adds a few new components to SGD, including a privacy mechanism, a random rotation to reduce quantization error, a gradient coordinate selection mechanism to reduce communication/computation. Experiments with high \\epsilon local differentially privacy guarantees are conducted. The proposed algorithm outperforms a baseline algorithm.",
    "This submission works on the neural machine translation problem. The authors extend the previous works on leveraging language statistics or prior knowledge (SMT model or whatever) in LSTM based NMT models in self-attention based NMT models, Transformer model. The authors propose two alternatives to incorporate prior knowledge, which are the word frequency information for the monolingual data and the prior translation lexicon information for the bilingual data. These resources are integrated into the hidden representations from the self-attention computations and then the two output hidden representations are gated together for upper computations. The experiments are conducted on two typical NMT datasets: WMT14 En->De and WMT17 Zh->En, the results show that the proposed method can improve the NMT model performances. ",
    "This paper proposes a method to introduce **prior knowledge** into Transformer-based sentence encoders, here in the context of neural machine translation (NMT). More concretely, the prior knowledge is represented in the form of a matrix $\\boldsymbol{M}$, where each row denotes a vector of prior knowledge associated with each word $x_i$. The prior knowledge matrix $\\boldsymbol{M}$ is then represented as a (key, value) pair that can be attended by the query matrix $\\boldsymbol{Q}$ (the same query matrix as used in the main NMT component) using a standard Transformer self-attention mechanism. This procedure results in a prior knowledge representation matrix $\\boldsymbol{PK}$, which is then combined with the standard Transformer encoder output using a simple gating mechanism. ",
    "This paper presents a method for introducing prior knowledge into Transformer models. More specifically, the authors propose to use an additional self-attention block to incorporate prior knowledge about the word frequency and translation lexicon and use a gating mechanism to combine its output with that of the standard sefl-attention block. Experiments are conducted using English-to-German and Chinese-to-English translation datasets, and the results show the effectiveness of the proposed approach.",
    "This paper proposes the game-theoretic model of Bayesian Stackelberg Markov Games (BSMGs), a generalization of Markov games, as a formalism for studying Moving Target Defense (MTD) systems, a type of defender-attacker game with applications to cybersecurity. An algorithm for finding the Stackelberg equilibrium in BSMGs, called Bayesian Strong Stackelberg Q-Learning (BSS-Q) is proposed, and an OpenAI Gym-style environment for testing the derived policies in particular MTD settings is introduced, which allows for empirical evaluation of the policies' effectiveness. The paper then shows experimental results supporting the BSS-Q algorithm's success at finding the Strong Stackelberg Equilibrium of BSMGs.",
    "This paper studies the problem of learning how to adapt the defense methods in the domain of cybersecurity. The paper proposes a new model called Bayesian Stackelberg Markov Games (BSMG) to capture the uncertainty of the attacker's types as well as their strategic behaviors. The authors design Bayesian Strong Stackelberg Q-learning that can converge to the optimal movement policy for BSMG. The empirical studies verify the support the theoretical results.",
    "This paper introduces a Bayesian Stackelberg Markov Game (BSMG) model that considers a defender\u2019s uncertainty over attackers\u2019 types when implementing defensive strategies. It also proposes to use a Bayesian Strong Stackelberg Q-learning method to learn defense policies by first simulating an adversary to obtain feedback of an attack and then computing the Bayesian Strong Stackelberg Equilibrium for the BSMG with a solver. In this way, this work relaxes the assumption that the defender knows attackers\u2019 types in existing game-theoretic models for moving target defense.",
    "This paper proposes a simple and effective technique to improve disentanglement by coupling the latent spaces of different VAE models. It builds on Duan et al. (2019)\u2019s proposed method to rank the representations of different models. By learning a VAE ensemble with linear transformations between the latent spaces and an additional \u201ccross-model\u201d reconstruction loss, the authors show that they can achieve significantly better disentangling.",
    "The authors introduce a novel VAE-based approach for unsupervised learning of disentangled representations of image data.  The approach trains an ensemble of VAEs along with pair-wise linear transformations between their latent spaces.  The objective includes the ELBO objectives for each VAE as well as two additional pressures:  (i) An L2 similarity objective that pressures samples from each VAE latent space to match under linear transformations samples from the other VAE latent spaces, and (ii) A cross-model decoding objective that encourages decoding accuracy of the linearly transformed latent samples.  The authors provide a theoretical argument that the linear transformations should learn to be orthogonal, and show some experimental results indicating that their model performs well compared to baselines when evaluated with an established disentangling metric.",
    "This submission proposes an ensemble framework to improve learning disentangled representations with Variational Autoencoders (VAEs). The approach builds on the assumption that entangled latent representations learned by VAEs show some \u201cuniqueness\u201d in their latent space structure, while disentangled representations exhibit some \u201csimilarity\u201d; an assumption corroborated by recent studies. On that basis, a VAE ensemble approach is proposed where several VAEs are connected through linear mappings between the individual latent spaces to encourage alignment of latent representations and thus disentanglement. A formal derivation of the framework is provided and the formal validity of the underlying assumption demonstrated. Furthermore, empirical evaluation of the proposed approach in comparison to the standard VAE, beta-VAE and FactorVAE on the datasets dSprites (main results, main text) and CelebA (appendix) is performed, yielding improved results on the FactorVAE disentanglement metric (all baseline methods considered) as well as the Distance to Orthogonality (DtO) metric (only standard VAE considered).",
    "The paper proposes an efficient way to automatically choose the best or most suitable pipeline for different datasets. The proposed method can accelerate the AutoML using a pre-trained meta module. In particular, the AutoML job of a new supervised learning task can be accomplished without model evaluations, namely zero-shot / real-time AutoML. The meta module is constructed as a graph structure in which each node represents a dataset used for meta-training. ",
    "The problem that the authors attempt to solve is to determine what ML pipeline will perform best on any new dataset, without incurring in the extra cost of actually running a large number of such pipelines, as is typically done in AutoML algorithms. The way this paper tackles the problem is to train a neural network that given a new dataset as input, will output a pipeline that is predicted to perform well on that dataset. This neural network is trained on other datasets, for which high performing pipelines are already known. Predicting a pipeline for a new dataset thus only require a forward pass through their NN.",
    "This paper presents a very interesting idea of utilizing the documentation for the data and the operators in the pipeline to generate meta-features for meta-learning. This is a very novel application of graph neural networks GNNs and language models for AutoML meta-learning. This view of meta-learning takes a very intuitive on a very high level. The use of the outputs of existing AutoML systems (such as auto-sklearn, TPOT, etc) is also very intuitive and well motivated. All these intuitive ideas are put together into a novel AutoML recommendation architecture making use of modern deep learning components.",
    "the paper investigates what neural networks learn when trained with gradient descent, in case parts of the inputs are only partially relevant to the output. The main claim is that GD is what prevents compositionality. In a set of synthetic experiments it is shown that indeed GD learns to use all information in the input, which results in poor generalization ood when only a subset of it was relevant.",
    "This work analyzes the effect of gradient descent training on the compositionality of the learned model. It is shown that the gradient descent would use all the available information, even when it is redundant to learn the mapping from input to the output. It is then argued that the gradient descent training has the bias against compostionality despite the model architecture. Experiments are conducted on three simple benchmarks to demonstrate that when gradient descent trained model would use redundant information and not generalize compositionally. ",
    "This paper addresses the effects of gradient descent methods onto compositionality and compositional generalization of models. The authors claim that the optimization process imposes the models to deviate compositionality, which is defined with conditional independence among random variables of input, predicted output and the ground-truth. Since compositionality is one of important features of human intelligence, it has been interested widely in the field of AI/ML such as vision, language, neuro-symbolic approaches, common sense reasoning, disentangled representation, and the emergence conditions of compositionality. As it has been not much focused on the relationship with optimizers, it is fresh and interesting. However, it is not easy to figure out the position of this paper from two reasons: (1) the definitions on compositionality in this paper are not so compatible with recent related works, which mostly consider certain structures in models [ICLR19, JAIR20] or representative problems such as visual reasoning [CVPR17] and Raven progressive matrices [PNAS17]. (2) The authors do not consider quantitative approaches such as compositionality [ICLR19] or compositional generalization [ICLR20]. ",
    "The paper proposes NeoEA, an approach that further constrains KG embedding with ontology knowledge. The paper first tries to summarize the existing embedding-based entity alignment methods, stating that most of the methods choose TransE as scoring functions. But their embedding features are not aligned well compared to the neural-based or composition-based loss function. The paper, therefore, solves this problem by developing a new NeoEA architecture which shows that adding a KG-invariant ontology knowledge can minimize such difference. The experiment shows the new constraints can improve state-of-the-art baselines.",
    "Entity alignment plays an important role in improving the quality of cross-lingual knowledge graphs. As one of the most important solutions, embedding-based methods aim at learning a semantic space where the unique entity cross knowledge graphs can have the closest distance. Most of research focus on entity-level granular, but discard the whole picture of embedding space of cross-lingual KGs. Besides the aligned entity pairs as the labelled data, this paper extended the labelled data with the conditional neural and basic axioms, which are actually sets of randomly selected entities or entities with the same relation type. Then the final objective is to align the cross-lingual knowledge graphs by both optimizing the distance of labelled entity pairs and neural axioms.",
    "In the paper, the authors propose to minimize the discrepancy between pairs of (conditional) neural axioms to align the embedding spaces of different KGs. This method is justified by the authors' study of all kinds of OWL2 properties. The author also studied the influence of margin $\\lambda$ on less constrained/long-tail entities. The authors conducted experiments by adding the proposed model on top of the best models for entity alignment. The results are mixed, but the proposed model improves the SEA and RDGCN consistently. ",
    "The paper proposed to adopt differentiable network architecture search (DARTS) for the co-design of the sensor (a lensless camera) and the deep model for visual recognition tasks, so as to maximize the accuracy and minimize the energy consumption. The key idea is to include the sensor configuration, in this case the phase mask of a lensless camera modeled as 2D convolutions, as additional parameters in architecture search.  The proposed method was evaluated on simulated data for a number of vision tasks (image classification, face recognition and head pose estimation), as well as using fabricated masks on a real world camera. The results demonstrated significantly increase recognition performance given the same energy level.  ",
    "This paper presents a method called SACoD to develop a more efficient CNN-powered Phlatcam. The proposed method optimizes both the PhlatCam sensor and the backend CNN model simultaneously.  That is, the coded mask in Phlatcam and neural network weights are regarded as learnable parameters. The coded mask (the optical layer) can be considered as a special convolution layer. As a result, it achieves energy saving, model compressing as well as good accuracy. Extensive experiments and ablation studies are presented to show the effectiveness of the method.",
    "SACoD presents a novel attempt to integrate the computational capabilities of a lensless imaging system, PhlatCam, with the search for the optimal convolutional neural network design for a given task. SACoD provides a framework which enables joint optimization of sensor and CNN resulting in IoT devices that achieve higher task accuracy\u2019s with limited resource budgets of a typical IoT system. The authors present a new an optical layer design that enables above described features. Detailed experiments comparing SACoD sensor + CNN with other baseline models covering past papers, demonstrate the superiority of SACoD\u2019s accuracy/efficiency curve over that of separately optimizing CNN arch or sensor/CNN joint-optimizations that do not vary network architecture. Additionally, ablation studies and results from measurements from actual phase masks fabricated help breakdown the accuracy/efficiency benefits of SACoD while analyzing the noise limitations of mask fabrication process.",
    "The authors introduce a novel method for non-negative matrix factorization for timeseries and apply it to longitudinal honey bee interaction data.  The model leverages consistency of individuals over time by forcing the factors (or rather, the residuals of the factors with respect to a global trajectory) to be linear combinations of a small set of temporal basis functions.  These temporal basis functions are functions of the bee\u2019s age.  In other words, the factor embedding of each bee is a vector of linear combinations of 16 learned basis functions of time.  Since all bees use the same 16 temporal basis functions, given these basis functions the lifetime embedding of each bee is encapsulated by a small matrix of numbers, namely the coefficients for the temporal basis functions for each factor (and in practice only two factors were significant, so each bee\u2019s life is embedded in 32-dimensional space).  There are a number of regularizations on the temporal basis functions and the embedding coefficients.",
    "The authors present a matrix factorization model to jointly characterize the lifetime interactions of thousands of bees over generations. The problem is fascinating as both a technical and scientific question and the modeling framework appears novel. Although not directly addressed, the authors appear to be trying to solve a *tensor* factorization problem, not just the special case of a matrix (which is of course a 2-d tensor). It would have been interesting to see results comparing their method with a non-negative variant of, say, PARAFAC/CANDECOMP or generalizations thereof. It would have at least have been appropriate to explain why or why not existing tensor methods are not appropriate.",
    "This paper proposes a NMF formulation ||A-FF^T||^2 where A and F are different types of information extracted from social datasets. In the honeybee example the authors highlight, A represents the spatial relationship between bees, and F encodes the age of the bees. The authors setup F to be decomposable into two types of embeddings, one which characterizes the group activity and the other which characterizes the individual activity. ",
    "Review: This paper proposes data augmentation methods for medical imaging(especially for accelerated MRI) based on the MR physics. The augmentation includes both pixel preserving augmentations/general affine augmentations on both real and imaginary values in the image domain. Then, the augmented images are transformed to k-space domain and the k-space data are down-sampled for the input data generation for the accelerated MRI task. They claim that how to schedule p(the probability of applying combinations of augmentation) over the training is important and the schedules from p=0 and increasing over epochs shows best results, experimentally.",
    "In this paper, the authors design a data-augmentation pipeline for the domain of MRI reconstruction (specifically, by proposing sensible guidelines for augmenting k-space data when learning image reconstructions, to preserve the noise characteristics of the image data). They show that this pipeline works as you might expect data augmentation to work: it boosts results for small training sets and becomes increasingly less effective as the training set grows. However, while the problem domain is of interest, there are issues with the presented work.  ",
    "This paper presents a method to use data augmentation to improve accelerated MRI reconstruction when the amount of training data is limited. This is an important problem since MRI data is expensive to obtain. Traditional image augmentation methods can't be applied directly for this problem because MR images are complex valued. Further, the applied transformations need to preserve the noise distribution, without which model performance degrades significantly.",
    "The novelty of the network structure is marginal. The decomposition way of feature is very common in computer vision. Just utilizing the latent vector of the encoder with only the comparator loss to decompose the feature into two feature types is limited. The authors should show the visual differences between these two feature types. The expression of the article is very clear, but some basic theories need not be explained in detail (Such in Section 3.4)",
    "This paper considers the problem of order learning, which learns an ordinal classification function. This paper proposes to learn separarted order-relavent and order-irrelavent latent representations to improve the performance of existing methods, which is a very interesting and promising idea. However, the approach lacks novelty and convincing theoretical guarantees, as well as not showing convincing performance even through the insufficient empirical evaluation.",
    "- It is well presented. The idea of splitting the encoding feature space into task related features and non-task related features is probably not new. But the use of it in estimating rank might be new and intuitively it makes sense to use it. They also propose an extension to the clustering algorithm using a repulsive term and propose MAP estimation algorithm to assign a rank based on the output probabilities of the comparator when the max possible rank is known.",
    "This paper presents RAPID, an exploration algorithm for procedurally generated environments. The paper introduces an exploration scores composed of a local and global score. The local score is computed per-episode, it is the fraction of distinct states visited during an episode, the global score keeps track of the exploratory effort of the agent over the whole training procedure.",
    "This paper presents an exploration method for procedurally-generated environments, RAPID, which imitates the past episodes that have a good exploration behavior. First, authors introduce exploration scores, local score for per-episode view of the exploration behavior, and global score for long-term and historical view of exploration. The authors use the weighted sum of these two exploration scores and extrinsic reward as a final episodic exploration score. They rank the state-action pairs based on episodic exploration score and train the agent to imitate behaviors with high score. In experiments, they show the results by comparing state-of-the-art algorithms in several procedurally-generated environments.",
    "This paper tackles the problem of improving exploration in deep RL for procedurally-generated environments, where state-of-the-art exploration techniques typically fail. In the proposed approach, called RAPID, each agent-generated episode is evaluated with respect to its local exploration score (for the given episode), global exploration score (across all previous episodes), and extrinsic reward obtained. Episodes with high scores are stored in a replay buffer, and a policy is trained via behavioral cloning on batches of state-action pairs from this buffer. This policy is also used to produce the agent-generated episodes.",
    "This paper focuses on improving zero-shot classification by reducing the bias of the classifier towards seen classes. The bias occurs since the embedding is trained with visual examples from the seen classes, while using only the attribute information from unseen classes for testing. Authors propose an isometric propagation network that build a graph in both visual and semantic space, performs some steps of propagation, and then uses the updated prototypes for training a classifier. They use attention to construct the graph and also use attention to regularize the graph edges between the two spaces to be isometric. Authors also propose to use an episodic training method to improve learning. ",
    "In this paper Zero Shot Classification is studied using prototypes. Each class is represented with a visual and semantic prototype, and at test time compared to a visual example + prototype for a(n unseen) test class. The most similar test class is chosen. In this work a novel method is proposed to construct the prototypes, which are trained in an episode learning setting. On various benchmarks the proposed method performs better than existing method for the generalized zero-shot classification task (seen + unseen) test classes.",
    "The authors propose a novel computational pipeline to tackle a well-known problem in zero-shot learning: although multiple visual instances are available for the classes and categories to be recognized, one and only one semantic embedding is available to describe the classes/categories while using side information like attributes or relevant textual information. To cope with that problem, authors learn visual and semantic prototypes which are then adopted to perform gradient descent over a graph in which the topological relationship among similar/dissimilar classes are preserved. In the experimental validation, the proposed method shows its superiority among a number of prior methods in zero-shot learning, including discriminative and generative methods. ",
    "This paper presents a HyperGrid Transformer approach to fine-tuning, where one takes a pre-trained transformer model and then modifies it by introducing hypernetworks that modify the 2nd FFN in each transformer block by generating additional weights conditioned on input. These hyper-networks are trained on all tasks in GLUE/SuperGLUE datasets simultaneously and are task aware through prefixing of a task specific token to input. This allows one to fine-tune only a small number of parameters and end up with a model that performs quite well on all tasks at the same time, not much worse than fine-tuning the entire transformer model on all of these tasks.",
    "The authors propose HyperGrid Transformers with a decomposable hypernet-work that learns grid-wise projections to specialize regions in weight matrices for different tasks. Usually, people would use different models to solve different tasks respectively. In this paper, the authors focus on using a single model to solve all tasks and it will save a lot of model parameters for natural language understanding. And the authors have done comprehensive experiments on GLUE and SuperGLUE, and prove that the proposed single model can achieve much better performance than baseline and competitive performance with multiple task-specific models.",
    "This manuscript presents a HyperGrid Transformer, which is engaged in learning a single model to account for multi-tasks in NLP. The core idea of HyperGrid Transformer is to learn task-conditional dynamic weights in a grid-wise manner in the feed-forward layers, where the weights are factorized in local and global components. This idea is simple, materializing the goal of reducing the parameter cost for the used multi-task network. However, the conducted experiments look nice, showing promising performance on GLUE/SuperGLUE. Therefore, from my point of view, this work is worthy of a publication at ICLR. ",
    "This paper proposed a novel adaptive data augmentation algorithm that produces random perturbations on the training dataset to train an imitation learning-based self-driving network. It starts with a sensitivity analysis of network performance under different types and levels of perturbations. And a novel automated perturbed training dataset selection mechanism is then proposed to improve the performance. Validation has been conducted over simulated data with both seen and unseen perturbation types. ",
    "This work proposes a new method to improve the generalization of ML models for the task of vehicle steering using a hybrid of data augmentation and adversarial examples. In a nutshell, the proposed method attempts to increase the accuracy of the model by dynamically adding a selection of candidate datasets during training. Each of these \u201ccandidates\u201d is created offline applying a transform (e.g. blur, distortion, and changes in color representation) to the original (base) dataset. During training, the method chooses among the K transformed-datasets those who minimize the mean validation accuracy and based on this selection the steering model is retrained. The approach is evaluated on a driving dataset.",
    "This paper presents an algorithm to improve the model generalization of the task of \"learning to steer\". First, the sensitivity of a baseline learning algorithm to degraded images in varying qualities caused by different factors is carried out. Some empirical insights are gained. Then, a new training algorithm is proposed to solve a min-max optimization problem, where the most difficult datasets are chosen and used for training at each iteration. Experiments are conducted to validate the effectiveness of the proposed method. ",
    "+ The paper proposes a general framework to deal with constraints in optimization problems using neural networks. In my opinion this is an important problem since there exists no standard method in many existing deep neural network frameworks to deal with constraints, which are also inapplicable even if the constraints are only slightly nontrivial. The paper proposes to deal with equality and inequality constraints differently which may be often easier in large scale settings.",
    "There has been an increase of works using deep neural networks to heuristically predict solutions to constrained optimization problems. However, these methods cannot generalize to arbitrary constraints.  In this paper, the authors propose a method to build neural networks that output vectors that satisfy hard equality and inequality constraints. They do this by first having the network predict the underdetermined part of the system defined by the equalities, then doing a series of gradient steps to project the solution onto the space delineated by the inequalities. They evaluate on synthetic quadratic programs and problems derived from a AC power flow application.",
    "This paper proposes a method to strictly enforce hard constraints during a neural network, without compromising differentiability. The method has two stages 1) From a smaller set of predicted variables, compute the remaining ones so that equality constraints are satisfied; 2) Take a few gradient steps (w.r.t soft constraint) in case inequality constraints are violated. They perform experiments on synthetic and also somewhat applied instances of quadratic programs. The results look very promising.",
    "The authors propose regularization-based pruning methods with the penalty factors uniformly increased over the training session. The first algorithm (GReg-1) sorts the filters by L1-norm and only applies the increasing regularization to the \u201cunimportant\u201d filters; the second one (GReg-2) applies the increasing regularization to all the filters. The experiments are very extensive and convincing to support the claimed contributions.",
    "The paper proposes a new pruning scenario using regularization to better prune the network. The scenario has two-component, the first one proposes a new pruning schedule that does not directly remove the neurons that need to prune from the network. It removes the neurons by adding an L2 regularization and makes the neurons that need to remove gradually decrease to zero. The second one gives the importance score to the neurons. It uses the L2 regularization and studies how the coefficient \\lambda of the regularization term can influence the weight change to derive the neuron's importance in the neuron network. By perturbing the penalty term to the converged network, the algorithm can get the Hessian information to score the neurons but uses less time than calculating the Hessian. The paper also shows many empirical results on various benchmarks to show their advantages when using the new schedule and scoring criterion during the pruning process. The result shows that their method can get better at a fast speed.",
    "This paper explores how the basic L2 regularization can be exploited in a growing fashion for better deep network pruning. The authors proposed two algorithms in this work: (1) The first (called GReg-1) is a variant of the L1-norm based filter pruning method [Ref1]. The important/unimportant filters are decided by their L1-norms. Later the unimportant ones are forced to zero through the proposed rising penalty scheme. (2) The second algortihm (called Greg-2) imposes the rising L2 regularization on all the filters. It is theoretically shown in the paper that this makes the parameters to separate to different degrees according to their local curvatures (ie, Hessian values). The method takes advantage of this by driving the weights into two groups with stark magnitude difference and then prunes by the simple L1-norm criterion.  The two methods are demonstrated effective on CIFAR10/100 and ImageNet benchmarks in the comparison with many state-of-the-art methods. ",
    "The paper investigates how and why planning might be beneficial in model-based reinforcement learning settings. To that end, the authors ask three questions on planning in MBRL: (1) How does planning benefit MBRL agents? (2) Within planning, what choices drive performance? (3) To what extent does planning improve generalization? In order to answer these questions, the authors investigate the performance of MuZero in a variety of learning challenges while systematically ablating the algorithm to find how each part of the algorithm effects the overall performance.",
    "This paper tries to disentangle the role of planning in model-based reinforcement learning with a number of different ablations and modifications to MuZero. Specifically, the authors analyze the overall contribution of planning by omitting planning from which it is originally used in MuZero, and investigate different planner settings that can drive performance. In addition, they check the generalization advantage of MBRL. Overall, the paper is well-written, and experiments are conducted appropriately. The results provide some insights that other researchers in the MBRL community can leverage for their future work. My major concern is the lack of direct ablation study that can clearly show the advantage of planning in providing a good learning signal. See the detailed comments below.",
    "This paper analyzes the role of planning in the model-based reinforcement learning agent, based on evaluating MuZero on eight tasks (i.e. Ms.Pacman, Hero, Minipacman, Sokoban, 9x9Go, Acrobot, Cheetah, and Humanoid), which have discrete action spaces. The conducted experiments show three major implications: (1) Of the three parts in which search is used (i.e. search at evaluation time, search at training time for exploration, and using search result as a policy target), the role of serving as a policy improvement target was most substantial. (2) Deep tree search did not make a significant contribution to performance, and a simple Monte-Carlo rollout could be performant enough for MBRL. Also, a too small or too large search budget can be harmful to the performance of the MBRL agent. (3) Search at evaluation time was helpful for zero-shot generalization especially when the model is accurate.",
    "The authors propose a generalization of Value Iteration Networks to unknown, potentially continuous state spaces. They describe a framework for leveraging a learned graph embedding model (TransE) in combination with a deep RL model and an execution model based on graphical message passing to perform a VI-like operation. The authors show improved performance compared to baselines on a grid-world task with a known MDP, as well as several simple continuous control environments and the Atari game Freeway.",
    "The paper tackles an open problem of the value-iteration-network-paradigm. The proposed method (XLVIN) has a conceptual edge over traditional value iteration networks in that it can be applied to continuous problems and problems where the state space is either too big or not fully known in advance. The experiments mostly succeed in making the case that XLVINs:",
    "This paper proposed a novel policy prediction model that combines self-supervised contrastive learning, graph representation learning and neural algorithm execution to generalize the Value Iteration Networks to MDPs. The method described in the paper is a combination of existing works in the literature but seems to work well in practice. The experiments evaluate multiple aspects of the proposed model (E.g. number of executor layers, etc.) and show significant performance improvement over the existing approaches.",
    "This paper investigates the problem of learning monotone read-once DNF formulas using convex neural networks. Specifically, the authors explore the distribution-specific PAC setting, where training samples are drawn independently according to the uniform distributions and are labeled according to a target monotone read-once DNF. The main contribution of this study is essentially empirical: convex neural nets, trained with GD for minimizing the cumulative hinge loss, converge to global minima for which neural units coincide with the monomials of the target DNF. This remarkable stability is corroborated by theoretical insights about global minima.",
    "In this paper the aim in to understand the inductive bias of neural networks learning DNFs. The focus is in convex neural networks and gradient descent. It is shown that under a symmetric initialization, the global minimum that gradient descent converges to is similar to a DNF-recovery solution. Further, experimental evaluation demonstrates that gradient descent can recover read-once DNFs from data. ",
    "The paper considers learning Boolean functions represented by read-once DNFs by using neural networks. The neural network architecture consists of a hidden layer with 2^D components, which is rich enough to express any Boolean functions. Given a whole 2^D instances of some read-once DNF, the authors showed that (1) weights corresponds to the true DNF is the global minimum of the loss minimization problem with the network, (2) they empirically observe that gradient descent with a rounding heuristics finds the true DNF expression, and(3) the solution of a 2-norm minimization recovers the true DNF.",
    "This work presents a strategy for improving exploration and efficiency of RL by leveraging the graph structure of an episodic experience buffer. This strategy combines goal-oriented RL with structured exploration. The authors compare their proposed technique to two popular benchmarks for goal-reaching tasks. In addition, the authors provide some theoretical justification for their algorithmic choices.",
    "This paper proposes a new framework, GSRL, to handle the sparse reward challenge and better leverage past experiences. Specifically, it formulates trajectories as a dynamic graph, and generates hindsight-like goals based on sub-group division and attention mechanism. The authors provide theoretical analysis to show the efficiency and converge property of their method. The experimental result shows the proposed method significantly outperforms the baselines. ",
    "This paper introduces Graph Structured Reinforcement Learning (GSRL) framework, able to balance exploration and exploitation in RL. Actually, GSRL builds a dynamic graph based on historical trajectories. Then in order to learn from sparse or delayed rewards and  be able to reach a distant goal, it decomposes the main task into a sequence of easier and shorter tasks. An attention strategy has also been proposed that is able to select an appropriate goal for each one of the easiest tasks. Experiments have been conducted on various robotics manipulation tasks showing that GSRL performs better compared to HER and MAP algorithms. ",
    "This paper concerns about the use of experience replay in a way that past experience is sampled based on (implicit) levels so as for the agent to better adapt to the current task at hand. The authors defined a replay distribution (where experience is sampled) based on two scores relevant to learning potential and staleness. Due to its formulation, the change of replay distribution can be used as an outer-layer of a learning algorithm without any modification of the underlying learning mode. The authors conducted experiments over a set of benchmark data sets relevant to level-ness and found statistically significant improvements over more than half of the tasks.",
    "The present work considers the problem of learning in procedurally generated environments. This is a class of simulation environments in which each individual environment is created algorithmically where certain environmental factors are varied in each instance (referred to as levels in this work). Learning algorithms in this setting typically use a fixed set of training and evaluation environments. The present work proposes to sample the training environments such that the learning progress of the agent is optimized. This is achieved by proposing an algorithm for level prioritization during training. The performance of the approach is demonstrated on the Procgen Benchmark and two MiniGrid benchmarks and the authors argue that their approach induces an implicit curriculum in sparse reward settings.",
    "This paper allows agents to set the initial conditions (level) for procedurally generated episodes during exploration to past observed values, and proposes to have agents form an intrinsic curriculum by resampling past levels based on a heuristic measure of expected learning progress. The authors test several heuristic measures and find that the average absolute magnitude of the generalized advantage estimate works well. The authors hypothesize that this intrinsic curriculum will improve optimization/learning relative to an agent that always samples initial conditions from the environment distribution. The authors verify that their prioritization strategy usually improves performance in several Progen Benchmark and MiniGrid environments, usually by a small but statistically significant amount, but sometimes by a large amount. ",
    "The work studies the auxiliary task selection in deep learning to resolve the burden of selecting relevant tasks for pre-training or the multitask learning. By decomposing the auxiliary updates, one can reweight separately the beneficial and harmful directions so that the net contribution to the update of the primary task is always positive. The efficient implementation is experimented in text classification, image classification, and medical imaging transfer tasks.",
    "Leveraging the power of the data-rich related tasks have been studied (e.g., pre-training and multitask learning). This paper points out that careful utilization of auxiliary task is required to gain enhanced performance in primary tasks. In order to prevent harming the performance of primary tasks, they suggest the method to decompose auxiliary updates into three directions which have positive, negative and neutral impact on the primary task.",
    "The authors present a general formulation of different settings in multitask learning (including pretraining regimes), in a setting where the goal is to get best performance for a pre-specified primary task and additional auxiliary tasks. The main idea is to divide the gradients on the auxiliary task into 2 subspaces: a subspace where the gradients influence performance of the primary task and a subspace where they only influence the auxiliary task without changing the loss on the primary task. Within the subspace that does have influence on the primary task, it is easy to compute directions that have a positive or negative effect on the primary task, which allows to create different learning schemes given the gradients that point toward: i) auxiliary influence only, ii) positive influence on auxiliary tass, iii) negative influence on primary task. Experimental results show improvements over previously identified meta learning methods on 2 natural language datasets and 3 image datasets.",
    "The authors use a 3D world to explore grounded language learning, in which an agent uses RL to combine novel word-learning with stably acquired meanings to successfully identify and manipulate objects.  They show that a novel, psychologically-inspired memory mechanism is more memory-efficient than Transformers (both of which outperform plain LSTMs) and that it exhibits surprisingly robust generalization to novel action-object pairs.  The results should be of interest to many working in grounded language / multimodal representation learning, and the experiments are thorough and well-motivated. ",
    "This paper presents experiments for acquiring words via fast-mapping in an embodied environment. The technical contribution is interesting and solid, but the experiments fail to address some important questions that are yet scoped by the claims of the paper (namely, that learning is being done -both- fast and slow, as per the title). Notably, the paper is really well-written and readable, and the experiments on novel category + novel instance recognition are really convincing specifically for fast-mapping (4.1).",
    "An agent following instructions in a grounded world is a core task in AI. This paper studies agent that accomplish this using memory-based architecture. This paper presents an argument for a multi-modal memory-architecture called DCEM whose key/queries and values are dependent on language and vision modalities respectively (or vice versa). An argument is made that this will be helpful for generalizing to novel language at test-time. Results are presented in a simple 3D domain containing several objects randomly sampled each time from a set of 30 objects. Task contain two types of instructions: \"pick up an object\" and \"place an object on another object\". Interaction proceeds in episodes where each episode contains a discovery phase where the agent learns the phrase associated with each object, and an instruction phase where the agent solves a given instruction. The proposed DCEM model outperforms baselines on various metrics and ablation. Importantly, it is shown that the DCEM can generalize to novel object names. ",
    "The paper analyses the effect of class imbalance on few-shot learning problems. It draws a number of interesting (but kind of expected) conclusions e.g., the support set imbalance has a larger influence on the FSL performance compared to base class imbalance, a high impact of imbalance on gradient-based meta-learning methods compared to metric learning approaches. The paper is overall  ",
    "The authors present a detailed study of few-shot class-imbalance along three axes: dataset vs. support set imbalance, effect of different imbalance distributions (linear, step, random), and effect of rebalancing techniques. The authors extensively compare over 10 state-of-the-art few-shot learning methods using backbones of different depths on multiple datasets. The analysis reveals that 1) compared to the balanced task, the performances of their class-imbalance counterparts always drop, by up to 18.0% for optimization-based methods, although feature-transfer and metric-based methods generally suffer less, 2) strategies used to mitigate imbalance in supervised learning can be adapted to the few-shot case resulting in better performances, 3) the effects of imbalance at the dataset level are less significant than the effects at the support set level. ",
    "This paper conducts extensive comparison experiments to study the effect of class-imbalance for many few-shot approaches. A detailed study of few-shot class-imbalance along three axes: dataset vs. support set imbalance, effect of different imbalance distributions (linear, step, random), and effect of rebalancing techniques, are presented. Also, this paper is clearly written and easy to understand. ",
    "The paper proposes Polynomial Graph Convolution (PGC), which enjoys a larger-than-one-hop receptive field within a single layer. This is done by first propagating information with a fixed (not learned) propagation matrix (e.g. adjacency matrix or graph Laplacian), and then projecting the information from different topological distances with a learned linear layer. PGC is shown to be theoretically more expressive than linearly stacking simple graph convolutions; experiments on several graph classification tasks show good performance.",
    "This work proposes the Polynomial Graph Convolutional Networks (PGCNs), which is built upon the Polynomial Graph Convolution (PGC). The PGC is able to aggregate k-hop information in a single layer and comes with the hyper-parameter k. The PGCNs are composed of a PGC with k=1, followed by a PGC with a chosen k (usually > 1), and a complex readout layer using avg, max, and sum over all nodes. Theoretically, the proposed PGC has two major benefits as claimed: 1) Common graph convolution operators can be represented as special cases of the PGC; 2) A PGC with k = q (q > 1) is more expressive than linearly stacked q PGCs with k=1. The PGCNs are thus more general, expressive, and efficient than existing GNNs. Experimental studies are conducted on common graph classification benchmarks, showing the improved performances of the PGCNs.",
    "The article presents a novel framework for Graph Convolutional Neural Networks (GCNs). The method called  Polynomial Graph Convolution (PGC) is based on concatenating the powers of a transformed adjacent matrix in a given layer. The paper shows that various popular variants of GNNs can be expressed using the PGC framework.  Theoretical results presented show that PGC with higher degree is more expressive that deeper std. GNNs. Numerical results are presented on graph classification task that illustrate the performance of the method.",
    "This paper introduces a framework to utilize the synthetic data as augmentations in the scene graph generation task, which is able to narrow the domain gap by decomposing it into several discrepancies between the two domains. They are the first to propose the synthetic-to-real transfer learning for SGG. The experimental results show the Sim2SG can improve the baseline models in three different scenarios: CLEVR, Dining-Sim, and Drive-Sim.",
    "The paper addresses the problem of learning scene graphs from synthetic data and unlabeled real data while performing well on real data by narrowing the content and appearance gap between the two domains when training on synthetic data. Scene graphs are extracted in a two-step process, mapping input to an intermediate latent space and generating the final prediction from the latent space. The authors decompose the content gap into two components: (a) label discrepancy, i.e. how much do the label distributions between the two domains differ, and (b) prediction discrepancy, i.e. the difference in distributions of outputs predicted from the latent space for the two domains. They further model the appearance gap by aligning the latent representation for both domains after accounting for the content gap (to avoid spurious influence of differing content distributions as the latent space is expected to comprise content and appearance). Most of these components are intractable and the paper provides approximations. Empirical investigation on two entirely synthetic and one real/synthetic data set provide evidence for the benefit of the method in closing the posed domain gaps as well as the quality of chosen approximations, the influence of the individual content and appearance gap terms, and the effectiveness of the optimization procedure.",
    "The paper tackles the problem of sim2real transfer for scene graph inference. It proposes an approach for closing the gap between simulated training data and real test data, to allow models trained purely on simulated data to be deployed on real images. The approach is tested on multiple environments, including transfer from a driving scene simulator to real KITTI scenes.",
    "This paper proposes Randomized Ensembled Double Q-Learning (REDQ), a new model-free RL algorithm that aims to improve the sample efficiency over existing model-free methods. Experiments on Mujoco show that REDQ achieves better sample efficiency than popular model-free methods such as SAC and is comparable with model-based methods such as MBPO. The paper further provides extensive ablation studies that justify the necessity of the algorithmic components in REDQ and show that improved Q estimation bias may have been the key reason for the performance gain. The paper also provides some theoretical analysis of the Q estimation bias.",
    "The paper proposes three techniques that altogether greatly improves the performance of soft actor-critic (SAC), resulting in a new algorithm called REDQ. (1) A higher update-to-data ratio, which speeds up the critic update. (2) Using the average ensemble Q for the policy gradient, therefore reducing its variance. (3) Taking the min of a small subset of the ensemble Qs to compute the target Q, therefore reducing the Q bias. The paper also performs extensive ablation studies to prove the importance of each technique.",
    "This work proposes a modification for double Q-learning, termed as randomized ensembled double Q-learning (REDQ). REDQ maintains $N$ different Q functions, and for each update, the target value is a minimization over $M$ randomly chosen Q functions, where $1 \\le M \\le N$. In addition, REDQ adopts a high update-to-data ratio to improve the sample efficiency. Empirical results show that the proposed method outperforms state-of-the-art model-based algorithms in certain tasks with continuous action space.",
    "The method introduces the DIDA architecture to learn from distributions and be invariant to feature ordering and size.  The authors extend the ideas proposed by Maron et al. (2020) to the continuous domain and generalize their results.  The experiments are done on two tasks.  The patch identification (out-of-distribution test) clearly show the invariance to feature and dataset size. Nevertheless, it is not clear whether the method is invariant to feature permutation.  The performance model task shows properties of the architecture to predict global structures of the dataset within their meta-features.",
    "The paper presents a neural network layer designed to process distribution samples that is invariant to permutations of the samples and the features. The proposed method is compared empirically to DSS, which achieves the same types of invariance but is restricted to point sets rather than discrete or continuous probability distributions. The two tasks used for the empirical evaluation in the paper are: a) patch identification (are two blocks of data extracted from the same original dataset?) and b) model configuration assessment (is one configuration of a learning algorithm going to produce a more accurate model for a particular dataset than another one?). On the first task, the paper compares to models built using Dataset2Vec embeddings as well as DSS. On the second task, the paper compares to handcrafted features as well as DSS. In both tasks, the proposed method produces more accurate predictors than DSS, etc. The paper also has some theoretical results regarding the universality of the proposed architecture and its robustness w.r.t. Lipschitz-bounded transformations. ",
    "This paper proposes a novel set/distribution representation architecture DIDA, which leverages pairwise embedding of the set\u2019s elements. The method can be used to represent discrete and continuous distribution representation. The authors also provide the theoretical proofs of the universality of the invariant layers, the local consistency. The experiments show that the architecture improves some dataset representation tasks",
    "This paper studies ways of adding edges to graphs to improve the result of spectral embedding / clustering. It refines existing embeddings using by measuring edges' effect on Laplacian eigenvalues, and adjusting such edges to reduce the distortions. The performance of the algorithm is justified using developments of worst-case efficient algorithms for Laplacian matrices, and experimentally, the algorithm converges quickly when starting with nearest neighbor graphs, and leads to significant increases in accuracy.",
    "The paper proposes a graph learning method for spectral embedding and associated problems such as clustering and dimension reduction. What differentiates the method from much the existing literature is that it focuses approximating an optimal densification of a very sparse initial graph rather than on sparsification of an initial graph, as is more common. The method is based on iteratively identifying edges to add to the graph so as to best improve the corresponding spectral embedding, so called \"spectrally critical\" edges. The authors motivate spectral criticality in relation to the partial derivatives of an objective function inspired by the log-likelihood of a Gaussian graphical model. In particular, those with the highest partial derivatives will tend to be those which, through their addition to the graph, lead to the greatest increase in this objective. The authors go on to discuss a close connection between spectral criticality and distance distortion when comparing the spectral embedding and the original input space. Since the initial graph is very sparse it can be efficiently determined, and the relatively small number of additional edges which need to be added by the proposed method to obtain a high quality embedding means that the entire procedure can be implemented efficiently.",
    "and significance: Learning a graph from data is an important, yet less studied, problem. The proposed algorithm (GRASPEL) is based on a graphical Lasso formulation with the precision matrix restricted to be a graph Laplacian. The algorithm starts with a sparse kNN graph, and recursively adds critical edges (identification of these critical edges based on Lasso and spectral perturbation analysis is the main contribution of the paper). ",
    "This paper proposes a method for combining intrinsic motivation on a state space with goal-conditioned reinforcement learning (GCRL), where goals are defined in some \u201cperceptual space,\u201d such as text or images, which describe the current state. The authors assume access to a renderer that maps states to perceptual goals, but do not assume that the renderer is differentiable. The authors propose to train an intrinsically motivated latent-conditioned policy, using similar techniques as past work in which a policy maximizes the mutual information between a latent variable and the current state. The goal-conditioned policy is then trained to effectively imitate the latent-conditioned policy by maximizing the same reward as the latent-conditioned policy, conditioned on only the rendered version of the final state reached by the latent-conditioned policy. The authors demonstrate that the overall method outperforms past GCRL methods on a variety of tasks (Atari, MuJoCo manipulation and locomotion, and toy tasks).",
    "This paper proposes an unsupervised learning objective for learning perceptual goal-conditioned policies. The goal is to enable unsupervised discovery of high-level behaviors in tandem with a perceptual-goal conditioned policy that can achieve these behaviors. The learning proceeds by training one policy to exhibit diverse behaviors; the states induced by these behaviors are then rendered and used as target goal states for a separate goal-conditioned policy.",
    "This paper proposes a new solution to the problem of learning goal-conditioned policies without hand-crafted rewards. Prior work in this domain learn an embedding space to compute reward between current state and goal. In contrast, this paper utilizes unsupervised skill discovery from [1] to obtain a discriminator that identifies which states belong to a particular skill. Then, the final state of a given skill's execution is used as a goal input to a goal-conditioned policy, which is rewarded if it generates states that the discriminator identifies with this skill. The paper aims to validate the benefit of such a reward over other embedding-distance based reward functions on a variety of environments.",
    "In many real world applications for RL such as medicine, there are limits on the number of policies from which we can simulate data. This paper proposes an approach that adaptively decides when to update the simulation policy, based on the difference between it and the current learned policy. Experiments on a medical treatment environment and Atari show that the approach obtains similar performance to on-policy RL with fewer changes of the simulation policy.",
    "In the RL context, this paper aims at designing a generic solution for reducing the number of policy switches during training (called switching cost) while maintaining the performance. This study is done in the context of deep reinforcement learning. A few generic baselines solutions are provided as well as a more complex solution that empirically outperforms the baselines.",
    "This paper studies RL with low switching cost under the deep RL setting. It points out several naive algorithms like switching after a certain number of steps and then propose a new heuristic. This heuristic learns a new policy offline using the experience replay the behavior collected and switches the behavior policy once the similarity of the feature embeddings of the current state by these two policies becomes large. The paper also makes an attempt to provide a theoretical justification for a better understanding of the heuristic. This method might outperform the naive algorithms by some margin, if any. It would be a more interesting manuscript if some stronger results could be provided from the perspective of any of theory, experiments, or applications.",
    "This paper proposes homotopy SGD (H-SGD) which solves a sequence of unconstrained problems with a homotopy map and homotopy parameter. The authors analyze the algorithm for solving nonconvex problems satisfying PL condition. The analysis works with a generic homotopy map and homotopy parameter satisfying certain conditions (given in Sec 3.1). The authors show linear convergence to a neighborhood of the minimizer. The theoretical results are validated with experiments with clear explanations.",
    "This paper proposed a Homotopy-Stochastic Gradient Descent (H-SGD) algorithm by applying homotopy strategy to explore the nice local structures of problems. H-SGD can gradually approximate to the target objective function and enjoys a global linear convergence to reach a neighborhood of a minimizer. As verified by the author, the assumption of this paper is weaker than its predecessors, Karimi et al., 2016; Vaswani et al., 2019. Further, the numerical experiments verified the effectiveness of H-SGD on regression and classification tasks.",
    "1. It seems to me the proposed Homotopy-SGD is not a practical algorithm, as in each iteration the algorithm has to solve a nontrivial (possibly nonconvex) subproblem. In other words, each subproblem can be as difficult as the original problem. This leads to an essential question that what is the practical motivation of this algorithm?",
    "This paper proposes a way of reconstructing a surface from sparse point clouds via a \"meta learning\" approach. Specifically, the authors view each shape in a collection as a \"domain\", and predicting the SDF values of points in R^3 to reconstruct a given shape (the reconstructed surface is the isosurface of the SDF field) as the \"task\" for that domain. Then, they use a network to predict a distribution over \"task-specific\" latent vectors that characterizes the reconstruction task for a given shape. Given a latent-vector sampled for one shape, they pass it to a decoder that predicts the SDF value at any point in R^3 for that shape.",
    "This paper introduces a meta-learning approach for the neural implicit representation of 3D shapes. The main idea, in my understanding, is to consider the points in the input point cloud as few-shot examples of the object so that each of them can be encoded in a way to best approximate the entire object information. The experiments show that the network can reconstruct the entire shape well even with a very small number of the input points, such as 50 and 100. For better reconstruction, the authors also proposed to use some implicit function regularizations, which are introduced in a previous work (Gropp et al., 2020).",
    "This paper tackles the task of point cloud completion, aiming to infer an implicit occupancy representation given a sparse input point cloud. Following recent practices, the approach represents the shape via a latent-variable conditioned occupancy function $f_{\\phi}(x, h)$ that infers occupancy of a point $x$ given latent $h$. The central task addressed here is to be able to infer a posterior distribution over the latent variable given some observed points $D$ i.e. $p_{\\theta}(h|D)$.",
    "This paper studies the use of channel suppression in improving robustness to adversarial examples. The authors make a convincing illustration in section 3 on how adversarial examples tend to activate more channels compared to natural examples, and adversarial training is not effective in reducing them. This provides a convincing motivation to their design of the Channel-wise Activation Suppression (CAS) module. Their CAS module is also effective in improving adversarial robustness when used in conjunction with different adversarial defense methods, including adversarial training, TRADES, and MART. ",
    "This paper investigates the adversarial robustness from the activation perspective. Specifically, the authors analyzed the difference in the magnitude and distribution of activation between adversarial examples and clean examples: the activation magnitudes of adversarial examples are higher and the activation channels are more uniform by adversarial examples. Based on the above interesting findings, the authors claim that different channels of intermediate layers contribute differently to the class prediction and propose a Channel-wise Activation Suppressing (CAS) method to suppress redundant activations, which can improve the DNN robustness. ",
    "The authors studied the behavior of adversarial examples from the channel view of activations, which is very novel. They focused on the magnitude and frequency of activations and found that state-of-the-art adversarial defense (adversarial training) only addressed the magnitude issue but the frequency distribution issue remains. This provided a novel perspective for us to understand why state-of-the-art adversarial training method works to a certain extent but not so good. Then, the authors proposed a Channel-wise Activation Suppressing (CAS) to address the frequency distribution to further improve the adversarial robustness. CAS is generic, effective, and can be easily incorporated into many existing defense methods. ",
    "This paper studies the optimization and generalization properties of a two-layer linear network. The considered setting is over-parameterized linear regression where the input dimension is D, number of samples is n<D, and the target dimension is m. The hidden width is h. The paper has two main results. The first result is exponential convergence of gradient flow to global minimum, where the convergence rate depends on the (m+n-1)-th singular value of an \"imbalance\" matrix. The second result shows that the solution found is close to the minimum L2 norm solution if certain orthogonality assumption is approximately satisfied at initially; then it was shown that if the width h is sufficiently large, then under a random initialization scheme, the solution found is close to the minimum L2 norm solution with a distance $1/\\sqrt{h}$.",
    "This paper analyzes the convergence of gradient descent optimizing overparametrized linear nn, and proves a exponential convergence rate. Moreover, the paper proposes the distance of the optimizer to the smallest norm solution, which is justified in other papers such as Montanari, etc. as the generalizable solution. Thus the solution that SGD outputs has good generalization as well.",
    "This paper proves the convergence rate of gradient flow for training two-layer linear networks. In particular, this paper discusses the connection between initialization, optimization, generalization, and overparameterization. The results show that gradient flow can converge to the global minimum at a rate depending on the level of imbalance of the initialization. Moreover, the authors show that random initialization and overparameterization can implicitly constrain the gradient flow trajectory to converge to a point lying in a low-dimensional manifold, thus guarantees good generalization ability.",
    "The paper shows that the kernel derived from deep fully-connected networks on the sphere have the same approximation properties as their two-layer counterpart for ReLU activations. This implies the limitations of the kernel framework for studying the benefits of such deep networks. The authors derive the asymptotic eigenvalue decay of dot-product kernels from differentiability properties of the kernel function.",
    "This paper analyzed the expressive power of kernels by studying the reproducing kernel Hilbert space (RKHS) associated with the kernels. Specifically, the authors analyzed the eigenvalue decays in terms of the power series expansions of the kernel function around some points, which is related to the RKHS of the kernel. This analysis can be used to recover some previous results. Besides, using this analysis, the authors have shown several interesting results, including that NTK (which corresponds to fully-connected ReLU networks with infinite width, small learning rate, and proper initialization) with any depth has the same RKHS. The main result also has other corollaries about other kinds of kernels, e.g., Laplace kernel and infinitely differentiable kernels. Experiments were done to validate the theoretical results on synthetic datasets and MNIST/Fashion-MNIST.",
    "Recently, there are a large number of deep learning theory papers related to the property of neural tangent kernel. This paper shows that for ReLU, the kernels derived from deep fully-connected networks have the same approx. properties as their shallow two-layer counterpart. This highlights the limitation of the kernel framework for understanding the benefits of deep networks from such perspective.",
    "The authors propose a deterministic policy-gradient algorithm that extends the TD3 algorithm (Fujimoto 2018). The main claim is that it reduces overestimation issues in a more effective way. Two Q-critics are maintained with separate parameters, but updated using the same transitions. Then a convex combination of these critics is used in the deterministic policy gradient update. The mixture parameter is learned on a slower time-scale to minimize this convex combination over states (instead of taking the minimum of the 2 critics per batch as in TD3). Another contribution in the paper is the \u201cUnbiased\u201d variant of the algorithm (UAD3), which addresses the off-policy nature of the replay mechanism of the AD3 algorithm described above. My understanding is that this is simply a version of the algorithm that does not use any replay mechanism and samples the state iid from the on-policy distribution, so it isn\u2019t a novel idea in itself.",
    "This paper proposes new value-based deep reinforcement learning algorithms (AD3 and UAD3) to address the overestimation bias issue of Q learning. The main contributions of this paper are three folds: 1) The authors propose a weighted sum of two state-action value functions that are trained separately. Then, it is used to update the policy. 2) The mixing weights are updated by the two-step separation method. 3) The original method (AD3) is integrated with the idea of unbiased DRL (Zhang and Huang, 2020). ",
    "The paper presents an approach to mitigate the overestimation issue, which is quite common in RL algorithms whenever computing boostrap target is needed. The key idea is to introduce a weight parameter between two Q values and adopt a dual problem formulation to learn this weight and the policy parameters. The authors propose a two-step method to estimate these parameters and present some experiments to show the proposed algorithm's performance.",
    "The authors proposed inverse reinforcement learning (IRL) algorithm based on Monte Carlo expectation-maximization (MCEM) that maximizes the predictive distribution of trajectories given the reward distribution parameter (eq (1)). In my understanding, the knowledge of the environment dynamics is assumed. The authors tried to validate the proposed idea on objectworld (Levine et al., 2011)",
    "The authors propose an approach to model-based inverse reinforcement learning which estimates a Gaussian mixture model over reward-function parameters. The method uses MCEM and samples reward functions from a current estimate of the GMM, updates them via a gradient-descent based maximum likelihood approach and then updates the GMM to fit the updated parameters. The authors evaluate the approach on objectworld.",
    "The paper proposes a novel method for inverse reinforcement learning: inferring a (distribution over) reward functions from a set of expert demonstrations. Prior work has either learned a point-estimate, notably maximum entropy IRL, or used Bayesian methods to learn a probability distribution over reward functions. Maximum entropy IRL has scaled to complex environments with unknown dynamics and non-linear rewards (with methods such as AIRL), but do not learn a probability distribution. By contrast, Bayesian IRL is more theoretically principled, but has not scaled to complex environments or non-linear rewards. This paper performs maximum likelihood estimation of a parameter for a *generative model* over probability distributions, using a Monte-Carlo expectation-maximization (MCEM) method. It therefore still outputs a probability distribution like Bayesian IRL, but is able to learn non-linear rewards unlike prior Bayesian methods.",
    "of the paper: The paper gives a theoretical justification of self-training. It proposes a new notion of \"expansion\" - the amount of data distribution in the neighbor of an example. Here the neighbor means adding perturbations to the example, or augmentations of the example. When the label distribution satisfies nice expansion properties and that classes are properly separated according to the neighbors, the paper proves distributional guarantees of self-training. Combining with generalization bounds of DNNs, the paper also derives finite sample bounds for DNNs. The paper also verifies the expansion assumption via experiments using a GAN.",
    "This work provides a unified framework to analyze the self-training, semi-supervised algorithms. The key assumptions are 1) the \u201cexpansion\u201d assumption which characterizes the low-probability data subset must expand to a neighborhood with large probability; and 2) the neighborhoods of samples from different classes have small overlap.  Then the authors established the upper bound of the prediction error on the population when minimizing the self-training and input-consistency based loss on the population. They also extend their results to a finite-sample setting and semi-supervised setting as well.  ",
    "This paper provides a theoretical analysis of self-training for semi-supervised learning, unsupervised domain adaptation, and unsupervised learning. The authors propose a novel assumption that they dub _expansion_ to effect this analysis. The expansion assumption requires that the neighborhood of small sets have a class conditional distribution that is large. Under this assumption, the authors show population results for an algorithm that performs self-training under the objective that enforces input consistency. ",
    "This paper proposes a VAE based hierarchical model for video prediction. The model employs recurrent model to predict intermediate representations (in the form of label maps) and these representations are mapped to pixel level information, i.e., videos. The paper presents an interesting idea of using representations that do not use any domain knowledge. The authors demonstrate the value of modeling temporal evolution of these representations which enables long term video prediction.",
    "The paper extends video-to-video translation model of (Wang\u201918) to video prediction by first generating a sequence of segmentation masks and then translating them into videos. Variational video prediction is used to generate a sequence of segmentation masks. The model produces impressive high-resolution and long-horizon results, and is extensively evaluated on Kitti, Cityscapes, and dancing data, outperforming some previously proposed methods.",
    "This paper proposes a hierarchical framework for long-term video prediction. The structure is firstly predicted in the form of semantic map. It lies in a categorical structure space which is easier to predict. Then the authors translate the predicted semantic map to a real video sequence in a frame-by-frame manner. The proposed model is \"surprisingly successful\" for long-term video prediction, as claimed by the authors (thousands frames). ",
    "This work proposes a new graph neural network architecture with modified rules for message passing, Iterated Graph Neural Network System (IGNNS). The paper then provides a theoretical analysis of the proposed architecture by connecting it with Iterated Function System (IFS), an important research field in fractal geometry. This paper further demonstrates empirically that the proposed architecture outperforms related models on citation network datasets.",
    "This paper proposes a new framework of GNN which can deal with undirected and directed graphs in a unified way. The authors argue that the size of the symbol space for a message passing path with length n is 2^n, while previous architectures only have constant size. Motivated by this observation, the authors borrow ideas from Iterated Function System to augment the symbol space. ",
    "The paper proposes a new definition of GNNs designed to cope with bi-directional message-passing processes.  To do so, a new symbols space, different from the one adopted by Bidirectional GCN,  is considered, together with an iterated function system. These lead to an architecture composed of 4 steps: an input layer that acts as a classic FC layer; an IFS layer that applies the iterated function system considering the adjacency matrix; a layer to concatenate or sum the expected values of each iteration; and an output layer that combines the results using the functions of the IFS and a new learnable weight matrix.",
    "The paper investigates graph generation using adversarial technics. They introduce an algorithm named GG-GAN, based on Wassertain GAN, in order to accurately generates new graphs in hopefully the same distribution as a given dataset. GG-GAN generates points in an euclidian space that is then turned into a graph using a similarity function on the space. This approach is justified by Theorem 1. The authors show that their method successfully generate graphs within the same scope as the input dataset, and show that GG-GAN generates much more new graphs that current state of the art approach.",
    "In general, this paper deals with an interesting and essential problem to generate geometric graphs under several standards. The whole algorithm seems easy to implement or reproduce. It seems with minor modifications to traditional autoregressor based generative graph models, the proposed framework can effectively model isomorphism as well as delivers certain novelty. The idea of the paper is with novelty and some theorems can support the observations.",
    "The work proposes to use WGAN architecture to learn latent space for generating new graphs with similar properties to the original ones. The authors show that their model is capable to control a probability of each new generated graph. Moreover it\u2019s equivariant function which ensures that isomorphic graphs have the same probability to be generated. These properties are desirable  if we want to generate efficiently new graphs with properties similar to the graphs in the training set.",
    "The paper proposes an approach to explainable supervised learning by extracting sets of rules for two individual layers within a neural network. The authors build their work on recent published work for patttern-based rule mining [0] to efficently find so-called robust rules. The authors evaluate the approach for image processing tasks with convolutional neural networks on MNIST, ImageNet and Oxford Flower by comparing generated rules against activation maps and prototypes.",
    "This paper proposes to extract interpretable rules from a learned neural network. The authors claim that they are the first to propose rules connecting 1) multiple neurons together, and 2) do this at a dataset level. Their approach relies on using minimum description length and well known principles from the data mining community (e.g., downward closure lemma of apriori algorithm). The authors claim that experiments conducted on image data shows that their approach leads to more faithful, interpretable rules than other approaches such as prototyping or model distillation.",
    "The authors propose a method to explore how neurons interact within a neural network and derive rules of interactions that can help interpret the inner workings of the neural network and open up the black box. The algorithm, EXPLAINN, identifies rules between successive layers where each rule represents a set of neurons that are activate simultaneously and conditionally based on the previous layer. Minimum Description Length principle is used to derive an objective that minimizes the number of bits used to encode the rules. The rule sets are identified using a greedy heuristic and improved until convergence of the objective. The algorithm is then evaluated to demonstrate the interpretation of images with MNIST, GoogLeNet and VGG-S. ",
    "The paper proposes a theoretical framework for analyzing the error of reinforcement learning algorithms in a fixed dataset policy optimization (FDPO) setting.  In such settings, data has been collected by a single policy that may not be optimal and the learner puts together a model or value function that will have explicit or implicit uncertainty in areas where the data is not dense enough.  The authors provide bounds connecting the uncertainty to the loss.  They then show that explicitly pessimistic algorithms that fill in the uncertainty with the worst case can minimize the worst case error.  Similarly, proximal algorithms that attempt to adhere to the collection policy (as often the case in model-free batch RL) have improved error compared to a naive approach but not as good as an explicitly pessimistic approach.",
    "The message of this paper is that naive policy evaluations common in current (deep) RL algorithms, can lead to a dangerous overestimation of the value function. This overestimation of the value function can then lead to policy improvements with poor theoretical guarantees. To combat overestimation, the authors propose to penalize state-action pairs that are rarely visited. As an easier to implement alternative, and closer to existing algorithms in the literature, the authors also study another penalty term that penalizes deviation from the data generating policy. The authors show on a numerical example that the more principled penalty term that depends on visitation counts is better performing, and that the proximal penalty term only yields minor improvements over imitation learning (i.e. returning the data generating policy).",
    "This paper attempts to unify prior work on fixed-dataset (aka \"batch\" or \"offline\") reinforcement learning. Specifically, it emphasizes the importance of pessimism to account for faulty over-estimation from finite datasets. The paper shows that naive algorithms (with no pessimism) can recover the optimal policy with enough data, but do so more efficiently. The pessimistic algorithms are divided into \"uncertainty-aware\" and \"proximal\" algorithms where the uncertainty-aware algorithms are shown to be more principled, but most prior work falls into the computationally easier proximal family of algorithms that is closer to imitation learning. These insights are proven both theoretically and with some small experiments.",
    "This paper presents a memory-efficient asynchronous leapfrog integrator for numerically solving neural ODEs, referred to as MALI. The method comes with a constant memory guarantee (like the adjoint method) and also guarantees reverse-time accuracy (like the adaptive checkpoint adjoint (ACA) method). The authors also give a rigorous theoretical analysis of MALI, and also discuss a \"damped\" version with an increased stability region. The method is evaluated on a variety of tasks which includes classification, dynamical modelling and generative modelling.",
    "There are typically two methods for estimating the gradients with respect to the loss for neural ODEs. The naive method directly backpropagates through the steps of the ODE solver leading to accurate gradients but very large memory cost. The adjoint method in contrast does not store the entire trajectory in memory, but has reverse trajectory errors (i.e. the numerical solution in the reverse direction will not be the inverse of the numerical solution in the forward direction). In this paper, the authors propose a method that is both reverse accurate and has low memory cost.",
    "This paper proposes a new algorithm for solving neural ODEs. Each numerical solver step of the neural ODE is implemented as an invertible neural network via a variant of the asynchronous leafprog integrator. While still computing an accurate gradient, this allows memory savings by discarding intermediate data from the numerical integration steps since it can be reconstructed using the inverse. A theoretical stability analysis is provided. The experimental results show that the algorithm achieves similar performance to previous methods (e.g. ACA) while using less memory. ",
    "The paper provides a set of comparisons among different scene generation methods. It assesses ability of the models to fit the training set (seen conditionings), generalize to unseen conditionings of seen object combinations, and generalize to unseen conditionings composed of unseen object combinations. It finds that these models fit the training distribution with a moderate success, display decent generalization to unseen fine-grained conditionings, and have significant space for improvement when it comes to generating images from unseen coarse",
    "This paper studies the problem of scene conditional image generation with a focus on the evaluation of existing works towards unseen complex scene generation on the COCO-Stuff dataset. Specifically, it evaluates the model performances from three aspects, namely, image generation from seen conditionings, unseen fine-grained conditionings, and unseen coarse conditionings. For each evaluation, it computes the precision, recall, conditional consistency, F1-score, object accuracy, FID and diversity score for both object-wise and scene-wise measures. ",
    "Problem: There has been a plethora of work on image synthesis from a given layout of objects or label maps. However, it is not clear what has led to those results because there are no fixed backbone, optimization, training data, and evaluation protocol in each of them. This paper introduces a methodology to study three approaches (G2im, LostGAN, OC-GAN) that input a layout of objects to synthesize a new image.",
    "The paper presents a theoretical analysis to compare expressive power of Graph-Neural Networks (GNNs) w.r.t a class of simpler graph modles called  Graph-Augmented MLPs (GA-MLPs).   GNNs, especially deeper ones can be more difficult to train, and GA-MLPs have a simpler structure, significantly easier to train, and have been shown to have competitive performance on a number of tasks.  The paper dives deep into several problems (graph-isomorphism, node-classification, and community detection) and through innovative analysis shows that GNNs at least theoretically can have significant advantages for some of the problems. ",
    "The paper compares graph neural networks (GNNs) with graph-augmented multi-layer perceptrons (GA-MLPs) where GA-MLPs are MLPs over nodes with additional node features computed over the graph. The paper contains theoretical results and experimental results for graph isomorphism testing and for node level functions. In the overflow of papers studying the expressivity of GNNs, the originality comes from the study of GA-MLPs and from the comparison for node level functions.",
    "The paper studies a variant of Graph Neural Networks (GNNs) namely, Graph Augmented MLPs (GA-MLPs). Unlike in GNNs where nodes send messages to neighbors, and aggregate received messages via non-linear MLPs,  GA-MLPs rely on a single augmented embedding computed once and then applying an MLP to the new embeddings. The augmented embeddings can be obtained by applying linear transformations of the form A, A^2, \u2026, A^k to the input representations, thereby capturing larger neighborhoods. The main goal of the paper is to demonstrate a fundamental weakness when using GA-MLPs for solving graph problems as compared to GNNs. Along these line the paper the main results can be characterized as follows:",
    "The paper proposes an original idea to use distillation to speed up modern distributed RL settings, when data collection is done on CPUs with the learning happening on accelerated hardware, e.g. GPU. More specifically, the authors propose to use a transformer for the learner and distil the policy into LSTM actors. With this, they achieve much faster wallclock time compared to the Transformer for Actors setup, however, losing in sample-efficiency.",
    "The paper proposes a method for \"actor-latency constrained\" settings: Recently, transformers have been shown to be powerful models in RL which, in particular, exhibited better sample complexity in settings in which long-term credit assignment in partial observability was required (e.g. the T-maze). However, they are computationally expensive. Consequently, the authors propose to train transformers on the learner, supported by hardware acceleration, but also train a smaller LSTM agent which can be efficiently executed on the actors. ",
    "The paper proposes a solution to actor-latency constrained settings in RL by using policy distillation to compress a large \u201clearner model\u201d towards a more tractable \u201cactor model\u201d. In particular, it proposes to exploit the superior sample efficiency of transformer models while utilising an LSTM-based actor during execution. The proposed procedure, called Actor-Learner Distillation (ALD), provides comparable performance to transformers in terms of sample efficiency, yet produces a wall-clock run-time that's on par with LSTM agents.",
    "The paper addresses the problem of multi-domain few-shot image classification (where unseen classes and examples come from diverse data sources), and proposes a Universal Representation Transformer (URT) layer, which learns to transform a universal representation into task-adapted representations. The method proposed builds on top of SUR [Dvornik et al 2020], where a universal representation is extracted from the outputs of a collection of pre-trained and domain-specific backbones and a selection procedure infers how to weight each backbone for a given task at hand. While SUR inferred those weights by optimising a loss on the support set (the few examples provided in a task), the authors in this paper introduce an attention-based layer (inspired by Vaswani et al Transformer) that learns to weight the appropriate backbones for each task. This layer has the main advantage that it can be learned across few-shot tasks from many domains so it can support transfer across these tasks.",
    "Few-shot learning on meta-dataset is challenging due to the domain gap between train and validation. In order to bridge this gap, the authors present a model that learns to combine domain-specific representations to generalize to new domains. This combination is done with a transformer model that pays attention to the features extracted from domain-specific backbones. The authors demonstrate empirically that their model attains comparable performance to previous state-of-the-art at higher efficiency and include ablation results to test their model components.",
    "The paper presents a method for tackling multi-domain few-shot image classification problem where it obtains a task-adapted representation by weighing representations from pretrained domain-specific backbones according to the support set at hand. The desirable property of this framework is that the model can leverage information from other domains to make predictions. The effectiveness of Universal Representations have been discussed in the past work - SUR [1], and this work builds on top of it and introduces a learnable component (self-attention), and showed the improvement both quantitatively and qualitatively.",
    "The paper introduces a non-parametric approach, STAM, for unsupervised progressive learning (UPL), a variant of continual unsupervised learning with a single-stream requirement. STAM is developed for visual tasks. It comprises several components: (1) online clustering of hierarchical visual features (2) novelty detection (3) dual-memory for prototypical features. Experiments show STAM performs better than GEM, MAS in specific scenarios. ",
    "The authors propose an approach (architecture + algorithms) to unsupervised progressive learning in a non-stationary environment (the number of classes grows gradually) by keeping centroids at several hierarchies, using a combination of techniques from online clustering, via computing and updating centroids, with novelty detection, and dropping (forgetting those deemed outliers).  A variety of experiments are performed on several image datasets (MNIST, EMNIST, SVHN, CIFAR-10) with comparisons to other adapted methods. They evaluate performance in a supervised setting where they describe how they learn centroid to label(s) mappings.",
    "This paper presents an \"Unsupervised progressive learning\" (UPL) problem, where a model is exposed to data in an non-iid manner, and each training example is presented once. Simple to continual learning, but a little more explicit in the connections to the way biological agents learn. They present a model that uses clustering and long-term memory (buffered) and compare on a few UPL tasks with additional supervision signal (classification) or unsupervised (clustering).",
    "The authors consider the decentralized optimization problem and explain the generalization gap using the consensus distance. They show that when the consensus distance does not grow too large, the performance of centralized training can be reached and sometimes surpassed. The conducted experiments are extensive and the delivered message is pretty clear -- Critical consensus distance exists in the initial training phase and ensures good optimization and generalization, while a non-negligible consensus distance at middle phases can improve generalization over centralized training.",
    "This paper studies decentralized gradient methods for training deep networks. It focuses on the so-called \"critical consensus distance\" and how disagreement during different stages of training ultimately effects optimization (training loss) and learning (generalization error). Theory is provided for the case of synchronous symmetric averaging methods, and the paper is complemented with detailed experiments on CIFAR and tiny-ImageNet.",
    "This paper studies the problem of decentralized training where several computing units are used simultaneously to process the data, and computing units are assumed to be connected over a network. The main focus is to better understand the role of consensus, or lack there of, into the generalization abilities of decentralized training. The authors describe an upper bound for dissimilarity of local variables that guarantees the performance of decentralized training is as good as centralized one. Moreover, some heuristic guidelines are proposed to control consensus during training process. Some numerical evidence is also provided.",
    "This work concerns the metric learning between sequences using RNNs. The paper notices the similarity between a dynamical system and an RNN. Then it demonstrates that learning a pair of siamese RNNs is similar to learning synchronization between two subsystems of a dynamical system. Finally, the paper proposes to introduce coupling between the two RNNs in order to improve synchronization.",
    "Drawing inspiration from dynamic systems, the paper proposes a novel architecture that couple sequences. Such a system has easiness to bring two instances arbitrarily close and authors have shown the superiority of the approach over an action recognition dataset; but the results seem to far from state of the art on the dataset (see questions section). The authors also recognize that currently such systems need to calculate each pairs (can't be cached due to coupling) at inference time, which is slow. ",
    "I liked the formulation and motivation of the paper, explaining the sequence metric learning problem  and drawing parallel between synchronized trajectories produced by dynamical systems and the distance between similar sequences processed by a siamese style recurrent neural network. The authors propose modification the siamese recurrent network setting called classical Gated Recurrent Unit architecture (CGRU). The premise being two identical sub-networks, two identical dynamical systems which can theoretically achieve complete synchronization if a coupling is introduced between them. The authors describe how this model is able to simultaneously learn a similarity metric and the synchronization of unaligned multi-variate sequences in a weakly supervised way with the coupling demonstrating performance of the siamese Gated Recurrent Unit (SGRU) architecture on UCI activity recognition dataset (mobile data).",
    "This work analyzes the effect of co-distillation for distributed training under moderate batch sizes. Using distillation-like techniques to improve synchronous SGD training is an interesting direction. And the paper carefully analyzed this setting while using the same amount of compute, which is not done by prior work to my knowledge. In addition, the writing is good and easy to follow.",
    "The paper studies the concept of codistillation in data parallel distributed training. In this setting, the standard minibatch SGD algorithm requires exchange of models in every update of every node. Recent work in distributed training has studied \"local SGD\", where models are exchanged at frequent (usually periodic) intervals after a bunch of local updates. This paper studies an alternative, called \"codistillation\". The idea is that at a given node, say node $i$, the local model updates are regularized by the most recent models at nodes $\\{j, j \\neq i\\}$ through an appropriately modified loss term. Specifically, the loss term bias the model at node $i$ towards having similar classification outcomes on the training data as the (most recent) local estimate of the model at nodes $\\{j, j \\neq i\\}.",
    "This paper aims to have a closer look at the role of codistillation for distributed training. Authors provided an answer with their empirical observations. That is, codistillation acts as a regularizer, since the distance between the learned model and the initialization is smaller than sync SGD without codistillation. Then, the authors claim that the codistillation may over-regularize and study how to modify the training configurations to avoid it. There are further discussions on the overfitting and robustness to hyper-parameters in sec 4 and sec 5. ",
    "This paper studies the relations between the heavy tail phenomenon of SGD and the \u2018flatness\u2019 of the local minimum found by SGD and the ratio of the step size $\\eta$ to the batch size $b$ for the quadratic and convex problem. They show that depending on the curvature, the step size, and the batch size, the iterates can converge to a heavy-tailed random variable.  They conduct experiments on both synthetic data and fully connected neural networks, and illustrate that the results would also apply to more general settings and hence provide new insights about the behavior of SGD in deep learning. ",
    "The main theme of this work is to study conditions under which SGD iterations result in random variables with heavy-tail random distributions. Specifically they focus on the step size, batch size and problem dimension. First they show theoretical results showing how the tail-index of the distribution generated by SGD depends on the chosen step size, batch size and problem dimension.",
    "This paper gives a theoretical study of the tail behavior of the SGD in a quadratic optimization problem and explores its relationship with the curvature, step size and batch size. To prove their results, the authors approximate the SGD recursion by a linear stochastic recursion and analyze the statistical properties by the tools from implicit renew theory. Under this setting, they show that the law of the SGD iterates converge to a heavy-tailed stationary distribution depending on the Hessian structure of the loss function at the minimum and choices of the step size and batch size. They take a further step to clarify the relationship and study the moment bounds and convergence rate. ",
    " The article analyzes GCNs from spectral viewpoint, and discusses the performance of GCNs with respect to spectral filtering. The paper shows by experimentation, that the performance of GCNs mainly depend on low frequencies (lower end of the spectrum/eigen-pairs). It then shows that an MLP with low frequency information (Eigen-pairs) performs very well in graph tasks. Aspects such as smoothness and high frequency ablations are also studied.",
    "This paper aims to study how GCN will behave under spectral perturbations/manipulations. The empirical numerical analysis on three benchmark datasets (cora, citeseer, pubmed) show that most of the necessary information is contained in the low-frequency domain. Based on that, the author propose to expand the node feature matrix with the eigenvectors corresponding to low-frequency domain and apply MLP on this new feature matrix. Experimental results show that the proposed method outperforms vanilla GCN and achieve comparable results on pubmed with other baselines.",
    "The work presents an interesting analysis of GCN models under spectral manipulations and relates the performance of GCNs through bandpass filtering. The authors demonstrate that GCNs mainly rely more on low-frequencies rather than high-frequencies which is contrary to what is observed in signal processing. For this, the authors use band-pass filters which allow only a portion of the spectrum to be utilized by the GCN model. The major findings are as follows:",
    "Graph neural networks (GNNs) have become de facto methods for integrating the input graph structure and node features to learn effective node representations. However, in some domains (such as brain signals, particle reconstruction, etc.), there is access to only node features (but not the underlying graph structure). Motivated by the fact that GNNs tend to perform poorly in the absence of the graph structure, the paper",
    "This paper proposes to tackle jointly learning graph structures and GNN parameters without accessing the original graph structure. Specifically, the proposed method adopts a self-supervised auxiliary task, i.e., parallel training using the supervision of node labels and a self-supervised task using de-noised auto-encoding. The latent graph structure is generated through a fully-parameterized adjacency matrix or a KNN construction subsequent to passing node features to an MLP. Experimental results and corresponding analyses demonstrate the effectiveness of the proposed model.",
    "This paper considers the problem of nodes classification with few labeled data and missing graph structures. The proposed solution is expected to infer unobserved graph structure as well as the parameters of the classification model. The main contribution of this paper is proposing adding a denoise autoencoder layer which provides more supervision to the learning. The model compares favorably with other states of art models in several benchmark graph data sets.",
    "The authors propose a novelty detection module to help unsupervised class-incremental learning. The novelty detection relies on the percentage of accuracy drop during a model update when treating incoming data as a new class. If the model maintains high accuracy, then the module treats the incoming data as familiar, thereby choosing one of the existing classes as the correct label. The paper investigates the effectiveness of the proposed method on MNIST, SVHN, CIFAR-10, and CIFAR-100.",
    "This article proposes a method for predicting whether a batch of data is of the same class as one of the classes already seen by a classifier or whether it contains data from another class. The idea is to then be able to incorporate this batch to the previous training set, in an unsupervised learning context. It is assumed that each batch contains data from only one class. Experiments are there to show the interest of this method for anomaly detection or incremental learning.",
    "This paper proposes to tackle the problem of unsupervised class-incremental learning, where the training data is composed of a sequence of \"exposures\". Each exposure is comprised of a set of images that pertains to a single class, where the class label is unknown while the boundaries between exposures are known. The key difficulty in such unsupervised class-incremental learning is to determine whether an arriving exposure belongs to what the classification model $L$ has learnt previously or is a novel one, thus relating to the problem of novelty detection. The proposed method address the novelty detection by an interesting idea: they always treat the current exposure as a novel class and use it to train the copy of classification model $\\hat{L}$ together with the training exemplars of previously-learnt classes, if the current exposure actually belongs to one of the previous-learnt classes, the confusion occurs to make the classification accuracy significantly decrease (over a threshold) on that specific class, where the accuracy is computed based on the validation exemplars. Moreover, a technique of introducing class-imbalance into such confusion-based novelty detection is proposed and helps to boost the robustness of novelty detection. ",
    "The paper addresses how to learn policies for tasks in which constraints are specified in natural language. Towards this, the paper proposes a model that encodes the different types of natural language constraints into intermediate representations that model both spatial and temporal information between states. Then, they use this as input along with the observation to produce an action at each time step for a safe trajectory. ",
    "The paper proposed an algorithm to learn a policy when provided with natural language constraints. The paper defined a navigation task called Hazard World, in which an agent navigation on the map to collect items. The authors defined three types of constraints to restrict agents to visit certain states: 1. budgetary constraints, 2. relational constraints and 3. sequential constraints. The three constraints are described in natural language. The authors proposed a two-step solution. In step one, the algorithm learns a mapping between a natural language constraint to an intermediate representation. In step two the algorithm takes the intermediate representation to learn a policy that satisfy the constraints.",
    "This paper presents a new test environment, Hazard World, for learning the safe reinforcement learning agents with given natural language constraints. In this problem, the goal of the agent is to find an optimal policy that maximizes the cumulative rewards while satisfying the constraints given in natural language. The authors introduce the model that contains the following two separate components; constraint interpreter for encoding the language constraints and policy network for learning the RL agent. Finally, they report the results of their proposed algorithm and compare it with the baselines.",
    "This paper proposes the few-shot edge detection task, which is similar to few-shot segmentation but for the dual task of detecting semantic edges. For the task, the authors construct datasets and experimental settings constructed from existing edge detection dataset (BSD) and a few shot segmentation dataset (FSS). For the proposed method, the authors:",
    "This paper introduces a novel problem of \"few-shot semantic edge detection\" where semantic boundaries are to be learned/detected with a few labeled samples. In order to remedy the issue of label sparsity within the few-shot scenario, the authors have leveraged the use of the segmentation process which provides the semantic information to the edge detector. They have also incorporated a meta-learning approach, namely Multi-Split Matching Regularization (MSMR), to avoid the overfitting when high-dimensional embeddings are used for feature matching.",
    "This paper works on few-shot semantic edge detection. Instead of dealing with the problem in a single stage, the authors decompose the problem into two stages.  First, a few-shot segmentation stage, where the foreground and the background probability are estimated via attention with the foreground and the background prototype (averaged feature vector on the foreground and the background region). Second, the feature maps from the encoder are masked by the attention map and sent to the decoder to generate the final edge-map.",
    "This work proposes to explain graph neural networks from a causal effect view. The proposed method, Causal Screening, iteratively adds edges into the explanatory subgraph. The goal is to maximize the $do(\\cdot)$ calculus, which tries to select an edge such that the prediction probability when feeding into GNNs is close to the original prediction. Experimental results show that the proposed method can outperform other comparing methods.",
    "The paper proposes a procedure for identifying a subgraph $\\mathcal{G}_K$ of a given size $K$ (measured by the number of edges) whose output through the GNN function $f$ is as close as possible to that of the full graph $\\mathcal{G}$. The proposed method is a greedy approach which starts from an empty graph and gradually adds the next edge by minimizing the difference between the outputs using mutual information. Furthermore, to reduce the computational complexity, a node clustering is done on the graph and the attribution is applied first on the edges between $C$ identified clusters and then transferred to all edges.",
    "The paper introduces a novel method called Causal screening which takes a graph and the prediction made by a GNN, and returns an explanatory subgraph. The method aims to explain GNN models. To be precise, it starts from an empty set as the explanatory subgraph, and incrementally adds the edges, testing them for the individual causal effect.",
    "The paper proposes a novel generalisation measure, i.e., measurement that indicates how well the network generalises, based on pruning. The idea is to measure the fraction of the weights that can be pruned (either randomly, or based on the norms) without hurting the training loss of the model. The paper provides thorough discussion of the related methods and motivates the measure in multiple ways. Further, the authors show empirical evidence for the correlation of the pruning robustness to the generalisation ability of networks, based on the paper by Jiang et al., 2019 and dataset (updated with additional models) provided in the paper.",
    "In order to understand why deep networks generalize well, this paper proposes \"prunability\" as an empirical measure that can be predictive of the generalization. Prunability is roughly the smallest _fraction_ (i.e., $\\in [0,1]$) of parameters that can be retained, while zeroing out everything else, without increasing the model's training loss by too much. The authors experimentally demonstrate the predictive ability of this measure in three ways.",
    "In the present work, the authors tackle the highly debated (and sometimes confusing) problem of finding a good simplicity/complexity measure able to predict generalization performance of deep networks. A novel measure called 'prunability' is introduced and compared with some of the many alternatives in the literature. This property measures how networks are able to retain low training loss when a fraction of the weights is set to zero, and is clearly related to common training practices (e.g. dropout) that seems to yield better generalization performance in practice. The experimental settings and the evaluation methods for this new metric are inspired by recent extensive studies on deep networks performance. The authors are able to show that prunability is in fact associated with good generalization and seems able to capture some non-trivial phenomena (double-descent), but they also find it to be inferior to pre-existing (margin based) measures. Moreover, the close relationship to perturbation robustness and flatness measures is investigated, but the results are not fully conclusive.",
    "This paper tackles the problem of long horizon visual planning, with the aim of of being able to plan actions to reach distant goals. This is a well studied problem, and like prior work this method considers the setting where the agent is given an offline dataset of interaction, which it learns from to be able to reach new goals (specified by a goal image). The method first does unsupervised representation learning, where it learns a discrete representation of images (using contrastive predictive coding (CPC) with a discrete latent variable using Gumbel Softmax). Using a set of discrete latent variable, it then builds a set of graphs which connects these discrete states based on the collected experience, and derives a planning procedure to find a path in the graph which reaches the goal. ",
    "This paper presents a method that combines learning discrete representations together with planning using graph search to solve long horizon tasks from vision. The approach works by generating data via random exploration and trains a representation encoder on this data. This network extracts objects from the observations and passes them through a CNN and shared encoder to generate one-hot encodings; these encodings are concatenated to generate the discrete representation. The encoder is trained via a contrastive learning objective with a similarity matrix that encourages nearby states to share similar encodings, thereby encouraging spatial and temporal abstractions. Next, these representations are combined together with an abstract planner to generate a sequence of waypoints to the goal. This is done by creating a graph of transitions from the collected exploratory data and search within this graph \u2014 this is executed for each encoding at a time with the assumption that the task can be solved by moving each object independently of the others. Finally, a low-level controller is used for reaching the waypoints and final goal, this is done via MPC on an action-conditional predictive model that generates future observations given the current state and goal. The approach is tested on two simple planar planning tasks where the agent has to solve k-object arrangement and open a room with a key respectively.",
    "This work presents Discrete Object-factorized Representation Planning (DORP), which learns a discrete representation from videos with an enforced temporal consistency. This representation can then be planned over through a sequence of small alterations to the discrete embedding, which are then executed via MPC. DORB is demonstrated to solve long-horizon tasks and learn representations that consider objects and their properties. ",
    "This paper basically proposed to learn the quantization bits (precision) in each layer. Specially, weights are constructed with binary representation as $W_s = \\[W_s^1,...,W_s^b\\]$. During training, $W_s^i$ is relaxed to $ \\in \\[0, 2\\]$. And a group sparsity is imposed to all $W_s^i$ for all weights in a layer, leading to certain $W_s^i \\to 0$, thus cancelling the bit allocation in $i$-th. Experimental results is promising.",
    "This paper introduces a new method to quantize neural networks in a differentiable manner. Proposed method applies the group lasso on the bit-planes of the weight parameters to let certain LSBs in each layer to be zero-ed out. STE is used to train the binary representation of each bit-plane and the sign of weights during the training. Results demonstrate that the proposed method can achieve higher accuracy and compression ratio compared to previous studies.",
    "Quantization of weights in DNNs is a very effective way to reduce the computational and storage costs which can enable deployment of deep learning at the edge. However, determining suitable layer-wise bit-widths while training is a difficult task due to the discrete nature of the optimization problem. This paper proposes to utilize bit-level sparsity as a proxy for bit-width and employ regularization techniques to formulate the problem so that precision can be reduced while training the model.",
    "The paper identifies the gradient vanishing issue in the robustness of binary quantized networks. Therefore, it proposes to use temperature scaling approach in the attack generation. It has two methods for the temperature scale: (1) singular values of the input-output Jacobian and (2) maximizing the norm of the Hessian of the loss.",
    "**Update**: Thanks to the authors for addressing my comments. As it was pointed out by the authors, temperature rescaling is mostly applicable to non-linear loss functions. For linear loss functions, temperature scaling only linear rescales the gradients. The difference between the proposed PGD++ attack and PGD with linear DLR loss is small (see the author's response to AR4). The improvements are most significant for FGSM but FGSM is not recommended for the robustness evaluation. Given the limited technical novelty and small improvements for linear loss functions, my score remains unchanged.",
    "This work starts by questioning the apparent robustness of quantized networks and demonstrates that such robustness is more so a failure of the attack algorithm in picking up the gradient signal. The authors address this by tuning a scalar multiplier applied to the network logits, which doesn\u2019t modify the model\u2019s decision boundary. Through analyzing the Jacobian, two approaches are proposed to determine the scalar $\\beta$ without tuning it by performing the attack. This approach is quite effective on quantized networks and even provides significant improvement on floating-point networks combining with existing attacks like FGSM and PGD. The proposed modification might seem trivial at first, but it constitutes an important factor the community hasn\u2019t taken notice of, to the best of my knowledge.",
    "The authors propose ProtoryNet,  a prototype-based model for paragraph classification that associates each sentence in the paragraph with a relevant prototypical sentence from the training data. The idea is interesting and the ability to decompose sentiment scores over each sentence + find prototypes for each helps to build user understanding of the model prediction. Thank you to the authors for the submission.",
    "this paper presents an RNN sequence classifying model that generates a prototype for each sentence in a paragraph. The generated prototypes help explain the model's prediction. The method embeds each sentence, matches to prototypes, then runs through an LSTM before making a prediction. Experiments found improved accuracy compared to a previous model that generates only one prototype for a paragraph. A user evaluation also found improvement in interpretability.",
    "This paper presents ProtoryNet, a framework for text data that classifies and explains the prototypes' results.   The key concept, that is the novelty of the work, is that this framework is based on sentence prototypes, called prototype trajectory in the paper. In particular, instead of working at the entity of the text level, the text is split into sentences and each sentence is analyzed by itself.  The structure of the framework is composed of a layer that encodes a text's sequences, followed by a prototype layer in which is computed the similarity among each sentence and the prototype trajectories. At this point, the sentences are represented in one-hot encoding: for each sentence, there is a bunch of zero and then a one for the most similar sentence prototype. This representation is used for the classification of the sentence, done using an LSTM structure. In this setting, the interpretation is given by exploiting the prototypes matched for the text under analysis. ",
    "Authors demonstrated that one can encode the data likelihood function of an HMM using a specialized RNN architecture. Unlike previous work where neurons from different layers were multiplied together, the new encoding strictly followed the classical architecture restrictions of a neural network , i.e. each layer was a weighted sum of the previous layer. Empirically, author showed that the parameter learned by applying gradient descent on the likelihood function is similar to the one that is obtained using the EM algorithm. In addition, authors demonstrated that such formulation enables an application in studying Alzheimer's disease Symptom Progression.",
    "This paper introduces a novel architecture of recurrent neural network that mimics the working of a standard HMM. In particular, the proposed HMRNN learns model-parameters, which are statistically similar solutions to those of a standard HMM, within a general neural network learning framework. While it is shown the proposed network similarly to the HMM, there are many issues that should be considered critically.   ",
    "The authors describe an RNN architecture, the HMRNN, which models the log-likelihood in an HMM.  The authors provide theoretical results showing that the HMRNN objective function does, indeed, correspond to the log-likelihood of an HMM.  Synthetic results are presented which compare the learned parameters between the HMRNN and an HMM trained using the Baum-Welch algorithm.  Finally, HMRNN training is augmented and compared to an HMM trained using the Baum-Welch algorithm for the task of Alzheimer's progression prediction.",
    "This manuscript presents a novel dimensionality reduction method, called Factorized Linear Discriminant Analysis. The method starts from a real problem in neurobiology, and tries to link expression levels of neural genes to phenotypes. In particular, the main goal of the proposed technique is to find linear projections of the genes expression which vary maximally with one phenotypical aspect and minimally with the others. The approach is evaluated using a synthetic example and a real case study involving Drosophila T4/T5 cells.",
    "This manuscript describes a generalization of ANOVA that is intended to be used in the interpretation of single-cell RNA-seq data. The method requires specification of an orthogonal, discrete categorization of cells, nominally by phenotype.  The method then linearly factorizes the observed gene expression values into features and their interactions, relative to the phenotypic categories.  The factors can then be used to help interpret the categories, especially in conjunction with a regularizer to reduce the number of genes involved in the factors.",
    "The paper studies a very important problem in gene data analysis. The proposed method is technically sound. The method is intuitive in its idea and easy to implement. The results are interpretable. And according to the experimental evaluations, the proposed method is consistent to existing biological observations and could further identify unknown genetic targets. Therefore, it, potentially, has insightful scientific implications. ",
    "The paper presents a new saliency map interpretability method for the task of image classification. It considers the saliency map as a random variable and computes the posterior distribution over it. The likelihood measures the predictions of the classifier for an image and its perturbed counterpart. The prior encodes positive correlation among adjacent pixels. Variational approximation is used to approximate the posterior.  ",
    "This paper proposed a method for generating saliency maps for image classifiers that are stochastic (instead of deterministic). The probabilistic model assumes a saliency map random variable that generates the data with a classifier. The inference is done by variational methods. The paper presents several qualitative examples and a comparison to previous work using the pixel perturbation benchmark.",
    "This paper proposes a new interpretability method for image classification networks. It considers a saliency map as a random variable and aims to calculate the posterior distribution over the saliency map.  The likelihood function and the prior distribution are then designed to make the posterior distribution over the saliency map explain the behavior of the classifier\u2019s prediction. Quantitative evaluation on the perturbation benchmark as well as qualitative result show the effectiveness of the proposed method over baselines. ",
    "This paper introduces a novel technique for debiasing pretrained contextual embedding models. Their approach trains a 2 layer fully-connected neural network which takes as input the output from the pretrained model and outputs a new, \"debiased\" representation. This model is trained by minimizing the InfoNCE between the representation produced of original sentence and the representation of that same sentence with some tokens replaced with differently-biased tokens (e.g. \"his\" -> \"hers\"). This paper also introduces a regularizer which minimizes the CLUB between the generated representation and a word embedding for a biased token. ",
    "This paper studied a debiasing method to remove social bias in pretrained NLP models. The authors proposed to train a neural network which takes the sentence representations of a pretrained NLP model as input and outputs the unbiased representations. The neural network is trained by maximizing the mutual information between a sentence and its \u201ccounterpart sentence\u201d, which is automatically generated by replacing sensitive words by other values (e.g. replacing \u201che\u201d with \u201cshe\u201d). Moreover, the network can be further trained by minimizing the mutual information between the sentence representation and its sensitive word representation. The experiments show that the proposed method can effectively reduce bias while achieving better downstream task performance of the pretrained model.",
    "The paper builds on recent working attempts to debais sentence encoders by considering modified sentences. Sentences are selected that, for example, contain\u00a0gender cueing words, and then swap those words with a predetermined 'opposite' (i.e. man<->woman). The core novelty in the work is to train a lightweight modification the encoding of the sentence and its swap to (a) reduce the distance between the two embeddings, using a contrastive learning objective and (b) reduce the mutual information between cueing words and the new embeddings. Evaluated on a WHEAT style task, modified for sentences, the method performs significantly\u00a0better than existing recent work.\u00a0",
    "This paper proposes an improved sample-wise randomized smoothing technique, where the noise level is tuned for different samples, for certification of robustness. Further, it also proposes a pretrain-to-finetune methodology for training networks which are then certified via sample-wise randomized smoothing. The authors show in experiments on CIFAR and MNIST that combining their training methodology and certification methodology can sometimes improve the average certified when compared to state-of-the-art randomized smoothing techniques Smooth-Adv (Salman et. al, 2019).",
    "This paper suggests an extension of randomized smoothing, wherein the degree of smoothing is optimized both at training and test-time on each individual sample. At training time, the model is first \"pre-trained\" using a range of smoothing parameters (variance of the Gaussian perturbations), and then \"fine-tuned\" by selecting the variance on each sample which maximizes the verified radius. At test time, we can again select the smoothing parameter to maximize robustness.",
    "This paper considers the problem of provably defense to adversarial perturbations using randomized smoothing. The authors propose sample-wise randomized smoothing -- assigning different noise levels to different samples. They also propose to first pretrain a model and then adjust the noise for higher performance based on the model\u2019s outputs. Experiments show that proposed approach improves the performance of randomized smoothing with same noise level for small perturbations. ",
    "This paper proposes a Tomographic auto-encoder (TAE) for unsupervised recovery of corrupted data. More specifically, TAE takes a Bayesian approach to recover the posterior distribution of a clean image conditioned on an observed corrupted image and thus effectively modeling uncertainty in data recovery. The paper argues that a naive application of VAE is not effective due to the latent variable collapse, and proposes an alternative model where hierarchical latent variable models are used for both prior and variational posterior. Some tricks are introduced to facilitate the stochastic gradient variational inference. ",
    "Practical datasets often come with corruptions, such as missing items or noisy observations, thus needs models enable to recover the corrupted data automatically. This paper presents the tomographic auto-encoder (TVAE), which conducts inference over the data space $x$. Because the prior regularization acts over the data space, TVAE is enforced to generate diverse samples from the corrupted observations. Empirically, the paper demonstrates that TVAE can indeed generate diverse samples and can achieve superior test ELBO compared to the previous baselines.",
    "This paper proposes a novel approach to handle the recovery of dirty data in fully unsupervised scenarios. The corrupted data considers both missing data and noisy samples. They derive a VAE model with a novel reduced entropy condition inference method that results in richer posteriors. This is a very challenging problem, since the model cannot use clean examples as part of their training procedure.",
    "This paper proposes MAGNA, a multi-hop self-attention mechanism for attention based graph neural networks. The proposed method increases the receptive field at each layer, requiring less layers to achieve a large receptive field. Also, with the proposed method the attention coefficient between two nodes is not just a function of the two nodes but also of their neighbourhood. The proposed MAGNA method is an extension of GAT networks that introduces a diffusion step on the computed attention coefficients, following a similar approach (Diffusion-GCNs) that has been used for GCNs.",
    "The authors propose a novel attention-based GNN called MAGNA. The main contribution consists in considerably increasing the receptive field by considering a multi-hop neighborhood instead of the standard one hop. The technical challenge consists in obtaining attention scores for all relevant nodes in an efficient way. MAGNA solves this by using a diffusion-based technique combined with a geometric distribution. The authors show that the latter further allows for approximations, and also give interesting theoretical insights (e.g., show a relation to page rank). ",
    "     Conventional Graph Neural Networks (GNNs) learn node representations that encode information from multiple hops away by iteratively aggregating information through their immediate neighbors. Self-Attention modules have been adopted to GNNs to selectively aggregate information coming through the immediate neighbors at different propagation stages. However, current self-attention mechanisms are limited to only attend over the nodes' immediate neighbors and not directly over their neighbors that are multiple hops away. Here in this work, the authors intend to address this issue and propose a means to obtain attention scores over indirectly connected neighbors. ",
    "This paper describes a dataset consisting of ~14k multiple-choice questions drawn from many different fields across the humanities and science as well as professional disciplines such as law and medicine. It presents results for GPT-3 models (LMs trained on text corpora with document context) of different scales, as well as for the UnifiedQA model (seq2seq model trained on various QA datasets). Performance of these models is well below their performance on other benchmarks: not above chance for the smaller GPT-3 models, and under 50% average accuracy for the best models.",
    "This paper focuses on coming up with 57 different tasks and measure the performance of these large scale transformer models such as GPT3 on these different tasks. The main claims of this paper are to demonstrate these large-scale models still struggle to use the knowledge it has learned during the pretraining phase and these models struggle to on calculation-intensive tasks. Further one of the more important contributions of this work includes the massive multi-task dataset that comprises 57 different subjects.",
    "The paper proposes a benchmark for NLP models. The purpose of this test is to measure the model's knowledge in 57 topics covered by approx 15000 tasks in total, each formulated as a closed-form question in zero-shot and few-shot settings. Most of the tasks were taken from different human examination sets. Then, the paper provides results of experiments with the latest (GPT-3 and T5 based) models along with some quantitative and qualitative observations.",
    "This work explores a pretraining strategy (similar to https://arxiv.org/abs/1606.03622) to the problem of table question answering. More specifically a synchronous context-free grammar (SCFG) is first learned from training data (with manual alignment of entities/phrases). Then the SCFG is used to generate more full supervision data for Roberta model pretraining. The training objective is a combination of two parts: SQL Semantic Precision (SSP) predicts elements in SQL given the question on the synthetic data, and masked-language modeling (MLM) on the natural (training) data.",
    "The paper provides a interesting direction in pre-training for table semantic parsing. In particular, it proposes to first collect a collection of pseudo question-SQL pairs in an automatic way, based on tables from WikiTables tables and tables and databases in the training sets  SPIDER and WIKISQL. After that, masked language modeling and a newly introduced task called SSP, which is, given a natural language sentence and table headers, to predict whether a column appears in the SQL query and what operation is triggered. Experiments on Spider and WikiSQL show that the model achieves new state-of-the-art.",
    "This paper presents a general-purpose pre-training approach for jointly encoding utterances and relational tables in the task of table semantic parsing, where a natural language utterance is transduced into an executable query (e.g., SQL) over relational database tables. A core challenge in table semantic parsing is to understand the compositional semantics in utterances, and further ground salient entities and relations in the utterance onto the corresponding tabular schema (e.g., columns, cells). To improve understanding and grounding of compositional utterances, the authors propose fine-tuning a pre-trained masked language model (RoBERTa) using linearized table headers paired with synthetic utterances generated from a synchronous context free grammar, via an objective that encourages the model to discover the syntactic roles of columns mentioned in the input utterance. Experiments over four datasets demonstrated strong results when the this newly proposed pre-training objective is combined with classical masked language modeling objective.",
    "This paper provides a theoretical analysis of the inner workings of multi-task learning methods, based on a random matrix analysis applied to Gaussian mixture data model. The analysis is based on MTL LS-SVM with data from a Gaussian mixture model, where the bias of MTL LS-SVM is shown and a simple method is proposed to correct it. Experiments are conducted on a synthetic dataset and image classification task, where superior performance is shown in addition to the theoretical guarantees.",
    "The paper provides interesting theoretical insights in multi-task learning using common and specific parameters modeling framework and based on least-squares SVM. Especially, it is theoretically established that the standard MTL LS-SVM is biased. Thereon a method derived from the analysis is proposed to correct the bias and allows to achieve enhanced performances. Empirical evaluations highlight the effectiveness of the method.",
    "The paper considers the multitask least-square SVM problem. Such a problem consists of k SVM tasks, each being a binary classification problem. The normal vector of the separating hyperplane in each task is \u201cclose\u201d to each other, reflecting the commonality of the tasks. For an input data point, the problem asks to predict the classification of the input data point for a given task. This problem has a standard optimization formulation.",
    "This paper addresses an important symmetry in meta-learning.  Namely, the context data consists of a set of datapoints in arbitrary order.  The model should thus be permutation equivariant to their order.  At the same time, the data itself may have its own symmetries, e.g. rotation, which the network should likewise be equivariant to.  The authors follow a theory-driven approach, proving in Thm 2 that a function with these two types of symmetries may be factored and represented by a composition of functions reflecting each symmetry individually.  They then design a Neural Process (NP) model, EquivCNP, which reflects this result.  Other works have used permutation equivariance and translation equivariance in NPs, but this is the first to incorporate other symmetry groups. ",
    "The paper provides an extension of convolution conditional neural processes CNPs to more general Lie group equivariant CNPs. The development of the theory seems sufficiently clear to someone more familiar with the field. However, for newer readers, it seems important to be familiar with background concepts and prior work. This is not a penalizing point but rather just an observation.",
    "This paper presents EquivCNP which extends Conditional Neural Processes (CNP) to incorporate symmetries of the data, e.g. rotation and scaling. The approach utilizes a combination of LieConv (Finzi et al., 2020)  and DeepSet (Zaheer et al., 2017) to achieve the equivariance in the data space and permutation invariance across the samples in a dataset. They provide empirical results on a 1D regression task with synthetic and 2D image completion tasks using digital clock digits dataset which they constructed.",
    "This paper introduces a new optimization method for text generation that improves upon directly optimizing MLE. It frames text generation learning as an off-policy reinforcement learning (RL) problem using demonstrations (the training examples). The authors also discuss why off-policy learning is more suitable for text generation than on-policy learning. After simplifications and approximations, the proposed optimization objective comes down to a form that is similar to MLE, but upweighs training examples that are more likely under the learned policy $\\pi_\\theta$ (\"easy\" examples) and having higher estimated rewards (considering the future).",
    "This paper proposes a method to train generative models of text using reinforcement learning from off-policy demonstrations. This helps solve the problems of exposure bias and mismatched objectives in standard learning schemes such as maximum likelihood estimation and policy gradient optimization on metrics like BLEU. In the proposed method (GOLD), the authors use policy gradient combined with importance weighting to train the model using just the off-policy demonstrations, i.e. human-written text. They experiment with three different reward formulations, and demonstrate improvements over MLE baselines on tasks like summarization and machine translation. ",
    "This paper formalizes training of conditional text generation models as an off-policy RL objective, specifically, in the limit case where samples are only obtained from the training data. The motivation behind this is that MLE objective optimizes recall -i.e. increasing the prob of all correct sequences that could be generated by humans as an output to a certain input context. While for certain tasks such as MT or summarization it is often sufficient to focus training to generate 1 single correct Translation or summary (see cons: for comments on the effect of this on sample diversity).  Therefore explorations in traditional PG by generating examples from an auto-reg model is unnecessary in this context. Therefore, using importance sampling, PG objective \\E_{x \\sim \\pi_\\theta} is modified to \\E_{x \\sim \\pi_{data}} with the incorporation of the importance ratio and given a uniform sample probability of the training examples. As shown in eq(4), The gradient updates from this loss are identical to the standard MLE loss reweighted by the global reward and the current model probability of the training example, enforcing the model's current belief of the training data. This aligns with the previous intuition of enhancing precision on the expense of recall. Given this formulization this work experiments with three types of rewards: a constant reward and 2 MLE based rewards.    ",
    "The paper proposes a strategy for training feed-forward networks in a more memory-efficient manner by employing local as opposed to end-to-end supervision. End-to-end/global (E2E) supervision as the dominant paradigm in training deep networks considers a loss function at the very end of the network for backpropagation of the resulting gradients, whereas local supervision injects supervisory signals (such as the same E2E objective, e.g. classification) at intermediate layers in the network. The benefit of such intermediate supervision is the ability to train larger networks in smaller chunks piece by piece, where each individual training is more memory efficient due to reduced need to store activations (and weights and biases) in GPU memory. As a drawback, however, it had been shown earlier that such local training is less optimal than global training in terms of the achievable generalization performance. The authors propose a new training strategy that aims at combining the memory efficiency of local supervision and piecewise training with the error performance of global training. Considering a given intermediate layer, the paper motivates to maximize the mutual information between the activations in this layer and the input signal to retain relevant information, while minimizing the mutual information of the activations and a nuisance variable, where the nuisance is defined as having no mutual information with the target variable (e.g. the classification prediction). The authors argue that this local supervision allows to train the features at the intermediate layer such that they carry relevant information from the input to the target variable without resorting to direct supervision with the target variable. Direct computation of the nuisance variable is infeasible and the authors propose a bounded approximation. ",
    "The paper analyzes the pitfalls of locally supervised learning from the point of view of information propagation and proposes a new auxiliary loss that can facilitate locally supervised learning. The proposed loss, \"infopro loss\", is then relaxed to a tractable upper bound, which is then used instead. To implement the loss, mutual information is approximated with a decoder, as well as a classifier. The authors further introduce now contrastive learning fits in the framework as a lower bound maximization process regarding mutual information. The experimental results on standard datasets demonstrate the efficacy of the proposed method.",
    "This paper analyzed the reason why locally supervised training led to performance degradation. And based on the analysis, the author proposed the information propagation loss (can be understood as the combination of a classification loss and a reconstruction loss) aiming to prevent information collapse. Equipped with the proposed method, 40% memory footprint can be reduced demonstrated by their experiments, which is surprising. ",
    "In this paper, the authors propose to sample nodes of a given graph multiple times to form a set of K sub-graphs. GNNs are then applied on each sampled graph for learning node representations. For each node, all representations are combined for the downstream tasks. The idea of doing multiple sampling is to increase the chance that nodes with different neighborhoods can be more different in the set of sampled graphs, than only considering the original single graph. In contrast, nodes with same neighborhood will remain the same over all sampled graphs. This mechanism helps discriminate node representations better.",
    "The paper presents a method that should increase the expressive power of GNN. This method includes sampling subgraphs out of the input graph using a novel diverse sampling method and calculating the output of each node by using a shared GNN on each sampled graph and summing over the outputs. The empirical evidence presented shows that this method outperforms other GNN architectures such as GCN and GAT on several node classification tasks.",
    "This paper claims that existing GNNs often suffers from the limited capability of the aggregation function. This paper proposes a new framework of a diverse sampling of the graph to solve this problem. Specifically, this paper first samples several different graphs and use GNN on each graph to generate features, and finally use a type of injective multi-set aggregation function to obtain the final representation. The experimental results show that adding this module to GCN and GAT can further boost node-based multi-class classification performance. ",
    "The authors explored the robustness of video machine learning models to bit-level corruption. They investigated previous methods such as Out-Of-Distribution (OOD) detection and adversarial training and found that they are not effective enough to defense against the bit-level corruption.  Accordingly, this paper proposed a new framework, Bit-corruption Augmented Training (BAT), which utilizes the knowledge about corruption by bit-level data augmentation at the training stage. Also, the authors argue that the proposed method outperforms the previous methods in handling the bit-level corrupted dataset.",
    "The authors evaluate the effect of bit-level corruption, including network packet losses and bit corruptions, on video models such as action recognition and multi-object tracking. They found that the model performances drop significantly under severe corruption levels. To overcome this issue, they propose a defense method named Bit-corruption Augmented Training (BAT) to enhance the robustness of the model by embedding corrupted video samples in the training process. Results show that BAT is able to improve the model robustness over other methods such as Out-Of-Distribution (OOD) detection and Adversarial Training (AT). ",
    "This work investigates the problem of building robust video prediction models in the presence of signal corruption. The problem itself is not widely studied and experimental work like this one certainly opens some possibilities. The solution on the other hand is surprisingly simple and easy to implement. It serves the purpose of introducing the problem to a wider audience, and shed some light in different types of remedies. ",
    "In this paper, the authors propose learning node embeddings of time varying graphs. They extend the ideas from Skip Gram Negative Sampling (SGNS) to time varying graphs. They extend the relationship between SGNS and Matrix Factorization to a tensor setting. The key contribution seems to be learning a static embedding for each node and an embedding for a time step. These embeddings are combined to learn a time-aware node embedding. Experiments on multiple datasets show that the proposed method outperforms related benchmarks. ",
    "In this paper, the authors studied the problem of time-varying graph embedding problems. The authors generalized skip-gram based graph embedding method to time-varying graphs. The authors show that the method can be used to factorize time-varying graphs as high-order tensors via negative sampling. The authors carried out experiments on several time-resolved proximity networks with comparison to several state-of-art baselines.",
    "The paper proposes an implicit tensor factorization approach for learning time-varying node representations over dynamic networks.  The core method lifts the well-known skip gram based embedding approach from matrix to higher order tensors to support temporal dimensions. The authors claim that such tensor based treatment allows to disentangle the role of node and time. Negative sampling method ( similar to noise contrastive estimation) is extended the higher order tensor setting and incorporated in the cross entropy objective for training. In the experiments, the authors consider five variants of face-to-face proximity data that contains temporal interactions and focuses on tasks of node classification (predicting outcome of SIR epidemic process) and link prediction (in the form of event reconstruction). The proposed method has been compared against two discrete time graph representation learning model and a recently proposed tensor based method. The authors claim that the provided method shows comparable performance with requirement to train lesser number of parameters. Also, the authors provide qualitative analysis in terms of embedding visualizations and goodness of fit plots. ",
    "The authors propose a self-supervised learning task to enhance the reasoning capabilities of machine learning models on mathematical formulas and to perform conjecturing in higher order logic. The task consists in masking out specific portions of mathematical statements and predict them from the surrounding parts. The task can (i) be used during training, to provide supervisory signal to the machine learning model and to increase the effective size of the otherwise small training dataset, and (ii) be used during testing, to evaluate the reasoning capabilities of the learnt models by masking out the mathematical statements at different level of granularities. The authors perform an extensive experimental analysis and provide evidence on the utility of using self-supervised learning in the context of theorem proving.",
    "This paper proposes a skip-tree training task. The authors show that self-supervised language models (the Transformer architecture to be exact) trained on the proposed skip-tree training task for mathematic theorem proving enable mathematical reasoning capabilities. Moreover, no fine-tuning is required to achieve the reported reasoning capabilities. They compare the mathematical reasoning abilities of the skip-tree training task with skip-sequence and show an impressive performance improvement. Another interesting result is studying whether any useful (novel) conjectures can be generated by the model.",
    "This paper extends the idea of language-model style self-supervised learning approach to training logical reasoning models from unlabeled mathematical expressions. The main idea is to develop a skip-tree proxy task (self-supervision) for training the encoder-decoder architecture.  The skip-tree method masks out a complete sub-tree in the input and linearizes it into a sequence in the form of S-expression. The model is required to predict the masked subtree at the decoder end. The paper also proposes several new reasoning tasks for evaluating the model performance. Experimental results show that models learned from this task significantly outperform those trained on the skip-sequence task. Furthermore, the model also exhibits good conjecturing ability in generating quite reasonable amount of new theorems that are provable and useful, which is quite encouraging and impressive.",
    "The paper introduces and analyses the possibility that the effectiveness of PGD-based adversarial attacks might be reduced by imbalanced gradients between the terms of the margin losses commonly used. As a remedy, it also proposed a new scheme for PGD attack, where for the first half of the iterations a single-term loss is optimized, before falling back on the the usual margin loss. The authors test the hypothesis of imbalanced gradients, introducing a new metric, GIR, and the newly proposed attack in two versions, MD and MDMT, on several defenses based on adversarial training.",
    "This paper explores constructing adversarial examples in classification, in order to create better robustness metrics for general classifiers. An attack is defined as an epsilon-perturbation of the learned parameters which create a model whose performance is much degraded. The premise of this paper is to use gradient imbalance as a way of creating perturbation targets, which are claimed (and shown numerically) to better fool networks that are trained to withstand more traditional attacks, and can be used to create more robust models in general.",
    "This work highlights the existence of imbalanced gradients as a phenomenon that may hinder optimization of gradient-based adversarial attacks and, thus, give a false sense of robustness. Imbalanced gradients may occur as the attack objective consists of the difference of two terms (typically, the outputs of the network on two different classes). When the gradients of these two terms have opposite directions, the attack optimization may get easily stuck in a suboptimal local optimum, thus decreasing the attack effectiveness.",
    "This paper proposes a model for verifying semantic equivalence  between symbolic linear algebra expressions. Expressions are represented by trees and equivalence is proven by a sequence of axioms applied to the first expression. The proposed model encodes the expression/program trees as nodes on a graph connected by edges representing one of a set of axioms being applied to one of the elements in the first expression to yield a node in the second expression. The output of the model is a path, a sequence of edges, on this constructed graph that correspond to a sequence of axioms applied to the first expression to arrive at the second.",
    "The authors introduce a new synthetic dataset of equational proofs over the basic axioms of linear algebra.  The dataset consists of triples `(t1, t2, rewrites)` where `rewrites` is a sequence of rewrite instructions that can transform `t1` into `t2`, though some of their models emit one rewrite at a time and observe the result of applying the rewrite instruction to `t1`.  They develop a GNN for the task called pe-graph2axiom and show that it beats two baselines.  Finally, they show that their trained system can solve 15 problems from two Khan Academy modules that can be expressed in their fragment.  The appendix refers to supplementary material including code and data, but no supplementary material was submitted.",
    "This paper proposes a synthetic dataset of algebraic expressions with various kinds of symbols (e.g. scalars, vectors, matrices), and applies graph-to-sequence networks (with attentions) for predicting a sequence of rewrite rules (i.e. axioms) as an equivalent proof between two expressions. The prediction can be validated by a simple checker so that any false positives can be eliminated.",
    "The paper is a nice read. It builds on a line of research on multi-modal video understanding that utilises transformers where these works: 1) fix one of the transformer models (e.g. BERT) and 2) utilise tokens and thus do not train the approach in an end-to-end fashion. This typical trend is due to the memory requirements for training a multi-modal transformer end-to-end.",
    "In this work, the authors present a method for learning audiovisual (AV) representations from videos using a Transformer-based model architecture. Since both video processing and Transformer-based model are memory-intensive, a parameter-reducing scheme is proposed, which facililates training the model end-to-end. The AV representations are learned by training the network to solve two self-supervised pertaining tasks, and subsequently evaluated on various audio/visual downstream tasks. An ablation analysis is performed to demonstrate the efficacy of the various contributions.",
    "This paper studies modeling and training choices when designing a single model based on ConvNets and transformers for audio-visual representation learning. It proposes ablations for which weights/layers to share across modalities, when/where to fuse/join both modalities, and other modeling details (that matter). It also completes pre-training with 3 InfoNCE (audio-audio, visual-visual, audio-visual) with a binary classification loss about if two pairs of audio-visual are from the same or different videos. As strategies for negative sampling in audio and videos are different, it proposes to sample negatives that are similar in the ConvNets' embeddings. The models are pretrained on Kinetics-700 and AudioSet and evaluated on UCF101, ESC-50, and Kinectics-Sounds.",
    "The paper proposes a new learning paradigm that combines both few-shot learning(FSL)  and continual learning (CL) to provide a more realistic learning environment rather than the traditional train-test-retrain approach in FSL. Two environments are proposed, along with a novel dataset. The evaluation seems to be thorough, with strong baselines (conventional approaches adapted to the proposed setting). A novel approach is proposed based on augmenting ProtoNets with contextual memory and is shown to have consistently strong performance compared to the baselines on both tasks.",
    "The paper presented a new setting of online contextualized few shot learning to mimic human learning. This setting combines continual learning and few shot learning, and additionally considers context switch. Specifically, a learning method is presented with a sequence of samples that might come with labels. The method is then tasked to classify the current input into known categories, or recognize the input as belonging to a \u201cnew\u201d category, while at the same time updating the model for known and new categories. Two new datasets (hand-written characters and indoor images) were constructed to support the learning setting. An extension of Prototypical Network (Snell et al.) was explored for this new setting. The results were compared against several baselines and were quite promising. ",
    "This work aims to make a realistic learning setting by combining few-shot learning and continual learning in the online setting. Similar to few-shot learning, the model needs to adapt to new classes with a few samples (at least in the beginning). Similar to continual learning, the model needs to learn new classes over time while being tested on the older classes as well. When encountering a new class, the model is expected to recognize that. Similar to the online setting, model evaluation happens on each trial, after which the model can be updated with that data (labeled or unlabeled). This new paradigm is called Online Contextualize Few-Shot Learning.",
    "This work empirically evaluates the sliding-window strategy for training GNNs with temporal graphs. One may cast the temporal nature of the graph data in an online setting, under which the change of the graph structure as well as the variation of the classes cause distribution shift. The authors conduct a series of experiments to show that the sliding-window strategy is as effective as using the entire historical data for training.",
    "This paper proposes a paradigm which speeds up the training time of GNNs while not compromising too much performance. The method adopts a layerwise training procedure. In particular, the authors inject a loss function at each layer while storing and fixing the feed-forward values of its previous layer. The training is then carried out along all layers parallelly, which allows the updating of paradigms to be decoupled and is not applicable in previous works. A further improvement (lazy-update) by not updating the feed-forward values of each layer is used to reduce the training time.",
    "This work studies the problem of online or incremental learning in temporal graphs (dynamic networks), and more precisely, whether past data can be discarded/ignored without losing predictive accuracy under the assumption that there is the presence of a distribution shift. This question has been essentially investigated over the years in various contexts, e.g., relational learning and classification in dynamic or time-evolving networks. It is also completely obvious that forgetting older data, especially under the assumption of a distribution shift, makes sense and is the correct thing to do. This is exactly what has been done in time-series forecasting for decades. The problem formulation is unclear and can be more precisely defined and motivated appropriately. This needs to be fixed. Are the class labels of a node changing over time, so if a node has label A at time t, then at time t+1 it could have label B, etc. This doesn\u2019t seem true, as it seems the class labels of the nodes are \u201cstatic\u201d, which is unrealistic in many cases. How are the graph snapshots created? How was the timespan selected? What does every time step represent (1 hour, 5 minutes, etc.)?  Also, are the node features changing over time? This doesn\u2019t seem true, but if this is the case, then it is unclear why this would be the case in practice (it would be great to provide some motivation for this, or an example application or problem where this may be true). There are many assumptions that make this problem unrealistic. Furthermore, there have even been works that study the dynamic node classification problem previously, see [1-2] below. ",
    "This paper proposes a new method for learning representations of images with the goal of improving generalization in RL. The key idea is to regularize the learned feature space by forcing embeddings of states followed by the same action (or sequence of actions) to be more similar than embeddings of states followed by different actions. The method is evaluated on the Procgen and achieves superior performance relative to Rainbow, a standard RL algorithm.",
    "This paper tackles the problem of representation learning from visualized input. The paper presents \"cross-state self-constraint(CSSC)\", a technique for regularizing the representation feature space by favoring representation similarity (scalar product between representations) between representations when the agent behaves similarly. The approach is tested with deep RL on the OpenAI ProcGen benchmark.",
    "The authors modify the Rainbow loss through an additional loss based on a cross-state similarity. The notion of similarity is called in the paper \"cross-state self-constraint\" - CSSC. The CSSC loss looks very simple and can be applied with other RL algorithms. The loss is defined in terms of an embedding e of the visual input into a 1-dim space. Given three states x_p, x_q, and x_r, their similarity is defined as the scalar product of e(x_p) and e(x_q) minus the scalar product of e(x_q) and e(x_r). It would be useful if the authors include pseudocode how the loss is exactly computed for a given batch of samples. My understanding of the description is that for a given batch the authors generate triples with the same action set and then take as an auxiliary loss the weighted sum of the logarithms of sigmoids of similarities of these triples.",
    "This paper studies the problem of designing adversarial attacks (on GNN models) that perturb the feature to maximize the misclassified instances. Assuming that the activations are activated independently at random, the paper shows that the attack design can be reduced to the influence maximization problem under the threshold model. The paper identifies several conditions on the threshold that can make the influence maximization problem submodular, thereby making it easy to optimize.  Experiments have been shown that the proposed attack method has higher performance compared to the existing ones.",
    "Paper summary: The paper studies the problem of attacking GNNs in a restricted black-box setup, i.e., by perturbing the features of a small set of nodes, with no access to model parameters and model predictions. The authors draw a connection between the restricted attack problem and the influence maximization problem, and then propose several approximation techniques to solve the reformulated attack problem. Experimental results on attacking three GNN models demonstrate the effectiveness of the proposed attack. ",
    "This paper introduces a novel connection between adversarial attack on graph neural networks in a restricted black-box setup via node feature perturbation, on the one hand, and the influence maximization problem under the linear threshold model on the same graph, on the other hand. An analysis shows that the objective function of the corresponding IM problem is submodular under assumption, hence the problem admits greedy approximation algorithms as effective black-box attack strategies. Experiments show such attacks are effective compared to baselines in degrading the performance of GNNs in terms of mis-classification rate.",
    "This paper attempts to exploit the low-rankness of the adjacency matrix of the DAG in Bayesian network structure learning. The overall framework is similar to NOTEARS, except that the adjacency matrix W is decomposed into low rank components W = UV'. To justify the approach, the paper also includes lower and upper bounds of the rank of DAGs, albeit mostly theoretical and not applicable to real experiments. ",
    "The paper develops several useful lower and upper bounds on the rank of DAGs \u2014 specifically minimum and maximum rank of all weighted matrices that induce the same DAG \u2014 in terms of various graphical properties like head-tail vertex cover, number of non-root and non-leaf vertices. The paper also bounds the rank of DAG in terms of the rank of its skeleton and moral graph. The paper proposes learning low-rank linear or non-linear structural equation models (SEMs) by adding simple norm constraints or matrix factorization to existing SEM learning methods. Through experiments on synthetic and real world data the authors demonstrate that when the underlying SEM is low-rank, exploiting this low-rank assumption in the learning process can lead to better performance. The authors also demonstrate that the rank can be estimated using the obtained bounds from a validation set.",
    "The paper provides a new approch for learning a (possibly densely-connced) low-rank DAG models in the high dimensional settings. In particular, this paper provides how to exploit the property of the low-rank for recovering a underlying causal structure. Futher shown is that under what circumstance the low-rank assumption holds and heuristically confirms that thgrough simulation settings. Lastly, the proposed approach is compared against the state-of-the-art DAG learning algorithms that requirs the assumption of a sparse graph.",
    "This paper shows how the complex autoML pipeline for neural networks can be trained in an end-to-end manner by combining existing methods. By using backpropagatable discrete sampling methods (Gumbel softmax), input transformed by data augmentation is seamlessly embedded in full backpropagation flow. And a differentiable architecture search algorithm is used, which also incorporates architecture search in full backpropagation flow. On top of this differentiable procedure, an alternating optimization is introduced to train network parameters and hyperparameters.",
    "Some of the choices that have to be made when training a neural net based image model are: type of data augmentation, architecture of the neural network, and other hyperparameters such as regularization and optimization hyperparameters (e.g. learning rate). Optimizing all of these is a challenging problem, NAS deals with architecture but ignores the others. More general hyperparameter optimization techniques such as Bayesian Optimization struggle with the dimensionality of the architecture parameters. And optimizing them independently might lead to local minima, and/or be slow.",
    "This paper focuses on achieving automated \"from data to model\" including different components in modeling, namely data augmentation, Neural Architecture Search, Hyper Parameter Optimization. The proposed approach first use data augmentation to select the data argumentation transformation. It tries to select examples which incurs higher training loss for the model to address hard examples. Then use the DAG for neural architecture search. Given the data and architecture, it then alternatively update the model parameter and hyper parameter. The overall proposed framework is end-to-end. Experiment on ImageNet shows slight performance improvement over existing approaches. The authors also conduct ablation study to show the effectiveness of jointly modeling the three components (data augmentation, neural architecture search, hyper-parameter optimization).",
    "This paper extends Prior networks models, previously introduced for classification, to regression problems.  Prior networks are neural networks whose main target is to \"modelling uncertainty in classification tasks by emulating an ensemble using a single model\".  Standard Prior networks models output the parameters of a Dirichlet probability distribution. This Dirichlet probability distribution then defines a distribution over categorical probability distributions over the different classes. This hierarchical approach allows to better capture uncertainty. The presented approach extends this framework to regression tasks. So, instead of returning the parameters of a Dirichlet distribution, it returns the parameters of a Normal-Wishart distribution, which then defines a probability distribution over Normal distributions, and, in turn, each Normal distribution defines a probability distribution over the value of the target variable.  ",
    "Prior Networks (Malinin & Gales, 2018) use Dirichlet prior over categorical predictive distributions to distill ensembles for classification tasks. This paper extends Prior Networks to the regression setting by using a Normal-Wishart prior in order to attempt to match the predictive diversity. The authors define the model and loss terms including analytical derivation and evaluate their proposed approach with synthetic data, UCI datasets and monocular depth estimation. ",
    "This paper addresses interpretable uncertainty quantification for data driven models. In particular, the authors focus on a sub-class of methods known as Prior Networks and attempt to extend these methods to regression tasks as existing approaches address classification only. The author contribution is thus clearly stated and positioned w.r.t. prior arts and tackle a non-trivial issue.",
    "The paper develops a semi-online Bayesian approach to meta-learning, where tasks arrive sequentially and learning within any task is performed in batch mode (hence my terminology semi-online). It suggests a sequential between-task Bayesian update, eq. 5, and proposed three approximations to aid computation. The basic setup is motivated within the recently introduced MAML framework where the learning takes place by adapting a within-task parameter to effectively set up learning within each individual task, allowing the learner to transfer information between tasks, while remaining adaptive to a specific novel task. The authors phrase this idea in the Bayesian language of posterior distributions, that are updated both within and between tasks. The posterior formed after learning t tasks, serves as a prior for learning a new task. The authors suggest 3 approximation schemes, a Laplace approximation, a Hessian approximation, and a variational approximation. Finally, a set of experiments are presented comparing performance to 2 baselines, namely TOE (train of everything) and TFS (train from scratch). A particularly interesting application is to 5 standard sets of images, testing for catastrophic forgetting of previous tasks and the transferability of  information across tasks in the face of distributional shift.",
    "The paper proposes an Bayesian approach to online meta-learning. This is done by lifting (approximate) sequential Bayesian inference from the model parameters to the meta-parameters. Two approaches are proposed to do this: (i) Laplace Approximation (LA), thereby extending Ritter et al\u2019s method from online learning to online meta-learning; and (ii) VI, thereby extending Nguyen et al\u2019s Variational Continual Learning (VCL) method in a similar way. Experiments are performed by converting existing meta-learning benchmarks into online settings in two ways, which they call \u201csequential tasks\u201d and \u201csequential datasets\u201d respectively. The experimental results show resistance to catastrophic forgetting in both of these experimental settings. ",
    "This work proposes a Bayesian approach to meta-learning from sequential data. Two algorithms are proposed. The first is based on the Laplace approximation to the model posterior which is made tractable by using K-FAC approximation of the Hessian. The second approaches uses a variational approximation for the posterior, where meta-learning corresponds to learning the variational prior. The experiments present results of the proposed method in sequential Omniglot and a pentathlon task involving different datasets.",
    "The paper has a fully theoretical flair while proposing a novel and seemingly efficient procedure to recursively compute the higher-order (i.e. more than 1-hop) neighbourhood of a node that are used for learning discriminative graph embedding. The paper contributes with the model above (RNP-GNN) and by providing a proof of its representational power and a general theorem supplying an information theoretic lower bound on the complexity of GNNs that can count induced substructures.",
    "The goal of the paper is to show that GNN's (without exponential computational complexity) can be constructed with the ability to count subgraphs. To this effect, the authors propose a principled neighborhood pooling strategy and theoretically characterize their expressive power - with respect to other models proposed earlier. More specifically, the authors propose a recursive neighborhood pooling strategy which characterizes graphs based on the counts of subgraphs . Furthermore, they show that if the tuple of recursion parameters are chosen well, their proposed model can capture all induced subgraphs (universality) of sizes smaller than the first value in the tuple of recursion parameters plus 1 - and show a relationship to the reconstruction conjecture (Kelly et al. 1957). The authors also provide a bound on the number of iterations required to learn the expressive representations.",
    "The proposed paper seeks a theoretical possibility of counting the subgraph by a graph neural network. To this end, the authors proposed a recursive neighborhood pooling graph neural network and proved the express power of the model. The universal approximation results on a subgraph have been shown as well. Analysis of computational complexity shows the algorithm is much efficient than the known class of models that can count substructures.",
    "This paper studies Lyapunov chaos in learning algorithms for matrix games. It appears to extend earlier work by Cheung and Piliouras to more general-sum settings with the conclusion that in these more common settings the learning algorithms considered exhibit chaos. The paper also presents an interesting notion of matrix domination which is a necessary and sufficient condition for chaos, and also a linear programming approach for the purpose of identifying chaotic games.",
    "This paper studies the chaos phenomena of learning in general normal-form games beyond zero-sum and coordination games. Building upon the previous works by Cheung & Piliouras, the authors apply the canonical decomposition of a general bimatrix game to a sum of a zero-sum game and a coordination game. The authors further devise two new techniques: matrix domination and linear program to help analyze the game dynamics.",
    "This paper provides tools for classifying the payoff dynamics in general-sum n-player games as Lyapunov chaotic assuming three common algorithms are used: multiplicative weights update (FTRL with entropy regularizer), optimistic MWU, and FTRL with L2 regularizer. Previous work (Cheung & Piliouras) showed that the existence of Lyapunov chaos in the dual space is indicated by the sign of a function C of the game. This work shows that this function can be decomposed into a sum: C of the zero-sum part + C of the coordination part. They also show how to use trivial matrices (which don't affect C) to further reduce parts of the game in a way that eases the analysis. As part of their analysis, they prove that the set of bi-matrix games exhibiting chaos has positive Lebesgue measure and discuss how the relative strength of the zero-sum and coordination parts determines the ultimate sign of C.",
    "The paper provides a new family of adaptive optimization algorithms by designing the proximal function of the adaptive algorithms to minimize marginal regret bound. The paper shows that the regret bound is better than existing algorithms in a sense. The paper also presents simulation study on a variety of domains that compare the proposed algorithms with other commonly used algorithms.",
    "This paper proposes a new class of adaptive algorithms inspired by finding an optimal proximal function of adaptive algorithms. They provide a theoretical analysis of the new method showing that it would potentially improve the regret bound of current algorithms. Finally, the proposed method is empirically matched with or superior to other popular algorithms on different tasks. ",
    "This paper introduces a new online convex optimization algorithm that operates in via the reduction to online linear optimization in which the regret is bounded by $\\sum_{t=1}^T \\langle g_t, x_t - u\\rangle$ where $g_t$ is the gradient of the t^th loss at $x_t$. The algorithm is based on online mirror descent with non-decreasing quadratic regularizers $x^\\top H_t x$, using the update $x_{t+1} = argmin_x \\langle g_t, x \\rangle + (x-x_t)^\\top H_t(x-x_t)$ (or, equivalently using the terminology in the paper, $argmin \\langle g_t, x_t\\rangle /\\sqrt(t) + (x-x_t)^\\top H_t(x-x_t)$ where we replace $H_t$ by $H_t/\\sqrt{t}$. The analysis is restricted to diagonal $H_t$, for which we can break the regret into a sum of $d$ 1-dimensional problems, so it suffices to do the analysis in the scalar case. The idea is to break out the standard analysis of mirror descent regret as the sum over all t of $D^2(H_t - H_{t-1}) + g_t^2 H_t^{-1}$, where $D$ is the $\\ell_\\infty$ diameter of the domain, and then choose $H_t$ to minimize each of these terms greedily subject to the non-decreasing condition. A regret bound is provided for this algorithm that achieves worst-case $\\sqrt{T}$ regret, but in cases in which the gradients are small, the regret is much better. By employing this strategy on a per-coordinate basis one can obtain an adagrad-esque regret bound.",
    "The paper proposes an Expected Quadratic Utility Maximization (EQUM) framework for policy grandient Mean-Variance control. The authors claim that current state-of-the-art methods suffer either suffer from computational issues or cannot control risk at desiderable level, hence they propose their approach as a possible solution. They provide different interpretation for the EQUM: standard objective with a regularization, variance minimization with a constraint on expected return and a return targeting optimization. A policy gradient algorithm for EQUM is proposed together with its Actor-Critic extension.",
    "The paper proposes a policy gradient style RL algorithm that optimizes an expected quadratic utility, a commonly used objective of risk management in finance and economics. The key idea here is based on the observation that when using the quadratic utility function, the use of mean-variance RL methods can be shown to optimize the utility of the agent. To this effect, the paper considers the use of expected quadratic utility maximization in the policy gradient. The quadratic utility can be naturally modeled using mean and variance. The paper implements two variations -- policy gradient and actor-critic with EQUM framework. ",
    "In this paper the author proposed a new mean-variance algorithm whose policy gradient algorithm is more simpler than other SOTA methods and it has an unbiased gradient. Instead of formulating the problem as an traditional mean variance constrained problem, the authors utilized quadratic utility theory and formulate the problem as variance minimization problem with a mean reward equality constraint. Then by reformulating the problem with the penalized problem and opening up the variance formulation, they showed that this mean-variance formulation does indeed have an unbiased policy gradient, that does not require advanced techniques such as double sampling or frenchel duality. To demonstrate the effectiveness of this method on balancing risk and return, they also evaluate their methods on several risk-sensitive RL benchmarks (such as portfolio optimization) and compared with a wide range of risk-sensitive RL methods.",
    "This paper pinpoints the key issues of Auxiliary Learning: (1). how to design useful auxiliary tasks, (2) how to combine auxiliary tasks into a single coherent loss. Motived by the issues, this paper proposes a novel Auxiliary Learning frame work, named AuxiLearn. The paper is globally well organized and clearly written. ",
    "This paper studies a variant of multi-task learning, auxiliary learning, where one main task dominates, and other tasks are used to learn a good representation. To achieve this goal, the authors propose a learning-to-learn algorithm. In particular, the auxiliary losses are represented by a vector and then transformed to a new loss term via linear or nonlinear function $h$. They also made two more contributions. First, an approach of new auxiliary task generation is proposed. Second, an implicit differentiation based optimization method is proposed to find the solution. Both theoretical analysis and empirical studies demonstrate the superiority of their proposed model.",
    "The paper proposes AuxiLearn, a framework that can be used to combine losses from multiple auxiliary tasks (if present) into a single combined, loss function that does not require expensive grid search over possible linear combination. It uses an implicit differentiation-based approach to train a (deep) non-linear network that weighs the various auxiliary losses to optimize the generalization capabilities of the network. In the absence of such pre-defined tasks, a variation of the approach, using teacher-student networks, helps create relevant tasks to improve the performance of the network. Experiments across tasks such as classification (both few-shot and with limited labels) and segmentation show that the approach helps improve the performance of the model on the main task.",
    "The paper proposes a technique for assessing the uncertainty of a Transformer-based NMT model on a given input $x$. The technique relies on computing a variance-like estimate over a collection of translation candidates for $x$, where these candidates are obtained by perturbing the decoding mechanism through the use of dropout at test time. Experiments compare this technique with other ways of measuring the \"epistemic uncertainty\" of the NMT model. In limited training data conditions, the proposed measure is better aligned with the actual performance of the model than competing measures, and in particular is better able to detect Out-of-Domain translation requests.",
    "The paper proposed a Baysian method for detecting out of distribution (OOD) in machine translation. To this end, the paper introduces BLEU variance (BLEUVar) that is computed based on a number of samples from Transformer with MC Dropout. The advantage of BLEUVar is that it doesn\u2019t require reference, instead it\u2019s computed based on pairwise comparison of the decoded sentences.",
    "This paper describes a method for estimating a neural machine translation (NMT) system's uncertainty about its translation of a sentence that has two parts: (1) use MC Dropout as a proxy for integrating out parameters; (2) two uncertainty metrics (probability of translation summing over randomly-sampled parameters and variance in BLEU using randomly-sampled parameters). The baseline method is just to use the probability of the 1-best translation under the MLE parameters. The method is evaluated by measuring the BLEU score of a test set retaining only the most-certain fraction of the sentences.",
    "Generating a pruned network falls into two broad categories: 1) spend some extra time and effort to train or fine-tune the pruned model after first training a dense version, or 2) cut out that extra time and effort by generating a sparse network \"from scratch.\"  While approach (1) has historically given the best accuracy, recent advances (such as the lottery ticket hypothesis) suggest that there are sparse networks hidden in the initialization that don't need to first be trained, if only we could divine the structure of those models.  Approach (2) seeks to do just this: determine the connectivity as close to initialization possible.  However, even the best results taking this second path fall short when compared to the accuracy of the former path - why is this?  The submission pokes at three recent techniques to pull out some commonalities that are *not* shared with (1), suggesting possible issues that need to be overcome to improve accuracy, and proposes a set of experiments and comparisons that should be part of any new technique that claims to discover a good sparse mask at initialization.",
    "The paper provides an extensive empirical analysis of Pruning-at-Initialization (PaI) techniques and compares it against two pruning methods after (or during) training. This comparison sheds some light on why pruning at initialization is inherently hard. Furthermore, the comparison among PaI methods with various ablations shows some inherent properties that are common to PaI methods and the benefits/drawbacks of certain methods. With these experiments, certain conclusions are reached among them an important one is that PaI methods only determine what is the fraction of weights to be pruned in each layer rather than which weights to prune.",
    "A recent trend of 'pruning at initialization' in neural network pruning has left me baffled. It's counter-intuitive that neural networks can be pruned at initialisation, improving results for the training done thereafter. Nitpicking semantics, one could hardly even call this a pruning technique, since there is no a-priori knowledge of the dataset distilled in the network. Perhaps it's more aptly referred to as a method of sparse initialisation methods.",
    "The paper claims to be the first paper that simultaneously handles Byzantine threats while ensuring privacy in a federated learning setup. One of their main claims is that this is the first algorithm that provides dimension independent robustness guarantees against byzantine threats (I have some concerns regarding this claim). The algorithm first divides all the machines into shards. Within each shard there is secure aggregation. Finally, the outputs of each shard is robustly aggregated such that the error isn't dimension dependent.",
    "The paper considers robustness to poisoning and backdoor attacks in the context of federated learning. It proposes a defence based  on splitting the clients into shards, averaging their updates via secure aggregation and then using a robust mean estimation on top to ensure robustness. The authors point out that controlling the number of shards is a way to trade-off privacy vs robustness, thus potentially dealing with both malicious clients and an honest, but curious server. The paper provides some theoretical justification for the algorithm, as well as an experimental evaluation where its performance is tested against multiple attacks and compared to other existing methods.",
    "The authors consider federated learning setting and how to defend the overall learning task against malicious clients and a semi-honest centralized server. Though there are known ways to prevent attacks, they suffer from a large error in the estimator and also do not preserve privacy of updates since the server sees them in the clear in order to adjust for error. This paper proposes a sharding technique and use of the estimator method whose error does not depend on the number of dimensions as previous work.",
    "This paper focuses on model-based black box optimization problems in the offline setting. These are settings where access to ground truth is expensive, and instead the optimizer has access only to a trained model of the ground truth based on limited data. While optimizing on this surrogate space, a good optimizer often needs to account for model uncertainty and accuracy degradation. The main aim of the paper is to provide a test bed for algorithms that try to solve this challenge. ",
    "This paper studies the evaluation of offline black-box optimization algorithms. The community currently lacks a standardized benchmark to compare the performance of methods. This paper presents a new suite of offline model-based optimization tasks and standardized evaluation procedures for the community. The evaluation criterion for the quality of a benchmark is the realism and diversity of the tasks, with special consideration for high-dimensional design space and the objective function's sensitivity. The paper then evaluates several algorithms on the benchmark. ",
    "This paper proposes a benchmark suite of offline model-based optimization problems. This benchmark includes diverse and realistic tasks derived from real-world problems in biology, material science, and robotics contains a wide variety of domains, and it covers both continuous and discrete, low and high dimensional design spaces. The authors provide a comprehensive evaluation of existing methods under identical assumptions and get several interesting takeaways from",
    "This paper focuses on providing a more generalize multimodal ELBO to encompass previous PoE and MoE as special cases and combines their benefits. To this end, the authors first define the new ELBO L_{MoPoE} which is an interesting extension of PoE and MoE. Different from PoE (product of experts) and MoE (mixture of experts), MoPoE (mixture of product of experts) explores a more general way by mixing more experts where each expert is the product of a subset of all modalities\u2019 posterior. In this way, as illustrated by the author, PoE and MoE can be seen as specific cases of MoPoE easily. The proposed model achieves competitive results compared with PoE and MoE.",
    "The paper combines ideas from two previous works (MVAE and MMVAE) to propose a new multimodal formulation of the ELBO for VAEs. The approximate posterior consists of a mixture of subsets, with each subset a product of approximate posteriors for each modality. This generalizes previous works, and the authors show that their objective yields a lower bound on the full data log-likelihood. They also compare their approach with MVAE and MMVAE on three multimodal datasets, showing benefits in classification accuracy, coherence, and log-likelihood. Although the proposed method is not superior in all cases, it generally achieves a reasonable trade-off across performance metrics.",
    "This paper formulates a multimodal ELBO as a mixture of product of experts. This allows them to use one encoder per mode while still allowing inference over any subset of modes without needing a new encoder for each subset. The idea is simple and appears to improve on baselines derived from a mixture or a product of experts.",
    "The goal of this paper is to enable the introduction of prior expert knowledge in Bayesian optimization. This is performed by defining a prior distribution for the optimal value, which is included in the pseudo-posterior used to select new points by Expected Improvement. The number of iterations it takes to overcome a potentially wrong prior information is controlled by a parameter, whose sensitivity is studied. Extensive experiments are conducted on toy examples as well are more realistic hyper-parameter test cases.",
    "This paper incorporates a prior distribution given by experts into Bayesian optimization (BO), to leverage useful human knowledge to accelerate BO. The algorithm uses an intuitive approach to combine the prior with the probabilistic surrogate model of BO to derive a pseudo-posterior, which naturally leads the EI acquisition function. As the BO progresses, the prior information is gradually overwhelmed by the observed data, which ensures the asymptotically correct behaviour.",
    "The paper presents a novel method to incorporate experts' knowledge into BO. This is done through introducing  Prior-guided Bayesian Optimization (PrBO). Different experiments where conducted to compare PrBO vs different baselines and to show the effect of the user provided priors in the cases where it is well-specified or mis-specified. The design of PrBO enables it to guide the search in the early iterations and as optimization progresses, more emphasis is given to the model and the effect of the prior is washed out.",
    "The paper introduces the first way (to the best of authors knowledge) of building generative models with binary weights. Also the case with binary activations is considered. The authors consider two SOTA generative models (flow++ and RVAE) and develop technique to binarize all weights (and possibly activcations) in residual layers. They show that residual layers can be binarized with relatively small drop in performance and further binarization of remaining blocks in computational graph leads to significant degradation. Binary modification of weight normalization is suggested although no ablation is study is performed so it is unclear how crucial is BWN for robust learning. The training process itself is pretty standard way of training binary DNNs - they use STE + truncation of real-valued weights counter-parts.",
    "The authors propose to binarize weights and activations of generative VAE and Flow++ models. As Weight Normalization is commonly used in these models, the authors notice that Euclidean norm of binary [-1;1] vector is a square root of it\u2019s length, such that Weight Normalization can be reduced to affine scaling. They propose to call this scaling Binary Weight Normalization, and evaluate it on CIFAR and ImageNet datasets.",
    "This paper describes a method to binarize weights and activations of variational autoencoders and flow-based networks.  This is an important issue as these methods are valuable to solving unsupervised problems, but are rapidly growing in size, necessitating large and expensive computing systems. And, the literature of low and binary precision hasn\u2019t considered these use-cases to date.",
    "The paper extends current adversarial learning approaches beyond imperceptible L_p norm perturbations. The proposed approach can handle many models of natural variation, such as a change in brightness. The main idea behind the approach is to use unsupervised approaches such as GANs to model the natural variation. Given this model of natural variation, the paper replaces the adversarial learning objective of finding the worst example in an L_p norm ball around a data point to finding the worst example based on the model of natural variation. This is expensive, so the paper also proposes more computationally efficient approaches based on data augmentation. The experimental results demonstrate that the proposed approach performs well on a variety of tasks.",
    "This paper proposes a model-based framework for improving the robustness of image classifiers to average-case corruptions of varying severity. The proposed framework can be thought of as adversarial training where the perturbation is replaced by a function that transforms the image according to a specific corruption. A nuisance parameter controls the instantiation and severity of the corruption that is applied to the input. The paper compares baselines to different versions of this general model-based framework with experiments on several datasets.",
    "This paper proposes a \u201cparadigm shift\u201d for augmenting datasets when training CNN-based image classifiers. On one side, traditional augmentations include blur, Gaussian noise, color distortions. On the other side, methods like adversarial training consider augmentations under norm bounds in the image space. The proposed method, instead, uses models of natural variation to augment the images. Increased out-of-domain accuracy is shown on ImageNet-C and several slices of the CURE-TSR dataset. ",
    "The paper studies the non-convex optimization problem of training CNNs with ReLU activations under different choices for the CNN architecture, and shows how these can be framed as convex problems with a poly time complexity w.r.t. relevant variables. The derived convex problems provide valuable insights on how the CNN architecture induces different weight regularizers by giving them in explicit form -- these show a rich connection between the architecture and regularizer.",
    "[Summary] This paper focuses on training convolutional neural networks (CNNs) by using convex optimization techniques. By taking the dual of the nonconvex training problems, (and the dual of its dual), the main contribution of the paper is to show the strong duality between the convex problem and its original nonconvex training problems. This result has been proved for multi-layer CNNs with one ReLU layer and three-layer CNNs with two ReLU layers.",
    "The paper considers several types of CNN and proposes convex reformulations for non-convex problems of training these networks. As a result a polynomial complexity is shown for the training problem. The results are also interpreted as implicit regularization induced by the choice of the architecture. Finally, numerical experiments are made to support the theoretical findings and show that in the predicted regime, SGD for the original problem converges to the global minimizer given by the convex reformulation.",
    "This is a well-written paper that discusses how to learn disentangled representations for the learning from demonstrations (LfD) task in robotics. It is shown that using weak-supervision on top of unsupervised learning frameworks (that use the variational autoencoder for instance) can work well in this case. These disentangled factors of variation in the data are shown to correspond well to the 'abstract concepts' of the human demonstrations. This is shown in the example of the PR2 robot dabbing demonstrations, including visual data as well robot trajectories. ",
    "Under the context of learning\u00a0from demonstrations, the paper studies the problem of leaning interpretable low dimensional representations\u00a0from high dimensional multimodal inputs using\u00a0weak supervision. Paper argues that since robots and humans have different levels of abstractions and mechanisms, observation+action spaces between them are greatly misaligned which\u00a0complicates learning by directly observing humans. However, the underlying concepts essential for tasks\u00a0lie in a much lower-dimensional manifold. Learning this\u00a0manifold\u00a0effectively and in an interpretable way, especially using weak supervision, can significantly change how robots\u00a0can acquire skills from demonstrations and generalize them to new unseen scenarios. Towards this end, the paper proposes to learn probabilistic\u00a0generative models capturing high-level notions from demonstrations using variational inference. The strength of the paper is in demonstrating that conditional latent variable models can learn disentangled\u00a0low dimensional represented using weak supervision;\u00a0which authors effectively demonstrated\u00a0using real-world\u00a0experiments. My main reservations are in terms\u00a0of the technical novelty of the paper and the narrow scope of experimental evaluation.",
    "This paper presents a way to learn from demonstrations with weak or no labels. The premise behind this paper is that even when humans provide labels during a demonstration, those labels often do not fully describe the data (e.g., the human may say \"soft\" when \"fast\" would also apply). This paper presents a technique that uses latent variables to model the uncertainty over a group of class labels that could describe the task (e.g., slow, soft, left-of-object). The variables are modeled such that the observation is conditionally independent of the human provided labels given the latent variables. This allows the human provided labels to be decoupled (or disentangled as the paper calls it) from the observations. By doing so, it is possible to have only partial labels (weak labels). This model was applied to a task where a human would teleoperate a robot arm and apply a dabbing motion in relation to an object in the scene. The operator would provide only one of several possible applicable labels for each demonstration. The results show that the models using the weak labeling out-performed models with no labeling.",
    "This paper studies fine-tuning BERT-like pretrained language models (PLMs) on low resource target tasks. The authors hypothesize that the general-purpose knowledge obtained by the PLMs from pre-training might be irrelevant and redundant for a given target task. When fine-tuned onto a low resource target task, overfitting is likely to happen. To this end, a fine-tuning framework based on variational information bottleneck (VIB) is proposed to address these challenges. Specifically, the sentence representation will be mapped to a latent Gaussian variable  which compresses information in the sentence and also suppress irrelevant and redundant features, and a reconstructed version of the representation is used for task prediction. Empirical evaluations on sever datasets demonstrates the effectiveness of the method over previous research.",
    "This work applies information bottleneck as a way to compress the pre-trained representation so that only meaningful features are employed for the target task. It is applied for the number of GLUE tasks especially focusing on low resource settings and show consistent gains over previously known strong baselines, e.g., Mixout and L2-of-difference. This work also demonstrates that the learned model has generalization capacity so that the tuned model works on out-of-domain data.",
    "The paper proposes a method to avoid overfitting while finetuning the large pretrained models for downstream tasks on small scale datasets. It has been shown that many SOTA models usually overfit w.r.t. spurious correlations in the data and as a result fail miserably when tested for generalization on the out of domain datasets. The proposed method tries to maximally filter out task-irrelevant information in the feature vectors by minimizing the mutual information between the original features and the bottleneck features while simultaneously optimizing for performance. Experiments on several datasets show improved performance on both in-domain and out-of-domain datasets.",
    "1. This is the first work that attempts to reconstruct 3D shape from 2D image in an unsupervised way using GANs. The idea is neat: Use networks to predict four 3D parameters and use GAN to generate / synthesize the images corresponding to a set of parameters. Then these synthesized images can be used as pseudo ground truth to train the 3D parameter network.",
    "This paper studies an interesting inverse-graphics problem. It proposed a novel method to learn 3D shape reconstruction using pre-trained 2D image generative adversarial networks. Given an image containing one single object of interest, it first predicts the graphics code (e.g., viewpoint, lighting, depth, and albedo) by minimizing the reconstruction error using a differentiable renderer. The next step is to render many pseudo samples by randomization in the viewpoint and lighting space, while keeping the predicted depth and albedo fixed. A pre-trained 2D image GAN is further used to project the pseudo samples to the learned data manifold through GAN-Inversion. Finally, these projected samples are added to the set for the next round optimization. Experimental evaluations have been conducted on several categories including face, car, building, and horse.",
    "This paper proposes an iterative method that jointly estimates viewpoints, light directions, depth, and albedo from single images, by projecting intermediate renderings to the nautral image manifold. Intuitively, the method works by generating, with pre-trained GANs, multiple views of the same object under different lightings, and then inferring 3D shapes from those variants. The key idea is to use pre-trained 2D GANs to make such data generation photorealistic. The authors also demonstrate 3D edits, such as 3D rotation and relighting, that one can perform after running their model.",
    "The majority of feature extraction backbone is shared among different agents and the classifiers of experts are trained with both classification loss and proposed distribution-aware diversity loss. For the second stage, an expert assignment module is trained to re-weight the expert decisions. The whole paper is generally well-organized. However, there are some technical issues authors should further address:",
    "This paper proposes a Routing Diverse Experts (RIDE) framework to solve the long-tailed classification problem. It has 1) a shared low-level feature extractor and multiple expert classifiers, 2) a distribution-aware diversity loss to encourage experts learning different classification strategies, 3) an expert routing module that dynamically selects a subset of experts for each test instance to make a joint decision. This paper firstly increases the performances on all three splits (many-/med-/few-shot), while most of the existing methods have to sacrifice the head for tail improvements.",
    "This paper proposes a method termed RoutIng Diverse Experts (RIDE) for reducing both the bias and the variance of a long-tailed classifier. Specifically, RIDE consists of three crucial components: 1) a shared architecture for multiple experts; 2) a distribution-aware diversity loss that encourages more diverse decisions for classes with fewer training instances; 3) an expert routing module that dynamically assigns more ambiguous instances to additional experts. Experiments are conducted on three long-tailed benchmark datasets, i.e., CIFAR100-LT, ImageNet-LT, and iNaturalist. Satisfactory classification results of long-tailed visual recognition are observed.",
    "The paper discusses various baseline scoring mechanisms used for filter pruning that are norm-based and finds that none of the scoring mechanisms are particularly effective at pruning filters from CNNs. Moreover, all methods seem to perform very similar to each other. These conclusions are based on a theoretical (and experimental) analysis of the various scoring mechanisms under the assumption that trained filter weights follow a Gaussian-like distribution, which reveals that in this case the scoring mechanisms are insufficient to reliably discern the importance of filters since the resulting scores are very similar. The Gaussian-like assumption, which is termed \"Convolution Weight Distribution Assumption\" (CWDA), is validated through a large range of experiments on different architectures and data sets.",
    "The goal of the paper is to bring into attention that many norm-based pruning criteria used for structured pruning are very similar, in that their ranking of the redundant filters is highly correlated. The key ingredient is the CWDA assumption that filters in a particular convolutional layer are iid and approximately follow a Gaussian distribution, which is shown based on extensive statistical hypothesis testing. Based on this assumption, they prove that these pruning criteria are roughly the same. ",
    "This paper analyzes the current limitations of existing magnitude-based pruning methods. First, the paper focuses on the similarities between three methods and then focuses on the redundancy in large networks. The paper also analyzes the weight distribution for a well-trained network and propose CDWA as a way to prove this distribution.  My main concern with this paper is the contribution to the field. ",
    "This paper proposes GraphCodeBERT as a Transformer-based pretrained model for programming language that incorporates data flow information in the graph representation of variables in the code. The data flow graph encodes the structure of variables based on \u201cwhere-the-value-comes-from\u201d from the AST parse. The pretrained model is jointly trained on the code, the natural language comment of the code, and the data flow graph of the code. In addition to the Masked Language Modeling objective, two new pretraining objectives are proposed including predicting the edge of the data flow graph and predicting the alignment of variables between data flow graph and code. The graph-guided masked attention is used such that the attention can only occur if two variables have an edge in the data flow graph or there is an alignment between data flow graph and code. The experiments show that GraphCodeBERT can deliver improvements on Natural Language Code Search, Code Clone Detection, Code Translation, and Code Refinement.",
    "The authors present Graph Code BERT, the first language model that leverages data flow to learn code representation. They use three objective functions: Masked Language Modeling, Edge Prediction, and Node Alignment. They claim their structure-aware pre-training can help improving performance on code-related downstream tasks, including code search, clone detection, code translation, and code refinement.",
    "This work address the pretraining over code and text. It proposes to leverage data flow as additional inputs, and add two structure aware pre-training tasks besides the masked token prediction task. The pretrained model is evaluated on four different tasks and outperforms the CodeBERT baselines as well as other pretrained models. Further analysis confirmed the benefits from the additional tasks and data flow input. ",
    "The paper presents a novel approach to improve the accuracy of regression models that are learned from a skew dataset. The proposed approach consists of two parts, namely, (i) adversarial network for forcing output distributions and (ii) regularization based on an adversarial autoencoder. Experiments suggest that the proposed approach increases the accuracy of the regression model for all the four datasets considered in the paper.",
    "This paper proposed to learn a regression model using \"skewed data\", which is defined as the subset of training samples with true target above certain threshold. The model consists of two components. First, the input x was mapped to its latent space through encoder R_enc. The latent representation was further mapped to the predicted output through regressor network R_post. The predictive distribution was forced to match the true target distribution p(y) through an adversarial network. Second, the latent space representations were also forced to match the true target distribution p(y). Experimental results on synthetic benchmark data showed the proposed approach performed better than naively applying regression model on the skewed data.",
    "This paper proposed a semi-supervised learning approach to improve the regression model trained on output-skewed data. The key assumption is that, though the training outputs can be skewed, it is easy to estimate the true distribution of the output. The proposed model that combines an AAE that generates the output distribution, and an adversarial model that enforces the distribution of the predicted output to resemble the true distribution of the output. On several real datasets, the ablation study shows the proposed model can improve the regression accuracy.",
    "This paper proposes an architecture that addresses transferability of compositionality. The proposed architecture consists of three components: a network that transforms the input X into a series of hidden representations {H_1, H_2, ... H_K}, a network that reconstructs the input X from this series of hidden representations, and a prediction network that generates a prediction from the hidden representations. The authors propose several datasets meant to address transferability of compositional generalisation, and show that their architecture significantly improves standard DNN architectures as well as humans on these datasets.",
    "The paper introduces a \u201ctransferability of compositionality\u201d problem and proposes an approach to alleviate it. The said problem may arise when one trains neural models to produce \u201ccompositional\u201d representations of the input. In the paper \u201ccompositional representations\u201d consist of multiple vectors which are supposed to correspond to semantically meaningful aspects of the input, for example different objects in the case of images or different parts of compound words in the case of linguistic inputs. The transferability problem arises when there is a difference between training and test distributions, namely when certain combinations of objects have different probabilities in training & testing. The proposed solution at inference time is to project object representations to the manifold of individual object representations. The manifold is estimated by saving representations of individual object representations from the training time. ",
    "This paper studies \"compositionality\" and in particular the way in which it \"transfers\" on test data. They run simple baselines on three experiments (overlapped MNIST, colored MNIST and concatenated month names) and find that the baselines do not learn compositional representation. They proposed the use of an *auxiliary reconstruction network and a regularized optimization* which improves on these baselines. ",
    "The paper studies poisoning attacks on RL agents, in which the attacker influences the agent's learning process by changing the feedback obtained from the environment. The focus is put on attacking policy-based deep RL agents, without necessarily having access to the underlying MDP model of the environment. The paper proposes a new poisoning algorithm, called Vulnerability-Aware Adversarial Critic Poison, and experimentally demonstrates its effectiveness on 5 different RL environments.   ",
    "The paper studies poisoning attacks against online reinforcement learning agents. The attacker has the power of manipulating the training data, i.e., state-action-reward trajectories, in order to achieve some attack goal. The attack can be completely black-box, meaning that the proposed method allows an attack setting where the attacker has no knowledge of the RL algorithm used by the victim agent or the environment. In this scenario, the authors proposed that the attacker can imitate the learning procedure of the victim, and then based on the imitated policy; the attacker designs how to poison the training data. The attack is formulated as a bi-level optimization, where the lower level involves the imitated learning procedure. Due to the intractability of sequential optimization, the original formulation is simplified so that only the attack only solves the attack on the current training data. This procedure is repeated in every episode to achieve sequential attacks. Experiments on a variety of tasks demonstrate the superiority of the proposed attack.",
    "This paper proposes a poisoning algorithm named Vulnerability-Aware Adversarial Critic Poison (VA2C-P) to attack policy-based deep reinforcement learning agents. The poisoning attack is formulated as a sequential bilevel optimisation problem (Problem Q), where the attacker either minimises the expected total rewards of the learner (non-targeted poisoning), or forces the learner to learn a target policy (targeted poisoning). To solve Problem Q, VA2C-P mainly makes two decision: (1) when to attack: a new metric named stability radius is proposed to decide the attack timing, (2) how to attack: a mechanism of adversarial critic is designed to solve a relaxed version of Problem Q by only considering the loss of the immediate next iteration.",
    "The paper presents an online algorithm for dynamic tensor rematerialization.  Theoretically, it shows the same asymptotic order on the memory budget and tensor operations as of the optimal static approach.  By simulation, it shows the performance matches optimal static checkpointing in a few models.  A PyTorch prototype is implemented, which shows benefits of reducing memory footprint and increased batch size comparing with basic PyTorch models without checkpointing.",
    "Contributions: a) analyzes multiple heuristics for which tensors to evict where compute overhead of rematerialization is minimal overall, b) suggested approach is just-in-time, and thus does not require any static analysis of the network. That is, unlike prior work in this area, it covers any network type with no prior knowledge, c) offers a good formal analysis of proposed heuristic in terms of its components: staleness, memory capacity and recursive replay cost - their formalization covers previously published heuristics as well.  Experimental framework is sound. And some encouraging results are shown delivering memory capacity saving of 30% to 90% with training slowdown of 2x or less.",
    "This paper proposed a simple yet effective greedy algorithm with a new heuristics on checkpointing deep learning models so that people could train large model with restricted GPU memory budgets. The proposed method operates in an online setting and do not need static analysis of computation graph, thus could be used for both static and dynamic models. In a restricted model setting of linear forward network and equal space and time cost for each node, the author proves the proposed method could reach the same bound on tensor operation and memory budget with previous static checkpointing methods. The author also establish a theorem on tensor operation numbers between the proposed dynamical method and an optimal static checkpointing algorithm. In experiment, the author compared the proposed method with static techniques including the optimal Checkmate tool of Jain et al. (2020), showing the proposed method gives competitive performance without static model analysis in prior. The author also compared the proposed heuristics with prior arts on several static and dynamic models. Finally, the author described a prototype of PyTorch implementation of the proposed method. ",
    "The paper addresses the problem of \"hallucinated\" content in conditional neural generation for two specific tasks: machine translation and summarization. It proposes a new task for faithfulness assessment, which classifies each token as either hallucinated or not. The classifier uses a pre-trained LM (either XLM-R or ROBERTa) and is fine-tuned on synthetic classification data created using both 'noisified' real data and a pretrained LM (BART). Experiments on either summarization and MT system outputs labeled for hallucinations show relatively encouraging classification results (e.g., F1 of 0.46 to 0.66 for MT, and 0.56 to 0.66 for summarization).",
    "This paper proposes hallucination detection at the token level, which predicts if each token in the generation output is hallucinated or faithful to the source input. In contrast, previous studies usually work on the sentence level. To create synthetic training data, a denoising pre-trained LM is first used to generate (potentially) unfaithful counterparts T\u2019 of the references T. Then, token-level labels are obtained by comparing T and T\u2019 via edit distance. Finally, a standard classification model is trained on the token-level labels by concatenating the source S, true and unfaithful targets T (T\u2019).",
    "This paper presents a method to detect hallucinated tokens in generations from neural machine translation and summarization. Given a source input S and its output G generated by a sequence generation model, this paper formalizes the task of detecting hallucinated tokens as a labeling problem on the output G. In order to train the labeler, the method synthetically generates supervision data by using a BART model. The BART model receives a text with noises ([MASK] tokens) and tries to predict [MASK] tokens. In this way, the method obtains a pseudo hallucinated text T' from a text T, and assigns hallucination labels by estimating edit operations between T and T'. The labeler is trained by fine-tuning pre-trained cross-lingual (for MT) and mono-lingual (for summarization) language models. In training, the labeler receives a source text S, true target text T, and pseudo hallucinated text T' separated by [SEP] tokens and tries to reproduce the hallucination labels on T'. Receiving a source text S and its output G, the labeler predicts hallucination labels on G during the inference time.",
    "This paper proposes an interesting method that adopts NAS to search multiple class-aware generator architectures for cGAN instead of class-agnostic type. A search space containing both normal and class-modulated convolutions are introduced to simplify the process of re-training. Besides, this paper design a mixed-architecture optimization to specifically address the computational burden issue under the setting of a multi-net search. The search results also give some insights about constructing cGAN models.",
    "This paper proposes a framework NAS-caGAN that adopts RL-based NAS to search the optimal class-aware generator architecture by directly optimizing the Inception Score (IS) using the  REINFORCE algorithm, and leverages the mixed-architecture optimization to mitigate the training data sparsity of each category. The authors design a Class-Modulated Convolution to allow for the weight-sharing among different searched architectures. The proposed NAS-caGAN outperforms the model that employs searched class-agnostic architecture on CIFAR 10 and achieves better results compared with cproj (Miyato & Koyama, 2018) on CIFAR 100. ",
    "This paper proposes an interesting idea that adopts NAS to find a distinct architecture for each class based on cGAN framework. Within the framework, the paper also proposes an operator, Class-Modulated convolution (CMconv), to allow the training data to be shared among different architectures, so as to balance the training data across classes. The proposed method leverages a Markov Decision Process (MDP) in the search algorithm, and learns the sampling policy for NAS. Comprehensive experiments demonstrate the class-aware NAS can outperform class-agnostic NAS.",
    "The present paper introduces a new approach, deep orthogonal networks for unconfounded treatments (DONUT), that allows to estimate (average) treatment effects exploiting an orthogonality property implied by the classical unconfoundedness assumption. The authors propose a regularization framework based on the orthogonality constraint and prove that a resulting estimator is doubly robust, asymptotically normal and with efficient variance. They supply multiple simulations to demonstrate their theoretical claims and to show state-of-the-art performance of their estimator.",
    "The authors propose a regularized framework for estimating the average treatment effect. They assume unconfoudedness and show that it implies a specific orthogonality constraint. The main idea is to use this orthogonality constraint during estimation of the model parameters as a regularizer. On the theoretical side, the authors provide sufficient conditions under which the regularization yields an asymptotically normal estimator for the average causal effect. Based on the regularization framework, an estimator for average causal effect via feedforward neural nets is developed.",
    "This paper proposes a novel regularization term for designing loss functions to estimate outcome and propensity score models, where the end goal is to estimate ATE.  The regularizer is derived from the assumption of conditional independence of potential outcomes and treatment given covariates (i.e. the no hidden confounding assumption).  The authors observe that this assumption implies that residuals of potential outcomes and treatments are orthogonal.  The authors derive a loss function which yields this orthogonality at the optimum.",
    "This paper studies the effect of training BN parameters on training deep neural networks. The conclusion is striking: learning only BN parameters is enough when increasing the depth of the network. Authors have done extensive experiments to understand the effect of increasing the depth and width of the network. To stress the important role of BN parameters, the same number of parameters are chosen randomly and trained. Yet, it is observed BN parameters can obtain far better accuracy. Furthermore, an interesting observation is conducted on the distribution of BN parameters: when training only these parameters, a sparsity pattern is observed on the optimal parameters. While learning all parameters does not reach such a sparse pattern for BN parameters. The sparsity pattern indicates that an efficient network only needs to have a particular ground-truth connection between different units and the choice of weights is not important. This shows that random features imposed by neurons can create a very interesting function class when they are connected in a proper way. ",
    "The authors explore the representational power of BatchNorm's affine parameters (scale $\\gamma$ and bias $\\beta$). For that, they freeze the randomly-initialized parameters of different versions of ResNet and VGG, and only train the affine transformations. They also compare the expressiveness of BatchNorm coefficients with respect to the same amount of neural net parameters.  The main conclusions of this work are that BatchNorm coefficients have a greater discriminative power than the rest of network parameters. Moreover, in random networks, $\\gamma$ seems to disable non-useful features, disabling more than 25% of the channels, and in non-random networks it may prevent overshooting. They also show how these coefficients interact with networks of different depth and width, concluding that deeper random networks achieve better performance than wider random networks with the same amount of BatchNorm parameters.",
    "This paper studies the expressive power of batchnorm parameters by training only these parameters while fixing other randomly initialized parameters. With experiments on different datasets and models, the authors show that batchnorm parameters are consistently more expressive than other parameters. The authors also try to explain such phenomenon by examining the values of parameters and activations, showing that training BN only can lead to sparse values. ",
    "This paper proposes a method to adapt a pre-trained model to a target domain, without the need to access samples from the source domain - on which the model was originally trained. The idea is to adapt layer normalization parameters at test time, by learning affine transformations. This is applied in tandem with the re-collection of the domain statistics.",
    "This paper tackles an interesting problem setting \u2014 fully test-time adaptation with only target data. The proposed method is to minimize the test-time entropy, and the loss is used to update the feature modulation layer only. The proposed method compares favorably with the state of the arts, on the ImageNet-C benchmark and unsupervised domain adaptation tasks.",
    "Presents Test-time Entropy (TENT) minimization, an algorithm for adapting deep models at test time to distributionally shifted data, without requiring access to source training data. At test time, the algorithm updates batch-norm parameters (that control channel-wise normalization and transformation) to minimize predictive entropy over target data. This simple approach is found to lead to state of the art performance on various corruption benchmarks for image classification, and competitive performance on simple DIGITS recognition-based domain adaptation shifts. ",
    "This paper presents an approach to uncertainty modeling in recurrent neural networks through a discrete hidden state. The training of this discrete model is done using a reparameterizable approximation (in particular, using the Gumbel-Softmax trick). The authors show the utility of this method on a variety of problems, including showing effective out of distribution detection and improved calibration in classification tasks.",
    "This work proposes a novel method to estimate uncertainties in recurrent neural networks. The proposed model explicitly computes a probability distribution over a set of discrete hidden states given the current hidden state in an RNN. Leveraging the Gumbel softmax trick, the proposed method performs MC gradient estimation. A temperature parameter is also learned to control the concentration of state transition distribution. To estimate uncertainty of a given input, the proposed model is run multiple times to draw samples for estimating the mean and variance. Experiments are conducted in a variety of sequential prediction problems, including a reinforcement learning task, demonstrating the effectiveness of the proposed uncertainty estimation method.",
    "This paper proposes a method to quantify the uncertainty for RNN. Different from  the traditional Bayesian RNN, the proposed method is more efficient. At each  time, based on the current hidden state and memory, it generates a probability  distribution over the state transition paths on the transition probability by  using the Gumbel softmax function. The next state is computed based on the weighted average of the sampled states and its uncertainty can be  qualified by the sample variance. The hyper-parameter tau of the Gumbel function  is learnt from data to better capture the inherent uncertainty in the data.",
    "The paper focuses on the topic of differentially private deep learning. Specifically, based on the deep residual learning, they first see it as an ODE. Then, to reduce the reversibility of the ODE, they modify the model as an SDE. By discretizing the SDE, they get a perturbed version of residual learning and use this to design DP-algorithms. The first strategy is directly followed the SDE while the second strategy is with an addition multiplicative noise of the additive noise. Finally, they show that their methods to defend membership inference attack both theoretically and practically. ",
    "The paper presents a method for training ResNets with differential privacy. Rather than the usual methods based on noisy gradient descent, the authors propose adding noise at each layer of the network during both training and testing. The authors prove differential privacy guarantees for two strategies of this type (one with additive and one with multiplicative noise). They also show some evidence that the noise can help generalization, by showing that the Rademacher complexity of a continuous linearized version of the model is lower when noise is added.",
    "This paper studies an important problem and proposes the novel residual perturbation to protect privacy while maintaining the ResNet models\u2019 utility.  Two SDE models are provided to inject noises with abundant theoretical proof are provided. Experimental results demonstrate the performance of privacy protection and classification accuracy on benchmark datasets. My major concern is about the utility enhancement and the DP guarantee (see cons below). Hope the authors can address my concern in the rebuttal period.",
    "The paper proposed the Length-Adaptive Transformer. The model can be trained once and directly applied to different inference scenarios. To achieve this goal, the author proposed the LengthDrop method, which randomly samples the length at each layer. In addition, the author used the sandwich rule to train the model. At each step, the sandwich rule will train the largest model, the smallest model, and another bunch of randomly sampled models. In the inference phase, the paper proposed to search for the best length configuration that balances the accuracy and latency tradeoff via evolutionary search. Moreover, to generalize the model to token annotation tasks, the author proposed the Drop-and-Restore process, in which the tokens that have been dropped are used again in the final layer. Experiments show that Length-Adaptive Transformer is able to outperfom the baseline models when evaluated at the same latency level.",
    "This work introduces a method, called LengthDrop, to train a Length-Adaptive Transformer that supports adaptive model architecture based on different latency constraints. In order to make the model robust to variable input lengths, the method stochastically reduces the length of a sequence at each layer during training. Once the model is trained, the method uses an evolutionary search to find subnetworks that maximize model accuracy under a latency budget. ",
    "The work targets an interesting direction of improving the efficiency of Transformers by reducing the sequence length. The main contributions of the work are (1) proposing LengthDrop as the way to achieve length reduction; (2) utilizing techniques developed in NAS, namely one-shot NAS, to enable proper training and allow adaptive drop ratio search after training. All these ideas are very reasonable and interesting. Empirically, the authors show that the proposed method is able to match or even outperform BERT-base model with 1/3 - 1/2 FLOPs during inference (not training).",
    "of the paper: The main objective of the paper is to improve the expressiveness of the GNN by exploring powerful aggregators. The requirements to build more powerful aggregators are analysed. It is closely related to finding strategy for preserving the rank of hidden features, and implies that basic aggregators correspond to a special case of low-rank transformations.",
    "The authors propose two new layers for GNNs. CombConv and ExpandingConv are motivated by the insight that a GNN is only as expressive as the rank of the matrix that represents the coefficients of the aggregation function. To arrive at this statement, the authors formalize all GNNs as being composed of three steps: 1) generation of aggregation coefficients, 2) actual aggregation of the neighbourhood, and 3) feature extraction from the aggregation. Furthermore, it is shown that current approaches have very low distinguishing strength and that CombConv and ExpandingConv, by their construction, yield higher expressive power. ",
    "\tThis paper explores the representation power of graph neural networks. Unlike recent work on choosing among simple aggregation functions or combinations thereof, the authors here recognize that these aggregators are the bottleneck in the representation power and generalize simple aggregator functions commonly used in literature to an aggregation coefficient matrix. The paper supports this construction theoretically and also proposes two aggregators that satisfy the rank-preservation requirement for more expressive (distinguishing) GNNs.",
    "The paper presents a disentanglement metric to measure the intrinsic properties of a generative model with respect to the factor of variation in the dataset. Toward this, the paper first assumes disentangled factors reside in different manifolds. These different manifolds are the sub-manifolds of some manifold M for a given disentangled generative model. The paper considers the fact that in an entangled model the sub-manifolds are not homeomorphic and thus similarity across submanifolds can be measured to evaluate a model\u2019s disentanglement. As such, disentanglement is related to the topological similarity.  For measuring topological similarity, the paper then introduces Wasserstein Relative Living Times. The proposed metric is used to evaluate standard disentanglement methods and datasets demonstrating the importance. ",
    "Introduces unsupervised disentangling metric that measures homeomorphic similarity between submanifolds conditioned on a given factor, and homeomorphic dissimilarity on submanifolds conditioned on different factors. The paper also includes a supervised variant which can directly assess topological similarity of submanifolds with label-spaces. The paper also introduces a novel variation of RLTs that  employs wasserstein distance instead of euclidean distance. ",
    "The paper proposes a novel metric for evaluating disentanglement by taking a manifold-topological perspective on the representations learnt. The key insight is that for a disentangled representation, when we fix a certain factor of variation at different values the topology of the conditional sub-manifolds should be similar. Using this insight the paper proposes a metric for disentangling which does not require annotations of the factors of variation and is more general than previous such tests.",
    "The paper's motivation is based on protecting private data and preventing its being scraped and used to train models. Even though motivation is clear and very important, the problem is the same as the works in crafting adversarial samples (i.e., the ones under data poisoning and adversarial attacks parts of the related work). The key difference is to apply Projected Gradient Descent (Mandry et al. 2018) in the reverse direction iteratively to *minimize* the loss function.  Furthermore, the performance evaluation will be the margin between models trained on completely clean data and sample-wise/class-wise adversarially corrupted data (in contrast to fooling a pretrained network in adversarial attack benchmarks). ",
    "The authors proposed the idea of using invisible noise to make personal data unusable to authorized deep learning models. To achieve this goal, the authors proposed the idea of error-minimizing noise crafted by a min-min optimization method. The error-minimizing noise is then added to training examples to make them unlearnable to deep learning models. The idea is very well motivated and explained. The experiments not only confirm the exceptional effectiveness of the proposed method but also show its flexibility.",
    "The authors studied the problem of data protection from a new perspective. They proposed one kind of error-minimizing noise to make the data (added noise) unlearnable. The noise is imperceptible to human eyes, and thus does not affect normal data utility. The idea is very interesting and inspiring. The authors conducted a series of solid experiments to validate the effectiveness of the proposed noise, and tested it on a real world task of face recognition. ",
    "The paper extends MuZero for nondeterministic domains (NDMZ). Compared to MuZero NDMZ also learns a function that determines who is to act (player 1,2 or chance) and a distribution of chance outcomes. This makes it possible to employ MCTS search adjusted to handle nondeterministic nodes on top of a tree constructed by NDMZ's neural nets.",
    "This paper proposes NDMZ, which extends the previous MuZero algorithm to stochastic two-layer zero-sum games of perfect information. NDMZ formalize chance as a player (chance player) and introduces two additional quantities: the player identity policy and the chance player policy. NDMZ also introduce new node classes to MCTS, which allows it to accommodate chance.",
    "This paper introduces NDMZ, short for nondeterministic MuZero, a deep reinforcement learning algorithm for model-based RL that doesn't use the rules of the game to perform search. The paper's contribution is mostly focused on describing how to construct the algorithm, and experimental results are provided at the end. A good analogy is that of a player that must play a (physical) board game by not only making decisions, but also acting out the game: producing random events, such as die rolls, and moving pieces on the board. ",
    "This paper introduces a novel option-learning policy gradient method, HO2. The method learns a parameterized joint distribution over options and actions and uses a soft-continuation based approach to interrupt or \"switch\" between options before option termination. The method introduces a new meta-parameter which enforces a hard limit on the number of \"switches\" that can occur, significantly reducing the variance of the option-learning method and replacing softer loss penalization based approaches. The paper demonstrates the performance of the proposed algorithm on a handful of 3D virtualized environments as well as on robotic simulation tasks.",
    "The paper considers the Hierarchical Reinforcement Learning setting, Options in particular, and proposes an algorithm that allows to learn both the high-level and low-level (option) policies at once, from off-policy samples. An original aspect of the algorithm is that it is easy to constrain the learned policies on how often they terminate an option and start a new one. This prevents the agent from learning tiny options that immediately terminate. It is unclear whether it can also be used to prevent the agent from learning a single big option that does everything.",
    "This paper studies an important area in RL, hierarchical RL, which improves data efficiency by incorporating abstractions. In this paper, the authors proposes an efficient option learning algorithm, which utilizes a TD(0) type objective and constrains the learned policy being not too far away from the past policy. In terms of different abstractions, the paper studies action abstraction through a mixture policy, and temporal abstraction through explicitly limiting the maximum number of switches between options. ",
    "This paper proposes a modified bellman equation for reinforcement learning that optimizes the maximum expected single step reward along a trajectory, instead of the maximum cumulative reward. This formulation is applied to the generation of molecules with optimized properties of interest. A recently published molecule generation algorithm, that constructs molecules step wise via the (predicted) chemical reactions of building blocks, is modified with this new bellman formulation, and shows modest improvements in optimizing for some HIV activity targets.",
    "Motivated by the de novo drug design, this submission proposed a new objective in reinforcement learning, i.e., to maximize the expected maximum rather than the accumulated reward along trajectories. The authors defined the corresponding Bellman operator, and then proved its theoretical properties, including monotonicity and contraction. In the experiments, the authors first showed on a simulated grid that when compared with Q-learning, the proposed Max-Q algorithm can achieve higher maximum rewards along trajectories. Finally, the authors tested on de novo drug design task, by modifying the TD target in the previous PGFS algorithm. The new variant achieved better performance across different metrics.",
    "This paper proposes a max reward instead of cumulative reward objective for reinforcement learning. This objective is primarily motivated by applications like chemical synthesis where the goal is for the RL agent to generate the most desirable state possible. The paper then defines the corresponding varaint of the Bellman operator (the max-Bellman operator) and proves tabular convergence guarantees by a contraction argument. Some experiments in a gridworld and simulated chemical synthesis indicate that this objective modification can improve prior algorithms. ",
    "The paper proposes a few-shot meta-learning method for recommender system that uses a new feature's meta-information and observed samples for the features to predict the network weights for predicting the feature value from other features. The paper focuses on the cold-start problem where few samples with a new feature observed is available. The method outperforms a wide range of baselines on MovieLens-1M, a medical synthetic dataset, and a e-learning dataset.",
    "The paper proposes Contextual HyperNetworks (CHNs) as an auxiliary model to generate parameters from existing data, and observations and other metadata associated with new feature to address cold start problem of new feature. Besides, it doesn\u2019t need either re-train or fine-tune at prediction time. The CHN is applied to P-VAE and some experimental results are provided to demonstrate its effectiveness in some application, i.e., recommender system, e-learning and healthcare tasks.",
    "This submission focuses on the cold start problem of new entities (new items in a recommender system, new treatments in a medical application, etc.). It combines the strengths of the *relations* between a new entity and the existing entities, and the *content* features of the new entity, by fusing the two kinds of information into a neural network that outputs the estimated representation of the new entity. The proposed method outperforms several intuitive na\u00efve strategies as well as MAML.",
    "The authors present a new method for Bayesian deep learning motivated by the difficulty of posterior inference in the \"overparameterized\" regime of deep neural network models. The proposed method provides a principled strategy for selecting a subset of the neural network's parameters (forming a so-called \"subnetwork\") for which a full-covariance approximate posterior can be computed. The authors use the well-studied Laplace approximation with the generalized Gauss-Newton Hessian approximation for the covariance. An empirical analysis is presented which attempts to assess the efficacy of the proposed method in prediction accuracy and uncertainty quantification.",
    "The paper proposes to approximate the posterior distribution of a Bayesian neural network by an approximation that consists of a deterministic component. The authors select a sub network and infer approximate posterior distributions over the weights in the sub network. All other weights are estimated via MAP point estimation.  A sufficiently small sub-network allows high fidelity posterior approximations that do not make restrictive mean field assumptions to be tractable.",
    "The authors focus on the important problem of scalable approximate inference in Bayesian NNs. More specifically, they propose a method for scalable BNNs via a (full-covariance Gaussian) Laplace approximation on a (Wasserstein-based) pruned subnetwork within a deterministically-trained model. They include a theoretical analysis for a simple generalized linear model, and experiments on 1D regression, tabular regression, and larger-scale image classification with CIFAR-10 (using the dataset shift setup from Ovadia et al., (2019)). From the experiments, they show that their method generally outperforms comparable methods (including deep ensembles) on metric performance and on the ability to capture in-between uncertainty.",
    "The paper proposes a framework of jointly learning a state and action embedding using the model of the environment, eventually using those embeddings to learn a parameterized control policy using standard policy gradient (PG) methods. Joint learning of state and action embeddings allows us to capture the interactions between actions in different states. The framework proposes to learn an internal (embedding) policy, a state embedding, an inverse function on action embeddings, combining all the parts to form an overall policy. The paper theoretically shows that optimizing the internal policy leads to an optimal overall policy. ",
    "The paper proposes a method to jointly learn: (a) a latent state embedding; (b) a latent action embedding; (c) a state transition model; and (d) an RL policy.  The latent models should allow for better generalization over states and actions, and therefore result in improved learning, particularly for discrete action domains. The method shows improved performance over vanilla policy gradient on a grid-world task, a slot machine task, a recommender system, and half-cheetah locomotion.",
    "Learning on environments with large state-action spaces can be difficult. This paper addresses this issue by learning a joint state-action embedding and learn an internal policy(\\pi_i) on this embedded state-action space instead of the original state-action space. There are three parts of learning, 1. learning the embedding model that learns mapping from state to state embedding, 2. learning the internal policy, and 3. learning the mapping from action embedding to action space. The authors justify this approach by showing that the overall policy (\\pi_o) can be expressed in terms of the internal policy (\\pi_i). Furthermore, there is equivalence between the internal state-action-value function and overall state-action-value function and the authors show that updating \\pi_i is equivalent to updating \\pi_o. ",
    "Learning representations using self-supervision requires domain expertise to identify diverse transformations of the data samples that label preserving. This can be expensive and hard to obtain in many data modalities. The paper proposes to automate this by learning to generate transformations tailed to each modality and sample. Specifically, an adversarial strategy is applied to learning transformations that are close to the original view in the input space but hard to classify for the self-supervision encoder.",
    "The paper presents a generative model to automatically generate data that is needed for contrastive learning, with a focus on the SimCLR framework, while the method itself is general. Experiments were conducted across multiple modalities, including image, speech and wearable sensor data. The results demonstrate the effectiveness of the proposed model as compared to data augmentation methods relying on human domain knowledge. ",
    "The paper proposes a method for automatic generation of data views for contrastive self-supervised learning of representations. The method consists of learning an adversarial perturbation model that aims to maximize the distance between the original image and its perturbed views in the space of learned representations. To avoid collapse to a completely information-destroying perturbation model, authors propose to limit the perturbation strength in terms of the $l_p$ norm of the added noise. Authors apply their method on various image, speech and wearable sensor datasets where the proposed approach provides an improvement over other methods.",
    "This paper introduces a taxonomy of OODs and proposed an integrated approach to detect different types of OODs. Their taxonomy classifies OOD on the nature of their uncertainty and they show that no single state-of-the-art approach detects all these OOD types. Motivated by this observation, they combine multiple existing OOD detection methods to detect various types of OODs. ",
    "This paper introduces a novel taxonomy for OOD outliers. The authors analyze current OOD detection approaches and uncover their limitations. They propose to fuse several existing approaches into a combined one and extensively evaluate it on various data sets (CIFAR,10, SVNH, MNIST, STL10, ImageNet, etc.). The proposed integrated OOD detection approach clearly shows superior performance.",
    "The authors explore the different kinds of outliers and show that the methods previously proposed detect different kinds of OOD and not a single one can detect them all. The authors propose an interesting study of the different kind of outlier on synthetic data which  illustrates well the different characteristics of the outlier types. The authors then propose to combine different methods to increase the OOD detection rate. Experiments are conducted on 3 images classification datasets using different deep neural networks. For each dataset, samples from other databases are introduced as outliers and must be detected. The combination method yield better detection rates than baseline methods in almost all configurations. ",
    "The paper claims that high quality of generated samples and SOTA bpds are achievable by VAEs if the model is deep enough (deep in terms of the number of stochastic layers). The authors explain the architecture that resemblances the U-net architecture, and explain its building blocks. Interestingly, they are able to learn VAEs with up to 78 stochastic layers, and achieve SOTA bpds on CIFAR-10, ImageNet-32, ImageNet-64, FFHQ-256 (5-bit), and setting a great result on FFHQ-1024 (8bit).",
    "the paper puts forward an idea that deep-enough VAE should perform at least as well as autoregressive models. Authors explore this in the context of image generation, and construct VAE model that is a generalisation of typical autoregressive architectures. They use several tricks to ensure stable training of very deep VAEs and show that final performance exceeds all autoregressive models. This experimentally supports their claim that very deep VAEs encompass autoregressive models.",
    "This paper shows that deep hierarchical VAEs can outperform state-of-the-art autoregressive models on images. The authors first argue that autoregressive models are special cases of hierarchical VAEs and that hierarchical VAEs are universal approximators. They introduce a simple top-down (LVAE) architecture that scales past 70 layers. Furthermore, the model can be trained without using freebits or KL annealing -- although additional tricks are required (gradient skipping and prior warmup). They demonstrate that likelihood performance is correlated with depth and report state-of-the-art performances on multiple image datasets.",
    "This paper adopts semi-hard negative mining, a sampling strategy widely used for metric learning, for contrastive self-supervised learning. Specifically, the paper chooses the negative samples in the range of $[w_l, w_u]$ percentiles (close, but not too close) in terms of the normalized feature distance. As the initial representation is not informative, the paper anneals down the percentile range. This sampling strategy improves the contrastive learning methods (IR, CMC, MoCO).",
    "This is an interesting paper that discusses the negative sample mining in visual representation learning. The authors discuss the theory and method to conditionally select the negative samples based on the dot product of representations in noise constructive estimation (NCE). Their theory shows that the NCE with negative examples sampling from a conditional distribution q is lower bounded with mutual information, and the object has higher bias and lower variance. The authors also provide the method to construct the conditional distribution by picking a ring surface where the dot product of representations is bounded within percentiles of data.",
    "Inspired by the effectiveness of hard negative mining in deep metric learning, this papers focuses on the problem of negative mining in unsupervised learning under the contrastive setting. One of the problems in this scenario is that naively selecting difficult negatives may yield an objective that no longer bounds mutual information, which is the basis for many contrastive objectives such as the Noise Contrastive Estimator. To address this problem, this paper formally defines a family of conditional distributions where negatives can be drawn from (negatives are chosen conditional on the current instance), while maintaining a lower bound on the NCE and on mutual information, resulting in a new estimator dubbed Conditional NCE. It also shows that, even though it\u2019s a looser bound than NCE, it also has lower variance, which may lead to better local optima. Finally, within this family of conditional distributions, the paper proposes the Ring model, which takes inspiration from semi-hard negative mining approaches, and that can be applied to state-of-the-art contrastive algorithms in order to sample harder negatives, resulting in better representations.",
    "This work introduces CAFE, a novel training algorithm to leak training data in a federated learning setup. Extending from \"deep leakage from gradient\" fake images are optimised with respect to the difference observed from the client gradients (i.e. with the real images) and the one observed with the current version of the fake image. However, DLG does not work when the mini-batch size increases due to a messy gradient representation. In this work, the authors propose to keep track of the batch index. Indeed, it may happen that the server decides of the batch index corresponding to the training data that will be used by the client during the local training. Within such conditions, a malicious server can easily store fake images corresponding to specific indices and therefore optimise correctly each fake images w.r.t the corresponding real image. ",
    "This paper studies the data leakage issue in the federated learning. More precisely, when the servers have access to model parameters and gradients. It can recover the input data via gradient matching, and the authors claim that their method performs well even with large training batch sizes, e.g. over 40. Finally, the author also studies the possibility of attacking during learning, where they suggest that multiple updates of fake data helps. However, their contribution seems incremental, gradient matching is used in previous literature [zhu et al 2019], and their main modification is extra two regularization terms: total variation and internal representation regularization, and a data index alignment technique (whose exact meaning is unclear in the paper).",
    "The submission considers the problem of reconstructing private data from gradients in a Federated Learning system, which has been recently shown to a threat in distributed learning systems. Two types of federated learning systems are considered. Vertical federated learning (VFL) refers to the case where different agents hold different features of the same data points while  Horizontal federated learning (HFL) refers to the case where different agents how all the features of different subsets of the data.",
    "This paper presents a method for dynamic relational inference for multi-agent trajectory prediction. The method extends the neural relational inference (NRI) (Kipf et al., 2018) by changing the static relations between agents to dynamic relations. This equates to inferring time-varying latent variables $z_t^{ij}$ as opposed to learning time-independent latent variables $z^{ij}$. The paper conducts experiments on physics simulations and basketball trajectories to show the superiority of the proposed method against different variants of NRI.",
    "The authors propose a novel Relational Inference system that learns to predict the graph structure underlying the data as well as the updated state of the system. Relational reasoning has received considerable attention in recent year. Predicting the graph structure underlying a system from data in a dynamic way is an great next step, which could help alleviate some of the scalability issue currently afflicting these methods.",
    "This paper builds on Kipf et al. (2018)\u2019s Neural Relational Inference. In particular, this work introduces a latent variable model which treats the interactions (i.e. relations) between different agents as dynamic and time-varying. As in NRI, the interaction variable between any two agents is conditioned on the history of those agents\u2019 states. An agent\u2019s future state is conditioned on its history of states as well as its interaction variables with other agents.",
    "This work explores a popular problem, i.e., collaborative filtering, in an inductive setting, which is very important for real-world recommender systems. To address the challenges in the inductive settings, i.e., learning accurate representations for users who do not occur in the training data, the authors propose to construct a relational graph between users in the training data and new users based on a standard matrix factorization model and then use an attentive message passing framework to inductively compute user-specific representations. Besides, the authors prove the expressive and generalization capabilities of the proposed framework. Extensive experiments are conducted to demonstrate the effectiveness of the proposed framework both in transductive and inductive settings, as well as the scalability.",
    "This paper proposed an inductive collaborative filtering method, called IRCF. The goal is to possess expressiveness (against feature-driven methods) as well as generalization (against one-hot encoding based methods). In IRCF, there are a matrix factorization model for support users and a relation model for query users. The former is trained with transductive learning to obtain support users embeddings and item embeddings. The relation model then generates query user embeddings as weighted sum of support user embeddings by examining relational graph between support and query users.",
    "This work proposed an inductive recommendation framework on user-item relation graphs. Such a framework relies on the user-item relations without the requirement of side-information and perceives certain flexibility in terms of the parametrization for user/item representations. The authors also provided theoretical analysis to highlight some mathematical insights out of this framework. The proposed method is evaluated on three real-world datasets and compared with several baselines.",
    "Disentangled representation (DR) of data is useful in downstream tasks. However, VAE-based DR fundamentally suffers from a trade-off between high-quality reconstruction images and disentangling. To overcome this point, the paper approaches VAE from the multi-stage modeling (so-called MS-VAE). The proposed method starts from the other standard DR method which learns low-quality image(Y) and then, improves the quality of the image via training additional encoded representation(Z). The widely-used techniques in style transfer (FILM and AdaIN) are used to adopt 'Z' into 'Y' for a high-quality reconstructed image. The authors evaluated the proposed method through FID(high-quality image) and MIG(disentanglement). At the similar scale of complexity, the proposed method obtained high FID score and low MIG score than the baselines.",
    "This article introduces a method for learning high-quality generative model with disentangled latent representation by splitting the learning process into two steps. The first step consists in learning a generative model on the data using a method with strong disentanglement constraints, producing a low-quality generation. As a second step, a conditional generative model is trained to turn this low-quality sample into an high quality one. This intermediate generation acts as an observed variable, and thus separates the latent spaces of the two models, effectively preventing disruptive interference in the learning of the \"independent factors\" on the one hand and the \"dependent factors\" on the other, as has been previously observed as a difficulty in the literature. The authors provide detailed empirical analysis of the performance of the model.",
    "The paper studies the problem of learning disentangled representations while maintaining good data reconstruction. As common modeling, the latent representation is decomposed into disentangled representation C and correlated representation Z. Then a hierachical generative process is proposed, where the first stage is to reconstruct a preliminary version of the data given the disentangled representation C, and the second step is to reconstruct a full version of the data given C and correlated representation Z. The two stages are learned separately, with the first stage using the previous \u03b2-TCVAE model to learn C, and the second stage using the Feature-wise Linear Modulation (FiLM) technique.",
    "The paper discusses three mutual information (MI) objectives for representation learning in RL, referred to as forward, state, and inverse. The forward MI objective models latent dependencies given the action. The state MI objective models latent dependencies alone. And the inverse MI objective models dependencies between actions and future states (empowerment). The paper shows that of these three common objectives, only the forward objective is sufficient for learning the optimal policy / value function. This is demonstrated using simple examples and experiments on a simple game environment.",
    "of the work: This work studies which mutual-information representation learning objectives (1. forward information, 2. state-only transition information, 3. inverse information) are sufficient for control in terms of representing the optimal policy, in the context of reinforcement learning (RL). As a result, they find a representation that maximizes 1 is sufficient for optimal control under any reward function, but 2 and 3 fails to provide that guarantee in some MDP cases. They provide both proof and interesting counter examples to justify the findings. Besides, they conduct some empirical studies on a video game (i.e. Catcher) and show that the sufficiency of a representation can have a substantial impact on the performance of an RL agent that uses that representation. ",
    "This paper studies which commonly-used mutual information objectives for learning state representations are sufficient for reinforcement learning. In particular, they provide counterexamples to show that state-only and inverse MI objectives are not Q*-sufficient, while proving that forward MI is Q*-sufficient. They validate their findings empirically with experiments in a simple RL domain.",
    "This paper showed that a two-layer vector-output ReLU neural network training problem is equivalent to a finite-dimensional convex copositive program. Based on this connection, the authors gave the first algorithm that finds the global min of the network training problem, which has running time polynomial in the number of samples but exponential in the data matrix. For CNN, the running time is only exponential in the filter size, which is usually a constant. The authors also described circumstances in which the global min can be efficiently found by soft-thresholded SVD; provided a copositive relaxation that is exact for certain cases. The effectiveness of the proposed algorithms is verified in experiments.",
    "The draft is a vector extension of [1] on studying how to approximately solve the global optima of a two-layered Relu network. The key of the analysis is to enumerate all possible sign patterns of the ReLU unit generating from specific data. Once we have the enumeration, we can also enumerate the linear area separated by ReLU, and the whole optimization problem will become a non-convex quadratic optimization problem. The non-convex quadratic can be approximately solved with its convex dual (or exactly under some conditions), or we can relax it to a copositive program (which might still be NP-hard to solve). With some assumption on the data, the sign pattern of the ReLU is a singleton, then we will have efficient algorithms to exactly recover the global optima of the two-layered network.",
    "The paper proposes a convex formulation for shallow neural networks with one hidden layer and vectorial outputs. This is an extension on a line of previous works (Ergen & Pilanci, 2020a) and (Ergen & Pilanci, 2020b) where similar results have been established for the case of scalar outputs. A Frank-Wolfe algorithm for finding the global optimum of the resulting convex program is proposed and evaluated on smaller datasets. ",
    "This paper proposes to combine the neuro-symbolic concept learner for visual reasoning from language (NS-CL; Mao et al., 2019) with recent unsupervised approaches to learning object-centric representations such as MONet (Burgess et al., 2019) and Slot-Attention (Locatello et al., 2020). While NS-CL normally relies on pre-trained object-detectors (in a supervised fashion) to extract visual representations, the proposed combination (dubbed LORL) use MONet or Slot Attention for this. By additionally back-propagating error signals from language-driven visual reasoning tasks obtained via NS-CL into MONet/Slot-Attention, it is shown how LORL is better able at learning object-centric representations and perform instance segmentation. ",
    "The paper proposes a framework for object-centric representation learning with additional language supervision such as e.g. questions and answers, denoted as Language-mediated, Object-centric Representation Learning (LORL). The authors combine two ideas from prior work, the unsupervised object-centric representation learning and the neural-symbolic concept learning, in one architecture. The model obtains object representations by learning to reconstruct the input image (as in MONet and Slot Attention). The learned representations are used as input to the neural-symbolic program executor, which learns to answer questions about objects. The entire model is trained in three stages: first the reconstruction objective, then the QA objective, and, finally, jointly. Experiments on two datasets demonstrate that the obtained object segmentations have better quality that those of the original unsupervised models. The learned representations are also shown to be effective in several other down-stream tasks.",
    "This paper proposed an interesting idea that uses language to learn the concept and aid downstream tasks such as segmentation and referential expression interpretation. The authors combine the unsupervised segmentation method (MONet and Slot Attention) with neural symbolic concept learning (NS-CL). By joint training these two objectives, the authors show improvements in the object segmentation and several downstream tasks. ",
    "The work utilizes relational background knowledge contained in logical rules to conduct multi-relational reasoning for knowledge graph (KG) completion. This is different from the superficial vector triangle linkage used in embedding models. It solves the KG completion task through rule-based reasoning rather than using rules to obtain better embeddings. Experiments on FB15K, WN18, and a new dataset FB15K-R demonstrate the effectiveness of the proposed model EM-RBR. ",
    "The paper seek to improve KG representation (e.g. for link prediction and question answering) by combining logical reasoning (logical rule templates) with statistical methods (TransE). Rules are mined from the KG using AMIE and recursive backward steps are taken, using the mined rules, to determine if a fact is true.",
    "The paper proposes a framework (EM-RBR) for doing Knowledge Base (KB) completion. Instead of the direct triple score from an embedding based method, EM-RBR allows the triple score to be calculated as a composition of the scores of the rules mined from the KB. EM-RBR uses a BFS type algorithm that recursively searches for reasoning paths connecting the triple while also updating the score.  The authors show that EM-RBR when used as an addendum to a translation-based embedding method (such as TrasnE, TransH) is able to outperform them. They show their results on FB15k and WN18. ",
    "This paper proposes a new type of recurrent neural network architecture called schema / object-file factorization (SCOFF). This model contains multiple weight-sharing GRU cells. The input information is fed into each GRU cells through an attention layer. The output information is fetched from these GRU cells and mixed with another attention layer. The model is tested on several intuitive physics benchmarks and basic reinforcement learning environment. This model demonstrates superior performance than other modular RNN architectures such as RIM on specific tasks.",
    "The authors propose SCOFF, a novel architectural motif, one with memory, which, as they describe, can serve as a drop-in for an LSTM or GRU within any architecture. It is inspired by the notion that when modeling a structured, dynamic environment (such as one with objects moving around), one must keep track of both declarative knowledge and procedural knowledge. They propose that these two types of knowledge be factored, creating an architecture consisting of \"object files\" (OF) whose evolution is governed by input, all objects, and  \"schemata\" which can be selectively applied to each OF.",
    "The motivation and the proposal for splitting the schema from the procedural (representational) block makes sense. This is a good idea. A the authors build on top of RIMs, which have shown reasonable ways to model dynamical systems. However the paper itself needs to be improved and we need to evaluate the model more before publication. ",
    "This paper introduces the Visio-Linguistic Neural Module Network (VilNMN) consisting of a pipeline of dialogue and video understanding neural modules. Motivated by Hu et al. (2017), Kottur et al (2017), this paper extends the NMNs on video tasks for interpretable neural models. The model explicitly resolves entity references (dialog understanding) and detects actions from videos (video understanding) for response generation. Experiments show that NMNs achieve competitive results on AVSD (video-dialog) and TGIF-QA (video-QA) benchmarks. ",
    "This paper studies the language grounding aspect of video-language problems. It proposes a Neural Module Network (NMN) for explicit reasoning of visually-grounded object/action entities and their relationships. The proposed method is demonstrated to be somewhat effective in the audio-visual dialogue task and has been shown superior to existing works on video QA. Overall, the paper is motivated clearly and is delivered with good clarity. The followings need to be clarified.",
    "The paper studies the application of neural module network to video-grounded language tasks. They propose a method dubbed Visio-Linguistic Neural Module Network (VilNMN) to retrieve spatio-temporal information in a video through a linguistic-based parsed program. In particular, VilNMN first extracts entity references and their corresponding actions in linguistic cues. This information is then being used to locate relevant information in the visual cue to arrive at the correct answer. The proposed method is evaluated on two large scales benchmarks AVSD and TGIF-QA, demonstrating competitive performance with state-of-the-art methods.",
    "The paper suggests two techniques to improve the calculation of empirically figuring out a Nash equilibrium using an iterative application of best-response dynamics. One method learns the best-response to the previously used strategy. The other uses that technique to model the opponent, and then best-responds to the modeled opponent. The experiments show a faster reaching to NE than without these changes.",
    "The paper proposes two new methods in the Policy-Space Response Oracle framework. These approaches permit to reuse past knowledge in order to reduce the amount of data required for the RL training. The first algorithm Mixed-Oracles transfers the previous iteration of Deep RL, instead of the second one, Mixed-Opponents, transfers existing strategy action-value estimates.",
    "The paper focuses on resolving the computational and sample efficiency challenges with current PSRO style approaches. To this end it proposes two different modifications to the standard PSRO setup: 1) Mixed Oracles, and 2) Mixed Opponents. These approaches allow avoiding resetting learning after each outer loop epoch and reduce the stochasticity of dynamics during training. Thee efficacy is demonstrated on relatively simple games but using Deep RL policies where the proposed approaches are at least on par with standard PSRO approach in terms of final performance while drastically improving the sample efficiency.",
    "In this paper the authors tackle the problem of alignment between input tokens and output acoustic features. The key contribution of this paper is replacing the attention mechanism of the Tacotron 2 with an explicit representation of token durations. The attention mechanism is vulnerable to issues such as pauses, repetitions, and skips, and hence using durations directly takes care of such issues. The challenge lies in obtaining the durations. The authors propose different methods toward that end. ",
    "In this paper, the authors introduce a text-to-speech model based on Tacotron 2, called Non-Attentive Tacotron. Instead of an attention mechanism, a duration predictor is utilized to improve robustness, which is evaluated by two metrics, unaligned duration ratio (UDR) and word deletion rate(WDR). The authors propose semi-supervised and unsupervised duration modeling with a fine-grained variational auto-encoder (FVAE).",
    "This paper presents an approach based on the Tacotron model for speech synthesis, where the attention mechanism is replaced by a duration predictor. It also presents a short study on semi-supervised and unsupervised training. The paper also introduces two metrics to evaluate the robustness of the model. The experiments shows that the proposed model is on par with the Tacotron baselines in terms on MOS score and better in terms of the new metrics.",
    "This paper presents SBEVNet, a neural network architecture to estimate the bird's-eye view (BEV) layout of an urban driving scene. Given an image captured by a stereo camera, SBEVNet performs an inverse perspective mapping (IPM) to obtain an initial feature volume, which is further processed to generate the BEV layout. The system is trained end-to-end in a supervised learning setup.",
    "The paper proposes an end-to-end network for layout estimation from stereo images. The approach is built off previous stereo matching networks, which built and process a 3D disparity volume. The stereo estimate is used to project image features into a birds-eye-view representation which is processed using a U-net which predicts a semantic scene layout. The approach is evaluated on the KITTI and Carla generated datasets.",
    "The paper proposed to estimate the semantic layout in the bird eye's view from a pair of stereo images. The main novelty/contribution lies in how to organize and exploit the information from the stereo images. The proposed framework builds upon inverse perspective mapping, and projected stereo feature volume. The performance was evaluated on the KITTI and CARLA datasets. Given a pair of stereo images, there are various options to exploit the image information, where this paper provides a framework by exploiting the stereo information in the bird eye's view. ",
    "    The authors propose a new gating based recurrent graph attention networks for multi-relational graphs to capture long-range neighbor dependencies. The authors provide an interesting analysis of current gated GNN models (in the appendix + Figure 3) in light of their ability to capture long-range dependencies in graphs. Experimental results are reported for node classification with two synthetic datasets and two real-world datasets.  ",
    "This paper proposes a new GNN model (GR-GAT) for multi-relational graphs. The proposed method has better ability of capturing the long-range information. Essentially, the proposed GR-GAT is modified from GAT so that it can apply to the multi-relational graphs. Since the modifications are common and frequently used techniques, the novelty of this work is not enough. Also, why these modifications can help to capture long-range information is not well explained in this paper. Overall, this work is ok but not good enough for ICLR.",
    "This paper presents a graph attention architecture that captures long-range interactions. The novelties in the architectures are (1) vector-based parameterization of edge type in modeling message, (2) slight modification of graph attention (Section 3.2), and (3) GRU-based node update function. The experiments are primarily on synthetic tasks. However, it is unclear if modeling such long-range interaction is useful in real tasks. The paper fails to demonstrate convincing results on the real tasks of entity classification in knowledge graphs.",
    "This paper provides an interesting pos-hoc explanation method to identify relevant features in an input that may inform a trained neural model's prediction. The task is to identify a binary mask over input image/text such that the masked input yields almost similar prediction as original input. The author formulates this as an SMT solver task, but instead of making sure that the output prediction is similar (which involve multiple time consuming pass over potentially huge networks), they make sure that high influential neurons in first layer of the network are still activated. This provides a less time consuming way to evaluate invariance of masked input.",
    "This paper addresses the question of identifying which input features are most important for a neural network's decision. To do so, it frames the problem as an SMT problem that seeks to select the best input features, without changing the state of the first layer too much. The paper shows experiments, primarily on image classification, and also examples of how the approach may be applied to text classification.",
    "This paper presents a method to encode the minimal input feature discovery problem -- finding the minimal set of features in a input that is necessary for a prediction -- into a form that can is amenable to satisfiability modulo theory (SMT) solvers.  In particular they first use the integrated gradients methods to score first-layer neurons on the degree to which they influence the prediction.  Then, they produce and solve an SMT problem that finds the minimal mask that changes these influential neurons.  They demonstrate their approach on several problems.",
    "This paper tackles the task of pose prediction and takes a render-and-compare approach. However, instead of rendering pixel colors, the key insight is to render features -- each mesh vertex is associated with 3D (learned) features which are encouraged to match computed 2D image features. This 'neural mesh' representation allows pose inference via SGD as one can optimize for pose s.t. the rendered features best match the image features, and is also robust to foreground occlusion. The paper demonstrates results on ObjectNet3d and PASCAL3D+ where the proposed approach is shown to be more robust to occlusion and also better at precise pose estimation.",
    "The paper presents a novel approach for 3d pose estimation by combining render-and-compare (analysis-by-synthesis) and contrastive feature learning. The key idea is to render and compare learned latent features instead of synthesized RGB colors to optimize 6D pose parameters. The proposed method learns latent feature vectors on a template mesh as well as target images via backbone neural networks such that matched regions have similar features while latent features are as distinctive as possible. The paper evaluates the novel formulation on  PASCAL3D+, the occluded PASCAL3D+, and ObjectNet3D dataset, demonstrating the render-and compare optimization with the proposed approach is more robust to appearance change and partial occlusions.",
    "The authors propose a novel 3D neural mesh model of objects that is generative. They demonstrate that standard deep learning approaches to 3D pose estimation are highly sensitive to partial occlusion. Since their method works in a render and compare manner, it enables the method to be more robust to artifacts in general and partial occlusion in particular. They also achieve a highly competitive 3D pose estimation performance on popular dataset. They go on to show that even very crude prototypical approximation of the object geometry using a cuboid. ",
    "This paper addresses an interesting problem in retrieval system - compatible features learning. Given the old feature extractor and a new dataset, the objective is to learn a new feature extractor, so that the features extracted by two (old and new) feature extractors are comparable to each other. In the proposed setting, the old dataset (including its statistics), old classifier, and the parameters of the old model are not available.",
    "This paper deals with an interesting problem of feature compatible learning that the features produced by new model should be compatible with old features. The proposed method uses nearest class\u2013mean classifier instead of linear classifier. Random walk is applied to refine the class means. The proposed method is compared with several baseline methods and shows good performance.",
    "This work proposes a new problem setting by adding extra constraints to the Feature Compatible Learning problem. The new constraints avoid using old training data and the old model\u2019s parameter when learning a new model. The paper gives a baseline method and its variants for the problem by generating pseudo classifiers to regularize a new model\u2019s learning. The experiments show that the proposed method can satisfy the empirical criterion about success.",
    "This paper studies the gradient norm as a measure of generalization in deep learning. The authors first an approximation to the gradient norm (GN) that is the norm of the gradients for only fully connected layers (AGN). Then they empirically evaluate the correlation between AGN and GN as well as GN and the generalization error. In Section 2.1, the authors conclude that AGN is highly correlated with GN and both are correlated with generalization error. In Section 3, the authors conclude that the correlation between AGN and generalization error is not consistent in a wider family of models. In Section 4, authors propose to use AGN for model selection and conclude that AGN is not good for model selection unless the hyperparameter for mixing AGN with another metric is optimal.",
    "The paper empirically investigates the sum of gradient norms as a measure to determine the generalization abilities of a neural network. The approach is inspired by the theoretical work of Li, et al. 2020 which showed that the generalization gap can be upper bounded by a function of the sum of the full gradient norms of the training path. ",
    "In this paper, they provide the empirical studies  to understand the effectiveness and efficiency of the use of the gradient norm (induced by [the Li et al., 2020]) as the model selection criterion. To speed up the calculation process the of the gradient norm, they first propose an approximate gradient norm (AGN) based on the depth-wise, sample-wise and epoch-wise accelerations.  Their empirical studies find that the use of AGN can select the models with lower generalization error, but fails for bandit-based or population-based algorithms, and fails to predict the generalization performance of models based on different architectures.  In conclusion, they do not recommend using (approxiamte) gradient norm for model selection in practice.",
    "The paper introduces a new method to retrieve entity by auto regressively generating unique entity name as a sequence of word pieces, instead of pinpointing the ID representing an entity. This method stands out in novelty compared to existing various entity retrieval methods, which always assigns a single ID to each entity. Practically, the proposed method has two nice properties: (1) When the entity vocabulary is very large, this approach requires less parameter space and memory compared to other methods (as shown clearly in Table 4) (2) The model can address novel entities, which was unseen during the training. The paper is clearly written and extensively evaluated on three relevant tasks, entity disambiguation, entity linking, and entity retrieval.",
    "This paper proposes to tackle the entity linking task using a sequence-to-sequence neural model, trained by producing unique entity names, in autoregressive fashion. The paper makes a case that this approach can scale better with larger entity vocabularies than previous methods with dedicated entity representations both in terms of memory as well as computation costs. The model is studied under a number of tasks including entity disambiguation, entity linking and document retrieval for question answering.",
    "The paper proposed to use autoregressive approach to solve entity-based problems. They proposed a uniform framework and showed that their model achieved the state of the art performance on 3 different types of tasks (~20 datasets). The GENRE model also significantly reduced the memory usage compared to previous models that stored a big memory table. It's also capable of linking novel entities at inference time. This paper is clearly written. The experiment results are convincing.",
    "In this submission a routing problem is studied. In the considered model with each edge of the given graph a congestion function is associated that specifies the congestion depending on the current load of the edge. Then cars have to be routed through the network where each car has a source and a destination and one aims at choosing a path from the source to the destination with the smallest total congestion. However, the congestion functions of the edges are a priori unknown and hence one cannot trivially use a shortest path algorithm. Instead one gains information about the congestion functions only by routing the cars. When a car is routed one observes for each edge on its path the current congestion up to some random additive term. These observations can then be used for future routing decisions.",
    "This work introduces an interesting generalization of stochastic combinatorial semi-bandits for routing in a static graph. The main differences are: (1) the expected loss of an edge e is f_e(x^t_e) where the flow x^t_e is revealed at the beginning of each round (for each edge) and f_e is an unknown Lipschitz function (with known Lipschitz constant); (2) the regret is dynamic, computed against the sequence of optimal paths. When f_e is a constant function for each edge, then we recover a version of the stochastic combinatorial semi-bandit.",
    "The paper uses the bandit learning framework to study the online learning problem for routing in a city network . After each routing decision, the learning agent observes the actual delay on each edge, which is given by the congestion function on the given flow plus a random noise, and the reward is the total delay on all edges. The paper proposes a learning algorithm similar to the UCB approach, provide the regret bound result, and conduct simulations on the New York City network to verify performance of the algorithm. ",
    "This paper proposes an improvement to how tokens are selected for masking in pre-training large masked language models (BERT and family). Specifically, it stipulates that purely random choice of words (or word pieces) makes the MLM task insufficiently hard. It then goes on to propose a data-driven approach for selecting n-grams to mask together. The approach, based on an extension of pointwise mutual information for n-grams, is shown to outperform random token and random spans masking strategies on performance of downstream tasks.",
    "This paper presents a masking strategy for training masked language models (MLM). The proposed strategy builds on previous approaches that mask semantically coherent spans of tokens (such as entire words, named entities, or spans) rather than randomly masking individual tokens. Specifically, the proposed method computes the PMI of spans (and the generalization for spans of size >2) over the pretraining corpus, and randomly masks from among the 800K spans (lengths 2-5) with the highest PMI. Masking based on PMI removes the ability for the model to rely on highly local signals to fill in the mask and instead focus on learning higher level semantics. They motivate this hypothesis with an experiment demonstrating that as the size of the WordPiece vocabulary decreases (and words are more frequently split into multiple tokens rather than being their own token), the transfer performance of the resulting MLM decreases. However, using whole-word masking with this same vocabulary size recovers much of the original performance, indicating that allowing the model to rely on these strong local signals harms the transfer quality of the resulting model.",
    "The paper proposes a variant on the MLM training objective which uses PMI in order to determine which spans to mask. The idea is related to recently-proposed Whole Word Masking and Entity-based masking, but the authors argue the PMI-based approach is more principled. The method is straightforward--it involves computing PMIs for ngrams (in this case, up to length 5) over the training corpus, and then preferring to mask entire collocational phrases rather than single words during training. The intuition is that masking single words allows models to exploit simple collocations, thus optimizing their training objective without learning longer-range dependencies or higher level semantic features of the sentences, and this makes training less efficient than it could be. One contribution of the paper is a variant on the PMI metric that performs better for longer phrases by reducing the scores of phrases that happen to contain high-PMI subphrases, e.g. \"George Washington is\" should not have a high score despite the fact that \"George Washington\" does have a high score.",
    "This paper investigates the effect of partial conditioning on amortized inference in variational auto-encoders, focusing specifically on sequential data sources where it is common practice to have a posterior that is factorized in such a way that conditioning is partial (usually only conditioning on past signals in the sequence). Given a true posterior that is conditioned on the entire observed datapoint, the authors discuss the effect of having an approximate posterior that is only conditioned on part of the input. As the approximate posterior cannot adapt to the part of the input that is left out of the conditioning, the evidence lower bound becomes less tight, due to the larger KL divergence between the approximate posterior and the true posterior. The authors compare this to the work by Cramer et al. [1], where the distinction was made between having a restricted family of possible distributions for the approximate posterior (approximation gap) and the gap between an amortized approximate posterior with an inference network shared for all datapoints and a non-amortized approximate posterior that is optimized for each datapoint separately (amortisation gap). They argue that partial conditioning leads to a third type of gap which is distinct of the aforementioned inference gaps. Through an example with discrete observations the authors derive that when the true posterior is conditioned on the full data, and the approximate posterior is only partially conditioned, the optimal approximate posterior is something akin to a product of true posteriors over the unconditioned information, and not a mixture where the left out information is marginalized out. Through a 1D example they show that this could lead to overly sharp posteriors that have high densities in regions where the true posterior has very low density. ",
    "The paper considers the problem of Bayesian inference with partially conditioned variational posterior. Namely, this work describes the phenomena of ill-behaved variational posterior for the case of partially observed data. The paper's main theoretical finding is that the partially conditioned variational posterior behaves like a product of experts, resulting in a degenerate solution. Speaking intuitively, the true posterior can be seen as a mixture of distributions: the sum over the unobservable variable. At the same time, the optimal variational posterior mixes as a product of distributions. Clearly, the product of densities hardly depicts features of the mixture since a near-zero value of a single member is enough for zeroing out the product's density.",
    "The paper reviews the issue of partial conditioning of the amortized posterior in sequential latent variable models, typically state-space models trained with a VAE-style loss, but where the posterior used is the filtering rather than smoothing posterior. The author show that training a model with posterior with missing information can lead to a gap in estimating both the posterior and the corresponding model. They show the benefits of using the correct posteriors in simple examples.",
    "The paper analyses generalization properties of distributed kernel ridge regression (DKRR) with random features and communications. It studies optimal learning rates of the generalization bounds both in expectation and in probability. In the case of DKRR with random features, the optimal learning rate in expectation is shown to achieve by relaxing the requirement on the number of partitions from $O(1)$ (Li et al., 2019a) to $O(|D|^{0.5})$ (Theorem 1). Within the same setup of random features, the number of partitions is relaxed to $O(|D|^{0.25})$ guaranteeing optimal generalization performance in probability (Theorem 2). The latter bound $O(|D|^{0.25})$ on partition count is much smaller then $O(|D|^{0.5})$. However, as proved in Theorem 3, allowing multiple communication rounds in DKRR-RF, up to $O(|D|^{0.5})$ partitions can be handled depending on the number of communication rounds. In other words, it can exploit more partitions at the cost of more communication rounds.",
    "The paper investigates an algorithm for distributed learning with random Fourier features. The main idea is to sample M random Fourier features and split the data into m chunks. Each chunk is processed on a separate machine that outputs a linear hypothesis using the sampled M random features. The hypotheses coming from different machines are then aggregated on the master machine via importance weighting. In particular, each hypothesis is assigned importance weight proportional to its data chunk size (see Eq. 3). The regularization parameter is fixed across different machines. The main contribution of the work is a consistency bound. In comparison to a previous bound on the divide & conquer algorithm (Li et al., arXiv 2019), this one does not require a constant number of machines (in my understanding of the related work section).",
    "This paper studies the statistical properties of distributed kernel ridge regression together with random features (DKRR-RF), and obtain optimal generalization bounds under the basic setting in the attainable cases.  Numerical results are given for the studied new algorithms. The algorithms and the derived results are new and interesting to me. However, the presentations as well as the citations need some major revision before the publication. ",
    "Motivated by exploring the ranking correlations of the existing RandomNAS in NASBench-201, this paper proposes EPS to improve the search efficiency and keep good ranking correlations by evolving the proxy search space (PS) in RandomNAS. Specially, EPS contains three stages: 1) training the supernet in PS, 2) validating the architectures among the PS and 3) evolving the PS by tournament selection with the aging mechanism. Furthermore, a model-size-based regularization is introduced in the selection stage. Experiments on some popular benchmarks demonstrate the effectiveness of the method.",
    "This paper claims that random search-based NAS methods show a low ranking correlation among top-20% candidate architectures in the search phase. To address this issue, this paper proposes to introduce a proxy search space consisting of good architectures and evolve it using evolutionary algorithms. This paper also proposes a simple size regularization to help the NAS algorithm escape from the small architecture traps. The experimental results show that the proposed approach achieves competitive performance with baseline methods.",
    "This paper proposes Evolving the Proxy Search Space (EPS) as a new RandomNAS-based approach. The goal is to find an effective proxy search space (PS) that is only a small subset of GS to dramatically improve RandomNAS\u2019s search efficiency while at the same time keeping a good correlation for the top-performing architectures. EPS runs in three stages iteratively: Training the supernet by randomly sampling from a PS; Validating the architectures among the PS on a subset of the validation dataset in the training interval; Evolving the PS by a tournament selection evolutionary algorithm with the aging mechanism.",
    "This work seeks to efficiently learn new tasks by combining meta-RL and imitation learning (IL). Such a combination is a natural thing to try, as both lines of work improve sample complexity of learning a new task: meta-RL by leveraging experience on prior related tasks, and IL by leveraging demonstrations. Demonstrations also form a natural way of specifying a new task to the agent.",
    "This work proposes PERIL, a method for combined Meta Imitation Learning and Meta Reinforcement Learning using context-based meta-learning. Given a set of demonstrations, a latent variable representing the desired task is inferred, and trajectories are generated conditioned on the inferred latent variable.  The data from the expert demonstrations and trajectories are used for meta-learning updates.",
    "This paper introduces PERIL, a meta RL method that combines demonstration trajectories and trajectories collected by the policy, in order to adapt to a new task. To this end, the authors combine ideas from metaRL (specifically from PEARL (Rakelly et al. 2019) and Humplik et al (2019)) where a set encoder is used to encode trajectories to a latent vector describing the task, with imitation learning techniques by (a) training this encoder also with demonstrations (b) initialising the latent vector at test time by feeding demonstrations through the encoder, and (c) having additional losses inspired by metaIL techniques. The motivation is that using demonstrations allows us to learn tasks that are difficult otherwise, for example because the rewards (at test time) are sparse. ",
    "This paper is concerned with the question of generalization of convolutional neural networks. For that, the authors study a simple toy model, where each data point consists of several patterns. All patterns are assumed to be orthogonal to each other. Those images should be learned with a 3-layer neural network. The contributions of this paper are as follows:",
    "This paper studied a simplified image classification task with orthogonal non-overlapping patches and is learned by a 3-layer CNN. The authors observed pattern statics inductive bias (PSI) in experiments. They proved that if a learning algorithm satisfies PSI, the sample complexity is nearly quadratic in the filter dimension; while the VC dimension of the network is at least exponential in the filter dimension. The authors also verified PSI in some task based on MNIST that has non-orthogonal patches.",
    "In this manuscript the authors derive theoretical analysis for the generalization guarantees of a na\u00efve CNN (3-layers) where the task is a simplified binary classification task, under the assumption that the images contain orthogonal patches (a na\u00efve assumption). They define a statistical phenomenon that holds in SGD in the proposed setting and call it Pattern Statistics Inductive Bias (PSI). Informally, this means that the magnitude of the dot-product between the learned pattern detectors and their detected patterns is correlated with the distribution of the patterns in the data.   They prove that if a learning algorithm  satisfies PSI then its sample complexity is O(d^2 log (d)), where d is the dimension of the filter. According to their empirical derivation SGD satisfies this property. In contrast there exist learning algorithms that have exponential sample complexity. ",
    "This submission considers contrastive learning approach to representation learning under topic modeling assumptions. It proves that the proposed procedure can recover a representation of documents that reveals their underlying topic posterior information in case of linear models. It is experimentally demonstrated that the proposed procedure performs well in a document classification task with very few training examples in a semi-supervised setting.",
    "This paper tries to learn a document level representation from document level contrastive estimation. The training task is try to predict where two half of a document are from the same document. The author proved the contrastive estimation reveals topic posterior information given the topic modeling assumptions. And in experiments, linear models can get relatively good performance. ",
    "This paper presents a new contrastive learning algorithm for document representation. The main idea is to generate pseudo labeled two texts, whether the texts are coming from the same document. To learn the discriminating function between the two texts, the learning algorithm minimizes the cross-entropy loss function between them. With the function, the authors suggest the embedding function for a document with selected landmark documents. The authors also show the learned function can be represented by combining the topic posterior distribution and topic likelihood distribution. Experiments show that the suggested learning algorithm can identify hidden topics from a synthetic dataset. And the authors also show the usefulness of the representation in semi-supervised learning by classification performance and visualization.",
    "The paper tries to minimize the difference of the PMI between related and unrelated pairs of multimodal data but arrives at a very different objective with many approximations. It can be plugged into existing VAE based methods and improve learning performance and data efficiency. My major concern is about the derivation and the connection between motivation and the final objective.",
    " The paper proposes a contrastive objective that (1) minimizes the distance between \"related\" samples while (2) maximizing the distance between randomly paired samples. Existing multimodal VAEs optimize (1) via different multimodal ELBOs. The novelty lies in the optimization of (2) which can further benefit from unimodal samples for which no \"related\" samples of the other modality are available---this can be viewed as a semi-supervised approach for weakly-supervised multimodal data.  For the estimation of (2), the paper experiments with two different estimators, IWAE and CUBO.",
    "This work presents a generative model for multimodal learning. The paper maximizes or minimizes the pointwise mutual information between data from two modalities considering a novel random variable relatedness to dictates if data are related or not.  This is realized by casting multimodal learning as max-margin optimization with the contrastive loss for the objective. For the optimization, the paper considers the IWAE estimator. As per the experiments, the paper considers MNIST-SVHN and CUB Image-Captions dataset and perform evaluations across four metrics. Using the experiments, the paper demonstrates that the proposed approach improves multimodal learning, data-efficient learning, and label propagation. ",
    "The authors highlight an important problem in VAE - the prior-hole problem - which is that the approximate posterior and the simple gaussian prior do not match in spite of the KL term in the ELBO which makes sampling an issue - leading to the prior putting probability mass on latents that are not decoded to high probability mass regions in data manifold. Prior approaches have overcome this problem by increasing the expressivity of the prior through autoregressive models, and/or using hierarchical latents, EBMs with MCMC sampling. This paper proposes a very simple two stage method - (1) train a regular VAE, (2) train a binary classifier in NCE style to distinguish samples from prior and approx. posterior; use the re-weighting term from the NCE score to sample from a better re-weighted prior - either through langevin dynamics or re-sampling. The authors combine this approach with the use of hierarchical latents and produce really good performing generative models on a host of benchmarks with good looking samples.",
    "Authors approach the \"hole problem\" of variational autoencoders where the aggregate posterior fails to match the prior, causing some areas of the prior distribution to be left out. Consequently, the decoder is not trained properly to operate in such regions, and the whole generate models is then subject to suboptimal performance. To attack this problem authors introduce two changes:",
    "The goal of the paper is to model the marginal over latents in VAEs in such a way to minimize the mismatch with the aggregated posterior. The paper proposes a new class of marginal distributions over the latent space that is a product of two experts: the first expert is a non-trainable probability distribution, and the second expert is an unnormalized probability distribution parameterized using neural networks. Since training a product of experts requires to apply an approximate inference (e.g., MCMC sampling), the authors propose to use the likelihood ratio trick. Eventually, a VAE is trained in two stages. First, they assume the marginal over z's to be simply the non-trainable distribution, and the VAE is trained. At the second stage, they propose to train the second expert (i.e., the binary classifier that distinguishes z ~ q(z) and z ~ p(z)) in order to obtain the final NCP that better matches the aggregated posterior. Further, the idea is extended to hierarchical VAEs, and a separate binary classifier is trained per each stochastic level.",
    "This work considers a regularized IRL setup, where instead of the entropy regularization used in maximum entropy IRL, an arbitrary convex regularizer $\\Omega$ is used. The work presents a number of theoretical results for this general setting, and it is shown that when $\\Omega$ is Tsallis entropy, the $RL \\cdot IRL$ is equivalent to minimizing a Bregman divergence defined based on the Tsallis entropy and the expert state-action distribution. A practical algorithm is presented for IRL with the Tsallis entropy. A number of experiments are performed to obtain understanding of various components.",
    "This paper proposes a new method for regularized inverse RL. The paper builds upon work by Geist et al. who studied regularized MDPs with convex policy regularizers. The Shannon entropy is a special case of such a policy regularizer. The paper extends the analysis of Geist et al. for regularized IRL and devises tractable solutions to regularized IRL that only depend on the analytic knowledge of the regularizer. The paper further proposes regularized adversarial IRL (RAIRL), an extension of AIRL by Fu et al., as an algorithm for IRL in regularized MDPs. The algorithm is validated on a number of domains.",
    "This paper shows a formulation of regularized Markov Decision Processes (MDPs), which is slightly different from that of Geist et al. (2019). Then, the authors propose a novel inverse reinforcement learning under regularized MDPs. One of the contributions is that policy regularization considered here is more general than that of Yang et al. (2019). ",
    "In this paper, the authors present a study of different aspects of language-specific model capacity for massively multilingual machine translation. To this end, language-specific behaviour is achieved via a combination of conditional computation to decide whether to use language-specific parameters or not and statically assigning experts for each languages. The language specific sub-layers are incorporated throughout the network. The training objective allow budgetary constraints on the amount of language-specific parameters. The paper does a systematic analysis on the role of language specific parameters using the proposed architecture. Based on the analysis, recommendations on design of multilingual NMT architectures are proposed and their efficacy validated experimentally. The study sheds light on the amount of language specific parameter sharing, their distribution in the network, impact of language, etc. ",
    "The work proposes a hybrid architecture that has: (1) language-specific (LS) components; (2) as well as the components that are shared across all the languages -- a trade-off between specificity and generality.  A key conclusion of the work is that the best architectures typically are. the ones that have ~10-30% language-specific capacity. ",
    "In this work, the authors present a conditional language-specific routing (CLSR) scheme for transformer-based multilingual NMT systems. They introduce a CLSR layer after every transformer encoder and decoder layer; each such layer is made up of hard gating functions conditioned on token representations that will either select a language-specific projection layer or a shared projection layer. Further, a budget is imposed on the language-specific capacity measured by aggregating the number of gates that allow for language-specific computations; this budget constraint forces the network to identify the sub-layers that will benefit most from being language-specific.",
    "This paper propose a computationally efficient Wasserstein distributional normalization algorithm for accurate classification of noisy labels. An explicit upper bound for the Wasserstein-2 distance is derived and such a bound can be used as an estimator to determine if a network is over-parameterized. Empirical results on CIFAR-10/100 and Clothing1M suggest that the propose algorithm outperforms other SOTA approaches. ",
    "The paper is a contribution that aims at solving the label noise problem. In this setting, the labels are possibly corrupted, this yielding a potentially significant underperformance of a (neural network) classifier when minimizing the empirical risk. This problem is ubiquitous and important in real life scenarii. The paper builds on the idea of small loss criteria, which favors learning on certain samples in the beginning of the learning process, and gradually incorporate uncertain samples along iterations. The paper proposes a novel type of distributional normalization based on Wasserstein distance. It projects uncertain samples on a Wasserstein ball defined wrt. the certain samples. This process is done with a particle based stochastic dynamics, based on a Ornstein-Ulenbeck process. A theoretical Analysis is given, along with results on classical datasets in the symmetric noise setting, open noise and a real world dataset (clothing 1M), for which it achieves very good performances compared to state of the art competing methods. ",
    "The paper introduces a novel objective function by imposing geometric constraints on the logits of uncertain samples. The authors' approach is to map the distribution logits of uncertain samples onto the 2-Wasserstein ball centered on the measure of certain samples. To overcome the dilemma of selecting the ball radius, the authors propose a surrogate objective, namely Wasserstein Normalization. An SDE grad flow is proposed for solving the Wasserstein normalization. The paper also keeps the Gaussian parameters as moving average during training in light of batch normalization. The paper both theoretically and empirically validate their method.",
    "The paper proposes a new conformalized procedure for computing uncertainty sets in classification tasks. The key feature of the method is that the size of the uncertainty sets are regularized via a penalty on the size. The issue of large uncertainty sets produced by conformalized procedures is an interesting one, which the paper does well to highlight. The proposed solution of using an additive regularizer is reasonable, and appears to be effective for sensible choices of the hyper-parameters. However, the paper has some significant weaknesses.",
    "In this paper, the authors propose a regularized conformal score for use in a conformal prediction framework. This regularizer is motivated by the instabilities of top-p variations on conformal scores (cf. Romano et. al., 2020) and the resulting high-variance in output conformal prediction set sizes. The proposed regularizer smooths top-p scores with top-k scores, which empirically results in more robust predictive sets. The authors also perform a large-scale evaluation on ImageNet with modern architectures, which serves as a helpful benchmark for conformal prediction algorithms.",
    " Prediction sets are used to quantify the uncertainty of classification. The naive approach which include the labels until a pre-specified coverage probability is satisfied often leads to large prediction sets. Adaptive Prediction Sets (APS) can output prediction sets with desired coverage but set sizes are still not satisfyingly small and the results are unstable, especially when many probability estimations fall into the tail of the distribution. ",
    "This work introduces a new Wasserstein-2 barycenter computation method. The authors first derive the dual formulation of the Wasserstein-2 barycenter problem, and then parametrize the convex potentials by ICNNs. The congruent and conjugacy conditions are enforced by regularization terms, respectively. They then show that the algorithm can find a good barycenter if the objective function is properly minimized.",
    "The paper derives the barycenter mapping problem as an optimization over *congruent* convex functions---each convex potential corresponding to a component distribution.  Congruency is a property on the set of optimal potential functions that ties them together.  However, this optimization is quite challenging and so the paper derives an principled objective function that includes two regularization terms.  The first regularization term encourages congruency of the set of convex functions and can be seen as a variational bound on an ideal congruency regularization.  The second regularization term encourages the pairs of convex functions to be conjugate.  The paper proves that the optimal solution of this objective is the true potentials and thus no bias is introduced.  The proposed approach is demonstrated on the tasks of generative modeling (2-256 dimensions), posterior inference, and color pallete barycenters (3D)",
    "The paper considers the Wasserstein Barycenter problems in the continuous setting. In particular, the authors propose an algorithm to compute the Wasserstein-2 barycenter when only samples from the marginals are accessible. Some theoretical analysis of this method is presented. Several numerical examples are carried out to compare this method with two other recently proposed methods.",
    "The authors consider a binary classification task. As a model the authors use a deep fully-connected neural network and train it to separate the submanifolds, representing different classes. They assume that sub-manifolds belong to the unit sphere. Also, the authors restrict their analysis to a one-dimensional case. The main claim is that by increasing depth we can improve model generalization of a network, trained by SGD.",
    "The paper studies the conditions for a deep fully-connected network to separate low-dimensional data classes. A binary classification setting is considered, where the two classes are modelled as two different manifolds. The manifolds are assumed to be one-dimensional for the ease of analysis. It is shown that the network depth should be sufficiently large so as to adapt to the geometrical properties of data (e.g. the manifold curvature); the network width should increase polynomially with the network depth; and the number of data samples should also scale at a polynomial rate with the network depth. The authors show that if these conditions are met, with high probability a randomly initialized network converges to a classifier that separates the two class manifolds. The proof technique relies on conditioning the network parameters of the l-th layer on the parameters of the previous layers using a Martingale model, which gives sharp concentration guarantees. ",
    "The paper under review studies the question of whether gradient descent can solve the problem of calibrating a deep neural network for separating two submanifolds of the sphere. The problem studied in the paper is very interesting and as been the subject of recent increasing interest in the machine learning community. The contribution is restricted to a simple set up and addresses the question in the finite sample regime. The framework of the analysis hinges on the Neural Tangent Kernel approximation of Jacot et al. ",
    "This study presents a deep reinforcement learning method, Advantage-Weighted Regression (AWR). The policy update of AWR is constrained as in a similar manner as REPS (Peters et al., 2010). Although the benefit of AWR is not clear in the reinforcement learning tasks, AWR exhibits its advantages in the context of imitation learning and off-policy learning with static datasets. ",
    "This paper focuses on developing an RL learning algorithm that is simple and can significantly improve performance over existing algorithms. The paper presents the algorithm AWR, which is an extension of the algorithm reward weighted regression. The primary extensions of RWR are using the advantage function instead of the q function and the ability to use experience replay. Experiments on common environments are conducted to evaluate the performance of AWR and compare it to other algorithms. There are ablation experiments to justify the choice of some of the extensions. ",
    "This paper presents a reinforcement learning algorithm that applies advantage-weighted regression. In each iteration, it samples trajectories from a mixture of previous policies, estimates the value function and then computes the advantage value to estimate the policy. The idea is very similar to the work published in \u201cNeumann, Gerhard and Peters, Jan R, Fitted Q-iteration by advantage weighted regression, Advances in neural information processing systems, 2009\u201d, starting from reward-weighted regression and further developing to advantage weighted regression.  The difference in this paper is to add a constraint on the policy search, requiring the policy to be similar to the sampling policy. However, this constraint has also been studied in the paper \"Christian Wirth and Johannes Furnkranz and Gerhard Neumann, Model-Free Preference-based Reinforcement Learning, AAAI 2017\" (It seems not in reference). Overall, it may enhance this paper if it has more technical novelty when developing a new algorithm.",
    "The paper proposes using a sinusoidal regularizer for neural network quantization. The regularizer \u201cWaveQ\u201d (sin^2) pushes floating-point parameters towards quantized values. Because the period of the function is highly related to the required bit-width, it can be used to determine the bit-width while keeping good characteristics - continuous and trainable. The authors provide experiments on both CNN and Transformers. The proposed method is widely adaptable and easy-to-use with quite promising results.",
    "This paper proposed a regularization term to control the bit-width and encourage the DNN weights moving to the quantization intervals. The key in such regularization is the Sinusoidal function, where the penalty is maximized in the middle of quantization levels and minimized at the quantization points. The sinusoidal period is regarded as the continuous representation of the bit-width.",
    "When training quantized neural networks, one typically first fixes the desired bitwidth $b$ (of weights and activations). While training, one maintains and updates full-bitwidth weights during backprop and \"cheats\" by using $b$-quantized versions of these full-precision weights during forward propagation. The quantization scheme used may vary.",
    "The paper proposes a GAN process for training neural machine translation models. The noise generator in this approach uses a switching-aligned-words technique where they randomly switch a word in the source sentence with its translation in the target sentence. They use fast-align to get alignments between source and target sentences. The experiments show that the noisy sentence pair generator performs best with the proposed switch and align approach in comparison with other (more random) methods. ",
    "This paper describes a method for data augmentation and/or regularization for machine translation that works by running a word aligner on the parallel data, and then with some probability \\gamma, replacing a source token with its corresponding target token or vice versa. A proposed variant also mixes the embeddings of the two words. Small improvements are shown over simpler noising strategies such as replacing words with placeholder tokens or with random words from the vocabulary.",
    "The paper proposes a data augmentation technique where source sentences are perturbed by replacing (or mixing) source words with their aligned counterparts from the target language (while the target sentences remain as is). Alignments can be either obtained from an unsupervised aligner like fast-align or from the attention distribution of an NMT model. Perturbations are aimed to be semantically invariant to preserve the meaning of the source sentence. In addition to simply replacing the source word with the aligned word, authors also try out inputting a weighted combination of both the source word and the target word and refer to this method as \u201cmixing\u201d. Empirical observations suggest that simply replacing the source word with the aligned target yields better results.",
    "The paper is to measure each client\u2019s contribution to training the federated learning model. In particular, the contribution is measured by the distance between the local model and the global model in each iteration. The targeting problem is interesting, and the use of attention-based model divergence is also an interesting idea to measure the contribution. However, the paper lacks strict theoretical discussion to prove the proposed solution is a reasonable one rather than a heuristic method. Moreover, the experiment is too weak to support the claims. The paper\u2019s technique contribution and originality are also limited. ",
    "The paper proposes a low computational complexity method for weighting contributions of clients in a federated learning setting. The main contributions are to compare the weighting method with Shapley values and their sensitivity to low data volume and quality. The paper is based on the FedAtt paper that calculates weights based on the Euclidean distance between the server model and each client and for each layer.",
    "The paper proposes a new contribution measurement approach for federated learning. The basic idea is that the agent with a larger model update has a larger contribution. Specifically, based on FedAtt [1], the impact of a client is computed as the local updates plus the impact of the previous round times a decay rate. The experiments on a dataset show that the proposed approach can have a similar contribution measurement compared with Shapley Value.",
    "The paper considers the problem of robustly learning fixed structure Bayesian networks in nearly-linear time. Previous work by Cheng et al. gives a runtime of O(Nd^2/eps). The paper improves this to O(Nd). The algorithm works by directly relating the problem to robust mean estimation, and then leveraging the algorithm of Dong et al. for robust mean estimation which works in nearly-linear time. The authors have to modify the runtime analysis of the algorithm of Dong et al. to work in time linear in the sparsity, rather than dimension.",
    "The paper studies the problem of robust learning of fixed-structure Bayesian networks under the eps-adversarial corruptions model. Fixed-structure means a known structure of the underlying Bayesian network. Robust learning is an important area of research and this particular question has been studied in prior work. The main contribution of this work is in improving the running time of the algorithm. On a d-node Bayes net, let m denote the total number of parental configurations possible. Prior work of Cheng et al showed a robust learning algorithm using O(m/eps^2) samples and runs in time O(md^2/eps^2).",
    "This paper studies the problem of learning Bayes nets using adversarially corrupted data. The model is that $N$ samples are made from a Bayes net on d nodes, out of which an unknown $\\varepsilon$ fraction are changed arbitrarily. The structure of the Bayes net is already given, but it remains to learn the probability distribution.",
    "In this paper, the authors propose to replace commonly-used shooting-based methods for action sequence planning in learned latent-space dynamics models by a collocation-based method. They argue that shooting-based methods exhibit problematic behavior especially for sparse-reward and long-horizon tasks, as shooting methods do not allow for planning trajectories which (slightly) violate the learned dynamics. The authors propose a collocation method based on Levenberg-Marquard optimization with a scheduled Lagrange multiplier which outperforms two shooting methods (CEM and gradient-based) on a set of robotic tasks.",
    "This paper introduces a vision-based motion planning approach using collocation. Many existing approaches to vision-based control rely on computationally expensive planning approaches using shooting to perform model-based control, which is often only useful in simple control tasks. Collocation approaches are effective in settings with difficult path constraints, and thus exploited by this work to dramatically improve model-based reinforcement learning.",
    "The paper studies the problem of planning in domains with sparse rewards where observations are in the form of images. It focuses on solving this problem using model-based RL with emphasis on better trajectory optimization. The proposed solution uses latent models to extract latent representations of the planning problem that is optimized using the Levenberg-Marquardt algorithm (over a horizon). The experimental results show improvements over a) zeroth-order CEM optimization, b)  PlaNet (Hafner et al., 2019) and c)  gradient-based method that optimizes the objective in Eq. 1.",
    "The work propose a theory suggesting that the cold posterior phenomena arises solely due the the curated nature of image benchmarks. A generative model is proposed where multiple annotators label datapoints, and only unanimously labeled datapoints are accepted into a dataset. This theory is studied under a toy-problem using VI and a relabelled version of the CIFAR-10 test set with SGLD. ",
    "This paper addresses the perplexing issue of cold posterior having better predictive performance than the ideal Bayesian posterior in Bayesian deep learning (Wenzel et al., 2020), and offers a possible explanation in terms of a mis-specified likelihood function that deviates from the true generative process of the data. By considering the data curation process and augmenting the likelihood model accordingly, the effect of cold posterior is shown to diminish significantly, and the ideal posterior is again optimal. Empirical results on both a toy problem and image classification support the theory.",
    "The authors propose the idea that cold posteriors in Bayesian neural networks could be caused by the likelihood instead of the prior. They argue theoretically that the curation process of popular benchmark data sets would lead to a different weighting of the likelihood in the posterior. They show in some experiments that the cold posterior effect can be reduced when accounting for this.",
    "Traditional NTM is done with a large encoder and large autoregressive (AR) decoder. Due to the sequential nature of the AR decoder, inference can be slow due to lack of parallelism (unless done at very large batch sizes). Non-Autoregressive (NAR) models have been proposed to alleviate this problem, but all NAR approaches trade off some translation quality for speed gains. In this paper, the authors claim that an alternative to NAR is to speed up standard AR decoding by reallocating network weights and layers to the (easily parallelizable) encoder, and making the decoder a single layer. They claim that this matches the speed of NAR models while keeping the performance of traditional AR models, making it a better choice in the design space than any NAR models. Comparisons are made to CMLM and DisCo NAR models to justify these claims with experimental evidence.",
    "The authors advocate for fair comparison between autoregressive (AR) and non-autoregressive models (NAR) in non-autoregressive machine translation (NAT) research. They highlight three main aspects where the comparison has not been fair so far in the literature - suboptimal layer allocation, insufficient speed measurement, and lack of knowledge distillation. They perform extensive comparisons between AR and NAR models in these 3 aspects and report interesting results. ",
    "The paper proposes deep encoder and shallow decoder models for auto-regressive NMT. They compare rigorously to NAR models. They also study three factors: layer allocation, speed measurement and knowledge distillation. They include that with a 12E-D1 model they obtain significant speed-up and can outperform the standard 6-6 AR model and almost always beat the NAR model in terms of quality. They also show that NAR models need deep decoders because they need to handle reordering.",
    "The paper under review studies the epoch wise double descent phenomena empirically. The epoch wise double descent phenomena is the observation that the risk of a large neural network trained with SGD first decreases, then increases, and finally decreases again as a function of the epochs or SGD steps. In addition, it proposes a quantity called ``optimization variance (OV)'', and it demonstrate that OV correlates with the test error. Based on this observation, it proposes to early stop when the OV reaches a minimum.",
    "Having a stopping rule without the validation set is intriguing, especially for datasets with a low number of samples. The authors propose a rule that doesn't require the validation dataset, i.e. it is solely based on training data. It introduces the notion of optimization variance which is different from the variance of gradients. ",
    "The paper studies the trajectory of the test error as a function of training time focusing on Epoch-Wise Double-Descent.  Similar to \"Rethinking Bias-Variance Trade-off for Generalization of Neural Networks\" by Yang et. al., the paper shows that if one decomposes the test error to bias and variance terms, Double Descent occurs as a function of train time as a result of unimodality of the variance term (while the bias term decreases monotonically).  The paper also introduces a quantity they name optimization variance (OV) and that correlates with the test error (while being only a function of the train set) and can be useful for early stopping.",
    "This paper investigates the adversarial robustness of model agnostic meta-learning (MAML). Adversarial robustness can be added to MAML in two places, meta-update stage and and fine-tune stage. It shows that robustifying the meta-update stage via fast attack generation method is sufficient to achieve fast robustness adaptation without losing generalization and computation efficiency in general. The paper also demonstrates that unlabeled data can help using contrastive representation learning to improve generalization and robustness. ",
    "It is an interesting paper empirically addressing adversarial robustness of model agnostic meta learning (MAML). The paper investigates where to incorporate robust regularization in MAML in order to improve adversarial robustness, and based on that *efficient* robust MAML methods are proposed. Interestingly, contrastive learning is incorporated and derive a more robust MAML model. ",
    "This paper explores a way to promote the adversarial robustness in Model-agnostic meta-learning (MAML). It conducts extensive experiments to show regularizing adversarial robustness at meta-update level is sufficient to offer fast and effective robustness adaptation on few-shot test tasks. However, it lacks the theoretical analysis for this conclusion. Also, the experiments only are conducted on few-shot image classification task on miniImageNet dataset. This makes this conclusion lack sufficient credibility.",
    "Meta-gradient descent is an approach to step-size adaptation in which the step-size is adapted by considering how it influences the loss function over time. Intuitively, one can think of the trajectory of parameters $(w_s)_{s=1}^t$ as being a function of the step-size $\\eta$, and try to control the loss indirectly through the step-size's influence on the weight trajectory. This paper provides guarantees for this class of algorithms when applied to a quadradic loss function. It is shown that the meta-objective $\\ell_t(\\eta)=\\frac{1}{2}w_t(\\eta)^\\top H w_t(\\eta)$ contains no bad local solutions, but can suffer from vanishing/exploding gradients. It is then shown that this can be remedied simply considering the logarithm of this meta-objective, but that this too will have issues with numerical stability if approached with back-propagation. Finally, results related to the generalization ability of these methods are presented.",
    "This paper considers algorithms that attempt to learn learning rates for gradient descent by gradient descent. Analysis is provided for a few specific quadratic losses showing that the gradient with respect to the learning rate may explode or vanish, and taking the logarithm is suggested to mitigate this. Further results suggest that implementing the gradient of the log comes with interesting numerical difficulties as *intermediate results* might explode or vanish even if the final answer does not.",
    "This paper presents novel theoretical results on learning a step size for vanilla GD and SGD by unrolling the optimization steps and back-propagating, taking into account the simple problem minimizing quadratic functions and mean-square errors. The authors could demonstrate the occurrence of already-detected phenomena for learned optimizers, such as gradient explosion/vanishing and over-fitting, in the particular studied case. A few experiments illustrate what the developed theory predicts. ",
    "In this paper, a graph view-consistent learning framework (GVCLN) is proposed. Specifically, two view learners are used to give predictions for the input. Then, a consistency loss is employed to force the two viewers giving the same predictions. Moreover, a co-training scheme is proposed to alleviate the label sparsity problem.",
    "This paper proposes a view-consistent framework to address the issues of expensive labels. In particular, this work first uses graph neural networks and graph attention networks to construct two different latent features of the same data. Then, it uses the same classification neural networks to produce the node classification outcomes. Finally, it uses the classification outcome to construct a so-called \"view loss\". In addition, it uses an incremental strategy to gradually included pseudo labels until some termination conditions are satisfied. ",
    "This paper adopts a multi-view learning approach for graph representation learning where some labels are assumed to be available. It uses graph convolution network (GCN) and graph attention network (GAT) to create two different views of the same graph and then define a loss function to force the output due to the two views to be consistent. The low label rate scenario is considered and pseudo labels are created to define an additional loss function to better enforce consistency. Three datasets are used for performance evaluation.",
    "This submission explores the question of identifying conserved quantities in Hamiltonian dynamics for physical systems by attempting to learn canonical transformations. The approach closely resembles previous work on \"Hamiltonian neural networks\" but the loss is augmented with a term enforcing the invariance of the dynamics under the transformation and with a term that ensures the resulting transformed coordinates satisfy the constraints of the algebraic relations that emerge from the Poisson bracket. Together these two additions allow the authors to train a network that performs a change of coordinates which is subsequently optimized to bring it closer to a canonical transformation. Perhaps the main observation is that some of the cyclic coordinates identified by the network have a clear relation to the underlying conserved quantities. ",
    ".** The authors propose using a neural network to learn a canonical transformation of the data coordinates before learning a Hamiltonian. This is a novel contribution in that previous work has shown how to learn Hamiltonians with neural networks but it has not shown how to learn the proper canonical transformation. In the course of learning this canonical transformation, they show how to project out other symmetries (linear and angular momentum) and hence improve upon HNNs while also learning these other symmetries to a good approximation.",
    "This paper presents the results of a NN trained to learn symmetries in physics, specifically, to learn and preserve quantities that are preserved (e.g., energy, angular momentum). The input is a sequence generated from a Hamiltonian dynamics. Results of experiments on 2 and 3 body problems and a harmonic oscillator are presented. The training networks are small, shallow feedforward networks. There is some customization of the training networks to incorporate \"cyclic\" coordinates. Results indicated empirical conservation up to small error of physically conserved quantities. The paper is fairly easy to read, with much relevant background provided.",
    "The paper proposes a GNN model by incorporating gradient boosting. In the proposed BGNN, the input feature on the graph is learned by the gradient boosting model. The processed feature then becomes a new feature for a GNN model following the gradient boosting. Several experiments demonstrate the improvement of the performance for a tabular feature and graph-structured datasets. The running time of Res-GNN/BGNN is shown to have a significant reduction as compared to the plain GNN methods.",
    "This paper aims to learn from graphs with tabular node features. Existing methods are only designed to handle either tabular data, such as gradient boosting decision tree (GBDT), or graph-structured data, such as graph neural networks (GNNs). This paper naturally extends GBDT to deal with graph-structured data and train it together with GNN in end-to-end fashion.",
    "Review: This paper proposes a fusion of GBDT and graph neural network that works on graphs with heterogeneous tabular features. Previous approaches are computationally heavy and do not consider graph-structured data and suffer from lack of relational bias imposed in GNNs. The proposed method is a new ensemble tree method which alternates between functional gradient step in GBDT (which train on the current latent features) and SGD training of graph neural network (to generate the latent features which are fed into the subsequent trees).",
    "In this paper, the authors study the theoretical properties of meta-learning. In particular, the train-validation split to tackle the linear centroid meta-learning problem is investigated using statistical asymptotic theory. First, the authors proved that the train-validation method has statistical consistency, while the train-train method has a statistical bias to the centroid. Under the noise-free setting, however, both methods have statistical consistency. Furthermore, the train-train method is superior to the train-validation method in the sense of the asymptotic MSE. Based on the asymptotic analysis the optimal ratio of the data splitting for the train-validation method was also derived. The theoretical findings are confirmed by some numerical experiments. ",
    "In meta-learning, a common practice is to do a train/validation split of the data within each that, so that optimization of meta-parameters is performed on validation, not training, losses. In this paper, the author argue that this split is important for correcting model misspecification, but if the model is correctly specified, not doing a split might actually lead to better learning rates. They provide theoretical justification under a simple linear model, and some experiments on synthetic and real data.",
    "The authors verify the importance of train-validation split in meta-learning theoretically, which is commonly used in the meta-learning paradigms. By analyzing the linear centroid meta-learning problem, the authors show that the splitting method converges to the optimal prior as expected, whereas the non-splitting method does not in general, without structural assumptions on the data. The authors validate the theories empirically through both simulations and real meta-learning tasks.",
    "This paper proposes momentum of memorization as a way to distinguish hard examples needed for efficient learning from noisy examples which decrease classification accuracy. The method finds confident, hard examples and updates them dynamically during model training. This is done by iteratively selecting examples with labels that agree with model predictions and then training on only the confident data. Results show improved accuracy on standard image classification datasets with both synthetic and real world label noise.",
    "This paper propose a novel and effective method called Me-Momentum to cope with noisy labels. The algorithm borrows the idea of momentum from physics and tries to identify hard examples. The authors alternately update the hard examples and improve the classifier to achieve the robustness to noisy labels. Experiments and comparisons with recent state-of-art methods are provided to verify the effectiveness of Me-Momentum. ",
    "The authors introduce an interesting approach to handling hard \"confident\" samples in learning with label noises. At the heart of the proposed approach is an interactive method that jointly refines the classifier and the samples. The confident samples are initialized by utilizing the memorization effect of deep networks. Then, a classifier is learned from such samples. ",
    "First, the paper identifies k-Nearest Neighbor (kNN) and radius Nearest Neighbor (rNN) to be naturally effective baseline certified defenses against data poisoning attack. It is easy to see that kNN and rNN are resistant to poison attacks, since to flip the prediction of a test example, one would need to insert/delete enough examples to change the majority vote. Second, the paper proposes a joint certificate that further improves certified accuracy for rNN. Specifically, it uses the fact that for any given poison removal budget, it can only decrease the vote for a single label. Even though the idea is simple, the experimental result is quite impressive significantly outperforming the previous more sophisticated certified defense methods.",
    "The paper studies robustness of k-NN and r-NN against data poisoning attacks. The main message of the paper is that k-NN and r-NN are automatically resilient against attacks. Furthermore, by grouping test examples based their predicted labels. Data points with different predictions are grouped together, and then better certification guarantee can be derived. Experimental results demonstrate that k-NN and r-NN are indeed self-robust against data poisoning attacks.",
    "This paper studies to train a certifiable robust model against data poisoning attacks using nearest neighbors. The paper studies the voting mechanism in the nearest neighbor models, and presents a relationship between the poisoning instances and the difference between the majority votes and the second majority votes. Such a relationship will result in a guarantee on the lower bound of a training model's accuracy, which is referred to as Certified Accuracy (CA). The theoretical results are neat. The experiments are conducted on MNIST and CIFAR, and results show better CA than previous approaches of DPA and Bagging.",
    "In this paper, the authors study an important problem on how the choice of batch size (i.e., the number of sampled nodes) affects the training efficiency and accuracy of graph neural networks (GNN). Focusing on the layer-wise and graph-wise sampling for training, the authors theoretically characterize the impact of batch sizes on the efficiency (measured by a product of computation time and variance) of the algorithms. Especially, in order to better capture the randomness of two-consecutive layers, the authors investigate a different estimator rather than the one truly used in the training of GNN. The resulting theory suggests a choice of the batch size to be n/\\hat d, where n is the total number of nodes and \\hat d is the average degree of the graph. The authors empirically show that compared to the training of NN, the training of GNN requires a much larger batch size to achieve an efficient training. In addition, the experiments show that the best batch size is much smaller than the full batch that is widely adopted in the training of GNN.",
    "In this paper, the authors studied the problem of batch size selection in graph neural networks. Since scaling up the batch size is the most efficient way to increase parallelism, this topic seems to be very important for making full use of modern computer architectures like GPUs or TPUs. The authors conduct a detailed analysis on the impact of batch size in graph neural networks. After a series of discussions, the authors conclude that an ideal batch size should be n/d where n is the total number of nodes and d is the average node degree. The authors suggested that this batch size should be able to give the best convergence/generalization performance for graph neural networks. Overall, the paper is properly written. In terms of presentation, the structure is clear and the idea is easy to understand.",
    "The goal of the paper is to propose a principled strategy to select batch size for training graph neural networks with SGD. Training (using GNNs) real world graphs with a large number of nodes/ edges may not always fit in CPU /GPU memory, hence constructing mini-batches is important. Specifically, the authors propose a strategy for the task of node classification - where they aim to select batch size based on number of nodes and average degree in a graph and show that their proposed guidelines have benefits in terms of training time as well as accuracy. The authors propose a metric - pseudo precision rate which is dependent on the computation cost and the variance of the gradients and derive a lower bound for this metric which factors into account the batch size.",
    "This paper introduces RED, a new methodology to produce reliable confidence scores to detect missclassification errors in neural networks. The idea is to combine kernels based on both input and output spaces (as in RIO) to define a (sparse) GP that estimates the residual between the correctness of the original prediction and the maximum class probability. The authors show enhanced performance against other related methods and the ability of RED to detect OOD and adversarial data through the variance of the confidence score. ",
    "In this paper, their goal is to improve calibration and accuracy by augmenting a classification model with a GP. They base their model off RIO (ICLR 2020) which targets regression problems and tries to predict the residual between predicted value and true value. They propose a model, RED, which instead tries to predict the residual between the predicted confidence score for the true class and 1 \u2014 the true class target confidence score using a GP. They show strong improvements over the methods they compare to for 125 UCI datasets and CIFAR-10 dataset.",
    "This paper solves an interesting problem of predicting uncertainty in NN without re-raining/modifying the existing NN. The authors propose a framework to calculate a confidence score for detecting misclassification errors by calibrating the NN classifier\u2019s confidence scores and estimates uncertainty around the calibrated scores using Gaussian processes. This framework is called RED (Residual i/o Error Detection). ",
    "Many Information Retrieval systems rely on two components: a retriever that identifies a small set of \"support\" documents from a large corpus, followed by a reader that re-scores these support documents more finely. For retrievers, metrics like BM25 were once common but they are increasingly replaced by machine learned components. However, most datasets do not provide direct supervision information for the retriever.",
    "The paper targets an important problem in open-domain QA - the training of the retriever for the purpose of determining a segment that may contain the answer. In the most traditional setting, the retriever is just a traditional IR system such as BM25. In some existing work, the retriever has been trained to locate the documents containing the answer (e.g. inverse cloze task, or DPR). This paper goes in the same direction. The difference is that it uses the attention weights as relevance signals to train the retriever, instead of the inclusion of the answer in the passage.",
    "The authors propose a training technique for information retrieval models in the context of (open domain) question answering. Assuming the existence of some reader model, the idea is to use internal information of that model as a training signal for a retriever. Specifically, they use the attention activations over the input documents as synthetic labels for the retriever.",
    "The paper proposes a constrained reinforcement learning (RL) formulation relying on constraints written in a formal language. The proposed formulation is based on constrained Markov decision processes where the constraint is represented as a deterministic finite automaton that rejects any trajectory violating the constraint. The proposed solution relies on transforming the automaton's sparse binary cost into an approximate dense cost and augmenting that with the reward objective. The paper presents a series of results from simulations in Safety Gym, MuJoCo, and Atari environments.",
    "The paper builds on the constrained MDP framework (Altman, 1999), by considering the special-case where the cost functions are defined in terms of states from a parser of a formal language. In the experiments the work uses deterministic finite automata (DFA) but in principle other more expressive classes could be used. Using a formal language to specify constraints may simplify model checking (although this is left to future work). ",
    "The authors propose to use formal languages, specifically DFAs, as a mechanism to specify constraints in a constrained MDP setting. This has the benefit of being able to rely on a large body of existing work on identification, safety verification, etc. The strategy relies on decomposing the constraint into a translation, recogniser & cost assignment function that connect the MDP to the DFA. The mentioned cost can then be combined with existing solution for solving cMDPs, such as reward shaping and Lagrangian methods. The key observation is that adding the recogniser state to the observations of the policy can result in significant gains in both performance and constraint satisfaction. A range of results are presented across different environment suites and hyper parameters.",
    "The authors presented in this submission a nice novel idea of building a tree ensemble in a cascading style so that any positive predictions are decided and explained by the first tree predicting them positively. The reviewer finds this idea very interesting and clearly elaborated in this paper. However, more theoretical and empirical justification is crucially necessary in order to make the claims in the submission convincing. The issues listed here are some questions that the reviewer believes should have been discussed or answered in the paper.",
    "This paper introduces the Cascading Decision Tree, a novel variant of decision trees with permits to extract short explanations for a class of interest. The idea is to realize a cascade of small decision trees: at a certain level, the tree is built using all points except the positive ones correctly classified by trees in previous levels. The method has been tested using three standard datasets and a novel application.",
    "This paper introduces a new type of classification model called the \"cascading decision tree.\" The cascading decision tree is a rule-based classifier designed to have an overlapping hierarchical structure between its nodes to produce succinct explanations. The paper introduces these models, presents an induction algorithm to learn them from data, and includes an empirical evaluation on three UCI datasets as well as a propietary dataset. The submission includes code.",
    "This paper analyzed the influence of neural network width on the network performances while fixing the total number of parameters. Specifically, the authors introduced several ways to change the model width without increasing the number of parameters, and showed experimentally that for widened networks with a random static mask on weights to keep the number of parameters, increasing the width can improve the performances of the models until the network become very sparse and hard to train. They author theoretically showed that for a not so sparse one-hidden-layer neural network, increasing width decreases the distance to the Gaussian Process kernel corresponding to the infinith-width limit, which partially supports their experimental findings.",
    "In this paper, the authors analyze the enhancements brought by widening networks with the number of parameters fixed. From the experimental side, they conduct various experiments to compare the methods of widening the networks and demonstrate different ratios of widening different networks on diverse datasets. From the theoretical side, the authors relate the training dynamics of neural networks to kernel-based learning, in  the infinite-width limit. As a consequence, the authors claim that wider networks indeed improve the performance of algorithms under certain conditions.",
    "This manuscript provides an intriguing discussion on the different roles that the width and parameter size could play in a neural network. While these two aspects are traditionally treated as -if not identical- correlated, the authors managed to develop a couple of configurations to decouple and analyze both separately. Especially the wide and sparse approach could be a new way to design neural networks that are supposed to be small and expressive at the same time. ",
    "This paper presents an approach to jointly pre-train language models and representations for knowledge graphs. In particular, natural language texts (English Wikipedia) are used to train context representations, while knowledge graphs (Wikidata) train entity representations (and both depend on each other). Experiments show that the approach outperforms baseline methods on several natural language understanding tasks: few-shot relation classification, knowledge graph question answering, and entity classification. ",
    "This work proposes a method for joint pre-training of knowledge graph and text data which embeds KG entities and relations into shared latent semantic space as entity embeddings from text. The proposed model JAKET consists of two main parts: a language module and a knowledge module. The model is pre-trained on a collection of tasks: entity category prediction, relation type prediction, masked token prediction and masked entity prediction. The proposed framework enables fine-tuning on knowledge graphs which are unseen during pre-training.",
    "This paper proposed a new language modeling pretraining method that leverages the knowledge graph information. Specifically, the paper replaces the entity embedding in one hidden layer of BERT context embedding, with the corresponding graph attention embedding that is obtained from the knowledge graph. The pretraining tasks contain not only the language related tasks (like predicting masked tokens), but also the knowledge graph tasks like entity classification or relation type prediction. Experiments on few-shot learning tasks, question answering and entity classification show better performance over other pretraining counterparts. ",
    "This paper proposes to model the generation order as latent variables for sequence generation tasks, by optimizing the ELBO involving a proposed process of Variational Order Inference (VOI). To alleviate the difficulty of optimizing discrete latent variables, the authors propose to cast it as a one-step Markov Decision problem and optimize it using the policy gradient. The authors also introduce the recent developed Gumbel-matching techniques to derive the close-form of the posterior distribution.",
    "This paper aims to decode both content and ordering of language models and proposes Variational Order Inference (VOI). The authors introduce a latent sequence variable z = (z_1, .. ,z_n) in which z_t is defined as the absolute position of the value generated. The authors model the posterior distribution of z as a Gumbel-Matching distribution which is relaxed as a Gumbel-Sinkorn distribution. To training the encoder and decoder networks, the ELBO is maximized using the policy gradient with baseline. The experimental results on Django and MS-COCO 2017 dataset show the proposed VOI outperforms the Transformer-InDIGO, as well as suggests that learned orders depend on content and best-first generation order.",
    "This paper designed a new generative model by capturing the auto-regressive order as latent variables for sequence generation task. Based on combinatorical optimization techniques, the authors derived an policy gradient algorithm to optimize the variational lower bound. Empirical results on image caption and code generation showed that this method is superior than both fixed-order generation and previous adaptive-order method transformer-InDIGO. The authors further analyzed the learned orders on global and local level on COCO2017 dataset, demonstrating that the arrangement tend to follows the best-first strategy.",
    "This paper studies the convergence of stochastic training methods for graph neural networks. Here, this paper views GNN as a compositional optimization problem. Then, to reduce the variance incurred by the neighbor sampling, this paper uses SPIDER to reduce the variance to accelerate the convergence speed. It provides theoretical convergence analysis for SPIDER used on GNNs, showing that the proposed method has a better convergence rate compared with the traditional gradient descent method. At last, this paper conducts experiments to verify the proposed algorithm. ",
    "Node sampling is a crucial point in making GCNs efficient. While several sampling methods have been proposed previously, the theorectical convergence analysis is still lacking. This paper finds that the convergence speed is related to not only the function approximation error but also the layer-gradient error. Based on this finding, the authors suggest to take historical hidden features and historical gradients to do doubly variance reduction. Experiments are done on 5 datasets for 7 baseline sampling-based GCNs.",
    "This paper presents a novel variance reduction method which can adapt to any sampling-based GCN methods (inductive GCNs). The paper draws the idea from VRGCN that integrates the historical latent representations of nodes computed with full Laplacian to approximate the that computed with sampled sparse Laplacian. The variance reduction is implemented on both node embedding approximation, as well as layer-wise gradient computation in back-propagation. The resulting algorithms lead to faster convergence rate.",
    "This paper proposed a single image-based manipulation method (DeepSIM) using conditional a generative model. The authors addressed this problem by proposing to learn the mapping between a set of primitive representation, which consists of edges and segmentation masks, and an image. They also adopted a thin-plate-splines (TPS) transformation as augmentation which enables the model to robustly manipulate an image by editing primitives.",
    "This work proposes a method to design conditional generative models based on a single image. In particular, while some recent models have enabled one to sample (unconditionally) images from a generative model learned from a single image (like SinGAN), this work explores a way of conditioning the generation on a primitive, which can be user-specified. As a result, one can produce realistic modifications to a given image by modifying - or sketching - some primitive.",
    "This paper provides an augmentation method to enable single image training. The network learns to map between a primitive representation of the image (e.g. edges and segmentation) to the image itself. During manipulation, the generator allows for making general image changes by modifying the primitive input representation and mapping it through the network.",
    "Given two input graphs G1,G2 the maximum common subgraph detection problem asks to find an induced subgraph of both G1 and G2, with as many vertices as possible. In the recent years, there have been papers that introduce different heuristics for guiding the search of this subgraph within branch & bound algorithms. The main contribution of this paper is a combination of graph neural network embeddings and RL to guide the search more efficiently.  The function used to guide the deep Q-network is given in Equation (3). The paper performs a set of experiments on synthetic and real world pairs of graphs, where it is shown that it performs well in practice. The supplementary material provides more details on the experiments. ",
    "The motivation of this paper is clear and interesting, as it\u2019s important to explore the maximum common subgraph in biochemical domain. In this paper, the authors conduct a lot of experiments to demonstrate the effectiveness of the proposed method. Despite of this, the presentation of this paper requires improvement because many important details are missing, which makes it hard to follow. The time-complexity analysis might also be crucial to demonstrate the superiority of the proposed method over other baselines in terms of searching time. ",
    "The paper deals with the problem of Maximum Common Subgraph (MCS) detection, following a learning-based approach. In particular, it introduces GLSEARCH, a model that leverages representations learned by GNNs in a reinforcement learning framework to allow for efficient search. The proposed model has been experimentally evaluated on both artificial and real-world graphs, and its performance has been compared against traditional and learning-based baselines.",
    "This paper introduces a supervised neural network predicting a wireframe structure from a 3D point cloud. The network takes a raw unordered 3D point cloud as input, processes it using FCGF architecture, and predicts three types of information: vertex existence in each patch, vertex location, and edge existence for each pair of vertices. In the experiments, the network is evaluated with two datasets, a subset of the ABC dataset and a set of 3D models from Google 3D warehouse. Also, it is compared with the baseline methods using four evaluation metrics, which are created to assess the accuracy of the predicted vertices, edges, and the overall wireframe graph structure. The results demonstrate the outperformance of the proposed method quantitatively and qualitatively.",
    "This paper presents a deep architecture to extract a wireframe model from a 3D point cloud. This is a problem of high interest, and the author claim that the approach they present is the first one to address this task, which is true to the best of my knowledge. Since both the approach and the evaluation are sound, this alone seem to warrant publication. There are however several weaknesses in the paper, and my accept recommendation is conditional to clear answer on each of them:",
    "This paper introduces PC2WF, a neural network that turns 3D point clouds into a wireframe model. PC2WF encodes each point into a feature vector and uses them to predict the candidate corners. After that, line proposals are generated by connecting pairs of corners, and the point features along each line are pooled into its confidence value. By pruning the proposed lines, PC2WF generates the final wireframe represesntation.",
    "This paper studies gradient-based stochastic optimization algorithms which incorporate (estimates of) the noise statistics in the adaptive stepsize design. Starting from the standard analysis of SGD with adaptive steps (Thm 1) the authors show in Cor 1 how, using a second-moment-dependent learning rate, one can \u201caccelerate\u201d (see comment later) the convergence of SGD. Next, the authors show (Thm 3) that one can recover a similar result by estimating the second moment using an exponential moving average.",
    "This paper studies the problem of stochastic optimization where the gradient noise process is non-stationary. Based on a general convergence results based on a general sequence for the second moments of the stochastic gradient norms and a general stepsize sequence, the authors propose to use an online estimation procedure for the gradient norm second moments, in order to mimic the behavior of the ``idealized'' stepsize sequence. Finite-time convergence rates are established for the algorithms with adaptive stepsize, leading to an acceleration effect in certain regimes for the non-stationarity.",
    "The objective of the paper is to provide a theoretical justification for the value of using adaptive learning steps. The paper presents two results. The first is essentially of theoretical interest, and assumes that the noise level indicators defined in Eq. (1) [but which are difficult to understand at this level of the paper] are known. The second is more practical: it shows that a variant of the RMSprop algorithm achieves the same results as the \"theoretical\" algorithm.",
    "This paper proposes to integrate word alignment obtained from SMT into an NMT system. This is an exciting topic not only because it can help interpretability, but also because the same mechanism could be used e.g. for imposing a specific terminology in translations, something that was relatively easy to do with SMT but is much harder to achieve with NMT. The proposed method involves computing word-word alignment using existing SMT models (GIZA and FastAlign in the experiments) and integrating that information in the decoder of a transformer-based NMT model. Experiments on English-Romanian and English Korean show small improvement over a standard baseline.",
    "This work proposes to incorporate word alignment information as a word substitution model. Basic idea is to jointly train a separate encoder using a cross entropy loss which predicts a source input sequence with words substituted by aligned target words. The learned representation is combined with a Transformer either by simple summation, gating or joint attention mechanism. Experimental results on Romanian/English and Korean/English tasks show very marginal gains over the baseline Transformer.",
    "The paper presents a strategy to integrate prior word alignments into NMT models. It is not clear the motivation for this in the NMT context, especially why the prior alignments are crucial information that is necessary to be given a-priori to the Transformer. Besides this, the description of the method and the discussion of related work is given, SMT methods are briefly mentioned but the usage of the idea in previous work, also SMT literature is necessary.",
    "The paper describes a new benchmark for evaluating reinforcement learning techniques (MDP-playground). It can be seen as a toolbox allowing to generate different MDPs with different characteristics. Each MDP will then be used to probe a particular ability of learning algorithms, resulting in a comparison of methods over multiple dimensions. Proposed dimensions are reward sparsity, stochasticity, delayed reward, etc....  In addition to this toolbox, the authors also evaluate some of the classical algorithms in the domain. ",
    "This paper proposes a suite of benchmark tasks designed to test (and possibly debug) reinforcement learning algorithms. Deemed the MDP Playground, these environments are applicable to both discrete and continuous RL agents and allow tuning of various dimensions of complexity - reward delays, reward sparsity, stochasticity, etc. The authors demonstrate their framework by evaluating the performance of many well-known RL agents across a variety of these playground environments. Additionally they conduct similar experiments on Atari and Mujoco tasks and observe similar trends in agent performance when injecting noise, reward delays, and varying action max values. Finally, the MDP Playground is very quick to run and facilitates fast experimentation.",
    "This paper presents \"MDP Playground\", a family of procedurally generated MDPs that can be used to benchmark certain dimension of difficulty considered by the authors to be challenging to current RL algorithms.  The paper presents the effects of the various perturbations to the MDP on state-of-the-art learning algorithms and discusses particular dimension of interest in the paper.  A full and exhaustive analysis of results is presented in the appendix.  The \"MDP Playground\" is slated to be open-sourced so that the community can benchmark against it.",
    "The manuscript discusses the side-effects (or drawbacks) of Isotonic regression and proposes an alternative approach for calibration in regression problems. The authors demonstrate the limitiation of Isotonoc regression such as nonsmooth PDFs and truncation of support under some constructions of the calibration dataset (line 2 in page 4) on a simple linear regression problem (last paragraph before section 4). On the light of these observations, they propose quantile regression (QR) which does not require an additional dataset.",
    "The paper discusses a new calibration mechanism for regression models which produce better model prediction and uncertainty estimates. In Section 3, the paper first discusses some properties and drawbacks of the approach based on isotonic regression in Kuleshov et al., 2018 which uses a post-hoc calibration dataset after model fitting for calibration. Section 4 discusses a new approach based on regularization to achieve implicit regression calibration during model training instead of using a post-hoc processing approach. Section 5 is devoted to experimental results supporting the theory outlined in Sections 3 and 4.",
    "The authors consider the problem of learning quantile calibrated regressions model. A probabilistic regression model is a model that, given an input, outputs a distribution over possible scalar values. A quantile calibrated model is one is such that, for all quantiles $p$, the probability over $X, Y$ that the model predicts $Y$ is in the $p$th quantile is equal to $p$. Machine learning models are not usually calibrated after standard training, so the authors consider a regularization approach to improve the calibration of the model during training.",
    "This paper describes a Deep Variational Bayes Filter (DBVF) for Deep-Learning based SLAM in 3D environments. It builds upon similar work for 2D environments in [Mirchev et. al. 19], and learns a full 3D RGBD occupancy map and a sequence of 6 DoF poses (localization) using raw stereoscopic camera data. Differentiable ray-casting and an attention model is described to access the learnt global map to give a local map and an expected observation - using an emission model from the current pose and local map. A transition model describing the evolution of the dynamics of the agent is also learnt. A variational approximation of the actual posterior (of the sequence of poses and the map, given the sequence of observations) is learnt by optimizing the standard ELBO equation from Variational Bayes. Such deep generative models, once learnt (in an unsupervised way) for an environment, allows one to hallucinate a sequence of poses and observations, given the learnt map and control inputs. This allows downstream robotic control tasks like environment exploration and path planning to be integrated into the model. Experiments on a simulated dataset with a flying drone in a subway and living room environments demonstrate good SLAM performance (that approach traditional methods): bird's eye view projections of the 6 DoF poses and the emitted maps closely match the ground truth poses and the occupancy grid. This is a well-written paper that represents a good step up from [Mirchev et. al. 19] to formulate a DVBF with realistic RGBD data streams. The authors mention that the computational times for this method is still far from conventional SLAM techniques - an actual quantification of the time taken during inference would be useful.",
    "This paper addresses the problem of dense RGB-D SLAM. The key idea is to formulate the problem as a deep state-space model and infer the state of the latent variables (i.e. pose and geometry) using variational inference. The experiments demonstrate that the method performs well in a challenging quadcopter dataset. However, the advantages of the approach are not demonstrated. ",
    "This paper presents a novel learning-based visual-inertial odometry algorithm. The algorithm simultaneously reconstructs the world map as well as the states of the agent from the stereo RGBD sensors.  The world is modeled as an occupancy grid with color. A graphical model with attention mechanism and ray casting is used to model how the world and the agent state renders the RGBD sensor data. ELBO is used to optimize the model. The technical details look sound to me.",
    "This paper is studying the problem of learning to interpret manuals / textual information about the task, with the goal of faster learning and generalization in RL. Unlike recent prior work (Narasimhan et al 2018, Zhong et al 2020) where the entities in the environment are already partly grounded to text (e.g. by representing them as their textual description), the agent here needs to learn the mapping between entities and corresponding text. In order to study this problem, the authors use a new environment and dataset of natural language descriptions, as well as propose a self-attention model that matches entities to relevant sentences. The proposed model performed comparable to a partly grounded policy (as in Narasimhan et al 2018).",
    "The paper considers the task of training an agent to act following a manual expressed in natural language. The manual describes the roles and the behaviors of the entities in the environment. Each entity can be the goal, the message or the enemy and it can also be either fleeing, chasing or not moving. The agent has to bring the message to the goal while avoiding the enemy. A model called EMMA is proposed to change entity representations based on the manual, thereby making the agent aware of the entities\u2019 roles. It is shown that EMMA is more effective than simple baselines.",
    "Natural language grounding is an interesting research direction and has attracted many researchers in recent years. Previous work mainly considered grounding the text to image objects. This paper considers collaboratively to learn \u201centity\u201d representations and natural language explanations with a reinforcement learning framework. Specifically, a multi-modal attention network is proposed to model the interaction between the entity representation and the text descriptions. The entire framework is trained over multiple games in a multi-task manner. Experiments are conducted on a newly designed benchmark. The proposed RL framework achieves reasonable performance in domain games (training & test are from the same games) and also has a strong zero-shot generalization to unseen games and \"entities\" (thanks to the parameter sharing and multi-task learning). Besides, the newly released dataset may facilitate future research in natural language grounding.",
    "This paper presents AVEC, a new critic loss for model-free actor-critic Reinforcement Learning algorithms. The AVEC loss can be used with any actor-critic algorithm, with PPO, TRPO and SAC being evaluated in the paper. The loss builds on the mean-squared-error, and adds a term that minimizes $E_s [f_{\\\\phi}(s) - \\\\hat{V}^{\\\\pi_{\\\\theta_k}}(s) ]$. The addition of that extra term is motivated by recent research on the stability of actor-critic algorithms, and the benefits obtained by the AVEC loss are empirically demonstrated in numerous environments, with AVEC+PPO, AVEC+SAC and AVEC+TRPO.",
    "The paper explores an alternative loss function for fitting critic in Reinforcement Learning. Instead of using the standard mean squared loss between critic predictions and value estimates, the authors propose to use a loss function that also incorporates a variance term. The authors dub the approach AVEC. The authors combine their approach with popular RL algorithms such as SAC and PPO and evaluated on the standard benchmarks for continuous control.",
    "The paper proposes a simple and elegant idea for changing the value function objectives in deep RL and demonstrates reasonable empirical evidence of it's potential usefulness.  The authors also provide a clearly articulated intuitive motivation and provide experiments to support the proposal.  The idea complements several other algorithms and is therefore quite widely applicable (and easy to try). The analysis of the experiments is also quite interesting and clearly presented. ",
    "This paper aims to empirically explore the depth dependence of overparameterized networks. The authors study fully-connected networks trained on a synthetic dataset consisting of random Gaussian inputs, with the label a simple function of the input. In one case, for \"local\" labels, the label is the parity of a product of a subset of the components. In the other case, for \"global\" labels, the label is a sum of such products of subsets with coverage over all the components. Broadly, the authors find that deeper MLPs are better able to learn the local labels, but shallower MLPs are better able to learn the global labels. Finally, the authors compare these results to the infinite width NTK and show that the NTK does not at all capture the behavior of the finite networks.",
    "This paper analyzes overparametrized networks evaluating how depth and width affect the generalization performance of the network. A set of experiments is designed in which labels are determined either by local or global interactions among the features, and generalization is observed for different values of width and depth of the network. NTK is also considered as a limit case of a network with infinite width.",
    "Recent theoretical study on the training of neural networks has introduced an important kernel function called neural tangent kernel. This paper studies the training of deep ReLU networks and compares it with the training directly using NTK by conducting experiments on synthetic data. Based on the experimental results, the authors conclude that deeper networks perform better on certain datasets whose labels are more \u201clocal\u201d, while shallower networks are better at more \u201cglobal\u201d labels. Moreover, the authors observed that finite-width networks have better generalization than NTK. ",
    "This paper studies the benefit of few-shot learning for sample complexity, when all the tasks (both source and target task) share the same underline representation. Under some assumptions on the data and tasks, this paper improves the previous result based on the iid task assumption and shows that they can utilize all source data. The considered models include linear model (both low dimensional and high dimensional representation) and two-layer neural network.",
    "The paper aims at justifying the success of few shot learning methods that work based on finding a shared representation among a number of tasks. A serious theoretical challenge is that, even if we assume such a representation exists (and belongs to a predefined class of functions with controlled capacity), we would still need to assume something that connects the source tasks with the target task. Previous work has considered \"i.i.d. tasks\", however, the obtained bounds were not natural in the sense that we don't have the usual decrease in the error as we increase the size of the training set of the source tasks. Under a different set of assumptions, the authors show that, in a sense, one can \"fully\" exploit the training data from the source tasks. ",
    "This paper presents some new theoretical insights into a two-layer (linear or non-linear) network based meta-learning framework for dimension reduction and few-shot linear regression. In the considered problem setting, the hidden layer for feature extraction is assumed to be shared across the training and test tasks, and the output layer is optimized in a task-specific way with quadratic loss. For well-specified low-dimensional linear representation learning models, statistical analysis shows that when the tasks are sufficiently divergent, the excess risk of the target task estimator has a near-optimal rate of convergence, up to a near-optimal statistical error of meta-training. The corresponding results for well-specified high-dimensional linear representation and neural networks have also been derived under additional regularization conditions.",
    "The present paper proposes to consider features derived from PCA for the purposes of adversarial attack and defense. They argue that, based on these features, they can verify larger neighborhoods and provide stronger attacks. The neighborhoods are based on the ERAN verifier and the attacks are in comparison to a recent attack called AutoZoom. Defense performance is measured in number of images in the neighborhood, and attack performance in terms of L2 distance.",
    "The authors study the problem of adversarial robustness, aiming to find regions of the input space for which a classifier is robust. Instead of the standard approach of defining a neighborhood around each data point based on some $\\ell_p$-norm, they use PCA to identify directions along which the model is robust or brittle. They then use these methods to identify large regions of input space for which models are robust and, in a complementary direction, to craft imperceptible adversarial examples with few model queries.",
    "The overall quality of the paper is good. This paper proposed a feature perturbation procedure, as a comparison to the commonly used perturbation to the original input data. Given access to a feature mapping and a black-box classifier, the proposed procedure is able to select the most robust/weak features. This then can be used for two important tasks: to determine a robust neighborhood for a data point using the robust features and to design adversarial examples using the weak features. For the first task, the feature-based robust neighborhood proposed by this paper is shown by experiments to contain far more points than the traditional input-based neighborhood. For the second task, the feature-based adversarial examples require less query to the black-box classifier and have less distortion from the original data points compared with other competitive methods, and thus are more human-imperceptible. These characteristics make the procedure appealing.",
    "In this paper, the authors present a new multi-task reinforcement learning (RL) algorithm. Since In general, the relationships between tasks is unknown a-priori, directly applying classical multi-task learning approaches that assume all tasks are related, could suffer from negative transfer. The authors propose to cluster tasks into disjoint groups: The proposed algorithm iterates through steps of assigning tasks to specific policies and training each policy only based on the respective assigned tasks (clusters). In the experiments, the authors compare their algorithm with two single-task learning baselines (SP: a single policy for all tasks and PPT: a policy per task) and a recent multi-task RL algorithm of Eramo et al. 2020 on Pendulum, Bipedal Walker, and Atari problems.",
    "This paper proposes a multi-task RL algorithm that leverages unsupervised task clustering. The authors propose to initialize a number of policies, cluster each task based on its performance on different policies, and train each policy with data coming from tasks within the cluster. The paper shows that such kind of an EM style clustering can lead to better performance than single-task training and be more sample efficient more training each task independently on both tabular settings, continuous control experiments, and Atari. ",
    "The authors propose to approach multi-task RL problems in which tasks may differ considerably in transition functions/dynamics and reward functions as well as in the action space through task clustering. Specifically, tasks are modeled as belonging to separate task clusters defined by the return obtainable by individual policies i. All policies are evaluated on a single task and the relative cumulative discounted rewards over some iterations determines the assignment of tasks to policies. Simulations show the advantage in terms of number of training iterations on several tasks compared to a selection to other related algorithms. ",
    "This paper proposes a self-supervised encoder-discriminator based framework for embedding the multivariate time series into a compact fixed dimensional representation. The approach dubbed Temporal Neighborhood Coding (TNC) leverages the concept of a neighborhood in time (with stationary properties), and learns time series representations by ensuring the distribution of neighboring signals is distinguishable from the distribution of non-neighboring signals, in the encoding space. Empirical evidence is provided that such embedding of time series results in clusters of higher quality, as well that use of such obtained representations for supervised tasks outperforms few competitor (unsupervised) approaches. ",
    "The authors propose a novel unsupervised encoding scheme for time series. Utilizing a statistical test for non-stationarity, the authors derive a Temporal Neighborhood Coding (TNC) scheme and combine it with ideas from Positive-Unlabeled (PU) learning to learn informative hidden representations of time series windows. The representations are evaluated in terms of how well they can be clustered and how much they influence classification performance on three data sets. The supreme performance was demonstrated when comparing to the state of the art methods and a $k$NN (for classification) baseline. Furthermore, the authors illustrate how the learnt representations remain interpretable as long as the encoding network is reasonably small. ",
    "The paper proposes an unsupervised representation (embedding) learning method for time-series. While unsupervised representation learning has been extensively studied and shown good performance in fields like NLP and vision, it is relatively new to the time-series community. This paper, in contrast to recent work (CPC and Triplet-Loss), has the following differences:",
    "This paper presents a method of composing stacked neural network blocks by linearly combining module \"template\" weights.  The work extends \"isometric networks\", in which each block in the stack has the same operational structure, by parameterizing each block using a mixture of the weights from a bank of K blocks (\"templates\").  In multitask learning experiments, the mixtures naturally learn to share common components between tasks, while learning task-specific components where needed.  Further experiments describe behavior of the system applied to transfer learning and domain adaptation scenarios.",
    "The authors propose a method to design network architectures as a combination of network components. Their idea consists in imposing an architecture that is a sequence of identical network blocks, and learn a series of templates, which provide an instantiation of model weights for one such network block. Model weights are then estimated for a specific task as a linear combination of a set of template weights. ",
    "This paper considers \u201cmodular multi-task learning\u201d where parameters in each layer/task are generated as a (layer/task-specific) linear (mixture) combination of a common pool of parameters. Exploring this idea, several observations are made: (1) single task isometric model performance on ImageNet can be improved, (2) Multi-task learning is supported and parameter sharing (selecting same mixture components) emerges in early layers, with specialisation emerging in later layers. With multi-domain learning, the opposite effect is achieved with domain-wise specificity arising in earlier layers, and sharing in later layers. (3) Parameter-efficient transfer learning is supported by fine-tuning the task-specific weights for new tasks. (4) Parameter-efficient domain adaptation is supported by optimising the task-specific weights for new domains. ",
    "The paper considers Gaussian VAEs and their tendency to suffer from posterior collapse. In particular, the authors analyse the impact of the usually fixed covariance $\\sigma_x$ of the decoder Gaussian on the learned encoder variance. They show that the former can be seen as a regulariser for the latter and therefore impacts the \"smoothness\" of the encoder. The authors hypothesize that a large value of $\\sigma_x$ causes posterior collapse as a consequence.",
    "This paper studies the Gaussian VAE and figures out that the decoder variance regularizes the VAE and affects the model smoothness, and an inappropriate estimation of this parameter would raise posterior collapse, which is supported by theoretical analysis and empirical demonstrations. Hence, this paper then proposes an ELBO with adaptive decoder variance to avoid oversmoothing the model. Overall, the idea is interesting and provides some new insights for our community. The major concerns regarding this paper are listed as below.",
    "This paper analyses the \"posterior collapse\" phenomenon observed in training latent variable models (in particular Variational Auto-Encoders), and propose a new training objective to remedy the problem. The theoretical analysis of the authors suggests that the posterior collapse is induced by an inappropriate choice of variance in the decoder distribution. The new objective they propose, the AR-ELBO, jointly optimises this variance along with the usual network parameters. The authors demonstrate that their objective yields relatively good results on image modelling, compared to other standard VAE methods.",
    "This paper proposed a deep generative model based on the non i.i.d. VAE framework in an unsupervised version. The model which combines a mixture prior in the local latent space with global latent space has three advantages: First, the latent space can capture interpretable features. Second, the model performs domain alignment. Third, the model can discriminate among their global posterior representations. Although this paper has mild improvement on the basic VAE structure, the model displays a good interpretability power, and the setup of the latent variables are illustrated reasonably in the paper.",
    "This article introduces a VAE-based method for separating local variation factors from global variation factors in the data in an unsupervised manner. It achieves so by designing a graphical model with a mix of example-local and batch-shared variables, and training it using the ELBO. The article provide an detailed experimental analysis on MNIST and CelebA, and experimental evidence that all parts of the model (notably the discrete d variable) are relevant.",
    "This paper presents a novel deep generative model based on noni.i.d. variational autoencoders that captures global dependencies among observations in a fully unsupervised fashion. The proposed model combines a mixture model in the local or data-dependent space and a global Gaussian latent variable, which captures interpretable disentangled representations with no user-defined regularization in the evidence lower bound. The proposed model is being evaluated in two tasks: (1) disentanglement, and (2) domain alignment.",
    "This paper proposes to improve upon unsupervised representation learning for various downstream vision tasks by leveraging human motion and attention (gaze) information. The authors collect a large spatio-temporal dataset with gaze and body motion labels for this task. They train a network to jointly predict the visual focus of attention in scenes and body motion besides visual instance recognition via an NCE loss to learn good visual representations. They show large improvements in accuracy of many different visual recognition downstream tasks with their approach versus the SOTA MOCO approach, which uses visual information only.",
    "The main aim of the paper is to make use of human interaction/motion to learn a visual  representation that can be re-used for classic visual tasks such as depth estimation. The authors claim that by encoding interaction and attention cues in the self-supervised representation, the method can outperform visual-only state-of-the-art methods. To study the interaction element, the authors attach sensors like Inertial Movement Units (IMUs) to the limbs of subjects and monitor their reaction to visual events in daily life. The paper also introduces a new dataset of 4260 minutes of human interactions by 35 participants which include synchronized streams of images, body part movements, and gaze information.",
    "The paper uses a combination of visual, human gaze and human motion sensors to build representations that perform better on downstream tasks such as action recognition, physics prediction and depth estimation than representations extracted from solely visual input. The paper announces the release a new data set of aligned visual images, eye gaze fixations and IMU motion readings from test subjects walking around an environment. Representations are computed using three different forms of information simultaneously. Given a visual input, the system tries to predict the location of eye gaze in image frame coordinates, whether each of 6 groups of motion detectors are active or not (head, torso, legs, etc.) and the result of a more traditional auxiliary visual pretext task. In this work, the paper uses \u201cinstance discrimination\u201d where representations of augmented versions of a specific image are pushed close together in latent space and far away from augmentations of other images. Tests on diverse benchmarks show that the gaze and motion prediction improve over visual pretext tasks alone and that there is a small benefit to using both together, but it is not additive. The paper also shows the benefit of gaze and motion is present for two different visual auxiliary tasks.",
    "This work investigates the intriguing phenomenon where pretraining on one task hurts the finetuning performance of another. Besides being interesting in general, this phenomenon has practical relevance as pretraining becomes increasingly popular with large-scale models. Here, the authors present a clean case for \u201cnegative pretraining effect\u201d on images, and propose three ways to mitigate it.",
    "This paper conducts an empirical study to examine the well-known negative transfer phenomenon (termed as a negative pretraining effect in this work) in neural networks. In particular, a network trained on a sequence of tasks performs inferior to a network trained from scratch on the intended target task. The main idea of the paper is to study this phenomenon by formulating and intervening on different constituents of the sequential learning process - (1) changing the learning rate across tasks, (2) number and type of tasks encountered in the learning process, and (3) resetting the model biases when going from one task to another. The paper conducts experiments on four visual classification datasets (CIFAR-10, FashionMNIST, MNIST, SVHN) and report their findings for sequential training of ResNet-18 architecture. They show that increasing the learning rate after training on the first task can alleviate the negative pretraining effect. They further showcase how different task discretization and resetting model biases help to reduce the effect. ",
    "The authors study what they call a negative pretraining effect = models pretrained on task 1 and tuned on task 2 sometimes underperform compared to just training on task 2 from scratch. This is an important factor in many forms of life long learning, multi-task learning and curriculum learning. They investigate 3 potential remedies / setups: a) using different learning rates for task 1 and task 2, b) changing from task 1 to task 2 more smoothly, and c) resetting network biases at different stages of the process. The perform with a single ResNet18 architecture on MNIST, Fashion MNIST, SVHN and CIFAR-10.",
    "This paper aims to improve adversarial robustness of the classifiers in a different perspective than the existing works. Usually, the networks are trained using adversarial examples to improve robustness (adversarial training). This work extend this line of thought and make an input robust to adversarial attacks. Instead of updating the network, they make updates to the input to gain robustness. In other words, this work explore the existence of safe spots near the input samples that are robust against adversarial attacks. Results on CIFAR-10 and ImageNet reveals that there exists such safe spots which are resistant to adversarial perturbations and improve adversarial robustness when combined with adversarial training (the authors term it as safe-spot aware adversarial training). Based on this approach, the authors also propose out-of-distribution detection method that outperforms previous works.",
    "This paper proposes a new adversarial framework where the defender could preemptively modify classifier inputs to find safe spots that are robust to adversarial attacks. They then introduce a novel bi-level optimization algorithm that can find safe spots on over 90% of the correctly classified images for adversarially trained classifiers on CIFAR-10 and ImageNet datasets and show that they can be used to improve both the empirical and certified robustness on smoothed classifiers. Besides, they propose a new training scheme based on their conjecture about safe spots for out-of-distribution detection which achieves state-of-the-art results on near-distribution outliers. ",
    "The authors argue that there are some safe \"spots\" in the data space that are less prone to adversarial attacks. The authors propose a technique to identify such \"safe spots\". They then leverage them for robust training and observe higher robust accuracy than baseline. Finally, they leverage this observation to identify out of distribution data. ",
    "This paper introduces a new convolutional approach to directly process raw spatiotemporal (ST) point cloud data. The proposed point spatio-temporal (PST) convolution operates on \"point tubes\" and decouples space and time through a shared spatial convolution at each timestep, followed by a temporal convolution. It also introduces a transposed PST to enable point-wise predictions in an encoder-decoder framework (PSTNet). The presented experiments demonstrate the effectiveness of these convolutions by using PSTNet for action recognition and semantic segmentation on point cloud sequences, showing improvement over relevant recent work.",
    "The paper introduces point spatio-temporal convolutions, which are used for the feature extraction of point cloud sequences. A trainable kernel is used which is applied locally as a continuous convolution. An important aspect is that the temporal dimension is processed separately, with an additional convolution, instead of simply using a 4D convolution. The authors claim that in this way the network will achieve a better understanding of the dynamics of the input.",
    "This paper aims to process the point cloud data in a convolution manner. The authors propose the PST convolution and deconvolution operations to handle the different tasks such as the classification and segmentation on point cloud. The extensive experiments verify the effectiveness of the proposed method and achieve state-of-the-art results on multiple benchmark datasets. Overall, the paper is well-written and organized. ",
    "AdaSpeech is a paper on practical TTS custom voice adaptation with the aim of reducing the amount of adapted parameters per voice to allow cloud serving of a large number of custom voices while maintaining high adaptation quality and similarity. The novel piece that enables this is the conditioning of layernorm in the model on the speaker embedding. The grammar reads slightly awkwardly in places, but the paper is understandable and well structured. Descriptions of the model, experiments, and analysis of results are well done.",
    "The authors propose an interesting text-to-speech adaptation method for high quality and efficient customization of new voice. The proposed method consists of two-stage modeling : multi-phonetic-level acoustic condition modeling and conditional layer normalization. In the first stage modeling, the authors proposed a new phoneme-level acoustic condition modeling in addition to the speaker and utterance-level approaches. In the second stage modeling, they employ conditional layer normalization for efficient adaptation.",
    "In this paper, the authors present AdaSpeech, a TTS system that can adapt to a custom voice with a high quality output and a low number of additional parameters. The model is based on the TTS model in FastSpeech 2, with several additional components. The authors show that AdaSpeech has improved results over other baselines. They also provide an interesting ablation study.",
    "This paper proposes effective gradient flow (EGF), which is a layer-wise normalized gradient flow. Compared to (unnormalized) gradient flow, the paper shows that the proposed EGF is (slightly) better correlated with metrics like test loss and test accuracy (see Table 1). Given that this claim is supported with experimental results, the paper would become much stronger if a larger number and a more diverse set of data-sets were used (in addition to CIFAR-10 and CIFAR-100, which are two very similar image-data-sets) as to show that the claim holds more generally. Apart from that, given that the correlations are (only) about 0.4 in Table 1, it seems that only some aspects are explained by EGF. ",
    "Recently, initialization has been found critical to the model accuracy attained by sparse training [1]. In this paper, the authors studies the impact of factors other than initialization on the model accuracy attained by sparse training relative to dense training (under the same model parameter count). At the core of this paper, the authors argue that the effective gradient flow (grad norm from only activate model weight dimensions) is an effective indicator on the model accuracy attained by sparse training. Firstly, the authors show that the effective gradient flow attains higher correlation with model accuracy than the norm of full gradient (including gradients on sparsified weight dimensions) in sparse training. Secondly, the paper empirically demonstrate that in sparse training, 1) weight decay and data augmentation can hurt model accuracy, 2) batch normalization plays significantly role for model accuracy in sparse training and 3) non-saturating activations boost the magnitude of effective gradient flow and consequently improve model accuracy. ",
    "This paper looks at how choices in optimization affect how well you can train sparse networks. The authors come up with a new measure of effective gradient flow, which is important for good performance. They also compare sparse vs. dense networks across various optimizers, hyperparameters and activation functions, and find that batch norm and certain activation functions are beneficial for sparse networks",
    "The manuscript proposes a unified model which combines label propagation algorithm (LPA) and graph convolution network (GCN). The main idea is to optimize edge weights (after making edge weights trainable) by maximizing the intra-class feature influence. Introducing the theorems on the relationship between feature and label influence, and LPA\u2019s prediction, the authors propose the unified objective function (a summation of the GCN loss and LPA loss) which combines both methods.   ",
    "This paper addresses the problem that edges in a graph could be noisy, containing erroneous edges. With the assumption of GCN that \u2018labels/features are correlated over the edges of the graph\u2019, it is desired that weights of inter-class edges are large, and those of intra-class edges are small. Hence, these noisy edges could impair GCN\u2019s performance.",
    "This paper aims to combine the label propagation and graph convolutional network with the modeling of their latent relationships. In the developed model, the node label is utilized to infer the edge weights between different nodes. From the evaluation results in Section 4, the performance improvement between the proposed method GCN-LPA and GDC is marginal, which can hardly demonstrate the advantage of the unified model (with GCN and LPA) over the graph diffusion network (without the restriction of information aggregation over neighboring nodes).",
    "This paper studied a novel perspective on generalization error bounds, by introducing the \"label generating function \"(LGF). Several new complexity measures (correlated Rademacher complexity, co-complexity, invariance co-complexity, dissociation co-complexity, Rademacher smoothness) were proposed. The properties of the measures and generalization error bound with respect to these complexity measures are studied.  ",
    "The paper provides an interesting perspective to view generalization error for the machine learning model. In particular, it proposes to investigate the constraint on the label generating function space. They propose a concept of co-complexity analogous to the entropy-ish concept which measures complexities between two function spaces. This co-complexity can be decomposed into two parts which measure the categorization ability of the classifier in generator and extent level in classifier for the invariance transformation in the generator.",
    "This paper aims to propose a new complexity measure, called co-complexity, to control classifiers' generalization gap. This new measure acts like a joint-entropy and leads to tighter bounds on the generalization error in this setting. The main idea is to extend the classical complexity measure of Barlett & Mendelson (2003) by introducing a new function space: the generator space is defined as the function space of all possible LGFs satisfying ad hoc constraints. Thus, the authors claimed to be able to measure the extent to which the classifier's function space obeys the invariance transformations in the data and measure the extent to which the classifier can differentiate between separate categories in the data.",
    "This paper proposes BRECQ which is a new Post Training Quantization (PTQ) method. The goal of the paper is to push the limit of PTQ to low bit precision (INT2). They try to address this by considering both inter and intra-layer sensitivity to find the best update to the model parameters so that the output from a block is minimally changed/perturbed. Furthermore, the authors also consider mixed precision quantization setting.",
    "This paper explores the post-training inference quantization. Based on second-order quantization error analysis, it proposes to reconstruct quantized model in a block level to achieve SOTA accuracy for INT2 weight quantization, which distinguish this paper from previous reported layer-wise reconstruction approach. The proposed approach is intuitive and supported by extensive experiments across a wide range of image classification and object detection tasks.",
    "I couldn't follow the method described in the paper. The authors are basically trying to address post-training quantization by perturbing the the weights of a trained DNN. The goal is to perturb the weights so that the quantized DNN will behave similar to the original full-precision DNN. The authors draw a link between this optimization problem and optimizing for the \"reconstruction\" of the output activations of a block (see Equation 7). The technique BRECQ, shown in Algorithm 1, is basically to optimize the perturbation of the weights for the right hand side of Equation 7 for each block of a DNN.",
    "\tThis paper discussed how data properties (e.g., label noise, label imbalance, data size) affects calibration error. The author designed experiments on varying computer vision datasets (i.e., cifar10, cifar100, eurosat and iNaturalist) qualitatively: 1) calibration error for various individual classes under class-imbalance situation; 2) calibration error for different scale of label noise; 3) calibration error under non-uniform noise; 4) calibration error under various scale of dataset size; 5) Calibration error under different combinations of data augmentations. The experimental results show that poor calibration performance accompanies with large noisy label rate, large imbalance ratio and small dataset size. For the reason of small dataset size causing poor calibration error, this paper provided the theoretical proof. ",
    "This work is an empirical survey of the calibration problem with convnets. The authors use several existing benchmark datasets and create synthetic class-imbalance for datasets that are initially balanced. They then extend the well-known results on higher prediction error of minority class, to its calibration error. The work investigates several existing methods that alleviate prediction error in imbalanced datasets and examine their effect on calibration error. At last, the effect of dataset size and data augmentation on calibration error is reported. Later on, the effect of random label noise is also examined. The observations, although not surprising, have not been reported before ",
    "In this work, authors demonstrate that dataset properties can significantly affect calibration and suggest that calibration should be measured during dataset curation. In the field of applied AI to real-life problem, we face all the time decision-makings on what is the most effective strategy in the pipeline (eg. sampling, noise, labeling) and this paper present some evidence for those decisions.",
    "The paper investigates emergent gesture-based communication in Embodied Multi-Agent Populations. A noticeable feature of the paper is that it investigates emergent communication in the case of non-uniform distribution of intents and costly communication (i.e. agents are penalized for effort). The authors find that in certain scenarios, these conditions may lead to communication generalization of learned communication strategies to new, previously unseen agents.",
    "The paper deals with agents that communicate non-verbally via actuating their joints in a 3D environment. The authors show that the agents should be able to learn protocols that can generalize to novel partners. Furthermore, the authors find that the current training approaches are brittle, and they propose and evaluate approaches to address this challenge.",
    "The authors study the zero-shot emergent non-verbal communication in this paper. Different from most papers on emergent communication. this paper uses the motion of three-joint agents. The agents meet partners that they have never seen in the training phase, presenting the challenge of the universal protocol. To make a universal protocol possible, the authors study intents sampled from Zipf distribution and energy regulation. The authors conducted experiments on tasks with 2, 5, 10 intents. The results show that providing latent energy feature is essential for zero-shot coordination. To achieve better than chance accuracy on tasks with 10 intents, a torque curriculum is needed. ",
    "In this paper, the authors propose a technique for uncertainty estimation in regression with neural networks. The basic idea is to use an auxiliary \"meta model\" that (in the authors' best performing setting) has access to the base model and is trained jointly with it. The purpose of the meta model is to predict the error characteristics of the base model, which of course naturally leads to error bars. In order to account for the fact that the models errors on the train set are unlikely to be representative, the authors make use of a validation set on which the meta model is trained further. ",
    "In this work, the authors present a meta-modeling approach to provide predictions with uncertainty estimates in a sequential task. They develop a white box, black box, and joint modeling method that allows them to apply their method to a variety of scenarios. These methods differ based on the amount of information provided to a meta-learner which has the goal of predicting errors $\\hat{z} \\in \\mathbb{R}^{D \\times M} $. The authors also incorporate the ability to make asymmetric uncertainty bounds. They apply this method and many baeslines to two datasets: MITV and SPE9PR.",
    "This paper describes a method to generate symmetric and asymmetric uncertainty estimates. The method is proposed to work for the non-stationarity processes found in real-world applications. The paper introduces a meta-modelling concept as an approach to achieve high-quality uncertainty quantification in deep neural networks for sequential regression tasks. The paper also introduces metrics for evaluating the proposed approach. A proposed meta-modelling approach is related to the work of Chen et al. (2019) which is mainly used for classification task in a non-sequential setting, however, the proposed method is mainly for the sequential setting. ",
    "The paper introduces a novel unbalanced Gromov-Wasserstein type problem. The Gromov-Wasserstein distance is very useful in practice for comparing probability distributions that do not lie in the same metric spaces. It has recently found several successful applications in ML for computational chemistry, graphs comparisons or NLP. Following previous works on unbalanced optimal transport (i.e. soft constraints over marginals enforcement of the coupling matrix), and the rationale that disposing of unbalanced versions of transport problems can alleviate in some ways presence of outliers or noise in the distributions, the authors propose two \u2018unbalanced\u2019 variants of the Gromov-Wasserstein (GW) problem, that allow comparison of metric spaces with arbitrary positive measures up to isometries (I.e. rigid transformations). ",
    "The authors consider the Gromov Wasserstein (GW) problem for metric measure spaces having different masses (i.e., Unbalanced GW). Similar to the ideas of unbalanced optimal transport (UOT), they proposed to use a quadratic divergence to relax the marginal constraints (instead of divergence as in UOT). When divergence is KL, the authors derive a GPU-friendly algorithm for the UGW  which relies on the unbalanced Sinkhorn algorithm. Additionally, the authors also propose a variant of UGW, namely Conic Gromov-Wasserstein (CGW) to address the different masses of metric measure spaces. The authors propose that CGW has nice properties (Theorem 1). However, there is no algorithm to solve the CGW yet.",
    "In the paper, the authors propose two versions of Gromov-Wasserstein distance when the weights of measures do not need to sum up to one. The first version, named Unbalanced Gromov-Wasserstein (UGW), is a direct application of unbalanced optimal transport (UOT) to the setting of Gromov-Wassertstein. The second version, named Conic Gromov-Wasserstein (CGW), is an extension of the conic formulation of UOT to the setting of Gromov-Wasserstein. The authors also show that CGW is a distance in the metric-measure spaces and is an lower bound of the UGW. Finally, the authors also provide some experiments with their proposed divergences.",
    "The submission deals with eliminating neurons in a network where either a) all the input connections xor b) all the output connections have been pruned. When this is the case, the unpruned a) output or b) input connections are unused and can also be pruned: and the freed parameter budget used for other more useful connections. This is shown to improve the accuracy of pruned networks at a given sparsity ratio, especially for very high levels of sparsity.",
    "The paper proposes to remove dead neurons and their connected parameters through a very simple check while reviving pruned (salient) parameters up to the prespecified sparsity level, such that the sparse network obtained could perform better. The main (and perhaps the single major) contribution of this work is in its demonstration that such a simple method is indeed effective for different pruning methods on various network architectures and datasets. The proposed method (AAP) can perhaps be considered as a generic post-processing step that could be equipped to any pruning method leaving dead neurons.",
    "This work proposes a novel pruning method, called all-alive pruning (AAP), which is a general technique to remove dead connections from pruned neural networks. AAP is broadly applicable to various saliency-based pruning methods and model architectures. AAP equipped with existing pruning methods consistently improves the accuracy of original methods on three benchmark datasets.",
    "In this paper, the authors propose an image attribute editing method by manipulating the GAN latent vector. Specifically, this paper uses a pre-trained GAN to synthesize images, a pre-trained regressor to get the image attributes, and trains a network T to find meaningful latent-space directions. It then edits image attributes by modifying the input latent vector, described as z' = z + T(z)\u03b5. The experimental results show that the proposed method performs better than other selected methods to some degree.",
    "This paper presents a new approach for the semantic image editing task by allowing the controllable transformation on the latent space. Authors proposed to integrate an attribute regression network for training the transformation functions. The local transformation T is learned from a simple MLP conditioned on the latent vector z. Two outputs of the regression module for the original latent vector z and the transformed one z+T*epsilon are used to minimize the cross-entropy loss. Experiments validate the effectiveness of the proposed method in terms of manipulation quality.",
    "The paper proposes a new simple, yet powerful and alternative method of editing the semantic attributes of images generated using pre-trained GAN models as well as a pre-trained regressors. The approach allows for the manipulation of single or multiple various image attributes, while preserving the identity of the original image in contrast to the baseline method of Shen et. al 2019. The method focuses on the manipulation of the latent space, in contrast to the popular image space editing methods. ",
    "The paper proposes an improvement to sequence generative adversarial networks (GAN) to cope with the common training issues of GANs. For the sake, the paper combines Gumbel-Softmax based GAN, relativistic discrimination  function with  the matching of mean representations of true and generated samples in a latent feature space. This feature statistics alignment allows to leak information from the discriminator to the generator as the used features are extracted from the discriminator network. Experimental evaluations on synthetic and real datasets show the improvement achieved by the proposed method over existing sequence generation networks.",
    "The paper addresses the task of improving GANs for sequence generation and proposed a method based on the relativistic discriminator. The proposed method employs a Feature Statistics Alignment (FSA) paradigm to reduce the gap between real and generated data distributions. It relies on the relativistic discriminator for \"coarse\" differences and FSA for \"fine-grained\" differences between real and generated data distributions. It is evaluated on synthetic and real datasets, and it significantly outperforms the baselines. It also outperforms baselines on human evaluation based on the acceptance, grammaticality, and meaningfulness of the generated sentences. ",
    "This paper proposes a new GAN-based text generation method that incorporates feature statistics alignment and gumbel-softmax for reparameterization to deal with mode collapse and unstable training. For feature statistics alignment, the authors design two methods such as mean square and mean distance alignments. They evaluate the proposed method on a synthetic dataset, MS COCO caption, and EMNLP2017 WMT news dataset, comparing them with RL-based and non RL-based models. With extensive experiments including ablation studies, the proposed method show promising results.",
    "This paper proposes an extension to DQN, more generally applicable to value-based deep RL systems, that encodes the return using a thermometer encoding with exponentially-sized bins. This enables returns of vastly differing magnitudes to be learned without hurting performance. The authors propose an algorithm for learning these encode returns, including the use of a variance scaling term to speed up learning.",
    "This work describes and addresses the issue of _reward progressivity_ in reinforcement learning, where as the task progresses the scale of the reward changes. The authors argue that reward progressivity harms Q-learning when training signals arising from large rewards interfere with those arising from smaller rewards. They propose a form of reward decomposition with an analogous modification to the Q-network output, which together help to ensure that training losses from small and large rewards are similarly scaled. The authors present a handful of experimental results demonstrating that their proposed method outperforms two other reward re-scaling baselines when reward progressivity is an issue and maintains good performance in more standard tasks.",
    "In this paper the authors propose a new RL method, spectral DQN, in which rewards are decomposed into different frequencies. This decomposition allow for the training loss to better balanced on certain tasks - in particular those with progressive rewards. The new method is shown to perform well on specially constructed tasks with extreme reward progressively, as well as on a selection of standard Atari tasks.",
    "Broadly, this work is an attempt to understand how neural networks can form generalizable representations while being severely overparameterized. This work proposes an information theoretic measure, called the \"usable information\", and use it to quantify the amount of relevant information in different layers of a neural network during training. The key idea is that, in order for the information represented in one layer to be \"usable\" by the next layer, it should be decodable by a simple transformation (affine + element-wise nonlinearity).",
    "The paper studies how initialization and the implicit regularization of SGD affect the training dynamics of neural networks in terms of minimality and sufficiency of learned representations. The main findings are that 1) SGD with random initialization learns almost minimal and sufficient representations and 2) SGD with an initialization that contains information about irrelevant factors fails to converge to minimal representations, increasing the chance of overfitting. These findings are interesting, useful for understanding neural networks, relevant to the ICLR community, but lack evidence of generality.",
    "The authors contribute to the recent research on whether neural network training (in particular, SGD) favors minimal representations, in which irrelevant information is not represented by deeper layers. They do so by implementing a simple neuroscience-inspired task, in which the network is asked to make a decision by combining color and target information. Importantly, the network's output is conditionally independent of the color information, given the direction decision, so the color information is in some sense irrelevant at the later stages. Using this, the authors quantify the 'relevant' and 'irrelevant' information in different layers of the neural network during training. Interestingly, the authors show that minimal representation are uncovered only if the network is started with random initial weights. Information is quantified using a simple decoder network.",
    "This paper studies the nonconvex strongly-concave min-max optimization problem. It improves the analysis of an existing method SREDA to make it allow larger step size and less initialization computation. Besides, it extends the algorithm to the case where the objective function is non-differentiable. The authors claimed it is the first zeroth-order variance-reduced method for the min-max problem. Experiments are conducted to demonstrate the improved algorithm is better than existing methods.",
    "The paper proposes a SREDA-Boost, which builds upon SREDA for nonconvex-strongly-concave minimax problem. The SREDA-Boost algorithm is less restrictive to initialization and has an accuracy-independent and larger step size. Thus it can run substantially faster than SREDA. The main contribution to the first-order optimization story is a new analytical framework that builds upon the previous analysis in SREDA and overcomes the dependence of highly accurate initialization via bounding the tracking error and gradient estimation error separately. It also proposes a zeroth-order variance reduction algorithm for the same optimization problem, which has the largest possible step size so far and also improves the complexity of the state-of-the-art in some cases. Various experiments have validated the superiority. The theoretical analysis and empirical results look good to me.",
    "The paper proposes a variant SREDA-Boost of the variance reduction method SEDRA for solving nonconvex-strongly-concave min-max problem. The first contribution of the paper is to relax the conditions on the initialization  of SEDRA and moreover enable larger stepsizes ($\\epsilon$-independent stepsizes). As SEDRA is already optimal, such modification does not improve the theoretical convergence rate, but it is beneficial from the practical perspective. The second contribution is to adapt the method to zero order oracle, achieving the state-of-the-art convergence rate. ",
    "This paper studies one-shot 2D object detections. The major conclusion is that when keeping the number of training images fixed, increasing the number of training categories can significantly increase the one-shot performance.  This paper demonstrated this conclusion empirically by doing controlled experiments on COCO, Objects365, and LIVS.   Inspired by this observation, this paper improves the state-of-the-art one-shot detection performance on COCO from 22.0 to 27.5 AP50 by training on LIVS.  Other two related conclusions in this paper: - PASCAL VOC is not suitable for evaluating one-shot object detection algorithms. The reason may be that the number of instances per image is low(2.9 ins/img on average). The algorithm only needs to recognize foreground objects rather than objects of target categories.  - Only when the training data is challenging enough, increasing the model size and training time can help improve one-shot performance.   ",
    "- The paper considers the problem of one-shot object detection, meaning, the model is asked to detect unseen categories, based on only one provided a template.  - The main discovery made by the authors is that, to generalise better, the model should be trained with data from as many categories as possible, given the same budget on number of samples for training.  - Architecture-wise, a Siamese Faster R-CNN is adapted. ",
    "This paper studies the effect of category number in the one-shot object detection task. In the testing of one-shot detection, there exists a performance gap between the base (training) classes and held-out classes. It is claimed that this performance gap can be largely closed by increasing the number of categories used for training. And the number of categories is more crucial than the number of samples per category. Experiments are conducted on VOC, COCO, Object365, and LVIS using a Siamese-style detector to verify the claims.",
    "This paper shows that the key to reduce the generalization gap between base classes and novel classes is to increase the number of training categories, instead of training samples. The authors did many experiments on four existing datasets (PASCAL, COCO, Objects365, and LVIS) with Siamese Faster R-CNN to verify this point. Experiments show that with more categories in the training set, the generalization gap will be nearly closed. Finally, the author proposes that future data sets should focus on the diversity of categories.",
    "This paper presents a method for 3D scene reconstruction from a single image using implicit surface representations such as occupancy or SDF. The authors propose to incorporate loss functions on the spatial gradients to provide dense supervision in the 3D space in the case where 3D labels may be incomplete (e.g. open 3D meshes) or not well-defined everywhere. Experiments are performed on ShapeNet and ScanNet show that the proposed method can achieve competitive performance on single-image scene reconstruction tasks.",
    "This paper describes novel loss functions for learning to predict an implicit 3D scene representation from a single image.  They argue that when working with real scan data of scenes (rather than single objects) it is difficult to generate accurate occupancy or signed distance function (SDF) ground truth as would be required for supervised learning.  Instead, they propose to only use occupancy or SDF supervision near the surfaces of objects; elsewhere, they rely on constraints on the gradient of the occupancy or SDF adapted from Gropp et al. 2020.  They perform a thorough evaluation on several benchmark datasets and compare against state-of-the-art competing methods.  They show that they outperform competing methods, even though in some cases their method has access to less supervisory data.    They also perform an ablation study to show the importance of various parts of the loss function.  ",
    "This paper presents a new method to learn implicit 3D scene reconstructions from single image input. The main improvement is a closed-form Differentiable Gradient Sampling.  By taking spatial gradient into  consideration, the proposed method can apply back-propagation of the  loss on spatial gradients to feature maps and allow the training for the case of without dense 3D supervision.   ",
    "In this paper, the authors propose a new method for single view 3D reconstruction.  A conditional (image feature prior) implicit representation framework is proposed to reconstruct 3D scene from a single view. In this paper, the authors propose that feature gradient is essential for watertight reconstruction and propose a differentiable gradient sampling method for the formulation. Experiments have been performed on both synthetic and real datasets. Superior results have been presented.",
    "This work studies the problem of efficient pretraining of large-scale models for language and vision representations, namely the issue of significant memory requirements for models with billions to trillions of parameters. Authors propose two modifications: first, to reduce the memory load and improve convergence at the initial stage of training, they suggest to train a multilayer model with shared parameters and then unshare them. Second, to maximize GPU utilization with offloading, authors develop a method for granular CPU offloading, which keeps larger chunks of the model in GPU memory. When combined, the proposed methods allow the authors to train a 10 trillion parameter model on 512 GPUs.",
    "The authors propose to train very large neural language models via a \"Sharing-Delinking\" paradigm. The proposed method first trains a model with weights shared across layers. In this way, the model appears to be smaller and it can fit into fewer GPUs. At some point, the authors delink the weights, and continue training the model in the conventional way.  The authors also propose a granular CPU offloading mechanism to save CPU memory.",
    "The paper proposes a technique called Pseudo-to-Real (P2R) for reducing the computational and time requirements of training massive (or Giant) models with trillions of parameters. The key idea of P2R is a two phase training approach for Giant models. The first phase involves training a smaller version of the model (a.k.a., Pseudo-Giant) which is obtained by making all layers share parameters. The second phase involves training the Giant model after initializing with Pseudo-Giant weights. The paper further proposes Granular CPU offloading which is to offload some but not all model parameters to CPU memory to reduce GPU memory consumption. Finally, the paper provides some evaluation results to demonstrate P2G.",
    "The paper proposed an interesting strategy to reduce the training time for large scale language models consisting of stacking layers with identical structures. Users first trained the models with shared parameters across the layers, then relax the tie constraints so that parameters at different layers are updated differently.  The paper showed some empirical evidence that the proposed strategy converged faster given a limited training time budget and demonstrated the feasibility of training a 10T model.",
    "This paper derives a Fenchel duality formulation of the maximum likelihood loss of F1-EBMs, which turns the optimization into a min-max problem on probability measures over the sample space. A dual algorithm with mean-field dynamics is proposed to solve this problem. Using the dual aogrithm they also draw a connection between maximum-likelihood training and score matching. Simple numerical experiments on two-layer ReLU network show that the algorithm converges much faster than the original MLE. ",
    "The authors formulated the Fenchel dual problems to maximum likelihood and score matching training applied to energy-based models defined by shallow neural networks. The authors then proposed practical algorithms based on the Hahn decomposition and compared this to various predecessor algorithms. An interesting part is that the learning dynamics can interpolate between maximum likelihood and score matching. There are also rich results in the Appendix. ",
    "Two approaches exist for learning a Gibbs measure: either by MLE (minimizing the KL divergence) or by score matching (maximizing the Hyvarinen score). With the same goal to minimizing the KL divergence, the author proposes an alternative training approach by augmenting an auxiliary $\\gamma$ measure and thereby optimizing a more tractable dual problem. The author claims that this new training method has a quicker convergence rate than the primary problem.  ",
    "This paper studies the training of Energy Based Models (EBM). The \u201cstandard\u201d technique is maximum likelihood maximization of the observed dataset. While theoretically sound, there are practical difficulties in simulating the MCMC dynamics due to large basins in the energy landscape. For this reason a class of alternative methods, like Score matching, have been explored in the literature. Score matching, however, is deemed to suffer in statistical power.  This work explores how, leveraging known results about Fenchel dualities, it is possible to connect the two training modalities (Maximum Likelihood and Score based) on a continuum, and proposes a practical algorithm based on such considerations. The authors consider for their theoretical analysis of the expressiveness of the models,  shallow neural networks in the lazy and kernel regime (spaces F_1 and F_2 respectively).  Section 2.1 introduces the two considered spaces, referring to the works of Chizat and Bach.   An energy based model is defined at the beginning of section 2.2 by means of the Radon Nikodym derivative. Training an EBM model via maximum likelihood corresponds to maximizing eq. (2), that, when considering networks in F_1, can be rewritten as the expression (3). At the end of Section 2.2. score matching is rigorously defined and the relationship between theoretical and empirical implementations (Hyvarinen) is clarified.  Section 3 is the core of the paper. If Assumption 1 holds (growth conditions), then Thm 1 states that eq. (3) is the Fenchel dual of (5). As (5) is a static functional, the authors propose to use results from Chizat and Santambrogio to rewrite it as the dynamical system (eq. (6))  together with the definitions in (7). Importantly, this formulation contains \\alpha, a free parameter >0, that determines relative time-scales over which functions \\gamma and \\nu are updated. System (6) is still \u201calgorithmically\u201d unsolvable. The authors then propose to use the two following approximations: first, the mean field technique known as propagation of chaos, is used to switch from (6)  to the system (8), where gamma is substituted by neural network  parameters and \\nu by and SDE. Then the continuous time system (8) is discretized using Euler-Maruyama. Algorithm 1 is the result of the process.  Section 4 explores how, in the infinite alpha regime, the dynamical system (6) is equivalent to score matching. By means of eq. (11) and proposition (3) the technical analysis is performed. Intuitively, parameters are updated infinitely faster than the samples.  Section 5 explores the implementation of Algorithm 1 on a synthetic dataset. The authors consider two cases (the two teacher neurons aligned to 164 and 78 degrees respectively). Comparison of the primal and dual (alpha<<1, alpha>>1) shows that the dual performs much better than the primal.  The conclusions stress the theoretical contribution based on Fenchel duality and propose as future work the exploration of convergence rates of (6) and (10) and numerical investigation of the restarting probability p_R. In addition, the authors suggest that \u201cporting\u201d the presented work to deeper network architectures (e.g. to work on realistic dataset, such as images) is straightforward from the practical point of view, and unpractical from the theoretical point of view. ",
    "This paper presents tight lower bounds on differentially private ERM, a well-studied topic in the DP literature. It obtains tight bounds for both the constrained and unconstrained settings. The exact quantitative improvements are stated precisely in the abstract, and I won't repeat them here. The improvements are not staggering, but they are tight, and are presumably the final word on this topic.   ",
    "The paper describes some lower bounds for differentially private empirical risk minimization (DP ERM). The main results are:  * An $\\Omega(\\sqrt{p \\log(1/\\delta)}/\\epsilon n)$ lower bound for unconstrtained ERM under approximate differential privacy. This improves on prior work of Bassily et al. in the presence of the $\\log(1/\\delta)$ term, and in the optimization being unconstrained.  * An $\\Omega(p/\\varepsilon n)$ lower bound for pure differential privacy.  The proofs use now standard techniques from the literature: fingerprinting codes for approximate DP and a packing argument for pure DP.",
    "## Summary of Contributions  This paper studies the unconstrained empirical risk minimization (ERM) under differential privacy (DP). In this setting, there is a loss function $\\ell: \\mathbb{R}^p \\times \\mathcal{X} \\to \\mathbb{R}$ and we are given $x_1, \\dots, x_n \\in \\mathcal{X}$; the goal is to output $\\theta$ that minimizes the empirical loss $L(\\theta; X) := \\frac{1}{n} \\sum_{i=1}^n \\ell(\\theta; x_i)$. The goal is to minimize the excess empirical loss $\\mathbb{E}[L(\\theta; X) - \\min_{\\theta^* \\in \\mathbb{R}^p} L(\\theta^*; X)]$. We want our algorithm to satisfies $(\\epsilon, \\delta)$-DP. Recall that the case $\\delta > 0$ is referred to as *approximate-DP* whereas the case $\\delta = 0$ is referred ti as *pure-DP*. Here we assume that $\\ell$ is 1-Lipchitz; the results easily extends to $C$-Lipchitz functions with an extra multiplicative factor of $C$ in the excess empirical loss.  The main contributions of the paper are: 1. In the approximate-DP setting, the authors show a lower bound of $\\Omega\\left(\\frac{\\sqrt{p \\log(1/\\delta)}}{\\epsilon n}\\right)$. This improves upon the best known bound of $\\Omega\\left(\\frac{\\sqrt{p}}{\\epsilon n \\log p}\\right)$ in the unconstrained case from [Asi et al., 2021] and $\\Omega\\left(\\frac{\\sqrt{p}}{\\epsilon n}\\right)$ in the constrained case [Bassily et al., FOCS 2014]. The new lower bound also matches the known upper bound in both cases [Bassily et al., FOCS 2014]. 2. In the pure-DP setting, the authors show a lower bound of $\\Omega\\left(\\frac{p}{\\epsilon n}\\right)$.  To prove 1., the authors reduce from the 1-way marginal problem (similar to previous work). Recall that in 1-way marginal, we are given $x_1, \\dots, x_n \\in \\\\{-1, 1\\\\}^p$ and the goal is to approximate $\\frac{1}{n} \\sum_{i=1}^n x_i$; a lower bound of $\\Omega(\\frac{\\sqrt{p \\log(1/\\delta)}}{\\epsilon n})$ is known for the problem [Bun et al., STOC 2014]. The authors use an $\\\\ell_1$-distance loss function, i.e., $\\\\ell(\\\\theta; x_i) = ||\\\\theta - x_i||\\_1$. Notice that here the optimal solution is $\\\\theta^*\\_j = sign(\\sum\\_{i} z\\_{i, j})$. This in spirit is very similar to 1-way marginal but not exactly the same. Specifically, if $\\sum_{i} z_{i, j}$ is roughly around zero, then taking $\\theta_j = -1$ or $\\theta_j = 1$ does *not* effect the loss too much. Therefore, a direct \"blackbox\" reduction from 1-way marginal does not seem to work. To overcome this, the authors observe that actually in the construction of [Bun et al., STOC 2014] most of the coordinates' means are not close to zero (formalized as \"biased mean\" property in the current paper) and thus the hard instance gives the desired lower bound for DP ERM.  To prove 2., the authors use a standard packing-style construction together with the $\\\\ell_2$-distance loss function",
    "This paper studies differentially private empirical risk minimisation (ERM) in the unconstrained setting. It gives tight lower bounds for approximate DP ERM for general loss functions, which also implies the same lower bound for the constrained case, which is an improvement over a classic lower bound by Bassily et al 2014. It also gives a lower bound for unconstrained pure DP ERM that recovers the result in the constrained case.",
    "This paper proposes a method to solve Wasserstein gradient flows based on the JKO scheme using variational formulations of functional objectives, such as the KL divergence or the generalized entropy (non-linear diffusion). Relying on known reformulations of the JKO scheme as optimization over convex functions, the paper departs from recent related methods in expressing certain objectives as f-divergences, and in turn using the dual formulation of these divergences to circumvent the need to do explicit density computation in these. The resulting method involves parametrizing two types of operators as neural networks (one of them as an input-convex neural network), and solving a mini-max objective. The paper presents experiments on simple PDEs (mostly in 1D or 2D) with known solutions. ",
    "This paper studies the implementation of some Wasserstein Gradient Flows (WGF) in discrete time but without discretizing the space. The methods proposed are based on the JKO operator to discretize WGF in time. The implementation of the JKO can be challenging. The strategy of the authors is to first reparametrize the JKO as a minimization over a space of functions (instead of measures) via pushforward. Then, when the objective function is a f-divergence, the objective inside the JKO admit a variational representation and can be expressed as a sup. Conclusion: each JKO is written as a min max over a space of functions. To solve it, they parametrize the functions by neural networks and alternatively maximize and minimize the problem using Adam. An important feature is that the objective in the min max can be approximated with samples of the current distribution (its density doesn't appear, only integrals wrt to the current distribution). ",
    "This paper proposes a variational formulation of each JKO step for optimizing functionals on measures. Different from existing recent works on emulating JKO steps by training pushforward neural networks (either directly or as gradients of convex functions), the variational formulation involves another inner maximization of a function, without needing density access that typically requires cubic time complexity due to computing the log determinants of the pushforwards. Experiments are done to demonstrate the practicality of the algorithm. ",
    "The paper proposes a method to compute Wasserstein Gradient Flows (WGFs) via neural networks and the JKO scheme. In contrast to prior works, to compute WGFs of functionals involving f-divergences, the authors use variational approximations rather than direct computations. It is claimed to work faster and perform better.",
    "The paper presents an approach, called MetaBu, for learning a meta-feature embedding from an existing meta-feature space into a latent space, which is aims at being rank preserving regarding different hyper-parameter configurations. The special kind of embedding and its property of aiming at being performance preserving in the context of AutoML is the main contribution of the paper, in my opinion. The quality of the learned meta-features is assessed through different experiments such as capturing to what degree the embedding is indeed performance preserving and how well AutoML tools perform when initialized with the corresponding meta-features. Moreover, the authors provide a sensitivity analysis of relevant hyper-parameters of MetaBu and demonstrate how to gain insights from the learned embeddings.",
    "In this paper, the authors address the AutoML problem, which aims to automatically select the best ML algorithm and its hyperparameter configuration for a dataset, and propose an approach to this problem that learns meta-features of the dataset. The proposed method, MetaBu, learns new meta-features by optimal transport according to the space of distributions of hyperparameter configurations. Meta-features in MetaBu is known only once and induce a topology in a set of data sets. Experiments on the OpenML CC-18 benchmark have shown that MetaBu meta-features can improve the performance of the state-of-the-art AutoML systems AutoSklearn and Probabilistic Matrix Factorization. Furthermore, the examination of MetaBu meta-features provides hints on when an ML algorithm will work. Finally, a topology based on MetaBu meta-features can estimate the intrinsic dimension of the OpenML benchmark for a given ML algorithm or pipeline. ",
    "This paper tackles the AutoML problem. It proposes to learn a linear combination of manually designed meta-features, which aligns meta-features with the space of hyper-parameter configurations via an Optimal Transport procedure. Experiments on OpenML benchmark demonstrate the power of the proposed method on boosting AutoML systems.",
    "This paper focuses on the AutoML problem for tabular data and proposes a meta-learning based novel solution. They consider the optimal transport to define distances between two datasets, utilizing the Wasserstein-Gromov distance between the distribution of the top performing hyperparameters for the respective datasets. Given this distance, they propose learning a linear transformation of existing dataset meta-features such that the Euclidean distance between a pair of datasets in this transformed space is proportional to their Wasserstein-Gromov distance. This method is termed Metabu.  The empirical evaluation compares Metabu to existing meta-learning schemes on (i) their ability to capture the desired Wasserstein-Gromov distance, (ii) their ability to find better hyperparameters via sampling without an underlying optimizer, and (iii) their ability to find better seed hyperparameters for hyperparameter optimizers. The results on the OpenML CC-18 suite with 3 machine learning models indicate that Metabu significantly improves upon existing meta-learning schemes. The paper also demonstrates how the learned linear transformation of existing dataset meta-features allow us understand the importance of different existing dataset meta-features and how these vary between machine learning models.  ",
    "This paper proposes a customisation strategy named \"Split-Max\" for federated learning. The authors identify the heterogeneity of devices and data in FL scenarios. They present the importance of considering devices' budgets and dynamics when dispatching training models. Split-max can adjust the model size according to the devices' budget while maintaining good accuracy and robustness.  Split-max works in steps. First, multiple base models from different initialisations are trained to improve diversity. These base models are randomly given to clients to extract generalisable features. Then, base models are aggregated to the server. Secondly, to provide devices with models with different robustness, it trains two similar models together to capture both the standard-training accuracy and adversarial-training accuracy. Then layer-wise mixing is conducted to achieve both standard accuracy and adversarial accuracy.   Experiments show that Split-Mix achieves better accuracy than naive approaches. Moreover, with customisation, the models are smaller and more robust under budget constraints.",
    "Split-Mix is a Federated Learning strategy aimed at easing the problems that arise when a heterogeneous pool of devices/clients (i.e. some with more compute/memory capabilities than others, different data distributions) collaboratively train a global model. Split-Mix trains a model that can later on be customized in terms of model size and robustness. As the name suggests, Split-Mix has two stages: During `split`, a large model is split into smaller base models. Base models are constructed by discarding channels but maintaining the the number and type of layers in the network. During `mix`, the server samples a fraction of the base models (depending on a given client's compute capabilities) and fuses them into a single one that is send to a client to train. All base models are trained on all clients (should these meet the compute requirements of a sub-model) in a federated manner. This means that the more capable devices, train all base models. This is envisioned to happen in a parallel fashion in a given device. Once FL training is completed, a customized model can be deployed to a device/client in hardware-aware and robustness-ware fashion. The Authors refer to this as _in-situ customization_ ",
    "This paper presents a new federated learning approach named Split-Mix FL that allows clients to train customized models efficiently while considering heterogeneity in data and computation resources. The key idea is threefold: 1) the global model is first split into several sub-networks called base models that each have different sizes, thus requiring a different amount of computational resources; 2) Each selected client trains a random subset of base models, under its computational resource constraints; 3) updated base models are aggregated at the server-side and distributed again. Furthermore, the proposed approach can train both accurate and robust models in a joint fashion, where all but batch-norm layers are shared for efficiency. Experimental results on multiple datasets (CIFAR10, Digits, DomainNet) demonstrate the effectiveness of the proposed approach compared to FedAvg and HeteroFL.",
    "The paper proposes a new federated learning scheme that is suitable for devices with heterogeneous resources. The proposal, namely Split-Mix, trains multiple models of different sizes and adversarial robustness levels, tailored to the budget of each device. Empirical results demonstrate the efficacy of the method against the main competitor.",
    "This paper constructs methods named CurvatureEG+ (and Adaptive EG+ and CEG+), built upon a recently proposed EG+ [Diakonikolas et al., 2021], a variant of EG, that works under the weak MVI condition. Most importantly, the CurvatureEG+ (and Adaptive EG+/CEG+) works for a range (of the weak MVI) larger than that of EG+. The corresponding nonconvex-nonconcave setting includes non-trivial problems illustrated in the paper, where the proposed method converges, while other existing methods reach limit cycles. Unlike EG+, the CurvatureEG+ can handle both constrained and composite cases. A stochastic variant is also studied. Although the experiments consider toyish problems, they seem interesting.",
    "This paper focuses on variants of ExtraGradient (EG) by considering different options for the two step-sizes of the method: one for the extrapolation step and the second for the iterate update.  Building on the analysis of (Diakonikolas et al. 2021),  the paper relaxes the setup therein by allowing a larger range of values for the $\\rho$ parameter (see Fig. 2) of weak Minty Variational Inequality (MVI) which parameter controls the degree of nonconvexity.  In particular, it provides the following contributions: *(i)* Primarily it defines Alg.1 where the step size for the iterate update is adaptive and shows the main convergence result (Thm  3.1.) that under some assumptions (Asm 1), Alg. 1 converges on weak MVI problem. *(ii)* It then considers a non-adaptive variant of Alg. 1, dubbed CEG+, which can be seen as a generalization of the EG+ method of (Diakonikolas et al. 2021), and complements the result of the latter by showing that the convergence result is tight on weak MVI; *(iii)* extends CEG+ by using an adaptive scheme for the first step size (for the extrapolation) which uses Lipschitz constant backtracking, and Alg.1 for the latter step size (for the iterate update), dubbed CurvatureEG+, which method is shown to empirically converge on some toy-examples on which CEG+ does not; *(iv)* finally, for the stochastic setup the authors consider one of the step-sizes to be diminishing and the other can be constant, and show that this variant converges on weak MVI problems. ",
    "This paper proposed CEG+ and CurvatureEG+, which extend extragradient method to a proximal variant (regarding the operator $A$), and apply it in nonconvex-nonconcave minimax optimization with Weak MVI condition in both deterministic and stochastic cases, and proved their complexities, which has the same order as those in literature (e.g., Diaonikolas et al., 2021). The authors also studied the lower bound in the simpler case when $A\\equiv 0$, showing a difference compared to EG+ in (Diaonikolas et al., 2021).  In the deterministic case, it proposed an adaptive stepsize strategy to allow larger range of the MVI parameter $\\rho$, and further a curvature-based strategy to avoid the lower bound requirement of $\\rho$. The authors also executes several experiments, showing that CurvatureEG+ can avoid cycling in the experiments.",
    "This work extends the extragradient algorithm in Diakonikolas et al. (2021) from unconstrainted and unregularized inclusion problems that satisfy weak Minty inequality (MVI) to their constrained and regularized counterparts. Compared with the original extragradient algorithm, the extended algorithm is proved to converge with a larger range of stepsize choices and MVI-related constant $\\rho$ (implying a larger set of applicable problems) in both deterministic and stochastic inclusion problems. The range of $\\rho$ is also proved tight by providing a lower bound of $\\rho$. The extended algorithm also generalizes the celebrated forward-backward-forward (FBF) algorithm in Tseng (2000). Finally, an improvement of this extended algorithm is proposed using Lipschitz constant backtracking. ",
    "The paper presents a new neural-bandit algorithm with shallow exploration and provides a regret bound for the proposed method. The existing approaches have introduced deep neural networks based bandit algorithms to learn reward functions, in which exploration takes place over the entire network parameter space, which can be inefficient for large-size networks which are typical in NTK based approaches. The authors address this by taking an existing approach that decouples the deep neural network feature representation learning from most of the exploration of the network parameters by only exploring over the final layer of the network.   Despite the fact that this idea of shallow exploration has been proposed previously, there has not been a theoretical analysis with a regret bound. The authors analyze a UCB version of this approach, then build from techniques from both deep neural contextual bandits and linear contextual bandits to prove an O(\\sqrt(T)) regret bound. Finally, the authors present experimental results to show that their algorithm work well in practice.",
    "This paper studies neural contextual bandits and proposes an algorithm that transforms the raw feature vector using the last hidden layer of a deep ReLU neural network, and uses an UCB approach to explore in the last linear layer. Compared with existing neural contextual bandit algorithms, the proposed algorithm attains computation efficiency. Regret guarantees and empirical results are provided to demonstrate the effectiveness of the proposed algorithms",
    "This paper study a novel contextual bandit algorithm: Neural-LinUCB. As in (Riquelme et al 2019), the idea of this algorithm is based on decoupling deep representation learning and exploration. A deep neural network learns the mapping between the context $x_{t,a_t}$, while a linear bandit, OFUL (Abbasi-Yadkori 2011), chooses the arm to play. In contrast to (Riquelme et al 2019), a regret upper bound of the algorithm a regret upper bound of the algorithm is stated in Corollary 4.6. The proposed algorithm is also an improvement over NeuralUCB (Zhou et al 2020) for two reasons: the computational cost of the exploration is lesser, since the exploration is only done in the last layer of weights, and the regret upper bound is tighter. Indeed, in contrast to (Zhou et al 2020) it does not depend on the dimension of the tangent kernel matrix, which can be in O(KT). Experiments, done on four contextual bandit problems, show that Neura-lLinUCB outperforms LinUCB and performs as well as NeuralUCB and NeuralTS. ",
    "Authors tackle the setting of contextual bandits, using deep representation learning combined with an upper confidence bound algorithm. The main contribution of this work is to provide a regret bound for the setup which decouples the representation learning from the UCB search, by searching only over the last layer of the network. The setting had been studied before, but only empirically, and using Thompson sampling rather than UCB. Authors validate their results empirically on several domains from the UCI data repo, as well as on MNIST, comparing against state of the art baselines. ",
    "The paper proposed a data-driven method for optimal action space selection in a reinforcement learning problem. Given a set of training state, action pair, the proposed approach first filters out the set of indispensable action set and then rank the other action set according to their cumulative reward values. To further improve the efficiency, a Monte Carlo sampling method is proposed for cut-off cardinality computation for action space. An action update rule is devised by computing optimal step size. Finally, a case study on a cloud environment is illustrated to select the optimal set of resources (#vCPUs and Memory size) to optimize the CPU utilization rate. The case study demonstrates that the Monte Carlo sampling based algorithm reduces action search space by 81% and then it creates a list of ranked action set. It is shown that a large action space does not necessarily lead to better performance for an RL agent. ",
    "The paper addresses the problem of action set selection, i.e. identifying which actions should be available to a RL agent, during training. The set of available actions can influence the RL agent's performance or even hinder it to reach its goal. A method to evaluate action sets is introduced and a case study is performed on a resource tuning example on cloud infrastructure.",
    "This paper focuses on Reinforcement Learning (RL). RL methods often entail a potentially large action space exploration to find a good policy. This work proposes a method to reduce such action space exploration. The method separates actions into two categories: dispensable (the action can be ignored) and indispensable (the action must be taken). Dispensable actions are also ranked according to their importance with respect to the final policy. The method is data driven and operates by looking at the global reward returns obtained when a certain action is removed from the action space. The method is evaluated on a case study simulating cloud infrastructure workload optimisation, i.e. the task of reducing high CPU utilisation by allocating more resources.",
    "This paper empirically considered the impact of training action space for reinforcement learning in a case study. Understanding the impact of training action space is a valid and important problem. An empirical study of this problem appears to be the main contribution of this paper.",
    "Let $X$ be an instance space, $Y$ a set of labels, $D$ some underlying (hidden) distribution over $X \\times Y$. This work studies a new method for converting the output of a probabilistic predictor (e.g. a deep net) to a good prediction set: that is a mapping from $C: X \\to 2^Y$, such that for most samples $(x,y) \\sim D$, $C(x)$ contains $y$. Formally, the authors study this problem in the PAC setting with covariate shift. The learner is given access to the score function, a labeled sample from the source distribution $P$ over $X \\times Y$, and unlabeled samples from a target distribution $Q$ over $X \\times Y$ whose marginal over $X$ may be shifted from the source. The goal is to output a prediction set which is as small as possible while still retaining PAC guarantees with respect to the shifted target distribution. This is a well-motivated model in practice. Probabilistic outputs of modern neural nets can be difficult to interpret, and small prediction sets may be useful in settings where one wishes to avoid or check more carefully a few marked outputs (e.g. a problematic medical diagnosis).  Assuming known, bounded importance weights, the authors provide an algorithm satisfying the PAC guarantee by maximizing a cutoff value for the score function that performs well over an empirical sample. They ensure their guarantee holds over the target rather than source distribution by rejection sampling to simulate the target distribution. The authors also extend this to settings where the importance weights are unknown but can be estimated from unlabeled samples. Finally, the authors provide experimental evidence over a couple common settings of covariate shift. They show that their algorithm outperforms baseline methods in the literature in the sense that it maintains PAC guarantees while outputting a smaller prediction set  in expectation. ",
    "This paper is concerned with learning prediction sets (in a PAC sense) under the covariate shift assumption, given a model $f(x,y)$. The form of the sets is restricted to $C_\\tau(x) := \\{y : f(x,y) \\ge \\tau\\},$ and the problem is set up as learning a $\\tau$, using a  labelled source dataset $S_m \\sim P^{\\otimes n}$ and an unlabelled target dataset $T_n \\sim Q^{\\otimes n}$ such that with high probability over $S_m, T_n,$ $Q(Y \\in C_\\tau(X)) \\ge 1-\\varepsilon,$ where $\\varepsilon$ is a given target coverage level. It is desired that $\\tau$ is as large as possible to minimise the size of the prediction sets learned.  The main scheme is presented modularly. The paper first describes how finding the maximum $\\tau$ whilst ensuring that the number of points in $S_m$ it captures is large enough (as specified by using a Binomial tail inverse) gives valid sets when $Q = P$. Next, it is argued that when $Q$ is absolutely continuous with respect to $P$, and the derivative $w(x) = \\frac{\\mathrm{d}Q}{\\mathrm{d}P}(x)$ is upper bounded and known, then one can importance sample the set $S_m$ to generate a sample from $Q$, which can then plug into the previous procedure. This step fundamentally uses the covariate shift assumption, and, to my understanding, is folklore. The following, then, constitute the main technical contributions.  Next, the assumption of exact knowledge of $w$ is relaxed, and it is argued that if instead for each $x_i \\in S_m,$ bounds $\\underline{w}_i \\le w(x_i) \\le \\overline{w}_i$ are available, then one can produce a worst-case estimate of the coverage of $C_\\tau$ for any $\\tau$ (by taking points that were missed to have high weights, and points covered to have low weights), and if this pessimistic coverage also satisfies the constraint. So, for each $\\tau$, the worst $w_\\tau$ can be produced, which can then feed into the importance sampling procedure above.  Then, it is pointed out that such a confidence bound on the $w_i$s can be learned using a probabilistic classifier $s(\\cdot|x)$ to separate data from $S_m$ and $T_n$, which leads to the main proposed algorithm. While it is roughly justified in the appendix that an accurate estimate can be obtained under smoothness assumptions with an appropriately fine gridding of the space (and a consequently huge sample complexity), the concrete proposal is to replace this step with a heuristic method for fitting bounds on the weights, and then plugging these into the above strategy. Note that this is not implemented as a direct optimisation over $\\tau$ - instead a set $\\mathcal{T}$ of possible values is pre-selected, and the procedure is executed for each $\\tau$ (the algorithm recommends an increasing order on the same).  Finally, the paper presents experiments in the DomainNet dataset, and in the ImageNet dataset, where the shift in the latter corresponds to adversarial perturbations. The principal baselines are the weighted split conformal inference (WSCI) method, which in my opinion is an appropriate choice, and the \"PS-C\" method, which simply uses a prediction set that has $1-\\varepsilon/b$ coverage on the source data, where $b$ is an estimated upper bound on $w$. The proposed method is ablatively presented, and it is seen that on just the DomainNet data, the method PS-R (which simply takes $(1-s)/s$ as an estimate of $w$) is both reliable and performs well, while the PS-M method, which further integrates samples in bins tends to be slightly optimistic on this dataset. Conversely, in the adversarially perturbed dataset, PS-R produces trivial prediction sets (since presumably this shift goes entirely outside the source domain's support), while PS-M performs well. The proposed method, PS-W, which further uses upper and lower bounds on $w$s after integrating them over bins, tends to be pessimistic (error-rates of $0.06-0.07$ are observed when only $0.1$ is demanded), but is not too much worse than either of these methods, and is effective in both types of shifts.",
    "The paper presents algorithms for PAC prediction sets under the assumption of covariate shift. Using estimated/known importance weights that encode the shift, the method optimizes for the smallest subset of labels such that with high probability the error of this prediction set is low. A rejection sampling based strategy is then shown to satisfy the PAC constraints. The methodology is extended to the case where the importance weights are uncertain (due to estimation error). It is shown that the robust variant can be solved using the extreme case weights and the rejection sampling based algorithm. Simulations show the efficacy of the method.",
    "This paper proposes a new method to construct approximately correct (PAC) prediction sets for uncertainty quantification in the presence of covariate shift. It is a natural and interesting extension of the previous works [Park et al. 2020a, 2021] on PAC prediction sets. The building blocks this paper took from these previous works are the optimization problem in Equation (1) and the Clopper-Pearson confidence intervals for the Binomial distribution in Section 2.2. The extension is based on a rejection sampling Clopper-Pearson bound given in Section 3.2.  The authors propose an algorithm with and without access to the true important weights. The algorithm is evaluated in the settings of \u201crate shift\u201d and \u201csupport shift\u201d on the DomainNet and ImageNet datasets. The experiments show that the algorithm gives the smallest prediction sets among approaches that always satisfy the PAC constraint. ",
    "The paper considers a popular approach to semi-supervised learning based on iterative pseudo-labeling the unlabelled data and refining the model parameters thereafter. The paper is supported theoretically for the case of the Gaussian mixture model establishing a generalization error bound based on the KL divergence between the pseudo-labeled and true data distributions. The paper is also supported empirically for binary classification examples coming from CIFAR10 and MNIST datasets ",
    "This paper considers one common semi-supervised learning algorithm, pseudo labeling, and studies this problem from theoretical point of view. Specifically, it derives an information theoretic upper bound on generalization error in each iterative update of pseudo labeling. They separate the bound into two main parts: one depends on the mutual information between the data samples and model parameters, and the other depends on the KL distance between the underlying data distribution and pseudo labeled samples from previous iteration. Their main conclusion is that as the number of labeled and unlabeled samples grows, the first term vanishes, but the second term does not necessarily vanish.   In the rest of the paper, the authors rely on the simple example of binary Gaussian Mixture Model to give a more understandable and sensible calculation of the their upper bound. Namely, they calculate the KL distance and mutual information terms in the main theorem and study the behavior of generalization error for this model. The conclusion they made is that the iterative pseudo labeling can decrease the generalization error for only the first few iterations and after than has no effect on reducing the generalization error. ",
    "The paper considers the problem of semi-supervised learning where pseudo-labeling is used to iteratively assign labels for unlabelled data batches to enlarge the labelled dataset for subsequent re-training of the classification model. The paper first adapts the recent results of Bu et al (2020) and Wu et al (2020) to this set-up and provides a general information-theoretic upper bound for the generalization error of such a learning algorithm. The paper then specializes its set-up to a binary classification problem with Gaussian class conditionals and presents its corresponding generalization bound. Additional experiments are performed on the more practical datasets with deep neural network classifiers. ",
    "This paper provides a generalization error bound for iterative semi-supervised learning (SSL) algorithms using information-theoretic principles (see Theorem 1). To provide more intuitions, the authors first work with a simple model, i.e., the binary Gaussian mixture model (bGMM). It is shown in bGMM that when the class conditional variances are not too large, the upper bound on the generalization error decreases monotonically with the number of iterations, but quickly saturates. The theoretical results on the simple model are corroborated by experiments on MNIST and CIFAR datasets, where similar phenomena are observed, i.e., the generalization error improves after several pseudo-labelling iterations, but saturates afterwards.",
    "This paper proposes a method for exploration called Generative Planning method (GPM), which generates a multi-step action sequence such that the exploration is more temporally consistent and \"intentional\" compared to regular single-step action noise exploration. The multi-step action sequence is output by a generator with an RNN structure, and the generator is optimized by maximizing the plan value function. The authors show that their method GPM performs better than some other methods in several continuous control tasks and present some interesting qualitative results (e.g. state trajectory) showing that the exploration is more effective.",
    "This paper presents a method called generative planning method (GPM) to improve exploration in RL. GPM performs exploration by learning a planner (a map from state to a sequence of action, aka a \u201cplan\u201d)) and performing MPC with a special rule for whether or not to use the latest plan or keep the old plan. The planner is an auto-regressive model (specifically, a stochastic RNN) and is trained to maximize an auto-regressive Q-function. Each time step, the plan from the previous time step is shifted forward by one time step and compared to the newly generated plan. The plans are compared using their predicted Q-values, and the policy switches plans with some probability that increases monotonically with Q(new plan) - Q(old plan). The exact likelihood is determined by a hyperparameter, l_commit_target, that, intuitively, sets a soft target for how long a plan is typically kept. The authors compare GPM to a variety of action-repeat-based exploration methods, from epsilon greedy policies to policies with learned action repeat counts (DAR & TAAC) and find that it is competitive with or outperforms these methods on various low-dimensional robot domains, as well as the image-based CARLA environment. The authors also visualize the trajectories and qualitatively show that GPM improves exploration.",
    "A generative planning method is proposed, which sits somewhere between model-free and model-based methods. No explicit model is learned. However, an action plan is generated using a recurrent action-plan generator, paired with a similarly recurrent critic.  At each environment step, a new action plan is generated, and  the current action plan can be abandoned in favor of the new action plan if the estimated benefit is large enough. The method builds on SAC.  Overall the benefits of the temporally extended action plans are: (a) temporally-coordinated exploration; (b) more effective than action-repeat; (c) some degree of interpretability given that an action-sequence plan represents then intent of a policy in a given state.",
    "This paper proposes a method called Generative Planning (GPM), which aims to improve exploration for model-free RL. GPM learns a recurrent model to generate short term plans at each time step, and only decides to switch to the new plan if it is a lot better than the old plan. This encourages temporally extended explorations, and also does it in an adaptive manner. Experiments on a set of continuous control benchmarks show that GPM is able to converge faster than prior approaches, explore more effectively, and generate interpretable short-term plans. ",
    "This paper summarizes the theoretical guarantee for the existing LRMC and LRTC algorithms, and provides the theoretical analysis for a new proposed Multi-Mode Nonlinear deep tensor factorization. The analytical results show that when n2 is larger than n1, the nonlinear DMF provides a tighter generalization bound than MF. Similar analysis has been extended to two-mode matrix factorization and multi-mode  tensor factorization. Experimental results in synthetic data and real data show better results of the proposed algorithm as compared to other algorithms in completion tasks. ",
    "To bridge the gap between deep learning and tensor decomposition, this paper presents two novel approaches named as two mode non-linear deep matrix factorization and multi-mode nonlinear deep tensor factorization (extension of two mode model to multi-mode scenario). The main contribution of the methods lie in full exploration of non-linearity of data in matrix and tensor factorization. To better motivate the proposed models, the authors provide theoretical analysis for why and when nonlinear deep matrix factorization outperforms linear deep matrix factorization in matrix completion. The experimental evaluation demonstrates that in some datasets, the proposed models outperform the existing models on matrix and tensor completion tasks.",
    "This paper studies the nonlinear low-rank completion of matrices and tensors. Specifically, it first presents the theoretical results showing why nonlinear deep matrix factorization is better than the ordinary matrix factorization model. Then, it proposes a model named two-mode nonlinear deep matrix factorization to make full use of the nonlinearity of the nearly square matrices. The authors also extend this method to tensor factorization by further factorizing the factor matrices in the Tucker decomposition using the deep factorization method. Impressive results are obtained using both synthetic and real-world datasets.",
    "The paper provides a multi-mode framework for the deep learning based tensor decomposition, which could be useful for dealing with nonlinear high-dimensional data sets. In particular, it extends the deep matrix factorization (DMF) method and proposes a multi-mode deep matrix factorization method for matrix completion with convergence guarantee. Based on this, it also develops a multi-mode nonlinear deep tensor factorization method with convergence guarantee. The proposed models are solved by various optimization algorithms. Numerical experiments on synthetic and real data sets of the matrix/tensor form have shown that the proposed methods outperform other state of the arts. ",
    "The paper works on a novel problem of interpreting and explaining structured output models. The paper utilizes an energy based model to account for correlations between structured outputs and learns an interpretability block which given as input an image learns to mask it such that the energy based model would assign a similar score to the ground truth output and input as well as the ground truth output and perturbed input. In essence, the energy based model is a proxy for the actual deep neural network performing the structured prediction task. Results on a couple of datasets demonstrate that the work does better than baselines like LIME which do not utilize the correlations in the outputs modeled by the energy based model.  ",
    "The paper proposes a technique for identifying what input variables are most relevant for determining the value of a single, given output variable in structured-output (MAP) inference.  The idea is to learn an energy model that predicts which input variables are relevant to a particular structured prediction (x, y).  The authors propose to implement the energy model using a neural network followed by a Gumbel-softmax activation, and to train it by maximizing a structured hinge loss.  The proposed approach is evaluated on three datasets and compared to standard attribution techniques (LIME, SHAP, L2X).",
    "The authors propose an energy-based training method for achieving model interpretability, which performs instance-wise feature selection. The proposed model adopts a similar approach of one of the pre-existing interpretable methods by calculating feature-level importance score with regard to each instance. The authors validate their method on synthetic and public datasets.",
    "This paper propose a method for interpreting structured output model. The key idea is to find an \"interpretation\" which explains an \"target\" output random variable based on subset of rest of the output variables. The training objective is on finding a small subset which keeps the target output random variable invariant. The proposed methodology is applied to explain a synthetic energy function and structured prediction energy networks. ",
    "This paper considers a generalization of the policy gradient method to optimize for arbitrary utility functions with weightings that depend on the entire CDF (rather than the expected reward). This generalization has two aspects: (1) a utility function on top of the trajectory reward and (2) a weighting function for the CDF of the trajectory reward with respect to which the expectation is performed.  The paper derives an expression for the policy gradient and also generalizes the standard variance reduction baselines. Inspired by the PPO loss, the authors then propose a clipped version of the policy gradient calling it C3PO and evaluate this on some benchmarks from the OpenAI Safety Gym, where it is found that the conservative weightings can offer improvements over the standard formulation.",
    "Risk objectives have long been investigated in reinforcement learning (RL). Most of the focus has been on classic risk measures, like exponential utility, value-at-risk (VaR), conditional value-at-risk (CVaR), leaving out, however, the cumulative prospect theory (CPT) developed by Tversky and Nobel Prize Kahneman in 1992, which has not yet been considered.  The advantage of CPT is to better model human decision-making, still allowing a wide class of risk measures, based on the utility $u$ and weighting $\\omega$.  Hence, the authors consider a new risk-aware objective. Following some derivation, they compute a sample-based estimation of the gradient of this new objective w.r.t. the policy parameters.  The authors propose a PPO-like algorithm (called C3PO), which incorporates the new, risk-aware, gradient estimator.  They perform an empirical analysis on some tasks of \"Safety Gym\", showing that proper risk-awareness helps increase the performance of classic PPO.",
    "The paper presents an alternate approach for distributional DRL via proposing an objective inspired from Cumulative Prospect Theory (CPT, Tversky and Kahneman, 1992). They use this distributional objective in conjunction with policy gradient methodology to propose a distribution policy gradient method for risk-sensitive RL. Under their approach, the distribution of the returns is optimized to maximize some chosen function of its CDF. They experiment with different such possible distributional objectives (risk profiles) on the OpenAI Safety Gym environments and show that their approach performs better than PPO. ",
    "The article propose a policy gradient method for optimizing a CDF based criterion, inspired by CPT.  By varying the weighting function inside the objective, it is possible to change the risk-aversion of the agent. The authors derives the policy gradient for the aforementioned objective and propose an estimation technique for it. Then, they propose an algorithm which extends PPO for optimizing their objective. Empirical analysis is carried on to evaluate the approach on some modified Safety Gym environments, in which a fixed negative rewards corresponded to adverse events. The authors evaluate different objectives obtained by employing a Wang weighting function, with different values of the parameter $\\eta$. They show that optimizing a cautious (or risk-averse) objective allow to obtain better results in terms of average reward w.r.t. optimizing an aggressive (or risk-seeking) one. By further exploring the parameter space, the author demonstrate that some risk-averse values of the parameters allow to outperform also the risk-neutral version of PPO w.r.t. the average reward objective.",
    "This paper tackles learning a flexible distribution approximator to approximate the output of a high-dimensional and computationally intensive stochastic simulator.  The contributions of this paper then reduce into three main components:   1 - Definition of a spatiotemporal neural process that can succinctly model a more richly structured latent process.  2 - Definition of a new acquisition function and using a neural process in an active learning setting.  3 - Application to epidemiological simulators to \u201ccompile\u201d estimation.  The method appears to work, validated on a toy-ish SEIR model, and a more sophisticated pre-existing epidemiological model.   ",
    "This study proposes a new method for learning surrogate models of stochastic simulators. The new method, Interactive Neural Process (INP), builds on Neural processes and leverages the spatiotemporal structure of the problems at hand to reduce the complexity of the inference task. On a few problems in epidemiology -- a low dimensional SEIR problem (2 parameters, 100-dimensional output), and a complex spatiotemporal LEAM-US problem --, the approach is shown to appropriately learn the surrogate in few iterations.",
    "The authors proposed a novel active learning framework integrated with the neural process. The neural process is used to mimic the simulator dynamics which is later used for Bayesian active learning. They also proposed a new acquisition function utilizing the latent from the neural process. The experimental results show that INP works better to accelerate stochastic simulation than GP, and the proposed LIG leads to faster convergence compared with alternatives.  ",
    "The manuscript entitled, \"Accelerating Stochastic Simulation with Interactive Neural Processes\", presents a novel approach to the problem of statistical emulation for mechanistic models of epidemic disease transmission.  To this end, structured neural processes are developed to exploit and respect the temporal and spatio-temporal character of these models.  An active learning strategy is developed to train these neural processes to minimise the computational costs of generating training instances of disease simulator outputs.  The methodology developed is applied to two SEIR compartmental model examples: a minimal one with a single homogenous population and a maximal one with many age and space delimited cohorts.",
    "In this paper, the authors propose a method that applies DP-SGD to NLP tasks. DP-SGD protects the privacy of the model training against that the individual information about the training samples is detected or inferred. The method is applied to the fine-tuning phase of the pre-trained language models (e.g. bert, gpt), thus it achieves good performances for many applications. To adapt DP-SGD to NLP models, this paper proposes ghost clipping that allows clipping in DP-SGD to run without instantiating per-example gradients for any layer in the model.",
    "This paper adapts the widely used DP learning algorithm, DP-SGD, to language models. It achieves to fine-tune the dataset while protecting the private information in the dataset. In this paper, the authors conduct some empirical studies on language models and find some useful conclusions (e.g. fine-tuning on a part of parameters with DP is enough). The authors verify the model on sentence classification, table-to-text generation, and dialog generation tasks, using various pre-trained language models (e.g. GPT, Bert).",
    "The paper propose a faster algorithm to learn approximate differentially private NLP models. Pretrained NLP models are often very large. Practical procedure involves fine-tuning NLP model on private data, which may leak private information. To avoid leakage, DP-SGD (and DP-AGAGRAD, DP-ADAM) uses norm clipping on each sample\u2019s gradient, and then add isotropic noise to aggregated gradients for samples in a batch. Then the normal update steps of SGD, ADAGRAD, or ADAM are performed. This will ensure privacy under differential privacy definition. However, this procedure requires computing per-sample gradient and keep them in the memory so that the norm of the gradient can be calculated, and the per-sample gradient clipping can be performed. This will introduce memory overhead proportional to the batch_size$\\times$#params, which is impossible for very large NLP models.   This paper propose GhostClipping method to save the memory, without the need of per-sample gradient instantiated. The idea is compute the partial sum of gradient element-wise square using two small matrices of the size of $T\\times T$, where $T$ is sequence length (<=1024 in practice), and aggregate them to obtain the per-sample norm (just a scale for each). And then it performs a second back-propagation to compute aggregation on the clipped gradient. It will uses almost the same memory as standard SGD (or ADAM), with one forward pass and two backward passes.   This paper also introduce two additional techniques to improve, one is choose a larger batch size, and the other is to introduce multi-task finetuning (fine-tuning includes masked prediction task on the target dataset). These two are important in boost the performance of the final models.   The paper evaluates on text classification, data-to-text generation, and dialog generation tasks. The results shows it gains prior DP methods.     ",
    "This paper investigated the problem of privately fine-tuning large language models for downstream NLP tasks, including sentence classification and language generation. The authors showed that by appropriately selecting hyper-parameters (including batch size, learning rate, training epochs, and clipping norm) and making the fine-tuning task aligned with pretraining tasks, directly fine-tuning large language models with DP-SGD yields strong performance, and provided an empirical guideline for setting a good training configuration. The authors also proposed ghost clipping trick for further memory saving when fine-tuning large language models. Finally the authors showed through experiments that low dimensional updates do not necessarily lead to better performance.",
    "This paper proposes a transform-and-control policy to optimize the robotic agents' designs. Contributions include: - A novel perspective on agent design: rather than formulating agent design as a bi-level optimization, this paper embeds both design generation and control into a single decision-making process such that both design and control are optimized by the same RL algorithm. - In this formulation, the training experience from different designs is shared to improve sample efficiency. - Joint-specialized MLP on top of the GNN policy that further finetunes the control of individual joints.",
    "The paper poses the problem of morphology design for robots as RL training of one joint GNN policy. Their policy first generates the robot's morphology and then evaluates the design with a common behavior policy that conditions on it. The authors also introduce a technique called JSMPL to allow asymmetric morphologies. Experiments in the Mujoco simulator demonstrate a large improvement over evolutionary methods in terms of sample efficiency and final performance (although the latter is less clear, as neither method has clearly converged). Ablation studies show that the GNN architecture is essential, but are less clear about the impact of JSMPL. ",
    "The paper proposes an algorithm for simultaneous agent design and policy optimization. The choice of the body structure is treated as another action available to the agent. Therefore, the policy is parameterized by graph neural networks (GNNs), and it outputs i) the skeleton structure, ii) node attributes such as bone length, size, motor strength, and iii) motor control commands. Thanks to the parameterization via GNNs, the policy can be trained with PPO. Experiments show that the proposed method outperforms prior approaches, which mainly employ evolutionary methods for optimization, whereas the proposed method leverages more sample efficient policy gradient algorithms.",
    "The paper introduced a reinforcement learning algorithm that simultaneously optimizes the design as well as the controller of a simulated robot to perform locomotion tasks. The core idea is to train a conditioned policy that performs the task in three stages: 1) morphology design of the robot, 2) design parameter adjustment, and 3) controlling of the robot to perform the task. By integrating the design process into the policy learning framework, they are able to design novel and effective agents to complete a variety of tasks. To support the proposed algorithm, graph neural networks is heavily used to support different morphologies. They further propose a joint-specific architecture to improve flexibility of the network, which improves the performance of the algorithm.",
    "The paper proposes a novel coordinate-based network architecture which proposes to process each of the input coordinates independently in the first layer instead of together in a fully connected layer. This input style results in a speed-up in terms of evaluation of the network, and thus faster training and inference in tasks where coordinate-based MLPs are used, without incurring a significant degradation in terms of the quality of the signal fit. These benefits are demonstrated for the tasks of image representation, video representation, and 3D shape representation.",
    "This paper proposes a new architecture for implicit neural representations, called CoordX, which splits each dimension of the input signal into separate branches (e.g. the x and y coordinates of pixel locations in an image) and processes each of these separately before fusing them. The authors achieve this by projecting each of these branches into a hidden feature and then using shared fully connected layers to process these. Each branch is then fused by an outer product which then reconstructs the entire input grid (e.g. for an image of size H x W, 2 branches take in H locations and W locations respectively which are then combined into H x W features by the fusion operation). The fused layers are processed by a few more MLP layers to output the predicted features. In addition, the authors propose a method for effectively subsampling the grid during training as well as different splitting strategies for the branches.  The authors perform experiments on various data modalities, including images, videos, 3D shapes and NerF scenes.  The main contributions of the paper in my eyes are then: - Introducing a new architecture for implicit neural representations that in certain cases can improve training/inference speed without incurring a decrease in reconstruction - Experiments on various data modalities showing the strengths/weaknesses of the method ",
    "Summary: This paper proposes a modification to INR models on multidimensional coordinate grids where a subset of the earlier layers operate on the decomposed coordinate grid. In this setup, the grid (which is assumed to be regularly sampled to permit this decomposition) is broken into its constituent components, (e.g. x and y instead of (x,y)), passed through a single linear layer unique to that component, then through a stack of shared layers, followed by an outer product to return to the joint (x,y) space, and at least one layer that operates on the joint space. This approach lightly reduces parametric efficiency but strongly improves compute efficiency (both in terms of FLOPS, memory usage, and actual observed runtime) for common implicit neural representation tasks, including fitting images, videos, shapes, and volumetric rendering via radiance fields. ",
    "The paper proposes an interesting tweak to the network architecture to accelerate CoortMLP. The idea is to split the input coordinates along the dimensions and then share weights before fusion.  The authors analyze the theoretical upper bound (as far as the MAC ops are concerned) and show about 2X speedup on actual machines.",
    "This paper proposes a novel unsupervised scene decomposition model that infers object shapes, appearances and 3D poses. The benefits over existing models are the structured, 3D object representations which allows to manipulate objects in the scenes such as moving and replacing objects. This paper also shows that the inferred object representations can be used in a visual reasoning task.",
    "The paper aims to decompose a scene into objects and infer the representations of 3D occupancy, color, and pose for each object from a single image of the scene without supervision. To this end, the paper proposes an autoencoding solution by combining the Slot Attention encoder with the GIRAFFE decoder. Each object is represented as a Neural Radiance Field (NeRF) additionally parameterized by the latent variables inferred from the encoder. The decoder then compositionally renders the objects. The experiments show that the proposed model (1) achieves competitive 2D segmentation performance on CLEVR6, (2) supports object-wise scene manipulation, and (3) outperforms non-object-centric methods on CATER snitch localization when combined with a powerful transformer.",
    "This paper proposes a model which is able to segment 3D scenes into objects by a combination of slot-attention (For inference) and a mixture of object NeRF functions which mix together (in 3D) to compose a scene. The method receives a single input image (with the camera coordinates though these are fixed) and extracts a set of slots - one slot for each object. These slots are decoded using a NeRF renderer: one part (the shape) generates the density, one (the appearance) generates the colours and one (the pose) transforms the points of the object to the appropriate pose in scene space. Results are demonstrated on CLEVR data as well as CATER (which is visually very similar) and some downstream tasks.",
    "This paper proposes a model to infer structured 3D object representations from a 2D scene in an unsupervised fashion so as to represent the visual scene in an object-centric way. Specifically, the inference part adopts a similar mechanism as Slot Attention to derive object slot latent code, and then maps slot latent code to 3D object representations with MLP. The rendering part takes the idea from 3D neural rendering where a shared NeRF function is used to represent all objects excluding the background. Rendering is performed by querying NeRF with 3D location, 2D view direction as well as object latent to get object color value and occupancy value. Object rendering is composed into scene rendering according to location derived at the inference stage and weighted by occupancy value.  To sum up, the paper interprets a 2D visual scene with 3D object-centric representation. With the existing 2D object-centric scene segmentation method and 3D neural rendering approach, it achieves comparable segmentation performance and derives manipulable object representation.",
    "The paper sheds an exciting light on the problem of producing a meaningful evaluation of GNN explanation methods (at least a subset of them). The idea is to introduce a deconfounder D to capture the effect of OOD explanations. The authors make an interesting example for a well-known synthetic dataset where the weight of the explanation in the ground truth is lower than a clear non-valid explanation when evaluated using the model to explain. The introduction of the deconfounder D creates a spurious path between the graph variable and the explainer variable. To mitigate this effect, then, they introduce a front-door adjustment to the causal graph. The front door adjustment requires a graph generator and authors use a novel Conditional-VGAE to generate graphs that will also cover the OOD case. The paper finally presents some experiments showing the evaluation method in action.",
    "In this paper, the authors use a causal view to investigate the OOD effect on the explanation evaluation of GNNs. They find the confounder between the extracted subgraphs and the model prediction, which makes the evaluation less reliable. To solve this problem, the authors proposed a deconfounding evaluation method based on the front-door adjustment from causal discovery. To generate a reliable surrogate subgraph, they proposed a generative model, which contains three losses for training. The experimental results show the effectiveness of the proposed method (DSE).",
    "This paper has done an excellent work of finding the out-of-distribution between the subgraph and graph as the confounder. Further, this paper proposes a conditional variational graph auto-encoder in assessing the causal effects of subgraph on the prediction. They also introduce a surrogate variable to denote this out-of-distribution effect. Through adversarial training, the effects of the proposed model is correctly verified.  ",
    "This paper presents a novel explainer-agnostic method to adjust the biases of feature importance scores of feature attribution for GNNs. The paper first describes the feature importance scores of the GNN feature attribution framework have biases due to the out-of-distribution (OOD) problem. The subgraph important scores are calculated by inputting a subgraph instead of data graphs, but subgraph patterns can fall into regions outside the distribution of training data graphs. To address this problem, the paper proposed a method to generate surrogate graphs within the data graph distribution by CVGAE to make a front-door adjustment for deconfounding these biases by distribution shift. Experiments using several state-of-the-art GNN explainers shows demonstrated the effectiveness of the proposed framework. ",
    "This paper investigates if using large, pretrained models in an active learning setup helps achieve better performance with lesser data when compared to using randomly sampled data. In order to conduct this investigation the authors study the empirical performance of large pre-trained models on some image datasets and a text dataset. In both cases large pre-trained model is finetuned on a small amount of seed data and then an active learning procedure is used (in this paper the AL procedure is an uncertainty sampling procedure) to collect more data. The datasets are chosen to illustrate several conceptual issues (i) distinguishing causal from spurious correlations (ii) measuring robustness to distribution shifts (iii) role of data imbalance.   Experiments are performed to show that using an active learning procedure indeed helps improve performance using only a small amount of actively labeled training dataset.  The paper is well written and the results are convincing and insightful. ",
    "The authors describe interesting empirical observations regarding using uncertainty sampling to select examples to fine-tune models that use pretrained embeddings and provide some hypotheses regarding the reasons for these performance improvements. Specifically, (1) from a methodological perspective, they propose using uncertainty sampling (i.e., least confident selection) to select examples for fine-tuning image/NLP pretrained models and (2) from an empirical perspective, they use Waterbirds/Treeperson/iWildCam2020-WILDS for image classification and Amazon-WILDS for review star prediction based on text and compare with random sampling \u2014 noting that these are settings where there is known covariate shift between train/test with semantic meaning to induce interpretable spurious associations (e.g., background in images). The proposed method works overall, especially on the image datasets, and they also dig into the types of examples selected \u2014 noting that they align with expected \u2018difficult\u2019 examples (depending on the setting).",
    "The authors set out to investigate if active learning is an emergent property of pre-training. That is if running active learning with pre-trained models gives better result than using the same models without pre-training. They run several experiments on different text and image datasets first showing that active learning performs better than random sampling on pre-trained models and secondly that pre-trained models perform better than un-pretrained ones for active learning.",
    "This paper investigates the active learning performance of pre-trained models vs their non-pre-trained counterparts on both vision and NLP tasks. Specifically, the investigation focuses on datasets with spurious correlation, domain shift, and label imbalance. Empirical results generally show that the pre-trained models with the uncertainty acquisition function performs much better than the random baseline and their un-pre-trained counterparts. ",
    "Automated program repair benefits from knowledge of its many properties, which includes its inherent (parse-)tree structure and graphical properties such as data-flow. This work proposes a graph-based encoder coupled with a tree-edit decoder, and optionally pretrained on a tree-based objective comparable to masked language modeling. The resulting model efficiently leverages relatively few parameters to achieve near-SOTA performance on a benchmark compiled from real-world bug fixes.",
    "This paper presents a model over sequential structural tree edits, used for program repair based on ASTs. The model itself uses a graph encode and decoder to predict the sequential tree edits. The authors also introduce a method for pretraining the model on existing (non program repair) code data: they delete subtrees of arbitrary size from the code, and predict their reconstruction. The resulting model performs comparably to several other state of the art code repair models on the Patches in the Wild Java repair dataset, but with fewer parameters than several of the best-performing pre-trained models (CodeBERT, CodeT5). ",
    "The paper proposes a new approach to abstract syntax tree-based automatic program repair. The novel technique called deleted-subtree reconstruction is based on dropping parts of the syntax tree and training the model to grow them back. The method is evaluated against edit-based and sequence-based approaches, where it outperforms only the edit-based ones.",
    "The paper presents GRAPHIX, a graph edit model for program repair. The work is directly related to Hoppity (Dinella et. al. 2020) which proposed using a sequence of graph edit for program repair. GRAPHIX employs multi-head graph encoder which improves upon Hoppity in terms of accuracy and complexity. Notably GRAPHIX is able to learn longer edit sequence and thus work on more program repair samples. The work has also proposed a pre-training task to improve model performance. Empirically the authors evaluated GRAPHIX on the *Patches in the Wild* Java bug-fix benchmark. It outperforms various baselines without pre-training. With pre-training, GRAPHIX-P stays roughly on par despite having much smaller model.",
    "This paper tackles an important problem in federated adversarial training: robustness accuracy significantly drops at the later stage of training. The authors first raise their assumption for the cause of this phenomenon: Adversarial training amplifies the heterogeneity of data distributions across different clients, and overfitted local robustness can not well generalized to other clients. Based on this assumption, the authors proposed \\alpha-weighted federated adversarial training, which essentially up-weights the model trained on benign distributions and down-weights those on harsh distributions when averaging them up at the cloud center. Results show the proposed method outperforms previous state-of-the-arts under different adversarial training and federated learning settings. ",
    "This work studied the limitation of conventional Federated Adversarial Training approach, and proposed an \\alpha-weighted relaxation for Adversarial Training in the federated learning setting. Then it proposed a novel \\alpha-Weighted Federated Adversarial Training for minimizing a lower bound of the inner-maximization in Federated Adversarial Training. The performance of the proposed \\alpha-Weighted Federated Adversarial Training were validated for both IID and Non-IID federated learning settings.",
    "This paper introduces the alpha Weighted Federated Adversarial Training algorithm. The key of the idea is that in the aggregate step, the center prefers the local machine that yields smaller lost. Some theoretical results are delivered with numerical experiments. The paper claims that the alpha-weighted mechanism is tailored for the inner-maximization of Federated Adversarial Training, which is the rationale of the whole work.",
    "The authors explore the adversarial robustness of federated learning. They claim that the inner-maximization optimization of AT can exacerbate the data heterogeneity among local clients. They propose an algorithm, $\\alpha$--WFAT, which relaxes the inner-maximization of Adversarial Training into a lower bound friendly to Federated Learning.. The authors also experimentally establish that federated learning models are most susceptible to attacks when clients are using non-IID training sets. The experiments are performed over the CIFAR-10 , SVHN and CIFAR-100datasets.",
    "In contrast to previous works on lifelong machine learning (LML) that put their focus on the supervised learning settings, this paper concentrates on the scenario that only a limited amount of data is available. The proposed method MAKO is mounted on the top of supervised LML model, without introducing additional knowledge based overhead, for better leveraging the unlabeled data. Labeling new data can be realized by using the data programming method which is supervised by the labeled data. The target of this paper is to design a SSL LML framework that minimizes the performance between using partially labeled data, and the upper-bound performance using fully labeled data. Several experiments on standard image classification data sets including MNIST, CIFAR-10 and CIFAR-100 are used to evaluate the the effectiveness of MAKO. ",
    "This paper propose a wrapper tool that mounts on top of supervised Lifelong Machine Learning (LML) frameworks, leveraging a well-known method data programming. The contributions of this paper can be summarized in three aspects. 1)  Adapting automatic label generation by semi-supervised learning/data programming to LML in some special scenario. 2) Implementing a LML wrapper that can accomplish some tasks under some restrictions. 3) Through detailed experimental results prove the superiority of its method.",
    "This paper proposes  data programming method, named Mako,  for semi-supervised continual learning. Mako automatically generates labels for unlabeled data with a set of weak labeling functions, each of the functions is trained on subset of training set with bootstrapping. Experimental on several datasets demonstrate the effectiveness of the proposed methods. ",
    "This paper presents an interesting idea of using data programming techniques to enable continual semi-supervised learning with limited labeled data. It proposes a stage-wise pipeline where probabilistic pseudo labels are first produced by a Snuba based Data Programming framework, then calibrates them by the temperature scaling, and finally inputs into the mounted Lifelong Machine Learning (LML) tools. Experiments show that the proposed framework achieves similar performance to fully supervised methods.",
    "The authors propose an attack that could break 4 adversarial detection methods published recently. Traditionally, attacks against detection methods have attempted to maximize the loss for both classification and detection simultaneously. However, using a toy example the authors show that this is suboptimal, as it may not find the worst-case adversaries. The authors propose to minimize the loss (targeted attack setting) iteratively by optimizing either only for the classification pipeline or the detection pipeline at a time.  The attack first considers the classification loss and further tries to fool the detection pipeline until the classification prediction remains incorrect. The authors also propose a variant of the attack by considering gradient steps for the classification pipeline to be orthogonal to the gradients of the detection pipeline and vice versa. Finally, the paper shows that these two proposed attacks completely circumvent four recent adversarial detection methods.",
    "This paper considers the problem of finding adversarial examples that simultaneously defeat a detector of adversarial examples. An argument is made that existing attacks often achieve one goal at the expense of another. This argument motivates the proposal of two attack techniques. These are evaluated against four existing detection-based defence methods, with successful results.",
    "This paper targets on attacking the defensive mechanism of adversarial examples detection. It proposes a new optimization algorithm to simultaneously meet two different requirements. It verifies its effectiveness on several state-of-the-art adversarial example detection methods.",
    "This paper proposes two techniques for generating adversarial examples: Selective Projected Gradient Descent (SPGD) and Orthogonal Projected Gradient Descent (OPGD). In order to fool both the victim model $f$ and a detector $g$, SPGD selectively optimise either $f$ or $g$ depending on whether the modified input is misclassified as the target class, while OPGD further orthogonalizes the gradients. Evaluation on four previously unbroken, state-of-the-art defence methods demonstrate the effectiveness of the proposed attacks.",
    "This paper studies valuation problems from cooperative game theory. There are $n$ agents and a valuation function $F: [n] \\to R$ where $F(S)$ is the collective payoff of the coalition $S \\subseteq [n]$. The goal is to use this function $F$ to define an importance vector $\\phi(F) \\in R^n$. Examples include the Shapley value and Banzhaf index.  The authors introduce a probabilistic treatment of this problem, where they use $F$ to define a probability distribution $p$ where $p(S)$ is the probability that coalition $S$ forms. They then phrase the problem of defining an importance vector $\\phi(F)$ as a decoupling problem. Under $p$, the $n$ agents may be correlated in a complicated way, but to assign each of them an individual importance value, one must decouple their interactions, or simplify their correlations. The goal is then to find a product distribution $q$ that is as close to $p$ as possible under the KL divergence. Specifically, the authors define $q$ to be an $n$ independent Bernoulli distribution, where the probability that agent $i$ participates in the coalition is denoted $x_i$. The authors show how to optimize the probabilities $x_1, \\dots, x_n$ using coordinate ascent. Finally, they define the importance score of player $i$ as $\\log(x_i/(1-x_i))$ (ignoring a temperature $T$ term for simplicity). The authors show that the resulting importance vector satisfies many of the game-theoretic axioms that the Shapley value and Banzhaf index satisfy, like the null player, marginalism, and symmetric axioms.  In the experiments, the authors look at small instances with $n = 25$ where it is actually possible to compute the gradients exactly (as opposed to an approximate sampling method). The applications they look at are for data valuation and feature attribution in the context of machine learning. For these tasks, they show that their proposed approach performs about the same as the Shapley value and Banzhaf index, and sometimes a bit better.",
    "Valuation criteria based on game-theory (e.g. Shapely value) have been used in the ML literature for analyzing feature importance and for data subset selection. These criteria serve as solution concepts for cooperative games and have been adapted by some works in ML for subset valuation problems.    The present paper presents a probabilistic treatment of cooperative games, and shows that two classical valuation criteria can be seen as a one-step factored approximation to maximum entropy solution to the game. They then propose a new valuation criterion \"Variational Index\" that uses a multi-step factored approximation and show it satisfies some common axioms for cooperative games. The paper also has experimental results on the proposed criterion.  ",
    "The paper studies valuation problems for cooperative games. It proposes a new valuation measure called Variational Index. The idea is to create a coalition probability distribution based on a maximum entropy criterion. Player valuations are then derived by creating decoupled surrogates of this distribution. The authors then present a gradient ascent algorithm to compute this decoupling. Classical valuation criteria like the Shapley value and the Banzhaf index can be recovered as special cases or modifications of the algorithms iterates.",
    "This paper proposes an energy-based perspective on cooperative games that permits a gradient-based calculation of Shapley/Banzhaf values, as well as the definition of a new alternative value - the variational index. A quick summary of the paper's key ideas is:  - For a given cooperative game $F$, we can seek an entropy maximizing distribution over coalitions $p(S)$ that satisfies a constraint on the mean coalition value $\\mu$ - Solving the entropy maximization problem via its Lagrangian yields the Boltzmann distribution $p(S) \\propto \\exp(F(S)/T)$, where the temperature $T$ has a one-to-one correspondence with the mean coalition value $\\mu$ (this result is in the appendix). This distribution gives more probability mass to coalitions that achieve higher values - We can seek a simpler alternative to $p(S)$ by doing mean-field variational inference, i.e., finding a factorized surrogate $q(S)$ where each player's participation is determined by independent Bernoulli RVs. The result will intuitively assign higher probabilities to players that belong to high-value coalitions, so these probabilities can serve a function similar to Shapley/Banzhaf values - The VI approach suggests a KL divergence minimization (or ELBO maximization) objective for learning $q(S)$, which is parameterized by $x \\in [0, 1]^n$. Doing gradient descent on this objective yields a relatively simple update rule, where we repeatedly set $x_i^+ = \\sigma(\\nabla_i f_{mt}(x) / T)$ for $i = 1, \\ldots, n$ - The authors define the \"variational index\" as a function of the solution to the KL divergence minimization problem: $s^* = T\\sigma^{-1}(x^*)$ - The authors find that the Banzhaf value can be found using a single-step update to a particular initialization of the KL divergence minimization problem (luckily the temperature $T$ is not important for single-step updates). Similarly, they find that the Shapley value is the average of the single-step update applied to different initializations (again, the temperature doesn't matter). Finally, the authors point out that any single-step update applied to a symmetric initialization will be a probabilistic value (a class of solution concepts in cooperative game theory, of which Shapley/Banzhaf values are special cases) - Lastly, the authors suggest a practical sampling-based approach to calculating the necessary gradients, which are just as difficult to calculate as the Shapley/Banzhaf values because they require calculating the value for every coalition $S \\subseteq N$  The experiments compare the variational index to Shapley and Banzhaf values in data and feature removal tasks, finding that it performs quite favorably in the settings examined.",
    "This paper uses out-of-sample prediction error as a measurement of epistemic uncertainty. Using this definition, it develops an estimator: direct epistemic uncertainty prediction.  The idea is to have a main predictor to learn the task, and an error predictor to predict the generalization error. Empirical studies show that their proposed estimator produces better estimation on downstream tasks such as sequential model optimization and reinforcement learning. ",
    "Given some supervised task, this paper redefines the uncertainty of a solution as its generalisation risk. The authors then propose to learn a secondary function to estimate the generalisation risk of the first. This is done by using held-out points as training data for the secondary model. In turn, this held out used to estimate the primary model error comes from a k-fold split.  The inputs to the secondary model are the data points being evaluated, estimates of the predictive variance of the primary model, density estimates from a generative model and whether the point has been observed by the primary model.  The authors posit that the advantage of their method is that it can capture uncertainty due to model selection bias, something omitted by existing work, which focuses on the variance of the learnt estimator. The authors provide a diverse range of experiments: OOD rejection in image classification, active learning for drug discovery, function optimisation and exploration in reinforcement learning. ",
    "This paper proposes a new approach for computing epistemic uncertainty. The proposed approach, DEUP, builds a new model (in addition to the original model) which predicts epistemic uncertainty, defined as generalization error minus aleatory uncertainty. I highlight some features of DEUP below: - DEUP works with a hold-out dataset that is used for training the error predictor.  - In case there does not exist a hold-out set or in interactive settings (like RL or active learning), DEUP is extended to be used in a cross-validation setting and the features used to fit the error predictor is extended to include data density estimates and model variance. DEUP is evaluated on different settings including OOD data, sequential model optimization and RL.",
    "This paper proposes a method to estimate the epistemic uncertainty (uncertainty due to lack of knowledge/data) at a new model input. The paper takes an indirect approach towards this goal by a) first estimate the generalization error at the new input, b) next estimate the aleatoric error (inherent uncertainty in the data distribution / irreducible error), and c) subtract aleatoric error estimate from the total generalization error estimate to obtain the epistemic uncertainty estimate.  The authors claim that this method captures both the uncertainty due to lack of data, as well as model misspecification in the process - while other/existing methods focus mostly on the variance of the posterior distribution (or its approximation) as a measure of epistemic uncertainty (and thereby implicitly assume the model is well specified.)  Estimating the total generalization error itself is performed with a second neural network model, which uses residuals obtained from the primary model as its labels. Estimating aleatoric error either assumes the presence of an Oracle or   The authors apply their technique on both static (fixed data set) as well as interactive (active learning) settings, though mostly focused on the mean squared error loss function.",
    "This paper proposes a block coordinate descent algorithm for rotation learning. The algorithm is based on Lemma 1 and Theorem 1. The rotation matrix on SO(n) is decomposed into diverse simple Givens rotation matrices. Then the optimized variable is converted into these Givens rotation matrices so that the rotation matrix is always on SO(3) and the projection is not required anymore. The authors also discuss how to select the coordinate, including random strategy, greedy strategy, and steepest strategy. Different from the existing work, it considers multiple Given rotations matrices in one step. ",
    "Current rotation learning methods are trying to minimize quantization distortion for fixed embeddings, which are not applicable to an end-to-end training scenario where embeddings are getting updated constantly. Therefore, this paper tries to address this issue to fully enable end-to-end training of Product Quantization (PQ) based embedding index with retrieval models, by using mathematical studies of the decomposition of orthogonal group. They proposed a family of block Givens coordinate descent algorithms to learn rotation matrices that are provably convergent on any convex objectives by leveraging geometric intuitions from Lie group theory. Authors claimed that their algorithms are much more parallelizable, reducing runtime by orders of magnitude on modern GPUs, and converge more stably according to experimental studies in comparison to the state-of-the-art SVD method.   Their main contributions can be summarized as follows:  - Changing the landscape of learning rotation matrix in approximate nearest neighbor (ANN) search from SVD based to iterative Givens rotation-based, to be applicable to end-to-end neural network training.  - Proposing a family of Givens coordinate block descent algorithm with complexity analysis and convergence proof.  - Proves that for the fixed embedding, their algorithm shows similar convergence result as the existing rotation matrix learning algorithms. Therefore, their proposed algorithm is able to learn the rotation matrix more effectively for the end-to-end training.",
    "This paper proposes to learn rotation matrix by Givens coordinate descent algorithms in the context of minimizing the quantization distortion for efficient storage. The proposed family of Givens coordinate descent algorithms are based on geometric intuitions of the special orthogonal group and are provably convergent on any convex objectives. The experiments show that the proposed algorithms are much time efficient and lead to performance improvement in an end-to-end training of embedding indexes.",
    "The paper address rotation matrix learning during product quantization in modern ANN embedding search systems. The main contribution is addressing rotation matrix learning via gradient descent of small rotation updates. The approach relies on the decomposition of any small rotation matrix into a product of Given rotations, so that partial derivatives can be obtained in parallel, but the product causes the computation of the rotation matrix itself to be slow, in O(n^2) matrix multiplications, hence the need to select a subset of coordinates and do coordinate descent. Experiments on product quantization show a marginal improvement in results over existing approaches OPQ and Cayley.",
    "This paper targets the problem of abstract reasoning, with a special focus on the task of learning visual analogies. The authors propose a multi-stage neural network (Neural Structure Mapping, NSM) for decomposing the problem into vision relationship recognition and concept inference. They tested their model on an existing RPM (Raven's Progressive Matrices) based visual analogy benchmark that contains different systematic generalization tests and outperformed existing models. The authors made further discussion on these experimental results to support their proposals on model designs.",
    "A model called Neural Structure Mapping (NSM) is introduced to solve the task of abstract visual analogy making. The NSM model consists of a visual relationship encoder and an analogy inference engine. The visual relationship encoder extracts the visual domain elements, including object, attribute, and relation, while the analogy inference engine is a neural modular architecture that constructs the model layout based on the relation and predicts the final answer. On the dataset proposed by Hill et. al., the NSM shows better performance than other baselines.",
    "This paper tackles the problem of analogical reasoning. In particular, it presents a framework for learning the Raven Progressive Matrices (RPM) task, an abstract analogy task.  In the RPM task, a sequence of three images from a source domain are given. There is some relationship that holds for the sequence, e.g. the third image is the union of the first two. Then, given an incomplete sequence of two images from the target domain, the third image must be chosen from a list of four possible candidates.  The proposed Neural Structure Mapping (NPM) system consists of two pieces. The first piece is the Visual Relationship Encoder. Given the source sequence of images, the encoder predicts the type of relationship exhibited in the sequence. This information is passed to the second piece, the Analogy Inference Engine. The architecture of the engine is assembled dynamically, according to the predicted relationship. The assembled network takes the target sequence and the candidate matrices as input and selects the completion of the sequence from among the candidates.  The encoder is trained with the ground truth relationship labels. The engine is trained using the ground truth candidate labels.   The paper presents an experiment to test systematic generalization, in which particular attributes are held out during train time. The NSM system is found to achieve better performance.  In contrast to Hill 2019, which presents the model with semantically-contrasting alternative candidates at train time, NSM achieves good performance even when the alternative candidates are not necessarily semantically related.  ",
    "This paper proposes a new architecture for learning visual analogies, based on Gentner\u2019s Structure Mapping Theory for how humans might draw analogies. Gentner\u2019s theory proposes representing the relationships between objects explicitly, so that this relational structure can be reused in new domains (and suggests that this commonality in structure is what permits analogies to be made between perceptually dissimilar objects). The authors propose a neural network model architecture and test it on the Raven\u2019s Progressive Matrices dataset. The proposed architecture first splits a series of \u2018source\u2019 visual scenes into objects, attributes and the relationships between those scenes, before feeding just the relationship head into a second network. The second network then switches between two different architectures (depending on the relation fed in). The architecture in the second network (whichever is chosen) receives the \u2018source\u2019 relationship and two \u2018target\u2019 scenes before trying to predict which of a set of 4 candidate  \u2018target\u2019 scenes completes the visual analogy between source and target. The authors test their architecture on the generalisation splits in the RPM dataset and compare test accuracy results to the baseline models used by Hill et al, 2019. The authors show that their model (which builds in additional architectural structure) performs better at a subset of tests than more general architectures.",
    "Recently several works have proposed semi-supervised learning methods to leverage unlabeled biological sequences for learning their general-purpose representations. In this work, the authors proposed the Self-GenomeNet, a novel contrastive learning method for nucleotides based on the reverse-complement (RC) context prediction. First, given a sequence, they divide it into two subsequences and transform one into its RC. Then, the model is trained to distinguish their representations from those of other random nucleotide sequences. The authors claimed that the proposed method considerably outperforms previous self-supervised baseline models on three benchmark datasets in both self-supervised and semi-supervised evaluation ",
    "This paper presents a self-supervised learning approach using contrastive loss for representation learning of genomic sequences. The contrastive loss has been used for self-supervised learning in the NLP and computer vision domains and the paper presents its application for genomics. Self-supervised contrastive learning tries to maximize the agreement between augmented views of a sample. Therefore, Self-GenomeNet splits a sequence into two subsequences, and the learned representation of subsequence 1 is compared to subsequence 2 and its revers compliment (positive samples) as well as other sequences (negative samples). The described method has two considerations specific to the genomics tasks - (1) it handles variable sequences (2) it incorporates reverse complement information of the sequences. The method is applied on two prediction tasks and one transfer learning task using sequences from viral, bacterial, and human genomes. Its performance is compared to the supervised model, generative language model, and self-supervised learning models - CPC and Contrastive-sc. The results show improved classification performance over the baseline for both supervised retraining and semi-supervised training settings. ",
    "This submission introduces self-genomenet, a self-supervised training method for learning from DNA sequences. The self-supervision is done by predicting the end of a sequence from its start (both broken into smaller subsequences), through a contrastive loss against other random sequences. The predicted part is also reverse-complemented (RC), making the network learn the expected reverse-complement invariance of the prediction function. The method is extensively tested on several learning tasks, where it shows good performances.",
    "The authors proposed a self-supervised learning method for nucleotide-level genomic data utilizing reverse-complement of genomic sequences. The proposed method achieved a considerable performance improvement. In addition, the authors proposed an architecture called Self-GenomeNet that handles varying-length genome sequences.",
    "This paper proposes to make the geometric neurons of Melnyk et al.'21 to be steerable so that objects undergoing arbitrary rotations can be classified with higher accuracy. This is done in multiple stages. First, the neurons of Melnyk et al. are trained to convergence with a hyperspherical output layer. Then, the frozen weights are transformed such that the input of a *steerable neuron* can be written as a linear combinations of the rotated versions of itself. The experiments act as a sanity check while demonstrating the validity of the algorithm on a simple human pose dataset.",
    "The paper proposes a method for constructing steerable spherical neurons, building on the recent Geometric Neurons developed in Melnyk et al 2021. The main technical result in the paper is a steerability constraint for a geometric neuron, as given by eq. (13) in the paper. This constraint is used in an implementation whereby a steerable model is constructed and is then use for two tasks. The first task involves the use of steerable spherical neutrons for the classification of 3D Tetris objects seen under rotations, and the second is a similar experiment applied to 3D skeleton data. The results demonstrate a very large performance boost when using the steerable versions. The second experiment builds on this idea to construct a version that adapts a possibly imperfect initial rotation estimate, using the representation. This second experiment is in the spirit of demonstrating equivariance under 3D rotations with perturbations.",
    "## Summary and contributions. Authors propose 3D \"spherical neurons\" leading to rotationally equivariant layers. They do so by building on the spherical and geometric neurons introduced in Melnyk et al. (2021), which leverages the conformal space (for $\\mathbb{R}^n$) to perform operations. The authors then solve for the steerability constraint for this neuron and empirically show that the proposed approach overperforms Melnyk et al. (2021) on rotated 3D data. ",
    "The paper aims to derive a steerability constraint for spherical neurons (3D point classifiers with spherical decision boundary). The steerability constraint enables test-time optimization of a pre-trained classifier to make predictions equivariant to 3D rotation perturbations applied to the input. When input rotation perturbations are unknown, the authors propose a method to recover the unknown rotations and therefore make rotation-invariant predictions. The experiments on a few small scale datasets verifies some of the claims.",
    "As the title suggests, the paper is a comparison of recent continual learning methods that prevent catastrophic forgetting and their effectiveness in some text classification tasks using popular pretrained language models such as BERT, RoBERTa, etc. The paper divides continual learning methods into three categories: (1) rehearsal-based, (2) regularization-based, and (3) dynamic architecture. The experimental results show that rehearsal based methods are superior to the other two, and also that BERT is generally better than other candidates. The paper then proposes a new probing techniques to find out what makes rehearsal-based method better and what's happening inside BERT. The paper finds that the last layer has the biggest catastrophic forgetting and lower layer is less impacted.",
    " This paper conducts an empirical study on the catastrophic forgetting of pretrained language models. On two continual learning settings (class incremental and task incremental), the paper evaluates multiple pre-trained models on different data sets, to see how severe the catastrophic forgetting issue is for these pre-trained models. Then the paper also tests the effectiveness of multiple continual learning methods on such pre-trained models and draws some conclusions. ",
    "The authors perform a comprehensive study of how pretrained language models work in the continual learning setting. The authors study 5 relevant pretrained language models (masked and unmasked) and somewhere between 3 and 6 continual learning strategies depending on where in the paper they are counted. In addition to a thorough everything-by-everything evaluation, the authors hone in on the details of how the different models and CL approaches are reflected in the transformer layers. The authors find that the different language models studied perform relatively differently, both qualitatively and quantitatively, and these insights may provide useful for directing future improvements.",
    "This paper explores the continual learning performance when combining different PLMs and common continual learning methods with 3 challenging NLP classification tasks.  To benchmark these combinations the methods are evaluated in task-incremental and class-incremental learning settings over various NLP end-tasks, which covers common learning settings in continual learning and NLP. There is also a layer-wise performance analysis to identify which layers keep or forget task relevant information during training.  Overall the paper shows that forms of replay outperform other methods like regularization.",
    "The paper tackles the problem of adversarial attacks in federated learning settings. The main proposal is a defensive technique to address the \u201cbyzantine generals\u201d problem in federated learning: how to ensure that the general ML model is not affected by \u201cpoisonous\u201d attempts made by corrupted clients. The proposed technique is experimentally validated on four datasets, outperforms previous defensive methods, and the evaluation also considers adaptive adversaries with increasing degrees of knowledge.   Overall, the presentation of the paper is very good. The quality of the English text is good. Figures are appropriate, Tables require some editing. The topic addressed by the manuscript is trendy and in-line with ICLR\u2019s scope. The references should be improved The contribution is significant  STRENGTHS: + Adaptive adversary  + Trendy subject (federated learning) + Evaluation on multiple datasets + Technically sound  WEAKNESSES - Unclear assumptions and threat model. - Problem or Feature space attacks? - Lack of a concrete use-case - Tradeoff? ",
    "The authors propose TESSERACT, an aggregation scheme that is robust to the directed deviation attack (proposed in Fang et. al. 2020). ",
    "This submission with the title \"Tesseract: Gradient Flip Score to Secure Federated Learning against Model Poisoning Attacks \" discusses defenses against data poisoning in federated learning. The authors propose a novel defense against the recently popularized attack \"Tesseract: Gradient Flip Score to Secure Federated Learning against Model Poisoning Attacks \" by Yang et al. This attack reduces model availability by sending malicious updates from compromised client that maximize sign flips in the global model gradient.  This defense then proposes a measure of change in gradient direction that can be evaluated for each local update and used to dynamically down-weight clients with a large number of flips in direction. ",
    "This paper studied a very important topic in the field of federated learning: how to efficiently resist untargeted model poisoning attacks. In order to defend against such a poisoning attack, the authors developed TESSERACT, an aggregation algorithm that assigns reputation scores to participating clients based on their behavior in the training phase and weights the client's contribution. Extensive case studies have verified the effectiveness of the algorithm. In particular, the experimental results show that TESSERACT provides robustness against even a white-box version of the attack. ",
    "This paper considers the problem of estimating an expectation over covariates of some functional of an unknown regression function. The authors propose two estimators, one based on neural networks and one based on random forests. In contrast to many (all?) previous estimators which were derived for specific functionals, these estimators are applicable to general functionals. They employ a (new?) debiasing technique. Moreover, they use a novel multi-task architecture based on the observation that it suffices to estimate the regression function as a function of the Riesz representer. The paper demonstrates improved accuracies compared to prior work and good coverage on semi-synthetic tasks derived from two data sets.",
    "The authors address the problem of estimating the average value of a moment function that depends on an unknown regression function, which is commonly used in causal inference.  By the Riesz representation theorem, the authors design a loss function where the Riesz representer turns out to be the minimizer of the proposed loss.  The authors propose both a Neural Network method (RieszNet) and a random forest method (ForestRiesz), i.e. a multi-tasking Neural Network method where the loss function is a combination of the Riesz representer and regression loss, and a random forest method that leans representation of both the regression function and the Riesz function.  The authors conduct experiments of estimating the average treatment effect and average marginal effects, and show that the proposed RieszNet and ForestRiesz beat the state-of-the-art methods.   ",
    "This paper shows novel methods based on the recent findings on the Riesz representation in econometrics and machine learning, such as Chernozhukov et al. (2021). While the proposed applications make sense and are persuasive, the contributions of this paper are a bit limited. Although the authors support the soundness of the proposed algorithms in experiments, the experiments are a bit simple and may not be sufficient for the justification. ",
    "The authors study the nonparametric estimation of an important class of (causal) estimands that includes the average treatment effect (ATE) in experiments and observational studies under unconfoundedness. The main innovation is the \"automatic\" nature of the procedures, one based on deep learning and one on random forests. While previous work has developed hand-tailored constructions for the ATE (a traditional problem in statistics), the authors show that existing constructions can be generalized considerably based on recent advances in semi- and nonparametric statistics based on Riesz representers. The key challenge this work addresses is the fact that the Riesz representer is typically unknown.  The main proposed method based on deep learning, RieszNet, may be seen as a generalization of the DragonNet procedure by Shi et al. (2019) from the ATE to more general estimands. Even in the case of the ATE, DragonNet and RieszNet are not the same and RieszNet outperforms DragonNet in simulations: RieszNet directly targets the inverse propensities, while DragonNet estimates the propensities and then plugs in their inverse.",
    "This paper establishes the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning (MARL) problems with average reward. It focuses on the practical setting where the rewards and actions of each agent are only known to itself, and the knowledge of joint actions of the agents is not assumed. The established finite-sample complexity matches that of the state-of-the-art single-agent actor-critic algorithms.",
    "This paper considers cooperative multi-agent reinforcement learning (MARL) for average reward MDPs with fully decentralized actor-critic methods. In particular, the authors make some progress on top of existing works in this direction, and in particular (Zhang et al., 2018). More precisely, the authors remove the assumption in (Zhang et al., 2018) that the joint actions are observable to all agents, and propose to modify the actor updates with mini-batch TD sharing to accommodate the scenario where each agent only observes its own action. The authors then establish a finite-sample bound for the proposed algorithm in terms of convergence to stationary points under linear value function approximation. Numerical experiments are also provided to showcase the benefits of the modifications over the algorithm in (Zhang et al., 2018). ",
    "This paper studies the cooperative average reward fully decentralized multi-agent reinforcement learning (MARL) problems, where the agents interact with their neighbors over a communication network. It proposes a consensus-based actor-critic algorithm and shows its convergence to the stationary point. The convergence rate and sample complexity of this algorithm are provided and comparison with existing algorithm is shown in the numerical experiments. ",
    "This paper studies a networked MARL problem based on the model in [Zhang et al 2018], where each agent can observe the global state, take local action and observe local rewards. The key difference in setting from [Zhang et al 2018] is that [Zhang et al 2018] assume the global action can be observed, but in this paper, only local action is known to each agent. To deal with this, an additional consensus loop is added to estimate the average TD error, which can be used to estimate the advantage function. Further, compared to [Zhang et al 2018], a finite time error bound is provided.  ",
    "This paper aims to provide theoretical understanding for contrastive learning where \"similar pairs\" of points $x$ and $x^+$ are encouraged to have similar representations through an InfoNCE inspired objective function. Some prior works show the benefit of learned representations for linearly classifying downstream classes, by making conditional independence like assumption on the similar pairs or positive samples, i.e. $x$ and $x^+$ are (approximately) conditionally independent given downstream label $y$. This work argues that these assumptions are quite strong for contrastive learning with data augmentations, and aims to show guarantees under the following weaker and more realistic assumption: support of augmentation distribution of different inputs from the same class overlap to form a \"connected graph\" of inputs within a class, whereas support of augmentations of inputs from different classes do not overlap. Lower and upper bounds using this and some other assumptions, connecting the downstream performance of representation function to the contrastive loss. Some simulation experiments are presented to support some aspects of the theoretical analysis.  Using the insights from the analysis, the paper proposes an \"Average Confusion Ratio (ACR)\" metric that can be used to predict the ranking of downstream performances of different augmentations **using only unlabeled data**. Experimental evidence is provided on CIFAR and STL datasets to verify the efficacy of this metric for some practical augmentations.    While there are some interesting aspects in the paper (especially the ACR metric), the theoretical analysis seems to have raised many questions and concerns that I have summarized below (details in main review).   - **Soundness of assumptions**: Assumption 4.6, which is crucial, seems questionable and may not be coherent or appropriate to make in this setting. More on this in point (W2) of main review  - **Deeper dive into theoretical results**: There is a lack of discussion about the (non-)vacuousness of the bounds in the main results Theorem 4.2 and 4.8, that puts the interpretation and significance of the result in question. More on this and related issues in point (W2) of main review.  - **Comparison to prior work**: The work of HaoChen et al. in particular is not adequately compared to, especially since some of the points being addressed here are covered through a different kind of analysis in that paper. More on this in point (W3) of main review.",
    "The authors provided a new understanding of contrastive learning from the perspective of data augmentation for intra-class samples. In particular, the authors proposed to understand the role of data augmentation as to create certain ``chaos'' between intra-class samples so to encourage the clustering of intra-class samples and also the learning of class-separated representations. Additionally, a new metric ARC is proposed to evaluate the downstream performance. The conclusion is validated via both synthetic and real-world datasets. ",
    "The current leading theory of what contrastive losses are doing and why they work interprets contrastive learning as balancing alignment with uniformity, as proposed in [2].  This paper seeks to augment that understanding of contrastive learning using a new perspective, focusing on the role of data augmentation.  It is well-known that contrastive learning techniques are highly sensitive to the data augmentation schemes used, most notably discussed in [1].  In this work, the authors interpret augmentation as a way to connect different intra-class images together.  Then, the contrastive loss is seen as a way to gradually cluster intra-class samples together by aligning augmented views, producing representations that are class-separated even in feature space.  On top of introducing a new lens with which to understand contrastive learning, the authors also provide proofs on performance guarantees, as well as a new evaluation metric.  The metric is inspired by their augmentation-oriented understanding, and was also found to align well with downstream performance.  The authors provide a scenario where alignment and uniformity are satisfied, but fails to translate well to downstream classification accuracy.  This suggests to them that the instance discrimination task alone cannot guarantee the learning of class-discriminative features that would enable better downstream classification, and directs their attention to the other important component of contrastive-learning to help explain the story: augmentation.  They then build off the analytical work of [3] to prove guarantees for the downstream performance with a relaxed assumption.   [1] Chen et al., A Simple Framework for Contrastive Learning of Visual Representations, 2021.  [2] Wang and Isola., Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere, 2020.  [3] Saunshi et al., A theoretical analysis of contrastive unsupervised representation learning, 2019. ",
    "The paper proposes a new theory for understanding contrastive representation learning. The novelty is the focus on the interplay between alignment and augmentation. Prior work has identified alignment as one of the factors of contrastive learning, but have not investigated how different types of augmentations may affect the learned embeddings. This work adds that missing piece. The results intuitively make sense, showing that proper amount of augmentation (that connects samples of the same class) has positive effect on downstream classification. Empirically, the authors verify that too weak or too strong augmentation harms performance. Based on observations, the authors define a metric on ratio of positive pairs among nearest (embedding) neighbors, and found the change of this metric throughout training positively correlate with performance.",
    "The paper proposes an approach called VoiceFixer which is aimed at restoring degraded speech signals. The paper considers a variety of speech degradations - additive noise, reverberations, clipping and limited bandwidth. The paper describes a two stage approach in which the first stage aims to produce restored mel-spectrogram and then a vocoder is used to synthesize the  speech from the restored mel-spectrogram. Experiments are done using the VCTK dataset and experiments are done using single distortions as well as combinations of all 4 distortions. ",
    "This paper proposes a general speech restoration (GSR) task that tries to remove multiple distortions in a single model. In addition, it also presents a generative framework called VoiceFixer consisting of analysis and synthesis stages to address the general speech restoration task. In VoiceFixer, the authors employ a ResNet for modeling the analysis stage and a TFGAN-based neural vocoder for synthesis stage. They report that their baseline GSR and VoiceFixer surpass the single speech restoration (SSR) models with more improved results by the latter. Their idea was well described and the experiments are systematical and extensive. The results are consistent and clear.  The contribution of this paper is to incorporate a variety of speech restoration tasks including speech denoising, super-resolution, dereverberation, declipping, etc. in a single unified task called GSR. Another is the proposal of a well-performing generative speech restoration framework called VoiceFixer. ",
    "This paper introduces a unified view of several speech restoration problems including denoising, decliping, dereverberation and audio super-resolution. In order to solve the problem of the general speech restoration task, the authors propose a U-Net architecture which is trained on all of these tasks simultaneously during training time. The authors conduct extensive experiments for the general speech restoration task as well as the individual tasks where they compare the proposed models with more specialized models bounded to each distortion. The experimental results show that the proposed VoiceFixer combination of the model and the analysis-synthesis procedure are capable of effectively removing the speech distortions and in some cases outperform previous approaches in the literature.",
    "The paper proposes a single system to deal with the speech enhancement tasks of denoising, dereverb, bandwidth extension (BWE) and declipping. The system is a two-stage system composed of an analysis module producing mel-band masks and a synthesis module using a vocoder. Both modules reuse existing architectures. Results comparing the proposed system to author-derived counterparts of it and to some existing systems for specific tasks show improvement for the proposed system in some cases, while achieving similar performance as existing systems in other cases. Data and code for reproducibility are provided.",
    "For multivariate time series forecasting, this paper proposes to use a tensor network to model the variable space and improve the quality of the variable space by designing the series-variable encoder. Under the variable space, this paper also proposes an N-order residual connection approach and the skip-connection layer for processing the long-term data. The proposed model MVSRTN achieves good results on some datasets. However, this paper has not well explored MVSRTN, and the results are not very competitive. In addition, there are many typos in the paper.",
    "The paper proposes a deep learning architecture for time series forecasting called MVSRTN. The model is composed of 3 blocks with skip-connections in-between them: a 1) \"Series-Variable Encoder\", 2) an \"N-Order Residual Tensor Network\", as the authors call it, and 3) the output layer. Out of these, 1) is essentially a 1D CNN combined with (causal and non-causal) self-attention, and 2) seems to be a tensor network built from taking the tensor product of the sequence entries, and then contracting that by a TT-rank-constrained weight tensor. The computation of the tensor network output is formulated as a recursion across time-steps, and motivated by residual networks, an identity mapping with respect to the hidden state at the previous time-stamp is added to the recursive formulation. Then, by the analogy with higher-order solvers for ODEs, a \"higher-order residual connection\" is introduced. The model is applied to four time series forecasting datasets, where some improvements are achieved, and an ablation study is included to show how the various model blocks contribute to the performance.",
    "This paper proposed the MVSRTN architecture for multivariate time series modeling. The MVSRTN consists of an encoder to extract latent variables and residual tensor network (TN) blocks to capture the interactions in the latent space.  The main contribution of the model is the TN block part. In particular, the authors used tensor-products to fully represent the latent variable space (Eq 2). Then, they proposed an N-order residual TN block to alleviate potential gradient problems of high-order TNs in long-term time series. They conducted experiments on four multivariate time series data for prediction. Moreover, an ablation study shows the effectiveness of the proposed residual TN blocks.  Combining ResNet and TN is an interesting direction. However, I think this paper did not present this problem sufficiently and some notations are confusing. ",
    "The paper considers the problem of forecasting of multivariate time series. The authors propose an architecture for such forecasting that incorporates several layers, including a residual tensor network layer. The idea is to tensorize (via outer products/Kronecker products) the features passed on from the encoder layer and then handle these very large tensorized features with a tensor network. The point of the tensorization is to better incorporate the effect of combinations of variables from different time steps. Experiments are done on four benchmark datasets.",
    "This paper formulated the graph neural network as a stochastic compositional optimization problem and then developed a new optimization algorithm to train GNN. However, there are some errors. It is not ready for publication.",
    "This paper proposed an improved variant of the Stochastic Compositional Optimization (SCO) framework to train GNNs, replacing all nodes' moving averages with a sparse representation. The proposed algorithm only requires a fixed-size buffer, regardless of the graph size, solving the memory issue of SCO algorithms and making it practically applicable to large graphs. The paper showed that the proposed algorithm preserves the convergence rate of the original SCO algorithm and experimentally validated that the algorithm could outperform the traditional Adam SGD for GNN training with a small memory overhead.",
    "This paper studies neighbor sampling techniques for training GNNs. Previous work has observed that sampling-based GNN training can be formulated as a Stochastic Compositional Optimization (SCO) problem. The authors argue that naive implementation of existing SCO algorithms incurs huge memory cost for training GNNs. This paper propose a Sparse Stochastic Compositional (SpSC) gradient method, which only stores the data for nodes sampled in the past few iterations. Convergence analysis on SpSC is provided and empirical results show that SpSC has better performance than naive SCO. ",
    "This paper studies the problem of training GNNs on large-scale graphs. Specifically, it proposes to use sparse moving average for sampling-based GNN training strategies. The convergence rate of the proposed approach has been proved under several assumptions. The authors conduct experiments on several large-scale datasets to show the effectiveness and efficiency of the proposal.",
    "Min-wise hashing (MinHash) is a fundamental and popular algorithm in machine learning. This paper proposes Circulant MinHash (C-MinHash) to approximate the Jaccard similarity in massive binary data. Compared with MinHash, C-MinHash only requires two (or maybe one in practice) random permutations in a circulant manner for approximation. The authors also systematically demonstrate that the C-MinHash can provide a smaller estimation variance than MinHash. Extensive experiments validate the effectiveness of C-MinHash.   ",
    "The paper designs an improved version of the classical MinHash data structure for calculating the Jaccard similarity between two binary strings.  The classical MinHash data structure generates K hash values for a binary string by generating K independent random permutations of the binary string and taking the index of the first \u201c1\u201d in the permuted string as the hash value in each random permutation. The estimator is then the percentage of equal hash values out of K hash values for the two binary strings. This is an unbiased estimator.  This paper\u2019s algorithm, called C-MinHash, first applies a random permutation to the binary string. For the K hash values, instead of using K independent random permutations, the new algorithm uses the same permutation but shifted by 1, 2, \u2026, K positions. The estimator is the same as that of the MinHash and can be easily shown to be unbiased. The paper then shows that this simple scheme, with only two independent random permutations, yields a smaller variance than that of MinHash. ",
    "This paper proposes C-MINHASH to improve vanilla MINHASH. Instead of using K random permutations to generate K hash values, C-MINHASH requires only two permutations. Theoretically, C-MINHASH provides unbiased estimate, and its variance is smaller than MINHASH. Extensive empirical experiments verify the theoretical analysis. ",
    "This paper proposes an effective approach for MinHash by permutating data vectors. It first randomly shuffles the data to break structures exhibited in the original data and then performs permutation K-times to obtain K hash values. Besides, this paper proposes an approach that performs only one permutation to compute hash values. This paper shows the theoretical approximation error of the proposed approach. By using text and image datasets, it shows that experimental results follow the results of the theoretical analysis.",
    "This paper proposes a method to produce image classifiers which are adversarially robust against multiple $\\ell_p$ threat models\u2014in particular, against $\\ell_1$, $\\ell_2$, and $\\ell_\\infty$ attacks. The method involves training against $\\ell_1$ and $\\ell_\\infty$ attacks with the hypothesis that this will additionally give robustness for $\\ell_p$ threat models with $1 \\leq p \\leq \\infty$. This hypothesis is supported by prior results that proved that affine classifiers robust to $\\ell_1$ and $\\ell_\\infty$ threat models are also be robust to other $\\ell_p$ threat models. The authors test their method on CIFAR-10 and ImageNet for both training classifiers from scratch and for fine-tuning robust models trained on one $\\ell_p$ threat model to the other $\\ell_p$ threat models.",
    "The paper tackles the problem of robustness against multiple perturbations and proposes extreme norms adversarial training (E-AT) that adaptively alternates between $\\ell_1$ and $\\ell_\\infty$-norm. Furthermore, the paper fine-tunes Gowal et al. (2020) to improve its multi-norm robustness. Finally, the experiments are conducted on CIFAR-10 and ImageNet with APGD for training, showing the proposed method's effectiveness.",
    "This paper addresses the problem of multiple perturbation adversarial robustness for attacks subsumed within $\\ell_p$ regions for $p\\in{1,2,\\infty}$. The main contribution of this work is to show how a model robust to a particular attack type (typically $\\ell_\\infty$) can be fine-tuned (at low cost) to be robust against multiple (or alternate) perturbation types. The authors build on prior formalization about the geometry of $\\ell_p$ balls (by Croce et. al.) to empirically demonstrate its effect. The results are convincing and evaluated against AutoAttack which is",
    "This paper mainly studies the problem of defending multiple norm adversarial perturbations. The authors propose extreme norms adversarial training (E-AT), which leverages different geometry of the $\\ell_{p}$-balls to conduct adversarial training by adaptively alternating between the $\\ell_{1}$ norm and $\\ell_{\\infty}$ norm. They also show that using E-AT fine-tune could turn $\\ell_{p}$ robust model into a model that is robust against the union of $\\ell_{p}$ adversarial perturbations. The authors also provide some theoretical proof for their method. ",
    "The paper propose a simple method for safe multi-task learning where there is no negative transfer or \"negative sharing\" among tasks. It jointly trains shared encoder, task-specific (private) encoders, gate, and decoder. The gate computes importance for each output of shared and task specific encoder and combine the outputs with simple convex combination. ",
    "This paper presents a multi-task learning approach that avoids negative sharing in training deep neural networks.  A novel network architecture is proposed, which consists of a public encoder shared by all the tasks, private encoder for each task, and a gate for each task to combine encoded features from public and private encoders. Their experiment results indicate the proposed approach is effective on image recognition related tasks.",
    "This paper focuses on the negative sharing problem in multi-task learning, which has not been studied sufficiently in existing work. The authors propose the Safe Multi-Task Learning (SMTL) model and several of its variants to avoid negative sharing and achieve safe multi-task learning. Both theoretical analysis and comprehensive experimental results are provided to demonstrate the effectiveness of the proposed method.",
    "This paper aims to solve the negative sharing problem, which is defined as that a multi-task learning model has inferior performance than single-task learning on some tasks, for multi-task learning. To address negative sharing, Safe Multi-Task Learning (SMTL) model is proposed. The model combines hard-sharing model and single-task learning together and is expected to achieve performance that not inferior than single-task learning. ",
    "The paper works in a computational model where various architectures of energy-based-models are viewed as computational models for accepting languages. EBM's assign a weight to each string. The sum of weights is called the partition function and this needs to be computed (or at best approximated) if the energy is to be thought of as a probability measure. The paper shows that expressive EBM's are turning complete, and uses that to show that the partition function may be uncomputable. And that is even in the case the energy of a sequence could be computed in poly-time. The paper then shows some corollaries and variations of this result, showing that model selection is undecidable as well. The paper concludes by suggesting scenarios where the partition function is computable but this naturally comes at the expense of the expressivity of the model.",
    "This theoretical work highlights uncomputability issues arising with energy-based sequence models. It is shown that an EC-complete family (a certain computational model capturing neural networks and transformers that is essentially equivalent to weighted Turing machines) cannot approximate the partition function of energy-based sequence models (EBMs) even given an unlimited amount of time and space. A consequence is the impossibility of model selection for EBMs. This paper also rules out popular estimators such as rejection and important sampling. This work concludes with a discussion of restricted EBMs that avoid such uncomputability issues. ",
    "This paper studies \"efficiently computable (EC) energy-based sequence models (EBMs)\" which are simply sets of strings equipped with nonnegative weights that can be computed by a poly-time Turing machine (upon normalization, the weights induce a probability distribution over the strings). In practice, it is common for these weights to be computed by neural networks. In fact, certain neural sequence model families like RNNs and Transformers are expressive enough to be Turing-complete. In this paper, the authors find that the expressivity of such sequence model families, so-called \"EC-complete parametric families\", comes at a significant cost in terms of *computability/decidability* of various primitives for inference. For instance, they show that if one could actually take in any vector of parameters specifying a model in such a family and output the corresponding partition function (sum of the weights of all strings) even approximately in expectation, then would be able to decide the halting problem (Theorem 2, 4). They also exhibit a single efficiently computable EBM for which proving (within ZFC) that the partition function is one of two possible values would either disprove Godel's second incompleteness theorem or disprove consistency of ZFC (Theorem 3); this can be extended to show that *asymptotic* estimates like rejection sampling and importance sampling will also fail (Theorems 5, 6). Along similar lines, they can reduce from the halting problem to other tasks like deciding whether two given parameter vectors give rise to the same EBM (\"parameter identifiability\", Theorem 7), or deciding which of two given parameter vectors gives rise to an EBM which is distributionally closer to some other given EBM (\"model selection\", Theorem 8).  In terms of techniques, the reductions from the halting problem are all based on a simple weight function that is tiny unless if the string corresponds to a valid accepting trace of an input-free Turing machine M. The point is that the weight for any string x can be computed by M simply by simulating M on x, but the partition function is large iff M halts. The ZFC results follow by taking M which enumerates all provable propositions under ZF and halts iff it proves 1 = 0.",
    "The paper studies the trade-off between expressiveness and computability (of the partition function) for energy-based sequence models. The theoretical results show that the high expressively of unrestricted energy based models comes at the cost of un-computability and in-approximability of the partition function. These negative results further show that rejection and importance sampling are not a panacea either.",
    "The paper proposes a new slice-based approach to efficiently compute the Wasserstein distance between two distributions $\\nu$ and $\\mu$. The method termed ASWD (augmented sliced Wasserstein Distance) first  projects the samples from $\\nu$ and $\\mu$ onto a higher dimensional space using a non linear injective mapping function and then uses the classical random linear projections onto 1D to compute the sliced Wasserstein Distance. Overall, the procedure amounts to applied a spatial Radon Transform to perform the slicing. Theoretical results establish conditions  under which ASWD is a metric. A numerical algorithm is given along with the design of the injective mapping using NN. Empirical evaluations on simulation datasets and on generative modeling highlight the potential of the proposed method over existing approaches.",
    "This manuscript introduces the concept of augmented sliced Wasserstein distances. The main idea is to extend the sliced Wasserstein distance based on mapping samples to higher -dimensional hypersurfaces. The proposed distance is shown to be a metric. Moreover, given that the optimal choice of the nonlinear maps is rather computationally intensive to obtain, an approximation based on neural networks is proposed. Several experiments are shown where a better performance is obtained with respect to existing methods.",
    "This paper introduces the augmented sliced Wasserstein distance (ASWD), a new variety of sliced Wasserstein distance (SWD), that allows comparing two probability distributions by combining a nonlinear embedding of the sample data points to a higher-dimensional space with a slicing scheme to calculate 1D Wasserstein distances between uniformly projection directions. The authors introduce the spatial Radon transform, which includes the standard Radon transform and the special case of polynomial generalized Random transform (introduced in Kolouri et al. 2019). They further prove that ASWD is a valid metric if and only if the mapping is injective. Several experiments are conducted on generative modelling (CIFAR10, CelebA,  MNIST, color transferring).",
    "This paper proposes a variant of sliced Wasserstein distance, named augmented sliced Wasserstein distance. ASWD maps input data points to hypersurfaces using neural networks, then calculates SWD on the hypersurfaces. ASWD alleviates the low efficiency problem of SWD for high-dimensional data. Various tasks including flow, generative modeling, and barycenters show the advantage of AWSD against some existing methods.",
    "This paper introduces a learned centralized exploration reward for multi-agent settings. The exploration reward is factorized into an on/off gate (dubbed \u2018switching control\u2019) and a scale function. Some mathematical derivations are included (sketched in the main text, with details in the appendices) to provide theoretical guarantees on how the exploration reward changes the solutions the training procedure might find. Evaluations on gridworld environments that target specific difficulties of multi-agent exploration show promising results. Some maps from the SMAC benchmark are also included, and again show good results.",
    "This paper proposes a method, Learnable Intrinsic-reward Generation Selection (LIGS) to improve coordinated exploration. LIGS incorporates an extra agent, called Generator to learn what state to give what intrinsic reward for each agent. The intrinsic reward is potential-based, so it preserves the optimality. Experimental results on several domains show its advantages over several MARL methods. ",
    "The paper describes a novel reinforcement learning algorithm for multi-agent system (MARL) that employs a generator of intrinsic reward and a switching control system that helps to regulate intrinsic control. Crucially, the intrinsic reward is learned to better fit the particular task being learned. The paper claims that the proposed algorithm helps with exploration as well as preservation of known policies. The paper has a strong theoretical background with a section that illustrates the properties of convergence and optimality. The experimental results appear to justify the approach with superior performance with respect to the baselines. The paper deals with an emerging and interesting area of RL and proposes a new mechanism for co-ordinated RL agents.  ",
    "The paper focuses on learning intrinsic rewards for multi-agent reinforcement learning, which is an important problem. Different from previous works on this topic, the authors propose to train an agent with a learnable gating function that incentives other agents. Theoretical analysis and empirical evaluation are provided to prove the effectiveness of the proposed method.",
    "The paper proposes a simple attention-based model for conversational and multi-hop QA tasks. The model use BERT-like pre-trained LM ETC separately encodes questions and paragraph (i.e., a collection of sentences). Besides the encodings on sentence-level, the final context encodings also contain extra paragraph embeddings, which are a weighted sum of sentences\u2019 encodings using a simple dot product attention. For the QA interaction, the models use a hard attention mechanism to select an entry representing either a sentence or a paragraph.  The experiments on two extractive QA datasets HYBRIDQA and QASPER show the model performs worse than the MATE model on HYBRIDQA but marginally better than other baselines on QASPER. On multi-hop QA and conversational QA tasks, the model performs marginally better than baselines on *expanded dataset*, but authors do not provide results on original datasets. ",
    "This paper introduces DocHopper, a new model for complex question answering over long documents (e.g., multi-hop QA over multiple paragraphs, conversational QA, reasoning over scientific documents). DocHopper is based on ETC (Ainslie et al., 2020) and DocHopper extends the existing hierarchical attentions from ETC with a new approach to update query representations in latent space. Their model does not jointly encode a question and context and does not require re-encoding of queries as in prior work, which leads to their effectiveness at inference time. They evaluate DocHopper on four different datasets: ShARC, QASPER, HotpotQA, and HybridQA. The proposed method achieves strong performance on those datasets, reducing the computational cost at the inference time. ",
    "The paper proposes an iterative approach for multi-hop question answering. At high-level the proposed model breaks a question into multiple sub-questions and then adds information relevant to each sub-question to the query vector for the next step retrieval. At each iteration an ETC encoder is used to encode the document and a sub-question; the vector corresponding to sub-question is then updated iteratively by contextualizing it over sentences and paragraphs in the document and is used to extract the final answer using a subsequent BERT reader. Evaluation results show improvements on 3 of 4 datasets. ",
    "This paper provides a novel MRC model (DocHopper) for multi-hop QA over long structured documents. In multi-hop QA, the evidence necessary to answer a user's question is spread across different parts of the long document. Previous approaches find the evidence by iteratively updating the user's query. The problems in these previous approaches are 1) computational efficiency and 2) ineffective modeling strategy for figuring out the relations of the evidence. DocHopper resolves these problems with a hierarchical attention mechanism. Hierarchical attention mechanism provides two types of embedding vectors for a single paragraph: 1) local sentence vectors and 2) global context vector of the paragraph. DocHopper computes the similarities between the query vectors and these sentence/paragraph vectors and selects the proper evidence. Since the sentence/paragraph vectors can be pre-computed, the only inference time required for this method is the time for question embedding, and this brings drastic improvement in the computational efficiency. This paper uses four types of datasets for evaluation: 1) conversational QA (ShARC), 2) TableQA (HybridQA), 3) QA on academic paper (QASPER), and 4) multi-hop factual QA (HotpotQA), and shows the QA performance and computational efficiency of their model.",
    "The paper proposes a label refinement approach. Starting from an initial set of labels, k-means clustering is used to refine the labels. The approach is described in the context of dubbing/voice casting. The method tries to obtain voice characteristics which can be further used for dubbing/voice-casting. Experiments are shown on video game datasets MassEffect and Skyrim and they primarily investigate how different parameters of k-means (# of clusters) and distance measure affect the label refinement. ",
    "The paper tackles a voice similarity system task for voice casting problem. The authors trained voice embedding network using voice character label and cluster the embedding features and used these clusters to train final voice embedding network. The introduction is well-written, however, the proposed method is known or marginal improvements from the existing technical skill in machine learning community (pseudo labeling with embedding feature clustering).",
    "This paper addresses the task of finding similar-sound voices with application to voice-dubbing (e.g. finding an actor to record dialog in English, translated from original French dialog, such that the English speaker sounds similar to the original French speaker). The paper proposes a method called \"label refining\". This method is based on p-vectors, a prior representation found to model similarity between characters. The method uses 1) non-expert \"initial labels\" to train a p-vector system 2) use k-means to cluster the resulting p-vectors and 3) use the groups learned by k-means to re-group the labels (the \"refined labels\"). To evaluate the method, English-French pairs of voice data from the video games Mass-Effect 3 and Skyrim are used. Performance is measured using clustering measures v-measure and purity-K, as well as accuracy on the test set (which it seems the ground-truth labels are mapping to the correct dubbing speaker). The method achieves a higher accuracy of 0.70 over a state-of-the-art system that achieves 0.69. A second experiment is performed using Skyrim data as a subsidiary corpus used to cluster, with the goal of \"bringing out vocal characteristics\" from the initial labels, which shifts the optimal K towards 2, which the paper claims is because the new representations start to model gender.",
    "The paper presents a \"label-refining\" technique, which helps users pick voices to provide a better user experience in dubbed video games. The idea is that a voice talent's voice in the target language should match the character's voice characteristics in the source language. The method seems to work by attaching labels to data-driven clusters, and refining these using a second corpus, on which the labels' value for discrimination is measured.",
    "This work is aimed at distributed \"privacy preserving\" training of neural networks for image processing tasks like deblocking, denoising, deraining, and deblurring. \"One of the most important contribution\" [pg 2] is breaking down the neural network model into task-specific convolutional head and tails (trained on \"clients\"), and a common shared (across tasks) Transformer based feature backbone, which is trained on the server. The heads/tails and the transformer backbone are trained in an alternate manner by assuming the other model to be fixed.    The proposed is similar to the method \"Splitfed\" (Thapa et al., 2020) but is extended for different tasks (as described above).  Experimental results demonstrate:  (i) successful training of the neural network models with the proposed method. (ii) better/comparable performance to prior works on distributed/privacy-preserving methods. (iii) better performance using the Vit backbone as compared to CNN backbones, and also with the proposed multi-task vs. single-task setting.",
    "In this work, the authors present a multi-task distributed learning framework called TAViT. The task-specific head CNN and the tail CNN are distributed to clients with their data connected to a standard Transformer body placed in the server. With an alternating training scheme, the heads and tails on client sides are trained by task-specific learning, while the body is trained by task-agnostic learning. Experiments on four different image processing tasks show the success of task-agnostic learning of the Transformer body and its synergistic improvement with the task-specific heads and tails.",
    "The paper presents an architecture for image processing tasks that splits up a network into three subsequent parts: head, body, and tail. Head and tail parts are CNN-based and can be trained on multiple client devices using federated learning (FedAvg), while the body part of the architecture is transformer-based and is trained on a central server. Head and tail parts are trained for specific tasks, while the body part is trained in a task-agnostic manner by selecting clients from each task for loss optimization. Experimental results show benchmark and convergence results that are comparable or favorable to non-distributed models, as well as comparison results to purely FL and SL approaches with a very small nr of clients.",
    "This paper presents a new distributed learning framework exploiting the vision transformer for various image processing applications. It gives impressive quantitative and qualitative results on multiple image restoration tasks meanwhile keeping privacy. Specifically, it employs a task-agnostic vision transformer to learn universal representation at the server, and several CNN-based task-specific heads and tails to handle different image restoration tasks at the client side. It also gives a training strategy to learn this model.",
    "This paper targets the very important problem of reward-hacking that occurs when the objectives optimized by intelligent agents are misaligned with respect to the tru objectives of the algorithm designer. The paper presents an empirical study across a range of different settings including a simple driving simulator, covid modeling, and a single atari game. The experiments show evidence of reward hacking as a function of modeling power of the agent and the size of the state-space. The paper concludes with some ideas and initial directions on how to potentially mitigate reward hacking. ",
    "This paper studies reward hacking, a common but understudied phenomenon, across a set of environments. Reward hacking emerges in several tasks, meaning that the resulting policy has a high proxy reward but a low true reward. A key finding is that reward hacking increases with agent capabilities so that increasing capability lowers the true reward. This holds across several ways of increasing capabilities (model size, training steps, action space, etc). The authors also find \u2018phase transitions\u2019 where a small increase in capability results in qualitatively new reward hacking behavior, a phenomenon that may require novel monitoring strategies. One such strategy is anomaly detection, for which the authors introduce a benchmark and baselines. ",
    "This paper provides a systematic study of \u201creward hacking\u201d in the environments with the misspecified rewards. The authors conduct a set of experiments with 4 environments, several types of reward misspecification in each of them and several agents of different expressivity (model capacity). They notice that often the agents that are more capable end up obtaining high proxy reward, but low real reward. Besides, often the transition to the low real reward happens very quickly and authors call this phenomenon \u201cphase transition\u201d. Finally, they propose a baseline for anomaly detection to identify this phase transition.",
    "This paper investigates the phenomenon of reward hacking as a function of agent capabilities. They introduce four diverse RL environments with nine misspecified rewards and demonstrate that more capable agents are better at exploiting the misspecification. They find instances of phase transitions where a small increase in agent capability produces a large change in behavior that sharply decreases the true reward.  To mitigate the reward hacking problem, they propose to set up an anomaly detection task, given a trusted model with moderate performance on the true reward, where the anomaly detector's task is to identify whether policies from a different model are satisfactory for the true reward. They provide several baseline anomaly detectors and show how they perform on different tasks. ",
    "The paper proposes a novel f-divergence Thermodynamic Variational Objective (f-TVO) framework for VI, that extends the TVO towards, a more general, family of f-divergences. The authors propose to use a $\\chi$-deformed exponential distribution, which casts the f-TVO objective as integral along the $\\chi$-path between p(x,z) and q(z|x) (rather than the geometric path in TVOs) under $\\chi$-geometry. The authors propose different variants of f-TVO, that vary between the type of the f-divergance used, as well as how this integral is approximated (K-partitioned ) left-Riemann sum (related to ELBO), right-Riemann sum (related to EUBO) or a 'zig-zag' that alternates between the two. Besides theoretical justifications, results from two sets of experiments show that, in general, the proposed f-TVO perform comparable to or slightly better than the f-VI counterparts, but without clear conclusion wrt the choice of the f-divergence.",
    "The paper presents a new bound as the objective for variational inference. The bound combines the recent progress of thermodynamic variational object which gives a tighter bound than the conventional ELBO, and the f-divergence which induces more possible distribution metrics. Experiments show its better performance on some Bayesian inference tasks.",
    "This paper proposed an $f$-divergence TVO, which includes some existing works e.g., RVB, CUBO, ELBO into a unified framework. This paper's main idea is to transform $f$-divergence into a generalized $\\chi$-exponenetial family and integral TVO along the $\\chi$-path. The paper provides some theoretical analysis and the optimization methods of the suggested framework and supports the proposed $f$-TVO with numerical results. ",
    "This paper proposed new variational inference that combines f-divergence variational inference and the thermodynamic variational objective. The authors introduced several new concepts of exponential families to extend TVO. Finally, the authors provided the estimator of the gradient of the objective function based on the reparametrization trick.",
    "This paper presents a deep reinforcement algorithm, Ensemble Deep Deterministic Policy Gradients (ED2), for continuous control tasks. The algorithm is empirically derived and is claimed to represent SotA performance on several tasks and while providing more stable results. These claims are justified based primarily on the (reward and stability) results on 4 MuJoCo environments.  ",
    "This paper has two main contributions: it introduces an ensemble-based actor-critic method, and it answers some pertinent questions in policy optimization by focusing on its different components. The ensemble is different from multi-actor learners that interact with multiple environments simultaneously, violating the standard RL setup. Instead, the learner of this paper maintains multiple actors and critics but uses only a single actor at a time to interact with the environment. All actors and critics are trained on a common replay buffer. The base method is the streamlined off-policy (SOP) method, which unlike soft actor-critic (SAC) doesn\u2019t use an entropy bonus. Additionally, no exploration noise is added, resulting in their Ensemble Deep Deterministic (ED2) method.  The proposed algorithm ED2 is shown to be superior and more stable in performance according to different measures compared to existing methods. It is also revealed that actor initialization affects performance less than critic initialization. ED2 uses deterministic actors, and its exploration comes from sampling among the actors. Such a form of exploration is also shown to be superior to UCB-style exploration. ",
    "The paper presents an empirical study evaluating the commonly accepted design choice in off-policy Deep RL algorithms in continuous control settings. The use of additive exploration noise, initialization choices, update frequency, and precision for retraining are tested empirically highlighting some interesting results. The paper also introduces ED2 - an ensemble method utilizing the design choices from the study which is demonstrated to achieve SOTA results on Mujoco benchmarks.",
    "This paper conducted an experimental study over a range of tricks that are often exploited to facilitate ensemble deep reinforcement learning. The experiment results show several interesting findings. For example, it was found that commonly used additive action noise may not be necessary for effective exploration. Meanwhile, experiments show that the initialization of critics perhaps has a higher impact on learning performance than the initialization methods adopted for actors. These findings can be quite important to guide future design of more effective ensemble reinforce learning algorithms.",
    "    This paper studies the problem of fair supervised learning under the Equalized Loss (EL) fairness notion, which is formulated as a non-convex constrained optimization problem. The authors introduce two algorithms that find the global (sub-)optimal solution by solving a sequence of convex (constrained) optimizations. Empirically, the algorithms perform well.",
    "The authors consider minimization of convex losses constrained by either bounded loss on each group, or bounded difference of losses over two groups. The second formulation is non-convex, whereas the first formulation is convex.   When the losses are strictly convex on both the demographic groups, so that their optima are distinct (I think this is the condition they need, but they use a more restrictive condition in the paper), they can find the \"EL\" fair predictor by solving a sequence of convex constrained optimizations, by exploiting a monotonicity property. They next give a more computationally efficient approximate algorithm for finding the EL fair predictor. ",
    "The authors study fair prediction subject to Equalized Loss (EL), and they introduce a variety of approaches for exactly and approximately solving the problem of finding the globally optimal predictor that satisfies EL. First, they show how to solve a sequence of convex constrained optimization problems in order to solve the larger non-convex problem. Next, they show how to approximately solve this problem more efficiently by using unconstrained convex optimization. Lastly, they evaluate both of their approaches on two datasets.",
    "This paper studies supervised learning models with fairness constraints. They specifically consider equalized loss fairness constraint.  When a traditional (convex) loss minimization problem is cast with additional fairness constraints, the corresponding problem is non-convex. They provide algorithms to efficiently solve this problem up to global optimality. They demonstrate the performance of their algorithms on real-world data. ",
    "This paper revisits the problem of neural network's systematic generalization ability from the perspective of meaningful learning, or more specifically, semantic linking. Based on this view, they propose two data augmentation methods from either the inductive learning perspective or deductive learning perspective. They train different model variants with such augmented data. The empirical results on SCAN, GEO, and ADV show that models can behave systematically. They further group some data augmentation methods on the machine translation task and semantic parsing task into the inductive or the deductive category, and show these augmentation methods can bring benefit in real data. ",
    "The paper introduces an interesting idea of improving the systematic generalization ability via meaningful learning. Through providing augmented data for inductive learning and deductive learning, the sequence-to-sequence model can be more generalizable to compositions of new concepts. It tests on real data to provide evidence of the efficacy. ",
    "This paper considers the problem of learning novel words from a few examples. The authors name their approach as \"meaningful learning,\" which, at a high level, means that we should relate the new word with existing words. The concrete technique they proposed is to use domain-specific rules to generate new data that contains novel words based on the existing examples.",
    "This paperintroduce semantic linking for systematic generalization through the analysis of inductive and deductive learning from a meaningful learning perspective. They show that both prior knowledge and semantic linking play a key role in systematic generalization, which is in line with the so-called 'meaningful learning theory'. Interesting results are attained from SCAN to real data.",
    "This paper proposes a novel 3D point cloud representation learning framework. At the core of this method, is a lifting scheme inspired by wavelet decomposition. The proposed method roughly splits the input data in half at each stage, producing a down-sampled approximation C and detail d. Then C is further processed by the next layer, forming a multiscale pyramid. In summary, the contribution of this paper is:  1. Proposed to use the lifting scheme in point cloud processing, using graph convolution networks and transformers as backbone.  2. Evaluated the method against state-of-the-art baselines and showed that the proposed scheme performs well. ",
    "This paper proposes a new 3D shape representation learning method using multi-scale wavelet decomposition. In particular, the authors introduce a neural network architecture that decomposed 3D shapes into sub-bands components at multiple scales. In particular, starting from a pointcloud the proposed model learns to decompose it into coarse (high frequency) and detail (low frequency) components using an adaptive lifting scheme, similar to the original lifting scheme introduced for defining second-generation wavelets. Subsequently, two transformer models are used to refine the coarse and approximate geometry of the 3D shape. The proposed model achieves state-of-the-art results on the shape classification task on the ModelNet40 and the ScanObjectNN dataset and on the part segmentation task on the ShapeNet Part dataset. The concept of using such an adaptive lifting scheme seems to facilitate learning and to the best of my knowledge is novel for the case of shape representation learning.",
    "This paper presents a novel framework for 3D shape representation learning, which is based on multi-scale wavelet decomposition. This is very different from existing works. A novel transformer-based neural network, AWT-Net, is also proposed.",
    "The paper presents a new deep neural network architecture for 3D point cloud representation learning, based on wavelet decomposition. In particular, the authors propose a data-driven adaptive lifting scheme that introduces non-linearity into wavelet. The original linear operators update(U) and predict(P) in wavelet decomposition are replaced by non-linear graph convolutional networks (GCN). Equipped with wavelet transform and Transformers, the proposed network aims to captures and refines the holistic and complementary geometry of 3D shapes to supplement neighboring local information. Experimental results on standard benchmarks (i.e., shape classification and part segmentation) show that it achieves state-of- the-arts or competitive performance.",
    "This paper proposes a simple yet effective method, cocktail fine-tuning, for the natural language generation tasks. Their results show that cocktail fine-tuning can handle both In-domain data and Out-of-domain data effectively by combing adapter-finetuning and full-finetuning through knowledge distillation and overall has comparable performance compared to their ensembles. It also provides theoretical analysis on multi-class logistic regression to explain why it works.",
    "This paper proposes an ensemble model between a full fine-tuning model and a parameter-efficient fine-tuning model to improve the out-of-distribution (OOD) performance of a full fine-tuning model. The proposed method is inspired by the observation that full fine-tuning model achieves good in-distribution (ID) performance while parameter-efficient finetuning model achieves better OOD performance. There are two ensembling methods presented in the paper: linear interpolation between the predictions of the two models; and distill from the predictions of a parameter-efficient model with ID training data. Improved OOD performance is observed with this ensemble method.",
    "This paper presents interesting an idea of combining lightweight fine-tuning and full fine-tuning to achieve the best of both approaches, i.e. perform best on out-of-domain and in-domain data. The authors proposed two approaches: a simple ensemble method and a so-called cocktail fine-tuning that combines two fine-tuning methods in one single model. They evaluated their tasks in three datasets: WebNLG, XSUM and OpenQA and obtained mixed results. The authors also provided good analyses for more insights. ",
    "The present paper first discusses the trade-off between performance for out-of-domain data and in-domain data with respect to whether the model is fully fine-tuned or lightweight fine-tuned on NLG tasks. Second, it argues that such a trade-off is not necessary if one can make use of both of these two fine-tuning schema in a clever way. To this end, it proposes cocktail fine-tuning, which augments full fine-tuning via distillation from a lightweight model and which achieves equal performance as an ensemble of the two fine-tuning schema. At length, this paper also explains the behavior of the cocktail fine-tuning through a toy model. ",
    "In this work, the authors propose the WARM method to help conduct iterative and interactive weakly-supervised learning. Active learning is used here to refine the labeling functions by focusing on data points that are once labeled. The authors further incorporated gradient propagation to alternatively update the LF parameters and the DP model. Experimental results show that the WARM method can improve the quality of training data.",
    "This paper proposes WARM, an active learning approach to weakly/programmatically supervised learning.  In the WARM approach, which bases off of the data programming/Snorkel paradigm for weak supervision, users write labeling functions (LFs) to programmatically label training data; these labeling functions are then modeled by the Snorkel framework for weak supervision and used to train downstream models.  In the WARM setup, these LFs are assumed to be, or cast as, differentiable.  The paper then proposes an active learning approach to sampling labeled data points to tune the parameters of these LFs, and validates this approach on several medical datasets.",
    "This paper proposes an algorithm for choosing a small set of labels to improve labeling function model performance both directly and for downstream tasks. Additionally, the authors provide a general method to convert standard labeling functions to \"soft\" labeling functions which are differentiable with respect to some parameters (e.g. a threshold). If the labeling functions are differentiable, this paper provides a method to update the labeling function parameters. Finally, experimental results show that the method introduced outperforms other active labeling approaches for weak supervision.",
    "The paper gives a method to iteratively and interactively improve the label model in weak supervision. The approach consists of two steps, first is standard weak supervision way of weighted combination of labelling functions to generate labels. Novelty and improvement mainly comes from the second step, where true label for most uncertain data point is queried using which the parameters of the labelling functions are improved, which in turn lead to a more accurate weak supervision model. A key requirement and assumption in this paper's setup is that labelling functions are given by some learnable parameters ( i.e. they can be differentiated w.r.t. their parameters), which allows parameters updates using the true labels acquired. Empirical results on various real world datasets in medical domain show that in some cases this approach can yield a more accurate model in comparison to pure active learning approach and some recent baselines which combine weak supervision with active learning. These results also show that the paper's approach can get accuracy comparable to fully supervised model as well.  ",
    "This paper proposes a novel ERM-based method for classification task with group annotated training data. The goal is to be group distributionally robust while enhancing the minority performance. The authors make an improvement to an existing method named Group-DRO by modifying the focus on the group with the highest regularized loss to focus on the group that leads to the largest decrease in average training loss. They analyze the convergence and present detailed comparisons with Group-DRO.",
    "The paper gives a new algorithm for the setup where the test distribution is different from the train distribution. The setup includes multiple groups whose information is present during the training time but not during test time and the relative proportion of these groups change during test. The most commonly used method group-DRO does distributionally robust optimization or finds a classifier which performs well on the group with worst loss. This paper proposes to focus instead on the group which leads to maximum decrease in the loss while training instead of the group which has the maximum loss. The paper present several synthetic toy cases where their approach could be useful and concludes with experiments on a variety of benchmarks for this setup and shows improved results.",
    "The paper proposes a new method for robust ML under distribution shifts. Past work has looked at formulations that minimize the worst group error. This paper adds a new twist on it and instead argues for focusing on the group that leads to the greatest decrease in average training error for all the groups. This intuition is combined into an algorithm and the paper proves that though their proposed algorithm doesn't minimize a specific loss function, it still finds first-order-stationary points. The results are shown on several synthetic datasets as well as on the WILDS Robust ML benchmark that show the superior performance of the proposed algorithm over several baselines.    Main Contributions:   1). The paper proposes a new approach for robust ML under distribution shifts that performs gradient descent not on the group with worst error but on the group which decreases the average error of all other groups.  2). Results are shown on synthetic and real-world datasets which show the superior performance of the proposed method in achieving group robustness. ",
    "The paper provides an efficient method to generalize to all groups in the presence of sub-population shifts and domain adaptation. The paper conducts extensive simulations to derive insights and also numerical experiments on the benchmark dataset to demonstrate the performance. The proposed method is intuitive, easily implemented, and has good performance.",
    "In previous studies, Shapley value has been widely used to explain model predictions, in which previous studies generally characterized importance for each feature instance separately. While some works have explored the effect of combinatorial features on prediction, no works have explored how features interact to influence each other, such as whether feature A is redundant if feature B is present.   In order to achieve this goal, this paper offers an intuitive solution. The degree of feature interaction is estimated using a matrix called a bivariate Shapley explanation map. The j-th column and i-th row of the matrix represents how feature i influences the prediction if feature j has been included. Item ij can be seen as a revised Shapley value: rather than summing up the marginal contributions of all coalitions, it only considers them when feature j appears. They then propose four different types of interactions based on this definition: least/most influential features, directional/mutual redundancy. The experimental results indicate that the proposed method can efficiently discover these four types of feature interactions. ",
    "This paper attempts to alleviate the shortcomings of existing local-feature-interaction explainers that assume symmetrical feature interactions by proposing a bivariate feature-explanation map that can capture asymmetrical (directional) feature interactions; this analysis provides evidence of mutual and directional redundancy, offering a comprehensive understanding of the features most influential for a given prediction. This proposed approach can also be instantiated using any univariate feature-based explanation method. Empirical results on image, text, and tabular data show the ability of the proposed method to accurately identify mutual and directional redundancies.",
    "This work proposed to study the directional feature interactions to explain deep models. The proposed method is a graph-based explainer and the data can be considered as graphs. Then it studies the Bivariate Shapley values to consider the directional feature interactions. Experiments on several datasets show very promising results. ",
    "In this paper, the authors generalize the univariate Shapley method to bivariate Shapley method. The authors first build a directly graph based on the asymmetric bivariate Shapley value (adding feature j to all sets contained feature i). Then several graph algorithms are applied to analyze the directly graph to derive (1) univariate feature importance available in univariate approach and (2) relations like mutually redundancy only available in bivariate approaches. Experiments on several datasets with comparison to existing methods demonstrated the superiority of the proposed method.",
    "POETREE aims to construct an interpretable model for a policy over a time series using decision trees. The healthcare domain is particularly targeted. As opposed to other works, the model directly maps observations of a POMDP to actions. POETREE creates a decision tree from time series data. The decision tree can be conditioned on the history, allowing the tree to be different at different time steps, allowing for example the tree to model that an exam done previously that is no longer informative is no longer likely. Each tree is a soft-probabilistic model first grown incrementally by developing, optimized globally (as it is differentiable), then pruned. Finally, the tree is simplified for interpretability by limiting each condition to a single variable. POETREE is then empirically evaluated and compared to baselines in terms of distribution modeling, interpretability and policy learning.",
    "  The authors argued that many methods failed the merits of interpretability in some important areas, e.g. clinical decision-making. Thus, this paper proposed a (soft) tree-based method for synthetic clinical datasets in the matter of interpretability. The authors model the clinical decision process as a partially observable Markov Decision Process (POMDP), which naturally fits the assumption of medical diagnosis.",
    "This paper proposes a novel approach for learning and representing human decision-making policies from observed behavioral data. The proposed approach emphasizes interpretability as a primary aim, while nevertheless seeking to maintain reasonable modeling accuracy. The decision tree model proposed extends canonical decision tree approaches to the probabilistic setting, allow for optimization of leaf-specific parameters via stochastic gradient descent. The proposed approach is evaluated both in terms of its interpretability (subjective measurements from a panel of licensed physicians) as well as its accuracy in recapitulating actions conditioned patient observations. The utility of the approach is demonstrated on both synthetic and real-world datasets.",
    "This paper proposes a new method to learn (stationary) interpretable policies using soft decision trees in partially observed settings. The soft decision tree structure is extended to allow for recursion over time, and account for policy decisions based on history of collected data. An algorithm is presented to optimize the parameters of the soft decision tree as well as the structure/topology of the tree. The algorithm mainly proceeds by splitting nodes and locally optimizing the parameters of the the associated probability representation of the soft node, and recursively split (if local optimization does not improve validation performance) and fixed as leaf otherwise. A global update step is then used after topology is fixed followed by pruning low probability paths in the trees. Experimental validation on surveys with clinicians demonstrate reasonable interpretability and improved prediction performance on imitating clinician policy. ",
    "This paper target the task of automatically determining the best augmentation method to obtain improved accuracy. While the previous related studies focus on the image-level augmentation and ignore the semantic information of the augmented images, the proposed algorithm augments the grid-wise patches of the given input with the preserved semantic information. To overcome the enlarged number of combinations to consider all the patches, the algorithm utilizes the MARL algorithm with the unified reward function. By MARL algorithm, the number of parameters can be reduced and the training speed can be much improved, compared to the previous auto-augmentation methods. Through the image classification and fine-grained image recognition tasks, the proposed algorithm was validated, and it shows the state-of-the-art performance among the compared methods.",
    "This paper proposes an automatic data augmentation approach. Different from existing works, they proposed to augment patches in the image rather than the whole image. The approach is formulated as a multi-agent reinforcement learning problem. They empirically show the effectiveness of their approach across several image classification datasets.",
    "This paper proposed a fine-grained automated data augmentation approach, Patch AutoAugment (PAA), which tries to increase diversity in local regions by divide an image into a grid of patches and search for the joint optimal augmentation policies for the patches. The proposed PAA considers the task as a multi-agent reinforcement learning problem,  and adopt a multi-agent reinforcement learning algorithm to automatically search for the optimal augmentation policies by considering the contextual relationship between the patches. They verify the proposed method on many classification and fine-grained recognition dataset(CIFAR10, CIFAR-100, ImageNet, CUB-200-2011, Stanford Cars and FGVC-Aircraft). The experiments show a good result and visualization results provide some insights that the PAA  help the target network to localize more class-related cues. ",
    "  The paper proposes an evolution of the traditional   pipeline of image data augmentation used to reduce ML   model overfitting.    Instead of applying transformations such as shear,   rotate, CutOut, etc. at the image level, the proposed   technique divides the images into a fixed grid and   applies a potentially different transformation to each   cell. The problem of selecting a transform for each cell   is cast as a multi-agent RL (MARL) task, and the agents   learn as the main network trains within a (multi-agent)   Advantage Actor Critic framework.    The agents use a shared reward mechanism, with the reward   defined as the difference between the loss on the   augmented sample and the original loss.    The regular grid is fixed for a dataset and   hyperparameters like the magnitude of the augmentations   follow a fixed schedule; the agents only pick _which_   augmentation to apply on a patch.    Experiments performed on CIFAR-{10,100}, ImageNet,   CUB-200-2011, Stanford Cars, and FGVC-Aircraft show   relatively small but very consistent improvements in   terms of image classification accuracy. Different design   choices (MARL vs. single-agent vs. random, grid size,   etc.) are ablated and discussed in detail. ",
    "The work presents a causal perspective of adversarial attacks on image-based machine learning models by studying a causal graph of the adversarial data creation process and highlighting how such a process makes the learned models vulnerable. It argues that the main reason for adversarial vulnerability is the reliance of models on spurious correlations between labels and style. Accordingly, it proposes a method to learn models for which the conditional distribution of label given style and image does not vary much when attacked. Empirically, the method is shown to be more robust than two baselines on three datasets.",
    "This paper presents a causal perspective on addressing adversarially vulnerability. It first constructs a causal graph, which then inspires the design of the distribution alignment method for reducing the gap between adversarial and natural data. Extensive experiments on CIFAR10, CIFAR100, and MNIST demonstrate the robustness of the proposed method against various attack methods.",
    "The paper shows a causal perspective to the adversarial robustness problem. It creates a graph over content and style variable sets. It identifies the spurious correlation between style and label as the main reason for adversarial examples, and then proposes a method to remove it from the trained model. Experiments on three datasets show that the proposed method is better than two baselines. ",
    "This paper proposes a causal graph to model the generation process of adversarial attacks. Based on the proposed causal graph, the authors identify the origin of adversarial vulnerability as the spurious correlation between style variable and class label. Under the adversarial distribution, such spurious correlation can be maliciously used to mislead a victim model. In this light, the authors propose a method to align the adversarial distribution and the natural distribution to prevent a model from learning spurious correlation. The proposed method is empirically validated on prevailing datasets under several attacks.",
    "This paper introduces a model for continual learning based on the decomposition of linear filters into low-rank components, called atoms. Specifically, the authors decompose convolutional filters shaped (c,c',k,k) into two components: i) alpha, shaped (c,c',m) and D, shaped (m,k,k). The former is learned on the first task and then frozen, whereas for D every task has its own and they are do not conflict during optimization. On top of that, the authors envision two different ensembling schemes that improve performances. i) First, in task-incremental settings, they retrieve atoms from the task of interest and from similar tasks as well (based on SVD decomposition of D matrices and Grassman distance) and ensemble them. ii) Furthermore, in class-incremental settings, they explicitly setup multiple atoms per task, building a task ensemble. During inference, all ensembles are queried and their predictive variance is used to \"discover\" the relevant task, for which a prediction is carried out. Experiments are carried out on 3 datasets in both task-incremental and class-incremental learning settings. ",
    "The paper proposes a continual learning algorithm that enforces the convolutional filter in each layer to a low-rank filter subspace defined by a small set of filter atoms. For each task, each convolutional layer is defined by a new filter subspace but subspace coefficients are shared among the tasks. The algorithm is validated on multiple benchmark datasets. ",
    "The paper, motivated by the task subspace modeling literature, enforced a low-rank filter structure to each CNN layer across time in continual learning. It not only ensures that the knowledge of the past tasks is not lost but also saves a lot of computing memory. Meanwhile, the paper proposes novel intra-task ensembles and inter-task ensembles for class-incremental settings and task-incremental settings, respectively. ",
    "This paper tackles the continual learning via enforcing a low-rank filter structure to each CNN layer.  They first perform atom-coefficient filter decomposition and then learn each task with a new filter subspace, so that the method only needs to save the new filters for each task. The contribution of this paper includes the low-rank filter scheme and the designed intra-task and inter-task model ensemble performing on the filters. The proposed method also achieves SOTA performance on several datasets with tiny size of model memory. ",
    "In this paper, the authors analyze the underestimation issue of stein variational gradient descent (SVGD), and propose the maximum mean discrepancy (MMD) descent. From the perspective of the decomposition of the gradient term (driving force and repulsive force), this paper suggested to use another driving force term instead of the original one in SVGD. But the new driving force makes MMD-descent impractical since it depends on an intractable integral of the desired distribution $p$. In addition, the paper identify the log derivative driving force as the problematic term in SVGD, and propose a modified SVGD with particle resampling. They also argue that the proportional asymptotic limit is more relevant to understanding the variance collapse phenomenon. The theoretical dimensional analysis of SVGD on Gaussian also suggested another modified (damped) SVGD.",
    "This paper provides an understanding of the variance collapse phenomenon of SVGD. The paper first (1) introduces the reader to the most important concepts and phenomena, then (2) gives an explanation for why this problem occurs, thanks to a comparison with an accurate (yet computationally intensive) algorithm they call MMD-descent. Finally (3) the paper shows how to fix SVGD with damping. The paper provides experiments and theory, nicely combined.",
    "This work studies the variance collapse phenomenon of SVGD. By comparing to MMD-descend, the authors argue that the driving force of SVGD suffers from a bias caused by reusing data, and thus tends to underestimate the variance of the target distribution. Theory are developed in the setting of estimating standard Gaussian with a proposal limit (i.e., $d/n \\to \\gamma$), and explains the understanding in the overparameterized/high-dim setting (i.e., $\\gamma > 1$). Experiments are also conducted to verify the understanding. Finally, motivated by the understanding, new algorithm is proposed to fix the issue of SVGD by damping the driving force term in SVGD.",
    "This paper analyzed the curse-of-dimensionality problem of the vanilla SVGD with Euclidean distance kernel in a qualitative and quantitative way. Specifically, the author first built a connection of SVGD to MMD-descent, where they share identical repulsive forces with different driving forces (if Euclidean distance kernel is adopted). Then, the author argued that the variance collapse problem is rooted in (1) high variance and (2) the deterministic bias of the driving force, which were confirmed by sampling from the isotropic Gaussian. Quantitatively, the author analyzed the stationary variance of MMD-descent and SVGD with isotropic Gaussian under the proportional limit, which confirms the curse-of-dimensionality problem of SVGD. ",
    "This submission empirically studies the efficacy of adversarial training for mitigating the effect of label noise in training data. Their findings are as follows: 1) \"Smoothing effect\" of adversarial training: \ta) on a 2-dimensional synthetic binary classification dataset where two points are incorrectly labeled, they show that vanilla training yields a classifier that memorizes the bad labels by forming \"clusters\" around the incorrectly labeled points, whereas adversarial training does not yield such clusters \tb) for CIFAR injected with 20/40% random label noise, they ran vanilla and adversarial training on the noisy data and found that if you look at the distribution over labels within the neighborhood of a random incorrectly labeled point, on average the entropy of that distribution is higher for the classifier obtained by adversarial training than by vanilla training 2) For vanilla training on CIFAR (also MNIST) injected with label noise, the gap between accuracy on the correctly labeled training data and the incorrectly labeled data closed over the course of training, whereas this gap does not close or seems to close much more slowly for adversarial training. 3) Over these same noisy datasets, adversarial training seems to mitigate the impact of noisy training data on (clean) test accuracy, unlike vanilla training for which generalization degrades as label noise increases 4) They consider a quantity they call the \"geometry value\" of a data point (x,y), which corresponds to the number of PGD steps needed to find a differently labeled point in the neighborhood of x. This quantity was originally introduced by [Zhang et al. 2021b], and in the present paper they find that: \ta) compared to loss(x,y), it appears to be a more effective way to effective way to distinguish correctly labeled data from incorrectly labeled training data, as well rare data from typical data 5) They propose a \"robust annotator\" for labeling unlabeled data that has possibly been subject to adversarial perturbations. The algorithm repeatedly alternates between 1) identifying training data points with high loss and low geometry value and re-labeling them according to the current classifier and 2) running a step of adversarial training. It appears to do slightly better than a PGD-based annotator baseline when trained over CIFAR injected with label noise. They also note that the geometry value can provide some kind of \"confidence score\" to go along with the label annotations.",
    "This paper studies the connection between noisy labels (NL) and adversarial training (AT). The contribution of this paper is two-fold. The first one is to adopt the number of PGD attack steps as a criterion for sample selection to correct noisy labels. The second one is that adversarial training can serve as a way to correct noisy labels. These two contributions indicate that adversarial training can be applied to more general model robustness problems.  ",
    "This paper focuses on understanding adversarial training in the presence of label noise by conducting empirical studies. Based on their observations, the authors propose to use _PGD step number_ of adversarial training as a new measure for sample selection to correct noisy labels. Moreover, they present two use-cases, namely 1. a _robust annotator_ algorithm to label unlabeled instances, and 2. PGD step number as a _confidence score_ for the labeling of unlabeled instances. Empirical observations are primarily made on CIFAR-10 images.",
    "This paper studies the adversarial training in the context of label noises. Specifically, it is discovered that adversarial training can prevent the model from overfitting to the label noises, leading to a more smooth landscape. In addition, the authors point out that the number of PGD step sizes can be considered as a useful metric to distinguish instances with correct or incorrect labels.",
    "Present a method to measure the expected robustness of a neural network model, by determining  the probability that a random input perturbation might cause misclassification, providing formal guarantees regarding the expected frequency of errors that a trained model will encounter after deployment. The method can be applied black-box. Applied the approach to compare the robustness of different models, and measure how a model\u2019s robustness is affected by the magnitude of input perturbation. ",
    "The paper presents a statistical method - Robustness Measurement and Assessment (RoMA) to measure the expected robustness of a neural network model. The robustness is defined as the probability that a random input perturbation causes an incorrect prediction. The presented approach is a blackbox approach. Different output labels are observed to exhibit different robustness values.   The basic premise of the paper is that the adversarial perturbations are not naturally normal, but a transformation (Box-Cox) can be applied to make them a normal distribution before applying statistical estimation techniques (Anderson-Darling test + z score). ",
    "This paper proposes RoMA, a robustness evaluation framework based on local sampling and probability computation.  The main contributions are: 1. Proposal of the ($\\epsilon$,$\\delta$) local robustness score for assessing the probability of random local samples that have different predictions than a given data input with a $\\delta$-confined top-1 confidence.  2. Use of Box-Cox transformation for input data to improve statistical estimation.  3. The method can be implemented in a model-agnostic fashion. ",
    "Summary:  The paper introduces a statistical method to measure the robustness of deep neural networks. The novel  part of the method is that it's designed to measure the probability of random points near an input being  adversarial, instead of probability of adversarial examples existing in the vicinity of an input. To measure it,  the authors proposes to use Box-cox transformation to transform distribution of confidence scores to normal,  then calculate the probability based on it.  ",
    "This paper presents HCM, an approach for chunking a sequence of data into a hierarchical representation. More specifically, HCM learns a tree with atomic units (ie the low-level inputs, in this case integers representing things like text characters or quantized pixel values) as the leaves and increasingly complex groupings of them higher up the tree.   HCM learns by iteratively parsing the provided data (ie stream of tokens), in each pass computing marginals for the current set of chunks as well as transition frequencies between them. After updating its marginals and transition frequencies, the two chunks with highest joint probability are combined into one. The process continues until all pairs of chunks pass an independence test.   I believe the main contribution of this paper is in that it presents an idea for interpretable grouping based on the principle of grouping by proximity from cognitive science, and a largely qualitative proof of concept for it.",
    "The paper proposes a graph-learning model (HCM) for learning hierarchical chunks from sequential data. The paper first proposes an idealised HCM method, for which the paper provides learning guarantees via a proof by induction, and an online approximation to this idealised method, which is more computationally feasible and which is used to perform experiments in temporal, visual, visuotemporal and language sequential data domains. The paper demonstrates that the online method learns interpretable chunks at multiple levels of abstraction and demonstrates positive (and negative) transfer to other hierarchically structured environments with similar (and different) structures.",
    "This paper proposes a method for learning representations of non- i.i.d. data in terms of hierarchical sets of chunks, inspired by cognitive theories of grouping by proximity. These sets are assembled over time from the initial set of primitive data points by finding correlations between temporally/spatially sequential primitives/chunks and appending to the set. The authors show that this learning method is tractable, has convergence w.r.t. hierarchically-decomposable problems, and learns intuitively and practically reasonable chunk sets.",
    "This paper proposes a non neural system of parsing natural language text by chunking sequences to form hierarchical structures. The algorithm strongly resembles classical parsing algorithms. Decisions about when to chunk a phrase into a constituent are based on chi^2 tests of independence, where a pair of chunks that are considered to be dependent are joined into a single constituent. They test this chunking algorithm on natural language data against an RNN,  concluding that the classical parsing algorithm is more sample efficient in achieving a low KL-divergence from the true sequence data. They also provide some examples of how this algorithm can be applied to temporal image data or video.",
    "This work studies the question to what extend a reparametrization of an optimization problem, i.e. representing the original parameters w to optimize for as a function of some other parameters theta, can accelerate the convergences of the gradient flow / gradient descent for nonconvex optimization problems. It studies the dynamics of the flow via eigenvectors of a matrix M formed as the expectation over the outer product of the gradient of the loss with itself to reveal 'slow' and 'fast' modes of the evolution. It subsequently derives sufficient conditions for the reparametrization (which is chosen to be linear but time varying) to balance the decay on all modes. After discussing an efficient approximation of the theoretically derived scheme, numerical results demonstrate the effectiveness of the proposed reparametrization in two exemplary applications.  ",
    "This paper proposes a reparameterization of non-linear non-convex optimization problems. This reparameterization amounts to a linear map (i.e., \"optimization params = linear operation of a different set of parameters). These linear maps are interpreted as a graph convolution network. The experimental results are validated on \"Kuramoto models\" and \"persistent homology models\".",
    "The authors derive a neural reparameterization of non-convex optimization problems in order to accelerate their convergence. They do this by deriving how the slowest components of the optimization variables can have their convergence rate improved by preconditioning with a NTK-based matrix. They make connections between this approach and Group Convolutional Networks. Experimentally, they show this approach improves upon baseline gradient-based optimization on a two datasets. ",
    "This work proposed a neural reparametrization scheme to accelerate a large class of nonconvex nonlinear optimization problems. The proposed method is grounded on analysis that the dynamics of gradient \ufb02ow are related to the condition number of the system. More specifically, by reparametrizing the optimization problem with a graph convolutional network (GNN), the proposed method can modify the condition number and obtain convergence speed up, the acceleration is demonstrated on optimizing synchronization problems and persistent homology of point-clouds.",
    "In this work auhors proposed an ensemble of multiple SVM classifiers setup in a hierarchical way (somewhat similar to neural networks). Each SVM is trained is a small patch or window from the input imagery and some classifiers can be eliminated from contributing to the predictions. Results show better performance by the model in the small data regime compared with larger convolutional neural networks trained from scratch.",
    "The paper describes the use of SVM classifiers trained independently using local receptive fields of images, outputting class probabilities for each pixel that are organized in channels. New independent SVM classifiers are trained over the class probabilities and their results are combined using voting to perform the final prediction. The authors report experiments on two datasets, comparing with versions of ResNet trained from scratch, in which SVMNet shows better results than ResNet when using fewer training examples, For one of the datasets, the ResNet could not converge, while SVMNet obtained up to 80%.",
    "The paper argues that one of the major drawbacks for deep convolutional neural networks (DCNNs) is the need for large annotated training sets. To address this drawback, the paper proposes a new architecture, SVMnet, which is designed to achieve relatively high accuracy  (compared to DCNNs) in settings of small training sets.  The SVMnet architecture is composed of one or more stacked \"SVM layers\". Each SVM layer is composed of a set of independent svm classifiers, where the input to each svm is a patch in the image and the output is a probability estimate for the image class. For example, given a grayscale h X w input image, an SVMnet with 5x5 kernels and stride of 5 would have a 2d \u201carray\u201d of h/5 X w/5 svms, each one trains on a patch of 5x5 pixels whichis flattened to a vector of 25 features. Each svm i is then trained directly to predict the class of the image, based on the 5x5 window, thus resulting in a probability vector for the 5x5 patch. From the validation step, we also obtain the average accuracy of each svm i, denoted by Ai, from which we can compute its weight when aggravating the predictions from all svms. In general each svm layer will have k X l svms, and thh output of the svm layer can be formulated either as a 2d array of k X l predictions or a 3d array of k X l X c of probabilities for each class (where c is the number of classes). When stacking a second SVM layer, the input to that layer is then the k X l X c probability map which is treated as a feature map. Finally, the predictions from the last SVM layer are tallied to produce a majority vote for the image. When training on images with multiple channels, for example RGB images, the channels are flattened to one vector, for example: a 3x5x5 patch would be flattened to a 75 dimensional feature vector.   To demonstrate the applicability of the proposed method, the paper compares SVMnet to ResNet on 3 publicly available datasets and claims to achieve superior performance to resnet in settings of limited training data as well as faster training time. ",
    "One of the weakness of traditional DCNNs is it needs large clean-labeled dataset. In this paper, the author proposes SVMNET, a deep learning architecture which includes a layered structure of Support Vector Machine (SVM) ensembles. The result shows that the SVMNET outperforms other deep convolutional neural networks such as ResNet-50 with less training time for cases in which the number of labeled training samples is small.  ",
    "The paper considers the problem of distributed training for graph learning tasks, under a setting where data privacy is significant for each individual machine and communication to/from a central parameter server is expensive. To preserve privacy each machine has only access to a distinct partition of the overall graph. The central server has access to the full graph. In the LLCG algorithm that the paper proposes, each machine trains on its local graph partition for some time before sending the parameters to the server. The server averages the received parameter, but additionally also does its own training using the full graph available to it. Theoretically the authors show that the proposed method avoids an error gap in the gradient norm that would exist if server correction is not performed. Experimental results show the proposed scheme performing similarly to GGS albeit with much lower communication costs.  ",
    "Training GNNs is challenging due to high communication costs or large memory overheads. This paper proposes a communication-efficient distributed GNN training technique named Learn Locally, Correct Globally (LLCG) to periodically model averaging on the server using locally trained models.  It also applies global server corrections to refine the locally learned models and solve the irreducible performance degradation caused by ignoring node dependency. This paper provides the convergence analysis and shows the proposed method can address the residual error. The experimental results show significant improvement compared to existing methods.",
    "This paper deals with the problem of distributed training of GNNs. Existing methods are either communication-intensive (sampling) or do not achieve good performance (averaging).  The authors propose a novel method, dubbed \"LLCG: Learn Locally Correct Globally\". Essentially, this method captures the idea of transmitting only local averages but adds a centralized step on the server to account for global structural information lost in the subgraph partition.  The authors further provide theoretical convergence guarantees. They both show that just averaging leads to an insurmountable residual error that explains the poor performance of averaging methods, as well as prove that this residual error disappears when adding the global correction step.",
    "This paper proposes a distributed training technique for GNN. This technique includes local computations done in parallel by several machines and a correction phase done by a centralized server. A theoretical analysis is given for this technique, showing that the server correction phase reduces some irreducible error that happens due to splitting the graph and doing a local computation on each subgraph. Several experiments are made on real datasets which show the merits of this technique over previous techniques in terms of performance, communication steps, and size.",
    "This work focuses on anytime pixel-level recognition (e.g., semantic segmentation). They propose to add intermediate exists in the architecture for anytime inference. They also consider spatial confidence adaptivity in their network, where they only execute subsequent layers on a small set of non-confidence pixels and obtain the features of other positions via interpolation. They apply the method to semantic segmentation and human pose estimation and demonstrate a reduction in FLOPs and good anytime performance for both tasks.   ",
    "This paper proposes an anytime method for pixel recognition tasks like semantic segmentation and human pose estimation. The key idea is to design a network with multiple \"early exits\", from which the network could make predictions using a corresponding prediction head. Thus, depending on criteria like budget or confidence, the network could decide where to exit and therefore leads to different accuracy-computation operating points (i.e. its anytime property).   The technical contributions are mainly on two parts. The first contribution is a re-design of prediction heads (denoted as RH in the paper) at each early exits, mainly to tackle the difference of granularity for different intermediate feature maps. Another contribution is a confidence-based adaptive filtering mechanism that decides how to allocate computation budgets across spatial regions. Specifically, at each exit, the max prediction scores are used as a measure such that all spatial pixels that exceeds certain score threshold will not be processed in later stages.   The authors evaluated their methods on two tasks (Cityscapes for semantics segmentation and MPII for human pose estimation) and demonstrated that their full-blown method yields a better accuracy-computation tradeoff, compared to variants of the proposed approach and several previous methods.    ------------------------- POST REBUTTAL -------------------------  The authors have addressed most of my concerns in their response. Also, after some discussions on the issue of lacking positive signals from wallclock time metric, I buy the arguments to position this work as a forward looking exploration in the alternative space to methods that are chosen in current hardware lottery. With this, I will raise my rating to positive inclined.    ",
    "The paper proposes a new task called \"anytime\" prediction, which requires a model to make a progression of predictions, which might be halted at any time. The authors then also introduce an end-to-end model for this problem. The main two components behind the proposed model are: (1) a cascade of \u201cexits\u201d enabling the model to make progressive predictions while taking into account accuracy vs computational cost tradeoff; (2) Confidence Adaptivity, which allows the model to focus on the less confident pixel prediction. The authors implement their approach using HRNet baseline and demonstrate improved performance and efficiency on semantic segmentation and pose prediction tasks.",
    "The paper presents adaptive and anytime methods for semantic segmentation and pose recognition. Both of these are \"pixel-level\" tasks where the model is expected to output a prediction for each pixel in the input image. Their adaptive method, that performs variable amounts of computation depending on the input and the budget, with the amount of computation devoted to a given pixel varying from one part of the image to another. This is done by adding early exits to the base model architecture, and modifying the convolution layers to perform sparse computation on a subset of locations followed by interpolation. Experiments are done on Cityscapes semantic segmentation and MPII pose estimation benchmarks.",
    "The paper proposed a new class of neural process algorithm called neural bootstrapping attention for neural processes (NeuBANP). This method utilizes efficient Neural Bootstrapping (NeuBoots) to improve Bootstrapped Attentive Neural Processes (BANP) in capturing functional uncertainty. Authors show that NeuBANP achieves state-of-the-art performance in benchmark experiments including Bayesian optimization and contextual multi-armed bandits.  ",
    "The authors introduce NeuBANP, an extension of B(A)NP that replaces the iterative prediction method of B(A)NP with a single prediction step following the idea behind the neural bootstrapper. This new model is computationally more efficient and able to produce more accurate uncertainty estimates as well as correctly model heteroscedastic uncertainties. The authors provide experimental results on nonparametric regression tasks, Bayesian optimisation, contextual multi-armed bandit tasks and image inpainting (in the appendix).",
    "The paper proposes Bootstrapping Attentive Neural Processes (NeuBANP), which utilize random sum-to-one weight in the encoder following from Neural Bootstrapper (Shin et al., 2021). The authors argue that this utilization resolves the overfitting problem in attentive NPs, and the proposed NeuBANP is more efficient in computation and memory perspective. Various experiments, such as synthetic examples and contextual multi-armed bandit, are conducted to compare against previous works of NPs and GP.",
    "The authors propose a new bootstrapping method in NP family called NeuBANP. The authors acknowledge the limitations of BANP and used the neural bootstrapping method to make development from BANP. While BANP does better functional uncertainty estimation than ANP, it carries a higher computational burden compared to ANP since it requires multiple computations of the encoder network, the adaptation layer, and additional heuristics. By incorporating neural bootstrapping to the bootstrapping procedure, NeuBANP is a more computationally efficient model, estimates functional uncertainty better than BANP, and also alleviates the overfitting problem that ANP and BANP carries. Experimental results show that it achieves state-of-the-art performance on stochastic optimization problems, including multidimensional Bayesian optimization and contextual multi-armed bandit.",
    "In this paper, the authors developed a transformer-based model, GeneBERT to align DNA sequences with regulatory elements. In particular, GeneBERT first applies transformers to learn representations of sequencing data and regulatory regions (e.g., open chromatin), and then aligns the representations of two modalities for identifying region-aligned sequences. The authors applied GeneBERT to recent scATAC-seq data in fetal and use aligned sequences to predict promoters, CTCF binding sites, a disease type and RNA splicing sites.",
    "The manuscript describes GeneBERT, a self-supervised and multi-modal pre-training approach for genomic data. GeneBERT combines 1D genome sequence data with a 2D representation of regulatory elements in different cell-types in three different pre-training tasks. A large-scale single-cell ATAC dataset is used to identify pseudo-bulk ATAC profiles for 17 cell-types spanning > 1M genomic locations. The sequence of these genomic locations provides the 1D representation of the data which are used in self-supervised training with masked genome modeling and next genome segment prediction loss functions, both inspired by the BERT framework. A 2D representation is derived using accessibility per regulatory element and cell type, and is self-supervised using a infoNCE loss. The pre-training framework is then compared in a variety of biological tasks including promoter prediction, TFBS prediction, splice site prediction. The authors then present ablation studies highlighting the importance of the different components of the loss function.",
    "The authors describe a pipeline to perform self-supervised learning on genome sequences, guided by accessible chromatin peaks. Their learning procedure is inspired by the NLP method BERT and uses several tasks from that work and its successors. After pre-training transformer layers, they fine-tune on several regulatory sequence classification tasks and demonstrate high performance.",
    "This work proposes an approach, called GeneBERT, for pre-training genome data in a multi-modal and self-supervised manner. They take the 1d sequence of genomic data and a 2d matrix of (transcription factors \u00d7 regions) as the input and optimize three pre-training tasks to improve the robustness and generalizability the model. Specifically, they introduce two main objectives for sequence pre-training, Masked Genome Modeling (MGM) and Next Genome-Segment Prediction (NGSP). GeneBERT consists of three main components: sequence pre-training, region pre-training, and sequence-region matching. The main contribution of the paper is that they use transcription factor information in genomic regions which makes the model more generalizable to other cell types than the previous DNABERT that only uses the sequence information. ",
    "This paper presents IGEOOD, a new method for detecting OOD samples by using geodesic (Fisher-Rao) distance in confidence scoring. It further combines confidence scores from the logit outputs and the layer-wise features of a deep neural network. The method is validated under various testing environments such as the availability of OOD data or the accessibility of latent features of a deep network. The idea of using Fisher-Rao distance for OOD detection seems novel and interesting. ",
    "The paper proposes a new group of methods for supervised OOD detection. In particular, the authors propose to use the Fisher-Rao distance between output distributions on the in-distribution data and test samples to detect OOD. The authors additionally propose to use Fisher-Rao distance in the hidden layer feature space, when possible (white-box setting). The method achieves strong empirical performance, improving upon standard baselines (such as Odin, Mahalanobis), especially in the white-box setting.",
    "The paper proposes to use a score based on the Fisher-Rao information metric (the Riemannian metric in the space of probability distributions) for the detection of out-of-distribution samples input to a trained DNN. While the output SoftMax probabilities are used in the black-box and grey-box scenarios, the learnt features in the intervening DNN layers are additionally used in the white-box scenario. The approach models each sample as providing posterior probabilities \u2013 (a) the SoftMax probability in the label space, and (b) class-conditional PDFs over the corresponding feature spaces for each DNN layer. These latter are modeled as multivariate Gaussian distributions with diagonal covariance matrices. Extensive experiments on existing benchmarks are conducted for comparative results against the state of the art demonstrating promising results. ",
    "UPDATE:  I acknowledge that I've read the author responses as well as the other reviews.   While the authors added further analysis on the proposed method, I am skeptical of the performance of the method since the proposed method requires validation OOD data to achieve SOTA performance and the runtime is much larger than MSP and energy baseline. However, I think the rebuttal clarified much of my concerns and therefore raise the score to 5 weak reject.   =================================================================  The paper proposes an out-of-distribution detection (OOD) metric based on Fisher-Rao distance which can be applied for pre-trained classifiers. First, the authors derive a Fisher-Rao distance applied to the distribution of softmax. Also, they motivate a toy example where the FIsher-Rao distance outperforms the conventional OOD metric, Mahalanobis distance. Furthermore, they formulate the Fisher-Rao distance-based framework, IGEOOD on Black(Grey)-Box, where we can only get access on the logit of the network output, and White-Box, where we can get access to intermediate feature layers. Finally, the authors compare IGEOOD against conventional OOD metrics on various out-of-distribution data and in-distribution data.",
    "This is a mainly theoretical paper that studies the capacity of equivariant representations, which is, the ability to linearly classify objects under different transformations of a symmetry group of interest. The main result in the paper is showing that the number of dichotomies (different binary classifications) is related to the dimension of the fixed subspace of the representations, rather than the dimension of the representation. The authors discuss several examples and also propose several usages of this theory to deep learning of symmetric objects: analysis of pooling operations and induced representations ",
    "This paper studies the expressivity of a representation constrained by group equivariance. The authors first use a classical notion of the perceptron capacity to offer a quantification of the expressivity. Then, an algorithm is designed to efficiently classify the $\\pi$-manifolds. Besides, the authors further apply the theoretical results to some practical examples and give bounds on the capacity when pooling operators exist.",
    "The paper provides an analysis of network capacity of group equivariant NNs. The analysis is based on determining the fraction of linearly separable dichotomies. It is found that this fraction is determined by the the number of trivial irreps that appear in the decomposition of the representations into irreps. I.e., the fraction is determined by the number of sub-spaces that are left-invariant by the group action. The paper is intuitive, well written, and theoretical results are confirmed by experiments.",
    "This paper addresses an underexamined area, the question of expressivity in equivariant neural networks.  In general, there is a large gap between our theoretical understanding of expressivity and generalization for non-equivariant networks and that for equivariant ones; this paper helps to close the gap.  In particular, given a set of equivariant representations coming from an equivariant architecture, the authors determine how expressive these features are for an invariant binary classification problem.  To do so, they define a reasonable generalization of perceptron capacity for invariant classifiers and compute it.  The answer turns out to be relatively simple and is mainly determined by the multiplicity of the trivial representation in the group representation type of the equivariant representation, which is not difficult to compute.  The authors also consider the case of useful but not quite equivariant operations such as pooling. Lastly, they provide a convincing empirical verification of their results.",
    "Goal: provide a human readable explanation to why a given classifier made a mistake on a given example.  Approach:   Step1: For the given input domain (here images), first obtain a set of concepts that are human interpretable. These concepts each describe a particular aspect of an image, and a human is expected to be able to look at image and say whether a particular concept applies or does not apply to an image (on scale of [0,1])  Step2: learn a map from the input domain to the concept space using an SVM  Step3: generate counterfactual perturbation of example that ensures that :1) classifier is now correct on example, 2) perturbation is valid (i.e. realistic) and 3) perturbation changes few concepts. The perturbation is the addition of a linear combination of concepts by different amounts.  Key to this is that generating the perturbation requires the true label and query access to the classifier.  Step4: present the user the weight vector of the concept perturbations.  Validation: two ways to evaluate, one controlled and one in the wild.  Controlled evaluation: using dataset of animal images in different settings, confound the class label, e.g. dog, with background, e.g. snow, then ask if approach can recover the confounding factor, here snow. They show that on a median basis, the method finds the right confounding factor in the top 2 spots.  In the wild evaluation: on dermatology and chest x-ray datasets, they studied the mistakes of of a  trained model. The evaluation of their findings is based on discussion with clinicians. ",
    "Explaining errors using semantically meaningful concepts is a critical tool for improving the performance, robustness, and trustworthiness of machine learning models deployed in application areas everywbere.  While there have been several proposed lines of work in this area, none is yet accepted as standard practice.  The authors present a method combining two prior methods in explainability: counterfactual explanation and concept activation vectors, and meld them together as coneptual counterfactual explanations.    They describe the training procedure, and show some examples on both ImageNet and real diagnostic imaging applications.",
    "The paper proposes a Conceptual Counterfactual Explanation for explaining a model's mistakes.  It starts by learning a \"concept\" using a linear separator in the models representation space and a small amount of data annotated with that concept.  Then, it explains a model's mistake by finding a change in those concepts that changes the model's prediction, does not change too many concepts, and does not change the concepts in an unrealistic way.  The method is verified by showing that, for OOD test points where the model makes mistakes, this explanation can identify the concept responsible for those mistakes.  ",
    "The authors propose a method for computing concept based counterfactual explanations - i.e. using the presence or absence of concepts (human understandable) for explaining the models prediction. In the paper they focus on image classifiers.",
    "The paper builds a memory and computation-efficient version of the KPConv model, which is a point cloud processing model. The paper uses many techniques to achieve this including, depthwise kernels, attention over kernels, and also neural architecture search (NAS). The paper conducts experiments to demonstrate the effectiveness of their techniques.",
    "This paper aims to accelerate the inference of 3D point cloud neural networks. The authors first borrow a few designs from efficient 2D neural networks: depthwise convolution and inverted residual bottleneck. They then propose to reweight the weights of kernel points with attention to boost its representation power. Finally, the authors adopt the predictor-based neural architecture search to explore the best model under a resource constraint. They have evaluated their proposed solution on the small-scale ModelNet40 dataset and the large-scale SemanticKITTI dataset and have achieved reasonably good empirical performance.",
    "This paper addresses point-based methods for classification and semantic segmentation in 3D applications. It aims to improve the computational efficiency of this kind of methods to make it better fit the applications of limited resources such as mobile scenarios. To achieve this, this paper conducts the following works. First, it develops a mobile attention kernel point convolution (MAKPConv) scheme to improve the performance of existing kernel point convolution. Second, it utilizes neural architecture search (NAS) technique to design the MAKPConv-based network. In this part, this paper proposes a wide & deep neural predictor for the NAS process. Experimental study is conducted on benchmark datasets and tasks to demonstrate that the resulted deep networks can achieve higher computational efficiency and improved performance. Ablation study is also conducted to illustrate the key components in this work. ",
    "This paper aims to address the point cloud analysis task by:  1) improving the existing KPConv operation via considering the kernel relationship;  2) designing the networks via a predictor-based NAS approach.  The improved KPConv operation. i.e., MAKPConv, can model the local structure efficiently, and the searched network has fewer parameters while performing better than the baseline on two datasets, including ModelNet40 for classification and SemanticKitti for segmentation.",
    "This paper proposes a metric for evaluating the learning stability of data and point out that unstably-learned instances are of low-quality for adversarial training. Through extensive controlled experiments, this paper investigates the impact of low-quality data on three issues in adversarial training, i.e., robust overfitting, robustness overestimation, and robustness-accuracy trade-off. The experimental results show that removing the low-quality instances can mitigate the issues.",
    "This paper studies the effect of data quality on adversarial robustness. Specifically, they focus on one measure of data quality (number of times there is a perturbation that is misclassified across training iterations). They study the effect of data quality on robust overfitting, robustness-accuracy tradeoffs and \"robustness overestimation\" (gap between strong and weak attacks). The main conclusions reported are that data quality as measured by their metric plays an important role in all three aspects, and a suggested takeaway is that we need data of higher quality to improve robustness. ",
    "**Few sentences summary**: the paper proposes an empirical study on how data quality impacts robust performance in the Lp-norm setting under three angles: robust overfitting (i.e. the difference in accuracy between the best and last checkpoints), robustness evaluation (i.e. consistency of the robust performance when trying various robust evaluations like AutoAttack) and clean/robust accuracy trade-off (i.e. the gap in performance between the clean and robust accuracies). They show that \"high quality\" data (selected with their proposed criterion) performs better than \"low quality\" data for these three performance metrics.  Regarding the **results** and **contributions**: * The authors propose a quantitative definition of \"quality\"  based on the average training robust accuracy over epochs per sample. * They show that \"low quality\" samples are better for standard training whereas \"high quality\" samples are better for adversarial training. * Studies on 1) robust overfitting, 2) robustness evaluation and 3) clean/robust accuracy trade-off on the datasets CIFAR-10/100 and TinyImageNet for Adversarial Training and TRADES.",
    "The paper investigates the impact of data quality, measured by the proportion of epochs in which the model classifies a specific input correctly during training, on the robustness, generalization, and robustness-accuracy tradeoff of adversarially trained models.  Unlike with standard training, the authors find that more difficult inputs (lower quality inputs) can hurt adversarially trained models.  They find that compared to randomly removing data during training, removing low quality data can lead to higher robustness, less robust overfitting, less robustness overestimation, and less robustness-accuracy tradeoff.",
    "The paper proves upper and lower bounds on neural networks for approximating Korobov functions $X^{2, \\infty}$. Upper and lower bounds match for approximation in $L^\\infty$ norm sense, and the rate is free of the curse of data dimensionality. The scope of network architectures discussed is extensive, including shallow (2-layer) networks, deep networks with ReLU(-like) activation functions and Sigmoidal activation functions.",
    "This paper studies what function class can be efficiently approximated by neural networks. This paper focuses on a special function class, namely the Korobov function space $X^{2, \\infty}$, which contains function with $L^\\infty$ bounded weak $\\alpha$-order derivative, where $\\| \\alpha \\|_\\infty \\le 2$. This is a local constraint on the local smoothness of the function space. This paper shows that shallow (with depth=$2$) and deep neural networks can efficiently approximate $X^{2, \\infty}$, and the number of parameters does not scale with $\\varepsilon^{-\\mathrm{poly}(d)}$, thus efficiently escaping the curse of dimensionality. Furthermore, this paper shows the optimality of their parameters bound by showing a matching lower bound. ",
    "This paper studies the ability of shallow and deep neural networks to approximate Korobov functions, and analyses their representation power in terms of the number of used parameters. The authors first show that 2 layers neural networks using common activation functions can approximate any Korobov function within eps error in infinity norm using O(eps^{-1/2} (log 1/eps)^{3(d-1)/2}) parameters. This result improves the existing upper bound of O(eps^{-d/r}) parameters for approximating Sobolev functions in W^{r,p} using 1-hidden layer neural networks, hence reducing the curse of dimensionality.  For deep neural network, this paper provides a new result, showing that neural networks with depth O(log d) and O(eps^{-1/2} (log 1/eps)^{3(d-1)/2}) approximate Korobov functions in X^{2, infinity} within eps error in L-infinity norm. This improves the result of [1], by requiring a depth independent of the required accuracy. However, the current work requires a C^2 and non-linear activation function, and is hence not applicable to ReLU.  Finally, the authors show that any continuous function approximator for the Korobov space requires O(eps^{-1/2} (log 1/eps)^{(d-1)/2}) parameters for achieving error eps, hence matching the previous upper bound for NNs up to factor (log 1/eps)^{d-1}.  [1] Hadrien Montanelli, Haizhao Yang, and Qiang Du. Deep ReLU networks overcome the curse of dimensionality for bandlimited functions",
    "This paper studies approximation capabilities of neural networks for the purpose of approximating Korobov functions which are multivariate functions of bounded second mixed derivatives.  The paper presents a complete study for approximating such functions with NNs: they study shallow nets and show that 2 layers with ReLUs and total #neurons of O(1/eps log^{1.5d}(1/eps))  where d is the dimension, can \\eps-approximate  Korobov functions. Moreover, by allowing larger depths, close to logd, they can get a better depedence on \\eps. Finally, they prove that any continuous function approximator requires a #params close to their upper bound in order to approximation Korobov functions.  This gives a complete picture for how Korobov functions behave wrt to function approximation with shallow or deep nets.  ",
    "The authors refer to prior work in sociolinguistic literature to state that larger communities create more systematic languages. However, they point out, this apparent correlation between language structure and population size has evaded machine learning practitioners studying language emergence. This paper claims that populations explored in machine learning have largely been homogeneous and that population heterogeneity is key to the emergence of structure in artificial agents. The authors reproduce the failure to achieve systematic languages by scaling up the population and then show that they can indeed get more structure by introducing heterogeneity. They explore introducing asymmetry between the speaker and the listener based on model capacity and learning speed, leading to an increase in language structure when the speaker is faster or has more capacity. The authors note that this effect only depends on the relative differences between the speaker and the listener and not the absolute values (there is a correlation with absolute values but the variation has a low magnitude). Further, they show that larger networks need fewer epochs to reach similar training accuracy, concluding that network capacity is a confounding factor of training speed in their setting. Finally, the authors create a population of heterogeneous agents by imbibing them with different learning speeds by updating an agent $i$ with probability $p_i$ after each round of the Lewis game. Four properties of the emergent language are studied: speakers synchronization, (negative) conditional entropy given an object, topographic similarity, and generalization. These metrics either improve or remain approximately at the same values as the population size increases.",
    "# Summary  The manuscript \"On the role of population heterogeneity in emergent communication\" addresses the question why results on population size in deep language emergence have not, so far, mirrored the effects it is claimed to have on natural language. In a nutshell, in natural communication population size correlates with simpler grammars and less idiosyncratic languages. The effects of population size on the structure of neural emergent communication is less explored and has hitherto not reflected what we know about natural language. The authors argue that one of the reasons for this is that artificial populations are often homogeneous. They show, through simulations, that introducing asymmetries in the training speed of speakers and listeners leads to trends that are more in line with natural language: the size of heterogeneous populations weakly correlates with more aligned languages; higher neg-entropy; better generalization when communicating about novel objects; and more compositional languages (measured as topographic similarity). ",
    "This paper analyzes the structure of emergent languages in signaling games played by _populations_ of agents, motivated by a rich body of socio- and psycho-linguistics results showing that languages spoken by more people (and with more second-language learners) tend to be grammatically simpler (e.g. have a more impoverished morphology).  The authors measure various properties of the emergent languages as proxies for how \"systematic\" a language is, and show several things.  First, increasing the number of agents does not correlate with any of their measures, so population size alone does not suffice.  Second, in a minimally small population, various measures of \"diversity\" of the two agents do correlate with their systematicity measures.  Finally, in a large but diverse population, we do see correlations with population size and _some_ of the systematicity measures.  The paper is interesting and timely, and reports on a large number of experiments.  While I think the experiments could be more closely linked to the hypotheses from the sociolingusitic literature, the paper will be of interest to many researchers in emergent communication, NLP, and cognitive science, and could spur future work in this intersection.",
    "This paper aims at solving a conflicting empirical observation and the present-state models for emerging languages. It has been observed that larger populations produce more structured languages. However, the state-of-art neural-based models have not been able to generate languages with such characteristics. This paper shows that a key ingredient is to allow population heterogeneity in the neural models rather than the current identically distributed specifications. ",
    "This paper considers the problem of designing polynomial graph filters for use in graph neural networks. The motivation for doing so stems from the notions of homophily and heterophily in labeling the nodes of a graph: the former requiring the use of low-pass filters, and the latter requiring the use of high-pass filters. Here, the authors consider the design of spline polynomials for spectral-domain filtering, as opposed to the typical ``global'' polynomials used in graph filter design. That is, they first partition the spectrum of the graph matrix into low-pass, band-pass, and high-pass components, learn polynomials over each partition, and then combine these polynomials, enforcing continuity at the boundary of each interval via a penalty function.  Of course, doing this requires a full eigendecomposition of the graph matrix, which has high complexity. To ameliorate this issue, the authors propose an efficient variant of their spline spectral filter. This approach only uses a coarse partition of the spectrum, rather than using the full eigendecomposition.",
    "This paper focuses on the task of node classification (semi-supervised learning) in heterophilic graphs. The authors identify that low-pass filter-based GNNs perform poorly on heterophilic graphs, precisely because they tend to smooth out differences in neighboring node features. Thus, they propose to look into filters capable of learning high-frequency content that can thus learn labels even if neighboring nodes do not share a label. In particular, the authors propose to learn different low-order polynomials for different parts of the spectrum.",
    " This paper proposes PP-GNN, a novel graph neural network that learns multiple adaptive polynomial filters acting on different subsets of the eigenvalues. The authors combine GPR-GNN with existing efficient algorithms for generating top and bottom eigen components to reduce the expensive complexity of eigendecomposition. They show that the piece-wise polynomial method can approximate a latent optimal filter better than a single polynomial in theory. ",
    "In this paper, the authors aim to develop GNN that can better adapt to the given prediction task (both homophily and heterophiliy). Specifically, the authors extend the existing polynomial filter and propose to learn a filter function as a sum of polynomials over different subsets of the eigenvalues. The effectiveness of the proposed GNN architecture is demonstrated on diverse node classification tasks. The ablation studies were carried out to understand the proposed GNN architecture.",
    "This paper proposed a new graph shortest distance embedding method. This method uses a betweenness centrality based random walk to sample paths in the graph and distance resampling step before optimization. They show that the estimated distance after embedding has a linear dependence with the original distance in the graph They also show that this embedding method preserves the shortest distance relation between points. In experimental results, they show that this algorithm achieves better accuracy than previous algorithms.  ",
    "This paper proposes a method to construct graph embeddings that are well-tuned for answering shortest-distance queries (SDQs), based on betweennes centrality distance sampling. The main idea appears to be that the betweenness centrality measures helps identify nodes that could serve as landmarks for distance calculations, hence an distance-oriented embedding anchored on betweenness centrality is bound to perform well. Distance are resampled from walk paths, and a step of other methods based on pointwise mutual information (PMI) optimization is abandoned.",
    "In this work the author(s) proposed a framework for node embeddings that captures better shortest path distances for undirected graphs. Specifically, the authors propose a new random walk framework based on betweenness centralities, and a distance resampling strategy that uses the shortest path distances, and the betweenness centrality scores and is shown to capture well shortest path distances (Proposition 1).  The authors also evaluate their framework experimentally, verifying that compared to other popular node embedding methods, it can be used to represent shortest path distances faithfully. ",
    "This paper presents a new Shortest Distance Query technique, namely, the Betweenness Centrality-based Distance Re- sampling (BCDR). The objective of this technique is overcome some drawbacks of traditional embedding-based distance prediction methods based on truncated random walks and point-wise Mutual Information (PMI). These drawbacks are a limited distance exploration and the lack of preservation of the shortest distance relation due to local optima. BCDR uses betweenness centrality to create a random walk that occupies a wider distance and uses Distance Resampling (DR) instead of PMI to preserve the relationship of distances. The paper presents theoretical guarantees of performance to address the exploration range and the intractability of shortest distance on paths. The experiments on three real datasets and simulated datasets show the performance evaluation with respect to baselines, exploration distance, and preservation of distance relation (and violation of the probability distance relation)",
    "The paper studies continual knowledge learning of language models, which is an interesting and important problem. Particularly, a new benchmark and a metric are introduced to quantify the retention of time-invariant world knowledge, the update of outdated knowledge, and the acquisition of new knowledge. To establish baselines for the CKL benchmark and validate the rationality of the proposed benchmark and metric, the author conducts extensive experiments with a pre-trained encoder-decoder model (T5) based on various training methodologies including regularization, rehearsal, and parameter expansion methods.  The paper is well organized and easy to follow. The proposed continual knowledge learning problem is quite interesting and important. The FUAR metric is also technically sound. The authors also conduct comprehensive experiments to verify the rationality of the proposed benchmark under the various settings.",
    "This paper presents a new continual learning problem setup: continual knowledge learning (CKL) and constructs an associated benchmark resource. The benchmark is based on slot filling-based knowledge probing tasks (i.e., the LAMA analysis). The authors show the empirical performance of some existing CL methods, ranging from regularization, rehearsal, and parameter expansion. And they show a few findings based on their experimental results, e.g., learning rate can be sensitive to balance the tradeoff between forgetting and learning new knowledge, and CKL methods might have transferrable performance across different LMs. (e.g., T5 and GPT). ",
    "- The paper is about continuous learning for language models. The authors leverage existing LAMA tasks and collect a new test benchmark with updated information and new information.  - They investigate several existing CL algorithms, and they propose a new metric called FUAR to measure trade-off between forgotten time-invariant knowledge and updated or newly acquired knowledge. - They provided some findings on their continuous LM learning. ",
    "The authors formulate a new continual learning (CL) problem called Continual Knowledge Learning (CKL). Particularly, they distinguished three sub-tasks in CKL, i.e., the retention of time-invariant world knowledge, the update of old knowledge, and the acquisition of new knowledge. They also introduce a new benchmark and metric to quantify the performance of various state-of-the-art models on these sub-tasks. They find that CKL demonstrates unique challenges that are not present in previous CL setups. Critical causes of knowledge forgetting in CKL are also discussed.",
    "The paper introduces an approach to decision tree induction based on sub-sampling and pruning heuristics.  Typically, inducing a tree involves O(D*N_j*log(N_j)) work at each node j, where D is the number of features and N_j is the number of observations at node j.  This is because we can find the optimal split at node j for each feature in O(N_j) time after sorting each of the N_j observations. The basic idea introduced in this paper is to reduce the computational complexity incurred at each node by starting with a subsample of N_j, pruning features with sub-par performance, increasing the subsample size, pruning sub-par performing features, .... until the best feature has been chosen on the full sample of N_j observations.  The idea is very simple and the authors attempt to bolster this simple idea with some theoretical results and a wide array of experiments. The method does appear to be effective for datasets with very large D, which for example occurs when constructing Haar features on image data.  ",
    "The paper proposes a stochastic (i.e. approximate) algorithm to fasten node splitting during tree induction. The idea of the method is to filter out the most irrelevant features using a (growing) subsample of training examples and then to optimize the split using all samples only for the remaining features. The approach is shown to improve computing times for tree construction by several orders of magnitude without impacting accuracy. ",
    "The paper presents a simple iterative sub-sampling procedure that can substantially reduce the runtime required for finding a split on a numeric feature in axis-parallel decision trees. In each iteration of the algorithm, the lowest-ranked half of features is discarded from further consideration, and the amount of data used for computing the value of a feature is increased for the next iteration, starting with a very small initial set of data. Once a user-specified maximum number of iterations has been reached, standard split selection is performed based on the remaining features and the full dataset available at the node. The paper derives a bound on the runtime, proves that the algorithm will monotonically decrease an upper bound on the split metric, and shows that the probability of discarding a feature depends on the overlap of classes wrt the feature (in a binary classification scenario). It also shows that the algorithm produces a consistent estimator and that the objective function decreases monotonically as new nodes are added. Experimental results on six high-dimensional datasets show that the proposed method produces decision trees that are competitive with standard trees that are obtained after pre-filtering features using chi-square or mRmR, but at a substantially reduced training time. The paper also has an additional experiment on MNIST and F-MNIST looking at trees generated using Haar features.",
    "This paper focuses on improving the computational efficiency of the construction of a decision tree. The paper proposes a scheme that combines row sub-sampling and an adaptive column subsampling to reduce the computational cost of finding the best split at each internal node during the tree construction. The authors present some theoretical guarantees for the computational gain and the reduction in the loss function. The empirical evaluation compares the train/test error vs computational complexity tradeoffs of the proposed scheme against various baselines and demonstrate significantly better tradeoffs, at times demonstrating over 2-3 orders of magnitude speedups. The empirical evaluation also highlights an application where the number of columns are very high -- a decision tree for Haar features of images, again showing significantly better tradeoffs than considered baselines. ",
    "The authors propose Eigencurve, a new approach to learning rate scheduling that utilizes information form the eigenvalues of the Hessian. They show that this scheduler obtains the minimax optimal rate on the noisy quadratic problem. Empirically, this scheduler demonstrates faster convergence on CIFAR-10 and ImageNet, especially when the number of epochs is small.",
    "The paper studies convergence rates of SGD with different stepsize schemes, in the context of linear regression. For convergence of the last iterate of SGD, the best known result still misses a $\\\\log T$ factor compared to the minimax rate. This work aims to fill this gap with an improved stepsize scheme that utilizes the eigenvalue distribution of the Hessian. When the true Hessian is known, the proposed method successfully fills the gap, provably and in the sense of the worst problem instances. When the true Hessian is hard to know, practical variants are also proposed, and are shown to be comparable to the state-of-the-art stepsize schemes in standard deep neural network benchmarks.",
    "This paper studies the convergence of SGD with different learning rate schedules and aims to achieve minimax optimal convergence rates on quadratic objectives. To this end, this work proposes a new learning rate schedule (named Eigencurve) based on the Hessian spectrum and provides an optimal last-iterate convergence rate. The proposed Eigencurve gives rise to slightly improved performance on image classification tasks with deep neural networks. In addition, the introduced schedule is similar to the popular cosine learning rate schedule on some problems, which, to some extent, justifies the effectiveness of the cosine schedule.",
    "# === Update === #  I appreciate the thorough response to my review provided by the authors. I have looked through the newest version of the submission and find it to be much improved. The inclusion of repeats for the train loss / test accuracy comparison is great to see and the updated figures are mostly fixed. The experiments now make a meaningful argument for Eigencurve as a (non)-convex optimization method.  I have increased my score to 6 to reflect the improvements and the author response.   # ====== #  This submission proposes a new step-size schedule for stochastic gradient descent which leverages the eigenvalue spectrum of Hessian to speed-up convergence.  The approach, dubbed Eigencurve, is shown to achieve the minimax optimal convergence rate for stochastic gradient descent on quadratic functions under an additional condition that the eigenspectrum of the Hessian decays according to a power law. When this decay condition is not satisfied, Eigencurve still improves upon the popular step-decay schedule; in this case, it is sub-optimal by a factor of $\\\\log(\\\\kappa)$ rather than the $\\\\log(T)$ factor of step-decay. A lower bound is also provided verifying that the $\\\\log(T)$ sub-optimality of step-decay is tight and cannot be improved for quadratics. The submission concludes with an empirical investigation of Eigencurve for (non-convex) optimization of several popular neural network architectures on the CIFAR-10 and ImageNet datasets.",
    "The paper provides an evaluation of many of the design choices and hyperparameter decisions made in offline model-based reinforcement learning methods which have emerged recently. Particularly, the empirical study looks at uncertainty penalties used in these methods, as well as hyperparameters such as ensemble size, penalty weighting, and rollout horizon. The authors find that offline MBRL methods are quite sensitive to each of these parameters. They compare the \u201coptimized\u201d version of MOPO with hyperparameters tuned using Bayesian optimization, and find that it leads to statistically significant performance improvements over the version of MOPO presented in the original paper.",
    "Model-based offline reinforcement learning algorithms typically involve constructing a pessimistic MDP, which is implemented based on an uncertainty estimation of the learned model. This paper conducts empirical analysis to compare different design choices of the uncertainty estimation in practice. In more details, the authors compare different approaches in terms of the correlation between the estimated uncertainty and ground truth model error. They also use bayesian optimization to search the best hyperparameter configuration that achieves strong empirical performance. ",
    "The authors present an empirical study of several uncertainty quantification heuristics applied to model learning in offline model-based reinforcement learning. Specifically, they consider the basic architecture of MOPO, in which an uncertainty based state-action penalty function is applied on top of the standard reward to construct a pessimistic MDP. Within this set up, the authors perform a empirical study of several different uncertainty penalties, exploring their correlation to the prediction error of the model, as well as in terms of their ability to detect individual transitions with high-percentile prediction errors. Finally, the authors perform Bayesian optimization over the choice of the uncertainty penalty as well as other hyperparameters such as number of ensemble elements, planning horizon, penalty weights, etc. They present these results showing that the optimal choice of penalty and penalty weight can vary significantly, not only between environments, but also within an environment as a function of offline dataset.",
    "Recent successful model-based offline RL techniques have relied on heuristics to penalize rewards according to the uncertainty of the estimated MDP. This paper reviews the different penalties that have been designed in the literature. The impact and importance of associated hyperparameters such as the planning horizon and the number of models in the ensemble are also evaluated. The author show that the selection of the best penalty and best hyperparameters lead to stronger performance.",
    "This paper studies the problem of experience replay. It proposes Model-augmented Prioritized Experience Replay (MaPER), a novel experience replay method, based on the intuition that the model is easier to estimate than Q-value. It also proposes a modification to critic network, Model-augmented Critic Network (MaCN), by predicting the reward and dynamics model additionally. Experiments on MaPER show that MaPER can be applied to both discrete action space (DQN) and continuous action space (SAC), both model-free RL algorithms (SAC) and model-based RL algorithms (MBPO), as well as sparse reward tasks, and improve the baseline algorithms a lot. ",
    "The paper proposes a new method for prioritizing experiences used in the prioritized experience replay (PER) method. The proposed approach is simple: the critic network also learns the reward function and transition function. The two errors (absolute value) are added to the absolute TD error to calculate the priorities in the PER method. The authors provide some intuitions to their method. Experiments on both Mujoco and Atari environments are presented to show the method\u2019s effectiveness. ",
    "Authors introduced Model-augmented Prioritized Experience Replay (MaPER) as a variation to the canonical prioritized sweeping. The main difference is that they extended the critic network on its last layer to also predict the reward and transition model. Then they changed the prioritization of sample for replay to also include the error in the reward and transition model, in addition to the TD-error. Experimental results in various MuJoC domains showed the performance boost introduced by MaPER on top of existing state-of-the-art techniques. Furthermore Authors carried an ablation study, investigation the impact of 1) incorporating the MaPER while all methods used the same network 2) incorporating various error values for prioritization, and 3) increasing the network size.",
    " *Summary Of The Paper Model-augmented Prioritized Experience Replay In this paper, the authors consider using the dynamics prediction error in the priority calculation. The priority is then used to decide the probability for each sample during training. The method is applicable to both model-based and model-free setting ",
    "The paper proposes HACO, a human-in-the-loop reinforcement learning method that safely trains an agent to imitate expert behavior while minimizing the number of expert interventions required. The key idea is to have a human watch over the agent (e.g., in a simulated driving environment), and take control whenever the agent enters unsafe states. HACO uses offline RL to train the agent to imitate the actions taken by the human during these interventions. To discourage the agent from intentionally visiting unsafe states in order to trigger human interventions, HACO also assigns a negative reward to the state transitions preceding a human intervention. Experiments with human participants in a simulated driving task show that HACO trains the agent to achieve higher success rates (in a test environment, without a human in the loop) than baseline methods based on imitation learning and offline RL, while requiring less training data and incurring a lower cumulative training cost.",
    "In this work, the authors propose a new algorithm for data-efficient human-in-the-loop learning, Human-AI Copilot Optimization. The main idea is to have experts intervene during training in cases in which unsafe situations arise. The HACO learned policy utilizes a multi-task objective: doing well relative to a learned value function (based on human interventions), keeping an exploratory policy, and keeping human interventions at a minimum. Experimentally, HACO seems to be able to drastically reduce the amount of number of environment training timesteps required to reach basic competencies to the agent in the test environment, while maintaining good task and safety performance.",
    "This paper proposed a method for driving policy learning based on human-AI copilot. The algorithm learns from human interventions and also tries to minimize the total efforts of human intervention. Comprehensive experiments and comparisons with multiple baselines show that the proposed algorithm can achieve high sample efficiency and reduce unsafe events. The contributions are in the design of the copilot learning method.",
    "This paper presents HACO, a human-in-the-loop learning algorithm that aims to learn imitative driving policy while minimizing the number of human interventions. HACO builds on CQL and operates under the no-reward assumption. HACO learns a proxy action-value function by penalizing the policy\u2019s action and maximizing during human interventions. It additionally adds an entropy term to encourage exploration. The policy trains by maximizing the proxy action-value, and penalizing an accumulative intervention cost, computed using the cosine difference between the human and the policy actions. HACO is evaluated in a closed-loop driving simulator. HACO outperforms the selected imitation and offline RL baseline and is on par with RL methods which have access to environment rewards. It is also orders of magnitude more sample efficient than standard RL methods.",
    "The authors propose to learn a high level policy network that picks a subskill policy to predict actions with meta imitation learning (DMIL). Both the high and low level policy networks are fine-tuned at meta-test time. They show that DMIL converges and evaluate their approach against several ablations on the ML10 and ML45 setting of the meta-world benchmark.",
    "This paper proposes a meta imitation learning framework aimed at learning long-horizon robot control tasks with fast adaptation capabilities. Specifically, the proposed approach adapts the model-agnostic meta learning framework for learning a hierarchical policy, where both levels of the hierarchy are meta-trained and fine-tuned at test time to learn new tasks. On the metaworld benchmark, the proposed method outperforms prior work, and qualitative analysis shows that the method discovers meaningful skills.",
    "The paper describes Dual Meta Imitation Learning (DMIL) which is a hierarchical meta imitation learning method where the high-level network and sub-skills are iteratively meta-learned with model-agnostic meta-learning (MAML). The DMIL is a hierarchical extension of MAML-based imitation learning (IL) and is a meta-learning extension of Hierarchical Imitation learning (HIL).  The authors provide theoretical proof of the convergence based on the connection with the Expectation-Maximization (EM) algorithm. They showed the state-of-the-art few-shot imitation learning performance on the meta-world benchmark.",
    "The paper proposes an approach for few-shot imitation learning that jointly meta-learns a high-level policy and a set of low-level policies from a diverse set of demonstrations (multi-task). It then finetunes both high-level and low-level policies on few demonstrations of the target task for imitating them. In experiments on the MetaWorld50 task suite the proposed approach outperforms few-shot imitation methods that either don't use hierarchy or don't use meta-learning. ",
    "This paper studies the embedding compression problem related to GNNs and graph representation. A two-stage method is proposed to generate the compressed embeddings: firstly, it encodes each node into its composite code with hashing; secondly, it uses a MLP module to decode the embedding for the node. Experiments are performed to evaluate the compression effect with both pretrained graph embeddings and node classification task with GraphSage. ",
    "In this work, the authors propose a hashing-based node embedding compression approach, which utilizes the random projection hashing method to generate a code vector for each node using auxiliary information such as the input graph adjacency matrix. The proposed method is memory-efficient in the training procedures of Graph Neural Networks (GNN) models. Experiments also demonstrate that the proposed method outperforms other coding schemes in both the embedding reconstruction task and node classification task.  ",
    "The paper presents a vertex embedding method with good scalability to large graphs.  The proposed method is based on locally-sensitive hashing and compositional coding: a memory-efficient binary representation of each vertex is constructed from a hashing technique and then, when needed, a decoder creates real vector embeddings of the vertices via compositional coding from a pool of codebooks. The encoding is constructed from prior knowledge and requires no training. Conversely, the decoder is trainable and can be learned end-to-end. The experiments show improved performance. A negative note is that some parts are unclear to me.",
    "In this paper, the authors present a general and scalable approach to obtain shallow embeddings of many entities. The authors achieve this by first mapping each entity into a code vector using LSH, and then learning a neural decoder on top of the code vectors to reconstruct the original embeddings/adjacency matrix. The authors then apply their approach to node classification problems, where node features are unavailable (the authors ended up artificially removing node features from existing OGB datasets). The superior performance is demonstrated over the random code vector baseline.",
    "The authors exhibit a strong link between game theory and domain-adversarial training. They show the optimal point in the latter is a Nash equilibrium of a three players game. From this perspective, the authors show that standard approaches, like gradient descent, cannot work in this setting as the method is known to be divergent in such a case. Instead, they propose to use Runge-Kutta methods (for example) to discretize the ODE, which gives insights for novel algorithms with better convergence guarantees.",
    "The setting in the paper is the classic unsupervised domain adaptation problem, where we are given a labeled sample from a source distribution and an unlabeled sample from a target distribution. The goal is to minimize the risk on the target distribution. Theoretical results led to a breakthrough in practice - the Domain Adversarial Learning architecture (Ganin et al., 2016).   The paper suggests looking at the paper from a game theory perspective. This is natural, as the objective is to minimize the loss on the source distribution while maximizing the distinction between the distributions.  The optimal solutions of the game are characterized by the local NE.  Motivated by the results from game theory, the authors suggest replacing Gradient Descent (due to its limitation in this optimization problem) with other optimizers - ODE (ordinary differential equation) solvers.",
    "This paper analyzes adversarial domain learning (DAL) from a game-theoretical perspective, where the optimal condition is defined as obtaining the local Nash equilibrium. From this view, the authors show that the standard optimization method in DAL can violate the asymptotic guarantees of the gradient-play dynamics, thus requiring careful tuning and small learning rates. Based on these analyses, this paper proposed to replace the existing optimization method with higher-order ordinary differential equation solvers. Both theoretical and experimental results show that the latter ODE method is more stable and allows for higher learning rates, leading to noticeable improvements in transfer performance and the number of training iterations. ",
    "This manuscript considers the adversarial domain adaptation training problem, specifically the gradient reversal method, from the perspective of game theory. The authors show that gradient-based optimizers without an upper bound on the learning rate violate asymptotic convergence guarantees to local NEs. The authors further show that these constraints can be lifted by higher order ODE solvers. In the experimental part, the authors evaluate their method i.e. Runge-Kutta ODE solvers of order 2 and 4 with different general and also game optimized gradient-based optimizers on a MNIST/USPS digits dataset. Furthermore, they show hyperparameter robustness of their method and finally, the method is tested on more complex image and NLP datasets and compared to current SOTA methods. Overall better results are achieved. ",
    "This paper introduced a simple but effective method to mitigate overfitting, which modifies the existing Flooding scheme. The proposed iFlood can solve the potential problems of the Flooding algorithm and improve the stability. Furthermore, the authors gave some theoretical analyses of the proposed method. The experiments indicated the proposed method is better than the baselines. ",
    "This paper proposed a stable and effective regularizer to prevent overfitting. Specifically, this paper proposes individual Flood. Different from Flood which constrains training loss on mini-batch level, iFlood gives instance-level constraints on training loss. This paper also theoretically shows that the design of iFlood can be intrinsically connected with removing the noise or bias in training data. ",
    "This paper extends the idea of Flooding to a sample-specific level and call it iFlooding. The extension is intuitively important and the authors also offered several analytical discussions to show its importance beyond the intuition. The empirical results are fairly relevant and strong. ",
    "The paper proposes a flooding loss function that encourages the training loss for each example to be a positive bias instead of zero. The paper has found that such training objective stabilizes the training compared to the regular Flooding, which regularizes the average loss instead. The paper also provides reasoning why such a loss function provides more robustness for training with noisy labels and biased label distributions. The empirical benefit on standard datasets seems marginal, but the benefit on noisy labels is significant.",
    "The paper presents a novel state representation technique that is based on Value Functions (VFs). The core idea of the paper is to use VFs to construct a high-level space representation in an hierarchical reinforcement learning (RL) scenario. The contributions of the paper are:  - Value Function Spaces (VFS): learned state representation - Practical algorithms with VFS both for model-free and model-based RL settings - Evaluation of VFS in 2 scenarios (MiniGrid and manipulation task)",
    "This paper proposes that given a set of skills or options, the vector of the value functions for the individual skills becomes the abstract state representation in the approach proposed by this paper. The authors then go on to develop a model-free RL algorithm akin to DQN and a model-based planning algorithm for planning in the state-space defined by the value functions of the component skills, and the action-space being the set of executable options.   The authors demonstrate that the value function space serves as a better representation than some baseline algorithms for representation learning for RL in a maze solving and robotic manipulation task.  The key assumptions made are as follows:  - The options are pre-defined and each option has an associated value function  - The new task is solvable with the defined set of options.",
    "The paper proposes a state abstraction in hierarchical reinforcement learning (HRL), called Value Function Spaces (VFS), that is constructed from the value functions of task-conditioned lower-level policies (or skills). The idea is that the value functions capture affordances of the lower-level skills while ignoring task-irrelevant information. The lower-level policies and the corresponding value functions are given a prior, and the state is constructed by concatenating the value estimate of each lower-level policy. The state abstraction is evaluated in a model-free Q-learning and model-based MPC type scenario.",
    "This paper presents Value Function Spaces (VFS), an abstract \"skill-centric\" representation for reinforcement learning and long-horizon planning. The core idea of VFSs is to leverage the learned value functions that are often trained alongside skills during skill learning to abstract knowledge about the world. Each element of this low-dimensional representation corresponds to the value estimated from one of the learned value function, so that the representation (by construction) tends to ignore distractor information unnecessary for accomplishing the skills. Using this representation on a set of pre-trained skills, the authors demonstrate improved performance on long-horizon planning tasks in grid-based maze and \"locked door\" environments, showing improved success probability on a number of such tasks compared to competitive baselines. They also show the ability of their abstraction to facilitate model-based goal-directed planning by learning a state-transition model (in VFS-space) that allows one to predict the outcome of executing a skill.",
    "This work proposes a new deterministic set sampling mechanism, Top-n. Top-n learns to select the best 'n' points from a trainable reference set. Unlike the previous set sampling mechanisms such i.i.d. sampling, First-n and MLP projection, Top-n do not suffer from collision problem and can generate sets of various sizes (unseen during training). Top-n can be incorporated for one-shot sampling in VAE and GANs like generative models. Experimental results on standard benchmark for set and molecular graph generation, suggest improved performance in comparison to prior sampling mechanism.",
    "This submission discusses probabilistic models that generate sets and graphs conditioned on latent vector representations. The paper discusses the following different approaches to generate sets:   * i.i.d sampling of set element representations, concatenated with the set's vector representation followed by (possibly equivariant) networks. * First-n generation, using a learnable reference set of a maximum number of nodes/set elements, and concatenating the latent set representation to each element of this reference set, and then picking the first n element of this reference set as node representations.  * MLP-based generation of node representations that don't take into account invariance of the generator under node permutation.   \t The authors claim that i.i.d sampling has two problems: the additional stochasticity makes it harder to train, and if two points are sampled too close together the resulting node representations will be similar (dubbed the collision problem). Furthermore, MLP-based generators don\u2019t explicitly take into account permutation symmetries, can't generalize to arbitrary number of nodes and first-n generation prioritizes learning of the first elements of the reference list as they will be used more often than the last elements of this reference list.   The authors propose a new definition of equivariance with respect to permutations: instead of talking about equivariance of functions, they propose to define equivariance for a learning algorithm, by stating that  \"a learning algorithm is equivariant to the action of a group if the training dynamics do not depend on the group elements that are used to represent the training data\".  They furthermore adapt first-n to the method top-n with differentiable sorting of the representations of the elements in the reference set based on cosine similarity with a vector that depends on the latent vector representation.   The following claims are made:  *  top-n is easier to train than i.i.d generation because it doesn't involve an extra sampling step * top-n  captures complex dependencies in data better.  The proposed method is benchmarked on set and graph generation tasks : SetMNIST, synthetic molecule-like 3D structures, the QM9 dataset.  ",
    "This paper considers the problem of \u201cone-shot\u201d set/graph generation, which involves learning a probabilistic decoder that maps latent vectors to sets.  First, the authors extend the usual definition of equivariance for a function to a learning algorithm.  This definition is used to show that exchangeability is not useful in GANs and VAEs when used for set generation.  Next, the authors propose Top-n, which is a new set creation mechanism which learns to select the most relevant points from a trainable reference set, in a deterministic and non-exchangeable fashion.  Top-n can replace iid generation in a VAE or GAN.  Experimental results are provided for SetMNIST reconstruction and generative tasks for a synthetic molecule dataset for sets, and the QM9 chemical dataset for graphs, demonstrating that Top-n is competitive with or outperforms a number of existing generative approaches.",
    "In this paper, the author proposes that exchangeability is unnecessary for the generative model in the domain of set and graph generation. The definition of equivariance is generalized to learning algorithms, which is appropriate for generative modeling. Then, a method called Top-N which can be used in classical generative models, such as VAE, GANS, is proposed. In the author's argument, the proposed method has the ability to extrapolate to larger sets than those seen during training as well as the ability to train easily, which are not satisfied by the previous generative models. ",
    "This paper studies the the statistical error of the Deep Ritz Method and Physics-Informed Neural Networks using neural networks and truncated Fourier basis in solving PDEs. The static Schrodinger equation is used as a prototype PDE. With appropriate assumptions, the authors established upper and lower bounds of the error for both methods. The upper bound derived in this paper improves existing results with a faster rate. The authors also proved that the upper bound of PINN is nearly optimal. Some numerical experiments are conducted to verify the results.",
    "This paper establishes statistical lower bounds and upper bounds for (a modified) Deep Ritz method and PINNs based learning of solutions of PDEs when the estimators belong either to a class of sparse neural networks or lie in truncated fourier basis. They utilize the fact that the objective in DRM and PINNS is strongly convex, and use it to get a faster generalization bound O(1/n) instead of O(1/\\sqrt{n}). Given that the upper bound for the initial non-modified version of DRM does not match the lower bound, they introduced a modified deep ritz method, where the number of samples to estimate the gradient squared is greater than (the ration is provided in the statement) rest of the objective. This enables them to achieve minimax optimality for DRM as well.   Through their experiments they verify that the number of training samples n and the test error follows a power low with \\alpha = 1/d as indicated by the derived rates.",
    "Applying deep learning (DL) to solving PDEs numerically has been a very exciting research directions. The current paper studies certain statistics properties of approximating linear Elliptic PDEs using neural networks (and truncated Fourier series). Under certain (quite strong) assumptions on the function class, the authors proved sharper (in some cases, tight)  bounds for the approximation errors. ",
    "This paper carries out a variety of studies, both theoretical and numerical, on numerical solution of a Schrodinger equation using deep learning inspired methods.  The main results are upper and lower bounds on a power law scaling for sample complexity, function of dimension and regularity, which are tight for one of the methods.  Another method (Deep Ritz) has a proposed improvement.",
    "This paper discusses a very interesting question: what is the relationship between adversarial robustness and cross-domain transferability. The previous studies show that a more robust model can transfer better. This paper argues that the true reason for the cross-domain transferability is not the adversarial robustness, but the effect of regularization, which can also be achieved through other methods, such as data augmentation.",
    "This paper aims to convey the message that adversarially robust models may not have better transferability in terms of transfer learning in vision tasks. However, this message is unclear due to the mixture of data augmentation, regularization, robustness in the presentation. Some definitions are confusing and the conclusion seems to contradict with existing literature, e.g,  Salman et al arxiv: 2007.08489.  --post rebuttal--  Thanks to the authors for the draft revision and the additional appendix C. Now the paper is clearer to me: the general idea is to say that robustness is a type of regularization, and this regularization is the key to generalization. However, I think the former is not novel as already mentioned in Roth et al NeurIPS 2020. Besides, there are still many presentation issues even after the revision, e.g.: 1) Prop 3.1 mentioned the relative domain transferability, but the formal definition is introduced later in Def 1. 2) The added paragraph is confusing to me. How would you define the input space ${\\cal X}$? Is it a compact set? Why would the perturbation go outside ${\\cal X}$? Shouldn't $x + \\delta$ still be in the domain of $f_c^{{\\cal D}_{\\cal S}}$ as otherwise it is not well-defined? 3) Def 2 should be compared with existing metrics.  4) In Section 3.4 the authors use the squared loss but in experiments they use cross entropy loss.  Despite the interesting topic, I would keep my current score until a more well-written version is presented.  ",
    "This paper studies theoretically how adversarially trained models can transfer better, and disentangle the robustness and accuracy on the target domain. They claim that the main reason is more of regularisation rather than robustness. Corresponding examples and theory are presented.",
    "This paper aims to investigate the theoretical connection between domain generalization (aka Transferability) and adversarial robustness in some general settings. Authors claim that a thorough theoretical treatment of this problem has not been given yet, and therefore set out to establish a number of fundamental relations.  A simple example has been proposed which shows the existence of cases, where adversarial robustness and transferability can be independent (or even negatively correlated). Also, paper proves that adding more restriction (tighter regularization) on the feature extractor stage of a learning algorithm gives better domain generalization. Additionally, some intrinsic and fundamental measures have been defined to bound the domain generalization error for transferring a learned model from domain S to domain T. In this regard, uniform convergence bounds have been derived to show the gap between empirical and statistical versions of such measures remain small or even converge to zero when sample size asymptotically increases.  Finally, a number of experimental results have been shown to support the above theoretical achievements. I have not gone through the experimental parts nor the proofs, yet.",
    "This paper aims to battle memorization overfitting problem in meta learning using causality. The authors view the process of meta-learning through the lens of causality which produces several causal graphs i.e. Fig. 1(b) for the general one and Fig. 2 (a-d) for special cases. Based on the causal graphs, the authors use 'front-door' adjustment and propose two algorithms MAML Dropout and MAML Bins. ",
    "This paper studies the memorization overfitting problem in meta-learning from a causal perspective. It provides explanations to current solutions and proposes to update the meta parameters by maximizing the interventional distribution $p(\\theta | do(\\theta'), S, Q)$. It provides an identification strategy for the interventional distribution by the front door criterion.",
    "The paper addresses the undesirable memorization problem in the context of gradient-based meta-learning, where the meta-learning knowledge obtained as a result of memorizing all meta-training tasks yields poor generalization and is detrimental to task specific adaptation. While previous work has focused on regularization-based and augmentation-based solutions to prevent the memorization of all meta-training tasks, the authors argue these methods and their benefits are still not well understood and propose a causal perspective of meta-learning in a unified causal framework. In this context the authors identify the universal label space of the base model as the confounding factor of memorization causing spurious correlations between initializations learnt in different meta-training steps. Informed by this analysis, the authors demonstrate why existing meta-learning overfitting solutions work, and propose two deconfounder approaches to address the issue of memorization, namely i) sampling multiple versions of the meta-knowledge via dropout (MAML-Dropout), and ii) grouping the meta-knowledge into bins (MAML-Bins).   ",
    "This paper studies the problem of memorization overfitting in meta-learning and proposes to construct a causal graph for gradient-based meta-learning. From a perspective of causal graph, this paper demonstrates how existing methods solve the memorization problem. Further, it proposes a novel causal intervention principle to debias the spurious correlation. Specifically, two implementations of the proposed principle are conducted, i.e., by sampling multiple versions of the meta-knowledge via Dropout and grouping the meta-knowledge into multiple bins. Experiments on four benchmark datasets demonstrates the effectiveness and compatibility of proposed algorithm.",
    "This paper proposes a new method, ODITS, to enable effective ad hoc cooperation without requiring to predefine a static set of teammate types. This is done by training encoder networks to extract latent variables which capture the \"situation type\", which is trained to be a sufficient statistic for predicting the joint action value. This enables the agents to adapt in online fashion (it doesn't assume static other agents), and additionally the methodology is able to deal with partially observable environments.",
    "The paper focuses on the important problem of building agents that can function as useful teammembers in a ad-hoc team where agents can change behavior over an episode. The paper propose a new framework named ODITS that allows training an agent for ad-hoc teaming applications without strong assumptions on observability or pre-defined roles and categories. It does so my learning a latent variable representation of teammate behaviors in a data-driven fashion during policy training. The framework also adds an information-based regularizer to allow learning these variables from partial local observations of an agent (using all available information during training in a CTDE manner). The paper performs experiments on three different environments to demonstrate their outperformance. ",
    "In this paper the authors tackle the challenge of ad hoc teamwork with unknown teammate types. Unlike most previous work, the proposed framework, ODITS, does not assume some finite set of teammate types or full observability, and adapts to current teammates via the utilization of a teammate situation encoder-decoder framework, which learns a latent representation of the teammate configuration the agent is currently observing (this observation can be partial). The authors subsequently show this approach outperforms state of the art baselines such as AATEAM on a several domains, namely a modified version of coin game, predator prey, and save the city.",
    "The paper addresses the problem of ad hoc teamwork, where an agent learns how to coordinate with a team of unknown teammates. Previous works typically assume that the teammates belong to one of a finite set of possible (known) types; at test time, the ad hoc agent uses the observed teammate behavior to identify their corresponding type and act accordingly.  The proposed method, instead, builds a predictor of the ad hoc agent's marginal utility (which depends on the teammates) that relies on local information alone. The predictor takes as input the ad hoc agent's current observations, $b_t$, and a latent vector, $c$, representing the current \"teamwork situation\". The teamwork situation representation, $c$, roughly plays the role of \"teammate types\" in previous works. To train the predictor, the proposed method makes use of an encoder-decoder model that, at training time, learns the \"teamwork situation\" representation $c$ using full state-action information. The output of the model is used in an \"integration network\" that estimates the $Q$-function for the underlying MMDP from $c$ and the agent's estimated marginal utility, $u_t$. Finally, since at test time the agent cannot access the full state-action information (and hence cannot estimate $c$ using the aforementioned encoder-decoder model), during training it learns an proxy encoder that builds an estimate $z$ for $c$ using only local information. The overall architecture thus includes two encoder-decoder models jointly trained so that they estimate a coherent representation for the \"teamwork situation\"---the first using only local information, and the second using full state-action information. At test time, the agent can use the estimated representation, $z$, as input to its marginal utility predictor and act accordingly.  The paper tests the proposed approach in 3 domains (modified coins environment, predator-prey, save the city) showing positive results over existing architectures and a well-established MARL approach (QMIX), and also presents a brief ablation study establishing the relevance of using the two encoder-decoder models to the overall performance of the method. ",
    "This paper presents a novel imputation method for high-dimensional datasets that typically serve as benchmarks for machine learning methods. This method (EMFlow) innovates by training a normalizing flow network to map input data samples to a multivariate Gaussian, where imputation is performed via an online version of expectation-maximization (EM), which is commonly used for missing data imputation. EMFlow is applied across regression tasks in datasets in the UCI machine learning dataset repository, and standard image classification datasets, MNIST and CIFAR-10. Empirical results show strong performance for missing data imputation, as well as downstream classification from these imputations, and the model design choices and well-constructed architecture make for easy training and fast optimization convergence.",
    "This paper presents a model named EMFlow, which performs data imputation in the latent space using the online EM algorithm together with the normalizing flow models. The normalizing flow models aim to capture the complete data density $p_X$ and the bidirectional mapping between the data space and the latent space, even when the data is only partially observed. The parameters in the latent space are updated using an online EM algorithm. Thanks to the feature-wise mapping, the dependency between features in the data space is carried over to the latent space and hence the imputation can be done. Evaluation using ten UCI datasets, MNIST, and CIFAR-10 datasets show impressive improvement against baseline models and the convergence is faster than MCFlow.",
    "The paper aims at imputing missing data which are MCAR and MAR.  For modeling the observed data distribution, it utilizes the framework of normalizing flow of which the latent variable/source variable space is Gaussian. By assuming the consistency of inter-feature dependencies in the latent/source variable space, it applies online EM for the imputation of the latent space variables. In the experiments, the proposed method, EMFlow is compared with GAIN, MisGAN, and MCFlow.",
    "The authors propose a novel architecture EMFlow for missing data imputation. The authors also show the results of various experiments with multivariate and image datasets. Finally, the authors report the accuracy of post-imputation classification on image datasets.",
    "The authors of this paper proposes a DLGN (Deep Linear Gated Networks), a novel class of deep networks, inspired by a recent dual view where the computation in DNNs is broken into two parts: learning in the gates and learning in the weights. The DLGN disentangles the computations into 2 parts: (1) \"primal\" part between input and the pre-activations in the gating network, and (2) \"dual\" part in the weights network, conditioned on inputs and gates. DLGN\u2019s performance recovers 83.5% of SOTA DNNs. This development may lead to more interpretable deep network models that are also highly performant.  ",
    "The paper extends the framework of the deep gated network to the deep linearly gated network. Based on this extension, the paper investigates the separate part of the network. By theoretical analysis and empirical experiments, the paper argues that the neural network is learned path-by-path instead of layer-by-layer. Also, it present that the neural path kernel has several interesting properties.",
    "This paper deals with the entanglement in the DNN through two steps. First, replacing the rectified linear units (ReLU) in the traditional DNN with Deep Linearly Gated Network (DLGN). Second, demonstrate the weighted network is disentangled in the path space.",
    "This paper proposed deep linearly gated networks (DLGN) for interpreting DNNs with ReLU activations based on a dual view. The proposed framework is able to completely disentangle the \u2018gating network\u2019 and the \u2018weight network\u2019. Finally, the experiment results demonstrate that DLGN can achieve good performance for classification on two benchmark datasets compared to the existing DNNs.",
    "This work presents a token normalization method in replacement of Layer Norm (LN) and Instance Norm (IN) for vision transformers (ViTs). The motivation is that the authors find that the common normalization used in most existing ViTs, LN, will reduce the difference in token magnitude, and this may lead to failure of capturing positional context and other inductive bias. Hence, they propose a Dynamic Token Normalization (DTN) component by combining LN and relative positional embedding based transformation. DTN can be plug in varying ViTs e.g., ViT, Swin, PVT. The experiments are done on ImageNet, ImageNet-C, ImageNet-R, and ListOps in supervised learning setting, as well as self-supervised pre-training. ",
    "This paper introduces a dynamic normalization, named Dynamic Token Normalization (DTN), to replace the vanilla layer norm in ViT. It learns to normalize tokens in both intra-token and inter-token manners, enabling Transformers to capture both the global contextual information and the local positional context. Experimental results show that DTN can improve some Vision Transformers in ImageNet Classification and Long ListOps tasks. ",
    "This paper studies properties in layer normalization and instance normalization, and states that the two normalization operations have their own drawbacks in vision transformers: LN suffers from lacking inductive bias while IN may be affected by the different semantics within the tokens. Accordingly, this paper proposes a new normalization method called DTN and considers both inter- and intra- token normalization into vision transformers. According to the experiments in the paper, the proposed DTN normalization boosts the performance of various vision transformer models on classification with ImageNet dataset as well as robustness with IMAGENET-C and IMAGENET-R.",
    "The paper first analyzes the limitation of LN in Transformers and then proposes DTN to capture both long-range dependencies and local positional context. DTN is a unified version that balances LN and IN. Extensive experiments show the effectiveness of the proposed DTN with some small/middle-scale Transformers on the ImageNet.",
    "This paper proposes a set of tools to probe spectral bias of deep neural networks, that is their tendency to learn low frequency, simpler functions earlier in training, whereas high frequencies are fit later. Authors propose adding noise to the labels through a target function via label smoothing, where the frequency and direction of the target function in image space can be varied. Moreover, they introduce a linear interpolation technique on validation data to probe the smoothness of the learned function along paths connecting natural images. Authors perform extensive experiments to demonstrate how the proposed tools can be used to investigate the spectral effect of training parameters such as model size and different forms of explicit and implicit regularization.",
    "This work presents an empirical study of how different training aspects affect the spectral bias of neural networks in practice. To that end, the authors propose to inject label noise of different frequencies to the CIFAR10 dataset and suggest that the time a neural network takes to start overfitting this noise is a good metric of its spectral bias. They also propose to measure the variability of the loss landscape in the linear interpolation path between two images as proxy for spectral bias. Experiments on the effect of model architecture, explicit regularization, and data augmentation suggest that deep neural networks exhibit a strong spectral bias, in practice, which can be modulated by different design factors.",
    "This paper proposes two methods for estimating smoothness of the prediction function learned by a deep network :   1/ an extension of Rahaman et al. to multiclass classification, by adding a sine of desired frequency to the target vector, then training on the new target vectors. The \"effective noise fitting\" is then the difference between the validation loss on clean targets and the validation loss on modified targets.  2/ a measure of change of the logits in l2 norm between 2 training examples, averaged over many examples  Using their methods, they show the effect on the smoothness of the predicted function of:  - varying the number of parameters  - adding explicit regularization (weight decay/mixup)  - distillation",
    "The paper focuses on the spectral bias of neural networks, i.e., their tendency to learn first the low-frequency information. The goal of this work is to extend the spectral bias into practical image recognition networks, i.e., beyond the fully-connected nets and the NTK regime that it was previously studied. To that end, the paper conducts a number of studies in both explicit and implicit regularization schemes used in practice, and provides links for the success of model distillation. ",
    "This paper proposes a mode-switching strategy for the exploration/exploitation dilemma instead of monolithic behaviour policies in order to obtain more diverse behaviour. Different granularities for the timing of the switches as well as different switching mechanisms are investigated (blind vs. informed switching). The focus for exploration is not on how, but when. For exploration, they both use Random Network Distillation (RND) as well as a uniform policy. Their experiments are conducted on the Atari Learning Environment (ALE), where they provide performance and diversity results.",
    "This paper proposes to study exploration at different levels of granularity. Current methods either explore at the level of individual steps (e.g., \\epsilon-greedy), or at the level of experiments (e.g. first a reward-free exploration phase, followed by a task-dependent learning phase using the gathered data). This paper proposes to study exploration at the intra-episodic level, i.e. where the agent switches between exploration and exploitation within the same episode.   They discuss various design choices to perform exploration at this level, for example switching after a certain number of steps or with a certain probability, or switching based on the discrepancy between the predicted value and actual experienced value.   The experimental results show that including intra-episodic exploration gives a modest benefit over other exploration schemes when using an R2D2 base agent. Other insights are also included, which show that the proportion of exploration does change throughout the learning process, indicating that different degrees of exploration are useful at different stages. They also show that the informed switching component learns switching behaviors which are non-uniform throughout the episodes.",
    "This paper studies switching between exploit and explore modes in reinforcement learning. It discusses switching mechanisms based on time (\"blind switching\") and based on state (\"informed switching\"). Studying seven Atari games, an empirical analysis of different switching mechanisms is performed.",
    "This paper investigates when to switch between exploitation and exploration and how long to stay in each exploration mode during RL learning. It proposes new ways to explore the subject, especially with intra-episodic exploration variants. It presents a large body of study results (10 pages of appendices!!), and concludes with very thought-provoking suggestions and discussions.",
    "This paper considers the problem of finding good initial centers for the fundamental problem of $k$-median clustering using a randomized embedding of the original metric into a tree metric.  After setting the initial centers, a standard local search algorithm is applied to produce an improved solution.  This is explored in both the standard context of $k$-median clustering, as well as in the relevant context of differentially private clustering.  In the latter setting, the goal is to minimize the amount of additive error introduced by the algorithm subject to being $\\epsilon$-differentially private.  An extension to $k$-means is given in the appendix.  In the standard setting of $k$-median clustering, the main theoretical result is an initialization algorithm which is an $O(\\log(\\min(\\Delta,k)))$-approximation to the optimal k-median clustering.  This is an improvement over k-median++ (which gives $O(\\log k)$) when $\\Delta$ is small, e.g. for $\\Delta = O(d)$ and $d$ is small.  Using this as a seed results for a local search method results in an $O(1)$-approximation overall.  At a high level, their algorithm first constructs an embedding of the original metric into a hierarchically well-separated tree (HST).  From there, the initialization can be seen as finding an $O(1)$-approximate solution on the HST efficiently.  The overall guarantee follows from standard results about HST's  In  the differentially private setting, the main result is a similar guarantee on the quality of the initial solution and also a bound on the quality of the final solution when using a known private local search algorithm.  The quality of the final solution has $O(1)$-multiplicative error and $O(\\epsilon^{-1}k^2\\Delta\\log(n)\\log\\log(n))$ additive error.  This is an improvement over the additive error of $O(\\epsilon^{-1}k^2\\Delta\\log^2(n)$ due to Gupta et al. 2010.  The number of local search iterations is also improved from $O(k\\log n)$ to $O(k\\log\\log n)$.  The main idea for the initialization is similar to the standard setting, but here they use the structure of the HST to ensure the initial solution is private by injecting a different amount of noise at each level of the tree.  An empirical study is done on a class of synthetic graphs as well as the MNIST dataset.  For the synthetic graphs, the metric space is given by the weighted shortest path distance in each graph, while for the MNIST dataset the metric is given by either $\\ell_1$ or $\\ell_2$.  The authors compare both the initial costs and the final costs (after running a local search method) for several initialization methods in both the standard and differentially private settings.  The main observation is that the proposed initialization methods tend to have better initial cost and the proposed differentially private method often outperforms the other methods in both initial cost and final cost.    ",
    "The paper proposes a new initialization scheme for the k-median problem on graph input (or general metric spaces) using metric embedding tree structure. The paper proposes an algorithm that finds initialization of good centers using HST that gets an approximation factor of O(log min{k,d}) if the data is in Euclidean space  where d is the number of dimensions. Then, the paper studies clustering with differential privacy guarantee and hows that the initialization method could be adapted to give a slightly stronger muliplicative and additive errors. The work complemented these theoretical findings with experiments and show that the proposed initialization imporves the performance of k-median++ initialization.",
    "This paper introduces a new initialization scheme for the k-medians clustering problem in the general metric space setting. This is based on the construction of metric embeddings via 2-HST\u2019s (Hierarchically well-separated trees). The authors also extend this to the differential privacy (DP) setting. They prove approximation guarantees in both the non-DP and DP settings, improving upon the literature. Finally, they empirically validate algorithms against a number of baselines with both real world and synthetic datasets for multiple metrics.",
    "The paper suggests an algorithm for the metric k-median problem using ideas from Metric embedding theory. The suggested use of the algorithm is as an initialization routine for the local search based algorithm for k-median. The differentially private version of the algorithm is also given along with bounds on k-median approximation factor. Experiments are conducted over datasets such as MNIST and results compared against the k-means++ algorithm (a popular initialisation algorithm).",
    "The paper studies conditional video prediction. In particular, it focuses on the problem of current models underfitting and not scaling to datasets. The paper proposes an architecture that is claimed capable of using parameters more efficiently in order to overfit. Then, data augmentation is introduced to improve performance for generalization. They evaluated their method against baselines on 4 datasets (Human 3.6M, KITTI, Robonet, BAIR pushing dataset). They also showed experiments to support overfitting/underfitting claims.  ",
    "The paper proposes a simple and scalable variational video prediction model FitVid, which attains a better fit to video prediction datasets even with a similar parameter count as prior models. The author has observed that previous methods suffer from underfitting on these datasets, directly applying FitVid actually results in overfitting. The FitVid uses a set of existing image augmentation techniques to prevent overfitting so that it can achieve state-of-the-art results on several prediction benchmarks. FitVid's architecture is based on SE-UNet LSTM, which seems to be the common backbone for the stochastic video prediction task. ",
    "This paper presents a new network architecture called FitVid to perform the task of video prediction, i.e. the task of predicting future frames from previous frames. Previous methods for this tasks usually suffer from \"underfitting\", while FitVid is able to overfit on major benchmarks without increasing the number of parameters, thanks to a better model architecture. What is more, FitVid is much easier to train than previous work, without using any bells and whistles in training. As a result, FitVid achieves state-of-the-art on four challenging video datasets across a wide range of metrics.",
    "This paper discusses a new framework named FITVID to handle the problem of video prediction. FitVid is built on existing modules like Sikp connection, Sequeeze and Excite, and LSTMs. FitVid only needs a simple training strategy and begins overfitting the datasets. Data augmentation is also adopted to handle the problem of overfitting. ",
    "This paper addresses the problem of characterising analytically the dynamics of stochastic gradient descent (SGD) in problems where the data have features with arbitrary covariance structure. All the results are valid for linear models (e.g., random features, neural tangent kernel) trained on the mean-squared error loss. First, the authors consider one-pass SGD and Gaussian features, and derive an exact closed-form expression for the time-evolution of the expected test loss, i.e., averaged over the data distribution and the sampling sequence. Then, they turn to generic non-Gaussian feature maps with arbitrary covariance and similarly compute an exact closed-form expression for the expected test loss of one-pass SGD. They also derive an upper bound that only depends on the features covariance, provided that a regularity condition holds on the fourth moments of the features. This result shows that non-Gaussian effects are negligible in the settings under consideration. Finally, they extend their results to multi-pass SGD and provide expressions for the expected test and training losses over time. The authors apply their theoretical findings to derive heuristic estimates of the optimal batch size and learning rate and study their dependence on the features and target distributions. The numerical simulations show a good agreement with the theoretical predictions.",
    "The paper studies the learning dynamics of stochastic gradient descent on simple linear models with structured features. In particular, the paper discussed the influence of data structure on learning dynamics and optimal batch sizes. In practice, this model seems to be able to predict the training/test error of small neural networks on real data. ",
    "The authors derive exact and non-asymptotic (in size or time) expressions for the expected test loss of a linear model during the SGD training dynamics. The time-dependent average test loss is given as function of the eigenvectors and the eigenvalues of the covariance matrix of the features when the features are Gaussian. For non-Gaussian features also forth-moments are involved and the Gaussian formula can be adapted to provide an upper bound. In any case, the formula for the  Gaussian case seems to match very well the experiments on real world datasets. The formalism covers both the online setting and the setting of multiple passes over a fixed training set. ",
    "This paper studies the relation between the test error of stochastic gradient descent on training linear models and the structure of the data distribution, the iteration number, and the batch size. The analyses are first done on one-pass SGD and then extended to multi-pass SGD. Results in theory and real data experiments are presented to illustrate the learning curves of the SGD algorithm.",
    "## Post-discussion reassessment  See relevant post below.  ## Summary of contributions  In this paper, the authors examine whether SGD with a large, constant step-size avoids local maximizers (or, more generally, undesirable saddle points of the underlying minimization problem). More precisely, they focus on the algorithm $$ w_{t+1} = w_t - \\lambda \\hat g_t $$ where $\\lambda>0$ is the algorithm's step-size, and $\\hat g_t$ is a (stochastic) gradient of the (stochastic) loss function $\\hat L(w;x)$, with $x$ a random variable.  The paper's results can be summarized as follows:  1. If $\\hat L(w;x) = (x/2) \\cdot w^2$, the authors identify a range of values of $\\lambda$ (which depends on the distribution of $x$) such that, in probability, $w_t$ converges to $0$ \u2013 which, under the specified distributional assumptions for $x$, is the global maximum of $L = \\mathbb{E}[\\hat L]$. This is made precise in Propositions 1 and 2, and Corollary 1.  2. They provide a quartic loss function under which SGD converges to the function's sharper minimizers (as measured by the trace of the Hessian at said points). [Proposition 4]  3. They provide a specific range of parameters under which the AMSGrad algorithm converges to the undesirable maximizer of item (1) above.  [In the supplement, the authors also provide an analysis of a gradient-like diffusion (Appendices B and C), which they discuss as a continuous-time model of (SGD). This part is not directly connected to the rest of the paper, so I am not including it in my evaluation below.]",
    "This paper demonstrates on several fairly simple (e.g. 1-dimensional quadratic) objectives that stochastic gradient descent may easily have very poor behavior: it could converge to a maximum, or diverge even in convex settings if the learning rate is too high.  Specifically, it is shown that for any learning rate, there is is a distribution over quadratics whose expectation is $-rx^2$ for some $r\\ge 0$ such that SGD will converge to the maximum at 0, and there is also a distribution whose expectation is $rx^2$ such that SGD still diverges even on this convex loss. Note that the distribution (and $r$) depend on the learning rate. Further, there are distributions such that SGD must escape a saddle point very slowly, and a distribution over 2-dimensional quartics such that SGD will converge to a \"sharp\" rather than a \"flat\" minimum. It is also shown that AMSgrad must converge to a local maximum on some non-convex distributions.  The results are proven by choosing a particular distribution over quadratic objectives that causes the logarithm SGD's iterate to be a sum of i.i.d. random variables. Then the central limit theorem provides an understanding of the limiting behavior of these iterates.  The results are augmented by empirical studies verifying the theorems directly, along with a very simple small neural network experiment.",
    "Many theoretical works have studied SGD, but they commonly rely on restrictive and unrealistic assumptions about the noise. In this work, the authors construct example optimization problems illustrating that, if these assumptions are relaxed, SGD can exhibit many strange behaviors, including (1) SGD can converge to local maxima, (2) SGD may escape saddle points arbitrarily slowly, (3) SGD can prefer sharp minima over flat ones, and (4) AMSGrad can converge to local maxima. Therefore, the authors conclude that in the most general nonconvex case, many counter-intuitive phenomena of SGD may arise and contrast to the commonly held presumptions.",
    "The paper provides several artificial examples on which SGD has an unintuitive behavior. This includes: (1) SGD converges to a local maximum; (2) If the learning rate is not fixed then SGD takes arbitrarily long time to escape saddle points; (3) SGD may prefer sharper minima (in contrast to several hypotheses regarding the implicit bias of GD); (4) Adaptive methods may also converge to a global maximum. Several experiments are made, varifying the theoretical results.",
    "The authors propose a hyperparameter optimization algorithm in meta-learning, where parameters w/o being involved in the inner loop optimization are treated as hyperparameters. The proposed algorithms approximate the second-order hypergradients via knowledge distillation. They further evaluate the effectiveness on tinyImageNet and CIFAR100. ",
    "The paper proposes a novel hyperparameter optimization algorithm in meta-learning to overcome previous limitations of only being able to see a longer horizon and not being scalable to high dimensional hyperparameters. In particular, the authors propose to distill the hypergradient second-order term into a one-step Jacobioan-vector product. The authors show that, with their approximated algorithm, it is possible to perform hyperparameter optimization for higher dimensional hyperparameters and longer horizon length even in an online setting. Empirically, the authors show the advantages of the proposed approach in several benchmark datasets.",
    "This paper develops a practical gradient-based hyperparameter optimization method, HyperDistill, that meets the following criteria   a) scalability in hyperparameter dimension and memory constraints,    b) accuracy (hyper-gradient update terms do not depend on only the last step of gradient updates)   c) applicability to the online setting.  The main difficulty lies in estimating the gradient of the weights with respect to the hyperparameters. The authors do so by approximating it as a single Jacobian-vector product, using a \"distilled\" weight and dataset pair.  Experimentally, HyperDistill achieves better validation losses and higher quality true hypergradient estimates than a variety of recent, relevant baselines, and does in an efficient fashion.",
    "This paper proposes a new online hyperparameter optimization algorithm. Applying meta-learning for hyperparameter optimization is reasonable and interesting but suffers from the second-order gradient computation. Implicit Function Theorem and Unrolled differentiation can be used to approximate the meta-gradient but also causes various problems. In this paper, the authors propose an interesting method by approximating the second-order approximation with knowledge distillation. ",
    "The paper proposes to apply the task-aware-modulation on global Meta-learning for learning on tasks sampled from heterogeneous distributions. This paper builds on prior work on the feature-based task characterization to integrate the rehearsed task gradient descent trajectory into task representation. As the rehearsal task is computationally expensive, the authors learn a different network to estimate the rehearsed task-trajectory characterization from the feature representation. The proposed framework is tested on few-shot image classification (meta dataset and miniimagenet) and cold-start recommendation tasks. ",
    "This paper proposes a meta-learning approach based on MAML but with a task-conditioned initialization, which takes into account both information extracted from the features of the task (support set) data, as well as geometric information from a \u201crehearsed\u201d learning path (obtained by gradient descent on the support set). The geometric information includes the parameters, loss, gradient and fisher matrix for different steps of the task adaptation process. They propose a GRU architecture to process this information across the different steps, yielding a path embedding. For both the feature and path embeddings, they utilize clustering, motivated by the need to share knowledge across similar tasks. They then combine the path and feature embeddings via an additional neural network to generate the final task-specific initialization. Computing the path embedding requires rehearsing which is computationally expensive (it\u2019s akin to training twice on the task, once for rehearsing, and then training from the task-conditioned initialization). To amend this at inference time, they meta-learn a \u2018tunnel\u2019 connection that predicts the path embedding from the feature embedding. At test time, only a forward pass through this meta-learned connection is required instead of rehearsing. They experimentally evaluate their approach on few-shot classification and cold-start recommender problems and show performance gains over similar MAML-based approaches. They also perform ablation studies and analyses to understand the contribution of different parts of this system to downstream performance.",
    "This paper proposes a clustered task-aware meta-learning algorithm. The proposed algorithm firstly collects the learning path and uses the path to train a sequence module. The sequence module output is combined with the task feature. The task feature is derived from the weighted sum of the soft cluster centers. The combination is then used as initialization of the model parameter for task adaptation. Experiments on image classification and cold-start recommendation demonstrate superior performance compared to baseline algorithms.",
    "This paper looks at the problem of meta-learning with heterogeneous tasks. This is an interesting problem that is receiving increasing attention in the past two or three years. Several previous work address this problem by clustering task representations and let the meta-learner exploit the information about task cluster. The authors claim that, for the first time, they cluster tasks not only at the level of the input representation (features), but also at the level of the optimization trajectory in parameter space. ",
    "The authors proposed a novel transductive novelty detection method using the disagreements of the ensemble models. More specifically, the authors directly utilize the unlabeled test set samples, providing different labels for those unlabeled samples, and training multiple models with fine-tuning. Then, this framework tries to identify the OOD samples using the disagreement of those samples. The authors provide some promising experimental results to discover the OOD samples in transductive settings.",
    "The paper presents an ensemble-based semi-supervised learning method for novelty detection.  The goal of their training scheme is to create an ensemble of models that has a high disagreement on the out-of-distribution (OOD) samples in the unlabeled set. The training resembles a self-training algorithm that labels the unlabeled pool and uses implicit regularization via early-stopping to find a \"sweet spot\" in terms of disagreement on OOD samples between the models in the ensemble. The final decision of whether an input is considered as out- or in-distribution is based on a hypothesis test using the average disagreement between the softmax outputs in the ensemble. In-distribution samples should be accurately classified with high confidence and show little disagreement in the ensemble while out-distribution samples should be detectable as the different models will produce different outputs. ",
    "The authors introduce a semi-supervised ensemble approach to novelty detection. The main idea consists in generating base classifiers that disagree on the out-of-distribution data (ODD). An early-stop criterion is used to achieve the wanted level of disagreement among the component of the ensemble.  The main assumption is the availability, for training, of clean labeled in-distribution (ID) data, and of unlabeled data which include both ID data and out-of-distribution (OOD) data. The unlabeled data follows the same distribution of the data the ensemble is tested on.  Each base classifier is first trained on the labeled in-distribution (ID) data. For a given base classifier, the unlabeled data is randomly assigned to one of the labels (a different label is chosen for each base classifier), and the classifier is tuned on the resulting labeled data. The tuning is stopped when the optimal tradeoff between high validation accuracy (on inliers) and low training error are achieved. This regularization process is aimed at avoiding fitting the incorrect assigned labels in the unsupervised portion of the training data and to achieve disagreement among the base classifiers on the OOD data.",
    "The authors develop an ensemble-based procedure for semi-supervised novelty detection (SSND). It utilizes a mixture of unlabeled ID and OOD samples to perform on near OOD data. A regularization technique is further used  to promote diversity on the OOD data while preserving agreement on ID data.",
    "This paper adapts transformer to multi-agent motion forecasting. The attention layers are applied on time and agent axis to capture motion and social information. A latent variable is introduced on the output to capture discrete motion for each agent. Extensive experiments are conducted on various dataset with good performance. The training time of the proposed model is significantly faster than previous methods.",
    "This submission presents a Transformer-based architecture for trajectory prediction tasks involving multiple agents. Such a multi-agent setting requires learning of spatio-temporal representations capturing both the long-term temporal dependencies as well as the social interactions between the agents. The paper formulates the task as modeling of the sequence of sets where every entry in the set corresponds to an agent\u2019s observation. The proposed architecture augments the set transformer with a discrete latent variable to be able to make multiple predictions into the future. The given seed sequence is first encoded into a context representation which is later used to make future predictions with a decoder where the agents can be modeled jointly or independent from each other. ",
    "The paper tackles the multi-agent trajectory prediction problem, primarily for autonomous driving, but experiments also include TrajNet and predicting Omniglot strokes. The authors claim their contributions in a very general sense:  - Novel method on modeling sequences of structured continuous variables and capture multi-modal distributions. - Strong results on nuscenes, argoverse, trajnet and omniglot stroke prediction.  The key modeling novelty is the latent variable sequential set transformer which applies self-attention across different agents and across time in the scene.   I mostly agree with the authors' assessment in general. I have some concerns on the claimed novelty (see below).",
    "This paper proposes a transformer-based VAE model for motion prediction that can output multi-model and scene-consistent predictions. Specifically, the transformer is employed for modeling both social and temporal information (but separately, first temporal and then social and repeat). The proposed method achieves state-of-the-art performance on the nuScenes dataset and top performance on the Argoverse dataset",
    "The paper introduces an experiment design and an approach to synthesizing the dataset for the experiment. The experiment asked the systems to classify whether the shape of the \"animal\" is Peaky or Stretchy. The advantages are that authors can controllably generate trainable examples under arbitrary biases of the predefined features (shape, color, etc). For experiments, human subjects are asked to predict the systems' output. The authors compared the visual explanation (concept explanation) and counter-factual explanation with the baseline explanation that uses the output logits and found that the the current good explanation approaches do not make humans understand the system significantly better",
    "The paper proposed a synthetic dataset to explore the bias contained in the dataset. Because the dataset is synthetic. We can manually change its attributes, add or eliminate the bias. Then, two main user study is conducted. One is to see if users can find the bias and another is to investigate if explanations are helpful.",
    "This paper proposes a dataset called TWO4TWO to conduct a user-study on two interpretability methods: counterfactual and concept-based explanations. Since the dataset is generated and can be fully controlled by users, the ground-truth important attributes to the decision are known. In this case, we know the ground-truth features and can thus assess whether the model explanation also reveal the correct features. As a baseline explanation, the authors group the input according to the model\u2019s output logits. The result from the user study shows that the two sophisticated explanation models don\u2019t surpass the simple baseline method, which indicates that explanation techniques shall be evaluate in user studies. ",
    "The authors explore several explanation methods for image classifiers via a user study. They study a toy environment containing images of two animals: stretchy (who has stretched legs) and peeky (who has a head that extends beyond its front legs). While the true label of peeky vs. stretchy is defined deterministically and specifically, the toy environment enables the authors to generate spurrious correlations between attributes like background color, animal position, shape, etc. and the label (which the model picks up on). The goal of the explanation methods is to help users identify which features (spurrious and not) the model is picking up on. Through a series of pre-registered user studies comparing a simple baseline to counterfactual explanations to concept highlighting, they explore whether or not users can accurately reconstruct which features the model is using in its predicitons. They find that concept highlighting performs far worse than the baseline of simply showing some model predictions in a grid, and that the baseline and the counterfactual method performed similarly. They release their procedures and generation code as a challenge to the community: can a new interpretability method outperform their baseline?",
    "This paper studies a defense against poisoning attacks using an outlier detection technique they develop using a notion of \"self-expanding\" sets. They assume a number of properties for inliers and outliers and can classify them so long as those properties are satisfied. They run experiments based on an existing backdoor attack and they show that their technique could be successful.    ",
    "This paper tackles backdoor attacks where an adversary performs targeted attack against neural networks by injecting some poisoned data into the training data without sacrificing prediction accuracy on clean data. The defense works by recovering the clean data from poisoned training data. The authors proposed an Inverse Self-Paced Learning (ISPL) algorithm to first find a set of homogeneous sets (pure clear or poisoned data) and use an ensemble of weaker learners to exclude poisoned data from training set. ",
    "This paper proposes a new defense to backdoor attacks. In practice, it is an iterative training procedure which aims to remove poisoned data from the training set. This happens in two phases: an ensemble of weak learners identifies distinct homogeneous sub-populations in the training se, and a boosting framework aims to exclude poisoned data and recover clean data. They compare their approach with a few other defenses on CIFAR-10 and on dirty-label backdoor attacks.",
    "This paper proposes an iterative data filtering/expanding approach with a set of weak learners for backdoor defense. The core idea is that clean distribution and backdoor distribution is incompatible and thus making them seperable based on the expanding error of the training set with many smaller subsets. The weak learners refer to the snapshots of the classifier trained on different subsets and expanded sets.  It is an iterative approach with multiple (8) rounds of  ISPL (Inverse Self-Paced Learnin) and 24 weak learners (each trained for 40 epochs). The entire process is also repeated for 3 times. Theoretical formulation and jusstificaiton have been given along with some empirical verfifiction.",
    "This paper consider multi-label text classification problem and propose a cross attention Transformer encoder to model the correlation between latent labels and input text sequence. The hidden states of those latent labels are concatnate as input to layers of MLP for the classification head. The experiment results show marginal gain over the baselines.",
    "This paper proposes to implicitly model label correlations in multi-label text classification. Different from previous studies (e.g., tree-based models) that describe label correlations explicitly, this paper appends \"latent labels\" to the beginning of each document and feeds it into a BERT classifier. These \"latent labels\" are randomly initialized, and the concatenation of their output is used for classification.  The authors conduct experiments on two benchmark datasets, AAPD and RCV1. Experimental results show that their proposed method outperforms several baselines for multi-label text classification. Ablation studies further show that using \"latent labels\" is better than using \"actual labels\" in their framework.",
    "This paper addresses the task of multi-label text classification by modeling the label correlations implicitly. Different from the previous works that explicitly model the label correlations, such as the label embedding methods, this paper proposes modeling the label correlations via latent labels. The proposed method outperforms the baselines on two multi-label text classification benchmarks in the reported experimental results.",
    "The paper presents a method that uses latent label representations to model label correlations implicitly, for the multi-label text classification (MLTC) task. The method concatenates a set of randomly generated latent labels to input text tokens. Then the method uses this as the input to the BERT model. At last, the contextual encodings of these latent labels are used to generate predictions for the actual labels. The model has been tested and compared against the LACO algorithm [1] that sets the SOTA on the AAPD and RCV1-V2 datasets, and outperforms LACO using Hamming Loss and Micro-F1. Especially, the proposed method has even better performance than the baseline LACO algorithm, on the low-frequency labels and intensive-label samples.  1. Enhancing Label Correlation Feedback in Multi-Label Text Classification via Multi-Task Learning",
    "In this paper, the authors study some simple convolutional kernels. They show that two or three layers convolutional kernels with polynomial kernels on the higher level and Gaussian pooling provide similar performance as the much more complicated state-of-the-art convolutional kernels (e.g., Myrtle kernel). Motivated by these good performance, they proceed to characterize the RKHS of these kernels, and describe how extra layers and pooling allows to capture interaction between patches with more or less spatial dependency. They then use the RKHS norm and some standard bound on the generalization error to show how choosing an architecture adapted to the target function can improve the statistical efficiency.",
    "The paper studies the RKHS and generalization properties of convolutional kernel networks, the NNGP corresponding to CNNs and the class of kernels that achieve state of the art performance on image classification. Among the theoretical contributions are analysis of the regularization induced by pooling, and interactions between patches captured with iterated convolutions. The paper also includes experimental results on CIFAR10 matching the prior state of the art for a kernel method while using a shallower architecture, as well as some ablations on the size of the convolutional kernels, the size of the pooling filters, and the number of layers. ",
    "This paper analyzed convolutional kernels. Experimentally, the authors showed that convolutional kernel formed by shallow convolutional neural networks (2 - 3 layers) performs as well as the state of art deep convolutional kernels (e.g., Shankar et. al.). The authors also provide an exact description of the RKHS functions and their norm, of the one layer convolutional kernel and two layer convolutional kernel with low degree polynomial activation function on the top layer. Finally, assuming that the target function has a specific form, then theoretical results can give the generalization upper bound of kernel ridge regression in terms of the sample complexity; this shows that using a proper architecture can same the sample complexity by a polynomial factor of the input size.  ",
    "The paper aims to study properties of deep convolutional models via the surrogate of simple hierarchical kernels with convolution and pooling layers. The authors characterise the underlying RKHS and their norms, and provide generalization bounds. The results imply that convolution operations such as pooling and patches, if present in the data, lead to improve guarantees. An empirical study both justifies studying these simple kernels in the first place, and illustrates the obtained theoretical results. ",
    "This paper studies an in-depth analysis of runtime and memory requirements for computing the finite-width NTK. The authors analyze computing costs of Jacobian-vector products (and vice versa) for both fully-connected and convolutional neural networks. They also improve the NTK computation cost by leveraging the structure of neural networks resulting in drastic speedup and memory saving. Finally, they make all their implementations open-source based on the JAX library.",
    "This paper studies the practical compute and memory requirements to computing the Neural Tangent Kernel (NTK), introducing two new approaches to doing so for standard NN primitives (structured derivative and NTK-vector product) which each have advantages (in terms of variables like batch size, output dim) over the naive jacobian contraction method. The authors provide experiments demonstrating the advantages of their approaches across a range of architectures and hardware. The authors provide open-source code which seems to be integrated neatly with the JAX and Neural Tangents frameworks.",
    "This work aims to solve the computation problem of the finite-width neural tangent kernel (NTK), which is a central object in deep learning. The authors analyze the computation and memory requirements for finite-width NTK and propose two novel algorithms that can improve efficiency. Open-source has been provided by the authors.",
    "Experiments are convincing. The provided code is helpful for researchers who need a fast computation of NTK. Though the ideological (mathematical part) is very simple.",
    "The authors propose a DICE-family method for solving constrained offline reinforcement learning problems. To do this, they adapt ideas from OptiDICE and find a reduction from a nested constrained optimization problem to a single unconstrained optimization problem that can be efficiently represented with a neural network. Additionally, they draw on ideas from CoinDICE to estimate a confidence interval over the cost, which makes their method better at obeying constraints. The  authors compare their method to a number of baselines on both random grid worlds and continuous environments, and find that COptiDICE achieves both good performance and better constraint satisfaction than alternative methods. ",
    "The paper considers the offline constrained reinforcement learning problem and formulates the problem as a CMDP. First, the paper presents the algorithm COptiDICE, which directly estimates the stationary distribution corrections of the optimal policy. Then, the paper shows that COptiDICE outperforms the baseline algorithms in terms of constraint satisfaction and return-maximization. ",
    "This paper studied the policy optimization problem in the offline constrained MDP setting. Compare with previous works, in which policy gradient based approaches are widely adopted, this paper solves the problem via policy visitation distribution that rooted from the primal-dual formulation of Bellman operator, which is novel. In order to guarantee the constraints are always satisfied, this paper provides a novel approach based on CoinDICE to efficiently estimate an upper bound of constraint violation. The author also provide sufficient empirical verifications to support their proposed algorithm.",
    "This paper has presented a DICE-based offline constrained RL algorithm for constrained RL. Experimental results on tabular CMDPs and continuous control tasks show that the proposed method can achieve a better trade-off between reward maximization and constraint satisfaction.  1st contribution: They firstly proposed to tackle constrained offline RL by solving a single minimization problem.   2nd contribution: To mitigate constraint violation in practice, they exploit the distribution correction obtained by solving the RL problem for cost upper bound estimation and then constrain the upper bound. ",
    "The main focus/goal of the submitted paper is the parallelization of the Gated Recurrent Unit (GRU) (the authors focus on classification problems). The authors describe the incorporation of a multigrid reduction in time (MGRIT) solver to speed-up and better parallelize the  application of forward and back propagation of information. The proposed technique seems to provide a speedup of about an order of  magnitude (at most) when implemented on distributed/shared memory hybrid computing environments.",
    "The paper proposed to parallelize the inference and training of GRU networks (a type of recurrent neural networks) at the `time` dimension.  The main contribution is the application of multigrid reduction in time (MGRIT) solver, and a new GRU architecture (Implicit GRU) that handles the stiffness in the architecture. As a result, the evaluation shows 6.5 times faster training time.",
    "The paper describes a technique for evaluating GRU networks based on the multigrid reduction in time (MGRIT) technique. These techniques are not new, in general or to neural network training, but the contribution here is their application to GRU layers. After presenting some of the theory behind ordinary differential equation (ODE) representations of the GRU and laying out the mathematical framework for the MGRIT method, the method is evaluated on two datasets. The results show impressive scalability up to 32 processes (CPU-only) at the cost of a slight loss of accuracy compared to the traditional, sequential GRU",
    "This paper aims to address the limitations of existing approaches for training Gated Recurrent Unit (GRU) given long sequence in terms of both training time and model accuracy. To tackle this challenge, author propose a novel parallel training scheme (called parallel-in-time) for GRU based on a multigrid reduction in time (MGRIT) solver.  Specifically, the key to achieving speedup is a hierarchical correction of the hidden state to accelerate end-to-end communication in both the forward and backward propagation. Authors gives experimental results on two public datasets to demonstrate the performance improvement in the long sequence scenario. ",
    "The submission proposes a new model for functional alignment of fMRI datasets from multiple subjects. It combines a one-in-many-out autoencoder with two regularization loss terms (one inspired by GRAE) to develop a model that can encode every subject's data to a shared latent space, from which each subject's data is then decoded by a separate decoder. Experiments are provided that demonstrate benefits to some downstream tasks.  ",
    "The paper proposes a new neural architecture named MRMD-AE that can be applied on noisy fMRI data in different tasks. Subject-specific decoders are used to more directly recover individual signals, while the encoder is shared across every subject under the assumption that every person will share common low-dimensional features for the same stimuli. A key component of this architecture is the usage of a regularisation term named PHATE (previously introduced in the literature) which allows the latent space to not be split into individual embeddings and be extendable for unseen data. The paper empirically shows how this architecture improves metrics on classification tasks when compared to previously used techniques. ",
    "This paper proposes a neural network-based modeling strategy to learn a common latent space from multi-subject fMRI data. In addition to capturing a useful common latent space, the proposed technique is further able to disentangle common representational patterns from subject-specific variations through the use of subject-specific decoders. The authors impose meaningful and desirable priors on the latent embedding, like geometric regularization and cross-subject embedding alignment. Unlike other manifold learning techniques, the proposed deep neural network modeling framework lends itself well to extendibility to new data (stimuli) since the PHATE embeddings are only required at training time in the geometric regularization loss. The proposed framework is tested on two large fMRI datasets and an improved stimulus decoding (from the shared space) and cross-subject translation accuracy is achieved over competitive baselines. ",
    "The paper proposes a model to learn a low-dimensional representation of fMRI data over multiple subjects of the same experiment. The model is built as an auto-encoder, with an encoder shared across subjects, and a separate decoder per subject. The model is regularized so that the first layer of each decoder gives a representation close to a pre-computed manifold embedding. An optional regularization also constrains the shared representation to be similar across subjects.  The paper then proposes a series of experiments to demonstrate the benefits of the learn representation. The experiments consider the tasks of (a) projecting new test samples to the learned manifold, (b) classify some stimulus features from the embedding (decoding task), and (c) predict brain recordings of a new subject.",
    "The paper presents the negative of the maximum unnormalized logit (MaxLogit) as an anomaly score for out-of-distribution (OOD) detection. Also, it introduces a large-scale setup for ODD. The proposed metric shows promising results compared to the maximum softmax probability (MSP) in the proposed setup (in-distribution ImageNet-1K and out-distribution Places365). For the multi-label experiment, the PASCAL VOC and MS-COCO are in-distribution and ImageNet-22K out-distribution. The proposed MaxLogit works better than in this MSP too. Finally, the proposed metric shows promising results in the  CAOS benchmark.",
    "The authors extend the out-of-distribution (OOD) detection from not-seen in small-scale settings to large-scale multiclass and multi-label ones. They provide large-scale benchmarks for evaluating ODD detectors on classification as well as segmentation. Additionally, they propose a simple yet strong baseline for this practical problem.",
    "The paper presents a collection of somewhat disjoint contributions to outlier detection. First, the authors propose Species - a novel OOD test dataset. The main advantage of this dataset is being disjoint from ImageNet-22k. Second, the authors propose to detect outliers according to the max-logit criterion. The authors claim that max-logit is especially suitable for OOD detection in multi-label environments. Third, the authors propose two novel datasets for dense outlier detection. StreetHazards is especially interesting since it allows proper rendering of introduced outliers. ",
    "This work explores out-of-distribution (ODD) detection in three large-scale settings: multi-class OOD detection, multi-label OOD detection and anomaly segmentation. To facilitate large-scale experiments, it introduces a novel species dataset and a road anomaly dataset for multi-class OOD detection and anomaly segmentation respectively. It also demonstrates a new setup for multi-label OOD detection. In addition, this work establishes a new baseline via a simple detector based on the maximum logit in all the three large-scale settings.",
    "The paper studies the relationship between dimensional representation of tournament and their structural characterization. In particular, a relationship is established between rank d tournament and their forbidden configurations in terms of flip classes, introduced by Fisher&Ryan(1995) as a way to partion the set of tournaments of a given order. In addition, the problem of bounding the minimum possible dimension of a representation of a tournament is also investigate and lower and upper bounds are given.",
    "This paper studies the theory of tournament representations, i.e. low-rank matrices $M$ whose sign agrees with the sign matrix of a tournament $T$.  The authors show several properties of such representations, reducing the study to so called $R$-cones, i.e. tournaments where one vertex beats all others. They also characterize completely rank 2 tournaments, and provide a forbiden class for rank $d$ tournaments.  Finally, they provide an upper bound on the minimum dimension of a presentation of any tournament $T$, in the for of a bound involving minimum feedback arc sets of $T$, and show how this can be extended to sign matrices.",
    "A tournament is made by choosing a direction for each of the edges in a complete graph. A tournament can be induced of by skew symmetric matrices M where entries M_{ij} > 0 if and only if (i,j) is an edge. A tournament on n edges can be represented by a set of d-dimensional vectores {h_1, \u2026 , h_n} if (h_j)^T A h_i is not zero iff (i,j) is an edge (and A is an appropriate matrix).  The authors address two questions:  1) What structurally characterizes the class of tournaments that can be represented in d dimensions?  2) Given a tournament T on n nodes, what is the minimum dimension d needed to represent it?.  The first question is answered by considering structures the authors called forbidden. The authors provide a characterization of these forbidden structures as a union of certain equivalence classes.   They answer the latter question in part by providing bounds on what said dimension d should be.   ",
    "This paper provides fundamental theories of tournament representations. The authors study two main questions. First they characterize the class of tournaments that can be represented in d dimensions. Second they give lower and upper bounds on the minimum dimension needed to represent a tournament on n nodes. ",
    "Neural processes (NPs) aim to stochastically complete unseen data points based on a given context dataset. This paper incorporates the stochastic attention in NPs to capture the context information. We empirically show that our approach on 1D regression, predator-prey model, image completion, and MovieLens-10k dataset.  ",
    "The paper proposes a novel method for the Attentive Neural Processes paradigm by adding stochasticity to the weights of the cross-attention module between the context and target representations. These weights are drawn from a proposal distribution which is a Weibull distribution with parameters determined by the context and target input points. A new KL regularization term is added to the total loss to enforce the proposal distribution be close to the gamma distribution determined only by the context points, in a similar fashion to the regularization term for the latent representation between the whole set of target and context points and that of the context points only. The authors include, from Fan\u2019s paper, the closed-form KL divergence between the Weibull and Gamma distributions, making the whole loss be differentiable w.r.t. the network parameters thanks to the reparametrization trick, as in the original NP paper. The new loss is linked to the gain of the target distribution by means of information theory, by making the assumption that the new regularization implies not only that the mutual information between the target distribution and the target points is maximized, but also the mutual information between the representation for the context and target points and the latent representation of the context variables only is minimized, enforcing the latent variable to also consider the context points, and not otherwise as suggested by the original NP formulation. ",
    "This paper proposes to improve attentive neural processes (ANP; Kim et al.) by replacing deterministic attention with a Bayesian attention module. Since the inference requires variational approximation, I think the proposed method is a variational counterpart of ANP, similar to the relation between VAEs and autoencoders.",
    "This paper proposes a neural process enhanced with stochastic attention to focus more on the context dataset. The method replace the classical attention used in ANP with the Bayesian attention module, showing that this design choice improves the performance also in noisy scenarios or when target datasets mismatched (by changing the kernel used to generate the target dataset). Moreover, the paper offers an interpretation of the method from an information theory perspective, proving that the NP with stochastic attention can be seen as a regularization of the latent space such that it pays more attention to the context dataset. The method is tested on both synthetic and real-world datasets and improves the scores especially in noisy or more complicated scenarios.",
    "The premise of the paper is that example train instances with the corresponding label can be an effective explanation of the model's prediction rather than post-hoc explanation which is not deterministic. The framework jointly trains label prediction and prototype clustering. Then, the framework computes the similarity between input and prototypes to retrieve the most similar prototype as an explanation while predicting the label as well. Moreover, the framework can reflect human-in-the-loop feedback on the prototype. The primary result of the paper is that their framework can show the proper explanation by a similar example while preserving the performance.",
    "This paper aims to model explanation and task prediction such that task performances are not (or less) traded off for interpretability. It proposes a novel framework for transformer models where classification and explanation generation are based on shared prototype embeddings which are learnt from training data by a combination of losses. The framework is also compatible with settings that requires human in the loop for extra supervision on prototype learning. Experiment results show that adding the proposed ProtoTrex benefit task performances on 3 sentiment classification tasks.",
    "This paper proposes Proto-Trex model to increase the interpretability of the text classification systems. The proposed model mainly adds a bunch of prototype layers to learn the similarity between the query and prototypes. They also propose an extension caleld iProto-Trex to interactively learn from users' feedbacks. Experimental results and example cases show that the Proto-Trex could give comparable classification accuracy compared to plain classification model (w/o explanation) and could provide reasonable explanations. ",
    "This paper introduces a method for improving interpretability of black box transformer based text classifiers. The approach is based on \u201ccase based reasoning\u201d where the network classifies an input by comparing it against a library of learnt prototypes (each with a corresponding label) and classifying the input based on a weighted similarity with the prototypes. Thus, in a sense it is more interpretable than an end-to-end classifier since a user can directly look at the similarity scores with the prototypes to understand the labeling decision. The approach also promises to be more \u201cfaithful\u201d than post-hoc interpretability methods since the predictions are based directly on similarity scores. The paper also shows that end-users of the system can interact with it by either editing prototypes (if they are experts) or providing weak feedback about which prototypes are good, and this feedback can be integrated to re-learn better prototypes. From experiments we see that their approach is competitive with standard end-to-end finetuning while being more interpretable. Based on sufficiency and comprehensiveness scores, we see some evidence that the explanations from prototypes are faithful, though it is unclear if these scores are competitive. ",
    "In this paper, the problem of forward knowledge transfer in continual learning settings is explored. The idea is to measure correlations between the learned tasks based on the notion of \"trust region\" which helps to identify the most similar learned tasks to the current task. The core idea is that frozen weights for similar past tasks can be relaxed to reuse them to learn the current task. Since task similarities are used for this purpose, this will not lead to catastrophic forgetting and at the same time helps to transfer knowledge. Experiments on four benchmarks are provided to demonstrate that the method is effective.",
    "**Summary:** The paper focuses on gradient projection (GP) for incremental learning. The authors motivate their work by stating that while approaches based on GP lead to superior performance in overcoming catastrophic forgetting, they suffer from a significant drawback. In GP, once one calculates the subspaces spanned by layerwise inputs for a task, say Task A, the network is then forced to only update the weights in an orthogonal direction to these subspaces for learning a subsequent task, say Task B (hence keeping important parameters for Task A intact and overcome catastrophic forgetting). However, suppose Task B and Task A are similar (an extreme case is when Task B is the continuation of Task A!). In that case, we know that the essential parameters for Task A are likely to be important for Task B and that the network could benefit by continuing to update the important parameters for Task A, which is not allowed in GP algorithms. This behavior has two consequences: 1) intransigence, i.e., the network won't be able to learn Task B as effectively as possible, and 2) the network will have reduced backward transfer. The backward transfer issue is apparent in the extreme case when Task B is a continuation of Task A, and the network's performance on Task A would have improved if it was able to learn Task B using the important weights for Task A!  The paper addresses this issue, with a simple, yet practical, solution. For a new task, the authors calculate the correlation between the subspaces calculated for old tasks and the new task (layerwise), keep track of the most correlated previous tasks for each layer, and denote them as (layerwise) Trust Regions. Next, the authors propose a scaled weight projection that allows for unfreezing the important parameters in the Trust Region of the new task, while learning this task, and learn the corresponding weights as part of the optimization process. Finally, the authors report results on Permuted MNIST (PMNIST), CIFAR100 Split, CIFAR100 Sup, and a sequence of 5-Datasets with 10-class classification which includes CIFAR-10, MNIST, SVHN, not-MNIST, and Fashion MNIST, in comparison with GP methods, regularization-based methods, and memory replay method. They show consistent improvement in accuracy, and more interestingly in backward transfer.  ",
    "Some existing methods put restrictive constrains on the optimization space of the new task to prevent catastrophic forgetting, which may lead to unsatisfactory performance for the new tasks. This paper aims to facilitate the forward knowledge transfer based on an efficient characterization of task correlation. Main contributions can be summarized as follows: 1.Introduce a novel notion of \u2018trust region\u2019 based on the norm of gradient projection onto the subspace spanned by task inputs to measure task correlation. 2.Proposed a novel approach for the new task to leverage the knowledge of the strongly correlated old tasks in the Trust Region through a scaled weight projection. 3.Developed a continual learning approach, trust region gradient projection(TRGP) based on the introduced Trust Region, scaled weight projection and a module to construct task input subspace. 4.Compared to related state-of-the-art approaches, TRGP achieves substantial performance improvement on all Benchmarks.",
    "This paper proposes a continual learning method based on gradient projection memory (GPM) of Saha et al., which projects the gradient of each layer to be orthogonal to the input subspace of previous tasks. Motivated by the fact that the orthogonal projection can harm the performance by being too restrictive, the authors propose a heuristic algorithm to reduce the restriction. Specifically, the authors choose a subset of most \"correlated\" tasks and let the model change along the subspace of the correlated tasks.",
    "This paper proposes a framework to analyze both optimization and generalization properties under the Uniform-LGI condition (Def 1). From my understanding, the main results consist of two parts:  * Optimization: define the Uniform-LGI as an extension of the PL condition, prove the corresponding convergence result with a sublinear rate, and bound the optimization path length. * Generalization: use the Rademacher complexity to estimate the generalization error. The Rademacher complexity scales with the diameter of the parameter set, thus can be bounded by the optimization path length, which connects with the optimization results.  Then the paper apply this framework to three application models: first establish the Uniform-LGI, then calculate the optimization path length and estimate the generalization error.",
    "The paper studies generalization and optimization of kernel-based and one-hidden layer neural network models. The convergence guarantee is shown for a Uniform-LGI loss function in Theorem 1. Then, in Theorem 2 the paper proves a generalization guarantee assuming a particular parametric model in Equation (3). Finally, the paper applies these results to p-norm regression, kernel regression, and one hidden layer neural network learning problems.  ",
    "The paper provides a novel generalization bound for the gradient flow equation related to the length of the optimization path. The bound is valid for loss function that locally satisfies \u0141ojasiewicz gradient inequality, which is applicable to different machine learning models such as underdetermined $\\ell_p$ linear regression, kernel regression, and overparameterized two-layer ReLU neural networks. Explicit derivations are provided for these three models to show that the length-based generalization bound is non-vacuous. ",
    "The authors study the connection between optimization and generalization for gradient flow (GF) on loss functions that satisfy a global version of the Lojasiewicz gradient inequality. Under this assumption, they prove convergence of GF to a global minimum and they find an upper bound on the optimization length \u2014 measured as the integral of the $\\ell_2-$norm of the gradient from time $t=0$ to the final time. This upper bound depends on the specific choice of the loss function and on the number of samples. With an additional assumption on the hypothesis class (encompassing, e.g., linear shallow networks, two-layer networks) the first result is used to derive an upper bound on the generalization gap. The bound depends on the choice of the loss function, its initial value, and the length of the optimisation path. This leads to the main result that shorter optimization paths induce smaller generalization gap. The authors apply this result to three models (underdetermined $\\ell_p$ linear regression, kernel regression, and overparametrized two-layer networks with ReLU activation) with a given target function. They compute non-asymptotic expressions for the generalization bounds at fixed ratio between sample size and ambient dimension, and show that in these cases the bounds are non-vacuous when the dimension increases. ",
    "In the paper, authors investigate the questions of adversarial robustness through the lens of spatial frequencies. In particular, contrary to a popular misconception, adversarial examples are not always related to high frequency components. Instead, they can encompass a wide range of spatial frequencies and are largely dataset dependent. The paper further studies adversarial training using different frequencies to better understand an accuracy vs robustness tradeoff. Carefully crafted experiments validate their findings and suggest a more effective approach for adversarial training.  ",
    "This paper presents a frequency-based understanding of adversarial examples in deep neural networks. The main observation is that the adversarial examples are neither in high-frequency or low-frequency components but dataset dependent. The authors also analyse the properties of training robust models with frequency constrains, and propose a frequency-based explanation for accuracy and robustness tradeoff.",
    "This paper intends to investigate and analyze the phenomena of adversarial examples through the perspective of Fourier Analyses. It claims three major contributions: 1) they claim that adversarial examples is neither high frequency nor low frequency. 2) they adapt adversarial training with Fourier Analyses 3) they provide a new framework to measure robustness",
    "This work explores adversraial robustness from a frequency perspective. While this had been done before, this work challenges the commonly held notions, that adversarial perturbations are mainly a high-frequency phenomenon. The authors provide insight that the frequency properties of adversarial examples are dependant on the underlying training dataset. Additionally, the impact of different frequency properties in adversarial training is explored.",
    "The paper shows that not all cases of heterophily are harmful for GNNs with aggregation operations. Based on a backpropagation analysis on an SGC-style GNN, it provides a new metric based on similarity matrix which considers the influence of both graph structure and input features. Observing that the diversification operation is able to address some harmful heterophily cases, it proposes the Adaptive Channel Mixing GNN framework which combines a high-pass filter, a low-pass filter and an identity channel.",
    "In this paper, the authors first analyze the potential drawbacks of existing heterophily metrics, then propose an aggregated heterophily metric aiming to better estimate the \"harmful\" heterophily and utilize diversification operation to address certain harmful heterophily cases. Based on the analysis, the authors propose an adaptive channel mixing (ACM) framework to improve GNN model performance. Several experiments have also been conducted to evaluate the proposed model.",
    "This paper proposes a new aggregation-based homophily metric for assessing the homophily of a graph. This metric complements the current metrics by considering unharmful heterophily cases. The second contribution is a new filterbank framework which uses the diversification operation to fight harmful heterophily information.",
    "The paper starts from studying the question of how heterophily affects the learning effectiveness of Graph Neural Networks on node classification tasks and posits that heterophily may not be always detrimental to the task. Following this observation, it proposes a new architecture, called Adaptive Channel Mixing, which appropriately applies aggregation, diversification and identity channels in each GNN layer in order to tackle harmful heterophily. According to the experimental results, the proposed architecture is successful.",
    "This paper introduces a deep RL approach combined with an equivariant model (to handle Euclidean symmetry) and local search heuristics (to improve a tour) to solve traveling salesman problems (TSP), in particular focusing on the generalizability of large-scale instances. The model consists of a graph neural network (GNN), a multi-layer perceptron (MLP), and an attention mechanism. In the training part, this model involves smoothed policy gradient, and stochastic curriculum learning to speed up the training and make the policy more generalizable. The experiments results show that the proposed approach significantly outperforms most learning-based solvers on large-scale randomly generated TSP and realistic TSP.",
    "The paper proposes a series of techniques and a new model to learn to solve the TSP using RL. First, a number of preprocessing steps are presented in order to transform a TSP instance into a standardized form. Then, a new encoder-decoder architecture is proposed, based on GNN, MLP and attention modules. The authors propose a modification of the policy gradient algorithms for training by replacing the value of the policy-generated solution by its value after applying a local search heuristic, and use the original value as a baseline. Finally they use a curriculum learning approach to increase the difficulty of the instances seen during training, the difficulty here being represented by increasing the size of the instances, within a given interval. Experimental results are presented on standard synthetic and realistic TSP instances of size up to 1000 nodes.  ",
    "This paper proposes a novel combination of policy gradient and local search algorithms for the traveling salesman problems (TSP). The main idea is to apply local search to tours generated by policy rollout and compute policy gradients using the (potentially) improved tour from local search. In addition to the algorithmic contribution, this paper also presents a collection of preprocessing steps to ensure problem instance features are equivalent. Empirical studies are provided on random TSP instances as well as those in TSPLIB. Finally, ablation studies show the importance for each component of the proposed algorithm.",
    "The paper employs equivariance properties and local search heuristics to derive a deep learning model capable of generalising to TSP instances of different sizes. The model constructs a tour, one city at a time, by learning a distribution (policy) over unvisited cities which is optimised via REINFORCE. The solution is further refined with a combination of different local search heuristics, and policy gradients are computed with respect to the final improved solution to smooth the loss landscape. The equivariance in TSP is mostly exploited during preprocessing steps\u2014where rotation, translation and reflection operations are applied to the coordinates of each city\u2014but is preserved by the model architecture which consists of a graph neural network and attention mechanisms. The model is trained with stochastic curriculum learning only on small TSP instances ($\\leq 50$ cities) but is shown to have competitive performance on problems with up to 1000 cities.",
    "The paper proposes a new federated learning algorithm called SDA-FL, which utilizes GANs to generate synthetic data for federated training on non-IID data. Specifically, each client pretrains a GAN to generate synthetic data and send them to the server. In each round, the server sends the global model and the synthetic data to the clients. Then, the clients update the label of the synthetic data and use both the local data and synthetic data to update the local model. The local models are sent to the server, which further averages the models and uses the averaged model to label the synthetic data. Experiments show that SDA-FL significantly outperforms the other federated learning approaches on non-IID data. The paper also studies the influence of different privacy budgets on the performance when applying differentially private GANs.",
    "Federated learning suffers from non-IIDness across clients. A line of previous works address the non-IID problem by data sharing which violates the privacy requirement. In this paper, the author propose SDA-FL. Compare to the most basic FedAvg, the additional components includes  - *Image synthesis with DP-GAN*. Before training classifier, each client trains a differentially private GAN to generate synthetic data, and upload these data to PS for future data-sharing.  - *Synthetic image labeling*. Similar to self-training, PS use local models to assign pseudo-labels to unlabeled data. These labels are updated during training, i.e., interplay between model training and synthetic dataset updating.  - *Mixup*. For each clients, private data and shared synthetic data are mixed to alleviate non-IIDness.  - *ServerUpdate*. Data sharing also makes it possible for the server to conduct gradient descent.   This paper also empirically evaluate their framework under supervised and semi-supervised learning settings. Moreover, this paper study the sensitivity to privacy budget and effect of synthetic data. ",
    "This paper focused on a classical federated learning setting where data was non-iid partitioned in different local servers, and came up with a method named SDA-FL, which combined GAN-generated data, differential privacy to both address the non-iid problem and keep local data privacy. The main contributions are: 1. Utilized differential private GAN-generated data to solve the non-iid and local data privacy problems; 2. Designed a label updating mechanism to increase the model performance; 3. Tested the algorithm on CIFAR-10, MNIST, fashion-MNIST to confirm the performance of the algorithm.",
    "This paper proposes a new framework for federated learning to resolve the non-IID issue by sharing differentially private synthetic data. Each client pretrains a local GAN to generate synthetic data and upload the data to the parameter server. To effectively use the synthetic data, the server performs pseudo labeling and shares this information with the clients along with the global model parameters, to let the local data, including both the real and synthetic data, approach an IID distribution. The interplay between model training and synthetic data updating improves the convergence of the local models and resolves the non-IID issue. ",
    "This paper proposes a loss function for training the base classifier for randomized smoothed classifiers. Specifically, the loss distinguishes between training examples with high prediction confidence and those with low confidence. Several empirical tricks are applied to design the loss function to optimize the performance. Experiments on MNIST and CIFAR-10 show that the proposed training method is superior to existing state-of-the-art randomized smoothed classifiers, especially when the radius r is large.",
    "This paper proposed new loss functions during the training of classifiers for certified robustness via randomized smoothing. The new loss function treat samples with different confidence level differently. The main idea is to prioritize samples with high confidence because it provides more additional certified radius when its confidence grows.",
    "This paper proposes CAT-RS which combines two novel losses for training base classifiers for randomized smoothing. The two novel losses aim at preserving clean accuracy for hard samples and improving the certified radius for easy samples. In term of ACR (average certified radius), the method achieves state-of-the-art on MNIST and CIFAR-10.",
    "The paper studies certified robustness via randomized smoothing (RS). RS has a fundamental accuracy and robustness tradeoff. The authors aim to enhance such tradeoff through a sample-wise control of robustness over the training samples. In particular, the authors investigate the correspondence between robustness and prediction confidence of smoothed classifiers and design a new loss function. The proposed method is evaluated on MNIST and CIFAR10.  ",
    "This paper proposes efficient packing methods for training sequences of BERT, such that the 50% of the padding tokens in the Wikipedia dataset is avoided to speed up the training. These methods include shortest-pack-first histogram-packing (SPFHP) and non-negative least-squares histogram-packing (NNLSHP) algorithms, which are shown to be straightforward to implement and have little impact on the performance. Empirical studies show that a near 2x speedup over the vanilla BERT training is achieved by the proposed methods. ",
    "This paper proposes two packing algorithms for bert pretraining, shortest-pack-first histogram-packing (SPFHP) and non-negative least-squares histogram-packing (NNLSHP). 2* speed was achieved under datasets such as Wikipedia for bert-large training.These packing algorithms packed Wikipedia\u2019s 16M sequences in 0.02s (SPFHP). Packing depths of from 1 to 16 were testified. This paper also has 20 pages near appendix telling about packing algorithms, packedBERT of model changes and hypermeter adjusting, and detailed experiments such as bin-packing algorithm comparison, scaling analysis and technical background on packing with some core codes attached as well.",
    "This paper profiles the training data of BERT and finds out opportunities to reduce padding thus saving computation. By packing multiple sequences into one fixed length sequence (two packing algorithms were used), the author shows that a BERT training speed-up of 2x can be achieved without loss of quality. The author also studies how to correspondingly change the modeling configuration and optimizer configurations to compensate the effective batch size increase due to the packing.",
    "The paper proposed to pack sequences instead of padding to reach the max sequence length for each sample for BERT pretraining. To achieve similar optimization results with the original training process, the proposed method modified positional embedding, additional attention masks and other optimization hyper-parameters. On the Wikipedia dataset, the proposed method can achieve 2x speedup while achieving similar training loss.  ",
    "This paper presents a novel algorithm called beam adaptive tree search (BATS) to enable the incorporation of search objectives that cannot be easily factorized. Unlike the regular Monte Carlo tree search algorithms that relies on a large number of playouts to update the value function, BATS relies on \"informed playout\", which is guided by the greedy decoding of the autoregressive models. To further constrain the search space, the paper also proposed a constrained node expansion criterion that gradually increases the lower limit of the node depth $d_{min}$, and allows for expanding $k$ nodes for each depth limit $d_{min}$.  Aside from the search algorithm, the paper also explored a couple of model changes to counteract the calibration issues, including two modified search objectives and using MRT-trained autoregressive models. Experiments show that while beam search performs better for the weaker models, BATS does improve the translation quality of the hypotheses when stronger MT models are used. Analysis on different beam size also show that unlike beam search, BATS can operate at large search budget without performance degradation under stronger models.",
    "The paper proposes an adaptive tree search algorithm for text generation. It uses an autoregressive model as the value network to produce the playout for each node. While decoding, the paper proposes a metric called max rank to address the shortcomings of utilizing the sum of token level log-probability. Results are conducted on several machine translation datasets, and the proposed method outperforms beam search in most cases.",
    "This paper proposes an adaptive tree search algorithm for NMT models. One advantage of this algorithm is that it does not make any assumptions about search objectives, and this enables the proposed algorithm to be applied on top of more general search objectives. In addition, it studies the issue of beam search bias and revisits some tricks to alleviate it as well as a new tricks. Combined with these tricks, the proposed algorithm delivers clear BLEU improvements over a strong baseline.  ",
    "**Summary**  This paper proposes an adaptive tree search algorithm BATS, an MCTS variant, for NMT that could optimize any desired objectives/metrics (e.g. BLEU). The algorithm values each internal node by scoring a greedy searched rollout (instead of that of authentic MCTS) with an autoregressive model, which avoids search biases caused by other heuristics (e.g., beam search would be biased towards shorter translations or incomplete partial generations). Plus, a new objective Max Rank is proposed with a better correlation with translation quality. Experiments show that BART works well in comparison with beam search, which is also shown to bound the progress of more robust modeling in NMT.    ",
    "This paper presents a model for detecting irregularities in images, such as would occur in manufacturing acceptance testing.  As a form of anomaly detection, the claims made are for a principled modeling approach and an adaptive algorithm quick to learn from just a few samples.   Based on \"energy based models\" for modeling data densities, the paper claims improvements to avoid the need for retraining for new tasks, such as, instead of synthesizing negative samples rom noise, using a more targeted method of \u201clearning from inpainting\u201d operation to learn anomalies.   ",
    "The paper proposes a framework for anomaly detection and localization that allows fast adaptation to new tasks.  Specifically, the authors propose an energy-based model (EBM) with an adaptive sparse coding layer directly trained with normal features of a target task.  A meta-learning process is followed to extract common knowledge across tasks enabling few shots adaptation.  Shrinkage functions, sparse coding with large receptive fields, and learning by inpainting are introduced to improve and accelerate the EBM training. ",
    "This paper proposes an image classification system, where a set of normal patterns are stored as a \"dictionary,\" and the degree of deviation is used as the anomaly score.    The overall architecture seems to feature a conventional deep encoder and a pattern matching module that compares the encoded latent vector against the pattern dictionary. The pattern matching is done by solving the lasso regression problem.   The authors propose a certain online learning approach, following existing few-shot learning methods, and also a synthetic sample generation approach using random perturbation combined with a gradient method. ",
    "The paper presents an anomaly detection algorithm that uses an EBM (Energy Based Model) to distinguish between 'normal' and 'anomaly'. This model generates pseudo-anomaly instances on-the-fly for each 'normal' instance and then learns to assign low energy to normal instances and high energy to pseudo-anomaly instances. The model is further designed to be able to adapt quickly (few 'normal' labeled examples) to new tasks.",
    "This paper addresses the problem of deriving the correct answer when contradicting examples are presented to the model. First, it introduces a dataset for the task. The dataset, ContraQA is built on SQuAD, and it contains contradicting contexts produced by humans and neural-models. Then, it presents a model for generating contradicting examples. The model, BART-FG, generates fake contexts by iteratively modifying and original input paragraph. The procedure starts by applying a constituency parsing to extract constituency spans from the input sentence. Then, it randomly masks some of these constituency spans, that are eventually fill by a BART model fine-tuned on Wikipedia dump. To study how QA models behave with contradicting examples, this work evaluates the performances in a scenario where the correct and the fake contexts are presented to the model. In order to make the QA system robust to fake contexts, it proposes a misinformation-aware framework that combines the score of the model with a trust score outputs by a fake detector, which is a transformer-based model trained to classify if a context is real or fake. The results show that under this setting, model performance decreases, and that the reduction can be mitigate by applying the fake detector model. Finally, it shows a comparison, between BART-FG and GPT-2, to identify which of the two can generate more impactful fake contexts for the QA model. ",
    "The work investigates closed-domain Question Answering under contradicting contexts by introducing a new task ContraQA\u2014an extension of SQuAD1.1\u2014which includes contradicting contexts for the SQuAD articles, produced by both humans and neural models. The work also proposes a neural framework, BART-FG, to automatically generate these contradicting contexts by iteratively modifying constituency spans on the original context. Finally, the work gives a brief analysis on how SOTA QA systems perform on the new task, ContraQA, and proposes a misinformation detecting system which when unified with a Machine Reader performs significantly better than SOTA systems over ContraQA.",
    "The authors studied how contradictory information affects the accuracy of QA systems.  They created a new dataset of ~10k from SQuAD with added contradictory paragraphs (context). The contradictory data was generated by two different ways. The authors employed Amazon Mechanical Turks raters to rewrite the original context. They also designed a BART-FG model to automatically produce such context by replacing spans with model generated value.   The authors also proposed a way to help QA systems avoid contradictory information. A RoBERTa-based model was used to classify a context into trustworthy or not, with an accuracy around 80%. The trustworthiness score is then used to weigh the final result, together with existing scores of quality/confidence.  Evaluation was done with the new dataset. It showed that 1) adding contradictory information hurts QA performance badly, 2) the RoBERTa-based classifier can help regain some of the loss, but not all of them. The authors also measured the effectiveness of contradictory information creation, where human takes the top place by producing the least altered context with largest effect on final outcome.  The authors promised to share the dataset and the source code / weights of the proposed models. They further discussed the potential ethical impact of releasing the data, arguing that it's net beneficial. ",
    "This paper releases a new dataset with human and machine generated contradictory contexts for QA pairs from SQuAD 1.1. Amazon Mechanical Turk Workers are shown a paragraph and are asked to make edits such that it contradicts the original paragraph with respect to elements such as time, outcome, purpose, location, etc. In addition, the authors fine tune BART on a collection of masked constituent parses of Wikipedia sentences and it is then trained to fill the mask with an alternative phrase.  To automatically generate contradictory contexts, the authors use this fine tuned the BART model on the masked constituency parse of paragraph sentences. A dataset of 10,000 paragraphs from SQuAD  are transformed (once by mechanical Turk workers, and the rest by three different transformations by the BART Model). The paper presents experiments on this dataset for the task of QA -- specifically, machine reading comprehension. In one experiment, the QA system is first trained to predict which of the 5 (1 real + 4 contradictory) is correct. Then an off-the-shelf span based passage reader returns spans as answers. In the second experiment, the performance of QA models is compared on the unmodified SQuAD dataset as well as a version where a distracting passage is also added to context (by randomly choosing a different passage). The authors experiment using BERT, ROBERTA and SPAN-BERT and report a drop in performance in both experimental settings. In addition experiments reveal that models return worse performance on the subset of the data created by human workers ( perhaps unsurprising). Additional studies on the nature of edits have also been presented.   Overall a well written and easy to read paper. However, I am not sure I am clear about the goals of the paper -- I elaborate further in the rest of the review.    ",
    "This paper frames cross-domain imitation learning as an optimal transport problem using the Gromov-Wasserstein distance. This problem is highly relevant to imitation learning settings where there is often substantial domain mismatch between action and state spaces, eg. a humanoid robot learning to walk from a human demonstrator. The paper introduces a reward function that can be optimised and proves that this is equivalent to minimising the Gromov-Wasserstein distance between state action occupancies of an agent and expert. Substantial discussion/ proofs are included to show that minimising the Gromov-Wasserstein distance is equivalent to recovering an optimal policy up to an isometry. This is both a blessing and a curse, as it allows for optimal policies to be recovered under extreme changes in domain or differences, but does mean that recovered policies could be entirely unsuitable due to isometry.   The paper is well written and concisely written, although does get excessively mathy at times, when a figure could be more helpful. Experimental results corroborate the proofs and propositions, and highlight the value of the proposed approach.   ",
    "This paper presents a method to transfer policies between different MDPs based on the minimization of Gromov-Wasserstein distance. This distance provides a pseudo-reward that can be used to learn via RL the optimal policy in the target MDP given an optimal policy in the original MDP. The method is optimal if the MDPs can be mapped into each other through an isometry, but works also empirically in other cases. ",
    "In this paper, the authors focus on a more general cross domain imitation learning problem where only expert demonstrations from one domain is available. To solve such a problem, the authors use the Gromov-Wasserstein distance to align and compare states between tasks from different domains and propose a Gromov-Wasserstein Imitation Learning (GWIL).  They also show theoretically the possibilities and limitations of GWIL. ",
    "A method is proposed for cross-domain imitation learning, without resorting to any form of correspondence. This is done using a Gromov-Wasserstein distance between policies (in practice, Euclidiean distances on collected state-action pairs,  within a given domain), which finds isometric transformations that best preserve distance measures, between the two domains. Given an imitation domain and an expert domain with example trajectories, a pseudo-reward is computed  based on the degree to which the distances from a state to its neighbors in the imitation domain, are preserved in the expert domain. Given these pseudo-rewards, as computed for collected episodes, SAC is used as an RL algorithm to optimize the policy.  The paper contributes both a theoretical analysis and experiments with:  U-maze, pendulum-to-cart-and-pole, and half-cheetah-to-fallen-walker. ",
    "This paper presents a hierarchical cross contrastive self-supervised learning framework for learning visual representation. This paper proposes to project the representations of an image and its augmented version to multiple latent spaces and also make predictions on each of the latent spaces.  A contrastive loss between the features of different projection levels is minimized to learn the parameters. Experiments on the image classification and detection benchmarks are evaluated. A comparison between important existing methods is also done in the paper. ",
    "In this paper, the authors proposed a Hierarchical Cross Contrastive Learning (HCCL) method for Self-supervised learning (SSL) of visual representation. The proposed method include a design of a hierarchical projection network that produces multi-level latent representations. A cross contrastive loss is also introduced to learn invariant visual representations. HCCL is validated on several downstream tasks including classification, segmentation and object detection.",
    "The authors propose an extension to the contrastive learning based representation learning approach. The proposed method, call Hierarchical Cross Contrastive Learning(HCCL), leverages the features in different levels and views for more consistent features over the standard CL using only the features of the final layers. The effectiveness is validated in classification, detection, segmentation, and few-shot learning tasks. ",
    "This manuscript proposed a new contrastive self-supervised learning approach (HCCL). Compared with exiting work such as BYOL and SimSiam, HCCL introduced (1) multiple hierarchical projectors and predictors; and (2) contrastive loss calculated across different layers of projectors. HCCL is empirically evaluated on several self-supervised learning benchmarks (e.g., iNat18, Place-205, and COCO instance seg, etc.) and achieves noticeable improvement compared with previous states of the art (e.g., SWAV, BYOL, SimSiam, and Barlow Twins). Additionally, ablation studies are provided to verify the significance of hierarchical projectors, cross contrastive loss, and higher learning rates of the predictor.",
    "This paper proposes a multi-agent deep reinforcement learning (DRL) method to compute general equilibria in economics. The main contribution is hence algorithmic. The method uses a combination of DRL, structured learning curricula, and suitable annealing of action space and of some penalty coefficients (which are useful to make some problems easier to solve, but distort the computed solution). The authors apply their method to an example of real-business-cycle model, which involve three types of agents: firms, consumers and a government. The problem is of Stackelberg (or leader-follower) type, with the government acting as a leader. Computing equilibria for such problems is generally very challenging. ",
    "This work investigates the use of Deep MARL in order to study economies. They propose and implement an RBC (economic market model) and propose a reward shaping schedule to bias agents into learning non-degenerate joint-strategies. In their setting, low-welfare equilria and provide a brief quantitative and qualitative analysis of discovered equilriba in open- and closed-economies. ",
    "This paper uses a multi-agent reinforcement learning algorithm to simulate an economic environment and solve the general equilibrium of the induced game. The authors propose to use a structured learning curriculum that runs only on GPUs. The authors conduct experiments to show that their algorithm converges fast and that the solution represents an epsilon Nash equilibrium.",
    "This paper proposed a deep reinforcement learning framework for finding dynamic general equilibrium, which is one of the most fundamental problems in economics. As the dynamic general equilibrium is a special case of the Markov game, this problem has also been recognized as a significant topic in machine learning. The proposed scheme is tested in a real-business-cycle model with 100 worker-consumers, 10 firms, and a government, the scale of which is much larger compared with the numerical examples in most related works.",
    "This paper proposes a novel defense against model extraction attacks. The proposed approach slows information leakage by asking all users to answer a puzzle before receiving the response to their query (proof-of-work). The difficulty of the puzzle allows to keep the computation overhead low for legitimate users, while rendering information leakage prohibitively expensive for attackers. The puzzle difficulty is calibrated based on an estimate of how much information each user has already acquired. This is based on PATE, a differential privacy metric. Experiments are performed on multiple datasets, opposing the proposed defense to a wide range of attacks, including adaptive adversaries.",
    "The paper discusses ML model extraction attacks while using APIs for accessing them on the public networks. Although some methods exist for preventing or making the attacks hard, all of them have substantial impacts on legitimate users\u2019 experience while using the system, including the slower models or lower accuracy in results. This paper proposed a method for dissuading the attacker by increasing the cost of the attack. Solving a puzzle for all users before getting the final response (POW) would be the solution noting that the difficulty will be increased if the system identifies any adverse behaviors. This method requires no modification of the victim model and can be applied by machine learning practitioners to guard their publicly exposed models against being easily stolen.",
    "This paper proposes a new defense to the model stealing problem that an attacker queries a supervised machine learning model service to have data labeled to use as training data and copy the functionality of the model. The proposed method is proactive defense that slows down the attacker in obtaining the labeled data, based on the information leakage estimator. The evaluation shows that existing attacks using out-of-distribution data can be slow down more than a regular user querying in-distribution data.",
    "This paper proposes a novel defense to prevent model stealing by requiring users to solve proof-of-work puzzles. The authors evaluate their method against different types of model extraction attacks. The results show that the defense will result in the attacker costing higher computational time (100x) than legitimate users (2x). ",
    "The paper describes the novel approach to generate high-resolution images in progressive manner. The approach is based on set of conditional flows that take the image generated from previous stage as conditioning factor and generate the image with the higher resolution. The quality of the method is compared to the reference approaches, mainly focusing on WaveletFlow as the most similar method.",
    "The paper proposes a multi-resolution variant of continuous normalizing flows for images. They show empirical results for image sizes upto 64 x 64 where they seem to be better than regular continuous normalizing flows. The key proposed benefit seems to be in number of parameters and training times.",
    "In this work, the authors propose a multi-resolution strategy for continuous normalizing flows. The proposed approach consists of a general wavelet based decomposition/downsampling where the transformation obeys some useful mathematical properties such as volume and range preservation. Empirical results indicate likelihood estimation performance better or on par with benchmarked methods. The proposed model also trains significantly faster with fewer parameters.",
    "This paper proposes a new architecture for continuous normalizing flows that explicitly models images at multiple resolutions. The authors achieve this by learning an unconditional distribution of coarse images and then learning conditional distributions at progressively finer resolutions, each with a continuous normalizing flow. In contrast to the typical \u201csqueeze\u201d layers used in normalizing flows, where the noise is only passed at the first layer, the proposed model injects noise at several resolutions (which has already proved successful with other generative models). The authors introduce a new (invertible) transformation to go from a coarse image to a finer image which preserves the range of the image while having unit determinant (implying the transformation leaves the log likelihood unchanged). The whole model is then trained via maximum likelihood.  The authors evaluate their method on standard image datasets and perform several ablations to test the contributions of their model.  The main contributions of the paper in my eyes are then: - The introduction of a new architecture and layer for learning multi resolution normalizing flows - Demonstration that the proposed model can be trained with limited computational resources even on fairly large scale datasets (such as Imagenet128) - Ablation studies evaluating the improvements from each aspect of the proposed model ",
    "This paper proposes a method to detect noisy labels given good representations (e.g., ones pre-trained by contrastive learning approaches).  The proposed noisy-label detection method uses  the neighborhood information defined by a good set of representations in two ways:   1) checks the noisy label consensuses of nearby representations  2) scores each instance by its likelihood of being clean and filters out a guaranteed percentage of instances with low scores as corrupted ones   The work provide definitions for good representation and further proves a worst-case error bound for the ranking-based method given a 'good enough' representation. It also provides empirical results for its proposed method. ",
    "This paper proposed a training-free solution by using only good representations to detect noisy labels. The author designed two detection methods of voting and ranking to filter instances that are likely to be corrupted. The major contribution is proposing a training-free solution to efficiently detect noisy labels, which is different from most current methods. Also, theoretical analysis is conducted on the worst-case error bound and the choice of K.",
    "The authors propose a training-free approach to detect samples with noisy labels by leveraging representations learned from pre-trained models. The models can be obtained by either supervised or self-supervised pre-training. The authors then argue that samples in the pre-trained manifold should be closer if they share the same clean label, therefore one can use (a) local voting or (b) ranking methods to detect samples with corrupted labels. Experiments on CIFAR10/100 show improvement over other learning-based approaches (CORES, CL, TracIn).",
    "The paper proposes a training-free instancewise noise label detection method. The main motivation of this paper is the observation that deep models generalize poorly because memorizing noisy labels in supervised training while using only representations may avoid this issue.  The authors suppose a good representation extractor is given and generate the initial soft labels based on the clusterability of representations using kNN. Followed by that,  they perform a local voting and global ranking-based scoring system to detect the corrupted labels. The main contribution of this paper is: It introduces a representation-based method instead of directly training a deep model on the corrupted data, which is more efficient and may avoid overfitting noisy labels.  ",
    "The paper proposes a method for computing the strongest adversarial perturbation on state observations of an RL agent from a specified set of perturbations. It relates perturbations on states to perturbations on policies. It poses a specific problem to this end, develops a solution, and establishes its optimality. ",
    "The paper studies evasion attacks in deep reinforcement learning (RL). More specifically, the paper considers a novel approach to performing evasion attacks based on two-component design --- director and actor modules, where the latter perturbs a given state based on the policy direction that the former specifies. Effectively, the search for an optimal attack is performed in the policy space, and since the policy space is typically more compact than the state space, the search is more efficient. The paper formally justifies its design choices, and experimentally validates the efficacy of the propose approach, showing that it yields significant improvements compared to the state-of-the-art methods.  ",
    "The paper introduces a novel algorithm to find the optimal evasion attack against RL in scenarios where the agent's policy is known. The key idea is to only learn the aspect of problem depending on the environment and is unknown through a clever decomposition. The algorithm shows promising empirical results.",
    "The paper proposes a method to craft stronger and more efficient attacks on state observation of the RL agent.  Here, the 'strongest' attacks refer to the attacks that minimize the reward the most. An 'efficient' attacker can craft such attacks using the least computational resources. In the work of (Zhang et al., 2021), the attacking strategy is described by a mapping from the state space of the underlying MDP problem to the same space. The agent observes the falsified states rather than the actual ones and takes actions based on the observed states. This misinformation eventually tricks the agent into taking a different action. In this paper, the authors argue that instead of finding the mapping from the state space to the same space, the attacker can first find the mapping from the state space to the action space that generates the least accumulated rewards to the agent. The 'strongest' attacks on the state observation can then be crafted based on the mapping found. Since in many deep RL applications, the state space is much larger than the action space. Hence, finding the mapping from the state space to the action space is more efficient than finding the one from the state space to the state space.",
    "The paper proposes Interior Policy Differentiation, a variant of Interior Point Method, for learning diverse policies in RL. The paper uses the empirical Wasserstein distance  to measure the difference between policies, then formulates the novel policy generation problem as a constrained optimization problem. However, the novelty of the paper is limited and the empirical evaluation is not convincing to make it pass the bar of ICLR 2022. ",
    "The paper explores a gradient-free constrained optimization framework for generating diverse policies. Its main contributions are: (i) a computationally light metric to measure the diversity of a policy with respect to an existing set of policies, based on the Wasserstein metric W2; (ii) a practical algorithm with instant feedback at every timestep, inspired by constrained optimization to generate diverse policies. Experiments on continuous benchmarks show that the proposed algorithm, IPD, can generate diverse as well as well-performing policies, and outperform competitors relying on multi-objective optimization.",
    "The authors describe an approach to regularise policy iteration methods towards regions of novel policies. They propose that constraint optimisation is superior to regularised objective functions. They attempt to to derive the algorithm form theoretical principles and demonstrate its superiority on a couple of artificial RL experiments. ",
    "The paper aims at enabling the learning algorithms with the capacity of solving the task with multiple solutions. The paper introduces a new metric to evaluate the difference between policies. It also proposes a practical novel policy-seeking algorithm, derived from the interior point method in the constrained optimization literature. The algorithm is evaluated on multiple mujoco tasks.",
    "This paper presents a deep neural net-based dereverberation algorithm that uses both audio and video modalities. Based on the observation that a visual scene captured by a camera conveys information that is related to room characteristics, the authors propose a visually informed audio dereverberation method that aims to extract clean, anechoic speech from reverberant speech. In doing so, they first construct a large audio-visual dataset synthesized using a 3D simulator for real-world scanned environments and LibriSpeech data. They then train deep neural networks that take as inputs both visual data (RGB and depth images) and audio data (reverberant speech), and output clean speech. When training, two types of losses - one for clean speech spectrogram estimation and the other for reverb-visual matching - are used. Through the experiments with several downstream tasks for speech, they showed that the proposed audio-visual dererberation method outperforms the baseline models, both for synthetic and real-world test data.",
    "This paper examines an audio-visual approach for dereverberation, where dereverberation of speech is conditioned on RGB and depth images (either field-of-view or panoramic). It proposes a dataset for this task based on real-world 3D scans of homes, using Librispeech data. Real data is also used The model is based on a U-Net conditioned on embeddings extracted by a \"visual acoustics\" network doing direct spectrogram prediction. The method is evaluated using PESQ, WER for speech recognition, and EER for speaker verification on synthetic and real data. The audio-visual method is found to perform marginally better than an audio-only version of the model. The audio-only version of the model outperforms several baselines from the literature on synthetic data, with mixed results on real data.",
    "In this paper, the authors introduce a novel audio-visual dereverberation approach. They propose a Visually-Informed Dereverberation of Audio (VIDA) model for dereverberation. The authors also create synthetic/simulated datasets and real-world data for experimentation. Finally, they show the impact of the proposed VIDA model on several speech tasks including, recognition, enhancement, and speaker verification. The results are encouraging. The main contribution of this work is the use of visual information as an auxiliary input for dereverberation.     ",
    "This paper describes an audio de-reverberation method which integrates (panoramic, rgb+depth map) visual input with a spectrogram U-Net to estimate a de-reverberated spectrogram and recover the original clean signal. The proposed method is compared to several baseline (audio-only) de-reverberation methods on speech enhancement, recognition, and speaker verification problems using both synthetic and real data. Several ablations of the proposed method are compared, along with some quantitative error analysis investigating the effects of distance and environment. The proposed method appears to consistently improve on speech recognition and speaker verification, and perform about on par with prior work on speech enhancement (as measured by PESQ).  ",
    "The submission proposed an effective approach to allow pre-trained transformer-based language models to extrapolate beyond the maximum length used in training, which potentially reduces the training time as extrapolation is empirically guaranteed. The proposed method adds fixed biases to the dot-product values between queries and keys that linearly decays w.r.t. the gap between two positions. Empirically, the proposed method indeed successfully allows pre-trained models to be evaluated on sequences that are multiple times longer than the training ones without significant loss.",
    "This paper investigates the extrapolation capability of transformer-based language models. The authors observed that existing positional encoding methods (e.g., sinusoidal embedding, relative positional embedding) fail to generalize to longer sequences in language modeling tasks. Therefore, they introduce a new positional encoding method called ALiBi, which adds temporal bias to the multi-head attention to penalize attention score proportional to token distances. Experimental results show that ALiBi has significantly stronger extrapolation capability compared to other positional encoding methods.",
    "This paper studies input length extrapolation for Transformer language models; i.e., how Transformer LMs perform on test sequences that are longer than training sequences. The paper finds that how positions are encoded plays a crucial role for input length extrapolation. Models with sinusoidal and rotary position embeddings do not extrapolate well, while T5\u2019s position-dependent attention mechanism (dubbed T5 bias) enables better extrapolation. The paper then proposes ALiBi, another attention mechanism that also allows extrapolation while being computationally more efficient than T5 bias. These results are empirically confirmed on two datasets.",
    "The paper addresses the extrapolation problem where a test sequence longer than training sequences is given and proposes Attention with Linear Biases (ALiBi) that adds a penalty linear to the distance between a query and a key to the attention scores. ALiBi shows remarkable input length extrapolation ability while computationally efficient with almost marginal overhead compared to the standard transformer. Moreover, ALiBi does not induce any additional parameters and generalizes well to a billion scale language model.",
    "In the standard online learning model, the aim of the learning algorithm is to minimize its cumulative regret, defined by the difference in cumulative losses between the algorithm and the best decision taken with the benefit of insight in some reference set. In the generalized model of \u201cmulti-objective\u201d online learning, the feedback is no longer a single scalar, but a vector of losses, each defined for a distinct objective. The performance of the learning algorithm is often defined in terms of \u201cPareto regret\u201d, for which each instantaneous regret is captured by the notion of Pareto Suboptimality Gap (PSG). Although multi-objective online learning has been studied in the (possibly contextual and linear) bandit setting, many questions remain open. Notably, this paper focuses on the full-information setting where a vector-valued loss function is supplied at the end of each round. Based on the Online Mirror Descent (OMD) paradigm, two versions of multi-objective OMD are provided and analyzed for the dynamic version of Pareto regret (the static version being left as an open issue). Comparative experiments for both versions are performed on several benchmarks. ",
    "The paper formulates a novel framework for multi-objective online convex optimization. The novel framework, similarly to the single-objective online convex optimization framework, can be viewed as a two players repeated game where at each round the online learner selects a point $x_t$ and the (possibly adversarial) environment selects a vector valued loss function $F_t (\\cdot )$. To extend the notion of regret to the multi-objective setting at each round the suboptimality of $x_t$ is measured using the Pareto suboptimality gap (PSG). Two algorithms (OMMD-I and OMMD-II) which upper bound the extension of the dynamic regret in the multi-objective setting are designed. The two algorithms can be viewed as extensions of the min-norm method for offline multi-objective optimization in the online setting. In both algorithms a composite gradient, which is a convex combination of the descent directions for every objective, is calculated. This composite gradient is used to select, together with a Bregman reguralization, the descent direction and consequently the point $x_{t+1}$. The main difference between the two algorithms OMMD-I and OMMD-II is that in the latter the composition of the descent directions in two consecutive rounds will possibly be \"more similar\" (due to the regularization term $|| \\lambda - \\lambda_{t-1}||_1$). ",
    "1. This paper introduces the problem of multi-objective online convex optimization. 2. The authors propose to use PSG as the performance metric, and show that it is related to the dynamic regret.  3. The authors develop algorithms that enjoy sublinear multi-objective regret, and also conduct experiments to show the effectiveness of the proposed methods. ",
    "The paper studies the problem of multi-objective optimization in an online setting, where the objective functions are time-varying. An algorithm is proposed to solve this problem. The algorithm queries the gradient of all objective functions, and returns a convex combination of these gradients as the input to the mirror descent algorithm. The performance of the algorithm is measured compared to a sequence of Pareto optimal points, where a single component of the loss vector cannot be improved without causing harm to the other components. Under some set of assumptions, Theorem 1 provides an upper bound on the dynamic regret of the algorithm. ",
    "The key idea proposed in this paper is to use generative replay as negative samples to improve performance in class-incremental scenarios of continual learning. The authors argue that samples from a generative model have a lot of artefacts due to challenges in training/adapting a low resource generative model. Hence, its use as a positive sample for future experiences fails. But, these imperfect samples can still be relied on as negative samples for classes being trained in the current experience to prevent \"learning in isolation\" problems. The proposed approach is compared to positive replay, negative replay and no-replay baselines for two complex datasets in both NC and NIC scenarios.",
    "In Continual Learning (CL) scenarios, storing data from previous experience is helpful to mitigate catastrophic forgetting. However, privacy issues or storage overhead makes replay methods impractical. Aware of this problem, generative models have been proposed in previous work to generate data that represent previous experiences. Still, these methods suffer from low performance because of the continual training of the generating model and/or the generation of high dimensionality data. In this paper, the authors propose Generative Negative Replay. Instead of using the generated data as a positive example of previous classes, they used it as a negative example for the classes present in the current experience. While training with the negative examples, the authors propose to freeze the weights of the classification head corresponding to the previous classes, similar to what happens in CWR. This solution is particularly relevant in situations where there are not as many classes from experience.",
    "This paper proposes a novel learning scheme for generative replay methods in continual learning. Different from the original generative replay method, the generated examples are treated as negative examples for new classes. Experimental results on CORe50 and ImageNet-1000 demonstrate the effectiveness of the proposed method.",
    "The paper proposes a method to make generative replay for continual more effective even if generated data quality is not perfect. The method uses replayed data only as negative samples for current tasks and not as training samples to remember. They apply their method on one model on Core50 and ImageNet data. The replay process is realized in the latent space.",
    "The authors consider the problem of inductive graph partitioning, which they formulate as clustering or partitioning multiple snapshots of a time-evolving graph for which we have no node correspondence. In other words, we cannot link the nodes in snapshot $t$ to those in snapshot $t-1$, which prevents incremental or evolutionary clustering algorithms from being applied. The propose a complicated dual graph neural network (GNN) architecture for this problem setting and demonstrate potentially good clustering accuracy with low computation time on simulated and real networks.",
    "The authors propose an inductive graph partitioning framework across multiple evolving graph snapshots to alleviate the NP-hard challenge. It first conducts the offline training of a dual graph neural network on historical snapshots to capture the structural properties of a system. The trained model is then generalized to newly generated snapshots for fast high-quality online GP without additional optimization, where a better trade-off between quality and efficiency is achieved. ",
    "This paper considers the problem of solving the graph partitioning problem repeatedly over many different graphs. Graphs are sampled i.i.d. from an unknown but fixed distribution and the goal of the algorithm is to solve the GP problem on each of the graphs. There are two quantities that are opposing; efficiency (on one hand we can solve an NP-hard problem each time but would be prohibitively time consuming) and quality (on the other hand we can generalize from the learnings on the other graph since they are related via the i.i.d. distribution). This paper proposes a NN architecture that uses a subset of the graphs in the family to learn an embedding, and then derives the solution to the other instances by using this embedding via a matrix multiplication. Using a number of simulated and real-world datasets they show that this method works well empirically.",
    "In this work the authors focus on an important problem, building an inductive framework for graph partitioning. This is a major problem with the potential of improving the performance of various classic transductive  algorithms for graph partitioning, both in terms of output quality, but also in terms of speed when a new snapshot  of a system needs to be partitioned into communities. This is a recent line of research, see, e.g., Nazi et al. 2019 \"GAP: Generalizable Approximate Graph Partitioning Framework\".  The proposed framework can address snapshots with differing number of nodes, by projecting them down to coarsened versions of the network. There are two versions of the framework, based on normalized cut and modularity objectives respectively. The framework can be potentially used with other measures as well. A nice idea is to leverage the unsupervised communities extracted from modularity optimization, or spectral algorithms through a dual GNN structure, that can then be used to partition fast unseen instances.  ",
    "The authors present a variational-autoencoder-based model for learning and generating graph structures. In particular, they propose a multiresolution graph network (MGN) that encodes a given graph in a hierarchical manner, i.e., at different levels of resolution.  Training the nodes of the coarsened graphs as latents of a variational auto-encoder allows for sampling a new graph in a bottom-up manner, i.e., at increasingly higher resolution.  The main contribution of this work consists of developing the framework of MGNs and demonstrating that they can be trained as hierarchical variational autoencoders, which yields the multiresolution graph variational autoencoders (MG-VAEs). The MG-VAEs represent generative models that allow for generating graphs in a multiresolution and equivariant manner. The authors evaluate these models in a range of different settings, from unsupervised representation learning, over link prediction on citation graphs, to the generation of molecules or graph-based image generation. ",
    "This study presents a multi-scale graph VAE with hierarchical graph coarsening. The Gumbel-max trick is employed to generate learnable hard partition for clustering, and permutation equivariant tensor operations are used (Kondor et al., 2018) to construct the group equivariance network. The authos find that the proposed framework exhibits competitive performance in graph generation, molecular generation, molecular representation learning, link prediction and graph-based image generation. Given the applicability of this framework, this proposed framework may be interesting to the graph generation community, and this paper is well-written.",
    "This submission considers a multiresolution graph auto-encoder framework which is equivariant with respect to node permutation. Contrary to prior work on multi-scale graph generation, in this work the hierarchical structure in the encoder is learned through differentiable graph coarsening and is encouraged to produce balanced partitions of the graph. In the decoder, the graph is generated hierarchically and at each level, local adjacency matrices need to be predicted, rather than directly predicting the adjacency matrix of the full graph.  The method is evaluated on molecular generation, community graph generation,  and citation network generation in the main paper. The supplementary materials contains additional experiments on link prediction, unsupervised and supervised molecular property predictions, and graph-based image generation.   ",
    "This paper proposes Multiresolution Equivariant Graph Variational Autoen-coders (MGVAE) which can learn and generate graphs in a multiresolution and equivariant fashion. Higher order message passing is used to encode the graph while maintaining learning mutually exclusive clusters so that coarsening into a lower resolution, thus creating a hierarchy of latent distributions. The model also maintain an end-to-end permutation equivariant with respect to node ordering. Their experimental results show that MGVAE achieves competitive re- sults with several generative tasks and graph link prediction etc.",
    "The paper proposes a framework for nonlinear ICA with that restriction that the mixing function is a volume preserving transformation. The authors prove that given this restriction as well as a few other conditions the sources are identifiable. The model set up is very similar to the one used in Sorrenson et al.'s work \"Disentanglement by nonlinear ica with general incompressible-flow networks (gin)\": A real NVP model is made volume preserving by a slight modification of the flow map and this flow is used to learn the mixing function. The sources are assumed conditional independent given an auxiliary variable $u$, which are the labels of classes in their experiments. The mixing function is learned by maximizing the Gaussian likelihood of the reconstruction sources, which is also conditionally independent given $u$.  The authors demonstrate empirically that some of the conditions of their identifiability proof might not be necessary because the sources can still be reconstructed empirically although the condition is not satisfied. Hence, identifiability might even hold true for an even larger class of problems. They also compare their method to iVAE and show that their framework can identify the true sources of generated data much better than this baseline. Furthermore, they apply the framework to MNIST and can identify a few important source variables explaining most of the variance of the dataset.",
    "[Sorrenson et al 2020] proposed to do nonlinear ICA via volume preserving mixing functions, when a variable u is observed that makes the latent variables conditionally independent. Via maximum likelihood optimization, the ICA model uses a volume-preserving encoder and then maximises a latent distribution, which is a factorized Gaussian conditional on the observed variable u.  The submitted paper does a theoretical identifiability analysis on that procedure. It assumes that the data is generated by an independent distribution, given observed u, then mixed by a volume-preserving mixing function. Furthermore, it assumes that both the mixer and the encoders are twice differentiable, there exist two observed u variables, u^1 and u^2 such that that the two resulting distributions of encoded latent variables have the same mean and that the set of ratios of the two standard deviations for each variable is distinct. If these assumptions hold, the paper proves that the original sources are identifiable up to a permutation and dimension-wise diffeomorphism.  The authors do three experiments: 2D mixture of Gaussians, triangle images and MNIST. For the first two, the authors quantitatively estimate the source identification and for all datasets, qualitative results on identification are given.",
    "In this work, the authors propose a framework for nonlinear ICA, in which the mixing function is a volume-preserving transformation, and the conditions for the sources can be relaxed compared to some prior works. The authors prove the identifiability of the proposed framework and implement the framework by volume-preserving Flow-based models. Numerical experiments on both synthetic and real data are performed to corroborate the theoretical results.",
    "The authors propose to use volume preserving transformation to solve the disentanglement problem in latent variable models such as ICA. The authors have explained that in literature that ICA can be expressed as a factorial member of the exponential family, however, this arrives at a solution which is not identifiable. The authors have explained that there are two ways of achieving disentanglement, this could be done by either (1) restricting the sources or (2) restricting the function f.   Interestingly that authors have proposed to use a volume-preserving transformation typically found in normalizing flows to be able obtain identifiability. There is a volume preserving transformation from the sources to the mixed signal which represents the generative process. Then there is a volume preserving transformation from the mixed signal to the latent space (which is not the source signal). Then a factorial multivariaate Gaussian is used to identify the conditional independence of each source signal.  In the classical ICA problem setup, the dataset does not contain any labels. While in this setting the input dataset for ICA appears to contain labels (u?).",
    "The manuscript proposes a novel convolutional operator dubbed BankGCN, that given a node input signal, first projects it in different subspaces using a group of projection functions (one for each subspace), and then applies to each projection an adaptive filter.  As projection functions, the authors use Linear projections. The model was tested on the Graph classification task.",
    "The authors introduce BankGCN, a graph convolutional network that learns (chebyshev) polynomial filters over the graph. BankGCN includes an initial subspace projection, and a cosine similarity regularization to encourage diverse filters. BankGCN is compared to a number of other graph networks on standard whole graph classification tasks.  The authors claim that most architectures of MPGCNs are limited in that they (1) focus on low frequency information and (2) lack a proper sharing scheme between filters, and that BankGCN addresses these two issues. ",
    "This paper proposes BankGCN, which simplifies spectral graph neural networks by utilizing an adaptive filter bank to extend the capabilities of GCNs beyond low-pass features. Compared to existing spectral graph convolutional networks, which have numerous free parameters, the proposed method reduces parameters by sharing learnable filters. The empirical study validates that BankGCN shows good performance on the graph classification task.",
    "This paper proposes a new variant of GCN model, namely BankGCN, based on a novel graph convolutional operator. The main idea of BankGCN is to the sharing scheme among different filters to adaptively capture information from different frequencies. Through detailed discussion, BankGCN is claimed to be equivalent to the learnable message passing mechanism across K-hop neighborhood. Experiments on graph classification tasks over a collection of graph benchmark datasets demonstrate that BankGCN could outperform many state-of-the-art spectral-based GNNs.",
    "The paper proposes a leave-one-out kNN supervised method for pre-training on large-scale datasets.  The paper claims such a method will benefit downstream tasks by NOT enforcing each class, whether visually similar or not, to cluster together. Instead, each sample just needs to be close to the nearest K neighbors.  In this way, the model will not be overfitted to pre-train datasets. To implement this method, the paper uses a loss of weighted soft kNN loss with cosine distance and softmax normalization. To solve the large search space and feature update problem of kNN, the paper uses ideas from MoCo, utilizing a memory queue as a feature bank to store features of previous N samples and First-in-first-out to update the memory queue. To solve the convergence issue, the paper uses ideas from SimCLR and utilizes MLP instead of the linear layer to project features into a more compact space.   The proposed is tested on a standard fine-tuning setting, using ImageNet as the up-stream pre-training dataset and multiple fine-grained datasets as down-stream fine-tuning datasets. The proposed method is compared with both the supervised and self-supervised methods,  ",
    "The paper proposes a new supervised method for visual pretraining by leveraging human labels. To avoid the intra-class instances to collapse into a single vector, the method implicitly encourages sub-clusters to occur within a category by a leave-one-out k-nearest neighbor classification loss. Compared with contrastive learning and several supervised baselines, the approach shows improved performance on several downstream tasks on car/flower/pets classifications, etc.",
    "The paper presents an interesting approach that expands the recent success of self-supervised pre-training with *instance discrimination* to supervised pre-training. The key insight is to have each class being represented not just by a single weight vector, but in a non-parametric fashion via KNN lookup from a MoCo memory bank. The paper avoids to compare the results for direct, supervised learning, but rather focuses on transfer learning to downstream tasks -- to me this has some empirical novelty. The transfer learning experiments are done extensively, including many settings for quantitative comparisons and qualitative visualizations. ",
    "This paper proposes LOOK, a new supervised pre-training method which can maintain intra-class semantic differences for better transferability to downstream tasks. Specifically, LOOK proposes to use a KNN classifier instead of the simple linear classifier for the pre-training task. Experiments show that LOOK outperforms previous supervised and unsupervised pre-training methods.",
    "This paper proposes a pipeline to induce geometrical deformations due to expressions on a person\u2019s 3D face. The existing works either uses single image based 3D reconstruction that manifest the expression present in image or learn a neural representation of the deformation (latent code) which can be used to transfer the deformation due to expression from one face to other. This paper uses direct expression parameters and action units instead of a latent code and predict the deformation on 3D face for an expression instead of manifesting it from image (unlike reconstruction methods). To this end, the authors use an existing robust single image based 3D face deformation method (Chen et al.) to initialise the texture map and geometry as a displacement map of a 3D face (using Basel Face Model) from an image.  Because there is no ground truth of the new expression, they train it using adversarial loss. They produce the deformation using the Action Units(AU) as input and tries to produce those AU from the output displacement map. For rendering, the method uses the Neural Texture which is trained with the texture map produced by the Chen et al. The rendering has two components. One is the coarse level rendering which utilises the shape and expression parameters of the Basel Face model and the detail rendering consisting of the information of the displacement map due to the AU obtained through this method. Both are combined to get the final appearance.  They compared the result with DECA (Siggraph 21) which is a FLAME 3D model based method and shows that the identity, shape and expression rendering is better in the proposed method. ",
    "They propose FaceDet3D to generate facial expressions with details. To do this, they propose a Detail Hallucination Network to generate the target detail map from the source detail map along with Expression Adversarial Loss [1] and Superresolution Losses. Then they propose a Rendering Network. In addition to Photometric Loss and Expression Adversarial Loss [1],  they add Augmented Wrinkle Loss and Detailed Shading Loss. The result is an image with target expression containing details (mainly wrinkles), comparison with DECA (a previous work) shows they improve FID and FaceID by large margin.  [1] Conditional Image Synthesis With Auxiliary Classifier GANs ",
    "The paper proposes to improve the quality of the 3D reconstructed faces by taking into account the facial expression. Using a set of generative losses some of the details are recovered or hallucinated. The visual examples provided confirm the improvements, however better numerical evaluations and comparisons are required.",
    "1. This paper proposes a new method FaceDet3D that can generate geometric facial details from a single image given any desired target expression. The method contains two components: first pass the input image to the Detail Hallucination Network to infer the geometric facial details of the subject as there expression changes; then a rendering network is used to generate the detailed rendering result using the 3D face geometry information.  2. The two component models are trained separately using a large scale in-the-wild images and a small video dataset. During the training of the rendering network, the novel Augmented Wrinkle Loss and Detailed Shading Loss were used.  3. The authors further evaluated the method and compared it to DECA to show that the proposed method could generate plausible facial details for any desired expressions and could render the result photo-realistically. 4. Ablation studies were also done to prove the effectiveness of the components in the proposed method. ",
    "This paper proposes a new model ADVAE, which uses a sequence of latent variables which are constructed using cross-attention, which are then used to condition the inference model. The findings show that certain latent variables correlated with different syntactic roles (measured using a dependency parser).  The work claims that the latent variables, in this case, are able to disentangle content effectively, which I am inclined to agree with, however, I feel that the experimental setup is lacking to solidly support this hypothesis (which I detail in the \u201ccons\u201d and \u201cquestions\u201d section). ",
    "The paper proposes a method for unsupervised disentanglement of text components and shows its ability to identify semantic roles. To this end, a neural network is trained to compress the input into a fixed number of independent latent variables which are regularized to be standard Gaussians via the VAE framework. The inference network consists of a Transformer encoder-decoder network, where the decoder inputs correspond to the latent variables, which cross-attend to the outputs of the Transformer encoder, i.e., the encoded sentence. The idea behind this architecture is that attention-based seq2seq architectures align source and target sequences with each other.  The model is evaluated on disentanglement of semantic roles. To this end, they investigate how resampling of individual latent variables impacts the semantic roles in the text generated by the decoder, and how syntactic roles are aggregated into latent vectors via attention. They find that their proposed architecture is more successful at disentangling semantic roles into the latent variables than standard VAEs.",
    "This paper propose a framework to obtain the disentanglement of syntactic roles as latent variables for sentence representations. The model is an attention-driven VAE which maps syntactic roles to separate latent variables using an encoder-decoder framework. In the second part of the paper, the authors introduce an evaluation protocol to quantify disentanglement between latent variables and spans both in the encoder and in the decoder, which includes syntactic role extraction, latent variable influence on decoder, encoder influence on latent variables and disentanglement metrics.",
    "## Summary  - This paper proposes a probabilistic model called Attention-Driven Variational Autoencoder (ADVAE). This model is another instance of $\\beta$-VAE whose encoder and encoders are composed of Transformers rather than previous neural architectures such as RNN. - The authors aim to disentangle the semantics of latent variables according to some syntactic roles (e.g., nouns and verbs) defined by syntax. To achieve this goal, they suggest employing the combination of Transformer and the existing $\\beta$-VAE framework which is known to be effective for disentangling the role of each latent variable in VAE. - Moreover, this work presents a new way of quantifying syntactic disentanglement between latent variables, relying on the information obtained from the attention matrices of the Transformer architecture. - The experiments show that the proposed method is quantitatively better than the normal VAE, and that swapping the value of a specific latent variable can impact the generation of the target word (decided by the syntactic role of the latent variable we choose).",
    "This paper introduces a new exploration method for cooperative multi-agent reinforcement learning (MARL), which utilizes influence-based regularization and curiosity-driven incentives to encourage coordinated and diverse exploration. This paper formulates the dissimilarity between other agents' behaviors and their one-step TD targets as the influence metric and extends the random network distillation (RND) to the multi-agent setting for crafting a \"novelty\" metric. Empirical results show that this method achieves improved performances on a comprehensive set of challenging tasks.",
    "This paper introduces the idea of estimating the influence an agent has on other agents' actions, in order to achieve better coordination among agents. An agent is chosen as the influencer, which estimates the gap between other agents' actions and their targets given its current action. The influencer is encouraged to minimize this gap to lead other agents closer to their target returns. The paper also proposes to learn an intrinsic reward for each agent to encourage agents to learn more diverse team behaviour. The proposed method was tested in a wide range of multi-agent tasks. ",
    "This paper introduces two techniques for Centralized Training with Decentralized Execution (CTDE) MARL. Specifically: (1) It proposes an \"influence\" training objective by which one agent is encouraged to help the other agents reach target returns. (2) It introduces intrinsic motivation and intrinsic cost terms aimed at encouraging efficient joint exploration of the Markov game. It then goes on to give several empirical comparisons with baselines, showing the utility of the approach in Starcraft Multi-Agent Challenge (SMAC), two sparse reward settings, Multi-Agent Particle Environments, and OpenAI Gym continuous control environments. It also performs an ablation study in (SMAC), demonstrating the usefulness of each component of the proposed method.",
    "This paper is situated in the context of CTDE for cooperative MARL. The paper proposes new forms of intrinsic rewards to improve multi-agent exploration and a policy regularization term for an agent to have more influence over others. Experiments were conducted on existing benchmarks, such as StarCraft micromanagement and scenarios in the multi-agent particle environment, and two sparse-reward gridworld settings designed by the authors. The proposed method was compared with selected MARL baselines and ablations.",
    "This paper tackles the challenging model of editing a potentially very large pre-trained model in a way that is specific (local) yet comprehensive (general). Their method, called MEND, take as input the decomposed, information-rich gradient from fine-tuning to learn the parameters for their meta-networks that subsequently perform the updates. The authors show that it works better than existing model editing techniques on large models like GPT-Neo, GPT-J, T5-XL, T5-XXL, and some smaller models like BERT-base, and distilGPT-2.",
    "While large pre-trained nlp models have achieved great performance on a variety of downstream tasks, the largest of these models still make errors. This paper deals with the problem of enabling both developers and end users of such models to correct inaccurate outputs while leaving the model otherwise intact. If presented with only a single problematic input and new desired output, fine-tuning approaches tend to overfit. To enable easy post-hoc editing at scale, this paper proposes Model Editor Networks with Gradient Decomposition (MEND), a collection of small auxiliary editing networks that use a single desired input-output pair to make fast, local edits to a pre-trained model.   The approach trains lightweight model editor networks to produce edits to a pre-trained model\u2019s weights when provided with the standard fine-tuning gradient of a given correction as input, leveraging the gradient as an information-rich starting point for editing.   MEND leverages the fact that gradients with respect to the fully-connected layers in neural networks are rank-1, enabling a parameter-efficient architecture that represents this gradient transform.  It provides experiments with T5, GPT, BERT, and BART models showing that MEND is the only approach to model editing that produces effective edits for models with tens of millions to over 10 billion parameters.",
    "A fast model editing method is proposed in this paper to edit pre-trained models at scale. The core component is a Model Editor Networks with Gradient Decomposition (MEND). The paper claims that the MEND method has reliability, locality, generality. MEND is empirically validated on some curated datasets.",
    "This paper studies the problem of \"model editing\" - altering the model predictions on local examples without affecting the global behavior.  Authors tackle the challenge of editing very large models with billions of parameters, such as T5 or GPT-J, where editing is particularly important, as it is impractical to re-train such models from scratch to correct every mistake.  To address this challenge, authors propose MEND - a novel model editing method that differs from prior art in three ways: - it does not require computing higher-order gradients (and hence, requires less compute/memory) - it can be trained for a given model without the need to change the model parameters (and hence, can be applied to pre-existing models) - it has better asymptotic time & memory complexity in terms of model size (and hence can be used for very large models) ",
    "This paper presents a compositional physics-aware neural network (FINN) for learning spatiotemporal advection-diffusion processes. It claims that the FINN outperforms pure machine learning and other state-of-the-art physics-aware models in all cases\u2014often even by multiple orders of magnitude. However, the design of the network depends too much on the form of the equation, which leads to a very narrow application of the method.",
    "In this work, the authors propose the finite volume neural network to solve advection-diffusion partial differential equations. The authors define a flux kernel as the sum of sub-kernel f_i on each element. And the authors define specific modules \\phi_D, \\phi_A, \\phi_N according to the form of the advection-diffusion equation. The model requires very few parameters to achieve the state of art results.",
    "The paper introduces Finite Volume neural network for modelling fluid dynamics inspired by the finite volume method. The paper models the velocity and the spacial derivatives as the neural networks. The work demonstrates more precise fluid simulation than the related physics-inspired models.",
    "The authors propose to model advection-diffusion partial differential equations as a composition of multiple neural networks. According to the authors, this leads to better generalization over different initial and boundary conditions for the physics system, and also the ability to learn different factors of the process as modeled by the terms in the PDE. Extensive experimental results are presented to support the author\u2019s claims that their framework performs better than state-of-the-art.",
    "In this work, the authors explore the relationship between 4 different brain regions (multi-demand network, language network, visual system, auditory system) and different features of program code. Specifically, they look at hidden state representations of code language models (seq2seq, CodeBERTa, CodeTransformer, XLNet), tf-idf and BoW representations of the input. For non-LM based features, they look at a code vs. sentence contrast, variable language (English vs. Japanese variable names), data types (strings vs. numerals) and control flow (for vs. if vs. no branching) To analyze relationships between the BOLD signal and stimulus features, they build linear classifiers/regressors from the BOLD activity of each system to each of the stimulus features. Models are evaluated using classification accuracy and linear correlation for regression. In the case of hidden-state features, model are evaluated using rank accuracy.  Overall, the authors find that the visual system is capable of significantly predicting several of the hand-crafted code features suggesting that these features are correlated with low-level stimulus properties like program length. While differences between MD & LS are not significant, these models successfully predict 5/6 hand-crafted features. In the code representation prediction task, the authors find that the MD, LS and Visual systems are able to rank significantly above change. However, the LS and visual systems do not beat a random token embedding baseline. Aside from CodeBERTa, the MD system is also not significantly above the random baseline.",
    "This work examines the relationship between fMRI recordings of people who read short programs and different properties and representations of the programming code. The aim of the work is to understand what properties of code are encoded by different brain systems, and to understand how similar the representations of code in the brain are to those encoded by self-supervised language models that are pretrained to encode programming code. The authors find that several program properties can be significantly decoded from 3 brain systems (the multiple demand system, the language system, and the visual system). They further find that representations of the programs extracted from several machine learning models of varying complexity can also be significantly decoded from these brain systems.   ",
    "This paper introduces a systematical framework to discover the relationship between the brain representations of programs and their corresponding code models. This framework helps us to understand the code properties encoded in the human brain so that we could evaluate whether ML models faithfully represent human brain representations of computer code comperhensions.  This paper focuses on answering two questions by showing the results of related experiments on a dataset of 72 programs and 24 persons' brain recordings: First of all, the authors show that how well each of the four brain systems considered in this paper including Multiple Demand, Language, Vision, and Auditory systems encode specific code properties using a ridge regressor. Then they demonstrate another ridge regressor that can map brain representations to the corresponding learned representations by computational language models of code with different model complexity. ",
    "This paper investigates encoding of computer code in the human brain. The author build decoding models for fMRI responses to predict 1) various properties of python code and, 2) representations of python code derived from different machine learning models. The main conclusion is that the responses from the Multiple Demand system in the brain is capable of provide significance decoding performance of properties and model representations of computer code, such as runtime information.",
    "This paper proposes a setup to perform Direct Speech To Speech Translation from one language to another. As such, we could view this as a voice conversion setup, but with the additional task of rendering translated voice in a different language. It seems to be created on the same lines as Translatotron, but with improved performance from different modeling choices. The architecture is encoder-decoder, with the decoder side consisting of two parts - a spectrogram synthesizer, and a phoneme/language translator. The phoneme translator is needed because it also needs to translate to a different language.   The experimental evaluation is quite good, consisting of cases to translate with the same voice as source (voice retention); samples with speaker turns (augmented dataset with two different speaker utterances concatenated together), and cross language translation. The paper shows improved results over Translatotron in all cases.   Aside from the results, the contributions seem to be incremental. They also emphasize a modified training setup that does not use speaker embeddings to avoid antispoofing. ",
    "This paper advances the previously proposed direct speech-to-speech translation (S2ST) model Translatotron.  Direct S2ST has many benefits but has quite limited research effort. The major contributions of this work can be summarized as follows. Translatotron 2 addressed the following major problems of Translatotron: 1)  translation quality, naturalness and robustness of predicted speech are significantly improved and now comparable to a cascaded system (i.e., speech-to-text translation followed by TTS).  2) Similar to Translatotron, the model retrains source speaker\u2019s voice in predicted speech, but Translatotron 2 achieves this without relying on any explicit speaker embedding or speaker ID, hence Translatotron 2 will not be able to generate speech in a different speaker\u2019s voice. This will address some ethical concerns for deployment. Translatotron 2 achieved these improvements through the following approaches. Compared to the previous Translatotron model,  1) Translatotron 2  uses  the output from the auxiliary target phoneme decoder as an input to the spectrogram synthesizer;  2) the spectrogram synthesizer is duration-based, while still keeping the benefits of the attention mechanism.",
    "The paper proposed a speech-to-speech translation (S2ST) model that is and improvement to a previous work. The model is trained end-to-end from speech to speech, along with an auxiliary speech-to-phoneme task. The relevance of the two tasks is further exploited beyond parameter sharing, by feeding phoneme decoder's hidden layer output to spectrogram synthesizer's input, and the synthesizer is duration based. To retain speakers' voice from source language to target language, two data-centric approach is proposed. First, a zero-shot voice-transfer TTS model is trained, to transfer target speech into source speaker's voice. Second, to enforce local voice similarity within an utterance, two samples from two distinct speakers are randomly selected and concatenated to create new training samples. Experiments are conducted on speech-to-text translation (ST) datasets with TTS synthesized target speech, and are measured by both objective (BLEU) and subjective (MOS) metrics. The proposed model's translation quality is much closer to the cascaded ST+TTS oracle than baseline S2ST models, for both bilingual and multilingual S2ST tasks. Its generated speech is also more natural and more resembles the source speech.",
    "Translatotron2, a speech-to-speech neural based translation system is proposed. The work is a modification of Translatotron (also a speech-to-speech translation system) and tries to address some of the  issues in Translatotron:  a) Translation quality fairly below a cascaded baseline  b) synthesized translated speech suffers from robustness issues, such as babbling and long pauses  c) Voice retention relies on explicit speaker embedding which can potentially be misused for generating spoofing audio with arbitrary content  Compared to Translatotron, following modifications are made in Translatotron2. The experiments suggest that Translatotron 2 significantly outperforms Translatotron, and is comparable to a cascaded system, in terms of translation quality, speech naturalness and speech robustness.  a)  Output from the auxiliary target phoneme decoder is used as an input to the spectrogram synthesizer   b) Conformer Encoder with SpecAugment is used, which is known to improve the speech to text performance  c) Duration-based  Spectrogram synthesizer is used. Specifically, architecture and hyperparameters similar to Non-Attentive Tacotron spectrogram synthesizer is used, which is known to improve the robustness issue in Tacotron2   d) To retain speakers\u2019 voices across translation, Translatotron2 is trained on parallel utterances with the same speaker\u2019s voice on both sides. This enables the trained model to restrict generation to only the source speaker\u2019s voice, mitigating the risk of potential misuse for creating spoofing audio artifacts. Parallel utterances are synthesized using a TTS model with cross lingual voice transfer capacity.  In addition, authors also trained Translatotron 2 with examples that contain two speakers\u2019 voices in both the source and the target. The experiments suggest that Translatotron 2 has capability to retain voice identity when the input contains speaker turns.  For multilingual experiments, Translatotron 2 was trained with 4 high resource languages  and BLEU scores suggest Translatotron2 outperforms Translatotron in multilingual settings as well.  ",
    "The article proposes to address attribute detection with a small data constraint in the training phase (few-shot approach). The experimental protocol is divided in a series of episodes, each defined by a support set that specifies the attributes to be predicted and a query set used to evaluate the prediction. The generic algorithmic structure to solve this problem is divided in two steps: a common pre-training phase that combines self-supervised representation learning and supervised fine-tuning, followed by a supervised learning phase to solve each episode task. A training dataset containing image samples with attributes is used to learn the pre-trained representation space. The pre-training phase is compared to other approaches on three benchmarks implementing few-shot attribute prediction episodes. An indicator computed from a logistic regression between attribute values is proposed as a way to predict transferability between the learning dataset and the few-shot problem. ",
    "This paper proposes the problem of few-shot attribute learning (FSAL) that follows the standard few-shot/meta-learning paradigm but focuses on attributes instead of object classes. The authors argue in Section 2 that the multi-label nature of attributes (smiling & wearing eyeglasses can be present simultaneously) makes this problem different; the context of each positive example in each episode can drastically change what the model is asked to learn.   This paper also proposes three benchmark datasets to study this problem, based on Celeb-A, Zappos50K, and ImageNet-with-Attributes. The paper evaluates multiple existing approaches on these benchmarks as well as improves upon them further. ",
    "The authors consider the problem of few-shot attribute learning. Contrary to most past approaches on learning with attributes, including classical zero-shot learning, the authors deal with the case where the attributes seen at test-time are previously unseen. As a result, few samples must be used to quickly adapt the learning algorithm to new attributes. The approach works in 3 stages. The first uses a classical representation learning algorithm to learn a visual representation, SimCLR. Following this, the network is given supervised training to fine-tune the representation. In the last step, the authors adapt a previously devised few-shot learning strategy that consists in training a linear classifier. ",
    "This paper investigates a new and interesting topic, few-shot attribute learning (FSAL), where the model is trained with base attributes with abundant samples and tested with novel attributes with only a few samples. Experiments were performed on three benchmark datasets with attribute annotation. The paper found that self-supervised learning helps to train a backbone that generalizes well to novel attributes, compared to training the backbone with only base attributes. The author also compares several few-shot learning models, e.g., MatchingNEt, MAML, ProtoNet, in this FSAL setting and found that the logistic regression layer works the best.",
    "The paper suggests a method for approximating the 2-Wasserstein gradient flow for the relative entropy. The proposed particle-based method uses a neural network function approximation-based approach to estimating the necessary density ratios. Experiments verify reasonable performance compared to MALA and ULA.  ",
    "This paper considers the problem of sampling from an unnormalized distribution. The unnormalized target distribution can be regarded as a stationary point of the Wasserstein gradient flow of the corresponding relative entropy functional, which can be equivalently identified from a microscopic perspective by defining a time-varying velocity field of the particles. While the exact time-varying velocity field is not exactly available, the authors propose to estimate such a quantity by approximating the corresponding logarithmic density ratio through minimizing the Bregman score. Such an approximation requires only samples from the variable distribution which can obtain by simulating particles following the estimated velocity field.",
    "The paper proposes a novel way to sample from unnormalized distributions. This is helpful when calculating or estimating the normalizing constant is untractable.  The main idea is to track the gradient flow of the relative entropy in the Wasserstein space of probability distributions. It is known that the flow converges to the target distribution and the paper introduces a variational characterization of the discretized steps. The main benefit of this characterization is that it bypasses the need to know the normalizing constant as well as being amenable to estimation by using a combined particle evolution.  The benefits of the new algorithm are demonstrated through several numerical simulations.",
    "The paper addresses the issue of sampling from an unnormalized distribution. The sampling problem is cast as the numerical simulation of the gradient flow associated with the KL divergence between the target unnormalized distribution and the approximating distribution. The challenging part is to estimate the density ratio that appears in the gradient term. The authors propose to use a deep neural network to estimate the density ratio. Numerical results show the usefulness of the proposed method.",
    "In this paper, the authors propose a certain type of trainable quantum procedures used as machine learning models for the classification of images. They explicitly show how to implement the circuits for loading compressed images into quantum states that are fed to a trainable unitary that writes the predicted label into a readout register. They conclude on numerical simulation performed on the MNIST dataset.",
    "The paper study the problem of quantum neural networks for classical image classification. It leverages the FRQI framework to enable larger size of the input image instead of using very small 4x4 input image. They construct parameterized quantum circuits using XX and ZZ gates (called \"CRADL\" and \"CRAML\") to perform the transformations of quantum state and perform classification.",
    "The paper presents an image coding approach based on 2qubit gates. Downsampled MNIST digits are classified using standard components. Additionally, the experimental section studies the use of reduced codes.",
    "This paper studies the image classification problem on quantum computers. The prior of image classification by Farhi et al. can only work on 4-by-4 input images, while this paper conducts experiments on 16-by-16 images for the MNIST dataset.",
    "This work proposes a novel framework to train a face recognition network for the federated learning setting. The proposed method leverages differentially private local clustering mechanism to allows to securelly share the information of class centers of a local client to other clients.   In addition, the consensus-aware recognition loss encourages the global consensuses for the learned face embeddings among clients and significantly improves the performance as compared with the plain federated learning baselines. ",
    "The aim of this paper is to tackle the privacy leakage issue when using federated learning technique to train deep face recognition models. The na\u00efve practice, broadcasting the last fully connected layer, results in the leakage of ID features. But if we cut off the broadcast of $W^c$, it will cause the issue of overlapping IDs among the clients, which harms the training of face recognition model. Therefore, the authors propose their method, DPLC, to tackle this problem. The idea is to conduct online clustering, gaussian perturbation, combined supervision of cluster and local data.",
    "The main contribution of the paper is a slight modification of the standard federated learning (FL) framework for the purpose of improving face recognition performance. Since face recognition involves learning a deep neural network for feature embedding and the weight vectors for mapping the feature embedding to an identity, the standard FL framework (e.g. FedAvg) that updates only the feature embedding network does not suffice. Hence, the paper proposes to cluster the weight vectors of each participant and transmit the cluster centers (albeit with Gaussian noise to ensure differential privacy) to the other participants. Once the cluster centers of other participants are known, the local weight vectors can be learned to avoid overlap with those received clusters.",
    "This paper proposes a FL strategy for face recognition. Despite the wide investigation of FL, very littler research discusses the use of FL for face recognition.  The proposed of PrivacyFace can: (1) distill sanitized clusters from local class centers using Differentially Private Local Clustering (DPLC) . (2) use a consensus-aware recognition loss to  encourage global consensuses among clients, leading to a more discriminative feature learning.  ",
    "# Summary  This paper proposes a method for using intermediate representations from a pre-trained model for better transfer to other tasks. A linear classifier is trained on features from multiple layers. A feature selection strategy is chosen, where first a linear classifier is trained on all features with group-lasso regularization, and then another classifier is trained only on features whose regularization score exceeds some threshold. This approach is evaluated in a low-resource transfer scenario of image classification, and compared both to training on all features without the two-step feature selection but with regularization, and to the standard fine-tuning approach. The proposed method works slightly better than fine-tuning with a ResNet model, and slightly worse with a ViT model, although the comparison is not completely fair, as discussed. There are different performances on different categories of images.   ",
    "This paper explores the utility of intermediate layers for linear probing in transfer learning. Specifically, authors proposed Head-to-Toe probing (HEAD2TOE), that selects features from all layers of the source model to train a classification head for the target-domain. Experiments on the VTAB benchmark shows that Head2Toe matches performance obtained with fine-tuning on average, but critically, for out-of-distribution transfer, Head2Toe outperforms fine-tuning.",
    "This paper propose Head2Toe, a method that exploits intermediate representations of DNNs to improve performance, and OOD generalization of transfer learning. The key idea of the Head2Toe is to augment traditional linear probing with intermediate representations. It uses group lasso as regularization to learn weights of different features, and then select features based on the learned weights and validation performance.Experiments on VTAB benchmark show that Head2Toe outperforms linear probes and is competitive compared with fine-tuning. An important finding is that Head2Toe improves OOD generalization.",
    "The main focus of this paper is the study the use of intermediate layers in a deep pretrained model on downstream tasks. Authors argue that the the fact that the good performance while fine tuning on downstream tasks even if data scarce is due to the prior existence of useful representations deep in the model which are brought up during training. Authors propose a new approach. Head2toe, which consist in utilizing intermediate representations, while freezing the weights of the network for training for downstream tasks Experimentation is carried out starting with a ResNet-50 and ViT-B/16 models on a variety of datasets collected on the VTAB collection, showing that the approach where Head2toe  outperforms linear finetunning (training a classification head on top of the model, while freezing the rest of the weights) and matches the performance of finetunning the whole model.",
    "This paper studies object-oriented text dynamics (OOTD) model and planning in text-based games. OOTD learns internal representation of object dynamics and uses transition layers to predict the belief of object states. Empirical results shows a performance boost compared to model-free baselines. Ablation studies are performed to explain the importance of OOTD components.",
    "This work proposes Object-Oriented Text Dynamics for model-based RL in the TextWorld environment. OOTD ensembles existing methods such as ComplEx, R-GCN to build a memory graph, which contains object-level information about each object's attribute and its relations to others, from history observations and predicts states at the next time step. Therefore, the authors can combine the learned model with Dyn-Q or MCTS methods to select actions. If I am correct, under an object-supervised setting, it assumes the existence of a dataset that contains a ground truth memory graph. In contrast, the network has to discover graphs from predicting observation and rewards in the self-supervised setting. Experiments show that OOTD achieves superior performance than various baselines, including model-free RL and previously learned graph models.",
    "This paper tackles the difficult problem of learning to play text-based games. This domain is particularly challenging, since the text observations received at each time-step are variable length, and will only provide a partial description of the world, from which the full state must be reconstructed. Additionally, the player must track the history of past states in order to make the correct decision.  This paper introduces a new framework for describing the time-evolution of a game: Object-Oriented Partially Observable Markov Decision Processes (OO POMDP). This work's main contribution is a learned Object-Oriented Text Dynamics (OOTD) model that learns the transition and reward function of a OO POMDP game.  Briefly, the presented method for predicting the transition function is: given a representation $z_t$ of the objects and $a_t$ of the action, create a graph, where the nodes are objects and the edges denote relationships. Perform message passing, and obtain new node representations $e_t$.  Then, (1) given $e_t$, predict a new representation $v_{t}$ using dual stream attention with the action $a_t$. Then, (2) use $v_t$ to predict the updated state $z_{t+1}$ of each object, using an independent set of parameters per object.  The dynamics model is trained using a Evidence lower bound objective (ELBo) in two varieties: one that relies on a deterministic extraction of the graph and one that learns directly from rewards and observations.  To show its effectiveness, the learned dynamics model is used to model-based training (Dyna-Q, MCTS) is used to learn a planner. The learned planner is shown to out-perform the baselines (DQN, DRQN, GATA), both on the test cases, and in terms of sample efficiency. Ablations of (1) and (2) find qualitative advantages of the proposed method, since the learned object representation are both more separable and better semantically clustered. Additionally, the ablations are shown to reduce the accuracy of the graphs and state recreated from the object representations.",
    "This paper presents a novel approach for task-based games. The authors used an object-oriented POMDP formulation for the task. The key contribution is to learn the dynamics of the environment with a graph neural network (with either object supervision or self-supervision), and apply an online planning algorithm (e.g., MCTS) to solve the problem. The authors show strong improvements over other approaches in terms of sample efficiency and task scores.",
    "The paper studys cost-sensitive hierarchical classification problems. The novelty is very limited, the experiments are vey tirial. I recommend to reject.",
    "The authors propose a new framework for cost-sensitive hierarchical classification. First, they decompose it into level by level learning to abstain (with different abstain costs per class) sub-problems. To solve these subproblems, authors apply deep distributionally robust learning (DRL) approach that directly minimizes the abstaining loss (based on Fathony et al. 2018). These two elements create a method named the Layer-wise Abstaining Loss Minimization method (LAM). The proposed method is compared with DARTS on two datasets and achieves attractive performance. The authors also demonstrate that this decomposition makes it easier to achieve the desired performance profile by adjusting abstaining losses of the layers.",
    "The paper presents an approach for hierarchical cost sensitive classification in which abstentions are allowed. It shows a bijection between original cost sensitive problem and the set of layer wise abstaining losses. It is based on using the existing distributionally robust cost sensitive classification and extending to it to the hierarchical setup. The proposed methodology is demonstrated on birds and cell classification datasets, which are claimed to be large-scale. It is compared to a relatively old DARTS method from 2012.",
    "The submission study the problem of cost-sensitive hierarchical classification (CSHC) with given label taxonomy via learning to abstentions each layer within the hierarchy. Indeed,  1. CSHC subject has had many researches while using abstention or reject decision has also had many works in flat classification, briding both seems relatively few for which the authors present LAM to achieve a so-called new method.  2. Using DRL framework to solve the learning to abstain problems in each layer makes optimization almost decouplable layer by layer, the rationale behind its strategy should attribute to the proved bijective correspondence between the hierarchical cost-sensitive loss and the set of abstaining losses. 3. LAM achieves better performance on limited benchmarks.",
    "This paper proposes a method for improving the detection and the localization of several sound sources using a 4-channel signal (The addressed configuration, determined or under-determined case is not detailed in this paper). The proposed approach is based on a so-called \"synperiodic\" filter bank representation that is used as the input of a deep convolutional neural network. Finally method proposed by the authors is comparatively evaluated on the DCASE2020 dataset and pretends to provide the best results.  ",
    "I am sorry, by mistake I posted the incomplete review version!   This manuscript proposes a sound source localization method utilizing \"synperiodic filter\" bank representation as to the input of a deep convolutional neural network.  Authors claim that the convolution of the proposed filterbanks with the raw waveform helps to achieve multi-scale perception in the time domain which results in performance improvement.  The authors demonstrated that their method could outperform some of the state-of-the-art similar work.   ",
    "This paper addresses the problem of sound event detection and localization from multi-channel raw audio waveforms. Essentially, a different audio front end feature extraction scheme - \"Synperiodic Filterbank\" if proposed which can be parameterized and jointly learnt along with a backbone classifier in an end-to end manner. The feature extraction scheme proposed is grounded in principle of uncertainty governing time-frequency resolution. Through ablation studies the authors show that this feature extraction scheme performs better (albeit marginally) compared to some of the traditionally used feature extraction schemes like MFCC, and LFBEs. Subsequently, the authors show that combining the proposed \"Synperiodic Filterbank\" with a significantly large model (~3X times the closest baseline model in terms of No. of trainable parameters) based on the Transformer Architecture offers a dramatic improvement in the results compared to the baseline. ",
    "This submission addresses the sound source detection problem. Compared to previous method, the authors propose a novel synperiodic filerbank compared to syndistance bank, which learns a data-dependent time-frequency resolution map. Experiments show that the proposed method achieves state-of-the-art performance on several datasets. ",
    "This work builds on the previous work[1] and extends it for a more general scenario, where per sample intermediate distribution shift is hard to quantify. They propose gradual feature interpolation for the case where samples from intermediate distribution are missing. Iterative self-training fails in such cases. The work presents results on synthetic and natural distributions to evaluate their claim.  [1] Ananya Kumar, Tengyu Ma, and Percy Liang. Understanding self-training for gradual domain adaptation. arXiv preprint arXiv:2002.11361, 2020.",
    "This work proposes an iterative self-training approach for unsupervised domain adaptation. In particular, the authors aim at gradually adapting a model trained on a source domain to the target domain. Based on the claim that previous work on this setting assumed that samples from distributions that represent gradual changes from the source to the target domain are available when adapting the model, the authors proposed a strategy to generate such intermediate samples for cases where they are not available. The introduced approach, named GIFT, consists in performing manifold mix-up between representations of examples from the source and target domains considering an increasing value of the hyperparameter that accounts for the weight of the representation of the target domain example. By doing so, the authors claim an automatic curriculum is introduced in the training. Moreover, since labels from the target domain examples are not available, the authors also introduced a heuristic to pair the examples that are mixed. GIFT was empirically validated on experiments with synthetic domain shifts on the CIFAR-10 dataset and was shown to outperform iterative self-training in terms of target accuracy. Experiments on two datasets presenting natural domain shifts were also performed.  ",
    "This work adddresses domain adaptation (DA) by a GIFT method. GIFT consists of a manifold mixup technique, which generates virtual samples by mixing up the features of source and target domains samples. The mixup coefficient is annealed over time to bias towards the target domain. Another ingredient of GIFT is a co-teaching strategy that lets two networks teach each other. On a few small synthetic as well as natural image datasets, GIFT outperforms a few baseline methods.",
    "This paper introduces how to deal with the situation when intermediate distributions are unavailable. The basic idea is to create virtual samples by interpolating source and target representations. The effectiveness of the proposed method is evaluated and results in several interesting conclusions.",
    "This paper proposes the use of user comments in addition to videos and titles to learn better representations for retrieval. Since user comments may be loosely related to the video, they use an attention-based mechanism to ignore irrelevant user comments. Their experiments show that using comments using this mechanism leads to better contextualized representations, which lead to competitive results on standard benchmarks.",
    "The paper looks into video-text retrieval problem.  The claim is that existing works mostly rely on titles and captions.  The paper argues for using user comments.  The challenge is that not all user comments are meaningful or relevant.  Therefore, the paper looks into attention mechanism to filter out the irrelevant content. The main contribution is a context adapter module based on transformer that allows relating visual input and textual input. The base architecture seems to have been derived from CLIP.",
    "In this paper, the authors proposed a multi-modal video representation learning and retrieval method based on it, taking advantage of visual and text embeddings, particularly users' comments on video sharing platforms. For this, the authors present a new component called Context Adapter Module (CAM), applying skip connections to selectively reflect user comments in the model. According to their experiments, the authors claim that the proposed method outperforms baseline models, by providing more contextualized representations of videos. ",
    "The authors propose a text-based video retrieval method based on context from weakly related user comments. Evaluation shows that considering user comments improves the retrieval performance. Compared to conventional methods, the proposed method shows similar performance with CLIP4Cilip. However, CLIP4clip needs a much larger-scale training, so the superiority of the proposed method is claimed.",
    "This paper adopts the framework of unsupervised skill learning. To solve the problem that the discriminator will have low confidence in the unseen data thus providing a low intrinsic reward, the paper derives an information gain auxiliary objective that involves training an ensemble of discriminators and rewarding the policy for their disagreement. The paper conducts extensive experiments on tabular grid world and 57 games of the Atari Suite. ",
    "The paper proposes a novel unsupervised skill discovery algorithm. Beginning with the family of such methods (DIAYN, VIC, etc) that learn a discriminator to distinguish skills given some observations of the trajectory and a policy that executes a skill conditioned on the (discrete) skill random variable Z, the premise of the paper is that such methods on their own will fail when new states are encountered during the skill learning process as the discriminator would not have had sufficient data to learn to distinguish novel states. The paper proposes a novel reward bonus that works in addition to a base method such as DIAYN (DIversity is All You Need), such that this bonus \u201creimburses\u201d the policy for visiting states where the discriminator uncertainty is high (measured using a form of disagreement across an ensemble of discriminators). Experiments on the pedagogical 4-room environment and the Atari suite of environments demonstrates the benefit of the proposed reward bonus in not only learning more skills (or \u201cempowerment\u201d in the VIC nomenclature), but the learnt skills are also superior for downstream tasks (external reward) and lifetime state coverage.",
    "This paper identifies a source of pessimism in DIAYN-style methods for exploring new parts of the state space. They argue that this issue is due to using a single point estimator as a discriminator and that capturing the epistemic uncertainty of the discriminator could serve as an additional signal to guide exploration. They achieve this by using an ensemble of discriminators and incorporating the epistemic uncertainty across the ensemble into an additional intrinsic reward to the diversity of skills reward (through a mixing parameter $\\lambda$). They examine this method against DIAYN-style methods and count-based methods and show that this new approach broadly outperforms both these classes of methods.    ",
    "This paper is concerned with unsupervised RL where an extrinsic reward signal is not available. The objective is for the agent to master the environment by exploring it while learning a diverse set of skills. This is done by simultaneously training a policy conditioned on a latent variable and a discriminator that tries to infer the latent variable from trajectories. The authors identify that the intrinsic rewards used in skill discovery result in the agent being pessimistic towards exploring novel parts of the environment. To alleviate this, the authors propose a new auxiliary objective, which results in a bonus based on the disagreement of an ensemble of discriminators. Empirical results on the grid world and Atari show improvements in skill discovery and solving downstream tasks compared to baselines.",
    "This paper presents a method to construct a molecular graph, which is inspired by a spanning tree. In specific, a molecule is constructed by a sequence of actions, each of which adds an atom, adds a bond, starts/ends a branch, adds residual edges for a circular structure, and terminates. The generative process is controlled by a transformer-based neural network, which is specialized to tree construction procedure. The empirical studies show that the proposed method can learn the distribution of molecules comparably or better than the existing methods, and can be used to molecular optimization.",
    "This paper proposes a spanning tree based generative model (STGG) for molecular graphs. STGG sequentially generate a molecule's spanning tree and fill in the residual edges on the way. The spanning tree construction is similar to the standard SMILES representation, but the model operates on a molecular graph rather than a SMILES string. STGG adopts a tree-based transformer with relative positional encoding for tree generation, and a attention-based predictor for residual edge prediction. The method is evaluated on standard ZINC250K, QM9, and MOSES benchmarks and outperform existing baselines.",
    "The paper proposes a novel spanning tree-based graph generation (STGG) framework. The key idea is to represent the molecular graph as a sequence of decisions according to a **novel spanning tree-based grammar**, and then model these decision sequences using the transformer.  To accommodate such a novel algorithm, several interesting techniques are involved, e.g., representing molecules as bipartite graphs, using tree-based positional encoding for transformer. The authors claim that the proposed method allows generating valid molecular structures and inferring the intermediate graph structure.",
    "This paper proposes a new paradigm of graph generation, a transformer network sequentially generates a sequence of decisions to generate a spanning tree for a bipartite graph. These decisions have 7 forms such as attach atom, attach bond, branch start,  etc. After the spanning tree, they add residual edges. The authors also have a focus on generating valid graphs (which is seen in the results) in which they mask out invalid decisions during the generation process itself.   ",
    "This paper considers a simplified model of the polynomial neural network, and shows that the eigenvalues of the induced tangent kernel have a slower decay rate, compared with the classical two-layer network. This also means the polynomial neural networks can learn the high-frequency components faster. The empirical evidence supports this tendency.",
    "The paper studies ReLU-activated two-layer neural networks. The main contribution is that unlike traditional deep neural networks (DNNs), this type of polynomial neural network (PNN) also learns high-frequency information quickly. This claim partially verifies why PNNs are suitable for tasks like face recognition, where high-frequency components are crucial for performance. ",
    "The paper is dedicated to the study of spectral bias in polynomial neural networks. For feed-forward neural networks with ReLU activation function it is well-known that learning high-frequency terms is made slower (Rahaman et al.).   Authors claim that polynomial networks are able to learn both low frequency and high-frequency terms almost equally fast. Theory, based on spectral analysis of an integral operator associated with the NTK kernel, is provided.  Theoretical approach was taken from arXiv: 1905.12173, but for NTK kernel of the network with an additional multiplicative interaction layer.  Then, experiments that support claims are provided.  It is claimed that multiplicative interactions in the architecture of a NN may be the reason for an ability to learn high frequencies.  ",
    "The paper gives an analysis of polynomial networks in the NTK regime. They show a theoretical speed-up in learning higher frequencies when using polynomial networks. They also have some experiments that verify these properties. ",
    "This paper extends the definition of the hidden subnetworks in randomly initiated neural networks. The new notion of subnetworks, namely the disguised subnetworks, apply a transformation on the hidden subnetwork weights to obtain final weights (a posteriori finding the hidden subnetwork).   Mathematically speaking, the main decision variable of the underlying optimisation problem of finding \u201chidden subnetworks\u201d is the so-called masking variable that is a binary vector, the variable that decides which components of the randomly initiated weights will be zero, constrained to a desired level of sparsity. On the other hand, the underlying optimisation problem of \u201cdisguised subnetworks\u201d has an additional variable U that applies a transformation on the set of weights after being \u2018sparsified\u2019. The selection of U = I, for I being the identity transformation, recovers the problem of hidden subnetworks, showing that the latter is a generalisation.  The author(s) present a heuristic algorithm that solves the forenamed optimisation problem. The idea is to first find a solution for the masking variable where (i) U = I is taken, (ii) the objective function is independent of a training set. Afterward, the algorithm proceeds by solving the problem for U given the solution of the previous step, where the space of U is restricted to the class of transformations where only sign-flips are allowed. If we think of the above solution process as a two-phase problem, the author(s) use the literature on sparse neural networks for the first phase and use the literature on binary neural networks for the sign flipping phase.",
    "Optimizing sparse neural networks is an important topic due to their computational and space savings.  Building on the work of the lottery ticket hypothesis, others have shown there exist hidden subnetworks within randomly initialized NN that have good performance. The authors extend this definition to disguised subnetworks, which contain hidden subnetworks as a subclass. Moreover, the authors present a novel combination of existing methods  into a single algorithm they call Peek-a-Boo (PaB) which can efficiently find such networks. ",
    "This paper proposes the idea of a \"disguised subnetwork\", which are hidden random subnetworks that can be transformed into a well-performing subnetwork. The paper introduces PaB as a way to uncover these subnetworks, by first searching for a mask over the random weights using pruning-at-initialization techniques, and then learning a transformation on the subnetwork. The paper further shows that this PaB process can be efficiently implemented, offering significant advantage over prior work.",
    "This paper presents an algorithm named peek-a-boo (PaB) to optimize network pruning (at initialization) and optimization (limited within flipping the sign of weights). This setting has not been studied by prior works. A two-step algorithm was designed -- pruning first, optimization second. Experiments show competitive performance compared to prior methods with similar optimization complexity.",
    "This paper focuses on developing a robust GNN model to defend against adversarial attacks on both graph structures and node features. More specifically, a general unified graph neural network is proposed to learn a graph structure and node features to correct the adversarial attacks. This a two-step approach. First, one operation is applied to reconstruct the graph with the node features. Then, the node features are updated by another operation with the learned graph structure. Experiments are conducted on four small datasets for evaluation.",
    "The authors propose a General Unified Graph Neural Network (GUGNN) framework to address graph and feature denoising. They use this framework to design a graph neural network (R-GUGNN) which is Robust against poison adversarial attacks in a semi-supervised node classification setting. The authors demonstrate on four common datasets (Cora, Citeseer, Cora-ML & Polblogs) that their method is generally more robust against perturbation compared to commonly used graph neural networks (GCN, GAT) and models which are designed to be robust in the same setting (RGCN, GCN-SVD, Pro-GNN).",
    "Considering the problem of adversarial manipulations of graphs, the authors propose a framework for \"cleaning\" the graph structure and its features to obtain more robust predictions. The core contribution, compared to existing works, is the additional considering of the feature cleaning. Technically, the authors first perform the graph cleaning (phrased as some kind of sparse, trace minimization problem) followed by some feature cleaning (phrased as some kind of feature diffusion/propagation). Experiments on standard (small) benchmark datasets shows some improvements.",
    "The paper proposes a robust model for graph neural networks (GNNs) to defend against adversarial attacks. While most of the defense mechanisms in previous work focus on identifying and fixing the perturbed structure of the underlying graph, this paper proposes to jointly fix the perturbed structure as well as the node features. The proposed objective function captures these components along with weighting by some hyper-parameters. The experiments include several baselines and show results on different attack models: targeted attack, untargeted or global attack, and random attack. The experiments also have results on ablation study as well as hyper-parameters. ",
    "The authors present a method to jointly learn a shape and UV parameterization of a creased document observed from multiple views. They use an SDF based implicit shape representation in combination with a recent neural volumetric renderer IDR, and optimize the energy composed of the main photometric term (a discrepancy between the observed and rendered image) and regularization terms enforcing well behaved UV space and a fixed scale conformal mapping which corresponds to a behaviour of a real paper material. Since the implicit field representation does not explicitly model a surface, the authors cannot directly optimize the 3D->2D mapping using standard graphics techniques and rather adapt the IDR renderer to be conditioned on the locations sampled from the UV space and train it jointly with the MLPs defined for the bijective mapping 2D->3D and 3D->2D. The authors show that they can get better results both quantitatively and qualitatively when compared to one of the SotA works DewarpNet.",
    "**High-Level Overview**  This paper proposes a neural rendering technique to learn how to estimate an implicit surface and its UV-parameterization from a set of 2D images. The proposed approach is applied to the problem of document unwarping, wherein a wrinkled, folded, or bent document (e.g. a piece of paper with text on it) can be digitally flattened with its contents preserved. For good measure, the paper also shows that learning the texture mapping enables the contents of the unwarped document to be edited in the texture space. The proposed approach is evaluated against a prior work, DewarpNet (Das et al., 2019) on the basis of Multi-Scale Structural Similarity (MS-SSIM) and Local Distortion (LD) as well as the auxiliary task of OCR.  **Key Contributions**  * Builds on IDR (Yariv et al., 2020) to learn an explicit bijective texture mapping for a learned implicit surface * A loss function formulation for the framework * Application of learned implicit surfaces for document unwarping with reduction in texture distortion and improvements in subsequent OCR metrics  **How It Works**  * Starts with the same problem formulation as IDR: an MLP to model the surface (Eq. 1) and an appearance MLP to model the color (Eq. 2) * Modifies the appearance MLP to also be a function of texture coordinates (Eq. 3) * Adds an additional forward and backward MLP to learn the bijective UV mapping * Jointly trains all MLPs using a pixelwise rendering loss",
    "This paper presents document unwrapping based on optimization of neural networks. Four MLPs are defined to model the implicit surface of the target, the colors of the target, the mapping function from 3D points to 2D texture coordinates, and the inverse mapping from 2D to 3D. Similarly to NERF, the target example is approximated by training the MLPs using differentiable rendering.   ",
    "The paper presents a multi-view method for undistorting documents. The method makes use of an existing method (IDR) for reconstructing distorted documents in 3-D, with an additional bijective neural network to parameterize distorted surfaces by rectangles. The method significantly outperforms SOTAs in the experiments.  ",
    "The paper is tackling the topic of fine-grained representation. In contrast to comparable methods, ARP focus on sub-sampled via strided operation to represent fine-grained information.  ARP is an intuitive strategy to extract critical regions and is more concise compared with multi-stage cascade architecture. This fact facilitates the efficiency.",
    "- **Motivation**. The paper argues that    - (a) there are some small but important regions of an interesting object, which are usually ignored by the previous fine-grained methods;   - (b) excessive reduction operations on image resolution fade the discriminative features.     - **Method**. According to the above observations, the paper proposes a pooling algorithm called Adaptive Region Pooling (ARP). This module has two procedures:   - (a) learn to crop image regions;   - (b) downsampling various size regions using bilinear operation.   - **Experiments**. The proposed method is verified in two tasks: fine-grained classification and re-identification. ",
    "This paper presents an adaptive region pooling (ARP) method for fine-grained representation learning. ARP crops the features with the estimated scale. The features are further downsampled to a consistent size through bilinear downsampling. Experiments conducted on two tasks validate the effectiveness of the proposed method.",
    "This paper proposes an adaptive region pooling (ARP) module that adaptively estimates the scale factors and crops the discriminative regions based on the estimated scale factors. It aims to focus on the most discriminative region and simultaneously contain more fine-grained information. The authors apply the ARP module to fine-grained image recognition and Vehicle Re-Id tasks.",
    "- This paper tackles the out-of-distribution problem for node-level prediction on graphs from the invariance perspective. It presents a novel approach in which the whole graph is divided into n ego-graphs where n is the number of nodes. All the ego-graphs can be treated as a set of IID. Based on this division, the model can be trained to defend the adversarial attack from multiple environments.  - This work extends the discussion of the OOD problem to node-level tasks on graphs. A new learning approach is proposed and theoretically proven to be correct. In empirical experiments on multiple datasets, the approach (EERM) outperforms its counterpart baseline ERM. ",
    "The paper adapts a recently proposed invariant risk minimization approach for tackling distribution shift on node-level predictions on graphs. The main idea is to decompose the graph into a set of ego-graphs rooted at each node, thus incorporating structural information. Since the learning objective requires data from different environments they authors introduce auxiliary context generators trained to maximize the variance loss. ",
    "This paper studies the problem of distribution shifts as out-of-distribution generalization. Specifically, it formulates the OOD problem as invariant risk minimization under different environments. The relation between these two has been extensively discussed in the paper. Multiple environment is done by graph editing using policy gradient. Experiments on three different kind of distribution shifts are presented and the effectiveness of EERM is validated.",
    "The importance of out-of-domain (OOD) generalization has emerged, and there is much research for out-of-domain generalization [1,2,3,4]. However, the related works on the graph-structured datasets are not explored well. OOD generalization of the graph is not trivial because the graph has the interconnection among nodes and the existence of structural information. To solve the problems, this paper proposes a new method, multiple contexts explore that are adversarially trained to maximize the variance of risk. The proposed model is validated on many diverse datasets, Cora, Amazon-Photo, Twitch-explicit, and so on.  [1] Arjovsky, Martin, et al. \"Invariant risk minimization.\" arXiv preprint arXiv:1907.02893 (2019).  [2] Sagawa, Shiori, et al. \"Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization.\" arXiv preprint arXiv:1911.08731 (2019).  [3] Krueger, David, et al. \"Out-of-distribution generalization via risk extrapolation (rex).\" International Conference on Machine Learning. PMLR, 2021.  [4] Creager, Elliot, J\u00f6rn-Henrik Jacobsen, and Richard Zemel. \"Environment inference for invariant learning.\" International Conference on Machine Learning. PMLR, 2021.",
    "This paper proposes InfoTS, a method for learning augmentations that improve contrastive learning of time series data. The core contribution is a learnable augmentation strategy that uses Concrete/Gumbel-Softmax distributions. The paper shows empirical results on several time-series forecasting and classification benchmarks.",
    "This paper describes an information-aware approach to representation learning for time series. The formulation focuses on how to obtain effective data augmentations and addresses the underlying problem from information-theoretic viewpoints, leading to the two optimization criteria, namely, high fidelity and high variety. The experimental results on several time series datasets for forecasting and classification show improvements over the methods in comparison. Detailed comments are listed below.",
    "This is a very good and solid paper that has both empirical elements and theoretical basis. As mentioned in the paper data augmentation in time series is a notoriously difficult problem for the simple reason that it can distort the time series completely - which in contrast to images - humans cannot verify this as it can happen with images. So the contribution of this paper is a new data augmentation approach based on information theory, a meta learning approach and an approach to select optimal data augmentation for contrastive learning.",
    "The authors propose a contrastive learning framework for time series data, where data augmentations are adaptively being selected, given a fidelity and variety criterion. Additionally to these two criteria, a contrastive learning objective is applied both on local and global level. The model is tested on a time-series forecasting and classification task on multiple datasets.  ",
    "Although Lottery Ticket Hypothesis has suggested an exciting corollary about the winning tickets, it is still unclear why winning ticket universality exists, or any way of knowing a priori. In this paper, authors make use of renormalization group theory to perform detailed understanding of this hypothesis. Authors find that the principle method iterative magnitude pruning (IMP) is directly related to the renormalization group (RG).    Based on the contributions of  RG leading to a first principled understanding of the universality in behavior near phase transitions, viewing the IMP from an RG perspective may lead to new insight on the universality of winning tickets. Such insight is build upon the experimental support of the theory in large scale lottery ticket experiments.",
    "This paper seeks to explain empirical observations in the literature on the Lottery Ticket Hypothesis (LTH) based on ideas from renormalization group (RG) theory in physics. The authors focus on the particular case of iterative magnitude pruning (IMP) as the pruning scheme and view the flow on the space of model parameters during IMP as analogous to RG flow in the space of couplings of a Hamiltonian. The primary experimental evidence for the connection comes from two considerations. (1) Computing the percentage of all non-zero parameters that are in a particular residual block (of a ResNet model) at a particular time. For ResNet-50 models considered, this leads to four scalar, dynamical quantities. These four quantities are found to grow or shrink exponentially with time, suggesting they are eigenfunctions of the IMP map. For three different types of learning & dataset (ImageNet / simCLR / MoCo) and one architecture (ResNet-50), the authors find the same eigenvalue across the three settings, per block. From this, the authors conclude that this universality (shared exponent) across different settings is evidence for the analogy to RG. (2) Transferability of lottery tickets. The authors hypothesize that the relevance / irrelevance / marginality  of a particular block ought to be matched by the source and target architecture when transferring tickets. More specifically, there are three conclusions from the literature (#1-3 in Sec 3.2) that are explained (for example, why the smallest model has the weakest transferability). ",
    "This paper tries to find a theoretical explanation of the transferability of lottery ticket used in similar tasks. Observing the similarity between the universality in renormalization group and the lottery ticket hypothesis, the author proposes that the iterative magnitude pruning, which is used to find the winning tickets, could be a renormalization group scheme. The authors also provide some evidence on their theory on vision model of ResNet families.",
    "The work aims to provide a deeper understanding of a corollary in the lottery ticket hypothesis: how to know whether a winning ticket found in one task can be transferred to another task. The paper tries to combine the widely used pruning method in the lottery ticket hypothesis (iterative magnitude pruning) with a concept from statistical physics, which is the renormalization group. The authors show iterative magnitude pruning can be considered as a renormalization group operator. Experiments are conducted using the renormalization group to examine whether pruned models are in the same universality classes and extend the renormalization group to the Elastic Lottery Ticket Hypothesis.",
    "This paper investigate the gap problem between cross-attention (CA) and dual-encoder (DE) models for document reranking. In general, cross-attention models perform much better than dual-encoder models while consuming more computational cost. The authors first leverage Mercer's theorem to prove that dual-encoders models are sufficiently expressive to model a broad class of scores using countably infinite dimension, which mainly the gap between CA and DE models should not exist from theoretical analysis. They further identified the gap is caused by the generalization ability of the DE models. To reduce the overfitting on the training data, they proposed to use distillation algorithms. Specially, they design the loss function which matches the margins between the teacher (CA) and student (DE) models. They also extend the margin to probability matching by using softmax cross-entropy loss. Through the experiments, they demonstrated that their proposed distillation approaches can further reduce the gap between DE and CA models.  The main contributions of this paper is that they show there should not be a gap between DE and CA models from theoretical analysis. They found that the gap is caused by the generalization ability of CA model and proposed distillation approach to reduce the gap.",
    "In information retrieval problems, there are two kinds of models: dual-encoder models and cross-attention models. Cross-attention models generally outperform dual encoder models by a large margin. Due to the latency requirement of real search systems, cross-attention models might not meet the requirements. So one ideal solution is to transfer the knowledge from cross-attention models to dual encoder models. This paper follows this line of research ideas by reducing the gap between the two models.   Firstly, the paper theoretically analyzes the effects with sufficiently large embedding dimensions. Secondly, the paper empirically verifies the theoretical results. Thirdly, the paper proposes a new method that further bridges the gap between the two methods. The writing is clear and well-structured. I like the idea and logic of the paper. I have some questions about the experiment part. ",
    "This paper aims to narrow the performance gap between cross-attention BERT and dual-encoder BERT for re-ranking task. The authors empirically and theoretically analyze the underlying reasons of the performance gap. The gap could be mitigated by the proposed knowledge distillation method, where the original cross-attention BERT model acts as the \u201cteacher\u201d and the more efficient dual-encoder BERT model is used as student. Comprehensive experiments confirmed the effectiveness of the proposed KD method for various re-ranking tasks.   ",
    "The paper contrasts cross-encoder vs. bi-encoder architectures for re-ranking in information retrieval.  The authors argue that bi-encoders under-perform cross-encoders, not for lack of capacity, but due to poor generalization, and back this claim with some theory and empirical results.  The authors then propose distillation of the cross-encoder model into a bi-encoder, which is shown to improve bi-encoder results.  While this has been proposed before, the distillation loss function the authors propose is slightly different than the standard cross-entropy (which the authors show is closely related).",
    "The paper proposes a policy improvement algorithm inspired by the minimum-variance policy of importance sampling (IS) technique in Monte Carlo simulation community. Properties of the new policy improvement algorithm such as convergence and implicit trust region are well studied in the paper. And in practical, the paper leverages a surrogate objective with the non-central alpha-moment as the finite sample objective for the algorithm. The new algorithm is used in the policy optimization in reinforcement learning. Empirical experiments on several continuous control demonstrate the benefit of the new proposed algorithm compared with existing trust region baselines, especially on the robustness to the small batch sizes.",
    "This paper proposes a novel policy optimization algorithm called POPE that is based off of ideas about how to use importance sampling for variance reduction from the Monte Carlo estimation community. The paper proves that the policy that minimizes the variance of the evaluation step actually provides a policy improvement, and then creates an algorithm that repeatedly estimates the minimal variance policy as a policy improvement step. It concludes with some small-scale experiments with linear policy classes on low-dimensional control tasks and claims modest improvements over TRPO and POIS baselines. ",
    "Importance sampling (IS) is at the core of many off-policy reinforcement learning (RL) algorithms.  The common use of IS in RL is to consider a _fixed_ policy behavior, say $q$ and an optimization policy $p$. The samples are acquired with the behavior policy $q$. The objective is to maximize  $$ \\max_p \\mathbb{E}_{x\\sim q}\\left[\\frac{p(x)}{q(x)}f(x)\\right]. $$  This approach suffers from high variance.   This paper highlight that originally, IS was thought to _reduce_ the variance of Monte-Carlo estimates. The main idea of this paper is to use IS as a variance minimization technique. It is interesting to see that the $\\min_q Var[p(x)/q(x)f(x)]$ leads to a _policy improvement_.  The paper is structured as follow:  1. The authors show in Equation 1 the _minimum variance_ $q^*$. This analytical result is (as far as I understand) purely theoretical and cannot be used directly in RL. Note that Equation 2 also shows how the minimum variance behavior is a policy improvement. The authors, therefore, suggest that one could simply iterate the minimum variance to consistently improve the policy. At this point, a few questions remain open: will this process converge to a local or global optimum? Can one quantify the divergence between consecutive distributions?  2. To study the convergence properties, the authors introduce an operator $\\mathcal{I}$ which takes in input a distribution $p$ and produces the next _minimum variance_ distribution $q$, which will be the next behavior policy. The operator $\\mathcal{I}$ has several fixed points: if $p$ is deterministic then $p = \\mathcal{I}p$. Theorem 4.2 ensures that the iterated application of $\\mathcal{I}$ converges to the optimum in the domain of $p$.  3. Often, trust-region methods are used in RL to ensure stability in the learning process. Theorem 4.3 shows that the application of $\\mathcal{I}$ produces a policy with bounded Renyi divergence with the previous policy. Interesting, this result is valid for any order of the divergence. This result is stronger than many other results in RL, where the divergence is only bounded for a unique order (typically 2: KL divergence), leaving the divergence on other orders unbounded.   4. However, the finding $q^*$ is often not possible. In short, if we consider a generic set of distribution, the application of $\\mathcal{I}$ to an element of the set, might produce a distribution not contained in the set. The authors need at this point to devise an _approximation_ of $\\mathcal{I}$, and check again for the convergence properties.  The first approximation consists in minimizing a $\\alpha$-Renyi divergence. The difference between classic divergence minimization (or constraint) approaches is that in this paper, the authors are constraining divergence between \"return distribution\" (even though modified by the monotonic function $h$) rather than the divergence between parameter distribution or state distribution like in REPS or TRPO (@authors: correct me if I am wrong on this point).  5. The authors analyze the policy improvement of this \"approximated\" operator. They notice that the policy improvement happens only for some particular choice of $h$    6. The authors prove in Theorem 5.4 that the approximated operator has a tighter trust region (for every single choice of $\\alpha$) w.r.t. the unconstrained operator $\\mathcal{i}$.  7. The authors provide a practical algorithm in Section 6, and evaluate its efficacy in four classic control benchmarks. They also provide an analysis of the hyperparameters used (monotonic function $h$ and batch-size).   To summarize, the paper proposes a different use of IS, which allows both for variance reduction and policy improvement.  The improvement scheme is new (although it can be related to other approaches) and sheds new light on policy gradient optimization.      ",
    "The paper analyzes the connection between searching for an optimal behavior policy that minimizes variance, and policy improvement in RL. The paper shows a number of interesting theoretical results, such as non-negative policy improvements, convergence and connections to implicit trust regions between consecutive policy iterates. The paper also shows results in constrained case where the policy class is parameterized. Finally, the paper shows empirical results on a few low-dimensional RL examples.",
    "This paper proposes a method to train large scale graph neural networks containing up to billions of parameters, called Graph Parallelism. The method is used to train large scale versions of the DimeNet++ and GemNet models containing 10-20x more parameters that the vanilla versions. These large GNN models are evaluated on a set of tasks from the Open Catalyst 2020 (OC20) benchmark and show improved performance compared to the smaller baselines. ",
    "This paper proposes a distributed training method for large graph neural networks (GNN) up to billion parameters. The method first distributes the triplet update operations to multiple GPUs and aggregate the updated vectors by global synchronization. It then distributes the edge update operations to GPUs and aggregate the edge vectors (another global synchronization). Finally, it applies node update in parallel and global node aggregation at the end. The method is applied to GemNet and DimeNet up to 1.12 billion parameters and achieved state-of-the-art results on OC20 benchmark.",
    "The authors present an approach to train graph neural networks with many parameters across multiple GPUs. The approach is specifically demonstrated for graphs representing molecular structure and two graph neural networks of similar flavor that have previously been presented to learn from such structures. Higher-order interaction terms make these networks very compute intensive. Leveraging their parallel approach to scale up the existing GNNs, the authors demonstrate compelling results on the OpenCatalyst benchmark. ",
    "The paper is based on the idea that most of the computation costs to extended graphs come from triplets. The authors proposed a way to parallelize the computation of triplets in a distributed way. The author also discussed two models that fit into this framework and showed their increase in performance due to the larger parameter count enabled by their parallel framework.",
    "This paper proposes to model the evolution of sentences in a document via a stochastic process; specifically a Brownian Bridge process. The paper start off by assuming that the generated sequences by autoregressive models like GPT-2 follow Brownian motion in that they tend to get incoherent and \"meander\" in the semantic space. This paper aims to reduce this random behavior by pinning the endpoints of the trajectory and model the generation by Brownian bridge process instead. The key intuition behind this process is that given two endpoints z0 and zT, the evolution of z along time t is a Gaussian with mean that is some linear combination of z0 and zT. This paper models text by training an encoder for sentences x that produces the embedding z by training over triplets (x0, xt, xT) where 0<t<T that encourages zt to follow Brownian bridge dynamics and uses contrastive loss with a negatively sampled x't for training.  The approach is tested for local coherence, long range order sensitivity, and generation of long sequences and is compared against ablative and external baselines. The proposed approach does lead to learning of embeddings that are obtainable via linear combination and this leads to improved performance on sensitivity to sentence order in documents and document generation. ",
    "The authors propose to use a Brownian bridge process to model global coherence of a long piece of text. They show how to train such a model in an encoder-decoder style setup, using a contrastive loss to model the Brownian bridge dynamics. The authors then verify aspects of their model with a series of experiments to show that their model with an underlying generative process outperforms competing approaches on a variety of local and global coherence and generation tasks.",
    "This paper introduces a method to enhance the global coherence of text generated from Language models. The proposed method (Time Control). Under the assumption in the latent space of sentence embeddings, the incoherent text can be seen as \"Brownian motion\" in the latent space. In order to enforce a goal to the generated text authors by fixing a start and end to this Brownian motion the process of text generation can be modeled as a Brownian bridge.   From this assumption, the authors drive a method that consists of three steps (1) training an encoder to map sentences to a latent plan defined as Brownian bridge (2) training a decoder to reconstruct sentences from the given context + the true encoded vector of the target sentence from planning latent space using the trained encoder (3) at inference time: given a start and endpoint, a target trajectory of vectors $z_0, ..., z_t, ..., z_T$ is sampled and use the decoder to generate a sentence based on this bridge.   Authors run several experiments to (1) evaluate the hypothesis that the encoder can capture local text dynamics using sentence order prediction task (2) evaluate the decoder to generate local incoherent text using the text-infilling task. (3) capture global text statistics by measuring the statistics (length of Wikipedia sections for city articles) of the generated text and compare them to the ground truth. (4) Evaluate the overall coherence of the long-generated text. Overall the results look convincing except for some caveats (see the areas of enhancement)  ",
    "This paper proposes a generation from a language model not only from an initial state, but also using a goal state. Instead of Brownian motion, the authors employ a draw from Brownian bridge by designating initial and end states, called Time Control. Experimental results show the proposed generation from Brownian bridge is more natural and coherent for text-infilling task, and also preserves text  structures both by automatic evaluation and human evaluation.",
    "This paper studies the problem of predicting the segmentations and poses (position + yaw orientation) of multiple objects, given the image of a scene. The paper introduces a method that is trained without supervision for the segmentations, similar to several other recent object-centric models. In contrast to these existing models, the method proposed in this paper additionally estimates the 3D location of each object by predicting a depth map and classifies the yaw angle by representing the pose domain as equally-spaced bins. To do so, during training the method operates on a short clip of the scene recorded by a moving camera, and uses self-supervision by predicting the scene\u2019s image at the next time step. At test time, the model is able to infer a representation of each object in the scene and segment them given a single image of the scene.",
    "This paper presents a method to learn how to parse 3-frame videos into object-centric representations, which include segmentation masks and 3D positions and yaws for those objects frame-by-frame, as well as an image representation of the background, and an overall depth map. This is accomplished with a depth network, an object network with an LSTM at the bottleneck to iteratively pick out objects and their positions and yaws, and a decoder to provide segmentations, a warping/re-compositing operation that pastes the inferred objects at their estimated positions for the NEXT frame (i.e., with a constant-velocity assumption), and finally an \"imagination\" network which refines the estimated image. The model learns with a combination of 4 losses, which include image reprojection/prediction, depth consistency, a spatial term that includes consistency and randomness (though I have complaints about this), and finally a penalty term that discourages object probabilities from being zero. The paper also introduces a new synthetic dataset where prior methods do badly, and the proposed method does slightly better. The learned depth maps look good, but this is perhaps expected because camera poses are known. ",
    "This paper presents an unsupervised object-centric scene representation technique that can decompose a scene into multiple objects (and segment the scene) and infer their 3D locations and pose. The overall setup is very similar to earlier models like MONet but this model works on sequences of images, more precisely on 3 consecutive images. It uses the first two images to infer the 3D position and pose of objects and combining this with known camera motion tries to predict the last (third) image. The main contribution here is an optical flow based method to warp the image at time t using the predicted object location/pose/depth to predict (some of) the pixels in image at time t+1.  In more detail, the object extraction network outputs the location and pose of each object. And a separate depth perception network outputs the depth for each pixel in the image. The location and pose of objects are used to estimate the velocity of each object (e.g., by subtracting the position at t-1 from position at t. note this requires matching each object at time t-1 to object in time t, which they do using a soft-matching approach). These along with the depth information are then used to warp the image at t to predict pixels in image at time t+1. This is possible only for a subset of the pixels so for the rest, they use a separate \"imagination\" network that takes in object information and predicts the color/depth and object masks at t+1. The predictions from warping and imagination network are then combined to form the final predicted color and depth images.  To train the model, they require images and camera motion, and use a combination of losses: reconstruction loss on predicted and ground truth image, self-supervised losses on object location, pose, and depth.  ",
    "Inspired by ideas about how humans learn about objects, the authors detail a system to train a neural network to perceive generic objects using image triplets where objects move and the viewer also can move.  The viewer's motion is provided as an input. Object perception by parts of the network operating on the first two time points is rewarded by predicting what is seen at the third time point (the training signal). Having been trained, the object perception part of the system, which is a relatively basic neural network, can segment them from a single image.  This new setup requires different data that what has been used in this space, and the authors contribute a synthetic dataset as well. ",
    "The paper proposes a VAE model for mobility forecasting. It focuses mainly on the disentanglement of spatial and temporal features by modelizing explicitly two groups of features in the VAE schema, a group of spatial features that are time-independent and a group of temporal features using a sequential prior. In order to make a prediction, the VAE is used to extract features from three groups of sequences describing the trend, the period, and the last few timesteps before the forecasting period.  An ablation study is provided concerning those three groups of sequences. Experiments show competitive results wrt SOTA.",
    "This paper proposes learning a disentangled representation of spatio-temporal mobility data using a VAE-based architecture, which essentially tried to decompose spatial and temporal features and model them independently. Disentanglement in the learnt representation is encouraged through the introduction of total correction as a regularization term in the VAE loss. The authors empirically demonstrate the potential of the proposed approach in 3 different mobility datasets (BikeNYC, TaxiNYC and TaxiBJ). Overall, the results suggest competitive predictive performance with other state-of-the-art approaches.",
    "This paper proposes a variation of the Variational Autoencoder (VAE) model to learn disentangled spatial and temporal representations from ST raster data. A separation module is designed in the proposed network. The proposed model is validated on three real-world datasets and achieves better performance compared with the baselines listed in the paper.  ",
    "The authors propose a novel neural architecture to structurally learn disentangled spatio-temporal representations in the context of mobility forecasting. This work argues that predictive models can benefit from enforcing the independence of spatial and temporal dynamics and proposes a VAE-inspired architecture for doing so.  By conducting experiments on three mobility datasets, the authors empirically evaluate the prediction performance of the proposed approach against various baselines. Additionally, further experiments attempt to (i) quantify the effectiveness of different temporal features (short-term/daily/weekly correlation), and (ii) formalize and justify a strategy for feature selection.",
    "This paper introduces a novel model, HeTVAE, for probabilistic interpolation of time series that are irregularly sampled. HeTVAE builds on prior work by complementing it with a learned time-dependent output variance in the VAE and architectural improvements. The latter include a new branch accounting for the distribution of the sampled timestamps in the series and the addition of a deterministic branch bypassing the stochastic variational latent variable. The performance of HeTVAE is evaluated on multiple datasets against various baselines and via ablation studies.",
    "This paper introduces a VAE-based model for interpolation of irregularly sampled time series. The temporal input data is mapped to a latent representation over fixed reference points with an attention mechanism, using an intensity network that allows to encode data sparsity information. This latent representation can then be used to interpolate points at new time steps. Thanks to the intensity network and the heteroscedastic output layer, the proposed HeTVAE model can capture uncertainty estimates over the interpolated points.  The model is tested on a number of datasets containing irregularly sampled points, and outperforms competing methods in the interpolation task.",
    "The paper introduces a novel model of Variational Autoencoder that deals with irregularly sampled time series with a probabilistic approach to do time series interpolation.  The main contribution is the architecture by itself, its components, and the training process.  The model was evaluated on both real-world data sets from the medical and climate domain and synthetic data. ",
    "This paper introduces several improvements over the previous work mTAN to better support probabilistic interpolation. Specifically, intensity encoding is introduced to make the model be aware of information about input sparsity. Also, the homoscedastic output distribution used by previous work is replaced by a heteroscedastic distribution. Experiments results show that this improved model (HeTVAE) achieves both better likelihood estimation and mean prediction compared to previous works.",
    "This paper seeks to answer whether modern DNNs are modular and proposes statistical methods to quantify modularity. In this study, DNNs are described as modular to the extent they agree with 2 prototypical conditions of modularity, namely importance (which is mainly captured by the drop in accuracy after removing a candidate module) and coherence (which would measure the extent to which neurons in a single module are .activated by similar features). These proxies for modularity, importance (with respect to task performance) and coherence (degree of specialization), are computed based on two well-known DNN interpretability techniques, namely lesions and feature visualization.  ",
    "This work aims to quantitatively evaluate modularity in neural networks (although, as detailed below, I am not sure this is what it ends up doing). To this end, the authors propose to cluster the neurons of the network using spectral clustering applied to a graph that is weighted by similarity between the neurons. They consider two approaches for defining similarity - either via similar responses to inputs (using Spearman or Pearson correlation) or by taking into account the weighted connections (leveraging the learned network weights) between them. There are some technical details regarding the division to layers, exact implementation, and especially the consideration of convolutional architectures (where certain neurons are grouped together along channels), which I will not refer to much here for brevity, but suffices to say that these are all well described in the manuscript and make sense without much need for justification. Once the clusters (or \"subclusters\" when divided to layers) are obtained, they are evaluated empirically to related them to the network's task. This portion is mostly based on image classification tasks, so clusters are evaluated based on their impact on classification accuracy, their importance in identifying each class, or coherence of visual features captured by them. The results are somewhat inconclusive (more details below), but it is appreciable that the authors do acknowledge this in a well balanced discussion section.",
    "In this work the authors provide an empirical definition of 'modularity' of trained deep networks. Their definition is \u2018automated\u2019 in the sense that is does not require any human identification and evaluation of the specific modules.  The proposed definition consists in the following steps.  1) Construct an undirected graph from the nodes and weights of the trained-network  2) Divide the graph in groups using a spectral clustering algorithm  3)  Define \u2018subclusters\u2019 as the sets of all nodes that are in the same cluster and in the same layer  4) For each subcluster compute an *importance* score and a *coherence* score  5) If the sub-clusters are more important and coherent than randomly defined groups of nodes of the same size than the network is said to be \u2018modular\u2019.  The *importance* of a group of nodes is computed as the loss of accuracy that results from masking to zero that group of nodes. The greater the loss of accuracy, the greater the importance of the group.  The *coherence* of a group of nodes is computed as the maximum magnitude of the pre-activation weights of the group that is achievable with a single image.  By numerical testing, the authors find that it is indeed possible to find groups of nodes that are more important and coherent than random in a statistically significant way for different architectures. ",
    "This paper uses graph-based clustering methods to identify the humanly comprehensible modularities in the neural network. They thoroughly discussed how they construct the graph of neurons and carry out the clustering. They also proposed the fisher bates p-value for testing the significance of identified modules.",
    "This paper conducts comprehensive analyses of lottery tickets hypothesis on automatic speech recognition. The authors verified the existence of highly sparse \u201cwinning tickets\u201d in ASR task, and analyze its robustness to noise, transferable to other datasets, and supports with structured sparsity. They conduct experiments on different model structures (CTC, RNN-T, Transfomer) and different datasets (LibriSpeech, TED-LIUM, Common Voice) with extensive analyses. ",
    "In this paper, authors propose to use lottery ticket hypothesis (LTH) for ASR model pruning. The whole idea generally inherits from the original LTH paper. The model is first trained from scratch. Then you collect all the model weights and sort them. A proportion of the smallest weights are set and fixed to 0. Given this sparsified subnetwork, one further repeats the whole process and prune more parameters. After several rounds, if the pruned subnetwork still gives at least the same performance of the original full network , it is called a \"winning ticket\". The \"winning ticket\" subnetwork should be lightweight, transferrable, and noise-robust. This work applies LTH to 3 models (CNN-RNN CTC, RNN-T, Conformer) on 3 datasets (TED-LIUM, Common Voice, LibriSpeech). The authors empirically show  1. The winning ticket exists for each method. The subnetwork could be only 4.4% size of the original full model, but still matches the performance. 2. Compared to other pruning methods, LTH performs best. 3. LTH with pretrained model performs better than LTH with random initialization.  Furthermore, the paper shows 1. One can enforce block sparsity for pruning to facilitate chip design. 2. The winning ticket can transfer to a new dataset and work well. 3. The pruned network is noise-robust. ",
    "This paper investigates using the lottery tickets hypothesis (LTH) strategy for pruning neural network weights for speech recognition. The method first explains the general LTH framework and extensions with transfer learning scenarios. The paper shows the effectiveness of the proposed method in the standard ASR tasks, pre-training with other models, and transfer learning, especially in noisy speech recognition tasks.  Some comments: - In the introduction \"End-to-end automatic speech recognition (ASR) (Wang et al., 2019)\": (Wang et al., 2019) is not a representative paper of end-to-end ASR - In the introduction, \"For example, the recognition of speech recorded by distant microphones is challenged by acoustic interference such as noise, reverberation and interference speakers (Kinoshita et al., 2020)\": Again not sure (Kinoshita et al., 2020) is a correct citation. I think the following papers are more appropriate   - Haeb-Umbach, Reinhold, et al. \"Speech processing for digital home assistants: Combining signal processing with deep-learning techniques.\" IEEE Signal processing magazine 36.6 (2019): 111-124.   - Kinoshita, Keisuke, et al. \"The REVERB challenge: A common evaluation framework for dereverberation and recognition of reverberant speech.\" 2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics. IEEE, 2013. - Currently, data augmentation techniques (artificially contaminate the clean speech with various noisy data) are more standard than transfer learning for noisy speech recognition. Please discuss it. - Section 2 \"On the model level, compared to CV models, speech models are mostly based on RNN backbones\": I'm confused about this description. As you mentioned in the previous paragraphs, many speech models now use transformer, conformer, and CNN. - Section 2 \"with 10ms shift is 1,000\": this is not exactly true as we usually use downsampling at the beginning of the encoder layer. - Section 3, RQ3: Frankly, I don't think this is an essential question for me. This sounds very trivial that the use of pre-trained models would improve the performance. - Section 4, What is the main message of Figure 1? I don't find the particular effectiveness of the proposed method from this figure/example. - Section 4, Table 3: Why are the other methods, especially KD-based methods, so worse? - Section 5 \"A common way to address this issue is through speaker adaptation (Zhao, 1994;\": Again, I don't think (Zhao, 1994) is a representative paper for speaker adaptation. MAP/MLLR adaptation techniques exist in this era, and they were standard techniques in the GMM era. - Section 5: I recommend the authors use the real noisy speech data like the CHiME data   ",
    "The paper explores the lottery ticket hypothesis, i.e., the existence of highly sparse subnetworks that can be trained in isolation without sacrificing the performance of the full models within the context of ASR. The authors show that it is possible to find subnetworks which contain just a fraction of the number of parameters of the full models without sacrificing performance on ASR. Three different architectures are considered and results reported on 3 datasets. Additional studies investigating the transferability and robustness of the sparse subnetworks are also conducted.",
    "In this paper, the authors propose some modifications to the classic ResNet architecture and initialization scheme, so that the network can be trained with fully deterministic initialization, even without any normalization layers. The authors motivate their design choices by identifying and analyzing the problems with the forward and backward dynamics of some naive ideas. Then the authors present their approach and explain why each choice they make can solve the specific problems they have presented. Then they evaluate their proposed method along with some baselines on two popular image classification datasets, showing that their deterministic initialization method is on par with the ones with random weight initialization. Finally, they present related work and conclusion.",
    "To initialize a ResNet with only zeros and ones, this paper analyses the problem of all-zero initialization and then proposes a  method named ZerO to achieve the goal by augmenting the standard ResNet architectures with a few extra skip connections and Hadamard transforms. The proposed idea is interesting and somewhat novel. However, it seems to introduce a new structure rather than only initialization, and empirical results are not really good.",
    "The paper proposes a deterministic weight initialization scheme called ZerO for residual networks.  ZerO works by first augmenting existing ResNet architectures with extra skip connections and Hadamard transforms and then initializes network weights with only zeros and ones (instead of random weights). The authors show that the proposed scheme has various benefits such as improving reproducibility, training networks without batch normalization, and improved performance.",
    "This paper proposes a new initialization scheme for ResNet. The key feature is the initialization values are set to all zeros and ones, rather than random. The development of this initialization scheme is motivated by avoiding the \"dead neuron\" problem and \"training degeneracy\" problem for networks with zero-initialized weights. Some toy examples are discussed to illustrate the motivation. Last, experiments on standard benchmarks are conducted to verify the initialization scheme.",
    "This study investigates defense against backdoor attacks for models that have already been trained. It proposes, in particular, a min-max formulation for backdoor defense, in which the inner maximum seeks a powerful trigger that leads to a high loss, while the outer minimum seeks to suppress the \"adversarial loss\", so as to unlearn the injected backdoor behaviors. To solve the minimax, the authors also propose a method, Implicit Backdoor Adversarial Unlearning (I-BAU). In addition, the authors also provide theoretical analysis including the convergence bound and generalization bound. Extensive experiments demonstrate the effectiveness and efficiency of the proposed method.  ",
    "The paper formulates adversarial training against backdoor poison attacks and proposes to use implicit hypergradient to solve the minimax problem instead of breaking it down into separate inner and outer optimization problems. The authors perform theoretical analysis of the algorithm and find convergence bound and generalization bound for the method. Also, the authors evaluate the proposed adversarial training routine, called I-BAU (Implicit Backdoor Adversarial Unlearning) in three attack settings:  (1) One-trigger-one-target attack, (2) One-trigger-all-to-all attack, (3) Multi-trigger-multi-target attack and compare with six defenses. For each attack setting, the authors test 7 different backdoor attacks. The results show that the efficiency of I-BAU is comparable to the best baseline for each of the attacks and is more time-efficient than other defenses. Finally, the authors show that I-BAU leads to a more stable training comparing to using universal adversarial perturbations in adversarial learning. ",
    "In this paper, the authors proposed a minimax formulation for removing backdoors from a given poisoned model based on a small set of clean data. Unlike previous work, which breaks down the minimax into separate inner and outer problems, the proposed algorithm utilizes the implicit hypergradient to account for the interdependence between inner and outer optimization. The authors also theoretically analyzed its convergence and the generalizability of the robustness gained by solving minimax on clean data to unseen test data. Extensive experiments showed improved backdoor defense performances and less computation time on several backdoor attacks over various attack settings.",
    "The paper studies the backdoor attack problem and proposes a minimax formulation for the defense against adversaries. Theoretically, the paper analyzes the convergence bound and the generalization bound for the proposed method. Empirically, the paper compares efficacy, stability, sensitivity, and efficiency with several competitive methods.",
    "# === Update ===  I have decided to maintain my score. This is very strong submission in my opinion. A brief overview of my thoughts is the following:  **Topic**: This paper comes in the middle of a wave of interest in permutation SGD and similar variants. It is highly topical and a good fit for the conference.  **Theoretical Results**: It is easy focus on FlipFlop and its limited analysis (i.e. quadratics only), but there are many other highly interesting results in this submission. Theorems 1 and 2 show that one-dimensional functions are \"easy\" for permutation-based optimization, while quadratics in higher dimensions are hard. Yes, this result requires a fixed step-size, but it is also the first analysis of permutation SGD conducted on the level of specific permutations. Theorem 3 refines these results to show that the improvement in Theorem 1 is specific to quadratics. The proof technique for these results is elegant (continuity of the composition of updates + IVT) and, as a I noted in my review, leads to useful intermediate results.  **Experiments** The experiments are limited to synthetic data, but this is a theoretical paper with ~37 pages of appendices already. I think that an intensive evaluation of FlipFlop is beyond the scope of this submission. Moreover, since the analysis considers quadratics only, I think that the nice results on logistic regression in Appendix H are quite encouraging.  # ======  This submission analyzes the effects of permutation choice on the convergence of the random-reshuffling, shuffle-once, and incremental variants of stochastic gradient descent (SGD). In particular, the goal of this work is to determine settings whether specific permutations can give faster convergence than random reshuffling and in what settings.  The authors show that, in the case of one-dimensional finite-sum functions with smooth Hessians, there exists a sequence of permutations for which SGD converges at a linear (i.e. exponential) rate.  However, they also prove that this phenomenon is specific to one-dimensional functions using a new, dimension-dependent lower bound for any permutation-based SGD method. This lower bound is tight with the known convergence rate of random reshuffling, implying this method is optimal in the general setting. Finally, the authors restrict themselves to finite-sums of convex quadratics and develop a simple heuristic permutation \"schedule\" giving provably faster convergence.  This approach, which is called FlipFlop, alternates between fresh permutations and the previous permutation, but in _reverse_ order. Small experiments confirm that FlipFlop accelerates convergence of permutation-based SGD variants. ",
    "This paper is motivated by the observed phenomenon that, in stochastic gradient descent (SGD), without-replacement sampling (random permutation) gives faster convergence than with-replacement sampling. The paper studies whether random permutations are optimal among permutation-based SGD, by considering different deterministic, random, or hybrid ways of generating permutations of input points.  Focusing on optimizing convex functions at a constant step size, the paper shows that: 1. there exist optimal permutations which converges exponentially faster than random permutations for 1-dimensional functions. 2. such improvement is not possible in higher dimensions or for strongly convex objectives, where random permutations are optimal. 3. by reversing the permutation every other epoch (flipflopping), convergence on quadratic functions improves for three permutation-based methods: Incremental Gradient Descent (deterministic), Random Reshuffle (random), and Single Shuffle (hybrid).",
    "This work investigates the optimality of random permutation as a scan ordering for SGD. They found that for general strongly convex functions with Lipschitz Hessian, random permutations are optimal in high dimension but not optimal in 1-dimension. For general convex quadratics, random permutations are also not optimal. Finally, the authors introduced a new technique termed FlipFlop that works by reversing the permutation of the previous epoch at every even epoch, and at the odd epochs the algorithm just follows its original permutation, whether it be random or cyclic. FlipFlop has been proven to improve the convergence of random reshuffling, single shuffle, and incremental gradient descent on quadratic functions. Experiments on a 100-dimensional quadratic objective and 1-dimensional logistic regression demonstrate that FlipFlop indeed converges faster than random reshuffling.",
    "This paper studies theoretical properties of permutation-based fixed-step size SGD for finite sum optimization. The main theorems state that  * For 1-d Hessian-smooth functions, there exists permutations such that the convergence rate is exponential in the number of iterations $K$ * For higher dimension, there exists strongly-convex function such that the convergence rate is at best $O(1/K^3)$ * If some component in the strongly-convex objective function is nonconvex, the convergence rate has a lower bound $O(1/K^2)$  The paper then proposes the algorithm FlipFlop, where adjacent epochs use permutations of reverse order. The algorithm is proved to improve upon random permutation when all the component functions are quadratic. The results are corroborated with simulations.",
    "This work provides the novel approach for searching flow architectures. Compared to the standard approaches used to find the best deep architecture in standard network networks this problem is more challenging due to the need of invertible transform and requirement for determinant of the Jacobian to be easy to calculate. To solve the problem the authors propose to apply the weighting for candidate transformations. In order to enforce invertible properties of the model the authors suggest to use the mixing distribution approach instead of mixing the base transformations. They formulate the problem of learning best weights and show that optimal solution for soft weights is not optimal for binarised versions. Therefore they propose to optimize the upper bound of the proposed loss function instead. Further they show how to deal with the problem with larger number of layers. Some experiments are also performed to show the quality of the approach with respect to the baseline that is expert-based selection. ",
    "In this paper, the authors proposed to adapt a differentiable architecture search formulation (Liu et al., 2019) based on learned weighting of an ensemble of modules to automated search for Normalizing Flow architectures. The authors made several adaptations to the original approach for the normalizing flow problem, due to the invertibility constraints that prevent direct linear summation of different transform operations. Furthermore, the authors proposed to optimize the full network using an approximated upper bound of the KL divergence, instead of directly optimization. The authors proposed two methods to decompose the optimization problem: grow method, which is more straightforward and greedy, and block method, that alternatively adjusts each block. The authors experimentally compared their proposed method with manually specified architectures across various datasets, including POWER, GAS, HERMASS, MINIBOONE and BSDS300. The results seem mixed, as the searched model outperforms the manual model in some contexts but not others.",
    "This paper proposes a DARTS-like method for searching automated normalization flow models. Instead of directly using the output ensembles, which leads to infeasible flow models, this work proposed distribution mixture to guarantee that the supernet is always a valid flow model. The upper bound of the loss function is optimized jointly with resource constraints. Experiments on small-to-medium scale datasets valid the effectiveness of the proposed method.",
    "In this paper, the authors present an automated normalizing flow(NF) architecture search method. The method employs a mixture distribution formulation that can construct an optimal flow model with n layers of transformations from the transformation set. Besides, the authors introduce a block-wise optimization method to deal with exponentially growing optimization complexity. In the experiment, the authors proved the effectiveness of the optimization method which via approximate upper bound. And AutoNF has a better performance-cost trade-off than hand-tuned SOTA flow models. ",
    "This paper tries to give a measurement method to evaluate the learned model, which is highly correlated with the final test accuracy. The measurement method depends on two key factors: Intrinsic Dimension (ID) and CLuster Learnability (CL). This paper claims that the model with higher ID and CL performs better. Using ID and CL to predict top-1 accuracy can achieve a Pearson correlation coefficient of 0.93, which is better than existing predictors (e.g., alignment and uniformity). Inspired by the above observation, this paper proposes a modified DeepCluster algorithm to increase the final performance.",
    "This paper proposes two metrics for assessing the quality of self-supervised learning representations in terms of expressiveness and learnability. Expressiveness expects to maximize the mutual information between the representation and the original data, while learnability emphasizes the representation suppose to be simpler and more learnable. Based on these two intuitions, the author applies Intrinsic Dimension (ID) and Cluster Learnability (CL) as the measurements of expressiveness and learnability respectively to predict downstream classification performance. The authors collect 30 checkpoints of recent self-supervised methods to validate the proposed metrics on two datasets, ImageNet and STL_10, and the results show a high correlation between the proposed metrics and the downstream classification performance.",
    "This paper proposes Intrinsic Dimension (ID) and Cluster Learnability (CL) as an alternative solution to efficiently evaluate learned representation quality of pre-trained networks, without using down-stream tasks/labels. These two frameworks are inspired by finding \u201cexpressiveness\u201d \u2013 finding the smallest number of variables to approximate the representation; and \u201clearnability\u201d \u2013 number of data samples needed for KNN clustering.  Extensive experiments have been evaluated on models trained with both supervised and unsupervised methods, and results showed that ID + CL would produce a high correlation with prediction accuracy from these methods, comparing to baselines. Finally, the authors argue that CL can also be incorporated into DeepCluster (an unsupervised method), as an auxiliary loss to further improve the prediction performance. ",
    "This paper proposes to use Cluster Learnability (CL) and Intrinsic Dimension (ID) to evaluate the representations learned by self-supervised learning methods. The authors collected 30 checkpoints and show that their method is more predictable when compared to other methods, e.g., alignment and uniformity. Moreover, the authors modified the labels generated by K-means in DeepCluster to improve the learnability of the representations and the results demonstrate slight improvements. ",
    "This paper proposes a black-box attack where, by relying on segmentation priors, the perturbation is applied only in the salient region. This allows one to obtain reduce perceptibility with a limited number of queries and a small reduction in success rate. More specifically, once the salient region has been identified, a refining procedure is carried out to find small areas where the perturbation should be added. Experiments are performed on ImageNet and results are compared with those of some SOTA methods and their variants that work on saliency regions.",
    "There has been a lot of interest in improving the query efficiency of black-box attacks in the recent past. However, these techniques produce examples that a human in the loop can quickly identify. The authors propose using segmentation priors to improve the black-box attacks so that the perturbations are restricted to the salient regions of the image. In addition to this, they also present a technique that improves the imperceptibility without forgoing the query efficiency.",
    "The paper studies how to reduce the perceptibility of the perturbations to the original images produced by black-box adversarial attacks (for the $\\ell_\\infty$-threat model). In particular, it proposes to use a prior based on segmentation techniques to localize the changes on the subject of the image and leave the background unaltered. Moreover, the Saliency Attack is introduced to further reduce the fraction of the original image which is modified to induce misclassification.",
    "This paper proposed a method to generate imperceptible attack in black box attack scenario by generating local perturbation blocks in salient regions. It used salient object segmentation to obtain the salient region, then applied a tree search method to find smallest blocks within the salient region that can cause the maximal change in predicted class logits. Experiments on 1000 Imagenet examples are conducted, compared to several existing baselines, showing that the proposed method can improve achieve more imperceptible attacks (where imperceptibility is measured by metric MAD).",
    "The paper proposes a GNN-based extension of transformers, which have been shown to be effective for reaction prediction etc. before. In particular, the GNN-based embedding of molecules in the reaction embeddings overcomes the artificial bias inherent in the often applied sequence embeddings. The experiments show that there are sometimes increases of performance in reaction and retrosynthesis prediction - and the approach could be applied to similar problems.   ",
    "This paper proposes a graph-to-sequence architecture called Graph2SMILES for the retrosynthesis and the reaction outcome prediction. Graph2SMILES uses an attention-augmented D-MPNN encoder to capture the local information and a global attention encoder with graph-aware positional embeddings to capture the global information. Experiments show that Graph2SMILES is competitive with Transformer baselines but does not outperform state-of-the-art methods on tasks of the one-step retrosynthesis and the reaction outcome prediction. ",
    "The authors proposed a new method for retrosynthesis, which does not require the mapping numbers and extracting templates from the literature.  Basically, the model consists of a graph-based encoder and a sequence based encoder. The encoder consists of local aggregation from neighbors and global attention using a new positional method. The decoder is a Transformer model with relative positional encoding.  The method achieved promising results on several retrosynthesis datasets. ",
    "This paper proposes a graph-to-SMILES framework, which incorporates several recently developed engineering techniques from the community, for synthesis planning and reaction outcome prediction tasks. The proposed method leverages graph neural networks and Transformer attention model to encode the graph inputs and then utilizes a Transformer decoder to generate the SMILES string as outputs. Experiments on benchmark retrosynthesis and reaction prediction tasks show that the proposed approach outperformed the vanilla SMILES-to-SMILES transformer baseline, but obtained inferior results than some other advanced methods. The paper is interesting, but both the technical novelty and the experimental studies are weak to me.",
    "This paper introduces hierarchical reinforcement learning (HRL) into automatic disease diagnosis, which reduces the action space and improves training efficiency. Besides, the authors also expand an existing public dataset and build a synthetic dataset for evaluation. The Experimental results show that their proposed hierarchical framework achieves higher accuracy and symptom recall in disease diagnosis than existing several baselines. ",
    "##########################################################################  Summary: This works proposes dialogue policy learning by incorporating a hierarchical policy. The proposed hierarchical reinforcement learning-based approach has two models, i.e., one master model that instantiates low models. The low models have several symptoms checkers and disease classifier. Experiments are conducted on both real and synthetic datasets to demonstrate the efficacy of the proposed work.    ##########################################################################",
    "The paper tackles the problem of automatic disease diagnosis through reinforcement learning under a setting of task-oriented dialogues. The authors proposed to integrate hierarchical policies with two levels (one high-level master model, and one low-level policy) into the dialogue policy learning. Experiments on both real-life and synthetic data suggest the proposed approach is effective.",
    "This paper applies Hierarchical Reinforcement Learning (HRL) to automatic disease diagnosis in task-oriented dialogues setting. The authors argue that applying RL to automatic disease diagnosis is challenging because the action space (i.e., symptoms) is very large. Therefore, they propose to learn a hierarchical dialogue policy where the high level policy is for categorizing patents into different groups and the low level policy is for checking symptoms and classifying diseases within a group.  Experimental results on multiple datasets show that the proposed HRL strategy achieve higher disease diagnosis accuracy compared to existing RL systems.     ",
    "This paper introduces the self-supervised learning (SSL) framework for FL. Different SSL methods are investigated to study their feasibility under the FL setting. With the popular SimSiam framework, personalized federated SSL is proposed. The performance comparison indicates that representation regularization-based personalization method is able to outperform other variants.",
    "The authors merge self-supervised learning in personalized federated learning to solve the limited label and data heterogeneity problems in the local clients. They test several current algorithms under their framework. Then they propose an algorithm named Per- SSFL considering the balance between the consensus and personalization. Finally, they provide experiment results to support their claims and comprehensive analysis of what they find. The main contribution is to design a self-supervised FL framework with supportive experiment results. They also provide suggestions to choose appropriate algorithms and hyper-parameters under different settings.",
    "The submission is not anonymized, the author's name chaoyanghe appears frequently in the attached SSFL_Sumpplementary/SSFL-Source-Code. Therefore, it should be directly desk rejected.  --- Logging error --- Traceback (most recent call last):   File \"/Users/chaoyanghe/opt/anaconda3/envs/fedml/lib/python3.7/logging/__init__.py\", line 1025, in emit     msg = self.format(record)   File \"/Users/chaoyanghe/opt/anaconda3/envs/fedml/lib/python3.7/logging/__init__.py\", line 869, in format     return fmt.format(record)   File \"/Users/chaoyanghe/opt/anaconda3/envs/fedml/lib/python3.7/logging/__init__.py\", line 608, in format     record.message = record.getMessage()   File \"/Users/chaoyanghe/opt/anaconda3/envs/fedml/lib/python3.7/logging/__init__.py\", line 369, in getMessage     msg = msg % self.args",
    "This work is concerned with a very practical scenario of Federated Learning where the participating agents may not have access to labelled data. SimSiam architecture to learn useful feature representations with extensions that incorporate personalisation for local client models. The learnt representation are evaluated against a KNN classifier for analysing their usefulness. ",
    "This paper studied a ResNet-like DNN model that can be expressed as a discretization of PDEs. First, this paper showed that, under some assumptions, any adjust operator is a solution of a second-order convection-diffusion PDE (Theorem 1). ResNets and ResNets with Gaussian noise injection are special cases of this theorem. Next, for the specific PDE (Eq. (7)), this paper derived generalization guarantees regarding the Rademacher complexity. This paper also derived robustness guarantees in terms of input perturbations. Finally, this paper analyzed the predictive performance of ResNet trained by the proposed method with various model hyperparameters on clean and adversarial datasets.",
    "This paper considers DNNs as transformations of the input data which can be seen as discrete approximations to the solutions of PDEs. It reformulates a point of view which has been trending for a few years now. More precisely, this paper represents the network as an operator, which is actually solution to a PDE, which acts on a \"base classifier\". Using facts from PDE theory, they then propose improvements for standard neural architectures.",
    "This paper connects the architecture of a resnet and a gaussian injected resnet to that of a transport equation and a diffusion equation respectively. They show that under this framework they provide robustness guarantees of their PDE framework scale with the $\\sigma$ parameter of the diffusion equation. Furthermore, they also show that larger the $\\sigma$ better the generalization gap for the resulting neural network.   They introduce a learning algorithm, to attain the network from their PDE framework starting from an initial NN (also a resnet).  They also empirically verify that their method improves robustness, and that it performs better than Gaussian Noise injection.",
    "The authors cast DNN classifiers as the push-forward of a base classifier under a flow map at some fixed final time. Under some reasonable assumptions on the flow, they show that, given any base classifier, the flow map can be obtained as the solution to a convection-diffusion equation. They show that ResNets and Gaussian noise injection can be viewed as special cases of their model and give a robustness guarantee for any  classifier defined as a solution to their PDE. Experiments on the 2-d half moon data set as well CIFAR 10 and 100 show better robustness  of their model to adversarial attacks  when compared to standard ResNet(s).",
    "This paper studies the expressivity, complexity and unpredictability of emergent languages in referential games. The authors demonstrate that the expressivity of emergent languages is a trade-off between the complexity and unpredictability of the context that the languages are used in. They also introduce a contrastive loss based training method for referential games that alleviates the collapse of message types often seen when using other standard training methods.",
    "The authors investigate what aspects of scenario design affect the resultant communication protocol in emergent communication. Specifically, the authors investigate whether scenario complexity (in terms of having many similar distractors) and scenario unpredictability (in terms of future batches not containing items to previous batches) affect the expressivity (measured in terms of learnability) of the resulting protocol.  Further, the authors show that defining a softmax loss over the entire batch of possible references (dubbed the 'contrastive' loss) outperforms the 'referential' loss used in previous works. ",
    "This paper studies the \"expressivity\" of emergent language in language games. To my understanding, \"expressivity\" is empirically the transferring ability of the language to unseen data. In this paper, the authors propose two factors of the underlying language game that can affect the expressivity of emergent language: context complexity and unpredicability. In referential games, the context is the distractor candidates for a sample. Complexity denotes how likely a \"close\" distractor will be included in the candidates. Unpredictability is how likely the context for a single sample will be different among epochs. This paper proposed hypotheses that both context complexity and unpredicability can improve language expressivity, but these two factors are \"contradictory\" and we need to have a trade-off between them. The hypotheses are supported by empirical experiment results.",
    "The paper studies the properties of emergent languages in DL-based language games. In particular, they look at referential games where speakers emit messages and listeners need to identify the target object observed by the speaker from some set of candidate objects.    They define the expressivity of an emergent language as the amount of discriminatory information required to encode the inputs so that a listener can correctly decode them. In this setting, complexity refers to the similarity between different objects in a given context. In a context with higher complexity, more similar objects will be present, and more discriminatory information will have to be encoded so that a listener is capable of identifying the correct target. In their definition, the notion of unpredictability can be thought of as how stable the information necessary for encoding is across different trials.    Their primary contribution is to support the hypothesis that the expressivity of emergent language is determined by (and a trade-off between) the complexity and unpredictability of context in language games. The authors introduce a new measure to evaluate expressivity based on partial ordering between languages in terms of their generalization across tasks. They argue that mutual information is not the most appropriate measure to evaluate the expressivity of languages. They propose a contrastive loss which they show helps mitigate the issue of the collapse of message types. ",
    "This paper studies exploration bonus in practical deep RL based on Sample Average Uncertainty (SAU) and upper confidence bound (UCB). SAU is a recently studied novel uncertainty quantification that works for rather arbitrary estimators. Previous paper has studied how to use SAU to derive UCB-type bonus in multi-armed bandits and proved that it could achieve optimal regret.   This paper successfully extends the SAU-UCB-type exploration bonus from bandits settings to RL and most importantly, deep RL settings, and shows how to incorporate SAU-UCB-type bonus in (deep) RL. This paper conducts various experiments for RL and deep RL, demonstrating the advantage of their algorithms over the standard benchmarks.   The paper is generally well-written.",
    "This work introduces $\\delta^2$-exploration for reinforcement learning (RL), which aims to incorporate sample average uncertainty (SAU) into RL exploration. The authors discussed the background and formulation of SAU. The authors further propose $\\delta^2$-exploration, which incorporates SAU into Q-learning and compare such exploration with value-uncertainty exploration (UCB-type exploration) and $\\epsilon$-greedy. The author then proposes to incorporate $\\delta^2$-exploration into DQN and conduct experiments to compare $\\delta^2$-exploration with SOTA exploration algorithms. Empirical results show that $\\delta^2$-explorations attain comparable results to bootstrapped DQN.",
    "This paper extends a recently-proposed exploration method called SAU in bandits to the RL problem. They combine this exploration approach with the standard Q-learning algorithm. Their experiments show that this approach can obtain better performance compared with the Q-learning algorithm with eps-greedy exploration.",
    "The paper extends the recently introduced SAU measure from bandits to RL. The idea is to enhance the exploration of action based on an approximation of the estimation error. More precisely, the bonus is proportional to the average squared temporal difference error. This uncertainty measure is easy to compute and can be integrated into both tabular and continuous methods (e.g., Q-learning and DQN).",
    "The paper introduces an INR-based design that utilizes an MLP network to encode spatio-temporal dynamics of video. The authors also propose an efficient discriminator to detect unnatural motions. The design is an extension of INR-GAN (Skorokhodov et al., 2021) architecture. The paper claims that the method obtains SOTA performance on the UCF101 dataset. ",
    "This paper leverages the implicit neural representations paradigm to build generative adversarial networks for video generation. Implicit neural representations encode continuous signals into parametrized neural networks, and the authors claim that this mitigates the issue related to the inefficient modeling of videos as 3d tensors of RGB values. Their GAN includes an INR-based video generator, and a motion discriminator that is more efficient at identifying unnatural motions. Their approach yields FVD improvements in various existing datasets.",
    "The paper proposes a video generation approach based on implicit neural representations (INRs). They construct a \"dynamics-aware\" GAN; where by the generator model used derives from the coordinate-based models used to capture continuous representations of images in prior  INR work. The discriminator architecture derives from the 2D discriminator traditionally used in image GAN research; they simply expand the input channels from the traditional 3 channels (i.e. rgb) used; to 7 input channels. This discriminator processes a stack of images from one video simultaneously, two frames from different time points in the video and their difference image.",
    "The paper present a new method to video generation. They built on top of the INR-GAN framework and extend it to temporal domain. They, therefore, get continuous time and space image generation--something all other video methods lack (technically one should be able to interpolate motion codes of existing CNN-based works, but spatially none of them is continuous to my knowledge). They model a video as a function $f(x,y,t)$. They condition this functions on motion codes and on content codes. The upper layers get information from the content, the lower layers get information from both content and motion. They further introduce a discriminator that is conditioned on the time difference between frames. It allows them to train on longer videos.  ",
    "This paper considers differentially private multi-winner voting. This problem is a generalization of single-winner voting, which is widely used in PATE type private semi-supervised learning. The authors give three private mechanisms and perform empirical comparisons on multi-label semi-supervised learning settings.  Specifically, when there is no total votes constraint on each ballot, the binary mechanism performs report noisy argmax for each candidate. When there is a total votes constraint, the tau mechanism performs l2 clipping first and then performs report noisy argmax for each candidate as the binary mechanism. The powerset mechanism converts the multi-label problem into a single label problem and performs regular report noisy argmax. ",
    "This paper considers the design of differentially private multi-label mechanisms. In particular, the authors employ multi-winner voting protocols to existing differentially private single-label learning algorithms e.g. PATE. They consider three multi-label voting protocols -- binary voting, $\\tau$-voting and powerset voting.   Binary voting works by independently applying majority voting on each coordinate. It is obvious that such an aggregation mechanism has does not provide a better privacy guarantee than $k$ applications of binary voting. The privacy guarantee can be improved when the coordinates are dependent. This motivates the authors to consider $\\tau$-voting where the $\\ell_2$-norm of each ballot is bounded by $\\tau$. Finally, in the powerset voting, the voting is done over the universe of all subsets of the alternatives i.e. $2^k$ alternatives.  The authors make two important observations through experiments. First, when there is high consensus and $\\sigma_G \\rightarrow 0$, binary voting performs best. On the other hand, $\\tau$-voting outperforms with lower consensus and larger values of $\\sigma_G$. Second, even in centralized setting, multi-label methods outperform existing benchmarks.",
    "The authors study differentially private multi-winner voting, which is designed for multi-label learning subject to a privacy constraint meant to limit information leakage about training data to an adversary. They propose three mechanisms: Binary, which essentially runs an existing differentially-private election for each label independently, \\tau voting, which works with votes that have bounded \\ell_2 norm, and powerset voting, which explicitly encodes each possible subset of winners as an alternative in an election and then votes over them. They show that Binary voting (the naive approach) generally outperforms powerset voting as long as there aren\u2019t strong correlations between votes. Lastly, they show that they can use these multi-winner DP techniques to a extend single-label technique, PATE, and empirically demonstrate the effectiveness of their approach.",
    "Private multi-winner voting is the task of revealing k-hot binary vectors that satisfy a bounded differential privacy guarantee. They propose three new mechanisms. 1. Binary voting operates independently per label through composition. 2. \\tau voting bounds votes optimally in their l2 norm.  3. Powerset voting operates over the entire binary vector by viewing the possible outcomes as a power set. They prove that Powerset voting requires strong correlations between labels to outperform Binary voting.  They also use these mechanisms to enable privacy-preserving multi-label learning. They empirically compare techniques with DPSGD on large real-world healthcare data and standard multi-label benchmarks. Their techniques outperform all others in the centralized setting, and show that mechanisms can be used to collaboratively improve models in a multi-site (distributed) setting.  ",
    "The authors propose learning rate grafting as a method to explore the power and dynamics of optimizers. Learning rate grafting partitions the parameters of the networks into groups, and for each group takes the direction of the weight update from one optimizer and the magnitude from another optimizer. The paper then shows that grafting allows for achieving the performance of a tuned optimizer using that tuned optimizer's group-wise magnitudes along with an untuned optimizer's group-wise directions.",
    "This paper proposes a method called optimizer grafting. It uses two optimizers in one training session. One is to decide the update direction of parameters, and the other is to decide the update stride of parameters. This paper proposes a new optimizing mode and take a large amount of experiment exploration. ",
    "The authors report on a technique to address learning rate hyperparameter tuning for deep learning referred to as optimizer grafting. Specifically, the paper proposes a meta-algorithm (referred to as M#D) that blends the steps of two optimizers by combining the step magnitude of one (M) with the direction of the other (D). The technique of optimizer grafting allows for the transfer of the overall implicit step size schedule to a new optimizer, resulting in reductions in computational cost of optimizer hyper parameter search. The second primary result is leveraging the technique to identify a non-adaptive per-layer learning rate correction to SGD which allows it to train a BERT model to state-of-the-art performance. Analogous results are presented for vision models for global (non-per-layer) schedules for AdaGrad.  The authors describe grafting meta algorithm  (M#D) as, at each iteration, M#D feeds the same input (w_t, g_t) to both M and D which manage their states independently and produce w_M, w_D. Then the norms of the steps each would have taken is computed, and used to combine M\u2019s magnitude update with D\u2019s direction update. Partitioning is managed to implement global versus per-layer grafting.2 optimizer hyperparameter searches with the same computational budget, but different performances.  The authors present an empirical study on the transfer of implicit step size schedules between optimizers, comparing SGD and Adam to Adam#SGD for task of BERT pre-training. They show that Adam#SGD is able to achieve performance at/near Adam.   The paper also presents results for image classification for ImageNet and CIFAR-10), for AdaGrad, SGD, and SGD#AdaGrad, showing  SGD#AdaGrad outperforms SGD and AdaGrad. However, without error bars, it is hard assess the actual results.  Finally, the paper shows results for grafting distilling a non-adaptive correction to D, eliminating the need to run M in parallel - that is, transferring a global, time-dependent non-adaptive multipliers for the learning rate. The results show for the global variant for ResNET (SGD, AdaGrad), the discovered learning rate is comparable to the one used on SGD and achieves a top1 accuracy of 72.46. For the per-layer variant, learning rate schedule enables a simple per-layer step size correction without adaptive preconditioning. The authors present proof-of-concept results for simplifying the discovered schedule as a way to support the robustness of their transfer approach. ",
    "The authors investigate the entanglements between the optimizer and the learning rate schedule and propose  the technique of optimizer grafting, which allows for the transfer of the overall implicit step size schedule from a tuned optimizer to a new optimizer, preserving empirical performance. This provides a robust  plug-and-play baseline for optimizer comparisons, leading to reductions to the computational cost of  optimizer hyperparameter search. Using grafting, they discover a non-adaptive learning rate correction to  SGD which allows it to train a BERT model to state-of-the-art performance.",
    "This paper aims to improve the performance of RL in sparse reward settings via the guidance of sub-optimal demonstrations. The idea proposed by this work is to modify TRPO to restrict its updates to remain close to the behavior policy that generated the offline dataset, while decaying this constraint over time to enable the RL policy to improve upon the behavior policy in an online fashion. The authors do so by minimizing the KL divergence between the current RL policy and the behavior policy while not moving too far away from the current RL policy. The method is evaluated on openAI gym style tasks as well as a real robot navigation task. ",
    "This paper presents \u2018LOGO\u2019, an extension of the TRPO algorithm which enables additional learning guidance from offline, sub-optimal (possibly incomplete observation) demonstration data. By annealing away the learning contribution from the sub-optimal guidance policy data during training (with a learning schedule and corresponding hyper-parameter), LOGO utilises this data for guidance, rather than directly imitating it. Furthermore, because LOGO utilises the trust-region methodology, the authors are able to provide a theoretical analysis and lower bound on performance improvement each episode. The method shows promising performance on several MuJoCo continuous control tasks, as well as in a Gazebo TurtleBot simulation, which is also able to be transferred to a real-world robot.",
    "This paper considers the problem of reinforcement learning with sparse reward functions obtained from offline demonstration. The authors propose a trust region policy optimization based algorithm with offline demonstration data for guidance. The proposed LOGO algorithm is proved to be efficient by a theoretical analysis showing the lower bound on the performance improvement. On benchmark datasets, the proposed algorithm performs better than the state-of-the-art approaches. An illustration is shown by implementing LOGO on a mobile robot for trajectory tracking and obstacle avoidance.",
    "In a regime where we have access to offline behavior data from a suboptimal policy (a heuristic, human demonstrations, etc) we can use that data and \"trust region\"-based methods (TRPO in this work) to nudge exploration in the right direction by keeping the learnable policy close to the behavioral one. While there are several works exploring this general idea, the particular way presented in this work is novel and achieves better results on a set of MuJoCo environment. The approach is also shown to work on a physical robot (Turtlebot).",
    "This work proposes a Hybrid Neural Pareto Front (HNPF) framework to solve multi-objective optimization problems. The proposed method needs to first generate a huge number of feasible solutions to cover the whole decision space (e.g., random sampling in this work), and then use a two-stage approach to select the Pareto optimal solutions. In the first stage, it builds a Fritz-John Condition (FJC) based neural network to verify the weak Pareto optimality for given solutions. In the second stage, it further filters the truly strong Pareto optimal subset from the obtained solutions. Experiments have been conducted on several low-dimensional problems to validate the proposed method's performance. ",
    "This paper has two contributions. First it argues for the need to benchmark multi-objective problems  using analytic functions for convex and non-convex conditions. Second, it presents a two-stage method for finding the Pareto front. ",
    "This paper intends to find points on the Pareto frontier of a multiobjective optimization problem. Despite other baseline methods for this problem, they claim that their proposed algorithm is suitable for non-convex optimization, and their solutions are evenly spread across the frontier. Also, their algorithm can handle constraints for the MOO problems similar to solutions proposed in existing operation research methods. Empirical evaluations show that the proposed algorithm can find Pareto points and omit non-dominated points in the final stage.",
    "The authors present key shortcomings of MTL solvers in addition to Hybrid Neural Pareto Front (HNPF) that aims to handle non-convex functions and constraints.  The authors claim the following contributions: - New strategy for weak Pareto front identification based on Fritz-John conditions. - New Pareto filter to remove dominated points from the weak Pareto front. ",
    "The paper introduces a representation consolidation method to properly aggregate the pre-trained knowledge from multiple teachers for transfer learning. It claims that a generalist teacher is necessary for preserving the transferability of distilled representations, and task-specific teachers contribute to better performance in the same-domain downstream tasks. The introduced method performs on par with multi-task training while neglecting the need for teacher datasets.",
    "- The authors propose a method of learning a consolidated image feature representation from a collection of related task-specific teachers that transfer well on novel recognition tasks.  - To achieve it, the authors utilize multi-teacher multi-task model distillation framework that jointly distills one or several task-specific teachers with a generalist one (trained with Imagenet dataset).   - Each teacher is set to operate on a different set of classes, and a multi-head student is trained to emulate all teachers.  - Experimental results show that the proposed method doesn\u2019t need to revisit original training data of each teacher, but gains better performance. ",
    "The paper proposes a task-agnostic Knowledge Distillation method that includes a generalist model as an additional teacher, to limit student forgetting and representation collapse. The authors call this method representation consolidation and claim it can benefit both related and unrelated downstream tasks. The authors experiment with ImageNet and iFood image classification tasks, the accuracy of the proposed method is generally higher than using Knowledge Distillation only.",
    "This paper studies the problem of multi-model consolidation, which aims to merge (consolidate) the knowledge from multiple models into one model so that we can better transfer this merged model for downstream tasks. Different from the traditional knowledge distillation or multi-teacher distillation, the proposed method aims to transferability of merged models for the downstream tasks, whilst achieving good performance on source tasks. The key technique (technical contribution) is to add a generalized model during the knowledge distillation, which can be regarded as s \"special\" teacher model.    The authors conduct extensive experiments on multiple datasets and most of the experiments are under a few-shot linear probe transfer learning setting.",
    "This paper proposes conformal methods for learning a predictive confidence set that is guaranteed to be nearly the most statistically efficient among predictive confidence sets produced by a parametric class of learning algorithms. To explain, many wrapper methods for assessing prediction uncertainty assume that the user has already committed to one particular learning algorithm and aim to quantify uncertainty in predictions produced by using *this* learning algorithm. By contrast, the methods proposed here assume that the learning algorithm has been specified only up to some parameter $\\theta$ so that it makes sense to optimize $\\theta$ with respect to the precision of the resulting predictive confidence sets.  From the point of view of practical implementation, the obvious challenge is the optimization of $\\theta$ (as well as the associated prediction sets) over an arbitrary and large space of possible values of $\\theta$, as the optimization involves a hard constraint. Thus, one main contribution of the paper is to propose a differentiable proxy that allows an efficient search over the parameter space. Regarding theoretical guarantees, the paper proves that the original, non-differentiable formulation of one of the methods achieves approximately valid coverage and nearly optimal statistical efficiency when the class of learning algorithms has a low capacity.",
    "This paper considers to improve efficiency of conformal prediction (measured in the \"size\" of prediction sets). To this end, this paper uses multiple-learnable parameters by generalizing single-parameter conformal prediction. By doing so, the paper demonstrate that the proposed approach can improve the efficiency of conformal predictors while satisfying valid coverage. The efficacy of the proposed approach is demonstrated over regression, multi-output regression, and classification.",
    "This paper generalizes the standard conformal prediction calibration setup to a constrained empirical risk minimization problem. Specifically, this work seeks to optimize some efficiency loss, while satisfying coverage constraints. This formulation allows for the introduction of multiple, learnable parameters which can help find a better set-based predictor. The paper explains the implications of this approach by analyzing the generalization error that may occur when transferring the solution learned by constrained ERM to a test population. It also explains practical ways of learning this problem via differentiable surrogate losses and Lagrangians. Contributions-wise, the paper contributes validating theoretical analysis that proves that this method can achieve approximate coverage and near optimal efficiency for certain set-function classes. It also empirically shows that the proposed method can improve over baselines that are not directly optimized for efficiency. ",
    "This paper introduces an extension of conformal prediction with a different formulation. Instead of guaranteed coverage for a finite calibration set, the authors solve a constrained optimization problem where the length of prediction intervals is minimized subject to a coverage constraint. As a result, coverage is only asymptotically guaranteed, but instead the length of the prediction intervals can be shortened compared to traditional split conformal prediction.   The authors present theoretical results in the form of coverage bounds for specific function classes.   In the experiments classical regression datasets are analyzed, as well as multi-output regression problems and one multi-class classification problem. ",
    "This paper proposes a new method for the task of query object localization. It learns an embedding network such that the image crop that is closer to the query object will have a closer embedding distance as well, and the improvement of the embedding distance will be used as the reward function. The RL agent is then employed to maximize the reward. The paper found that the proposed approach compares favorably to DDT on object location on CUB and FTA on few-shot object detection on COCO.",
    "The paper proposes a reinforcement learning approach for localization in images. The idea is to consider and environment where the states are crops of an image, the actions are changes in the current coordinates of the current crops starting at the full image. The method consists of learning both a reward function and a policy that maximizes that reward function. The policy is learnt with REINFORCE with entropy regularisation. The manner in which the reward function is formulated and learnt is quite appealing. To allow for more flexibility at test time, the reward function is made conditional on some exemplars and learnt in a few shot manner based on state features. Using a triplet loss to ensure the reward function is increasing as the overlap is increasing is quite good.  The experiments are quite extensive and I find compelling for the most part. Ablation of the elements of the method is well executed and benefits of few short learning are compelling enough in my opinion. The results on COCO are a bit limited but I would be willing to overlook that.   ",
    "This paper presents a new metric learning method on the RL formulation of query object localization. The metric learning method is based on a contrastive learning formulation of ordinal embeddings, which are pretrained with data augmentations and a loss formulation that respects IoU orderings. The experiment results have demonstrated that the proposed embedding metric increased the task performance compared with the baseline metric (IoU), and shown better generalization behavior on novel image categories. ",
    "This paper extends works performing RL-based object localization by: 1. Conditioning the localization on a exemplary set of images, instead of more classical hardcoded finite set of classes 2. Introducing a new reward signal which doesn\u2019t explicitly use IoU but instead enforces a rank-preserving metric space (where distances reflect how well 2 bounding boxes match up).  This is shown on multi-MNIST data, CUB and COCO. They are targeting rather challenging generalisation setups, where a policy is only trained to localize 1 digit class (in the MNIST case say) and extrapolates to all other ones. ",
    "This paper proposes a new attention mechanism in vision transformers, which is called quadtree attention. This quadtree attention mechanism builds token pyramids and computes the attention in a coarse-to-fine manner. At each level, only top K regions with the highest attention scores from query and key are selected for further attention computation on finer tokens, while other regions simply use (current) coarse attention as a part of output. In the empirical study, the proposed quadtree attention achieves good performance on a wide range of vision tasks (e.g. feature matching, stereo matching, classification and object detection) with less computation.",
    "The paper proposed an attention approach to handle the global or long-range attention by leveraging the idea of quadtree structure, meanwhile reducing the quadratic complexity of original attention operation to linear. Experiments are performed on several tasks, e.g. feature matching, image classification, and objection detection. Superior results are achieved on these tasks. ",
    "This paper aims to address the quadratic computational complexity of vanilla Transformers. The key idea is to build token pyramids and computes attention in a coarse-to-fine manner, which reduces the computational complexity to linear. The resulting attention paradigm forms a quadtree structure, and two variants, QuadTree-A and QuadTree-B, are further proposed to improve message aggregation. Experiments are conducted on four different computer vision tasks involving either self-attention or cross attention. Results show that the proposed approach matches the state of the art with much fewer FLOPs and model parameters.",
    "The paper proposes an efficient attention algorithm based on quadtree for vision transformers. It establishes a feature pyramid for tokens and aggregates sparse key-value features in each pyramid level. The method achieves competitive performance on the stereo, image classification and object detection.",
    "The authors propose an objective for learning a diverse set of options in which the goal is to maximize the entropy of terminating states from any initial state while at the same time minimize the entropy of terminating states given a specific option.  Intuitively, this means learning options that tend to be deterministic, while at the same time are able to reach diverse terminating states. The authors then evaluate against other option learning frameworks in a series of diverse environments.",
    "The authors propose an HRL algorithm that uses the VIC objective to discover the options, i.e., the termination condition of the options is trained to maximize the mutual information between the set of options and their terminating states. These options are first trained without access to a reward function in an unsupervised manner. Later on there are experiments that show how an RL agent can re-use these options in downstream tasks. ",
    "The paper presents an approach for learning diverse temporally extended and reusable options. It is based on the assumption that learning diverse options are generally useful for downstream tasks. Thus, the approach aims to discover options without making any assumptions about the downstream tasks. The main idea behind the approach is to discover options by maximizing the mutual information between the options and the corresponding state transitions and demonstrates the options discovered by this approach. Also, the paper demonstrates that these options are useful for faster learning in a downstream task.  ",
    "This paper proposed an algorithm, termed infomax Termination Critic (IMTC) to learn diversified options in RL. This algorithm learns termination conditions of options by maximizing mutual information between options and corresponding state transitions. The experiments demonstrate the IMTC algorithm learns diversified options and can be reused in various tasks.",
    "The paper addresses the problem of open world object detection - a lifelong learning system where the object detector is required to detect objects belonging to all classes known so far and \u201cunknown\u201d objects. Unknown objects are annotated and available for training at a later stage. At a given time only a specific set of training data is available with annotations that involve all known classes so far, while all past training data are unavailable.    The proposed approach builds upon recent work [A], by incorporating a semantic topology in the object feature space (RoI features in Faster R-CNN). While [A] use contrastive clustering to group object features based on object category, and energy based out-of-distribution detection to detect \u201cunknown\u201d objects, the authors propose an end-to-end trainable approach. The proposed approach uses RoI features in two parallel streams, with one focused on clustering operation, while having object category prediction loss on both streams of features. Features are clustered around predetermined semantically meaningful object representations. Pre-trained word embeddings from a language model (CLIP) are used for this purpose. The use of pre-defined semantic anchors allows learned features of known objects to form consistent clusters during incremental learning.    Experiments are conducted using 80 categories from PASCAL-VOC and MSCOCO datasets. The problem is designed as 4 sequential tasks each involving 20 object categories (same setup as in [A]). Detection performance is measured using mAP, as well as measures that focus on unknown object detection.  [A] Towards Open World Object Detection, Joseph et al., CVPR 2021  ",
    "This paper extends the recently-introduced object ORE object detector [A]. ORE is trained in an incremental fashion and was shown to minimize the confusion between classes presented in different task sets by adding a contrastive objective to the model training, that pushes features, representing different semantic classes, far away in the feature space. This paper presents the case that combining ORE detector with large-scale language models, trained by aligning textual queries and images, can significantly improve ORE detector results. This is not surprising: it was already shown that such multi-modal language models could be successfully used for detection of novel classes in a zero-shot setting (in which names of target classes are given, but image data for these classes is available during the model training, see [D]). To the best of my knowledge, the core idea of semantic anchoring using language models was introduced in [C] (see Sec. 3.3 Densely Sampled Embedding Space). In this work, the semantic embedding space is extended with additional data from external sources that contain semantic information about the unseen classes via language embedding to image embedding alignment. This method suggests using CLIP [B] instead (which makes sense and simplifies the knowledge transfer!)  [A] Joseph et al., CVPR\u201921 [B] Radford et al., ICLR\u201921 [C] Bansal et al., ECCV\u201918 [D] Xian et al., CVPR'17 [E] Zheng et al., CVPR\u201921",
    "This paper proposes a semantic topology embedding for Open-World Object Detection (OWOD) where an object detector identifies objects of unknown classes and incrementally learns to classify them assuming that their annotations are progressively given by humans. To maintain discriminative and consistent relationships among object classes, the authors introduce a semantic topology for the feature space of the detector by constructing pre-de\ufb01ned anchors for categories using a pretrained language model. During training, it enables the detector to distinguish unknown objects out of the known categories and also makes learned features of different classes undistorted during incremental learning. Eperimental results show that the semantic topology improves state-of-the-art open-world object detectors and help the open-world detectors preserve a discriminative and consistent feature space.",
    "The paper proposes a novel method for open-world object detection, where instances of unknown categories need to be identified and annotated data for such new categories need to be integrated into the model in an incremental fashion. Prior work typically separate this problem into two tasks, out-of-distribution detection and incremental/continuous learning. This paper proposes to use fixed semantic anchors for each category, which are embedding vectors from a language model (or randomly generated vectors) for each category.  Importantly, when new data arrives, new embeddings are added while previous ones do not change. This encourages the feature representation to be compact (discriminative) and consistent (over time).",
    "Most batch-mode active learning strategies involve maximizing a sub-modular score function of the value of each image to be labeled. This paper demonstrates that current methods fail to sample diverse classes or images near decision boundaries, arguably one of the most important regions to obtain label information. The paper proposes a technique for incorporating class-balance and boundary-balance constraints to the sub-modular optimization problem and performs experiments over several image data sets to show the value of class and boundary balancing. ",
    "The paper describes a new active learning algorithm for classification problems. The authors propose a selection criteria that trades off between uncertainty and diversity. The novelty lies in formulating a three-pronged approach to diversity that still manages to maintain submodularity of the selection criteria: 1) a traditional diversity metric based on cosine similarity of embeddings 2) a new triplet/clique \"loss\" that penalizes the selection of nearby points 3) class-balancing and boundary-balancing constraints  By showing this three-pronged approach maintains submodularity, they are able to devise a greedy algorithm that still has a constant approximation guarantee to the optimal selection subset (as measured by the selection criteria). Experiments on CIFAR-10, CIFAR-100, ImageNet, and CIFAR-100LT (long-tailed) suggest that the new approach performs as well as or better than state-of-the-art methods.",
    "This paper presents a new method for batch active learning in deep neural networks, which aims to progressively construct compact subsets from a training dataset that maximize accuracy of learned models. The authors propose to address this problem by optimizing a submodular set function, expressed as a weighted combination of uncertainty, diversity, and triplet objectives, under a set of balancing constraints on classes and decision boundaries. The resulting optimization problem is solved using a greedy algorithm. Experiments are conducted on CIFAR10, CIFAR100, ImageNet and CIFAR100-LT datasets, where the proposed approach outperforms all baselines, with larger improvements under a class-imbalanced setting (CIFAR100-LT).",
    "This paper proposed a new subset selection method with novel diversity objective and balancing constraints. The authors prove that the proposed sample selection criterion is a submodular function. Hence its greedy algorithm comes with approximation guarantees (Nemhauser et al., 1978). The experiments on popular image classification datasets show that the proposed method is slightly better than k-center (Sener & Savarese, 2018). ",
    "This paper presents a method on generalization of segmentation from synthetic data to real street scene data. To adapt the model pre-trained with synthetic source domain data such as GTA and SYNTHIA to target domain such Cityscapes, BDD and IDD, the authors proposes Instance-adaptive Batch Normalization (IaBN). In addition, as a method to learn from a single sample, TT-SEG was proposed in which a pseudo GT mask is estimated from augmented images with the initial model and the last parts of the network are finetuned with the pseudo GT mask. In the experiments, the proposed method which employs both IaBN and TT-SEG successfully outperformed all the baselines, which indicated the effectiveness of the proposed method.  ",
    "This paper contributes two techniques to improve generalization of semantic segmentation networks. The first technique is an adaptation of the test-time behaviour of batch normalization, where the statistics of the sample under consideration are blended into the training-time statistics of the batch-norm layer. The second technique is to use test time augmentations to first derive a pseudo-labeling from the sample and then to update parts of the weights to maximize the probability of the pseudo-labels. The paper additionally contributes a multi-dataset evaluation procedure and shows favorable performance of the proposed techniques on this evaluation protocol.",
    "The article proposes two techniques for test-time adaptation. The first is instance-adaptive bn, to combine statistics from source data with each single test sample.  The second is test-time training, based on pseudo labeling of the test sample. The two parts lead to promising results.",
    "This paper studies an existing problem - domain generalization for semantic segmentation of urban scenes. The technique keys of this work has two main points: instance-adaptive batch normalization and testing-time training using pseudo labels. Instance-adaptive batch normalization aims to bias to the data distribution of individual testing examples, which is a tradeoff of previous t-BN and p-BN. This paper generate pseudo labels for test-time training, which is not quite novel. To evaluate the effectiveness of the proposed method, this paper conducts experiments on GTA5/SYNTHIA -> Cityscapes, BDD100k and IDD, and shows better results. ",
    "This paper introduces an anomaly detection algorithm for tabular data based on contrastive learning in the semi-supervised setting (training set assumed to be only normal data). The contrastive learning task is based on masking: the features from a single training example are split into two groups (pairs), one being a subsequence of the features, and the other its complement set; the learning task is then to differentiate pairs of splits that overlap (positive) vs not (negative) (from the same split or not) for each sample. The contrastive loss defined by this task is used to train the model and as the anomaly score. The proposed method is extensively evaluated on a range of tabular datasets where it outperforms recent methods.",
    "- The authors propose a novel anomaly detection framework that can be useful for tabular data. - The authors utilize the contrastive learning to learn the relationship between features in the tabular data. Then, using the loss as the anomaly scores for evaluation. - The authors provide extensive experimental results which are promising.",
    "## After rebuttal I am impressed by the comprehensive experiments and baselines and increase my score. Authors provide very complete baselines and also compare in other datasets, which greatly reduces the concern that the proposed rule overfits to the ODDS benchmark.   ## Summary This paper learns a contrastive representation that helps differentiate between normal and abnormal data in the tabular data. Contrary to other contrastive learning methods which learns to differentiate between different examples, this paper instead differentiates between in-window vector and out-window vector for each example under a sliding k-sized window (k is a hyperparameter). Since the features are unordered, they shuffle the feature orders to get multiple score and average them. They show that it outperforms other baselines in a large suite of tabular data, ODDS benchmark, with default hyperparameter rules (e.g. the k is set based on number of samples N and d). They compare mainly with recent methods DROCC, GOAD and COPOD. ",
    "This paper proposes a contrastive learning method for unsupervised anomaly detection on general multivariate (tabular) data. The idea of the method is to train two encoders, one that embeds a subset of k features and one that embeds the residual d \u2212 k features, such that the resulting embeddings are closely aligned via the contrastive loss, where all other subsets of k features are taken as negative examples respectively. This is then repeated over all subsets of features of size k. Thus, the intuition of the approach is to extract common dependencies (e.g., correlations, statistical redundancy, etc.) between the features by achieving a small contrastive loss over the training data, thereby obtaining a high contrastive loss for anomalies (which presumably lack these common dependencies). An empirical evaluation on the Arrhythmia, Thyroid, KDD, and KDDRev datasets (where results from the literature exist) as well as 30 additional datasets from the ODDS library show that the proposed method performs favorably over other recent competing methods (DROCC, GOAD, COPOD) on tabular data.",
    "This paper presents a method to reduce the dimensions of resting-state functional connectivity for psychiatry disorders such as autism spectrum disorder, major depressive disorder, and schizophrenia. Their method is based on a conditional variational auto-encoder that utilized the diagnostic label. They evaluated their method on two neuroimaging datasets and obtained clustered 2-dimensional representations of multi psychiatry disorder.",
    "The authors present a new conditional VAE, which uses diagnostic information as a supervision signal in two different ways, with the aim to identify small latent embedding spaces for functional brain connectivity that preserve diagnostic information. The authors have potential applications in computational psychiatry in mind, which are indeed extensively discussed in the field (transitioning to a continuous nosological approach to mental illness). They compare their approach on synthetic data to various related approaches and ultimately apply it to two functional connectivity datasets from patients with different psychiatric diagnoses, which appears to give good results.  Their main contribution is technical and lies in defining a new cost function to learn the embedding space. Their work incrementally builds on existing work, but appears to be sufficiently novel. There is also a moderate empirical contribution as they analyze the relationship between MDD, ASD and SCZ.",
    "This paper presents a new conditional variational autoencoder (VAE) approach to learn a low dimensional embedding of neuropsychiatric disorders from resting-state functional connectivity data. The proposed approach uses diagnostic information in 2 ways: 1) to cluster samples from the same disorder together via the conditional VAE model, and 2) to separate the clusters using contrastive learning.  The method is compared against other dimension reduction approaches on both a synthetic dataset and 2 real datasets which showed a consistent nosological relation among 3 disorders. ",
    "The authors propose a novel variational autoencoder to utilize functional connectivity (FC) features from resting state fMRI (rs-fMRI) scans in order to uncover latent nosological relationships between diverse yet related neuropsychiatric disorders. The autoencoder  seeks to learn a mapping  from high-dimensional FC space to a low-dimensional embedding space that is constrained to preserve pairwise relationships between the diagnostic attributes of the disorders. From a clinical standpoint, this work studies the nosology of complex disorders using a continuous dimensional characterization rather than using categorical and discrete diagnostic labels for supervision.    The authors validate their framework on both synthetic data and two separate clinical rs-fMRI datasets consisting of patients diagnosed with Autism Spectrum Disorder (ASD), Major Depressive Disorder (MDD) and Schizophrenia (SCZ). Their experiments evaluate the consistency of uncovered pairwise nosological relationships inferred from their latent representations.  They demonstrate that their model is capable of reliably inferring a dimensional characterization of multiple brain disorders beyond diagnosis labels. ",
    "Quantum neural networks have two parts: a quantum embedding circuit that takes in classical data and embeds it into a quantum state, and a variational quantum circuit that learns a quantum circuit for evolving the quantum state before measurement.  The authors propose to encode the classical input data into the parameterized angle in the quantum embedding circuit using a tensor-train network (instead of a dense neural network). This results in a 3-4% improvement in prediction accuracy for MNIST (87.12% accuracy).",
    "This work proposes an end-to-end learning framework TTN-VQC for quantum neural networks. The main problem is that current quantum computer cannot handle large number of qubits.  The idea of this paper is applying QTT to perform dimensional reduction followed by quantum encoding TPE, which can be combined with existing quantum neural network (VQC) as an end-to-end learning model. ",
    "As it was already studied in the literature, one way to implement a machine learning classifier in quantum computers is to convert classical input data like images into quantum states that are fed to a Variational Quantum Circuit (VQC). However, current quantum computers have a small number of qbits, which requires to perform a dimensionally reduction of the input datasets as a preprocessing step. In this paper, the authors propose to use data compression based on the Tensor Train Network (TTN) model, which is a very well-known compression technique. They compare TTN compression against a straightforward dense layer and the PCA-based dimension reduction techniques. The paper includes experimental results on MNIST dataset by simulating quantum circuits with up to 8qbits for noisy and noiseless scenarios.",
    "Summary:  This paper is dedicated to designing an end-to-end learning framework for quantum neural networks. The authors design a novel quantum tensor network for dimension reduction and quantum embeddings generation, since it is quite related to the practical usage in real-world applications where only a small number of qubits could be supported on available NISQ computers at this moment. The key contribution of this paper is to leverage a tensor train network (TTN) to replace the dense layer for dimension reduction, which enables an end-to-end training process fully conducted in a quantum computer.",
    "The authors propose an algorithm that takes several neural networks and outputs an embedding for such networks and a meta-model. This meta-model can take any embedding of a network, and emulate its hidden states and outputs. The authors suggest that these embeddings can measure models similarity, and show how to interpolate and extrapolate between and from the models in the training set.",
    "This paper proposes an approach to combine together multiple (pretrained) neural networks into a single model that can simulate each of the considered neural networks, both in terms of output and hidden states. The setup here relies on all the considered networks to operate on the same task, and in particular the same input data type (but perhaps with different sampled training sets). The combined meta-model then considers as inputs not only the input data, but also an encoding (which is learned during its training) of each model. This allows model-dependent latent features to be computed by the meta-model, which can then be decoded to hidden states of each network via specialized decoders that can be thought of as auxiliary computational pathways that operate in parallel to the one producing the main output of the meta-model. The model encoding are then used to visualize and explore the relations between different networks (or instantiations), and furthermore, to further tune the combined model towards an interpolation or extrapolation that goes beyond (and seems to outperform) each of the individual networks used to train the meta-model. ",
    "This paper introduces a new approach to studying the population of trained neural networks. Specifically, the author's design and train a meta-model which when given a vector, the meta-model emulates the model associated with the given vector. The authors present a few applications of their framework, including clustering and semi-supervised learning. ",
    "The manuscript proposes to analyze the similarity of different neural networks trained to solve the same task by developing a meta-model capable of reproducing/emulating both the output and the hidden representation of each individual network.  This meta-model is parametrized by a set of parameters which is common to all the networks, and by other parameters which are network-specific (theta). In this way, each network will correspond to a different theta, and one can analyze the global features of the set of networks by unsupervised manifold learning in the  theta-space. ",
    "This paper aims to add explicit/human-defined constraints to learning-based simulation frameworks, where a learned constraint function implicitly regularizes the dynamics, and future predictions are generated via a constraint solver. The authors built the framework on top of graph neural networks (GNNs) to capture the compositionality of the underlying system and enforce the constraint using an implicit constraint function optimized via gradient descent.  The authors tested the proposed method in four physical simulation environments, including rope, bouncing balls, bouncing rigids, and BoxBath. Experiment results show that the proposed C-GNS has a competitive or better performance compared to prior learned simulators. In addition, they have also demonstrated that C-GNS can generalize to unseen, hand-designed constraints by applying more solver iterations than experienced during training to improve the accuracy on larger systems.",
    "This paper presents a neural-network simulator that learns to solve constraints inspired by classic physics-based simulation. The proposed simulator uses a graph neural network to encode a constraint solver and shows results in a number of simulation environments.  The main contribution of the paper is its idea of using graph networks to encode constraint-based simulation. ",
    "This paper presents to simulate physics via a constraint-based approach instead of direct prediction. In particular, the authors first employ GNN taking as input the history positions and dynamics, to capture the interaction between different particles within the system, whose output is considered as the constraint satisfaction scalar. Then, the gradient with respect to the constraint function is applied as the update of the dynamics over a certain number of solver iterations. The experiments are conducted on a variety of challenging physical domains, including simulated ropes, bouncing balls, colliding irregular shapes and splashing fluids.",
    "This manuscript proposes to learn the numerical solutions to Lagrangian physical simulation with a constraint-based inference method on graph neural networks. This method involves an iterative update during inference and thus enables test-time dynamical correction. The contributions are: (1) this manuscript builds a scalar predictor to indicate how well the constraint is agreed. (2) this manuscript proposes using the graph neural networks as the backbone to deal with a variable length of the physical domain. They also examine the effectiveness with a bunch of experiments including the state prediction experiment on four different environments and multiple ablation studies towards different hyper-parameters.",
    "The authors present EDO-CS an approach to multi-objective optimisation that ensures the high quality and diversity of generated RL policies. Instead of uniformly sampling solutions from the Pareto front, sampling policies from learned clusters is introduced, as a selection mechanism within the ES optimisation. The quality and diversity are further achieved by modifying the objective function of the ES algorithm so it includes both the fitness and behaviour-diversity terms, balanced with a hyperparameter $\\lambda$. This hyperparameter is set using a multi-arm bandit approach, which is adapted during the training.  The performance of the proposed approach is evaluated on several MuJoCo continuous control tasks, as well as compared to state-of-the-art QD benchmarks. ",
    "The authors present a new method for finding robust policies in reinforcement learning, those policies which give high rewards but also come from a diversity of behaviours. The authors accomplish this by using a clustering algorithm to first divide policies into relevant clusters and then use evolutionary algorithms to optimise policy choice. The result is an algorithm that performs well over several representative benchmarks, achieving SOTA performance with high convergence rates. ",
    "In the paper \"Evolutionary Diversity Optimization With Clustering-Based Selection For Reinforcement Learning\", the authors introduce a new selection mechanism for Quality-Diversity based algorithms. This new selection mechanism is based on the K-Means algorithm, to cluster the behaviour space into cells and then select only the best policies within each cell. The paper also uses a linear combination of the reward and novelty score when performing the policy updates. The weights the of the linear combination are automatically adjusted using a bandit algorithm so that the best reward is obtained. ",
    "This paper performs research in the area of diversity/novelty-seeking agents under evolutionary optimization approaches. The core idea in this area is to optimize a weighted combination between raw environment reward and diversity during training (even though evaluation is still on the raw environment reward only). The diversity acts as a \"regularizer\" in order to achieve better exploration, which can lead to higher rewards.  The specific approach (EDO-CS) by the paper suggests using a pool/\"archive\" $A$ of previous policies, which are then clustered via K-means according to the distance metric defined by the behavior function $b(\\cdot)$. Each cluster then produces a new policy (and thus there are a total of $K$ new policies), which are then updated via ES over a regularized reward (via diversity metric, along with an adaptive weighting $\\lambda$), and put back into the archive.   Experiments are performed over various continuous control benchmarks for testing exploration, and results show that EDO-CS achieves SOTA.",
    "This paper studies the problem of distributed linear stochastic approximation for a group of agents over time-varying directed communication networks (to be more specific, the setup is decentralized). The authors propose two decentralized algorithms, (1) consensus-based linear stochastic approximation using row-stochastic mixing matrices (Eq. (1)), and (2) a push-sum type algorithm using column-stochastic mixing matrices (Eq. (9)). They further provide results on the asymptotic and finite-time mean-square errors to the equilibrium point of the (proper) ODE for each proposed algorithm.",
    "An interesting submission dealing with distributed stochastic approximation driven by Markovian noise, in which the communication topologies considered among agents are captured by a stochastic matrix (in contrast to the doubly stochastic matrix studied in the related literature). Both asymptotic and finite-time error bounds are established and it was shown that the algorithm converges to some unspecified convex combination of the equilibrium points of local tasks. This paper finally proposes a push-type distributed stochastic approximation algorithm and provides its finite-time bounds for the performance by leveraging the analysis for the consensus-type algorithm with stochastic matrices. All analysis and error bounds are directly applicable to distributed TD algorithms.  ",
    "This paper studies multi-agent distributed optimization under general consensus-type interactions between agents. The main contribution of the paper is to study linear stochastic approximation in a multi-agent setup without using bi-directional communication among agents. Non-asymptotic upper bounds on the associated error function, in a mean squared sense, are derived. ",
    "This paper addresses a consensus problem in stochastic approximation, which has application to policy iteration in reinforcement learning. Specifically, the authors address the case where the interaction graph between agents is stochastic, but not doubly stochastic. Under certain assumptions, the authors prove convergence of their proposed algorithm in a certain sense. ",
    "The paper focuses on the formulation of a graph neural network approach towards the learning of update rules of constrained systems, extending prior work (Interaction entwork, EGNN) by learning the updates of constrained components in the generalized coordinates expressing those constraints and incorporating forward and inverse kinematics in the algorithm. Comparisons are made with Linear, Basic GNN, TensorForce Networks, SE3-Transformers, Radial Field and EGNNs by evaluating them on a constrained version of the N-body problem introduced by Kipf et al. 2018 and it is shown that the proposed method better adheres to constraints and generalizes better on the studied problem.",
    "This paper develops a model that augmented interaction networks with mechanical constraints and develops equivariant message passing schemes to ensure physical realism in the model outputs. The work focuses on a set of toy systems that contains particles connected by sticks and hinges and the developments are made for these systems in particular. There are some results on generalised equivariant message passing and the universality of the proposed method. ",
    "The paper proposes a new graph neural network model for predicting the dynamics of n-body systems. The two main innovations of this model are: 1. Ability to handle systems with rigid-body constraints.  2. A new 3D transformation equivariant layer with universality properties.  ",
    "The authors propose Graph Mechanics Networks (GMN), a E(n) equivariant model that explicitly models systems with rigid constraints, with exact constraint preservation by means of using generalized coordinates. In my opinion the main contributions are as follows:  C1. Establish math for writing models that operate on cartesian coordinates, make predictions in very generalized coordinates and then converted back to cartesian. This is an approach that has been used in previous work, but is usually hidden as an implementation detail.  C2. Extend the E(n) (Satorras et al.) equivariant message function to take and output a variable number of vectors with a proof demonstrating that the approach is flexible enough to actually approximate any E(n) equivariant function. I think this is a novel low level modeling contribution.  C3. Extent the E(n) (Satorras et al.) model to build an E(n) equivariant model for exact constraint preservation. Although a bit niche, this is the first model of that nature.",
    "To overcome statistical heterogeneity among data shards in collaborative federated learning, this paper proposes a novel personalization schema which only requires smaller memory footprint in clients and possibly is less susceptible to catastrophic forgetting. The main idea is to split the trainable parameters into  shared and personalized parameters where, unlike existing personalization schema, only the shared model is exchanged with the server in communication rounds to be aggregated- thus partial personalization. In regression, this corresponds to learning the residual error of shared model via personalized model and in the classification setting corresponds to output averaging (unlike interpolation based personalization methods that do parameter mixing). The authors propose two algorithms FedSim (simultaneous updating of shared and personalized models locally) and FedAlt (alternative updating of shared and personalized models locally), to learn in this setting, theoretically analyze the convergence rates in non-convex settings and conduct empirical studies on image classification and next-word prediction to evaluate the proposed methods. ",
    "This paper studies personalization in federated setting, i.e., instead of collaboratively training a global model, personalizing a model for each client.  This paper proposed to personalize only part of the model parameters instead of the full model, and studied two algorithms FedSim and FedAlt. In local client updates, FedSim will simultaneously train the shared and personalized parameters, while FedAlt will train the personalized model first, then train the shared parameter. ",
    "This paper proposed a personalized FL framework with partial model personalization. It separates the model parameters into two parts, shared model and personalized model, and optimize them in an interleaving manner. The authors proposed two optimization algorithm, named as FedSim and FedAlt, with partial clients participation. They also analyzed the algorithms' convergence rate on general smooth nonconvex function. In experiments, they consider 3 different model split methods: 1. input layer as personalized model, the rest as shared model; 2. output layer as personalized model, the rest as shared model; 3. adding adapter as personalized model.  The experiments conduct on NLP or vision tasks also demonstrate that the proposed algorithm outperforms other personalization method.",
    "The paper discusses using partial personalization objective function defined in equation (3) to achieve personalized models in federated learning. While the idea of partial personalization and the objective of (3) have been widely studied in previous literatures, the main contributions of the paper are the convergence analysis of two proposed algorithms FedSim and FedAlt in nonconvex case. The authors also did extensive experiments to compare partial personalized models with fully personalized models by using various model structures and on different datasets.",
    "This paper has developed a framework for contrastive learning through time (CLTT). Instead of using augmentation operations to create positive pairs for contrastive learning, this paper creates several datasets with a near-photorealistic training environment by changing different view directions. The temporally close video frames of the new data are thus similar and should align in representation, which can naturally be considered as positive data.   ",
    "The authors propose to perform self-supervised learning (SSL) by enforcing temporal consistency (as opposed to augmentation consistency in most recent efforts). They do this by adapting existing SSL approaches (SimCLR, RELIC and BYOL) to leverage video frames that are close in time as opposed to different augmentations of a given image (akin to a temporal augmentation). In addition, the authors introduce two new datasets which they use to train and study the learnt representations in detail, showing promising results.",
    "In this paper, author introduce an image-based contrastive learning framework which substitutes traditional data argumentation by using successive images along with the temporal dimension. A new dataset is also generated in this paper for better studying the topic. Extensive experiments demonstrate that the proposed method is able to learn as good feature representation as supervised learning  in some datasets.",
    "The paper proposes a new method to select positive pairs for contrastive learning: using adjacent frames in a sequence, referred to as Contrastive Learning Through Time (CLTT). This is relevant since CL approaches have been shown to depend a lot on what kind of augmentation is used. The method is integrated with a number of well-known CL approaches, and evaluated on three different datasets, two of which are novel --the method is shown to approach fully supervised results. The paper also provides a valuable discussion on how the notion of time can help representation learning. The method is also tested for latent representation similarity when one object or pattern is systematically shown after another, something which has been studied in the field of biological learning, and a similar trend is found here as well. ",
    "The paper addresses multi-goal reinforcement learning. It presents empirical results with a variation of an existing algorithm, Hindsight Experience Replay (HER). Specifically, the paper uses HER alongside AlphaZero. ",
    "This paper presents AlphaZeroHER, an extension of the AlphaZero learning-informed Monte Carlo Tree Search algorithm in which the ideas of Hindsight Experience Replay (HER) are applied to augment training and therefore better support goal-directed planning tasks. Consistent with the general HER procedure, the approach generates new data under the assumption that the goal was one of a set of sampled \"subgoals\", requiring that that the reward and target policy be recomputed. The target policy is chosen to be the empirical policy achieved during the episode, for though it is not optimal for the new goal, it did indeed reach the subgoal. The authors demonstrate performance on a handful of goal-directed planning tasks\u2014including BitFlip, navigation, and a quantum compiling task\u2014on which they show improved performance over AlphaZero without the addition of HER.",
    " The authors discuss the impact of Monte Carlo Tree Search (MCTS) algorithms.  MCTS allows us to roll out trajectories using state value estimates to determine local actions, however computational cost can be high. This means that the approach is prohibitive for large problem spaces.  RL seeks to learn a control policy that generalizes well over the state space. This can be challenging and MCTS algorithms can help with this.  In goal reaching problems the agent takes as input the current state of the env as well as the goals state.  The only trajectories that confer positive reward are those where the goal is reached. RL can struggle here as the rewards are sparse due to the success criteria.  More informative reward functions can be used (e.g. distance to goal) but this isn't always possible.  Hindsight Experience Replay (HER) is applied to offline RL algorithms to improve sample efficiency where a replay buffer is maintained over retained trajectories and a set of sub-goals are defined over visited states with returns applied accordingly.  The authors propose to apply HER to AlphaZero to solve goal directed tasks and thereby avoid computationally intense tasks. They evaluate the approach against a set of simulated environments and compare to AlphaZero, including a novel Quantum compiling environment.  Much of the challenge in solving games like Go and Chess comes down to the size of the state space.  AlphaZeroHER works by sampling new sub-goals from already visited states and thus avoiding both the high computational cost involved in tree re-weighting and also the problem of sparse rewards.   This is done by retracing episodes and sample M subgoals from a trajectory of length T and training the policy and value networks on these hindsight inferred goals.  Since AlphaZero is on on-policy the policies used during play are retained when computing updates from the sub-goal rollouts which alleviates the computational burden.  The authors show that AlphaZeroHER outperforms AlphaZero over a number of simulated environments where the latter often fails to achieve learning much while the former achieves strong results.   ",
    "For the AlphaZero approach, the rewards of goal-directed planning environments are too sparse to learn efficiently. To solve this problem, the authors proposed the AlphaZeroHER method by combining AlphaZero with Hindsight Experience Replay(HER) to enable AlphaZero agents to learn in goal-directed environments. The experiments showed that AlphaZeroHER is better than AlphaZero on BitFlip, 2D Navigation Task, 2D Maze and Quantum Compiler environments. ",
    "The paper introduces a new method, Recursive Gradient Optimization (RGO), for continual learning in the task-incremental scenario. This method modifies the direction of gradients on a new task in order to minimise forgetting on previous tasks, and unlike many previous works, does not require storing past raw data to do so. The authors introduce a Feature Encoding Layer to achieve this. The authors provide experiments on 4 benchmarks of varying size (MNIST to miniImageNet), showing good performance of their algorithm, with different architectures.",
    "The paper addresses a long-standing problem of deep neural networks where new training data for new tasks arrive continuously and data does not stay forever (continual learning). The network has to learn to cater for all the tasks without forgetting what it learnt for an older task as data from older tasks are no longer available. The authors came up with a formulation where learning will mean minimizing the (expectation of) forgetting and forgetting is formalized as increase of losses corresponding to the old tasks. The authors then move on to find a Taylor series expression of forgetting and an equivalent Recursive Least Loss (RLL) formulation of the loss (aka forgetting). Next the authors introduce a modification in the direction of gradient update of normal SGD that makes sure to minimize forgetting. The modification implied the introduction of a positive definite matrix and the optimization problem transformed into an optimization problem on finding the optimal positive definite matrix minimizing the RLL. As the relation between RLL and the positive definite matrix is not straightforward, an upper bound of RLL is proposed and the optimal solution is found under this upper bound. One more interesting proposal is a virtual feature encoding layer (FEL) that applies task-specific random rearrangement to the input feature maps. FEL eliminates possible interference between tasks by decorrelating features among old tasks without expanding the memory footprint. The experiments show great improvement over sota approaches on benchmark datasets and sometimes (rotated MNIST, Split ImageNet) even goes beyond supposed upperbound performance given by single task learning showing evidence of positive transfer.  Overall, I liked the approach, the presentation and the experimental results with only a few minor concerns detailed below.",
    "The paper proposes a continual learning approach based on recursive gradient optimization. To this end, a projection matrix is derived for the gradient modification. This matrix, P, is computed incrementally and updated by integrating the Hessian on each task locally. ",
    "This paper introduces a gradient-based approach to continual learning in neural networks called Recursive Gradient Optimization (RGO). RGO modifies the gradient direction at each update by multiplying it with a projection matrix P that is designed to minimize the increase in loss on previously encountered tasks. RGO is theoretically designed to prioritise performance on the current task and, among the optimal solutions for the current task, find the one that causes least interference with previous tasks - thus it assumes that the network is overparameterised. The derivation of the method starts by approximating the continual learning loss with the \u201crecursive least loss\u201d, which involves a sum of the Hessians of the previous tasks and assumes that tasks are fully trained and their solutions are close by to each other. It is then shown that the recursive least loss can be upper-bounded by an expression involving the projection matrix P, via which the solution for P that minimizes this upper bound is derived. It is shown that the expectation of the step size can be preserved by guaranteeing that trace(P)=dim(P) and by introducing random task-specific permutations at each layer - this preserves the \u201ccurrent-task-first\u201d principle and reduces the need for hyperparameter tuning. Experiments are run on a number of standard continual learning image classification benchmarks, demonstrating an extremely strong performance of RGO in comparison to competing methods, sometimes surpassing the performance of a baseline that trains a separate model for each task.",
    "This paper provides an in-depth study of the properties and applications of the semantic alignment between the original parent StyleGAN model and its finetuned child model on another dataset. Specifically, the paper empirically demonstrates the semantical alignment of the two models. Then, based on the properties, the paper solves serval tasks like image translation, image morphing, zero-shot image editing and attribute classification. ",
    "  The paper provides interesting analysis and leveraging of GAN\u2019s model alignment (i.e., transfer learning). Without custom architectures and losses, it demonstrates impressive performance in a diverse set of tasks (image translation and image morphing). It also demonstrates promising results for zero-shot image recognition by leveraging the shared latent space of aligned models.  ",
    "This work is about the task of transfer learning to tame a new \"child\" network using a pre-trained \"parent\" network. While the model and fine-tuning technology lack novelty, the shared semantic information in the generation network are interesting. Finally, the authors applied the proposed aligned model to multiple tasks, including image-to-image translation, cross-domain image morphing, and zero-shot classification and regression. The impressive results with shared semantic information are achieved. ",
    "The paper undertakes extensive experimentation in the adaptability of latent space modifications from a base model, and a fine-tuned model for a secondary dataset. They demonstrate which areas of the models change most, and which information remains trained in the parameters, despite re-training. They go on to use their findings in downstream experiments, reaching state-of-the-art quality.",
    "The paper proposed a relaxed version of the Gromov-Wasserstein (GW) distance between two probability distributions on (graph) structured data. The main idea of new divergence is to relax the target distribution via an optimization setting. Based on the proposed divergence, the paper also introduced new formulations for existing problems of learning with graphs such as graph clustering (partitioning), graph dictionary learning, clustering of the graph, and graph completion. The experimental results for those applications on graph data have shown the efficiency of the proposed divergence.",
    "In this paper the authors propose a modification of the Gromov-Wasserstein problem for matching given matrices $C$ and $\\bar{C}$ with its respective histograms $h$ and $\\bar{h}$, relaxing the restriction on $\\bar{h}$. The problem is then given in an equivalent formulation, which is solved via Conditional Gradient.  The authors propose applications with graphs, such as graph partitioning, clustering, and completion via Graph Dictionary Learning. ",
    " The paper proposes to apply a version of Gromov-Wasserstein divergence to graphs. In particular, they relax the weight constraint of the second graph  and try to find a minimizer of the Gromov-Wasserstein distance. They named it Semi-relaxed Gromov Wasserstein distance (srGW) and apply it to solve some problems in graphs, namely, graph partition, graph clustering and graph completion. The experiments were carried out on synthetic data and real dataset such as: Wikipedia hyper link network, Amazon product network etc. The results show comparable and better performance over other methods such as  GW and spectral GW.",
    "This paper proposes a semi-relaxed Gromov-Wasserstein (GW) dissimilarity for learning tasks on graphs. Here the \"semi-relaxed\" refers to removing one of the marginal constraints, with the practical effect that during GW graph matching, one is able to ignore some of the nodes in the source or target and thus obtain matchings that better respect the structure of the problem. What is quite interesting is that this simple relaxation immediately yields benefits in fundamental tasks such as graph partitioning, and the authors validate this observation with extensive experiments on graph datasets. The empirical results are strong, and show state-of-the-art performance compared to several recent baselines.",
    "The goal of this paper is to train models that imitate human behavior using limited samples. A human reward function is given but human behavior may be suboptimal according to this reward function and therefore we cannot use the standard assumption, Boltzmann rationality. The authors propose an imitation learning algorithm that uses the known reward function to form a prior over human policies, the Boltzmann policy distribution (BPD). A posterior over policies is then inferred from human behavior. This approach is empirically more data efficient than behaviorally cloning human behavior. ",
    " * This paper proposes an interesting approach to model and predict human behavior.  * The approach is called Boltzmann policy distribution (BPD). It improves the Boltzmann rational model in that BPD considers the systematic suboptimality in human behavior.     * Systematic suboptimality means that the human could be consistent in producing suboptimal behavior. Hence, to capture systematic suboptimality, it is necessary to combine the human's reward function (optimal behavior) and trajectory data (deviation from optimality) in human modeling and prediction.  * This approach predict human policies, rather than trajectories, so that it can capture the (systematically suboptimal) human behavior that is reflected in the human action choices over time.  * Approach detail: the approach follows GAN (generative adversarial networks):     * The goal is to compute the human BPD policy `= \\integral \\pi(a|s) * p_PBD(\\pi | s1,a1,...,s_{t-1},a_{t-1})` (Eq5).         * `\\pi(a|s)` is approximated as a **generator**, `f_\\theta(s,z)` (Eq.6).         * `p_PBD(\\pi | s1,a1,...,s_{t-1},a_{t-1})` is approximated as sampled human trajectories, `q_\\theta(z | s1,a1,...,s_{t-1},a_{t-1})` (Eq.6).     * The base measure, `p_base(\\pi)`,  is defined as the optimal human behavior based on the known human reward function with suboptimality parameter \\beta (Eq4).     * The **discriminator**, `d`, used to distinguish between the policy generated by the base measure, `p_base(\\pi)`, and the policy generated by the sampled human trajectories, `q_\\theta(\\pi)`.     * The networks can be seen as: `\\pi(s) -> d(\\pi) -> z -> f_\\theta(s,z) -> \\pi(s) reconstructed`.     * The training for the generator, `f_\\theta(s,z)`, is in Eq8,9 and the training for the discriminator, `d`, is in Eq10.   * Results     * Apple picking gridworld with simulated human data         * Cross entropy: BPD < Boltzmann rational models     * Overcooked (prediction only) with real human-with-human play data         * Cross entropy: BPD = behavior cloning < random < PPO+self-play, Boltzmann rational models     * Human-AI collaboration (prediction and control in Overcooked) with \"human proxy\" policy from previous work         * Mean return: human-aware RL policy (prev work) > policy based on Boltzmann rationality, self-play policy, behavior cloning policy         * Mean return: policy based on BPD > policy based on Boltzmann rationality, self-play policy, behavior cloning policy         * Mean return: policy based on BPD > Human-aware RL policy (prev work) in 2 out of 3 cases. ",
    "The paper proposes a new model BPD to account for the suboptimality of human behavior, and provide an approximation inference method for BPD. The authors illustrate BPD through a simple simulation and compare BPD with existing methods on the overcooked game. They show that their model can match the performance of the data-extensive BC method and outperform BR. They further evaluate their model on human-AI collaboration and show that their model can match or even outperform the human-aware RL model.",
    "The paper addresses the problem of modeling human behavior in a case where their deviation from the optimal behavior is consistent over time, rather than independent (systematic suboptimality). They claim that systematic suboptimality can be modeled by predicting policies rather than trajectories. To this end, they introduce Boltzmann policy distribution (BPD), as an alternative to Boltzman rationality, as a prior over human policies. BPD enables adaption to human policies over time. While in Boltzmann rationality past behavior cannot be used to predict future behavior (since current action is independent of all the previous actions), the paper claims that since humans are consistent one can use past actions to predict future ones which leads to introducing BPD. They consider that human is sampling over policies rather than trajectories which results in the previous actions and states inducing a posterior over policies. By taking the expectation over the posterior they predict the next action. They further use deep generative models in order to sample from the BPD and minimize the KL divergence between the two distributions (P_BPD and the distribution induced by the generative network) to ensure the predicted distribution is close to the BPD.  Through experiments, they demonstrate cases where Boltzmann rationality is not able to predict the behavior of a suboptimal human while BPD can adapt to the behavior over time and predict the correct next action. They also show that their method is able to predict human behavior as well as the baseline while using fewer data.",
    "In the manuscript, the authors propose SQuant, which is a data-free quantization method that can apply post-training quantization (PTQ) without any backpropagation.  Specifically, SQuant is taking advantage of approximated Hessian information. Based on the assumptions and deductions in the paper, SQuant tries to optimize constrained absolute sum of error (CASE) instead of MSE.  The authors show many experimental results to validate the effectiveness of SQuant.",
    "This paper proposes a data-free quantization method based on the second-order Taylor expansion of  loss, where the Hessian matrix is approximated with different levels: element-wise, kernel-wise and channel-wise. The authors progressively determine the quantized weights from element-wise to kernel-wise and then to channel-wise. The derivation and solution of the quantization are novel. Empirical results show that the proposed method outperforms recent data-free methods.  ",
    "This paper proposes a new data-free quantization method that does not require back-propagation nor fine-tuning. The key idea is adopting Hessian-based optimization that can be decomposed into three parts (SQuant-E, K, and C) corresponding to the three dimensions of the weight tensor (using a few approximations, such as cross-layer independence to simplify the optimization). Then, instead of MSE, the authors introduce CASE (constrained ASE) of weight perturbation. The experimental results show that the proposed DFQ method outperforms even GDFQ that is basically a kind of QAT. The proposed technique is especially useful for a low-bit quantization.",
    "In this paper, the authors propose a data-free quantization algorithm of deep neural networks called SQuant. The main idea of SQuant is to decompose the Hessian-based optimization objective into three components: element-wise, kernel-wise and channel-wise components. In order to jointly optimize these three objective functions, a constrained absolute sum of error (CASE) is studied and a progressive algorithm is used. Experiment results show that SQuant algorithm is able to keep higher accuracy with the same number of bits, compared to several baseline algorithms.",
    "The paper presents a new deep architecture for segmentation of time series, i.e. to find the subsequences inside of a time series corresponding to different classes and to determine the bounds of those subsequences. The proposed architecture includes two core components: a) a kind of LSTM with skip connections to deal with the multi-scale problem of time series, b) an encoder-decoder module based on CNN and ResNet. The outputs of the two components are then used in a convolutional layer to provide a stepwise classification at each time step. The approach is evaluated on two classical datasets wrt 3 baselines.",
    "The paper presents a stepwise segmentation for time series data, namely SegTime. Contrary to the sliding window approach, SegTime takes the whole sequence as input, and process it in two separate modules: the MSS-LSTM network and the 1D encoder-decoder network. Outputs from the two separate networks are concatenated and taken as the input to the final convolutional layer to produce the final output, which has class labels for each time-step segment. This paper\u2019s contributions can be summarized as follows:  (1)\tBy predicting in a step level rather than a sliding window, it works well on both fast- and slow-changing labels.  (2)\tHigh parameter efficiency is achieved with depthwise separable convolution, atrous convolution, and skip-LSTMs. (3)\tLong-term dependency is captured, using MSS-LSTM and 1D convolutional layers. \u2003 ",
    "This paper focuses on time-series (TS) segmentation. They claim that in the typical approach for this problem -- where you is to apply a model (e.g., a temporal conv net) over fixed windows in time in sliding window fashion -- it is challenging to predict precise breakpoints, especially when the labels change frequently relative to the sampling rate of the input data/sensors. They also claim that these approaches ignore long-term dependences. They introduce a network which they \"obviates\" the need for sliding windows and can precisely find breakpoints.  Their claimed contributions are:  * A conceptual framework for TS segmentation * An architecture for solving TS segmentation problems * An adaptation of DeepLabv3+ for TS segmentation problems * State of the art results",
    "The paper presents a supervised method (called SegTime) for time series segmentation that is based on stepwise time series classification. The method avoids sliding windows (which is the typical approach), thus avoids the specification of window size and stride. It also seems to be insensitive to the label changing frequency and this constitutes a major advantage over other approaches. The network architecture is based on two core modules: a novel multiscale skip LSTM (called MSS-LSTM) that employs LSTMs with skip connections and a very deep CNN (called 1D-DS-ResNet). Several other modules are also included such as 1D Depthwise Separable and Atrous Convolutional layers and the Atrous Multiscale Pooling module (AMSP). The method is evaluated on two datasets, one with fast changing labels and one with slow changing labels. ",
    "This paper proposes a decomposition-based explanations method for graph neural networks.  In detail, the authors design a subgraph level interpretation algorithm to reveal complex interactions between graph nodes, so as to achieve the faithful explanation for GNN predictions. They demonstrate the effectiveness of the proposed method on synthetic and real-world datasets.   ",
    "The paper aims at tackling the black-box nature problem of GNN by introducing a new type of explainable GNN framework called DEGREE (Decomposition based Explanation for GRaph nEural nEtworks). There are mainly two innovations. The first one lies in its ability to track contribution of components in the input graph. The second one is the algorithm for subgraph-level explanation via agglomeration. The model achieves a good compromise between performance and time efficiency.",
    "This paper proposes a decomposition-based explanation method for graph neural networks. The motivation of this paper is that existing works based on approximation and perturbation suffer from drawbacks. To address the issue of existing works, the authors directly decompose the influence of node groups in the forward pass. The decomposition rules are designed for GCN and GAT. Further, to efficiently select subgraph groups from all possible combinations, the authors propose a greedy approach to search for maximally influential node sets. Experiments on synthetic and real-world datasets verify the improvements over existing works. ",
    "The paper provides DEGREE, which decomposes the feedforward propagation mechanism of a GNN to understand it. They give realistic decomposition techniques for those typically used layers in GNNs after presenting the key guidelines for developing decomposition-based explanations. They also devise an approach for providing subgraph-level explanation via agglomeration, which makes effective use of graph topology. DEGREE surpasses baselines in terms of fidelity and can capture important structures in graph data, according to experimental results.",
    "This paper proposes DiffStride as a drop-in replacement to standard downsampling layers. It extends previous work Spectral Poolnig and learns the size of the cropping box in the frequency domain by backpropagation. Experiments are conducted on audio and image classification, and the results show that the model can learn non-integer stride and adapt different initial stride well.",
    "In this work the authors introduce a differentiable stride formulation, which allows for learning the stride value. To this end, they propose learning the size of a cropping mask in the Fourier domain, which allows for learning how to perform resize in a differentiable way. Authors present experiments on several datasets on different domains (image, audio), including large scale datasets.",
    "In this paper, the authors propose DiffStride, a technique for learning the stride of downsampling operations in neural networks by gradient descent. Specifically, similarily to SpectralPool, the feature map is transformed to the frequency domain by a Discrete Fourier Transform, where it is then cropped according to learnable parameters. The authors envision a simple soft-relaxation of the cropping in order to allow the gradient to flow towards cropping parameters. Performances against both standard and random stride policies are reported on a number of datasets, both for audio and image recognition. Moreover, the authors introduce a regularization objective that penalizes the use of small strides, in the interest of encouraging downsampling for improving computational and memory cost.",
    "This paper proposes an approach to learning optimal striding parameters in convolutional networks. The proposed approach, DiffStride, is a downsampling layer that builds on spectral pooling to allow for integer output dimensions, but arbitrary strides by cropping in the Fourier domain. Unlike spectral pooling, DiffStride relaxes the parameters of the cropping mask to be differentiable, and using the stop-gradient operator in the cropping. Results show that the proposed approach can work well as a drop-in replacement for normally fixed pooling layers. It is also demonstrated that from different random initialisations a variety of different pooling approaches can be learned that acheive similar performance. Use of a regularisation term the attempts to encourage time and space efficiency reduces this variability and allows accuracy to be traded off.",
    "This paper leverages the recent anisotropic certificates for randomized smoothing for certifying multi-output classifiers. In particular, it leverages anisotropic Gaussian  and Bernoulli smoothing for better collective robustness. Experimental evaluation was conducted on semantic segmentation and node classification to demonstrate the effectiveness of the proposed method.",
    "The paper makes three contributions in particular: - A local version of randomized smoothing for multi-output classifiers. The authors suggest using a customized smoothing distribution for certifying each output of the multi-output classifier. The custom distributions allow them to produce tighter guarantees for each output. - A new analysis method of variance smoothing for discrete data uses the average softmax value instead of the majority vote as the prediction rule. The authors use the first and second-order statistics (mean and variance) to provide robustness guarantees in this method. - A collective certification strategy for multi-output classifiers using a common interface ($\\ell_p$ norm ellipsoids) for base certificates for every output. The authors describe a common way of stating the base certified regions for every output. Then the multi-output certification problem can be expressed as a mixed-integer linear program to find a point inside the perturbation model that lies outside the base certified regions for the maximum number of outputs.",
    "The authors consider tasks mapping a single input to multiple outputs and study robustness certificate against input perturbations. To achieve the goal, the authors propose a collective certificate where each output is dependent on the entire input but assigns different levels of importance to different input regions, and then derived the collective certificate based on localized randomized smoothing. The proposed collective certificate is evaluated on both image segmentation and node classification tasks.  ",
    "**Summary**  The paper proposes a localized smoothing approach for certifying structured output models. The threat model of interest in this setting is the bounded input perturbation that results in the highest number of prediction flips per pixel. The paper proposes to utilize the idea that when certifying pixel predictions at location (i,j), one can smooth the input pixels (k,l) far away from (i,j) by larger noise magnitude (standard deviation) resulting in a higher certified radii as they perhaps may not play a significant role in predicting the label of (i,j). The paper formulates the problem of finding worst cases adversaries that result in misprediction to the task of finding adversaries outside the certified region with anisotropic smoothing over the input. The paper then lower bounds the binary objective with a box constraints and solve the problem using linear  programs. Experiments are conducted on image segmentation tasks along with node classification.",
    "This paper proposes a new type of normalizing flow for incorporating inductive biases into the model architecture. To this end, the authors introduce a so-called \u201cstructure layer\u201d, aiming to transform a spherical Gaussian variable into a pre-defined probabilistic program. A modified version, called \u201cgated structured layer\u201d is proposed in order to skip problematic parts of the model. The model is evaluated on a variety of different datasets and outperforms the masked autoregressive flow baseline.",
    "This paper first proposes to take a probabilistic program and compile it into a sequence of invertible transformations. Applying this invertible transformation to a standard normal distribution produces a sample from the probabilistic program. This \"compiled\" invertible transformation is then used as a layer with learnable parameters, called a structured layer, in a larger flow model which can also have unstructured layers. The paper argues that this enables the ability to incorporate domain knowledge via these structured layers while enabling deviation from this domain knowledge via the unstructured flow layers. The paper performs experiments on multimodal, hierarchical, time series and variational inference data. ",
    "This paper tries to bridge the concept of the normalizing flow model with the structured layers that encode the domain knowledge (also called inductive bias here). The general idea is to first notice that many existing probablistic programs (such as univariable RV) can be converted to flow under some special $f_{\\phi}$.  Furthermore, the authors proposed a gated layer to allow the model to switch between user-specified model and the learned MAF. Extensive experiments in toy multimodality distributions, hierarchical gaussian, timeseries models and variational inferences are conducted to compare the proposed method with other baselines.  ",
    "The authors describe how to translate a probabilistic program into a normalising flow layer which maps samples from a unit Gaussian into samples from the probabilistic program. They propose a \"gating\" mechanism for this layer so that it can learn to interpolate between this transformation and the identity transform. They then show how this layer can be combined with generic normalizing flow layers, and in this way add an inductive bias to a normalising flow without sacrificing its expressivity. In the experiments, they provide various examples using probabilistic programs in this way to construct normalising flows with helpful inductive biases.",
    "This works aims at investigating whether large language models (LMs) pretrained only on texts, can implicitly learn grounded concepts of the world beyond texts. Specifically, the authors test whether the LMs can map some conceptual domains (e.g., direction, color) to grounded world representations (e.g., textualized grid world, RGB representation of colors). The authors give a rather small number of examples as prompts to the models in an in-context learning setup. They find that large LMs like GPT-3 can often output the correct concept for the grounded world representations, even though it\u2019s likely that the model hasn\u2019t seen the grounded world representations in its pretraining. They conclude that the text-only LMs may already learn the grounded representations implicitly, without explicit from-scratch training like in the visual language models. ",
    "This paper investigates the question of whether language models encode, in some way or another, conceptual spaces that are analogous or isomorphic to grounded ones. The paper reports on the design and results of several experiments to test this in domains which can be easily serialized as text (and hence made accessible to an LM) \u2014 spatial directional terms, cardinal directions, and color terms. The ability of a language model to correctly ground conceptual terms is tested in a limited set of unseen environments and for unseen terms, where supervision is provided in the few-shot learning paradigm popularized with GPT-3. The largest tested model, GPT-3 175B, performs appreciably in all settings.",
    "The authors present their work looking at how text-only input can create what they call a \"grounded\" model. The results support the idea that a small input of text-only data can give rise to the models behaving in such ways as to generalise over things like left and right or colours. This indicates, the perhaps unsurprising conclusion, that language is able to, on a meta level, encode some aspects of groundedness, as defined by the authors, and the perhaps more impressive conclusion that the models can indeed tap into the latent structure found in language using a few examples and thereby generate useful isomophisms. ",
    "This work seeks to probe large pre-trained language models for indications that they have induced a conceptual space that is structured similarly to one constructed from interactions with the real-world, despite being trained solely from text.  Most of this probing takes the form perceptual tasks -- can LMs quickly learn new concepts related to navigation, or colors, if given some related examples from the space?  In both navigation and color tasks, this seems to be the case, and a consistent trend emerges where larger LMs perform better on this task.  The experiments seem well-controlled, and the authors present an insightful discussion of model performance.  ",
    "The paper examines the effect of reward shaping in the context of emergent communication, and specifically with respect to the Shannon entropy of the emerged language. The paper showed that shaping the rewards can lead to higher entropy than training with just the base reward. We care about the entropy because this relates to how expressive the language is. There are existing works, such as Kharatinov et al 2020, which examine the relationship between task/environment and the resulting language entropy.  The paper uses PPO as its main outer-level optimizer, which it uses because the task is a multi-step task which might be challenging to learn with other algorithms such as REINFORCE.  The paper provides theoretical analysis of the effect of reward shaping on entropy by considering an analogy between PPO learning and a process they call the 'Extended Chinese Restaurant Process' (ECRP), where at each step, the customer can be divided into beta parts, and each of the beta bits of customers (which are now each of size 1/beta) takes a seat. This is presented as being analogous to how PPO first store multiple episodes over a buffer, and then updates the weights of the network, using the results of the whole buffer; then rinses and repeats.  Experimental results are presented which show that making the task harder/longer (by increasing the world radius) results in a fall of the entropy of the resultant emergent language, but not in the presence of reward shaping.  The paper asserts that whilst multi-step tasks, and PPO, are not much used in emergent communication literature currently, but it seems plausible that this will become the case in the future, and this paper is a small exploratory step in that direction.",
    "The paper looks into finding effects of reward shaping on emergent language learning with RL. The work shows the difference via analyzing entropy and the behavior of the learned agent. It draws similarities between the Chinese restaurant process and RL. And shows that some of the differences between the behavior of the agent learned with and without reward shaping can be explained by experience buffer size used in the RL learning algorithm. The work uses a new simple navigation task for the study.",
    "This paper investigates emergent language research, whose goal is to study language as it emerges from the inherent properties of the environment, language, and agents. This is typically in the context of reinforcement learning such that the phenomena arises from the pressure to maximize reward. This paper considers two types of rewards. One directly comes from the task. The other is shaped rewards which makes learning easier. This paper mainly investigates the impact of shaped reward on the emergent language. Using a simple sender-receiver navigation game, the paper shows that shaped rewards can explicitly bias the semantics of the learned language, change the entropy of the learned language, and mask the potential effects of other environmental variables of interest.",
    "This paper studies the effect of auxiliary rewards in an environment for a multi-agent communication task. The task is for a sender to navigate a receiver to the center of some environment, in worlds with varying sizes, and must develop a discrete language (consisting of 1 of 64 symbols) to solve this task.  The authors argue that seemingly innocuous (\"unbiased\") shaped rewards in the environment have significant, measurable effects on the learned languages, both qualitatively and quantitatively. The authors both visualize the effect of shaped rewards on the emergent language, and measure the change in entropy to the languages caused by the denser shaped rewards. For example, adding denser rewards increases the entropy (and presumably information) communicated by the language; denser rewards prevent a decrease in entropy for languages generated for larger (more difficult) tasks, suggesting that information bandwidth remains high in the shaped reward setting.  Finally, the authors suggest an alternative hypothesis for the differential entropies observed by language in this game: the size of the experience replay buffer in their PPO algorithm, which roughly corresponds to the frequency of updating the semantics of the learned language. There is some connection drawn here to a batched CRP with varying batch size, though it's not super clear to me how strong this connection is to PPO learning and why this CRP is the right way of thinking about experience buffer sizes.  The core argument of the paper, then, is to more carefully consider how environmental rewards might change the semantics of the learned language and mask other factors of interest in studies of emergent communication.",
    "This paper investigates a method for improving the cross-lingual transfer of pretrained multilingual models. The paper first empirically analyzed the influence of representation invariance and distributional class shift. Then, the paper proposed a method to improve the representation invariance and correcting the class shift. Experiments showed its superiority under large prior shifts.",
    "In this paper, the authors provide substantial analyses on the cross-lingual transfer performance in the multilingual neural language models and reported that the performance is strongly correlated with representation invariance and negatively affected by distributional shift in class priors between data in the src/tgt languages. Based on these findings, the authors propose an unsupervised cross-lingual learning method, called importance-weighted domain adaptation (IWDA), where it performs feature alignment, prior shift estimation, and correction. The authors experimented on two different NLP tasks such as multilingual NER and multilingual sentiment analysis tasks, and experimentally showed the effectiveness. Besides that, they demonstrated that the proposed approach improves performance further, when combined with existing semi-supervised learning approaches.",
    "This paper looks at the problem of unsupervised cross-lingual transfer (termed UCL) in the paper through the optics of domain adaptation. After empirically analysing and validating that distributional shifts in class priors might cause a huge problem for UCL (which wasn't tackled in previous research), the authors proceed with an introduction of a new method that aims to mitigate that problem. The idea is to get rid of that shift through a approach called importance-weighted domain adaptation (IWDA), which is largely the adaptation of the work from Tachet des Combes et al. (NeurIPS 2020) to the UCL problem.  The results on two tasks in the UCL setup (NER and MARC classification) show slight gains over the standard zero-shot transfer when IWDA is applied, with more prominent gains reported when a stronger domain shift is observed - however, such a setup has been created mostly artificially, to further demonstrate the benefits of modelling the shift in the model.",
    "The paper first demonstrates the importance of feature invariance (language invariant representations) and class-prior invariance across languages on zero-shot cross-lingual performance. By analyzing the zero-shot performance on different languages on the MARC reviews and WikiANN NER tasks, and comparing against the class conditional distance between the source language (English) and target language feature representations, the authors illustrate the how high feature invariance results in better zero-shot performance. By also synthetically modifying the class prior for the target language, the authors demonstrate how increasing differences in class priors result in decreasing zero-shot cross-lingual transfer performance.  Building on their observations, the authors propose an approach that: (i) Introduces an adversarial loss term to penalize distortion in average class conditional feature representations between the source and target languages. (ii) Adds an importance weighting term to ensure the approach doesn't fail under class prior shifts.  Empirical studies demonstrate that the proposed approach improves significantly over the vanilla zero-shot model on both MARC sentiment analysis and NER tasks, also improving over self-training on sentiment analysis. Comparisons on synthetic datasets (sub-sampled from NER and MARC datasets) that enhance the class prior shift highlight the robustness of the approach under large class prior shifts where previous approaches fail.",
    "The paper proposes *Bootstrapped Meta-Learning,* a new meta-learning algorithm for hyperparameter optimization. Drawing inspiration from temporal difference learning techniques in reinforcement learning, the meta-learner is asked to predict the result of additional unrolled steps of the optimization process, by minimizing a carefully selected distance to a target generated during training. This allows for longer meta-learning optimization horizons, without the need for differentiation through longer optimization trajectories. The method is tested for hyperparameter optimization for reinforcement learning, including learning the exploration hyperparameter for a behaviour policy, and in multi-task meta-learning.",
    "This paper broadly considers meta-learning, a.k.a. bilevel optimization, across single-task, multi-task, supervised learning, and reinforcement learning settings. The authors aim to resolve two issues with the standard outer-loop gradient-based optimization of the meta-parameters (assuming a differentiable inner-loop): first, since the meta-learning objective is typically computed from learner parameters after applying up to $K$ inner-loop updates, the meta-optimization is myopic in that it does not optimize for further inner-loop improvement after $K$ steps; second, since the functional form of the learner's objective $f$ is used to drive the outer-loop updates, the meta-learning objective inherits the curvature of $f$. The main algorithmic contribution consists of a family of meta-learning objectives called bootstrapped meta-learning, in which meta-parameters are optimized to bring post-inner-loop learner parameters $x^{(K)}$ closer to a bootstrap target (which are also learner parameters) computed from $x^{(K)}$. The authors show that bootstrapped meta-learning generalizes the \"direct\" (my terminology) gradient-based meta-parameter optimization used in many previous works, recovering it when using specific choices for the bootstrap computation function and learner parameter matching function. With certain strong assumptions, the authors theoretically motivate the use of gradient-based bootstrap target functions for bootstrapped meta-learning in terms of optimization progress. The authors make several experimental contributions: they use bootstrapped meta-learning to achieve state-of-the-art model-free performance on Atari-57, demonstrate the viability of bootstrapped meta-learning in few-shot image classification on miniImageNet, and show that the more flexible, general form of bootstrapped meta-learning can enable meta-learning parameters that do not appear in the computation graph for the task objective, e.g. meta-learning the exploration rate of the behavior policy in $\\epsilon$-greedy $Q$-learning.",
    "\u200c\u200cThe paper presents a new meta-learning algorithm to address two shortcomings of standard meta-optimization algorithms: curvature (the meta-learner's objective is typically constrained to the same type of geometry as the learner), and limited evaluation (the meta-objective is evaluated only with-in a K-step horizon, ignoring future learning dynamics). The proposed algorithm addresses these two issues by minimizing the distance to a bootstrapped target under a chosen metric. Empirically, the new algorithm  achieved a new state-of-the art for model-free agents on the Atari ALE benchmark and yielded gains in multi-task meta-learning. Theoretically, some guarantees on performance improvements are provided. ",
    "The paper presents Bootstrapped meta-gradients (BMG), an extension of typical meta-gradients (MG) for the task tuning meta-parameters that control the learning process (i.e. update step) of a learner.  In general terms, MG applies a (meta-)parameterised update rule to a learner for K steps, and then backpropagates through these updates to update the meta-parameters in the direction that improves the performance of the adapted learner.  The authors identify two limitations to this approach, and propose BMG to address them. (i) MG is myopic, in the sense that it does not account for future learning dynamics beyond these K steps, therefore BMG proposes to bootstrap a target from the K-step parameters (in practice by continuing to optimise w.r.t. parameterised update rule for L-1 steps, and then taking a final step w.r.t. a fixed objective to ground the signal). (ii) MG updates are necessarily restricted to be within the geometry of the parameterised learning process.  In contrast, BMG introduces a matching function to measure the distance between the learners K-step parameters and bootstrapped target in an arbitrary (and hopefully more-suitable space).  After framing the problem and BMG, the authors provide a discussion of the necessary conditions for BMG to guarantee performance improvements, though ultimately the presented algorithm is justified empirically using experiments on (i) a toy RL problem, (ii) the Atari RL test suite, (iii) multi-task few-shot adaptation on an image recognition task.  In all settings, BMG provides significant improvement over meta-learning baselines \u2014 most impressively achieving a new SOTA on Atari.  Moreover, key features of BMG are highlighted, including the ability to extend the meta-learning horizon without increasing the number of updates steps through which we must backpropagate, and that behavioural parameters outside of the update rule (specifically, epsilon in epsilon-greedy exploration) can also be meta-learned.",
    "This paper evaluates how well model-based RL, specifically MuZero, generalizes in comparison to model-free RL. It empirically compares how planning, representation learning, and data diversity affect the generalization of agents. To evaluate the effect of planning, a Q-learning agent is constructed to be as similar as possible to MuZero without the MCTS. In experiments, it is found that planning, self-supervised representation learning (reconstruction, contrastive, self-predictive) and data diversity all improve generalization performance. However, results are not similar in the Meta World benchmarks, where self-supervision did not seem to improve results much. The paper concludes that self-supervision is a promising approach to improving the generalization of MBRL agents in procedural environments, but perhaps it does not improve task generalization.",
    "This paper measures the generalization ability of model-based agents, i.e. MuZero, in comparison to model-free agents. The authors identify three key factors for procedural generalization: planning, self-supervised representation learning, and procedural data diversity. However, they find that these factors do not necessarily provide the same benefit for task generalization. They argue for a move towards self-supervised model-based agents trained in rich, procedural, multi-task environments. ",
    "This paper explores the application of the MuZero agent for tasks which require generalization across environments, namely ProcGen and MetaWorld.  On ProcGen, they find that MuZero in its standard form performs on par or better than strong model-free methods. Furthermore, when combined with auxiliary self-supervised learning (SSL) losses, there is a significant jump in performance which achieves a new state of the art. The paper includes interesting control experiments disentangling the effects of different components. For example, it shows that both MuZero\u2019s modified targets for the value functions, as well as the tree search for action selection, each separately contribute to performance. Another interesting finding is that adding auxiliary SSL objectives can help generalization performance on unseen environments, even when they do not improve performance on the training environments, which I found surprising but useful.   Results are also reported on task generalization benchmarks from MetaWorld. Here the results are less strong, and self-supervision does not appear to help. There appears to be some transfer between tasks, but it is limited. ",
    "The authors present a systematic empirical study of the effect of planning and model learning on generalization performance, using the MuZero agent. They use 2 environments, Procgen and Meta-World, to respectively explore procedural generalization to new variants of the environment with the same reward structure and task generalisation to new structures of the reward function in the same environment. Their main contributions are their empirical results, specifically that additional reconstruction or self-supervised losses enable the MueZero agent to achieve state-of-the-art performance in procedural generalization, but are not enough to promote a similar increase in performance in task generalization tasks in Meta-World. Finally, they also explore the data diversity dimension, showing that having more diverse data during training can help procedural generalization even more.",
    "This paper proposes an approach to estimate a latent graph $A_L$ given an observed graph $A_O$ (e.g., the covariance matrix of signals generated through a graph diffusion process). The authors posit a polynomial model and unroll proximal gradient iterations to estimate a variant of the model. The authors conduct experiments on synthetic datasets with supervised $(A_O, A_L)$ pairs as well as a neuroimaging dataset, where $A_O$ denotes the functional connectivity graph and $A_L$ denotes the structural connectivity graph. The proposed approach performs better than several baseline approaches.",
    "This paper proposes a novel solution to infer the graph structure. It starts with the unrolling algorithm for graph structure inference problem, and then adopt the proximal gradient iterative solutions. The expressiveness is augmented by parameterized with deep neural network, called Graph Deconvolution Network (GDN). ",
    "The authors tries to recover the underlying graph structures from observed symmetric adjacency matrix. The key assumption of the paper is that the observed adjacency matrix can be represented as a polynomial of the adjacency matrix of the true underlying graph, which is reasonable. The experiments show that the proposed model can recover graph structures on provided dataset.",
    "The authors propose the graph deconvolutional network (GDN), which is a novel approach to graph structure recovery from noisy observed graph structures. It is based on an assumption that the observed adjacency matrix is polynomial in the true graph adjacency, and uses a proximal gradient computation to iteratively optimise for this structure. Experiments on both synthetic and brain imaging graph recovery tasks indicate the outperformance of the proposed method against several baselines.",
    "The paper proposes to frame the reward shaping method as a Markov game between two players. In this setting the first player is learning to act in the environment while the second player is learning to provide reward shaping to the first player. Additionally, the authors propose to use a switching scheme that indicates whether or not to perform reward shaping for the first player. The authors provide some theoretical guarantees under a large set of assumptions. The authors perform experiments on a set of toy tasks and a few more complex domains.",
    "This paper introduces a new algorithm to solve the sparse reward settings. The algorithm tries to find an optimal policy by leveraging two learners: a controller and a shaper. The controller learns to maximize the environment reward signal plus the signal provided by the shaper. The shaper learns a potential-based reward shaping function by maximizing the controller's objective plus a cost penalty for providing reward feedback and an exploration bonus. The shapers reward function is created using a randomly generated state function and a dot product based on the shaper's \"action.\" Some theoretical analysis is provided along with experiments demonstrate to demonstrate that this algorithm is helping solve sparse reward problems.  ",
    "The key idea in this paper is to jointly train a pair of agents, namely a Controller that performs the RL task and a Shaper agent that shapes the Controller's reward function to better its performance. Rather than shape all states, Shaper learns \"switching controls\" to determine states on which to place its modeling effort on, and ablation experiments suggest this works well compared to the straightforward approach of shaping all states. A natural concern is whether this Markov game approach results in stable training and convergence. To address this issue, the authors provide theoretical convergence results which show ROSA convergences to a Nash Equilibrium (NE) with weakly higher total return. Experiments on several domains suggest the method works well relative to alternative reward shaping approaches (e.g., those based on curiosity or bi-level optimization). ",
    "The authors propose ROSA, a reward shaping method that trains a separate \u201cShaper\u201d policy to learn how to generate reward bonuses. The problem is formulated as a two-player Markov game, in which the environment dynamics are only affected by the primary, \u201cController\u201d policy, but the Shaper and Controller policies each optimize their own rewards. The Controller\u2019s reward is the normal reward plus a potential-based reward that depends on the previous two states and the previous two Shaper actions. The shapers\u2019 reward is a combination of the Controller\u2019s reward, a penalty for switching often, and a count-based exploration bonus. The shaper\u2019s rewards are also automatically gated by a switching function, which is hard-coded to switch with higher probability whenever a curiosity-metric increases (in this case using the RND exploration metric). The authors extend the standard reward shaping result to show that including the actions of the Shaper in the potential-based reward shaping term maintains policy invariance. Then, the authors empirically demonstrate on a grid-world environment that ROSA provides useful reward shaping that guides the agent towards the goal and ignores irrelevant parts of the state space. The authors also compare to and find that ROSA outperforms ICM, RND, PPO, and LIRPG on Gravitar, and gets similar performance on Solaris and Super Mario as some of these prior works.",
    "This paper studies the robustness of vertical federated learning. They use intuitions from robust feature subspace recovery for low rank matrices to design a defense framework for vertical federated learning. They empirically show the effectiveness of their framework for some settings. They also try to provide theoretical evidence for the robustness of their scheme, but I do not find their theoretical studies illuminating. ",
    "This paper studies robust vertical federated learning framework against backdoor attacks. The authors utilize robust autoencoders with purified training to remove the backdoor features and obtain clean global model. The authors also proved that, with some assumptions, the exact uncorrupted features can be recovered.",
    "The paper tackles the problem of adversarial attacks against federated learning. The main proposal is RVFR, an original method that allows to protect against backdoor attacks targeting the specific \u201cvertical federated learning\u201d setting. The proposal is provided with a theoretical analysis of its effectiveness, and is then evaluated on two well-known datasets, showing better results than prior works in adversarial scenarios.  Overall, the presentation of the paper should be improved. The quality of the English text is appropriate. Figures and Tables should be improved. The topic addressed by the manuscript is relevant and in-line with ICLR. The references must be expanded with security-related works. The contribution is potentially significant.  STRENGTHS: + Relevant and trendy subject + Evaluation on two datasets + The theoretical analysis is appreciable  WEAKNESSES - Very poor Introduction, Abstract and Background (Related Work) - Unclear threat model - No Tradeoff",
    "The paper proposes a robust vertical federated learning framework called RVFR against backdoor attacks. In the framework, the agents train the local feature extractors and send the embedded features to the server. Then, the server trains a robust auto-encoder to recover and purify the features. Last, the purified features are used to train the global model. The paper provides theoretical analyses of the feature recovery under different threat models. The experiments show that RVFR is more effective when defending the backdoor attacks compared with the other baselines.",
    "This paper studies pre-training of Siamese Transformer encoders for the zero-shot dense retrieval problem. The author consider contrastive learning loss function to optimize the encoders and investigate variants of ICT for data augmentations. While not much novelty in the techincal sides, the author indeed present solid empirical study on zero-shot retrieval benchmark as well as extension to the few-shot evaluation.",
    "This paper proposes to use cropping strategy to train a neural model for IR. It is compared to BM25 and several other neural models, including BERT and the ones using inverse cloze task. The goal of cropping is to train a model that fits better the IR tasks. It is hypothesized that this task is more similar to IR than other pre-training strategies. The method is tested on a set of benchmarks of zero-shot retrieval and MSMARCO with training data. It is shown than the proposed method fine-tuned on MSMARCO can outperform the compared methods, including BM25. When no fine-tuning is used, the method is almost at par with BM25. ",
    "This paper presents a contrastive learning approach for unsupervised text retrieval. As the approach is unsupervised, similar to the Inverse Cloze Task (ICT) approach, the authors propose to do independent cropping of a paragraph to generate a pair of \"pseudo-question\" and \"pseudo-document\", which is used to train the model. The model is trained using contrastive learning following the MoCo algorithm. Experiments are performed on the recent BEIR benchmark for zero-shot and few-shot retrieval evaluation. The proposed approach often performs better than the BM25 algorithm on zero-shot retrieval on the BEIR benchmark. There are also some ablations presented to analyze different aspects of model training such as the effect of number of negative examples, training data, data augmentations etc.  ",
    "This paper proposed a contrastive learning-based method for zero-shot dense IR. Based on the contrastive learning framework, 3 positive pair construction methods and 2 negative pair construction methods are used and compared. Evaluations are performed on the BEIR benchmark, with the best average result achieved compared to a list of IR (both sparse and dense) baselines in the zero-shot setting.",
    "This paper explores how different strategies for fine-tuning affect in- and out-of-distribution performance. The authors contrast linear probing (updating only the parameters of the final linear layer), end-to-end fine-tuning (updating all parameters of the model) and a two-stage approach, where linear probing is followed by end-to-end fine-tuning. While end-to-end fine-tuning typically improves in-distribution performance, the authors show that it can also underperform linear probing out-of-distribution. The paper theoretically analyzes the tradeoffs in a simplified scenario with two-layer networks, finding that end-to-end fine-tuning can \"distort\" pre-trained features. Their experiments on a number of datasets including CIFAR, WILDS-FMoW and others, confirm the intuitions from their theory. The proposed mitigation strategy, a two-stage fine-tuning approach where end-to-end fine-tuning follows linear probing is found to be beneficial, especially out-of-distribution.   **Update:** The authors addressed most of the concerns raised by this and other reviews, and I am raising my score accordingly.",
    "This paper studies the problem of how to fine-tune a pre-trained model and obtain better results for both ID and OOD. Two methods, fine-tuning and linear probing, are investigated and compared, then a new two-step variant called LP-FT is derived. Results further verify that LP-FT obtains the best performance for ID and OOD tests compared with FT and LP.",
    "This paper contrasts fine-tuning (i.e., modifying all network weights) and linear probing based on their relative ID/OOD performance. It is known that fine-tuning (FT) outperforms linear probing (LP) ID. This paper presents that the reverse is true OOD (FT outperforms LP). This paper suggests that this occurs because fine-tuning distorts features in conjunction with the final linear layer. Instead, if a final linear layer is trained first, the features do not have to move that much during full fine-tuning. The authors refer to this method as LP-FT and show it often outperforms LP and FT both OOD and ID.",
    "This paper discovers an interesting behavior of model fine-tuning: the performance is worse compared to linear probing on OOD data (i.e., data from other domains), especially when the distribution shift between inner distribution and out of distribution are big. The explanation provided in the paper is that fine-tuning distorts the feature representations, overfits on inner distributions, and thus has a higher error on OOD data. The authors also provide a simple solution to this issue by fine-tuning with a classification head initialized from linear probing and had better results in all the benchmarks they have in the paper. ",
    "Learning to discover novel class is a very challenging task and a new research topic in recent years. In this task, a known-class dataset can be used to help cluster novel classes. \u201cNovel\u201d means that there are no overlaps between novel classes and known classes. This setting looks ill-defined since it is not clear why we need known classes to help cluster novel classes. However, this paper answers this question based on a novel concept: K-epsilon separation and points out when this setting is ill-defined/well-defined. Based on this contribution, this paper is above the acceptance borderline.   Nevertheless, the presentation should be polished. Although I understand the setting and the contribution in the end, the presentation flow is not smooth. Some typos make me struggle when I read this paper. Besides, the connection between sampling process and Assumption (D) should be discussed deeply. I find that they might not the same thing.  ",
    "The paper introduces meta-discovery as a way to adapt meta-learning strategies to the problem of learning to discover novel classes. It also presents a formalization of the problem that helps shading light on the conditions under which it is learnable.  The authors additionally introduce a novel sampling strategy aimed at sampling data having the same \"dominant\" view to help the following clustering procedure.  The experimental evaluation shows advantages over existing recent competitors when the number of examples for unseen classes is small.",
    "This paper considers the problem of novel class discovery (NCD). Different from the original setting of NCD, this paper reconsiders the assumptions behind NCD and defines a new yet more practical setting, which can significantly reduce the number of unlabeled data needed for training novel classes. In addition, this paper presents a meta-learning-based approach to address the new setting, which achieves consistent improvements on four public datasets. They also provide a theory to reveal why we need to assume that known and novel classes should share semantic features.",
    "The authors provide a formal definition of the L2DNC task, give proofs of useful insight into the problem, and empirically demonstrate novel methods. The authors use several baselines and ablation to demonstrate the value of the proposed methods. The theoretical insights suggest that common high level features are necessary to solve the L2DNC task, which motivates the proposed approaches based on low dimensional non-linear projection of the data. Similarly the clustering-centric definition of the problem motivates the similarity learning methods presented.",
    "The paper considers the problem of learning a causal model in the POMDP setting. It assumes the learning agent has the ability to collect online experiences through direct interactions with the environment and can access a large collection of offline experiences obtained through the observation of another agent. It further assumes that the observed agent can act based on privileged information hidden from the learning agent. The paper formulates model-based reinforcement learning in this setting as a causal inference problem. The paper then proposes to use offline data as a regularizer during learning. The paper presents empirical results on a number of toy problems.",
    "The authors study the POMDP problem from the causal perspective, and the propose to combine offline and online data to infer the transition model via deconfounding. On the theoretical side, they show that the proposed method is correct and efficient in terms of generalization guarantees. On the experimental side, they evaluate the proposed method on three synthetic toy problems. ",
    "This paper considers the model-based reinforcement learning (RL) problem by combining the offline and online data. The online data, i.e., the interventional data, is generated from the standard partially-observable Markov decision process (POMDP), while the offline data, i.e., the observational data, is generated from the privileged POMDP where the offline learner had the access to the state information (i.e., the unobserved confounder) to make an action. The authors proposed an augmented learning procedure to safely combine these two separate different sources and learn a more efficient policy. Their method is shown both theoretically and empirically better than not using offline data. My main concerns lie in their framework and assumptions, novelty compared with existing literature, and comparison studies.",
    "This paper studies the problems of evaluating interventional distributions (i.e., system dynamics) of a partially observed Markov decision process (POMDP) from samples collected from a combination of randomized experiments and observations of a privileged expert who could access the latent state. The POMDP is presumed to have a finite horizon, e.g., the physician could only perform a finite number of treatments for the same patients. The authors propose an unbiased estimator for evaluating system dynamics from the experimental data. As for the observational distribution where the unobserved confounding exists, the authors derive bounds over unknown system dynamics, estimable from observations.",
    "The paper tackles the problem of open-ended knowledge-grounded natural language generation, in the context of free-form QA or knowledge-grounded dialogue, where models must ground their generations on passages relevant to the input context. Specifically, the authors explore improving the retrieval component of retrieval-augmented systems by utilizing posterior signal from the label. A \u201cguide retriever\u201d learns the relevant passage to retrieve by including the target output in its input context, and then, using an ELBo loss, provides this signal to the normal, in-system retriever. The authors find that their model improves three-fold over baselines: 1) it retrieves relevant passages more frequently; 2) its generations are more grounded in retrieved passages; and 3) its generations are closer to human generations. ",
    "In this paper authors describe an approach to use the responses/ answers to guide retrieval during training of document grounded response generator. By having the retriever being trained using the posterior (p(document|response,context)), the model could learn a better (supervised) retrieval network (based on ColBERT) which could be used to guide the training of the prior ( p(document|context)).  Documents are retrieved using the dialog context and the top-k documents are used for training the posterior as well as the prior. Since the expectation for ELBOLoss cannot be computed exactly (due to the large document set),  it is computed by sampling documents from the top-r retrieved documents -- from either the posterior or the prior, guided by a parameter called alpha which governs the sampling proportion. The idea of doing variational training using a posterior network isn't particularly novel but the authors have made it work for open-ended response generation using this approximation for computing the ELBOLoss. The networks use BART for language generation and CoLBERT for modeling the retrievers. Experiments have been presented using the Wizard of Wikipedia dataset and the MSMARCO NLGEN. Experiments show an improvement over the baseline model (RAG - referred to as MarginalizedLoss) in both retrieval (success@k, MRR) as well as response generation (text-F1 overlap between response and grounded document and textF1 overlap between response and ground-truth output response). Overall this is a well written easy to read paper  ",
    "The paper tackles a problem of knowledge-grounded open-ended generation and proposes a new model that is an extension of an end-to-end training of the retrieval and the generator. In particular, there is another model called \u201cposterior-guide\u201d that is jointly trained with the other two models using ELBo. Intuitively, this posterior-guide is similar to the retriever that scores the evidence, but conditioned on not only the question but also the response. It is used as a weight of each evidence in the generation in order to encourage the generator to ground more to the evidence that is more relevant to the response. The retriever is also trained to be close to the posterior-guide (minimizing KL-divergence). To my understanding, this is a very clever way to give supervision to the model when it is not easy to obtain distant supervision data (unlike in short answer generation where the gold evidence is easily obtained by whether the short answer is included in the evidence or not).  Experiments are done on Wizard of Wikipedia and MS Marco NLGen. The model achieves significant improvements over the baseline retriever, based on three evaluation metrics: relevance, groundedness and generation quality. ",
    "This work focuses on the knowledge grounded text generation tasks. They argue that multiple passages can be valid and relevant to the context, but not all of them are observed/used in the target response. Therefore they propose that, during training, the target response should be utilized to train a \"guide-retriever\",  which predicts P(passage|context, response) and provides passage weight for the generator. A retriever is jointly trained with the generator and the guide-retriever, and the KL divergence between the retriever and the guide-retriever is included in the loss function.  The contribution of this paper is that they proposed a potential solution to the challenge that the model may be not effectively trained in case that multiple passages are valid but only one of few are used.",
    "Authors propose several neural network model-based approaches to influence maximization (IM). First, GLIE estimates influence using a GNN, which can be plugged into optimization algorithms like CELF. Second, GRIM avoids the cost of having to estimate the influence of every candidate by approximating the marginal gain with a two-layer MLP. Finally, PUN avoids the cost of having to estimate the influence for every seed node by approximating the influence with features from GNN hidden states. Experiments demonstrate that the proposed method can generalize to graphs significantly different from training data. Also, PUN provides solution quality close to the strongest baseline with a fraction of compute time.",
    "In this paper, the authors consider using learning-based method for Influence Estimation and Influence Maximization. The author proposed a GNN-based to estimate influence (as an upper bound). Based on the estimated influence, the authors use CELF optimization to find the optimal seed set. To further improve the efficiency, the authors proposed (1) a RL DQN based method and (2) a simplified influence function with only one layer. The author carries out experiments on several synthetic and real-world datasets. ",
    "This paper considers using learning methods to solve the well-known influence maximization problem. The paper proposes to estimate the upper bound of the influence by using graph neural networks, which can be used in subsequent steps for selecting the seed nodes through either Q-learning or a greedy algorithm based on the learned representation. Experiments on various datasets have been provided to evaluate the accuracy of influence estimation as well as the effect of influence maximization.  ",
    "The paper proposes a neural network approach (GLIE) for estimating the influence of a given seed in a given graph. More importantly, the authors propose three different methods to use the proposed Influence Estimation method for Influence Maximization. The authors show the superior performance of their proposed method in comparison with baselines and ",
    "This paper proposes a k-medoid solution for active learning in the context of domain adaptation. The paper builds on top of Mansour et al. (2009) and looks at the discrepancy between source and target distributions. Looking at the whole hypothesis space is very conservative since this would include hypotheses that the learner would never consider as a labeling function. In order to deal with this problem, this paper only considers localized discrepancy (Zhang et al. 2020) where we only consider the hypotheses that are epsilon away from labeling function for source domain, i.e. we are only considering labeling functions that are epsilon away from the source labeling function. Generalization bounds are derived using Rademacher average and localized discrepancy for general loss functions. From these bounds, the paper shows that one can minimize the target risk by solving a k-medoid problem.  ",
    "This paper proposes an active learning method to efficiently select data in the target domain that is suitable for learning hypotheses together with data in the source domain in domain adaptation problems.   The authors first propose to evaluate the dissimilarity between the source and target domains by localized discrepancy, where the hypothesis set is restricted to includes only hypothesithes with sufficiently small errors with the label function of the source domain on the training data (the union set of the input of the source domain and the input of the target domain to be labeled). Then an upper bound of the expected risk for the target domain based on this discrepancy. The main theoretical contribution is that the authors have shown that the discrepancy term in this upper bound is further bounded from above by the sum of the distances between the inputs of the training data and the inputs of the target domain, and this is the background for the design of the active learning algorithm.   In domain adaptation, the goal is to solve the problem of minimizing the discrepancy between the two domains. From the statements of this theorem, it can be replaced by the problem of selecting K data in the target domain so as to minimize the sum of the distances between the inputs of the training data and the inputs of the target domain. The latter problem is equivalent to solving the K-medoids problem for clustering, and the authors' technical contribution is that they have proposed an accelerated algorithm for this problem.   Finally, the authors conduct an evaluation experiment of the proposed method under various scenarios of domain shift using three types of benchmark data. ",
    "The paper studies the problem of active learning for domain adaptation. The paper has two main contributions. First, the problem of the selection of a query target sample set is studied theoretically. A generalization bound is presented, which is based on the recently proposed concept of localized discrepancy as opposed to rather classical discrepancy measures that can be too conservative. The second contribution of the paper is an algorithm for the batch selection of K target queries, which is motivated by the theoretical findings. ",
    "This paper studies active learning for domain adaption for a set of Lipschitz functions. The paper proposes to use a localized discrepancy to restrict the relevant candidate hypotheses. Under Lipschitzness, the localized discrepancy is further relaxed into a distance measure over the X domain; the authors also design an accelerated K-medoid algorithm to minimize such distance. In special cases (under certain simplifying assumptions), theoretical guarantees presented in this paper show advantages over previous ones. The proposed algorithm also shows empirical advantages over existing ones.",
    "Inspired by asymptotic results from singular learning theory, the authors of the paper propose using a generalised gamma mean-field distribution with a normalising flow (that targets the \"desingularization map\") to perform variational inference. The authors additional build on prior work to derive a tighter bound on the log normalised evidence for variational inference using this approximate posterior combined with the \"correct\" desingularization map.   Note: while I am familiar with the Bayesian Neural Network literature, I am not familiar with singular learning theory. This is reflected in my confidence score. As such, I was unable to verify the theory in the paper, and assess the significance of the theoretic results included in the paper.",
    "The paper analyzes the approximation of the log-ratio (called normalized evidence in the paper) (the log-probability under the model minus the log-probability under the true model). Since the model is singular, the Laplacian approximation of the normalized evidence needs a new method. The mean-field distribution and a resolution map allow us to estimate two important numbers (lambda and m) in the approximation.   The paper has made several contributions to the study of this problem in several aspects. First, the paper improves previous results by relaxing the assumption. Second, the paper actually uses a normalizing flow to actually learn the transformation.    ",
    "The paper builds on the recent theoretic results of [Bhattacharya et al. (2020)], which shows that a mean-field variational approximation with carefully chosen approximation family leads to an ELBO $\\Psi$ which is sharp up to a constant C(d) which only depends on the dimensionality d of the parameter space. For the proof, [Bhattacharya et al. (2020)] assumes that the approximation family is a Gamma distribution truncated to [0,1].  Therefore the authors of this paper conjecture that the Gamma distribution truncated to [0,1] is a good choice for the source distribution of a normalizing flow. Their experimental results suggest that this choice leads a higher ELBO than using as source distribution a normal distribution.",
    "Working with Bayesian neural networks, this paper proposed a variational algorithm to approximate posterior distribution of the network weights. To overcome model singularities, the authors used the idea of normalizing flow by transforming the weights through an affine coupling network, and subsequently worked on the desingularized parameter space. In addition, they derived an asymptotic expression for the ELBO, and compared the Gaussian and generalized gamma approximating families in the experiments.",
    "This paper considers the problem of domain generalization (DG), wherein predictors are trained on a related set of training domains and evaluated on an unseen test domain.  The authors first present a learning-theoretic bound on the performance of an average-case formulation for DG, and then present a set of experiments that consider the trade-off between complexity and out-of-distribution (OOD) performance.  The experiments indicate that such trade-offs exist for linear models, and there is also evidence that the trade-off persists for shallow neural networks.",
    "In domain generalization, recent work has shown that ERM has comparable out-of-domain accuracy to state-of-the-art DG methods. The paper aims to explain this result through model complexity. The main argument is that ood generalization requires a smaller model complexity. The upshot is that DG methods can utilize cross-domain validation to obtain better generalizing models.",
    "This paper presents a theory of domain generalization based on statistical learning theory (Rademacher complexity) and demonstrates a trade-off between training loss and model complexity. They show that existing methods are actually controlling the model complexity. Based on the analysis, the authors argue that proper model selection is critical for complexity control. Instead of hyper-parameter search, they propose to use domain-wise cross-validation as the model selection strategy. Experiments on the DomainBed benchmark show the effectiveness of the proposed method.",
    "This paper has several findings taking a bias-variance trade-off of DG performance, that explains existing DG algorithm performance variability. (ii) The complexity control strategy used to determine bias-variance trade-off is crucial in practice, with peak DG performance achieved when optimizing model complexity based on domain-wise validation. (iii) Regularisation required for optimal DG is greater than for conventional optimization for within-domain performance.",
    "The paper introduces a variant/generalization of multi set multi cover problem, where the aim is to maximize the weight of the elements covered at least n times by up to k overlays (subsets of a given input familiy of sets over the elements' universe). The authors show that the objective function is not submodular, hence does not admit a classical greedy approach. They show an ILP formulation that provides an optimal solution but not efficiently. They propose a greedy approach based on maiximization of marginal gains endowed with a look-ahead tie breaking that should prevent failure to attain n-coverage because of wrong initial choices guided by the sole marginal gain maximization objective.  The problem is meant to model vaccine design and show empirical evaluation on two toy data sets and presenting comparisons between the greedy approach and the ILP approach for a covid 19 vaccine. ",
    "Update: I have read the author feedback and other reviews. Based on the more detailed comparison to existing methods, I have updated several of my scores.  ---  In this work, the authors propose a variant of the set covering problem which aim to formalize peptide-based vaccine design as an optimization problem. The authors first formulate the problem and then draw connections to other set covering problems; they then show that the problem is NP-complete. They then propose a greedy algorithm to perform the optimization. A set of experiments suggests the proposed approach outperforms the formulations considered by the authors.",
    "This paper suggest the n-times coverage problem (a natural generalization of set-cover where items need to be covered n>1 times by the sets we choose) and motivates it with an application for the design of COVID vaccines. This application involves some ML pipeline, and this new combinatorial optimization problem helps with one of the steps.  The problem is shown to be not-submodular, and therefore the most standard methods don't quite work. Nonetheless, the authors present a greedy algorithm to get a reasonable approximation.  The paper evaluates the quality of their algorithm on artificial data and shows that it outperforms the more standard greedy method. Then they show the impact of this improvement for vaccine design.",
    "The submission is concerned with vaccine design and proposes to model the task as a combinatorial optimization problem that is essentially a generalization of set cover. The authors describe two algorithms: A marginally greedy algorithm using beam search and a mixed integer linear programming approach.  More precisely, the combinatorial problem consists in covering weighted elements (the population) with overlays (peptides) while maximizing the total weight of those elements that are covered at least n times. Each overlay may only be used once, but may cover the same element multiple times. In total, no more than k overlays may be chosen.  Additionally, the submission features a machine learning based tool that predicts the effectiveness of the designed vaccine.",
    "The paper investigates the effects of weight initialization for deep spiking neural networks (SNNs) on training speed and final accuracy. The main finding is that popular initialization methods for conventional ANNs and RNNs do not match the specific dynamics of SNNs, in particular they ignore the need to have sufficient firing early on to generate good gradients. The paper derives a theoretical first-order approximation on the response curve, and from it a weight initialization scheme that initializes the weights in a region where neurons fire from the first epoch on, but also avoid explosion or reduction of activities throughout the network. In various experiments on standard and spiking variants of MNIST and CIFAR, the initialization scheme shows good performance and fast convergence for different neuron types (e.g. non-leaking vs. fast leaking), and different encoding schemes. For CIFAR10 the results are significantly better than for other initialization schemes.",
    " This paper focuses on the parameter initialization problem of training SNNs. The authors derive the theoretical response of spiking neurons, and propose an initialization method based on slant asymptote, which can overcome the gradient vanishing problem. The results show that the proposed method can effectively improve training speed and accuracy.",
    "The authors tackle the problem of improving spiking neural net training with better initialization. They observe that error backpropagation efficiency in SNNs depends on availability of responding neurons and show that traditional surrogate backprop methods are inefficient as they take many iterations to move weights to the regime supporting neuronal responses.  The authors approximate the SNN neuron model (LIF, IF etc) I/O function using a piecewise-linear  iterative expression and show that clipping the output to (0,1) and normalizing the variance of the random weight initialization to insure that neurons produce substantial responses even with initial random weights results improves SNN training substantially. The improvement is to a large extent due to early onset of convergence. The authors demonstrate the superiority of their approach on MNIST, N-MNIST, DVS-MNIST and CIFAT datasets and present extensive experiments using different optimization algorithms and response functions.  ",
    "This paper enhances the efficient BPTT training of SNNs by proposing an initialization method to match the response of spiking neurons in initial training. Their method bridges the spiking neuron response to the wisdom of traditional deep learning training, which may have an influence on future research like ANN-to-SNN conversions with LIF neurons or other SNN training methods. The authors conduct experiments on CIFAR10, MNIST, and neuromorphic datasets to show the efficacy of their technqiue. One of the main contribution is their theorteical analysis of iterative systems to model first-order integrate-and-fire neurons and investigate the response curve. ",
    "The paper is to solve the distribution shift between daytime modes and nighttime modes in federated learning with a mixture of distributions. The proposed method could be viewed as a two-group clustered federated learning method. In particular, the client clustering is based on the model parameters of prediction layers.",
    "his paper proposes a federated learning method to address a specific non-IID challenge over clients, i.e., when some clients are only available during the daytime and others are only available at the night, and these two types of clients' data are drawn from a mixture of two corresponding distributions. They study a multi-branch model, similar to multi-task learning, such that all clients share the same backbone network to extract data representations but a different branch is applied on top of the backbone network for different distributions. Only the clients with the same data distribution use the same branch to produce the final prediction. Under the assumption that the data representation produced by the backbone network follows a mixture of isotropic Gaussian distributions, this paper proposes an EM algorithm to assign clients to different clusters: the E-step determines the (soft) membership of each client belonging to each cluster and assigns it to the branches, while the M-step estimates the mean and variance of the representation for each Gaussian component in the mixture. Some additional heuristics are shown to be important for this method to achieve promising performance, e.g., label smoothing, a temporal prior of the ratio of clients from day and night, linear/cosine/soft schedule of this ratio, one-hot (hard) assignment of clients to clusters, etc. In experiments, they simulate the day-night distribution shift on EMNIST, CIFAR, and Stackflow datasets in FL by splitting each dataset into two parts with different data types. They evaluate the proposed method under different shifting settings (different p) with a few baselines proposed in this paper. They also empirically studied the effects of label smoothing and different period lengths.",
    "This paper handles the distributional shift observed in data in clients in a federated learning production setting. In particular, the distributional shift is modeled as a mixture of distributions.Furthermore, a multi-branch network is used to encapsulate the shifting distribution and a Federated Expectation-Maximization algorithm enhanced by Temporal priors of the shifting distribution (FedTEM) is proposed. Experiments for image classification on EMNIST and CIFAR datasets, and next word prediction on the Stack Overflow dataset show the efficacy of the proposed algorithm.",
    "This paper investigates the problem of periodic client distribution shift in cross-device FL, as previously investiged by Eichner et al (semi-cyclic SGD). The authors propose to split the NN model in a shared part, with different heads for each component. A GMM model is added on top of the output of the shared part to allocate each client to a given head during training, with a temporal prior for the shift between classes. This GMM is fit via a federated EM scheme, in addition to the federation of the NN weights themselves. Experiments are conducted on EMNIST, CIFAR10/100 and StackOverflow datasets, for 2 components. The results demonstrate the superiority of the proposed method with respect to baseline approaches, including the addition of the temporal prior.",
    "This paper presents a novel methodology for deep network pruning from the perspective of the max-affine spline. The key idea of the paper is to remove the redundant subdivision splines and find winning tickets. This is an interesting and very nicely written paper that bridges the max-affine spline formulation and empirical pruning techniques. The authors provide a sufficient and straightforward introduction of the behind motivation. Beyond these, the authors discuss robustness considerations and perform thorough experiments on various benchmarked models and datasets, showing the favorable performance of their method.",
    "This paper conducts a series of empirical studies, which aim at relating node/filter/channel pruning with the partition of input space by neural nets using spline operators as activation functions. In particular, the final decision boundary is only determined by a few splines defined by a few filters of the network. This is verified in the paper through case studies of both fully-connected networks and convolutional networks, which implies that pruning does not severely degrade the accuracy as long as the important splines are not removed by pruning. Another observation is the early-bird tickets: the paper argues that the important splines do not change too much after a few early epochs since the binary activation patterns of data converge rapidly, so prunning can be applied after only a few epochs. The paper then proposes a pruning strategy that sequentially finds the most similar filter pairs and removes them. In experiments, they show that the proposed prunning method is more efficient than some recent pruning methods to achieve similar accuracy with pruning ratio <=70% for CIFAR10/100 and <=50% for ImageNet. ",
    "This paper mainly proposes a new angle to understand the deep neural network pruning based on Spline theory and propose a new pruning algorithm approach. First, the author introduces the back ground of the Spline theory and current pruning methods. Second, the author analysis the different pruning methods from space partition perspective and introduce the proposed algorithm. Third, the author run experiments to evaluate the proposed algorithm in different aspects. ",
    "The paper proposes to use the max-affine spline function to understand network pruning in the deep learning architecture. Specifically, it uses two examples (one in fully-connected NN and one in CNN) to show the splines visualization with different pruning rates. Inspired by the theory, it then proposes a policy that is based on calculating the cosine similarity between slope and biases to determine the importance. The experiment results show the proposed metric could achieve a similar or better accuracy with good energy efficiency in multiple datasets with both structured pruning and unstructured pruning.",
    "This paper considers fair representation as a bi-level optimization problem where the data representation is first learned then the fair predictors are optimized based on this fixed representation. A theoretical analysis on the the error gap of the implicit algorithm is conducted, and some positive results have been shown in the paper. The paper presents an interesting and topical problem and is easy to follow.   ",
    "This paper proposes a methodology for fair representation learning. The core novelty of the proposal is the satisfaction of a sufficient rule. Experimental results claim good performance with respect to other approaches in terms of an accuracy-fairness tradeoff, in which a sufficient gap is measured.",
    "This paper considers the fair representation learning problem. In particular, the fairness notion utilized is (close to) the sufficient rule, and this paper proposes a bi-level implicit path alignment algorithm to (approximately) achieve it.  The contribution of the paper includes (1) an empirical algorithm for DNN to (approximately) achieve the sufficient rule, (2) theoretical analysis w.r.t. effectiveness of the algorithm as well as its application scope (classification and regression).",
    "The paper considers the learning of fair representations (and classifiers). In particular, the paper considers the (group) sufficiency rule for fairness and optimization path alignment to achieve the fairness requirement. The paper considers a representation fair if the optimization path (gradient steps) of subgroups are equivalent / invariant, with respect to optimal subgroup classifiers. To this end, the paper introduces a bi-level optimization problem for a representation function, which is solved by approximating gradients with the implicit function theorem. The approximation error of the gradients and the convergence of representation function (appendix) are analysed. Their algorithm is then experimentally tested under various datasets and compared to various baseline approaches.",
    "This paper considers design choices involved in offline RL approaches that consider a reduction to weighted/conditional behavior cloning, a class of approaches referred to as Reinforcement Learning via Supervised Learning (RvS). The paper studies various issues including expressivity of policy architecture, regularization, choice of conditioning variables (e.g. based on goals or rewards).   At a high level, the takeaways are (a) RvS approaches are successful when using neural networks with appropriate capacity and regularization, (b) with appropriate conditioning variables (goal/reward based conditioning), (c) RvS can obtain policies that exhibit compositional behavior by conditioning on appropriate events.",
    "The paper investigates different variants of behavior cloning. The methods investigated aim at achieving better policies for use in offline RL through supervised learning than the average behavior contained in the data. The methods studied are categorized and examined against three to four benchmark problems.",
    "The paper studies the behavior cloning based strategies of offline RL algorithms in different type of environments and reports that performance primarily depends on model size and regularization. The results contradict some of the earlier claims, and the authors conjecture that model size and regularization characteristics can explain past results. The paper also discusses additional insights such as the importance of conditioning and simple validation based evaluation fail to generalize. ",
    "This paper studies the importance of the design decisions for supervised learning type reinforcement learning algorithms. Through extensive experiments, find that more complex design choices, such as the large sequence models and value-based weighting schemes used in some prior works, are generally not necessary. Our results show that carefully designed RvS methods can attain results that match or exceed the best prior methods across a range of different offline RL benchmarks, including datasets with little or no optimal data.",
    "This paper investigates the concept of map induction for exploration in novel environments. This is an important problem for robotics applications, relevant for scaling up navigation of autonomous systems to large environments and for exploring unknown environments.   The article's main contribution is a new task and a set of experiments to evaluate the central hypothesis: \"that humans use program induction to infer possible maps of unseen spaces, as made up of submaps encountered in the observed areas\".  This is evaluated by proposing a novel map induction task that is the main contribution of the paper, as well as a set of probabilistic models that implement the different hypotheses considered in the paper. ",
    "This work is motivated by the hypothesis that humans maintain a hierarchical spatial representation when exploring new environments, such that shared patterns (due to the hierarchy) between spatial regions can be used to predict how still unvisited places would look. A simple discrete 2D computational model based on probabilistic program induction is proposed for predicting the map at yet unseen places. The model assumes a discrete set of possible transformations (flips, rotations, concatenations, etc.) of small extracted regions (submaps of previous observations), based on which a distribution over possible completions of empty map regions can be formulated.  A control task is then considered, in which an agent needs to explore a completely new environment and collect rewards (tokens) in the process. Under strong structural assumptions for the test environments (e.g. it is ensured that patterns actually repeat in a very uniform way, rooms look the same, rewards are placed consistently, etc.), it is shown that model-based planning under the map-induction model results in more efficient exploration & reward-collection behavior. Furthermore, a study with actual human subjects is conducted where they need to solve the same task. Results suggest that real-life exploration behavior is consistent with the most expressive version of the proposed computational model, where a full distribution over possible map completions is maintained (as opposed to a MAP estimate or an uninformed model). ",
    "In this paper, the authors try to model how humans explore novel environments. The main hypothesis tested in the paper is that humans think of maps of unseen places as compositions of submaps in observed areas. Towards this, the authors propose a new \"Map Induction Task\" (MIT) to study how humans explore novel maps. Additionally, they try to model the exploration behavior exhibited by humans as a hierarchical bayesian generative framework which generates a distribution over possible maps given past observations, and use this distribution to plan. They present results on their  task (MIT) which validate the aforementioned hypothesis",
    "This paper tests a hypothesis of how humans choose the path to explore and maximize reward in unvisited space based on their past experience. The central hypothesis is that human uses program induction to generate prediction of possible spatial map. Based on human behavior in two experiments, the paper further compared different models of map prediction, and demonstrated that humans actually consider the distribution of possible maps instead of only consider the most likely map.  ",
    "  The paper proposes an extension of particle belief   propagation which allows the factor parameters (e.g.,   neural network weights for factors modeled as NNs) to be   learned using standard stochastic gradient descent.    This algorithm is then applied to several   continuous-domain state estimation tasks involving   articulated objects (e.g., hand pose estimation from   images).    The main contribution of the paper is adapting an   existing line of nonparametric belief propagation methods   to this setting, which allows (partial) end-to-end   learning.    The learning is only partly end-to-end as the particle   resampling stage is non-differentiable. Instead, the   proposed approach supervises the belief at every step of   the algorithm, but does not backpropagate through the   entire inference procedure opting to instead maximize the   belief of the GT values for the unobserved labels at each   step.    Experimental results on synthetic and real datasets for   articulated object state estimation show that the   proposed algorithm is able to learn meaningful NNs for   the unary and pairwise potentials while also producing   reasonable uncertainty estimates. The proposed approach   sometimes outperforms the baselines (e.g., an LSTM), but   in the task of parametric human hand tracking, it lags   behind the state of the art by a large margin.  ",
    "Supervised learning of Markov Random Fields (MRF) by MLE requires to compute pairwise and unary marginals of the current model estimate at each iteration of the likelihood maximisation. This task is not tractable except for MRFs on trees with finite hidden state spaces. The authors consider MRFs with infinite state spaces, propose to model the pairwise and unary potentials by neural nets and aim at developing an approximated belief propagation (BP) approach for learning these networks. BP is known to be exact on trees but is not tractable for infinite state spaces. The authors apply their method on a challenging task of hand pose estimation in  RGB-D image sequences taken from the first-person perspective.",
    "This paper enables end-to-end learning of the factors of a graphical model for nonparametric belief propagation (NBP) methods by using neural networks. It calls this method \"Differentiable nonparametric belief propagation\" (DNBP).   The aim is to replace domain-specific hand crafted factors with learned factors, by replacing each factor with a neural network. Compared to vanilla neural net based solutions, DNBP also reports uncertainty.  The method is evaluated on a couple of toy examples of articulated pose tracking, as well as using hand pose estimation on the FPHAB dataset.  The method is compared against learned, neural network based baselines. ",
    "The method (DNBP) proposed in the paper considers a non-parametric belief propagation method where the unary potential functions, the pairwise potential functions and the particle diffusion function are modeled as feed-forward neural networks. It allows them to learn the parameters of these networks using labeled data which is the main contribution of the paper.  DNBP is evaluated on three tasks (simulated double pendulum, simulated articulated spider, first-person hand action). In each application, DNBP is not able to outperform the considered baseline but it is able to provide measures of uncertainty associated with its predictions. ",
    "The authors present a method for iterative small molecule generation based on an autoencoder framework with graph neural networks. The method specifically focuses on the ability to extend molecular scaffolds (predefined subparts of a molecule) with structural motifs and individual atoms. The authors show results on unconstrained molecular optimization tasks as well as tasks in which a scaffold is given. ",
    "The paper study the problem of fragment-based molecule generation.  They propose a model MoLeR which consists of an encoder of molecular graph using Graph convolutional neural network (two GNN, one for complete molecules and one for partial molecules), a MLP decoder layer to predict the fragment, the attaching atom on the fragment, and the bonding atoms on the partial molecule. To train the model, it includes three losses for multi-task learning: a KL term between variational posterior and prior of latent representation, a self-reconstruction loss, and a property prediction MSE loss.  The paper conduct experiments on GulcaMol and show that it is able to generate molecules similar to the training molecule distribution, from scratch or from a given scaffold. It shows better results than LSTM, JTVAE, CDDD-MCTS, etc.  ",
    "This work proposes a generative model for molecules. The approach uses a library of motifs, extracted from the training data by breaking down molecules through acyclic bonds adjacent to a cycle. The model can also sample individual atoms. The method is set up in an autoencoder fashion with a GCN encoder that learns node and edge embeddings that are projected into a vectorial latent space. The nodes are initialized with features representing which motif they belong to, so the latent space is motif-aware. The generative approach from the latent space is reminiscent of autoregressive models, but it does not marginalize over the full sequential set of steps, and only through single-step transformations. Seeded with a starting atom or motif, the model sequentially samples the motif (or atom) to be connected and which atoms will be connected. Because more than one path can connect an initial and a final product, it is important to train over multiple paths",
    "This paper proposes a graph-based generative model for molecule generation. The proposed framework MoLeR can use scaffolds as the initial seed to incrementlly generate molecules motif by motif or atom by atom so that the generated molecules consist of the specified scaffold. Experiments show the proposed method performs comparably to existing methods on unconstrained molecular optimization tasks and outperforms these methods on scaffold-based tasks. At the same time, the proposed method is more efficient due to that it is not conditioned on the generation history.",
    "The authors propose an algorithm for imitation learning which rewards the agent for observing state-action pairs that are part of the demonstration-set. The main contribution of the paper is the theoretical analysis which shows that the algorithm, given sufficient expert data, matches the expert\u2019s occupancy distribution and expected reward. The proof comes in three parts: first, the authors relate expert rollouts to the limiting distribution of the expert\u2019s policy. Second, the authors put a probabilistic bound on the expected agreement with expert-data based on the mixing time of the agent. Finally, the authors use this bound on expected agreement to bound the difference in expected extrinsic reward. The authors also provide an empirical evaluation in standard control benchmarks.",
    "This paper considers imitation learning problem which aims at obtaining a policy that imitate expert behavior. Authors considers using reinforcement learning with a stationary reward constructed by expert datasets. Through theoretical analysis, the corresponding imitation policy is proved to achieve high expected per-step intrinsic reward and extrinsic reward. The difference between the expert policy and the imitation policy is bounded with a high probability. Some empirical experiments are performed on continuous control tasks. The results show this method is comparable with other algorithms while the algorithm is simpler. ",
    "In this paper, the authors show that, for deterministic experts, imitation learning can be done by reduction to reinforcement learning with a stationary reward. theoretical analysis both certifies the recovery of expert reward and bounds the total variation distance between the expert and the imitation learner, showing a link to adversarial imitation learning. Experiments are given to confirm that the reduction works well in practice for continuous control tasks. ",
    "The paper contributes a theoretical analysis of imitation learning (IL) under deterministic experts. The paper shows that IL in this setting can be reduced to RL with a stationary reward, and the stationary reward minimizes the total variation distance between the expert and the learner. Several empirical experiments were presented to validate the theoretical analysis.",
    "The authors study the problem of improving the worst-group accuracy in the over-parametrized setting. They offer theoretical and empirical evidence that reweighting does not affect the final solution in this setting; in other words, the algorithm would converge to the same interpolators as that of basic ERM. The theoretical analysis is done for linear models, linearized networks, and wide fully connected networks.   The authors also argue that the solution does not change unless a considerable amount of regularization is incorporated, so much so that it affects the training error. Again, some theoretical and empirical evidence is provided.  ",
    "This paper theoretically proves the empirical observation that has been made in a lot of recent works regarding the role of importance reweighing in overparameterized deep networks. For squared loss and independent data points, it theoretically proves that reweighing the data points has no effect on the final model learned for linear models and linearized neural networks. This work also analyzes the role of regularization in preventing this behavior and proves that regularization has to be large enough to prevent small training error to have any effect. This work also has supporting empirical results on two datasets- celeba and waterbirds.",
    "This work studies the problem of training for worst-case subgroup performance. This has been a very prominent research avenue in the past few years and provides a natural approach towards learning fair and \"causal\" models (that do not perform too badly for any pre-specified subgroup). In practice however there have been some difficulties with existing approaches, and e.g., in the overparameterization regime, these methods do not perform well in terms of  worst-case performance on test sets. This paper provides a theoretical explanation for this fact (using linear models and linearized neural networks) and also illustrates it using numerical experiments on two datasets. Furthermore, the authors assess the role of $L_2$ regularization in training. The practical takeaway is that existing approaches based on reweighting require substantial regularization or early stopping to perform well in terms of test accuracy (in the overparamerized regime). ",
    "This paper mainly focuses on the reweighting algorithms (e.g. Importance Weighting, Group DRO) for the worst-group performance. It tries to theoretically explain why overfitting problems always appears in reweighting algorithms. Specifically, the authors prove that under several conditions (e.g. assumptions for algorithms, wide fully-connected neural networks, squared loss), the worst-group test performance of the reweighting algorithm will converge to the same level as ERM.",
    "The paper proposes Rational Inattention Reinforcement Learning (RIRL), a multi-agent reinforcement learning framework that incorporates the behavioral model of rational inattention. Building on the classical formalization of rational inattention, the objective penalizes for the mutual information between the action selected and the observable state of the world. They also extend their framework to support multiple channels of information with heterogeneous cognitive costs.   They empirically evaluate RIRL in two principal-agent problems, building on classical models from the economics literature. The first simulation consists of a single agent, while the second simulation explores interactions between multiple agents following the RIRL-actor architecture (although only the principal faces inattention). ",
    "Standard Bayesian-type decision making models have that given some signal X, our decision makers choose an action A to maximize utility given the signal X. This gives a conditional distribution A|X. Rational inattention models say that the there is limted processing capacity in the agent and model this by requiring that A | X has a capacity constraint (i.e. which under some extra assumptions essentially becomes maximum amount of mutual information).   The authors put this into RL by, basically, writing a policy P(a|s) into an observation component (O(observation | state)) and an action conditional on the realized observation with an information penalty (so the higher capacity the channels, the more penalty).   The authors apply this RIRL model to some canonical game theory games.",
    "The paper proposes a RIRL, which incoporate rational inattention suboptimality into the optimal RL model. The authors simulate RIRL in a single agent and a multi-agent setting. They compare RIRL behavior with the rational model in those settings and discuss the emergent behavior of RIRL. ",
    "This paper studies human bounded rationality using multi-agent reinforcement learning. It particularly focuses on the rational inattention model and proposes the RIRL framework which allows multi-timestep dynamics and information channels with heterogeneous processing costs. The proposed RIRL framework is evaluated in two specific Principal-Agent problems. ",
    "This paper proposed a novel idea that generates imperceptible adversarial attacks for ASR by perturbing the phase information. Proof that phase perturbations reduce the magnitude of the spectrogram is provided. White-box-threat-model-based experimental results showed the proposed method can generate effective adversarial examples for an academic Transformer-based ASR system with better efficiency than the state-of-the-art counterpart methods. ",
    "This paper introduces a new way of constructing adversarial examples for automatic speech recognition using the phase of the short-time Fourier transformation. The authors conduct experiments and subjective evaluations to show how their adversarial examples compare to previous state-of-the-art algorithms. The experimental results show that the proposed phase-oriented audio adversarial samples can be produced in reduced time as well as they are less perceivable by humans.",
    "This paper proposes a phase-oriented algorithm PhaseFool to efficiently construct imperceptible audio adversarial attacks with energy dissipation.  The authors leverage the spectrogram consistency of STFT to adversarially transfer phase perturbations to the adjacent frames and dissipate the energy that is crucial for ASR systems. Empirical evaluations show that the attack effectiveness of the proposed attack is high.",
    "This paper proposes a novel adversarial attack method that attacks ASR network. The idea is that the attack is likely to be imperceptible when phase information is perturbed because phase information is known to give releatively small perceptible difference than magnitude information. The perturbation on phase information influences the magnitude information which is known as energy dissipation. Experiment results show that it reaches almost state-of-the-art results in terms of imperceptibility. The advantage of the proposed method is that it can generate the imperceptible perturbation using fewer steps than the previous state-of-the-art method. They also qualitatively show that it is usually the harmonic parts of speech where the energy dissipates. ",
    "The paper provides a new method for self-supervised learning (SSL), called DirectCopy, based on a previous work DirectPred. An important contribution of this work is theoretical analyses on DirectSet($\\alpha$), a theoretical model on linear neural networks that work with arbitrary $\\alpha$. The authors prove that the weight decay coefficient $\\eta$ has the ability to filter out unnecessary features and hence helps learn useful representations. DirectCopy is a special case of DirectSet($\\alpha$) when $\\alpha=1$. The new algorithm does not require to compute the burdensome eigen-decomposition while enjoying similar empirical performance as DirectPred. ",
    "In this paper, the authors make theoretical progress on understanding non-contrastive self-supervised learning (ncSSL).  ncSSL has previously demonstrated strong empirical performance, even outperforming contrastive learning, but the theory behind it is still unclear.  In this work, the authors build off of prior analysis by [1], and showcase the role weight decay has in learning a desirable representation; it acts as a threshold that discards noisy features with high variance introduced by the data augmentation, and keeps stable features with low variance.    [1] Tian et al., Understanding Self-Supervised Learning Dynamics without Contrastive Pairs, 2019.",
    "This paper attempts to investigate the reasons behind why non-contrastive SSL methods such as BYOL and Sim-Siam do not collapse to trivial solutions, how they learn representations that are related to the data distribution and augmentation process, and how these reduce the sample-complexity of downstream tasks. It heavily draws upon DirectPred (Tian et al) and generalizes the method for directly setting the weights of the predictor network via a parameter that seems to be tied to the strength and distinguishability of the learnt features.   Tian et al: https://arxiv.org/abs/2102.06810",
    "The paper \"Towards demystifying representation learning with non-contrastive self-supervision\" presents and analyzes a family of algorithms, DirectSet(\\alpha), for non-conctrastive self-supervised learning with only positive pairs. The theoretical analysis assumes linear layers, and focuses on a special data distribution assumption, where the input space is separated in two linear subspaces, one invariant under the 'data augmentations', the other being the complement. It is then shown that the proposed algorithm converges to the projection matrix onto the invariant sub-space. Further it is shown theoretically that this has the down-stream advantage reduced sample complexity for learning on this representation. Empirically, it is shown that the method performs on par, or sometimes slightly better, than the previously proposed closely related method DirectPred (Tian et al. 2021). ",
    "This paper introduces a model class of neural networks whose architecture is defined by a circuit that computes a discretized step of a pair of multi-scale ODEs. The key novelty is on the multi-scale aspect of this system. In terms of representation capability, this class can represent LSTMs (and vice-versa) and can also approximate any dynamical system from a very broad class of dynamical systems (as well as multi-scale dynamical systems). The authors also prove upper bounds in l_infinity on both the hidden state values and the gradients, and argue this addresses the exploding gradient problem. They also address the vanishing gradient problem by arguing that the magnitude of the partial gradient corresponding to the contribution that depends on step k of the circuit does not depend on k.  They then present a variety of experiments using this new architectural component for modeling several sequence problems. They include a small study on the multi-scale nature of the datasets they study as well.",
    "The authors propose a new RNN architecture, long expressive memory (LEM), motivated by a system of ODEs with multiple time constants. They prove that it can avoid the vanishing gradient problem while retaining the flexibility to approximate a broad class of dynamical systems. They report comparable or improved prediction performance of LEM-based sequence models across a very wide variety of tasks, as compared to several recent alternatives.",
    "This paper introduces Long Expressive Memory (LEM; Eq. 3) which is a new architecture for recurrent networks derived from discretization of a particular system of multi-scale ODEs (Eq. 2). It presents interesting theoretical results that characterize the properties of the proposed architecture (Sec. 4). The key results are that under certain conditions (e.g. fine discretization) the gradient propagation through time is well behaved, and that it is expressive enough to represent general dynamical systems, and multiscale dynamical systems in particular. Empirical results are presented on the adding problem, a synthetic two-scale dynamical system, sequential MNIST/CIFAR-10 classification, EigenWorms classification of very long time series, heart rate prediction, the Speech Commands dataset, and character-level modeling on Penn Treebank (Sec. 5). Across all tasks, the authors report best performance using the proposed architecture when compared to various methods in the literature. ",
    "The paper tries to propose a new recurrent architecture that could address the well-known issues (of recurrent models) like vanishing gradient and exploding gradient. The architecture is a kind of a realization of numerical discretization of ODEs using an implicit-explicit time-stepping scheme. The authors clearly explain why the designed model architecture can capture multiscale data. The authors also connect the proposed method to vanilla LSTM, Hodgkin-Huxley equations, and heterogeneous multiscale methods for ODEs.  The authors also try to provide theoretical evidence that the proposed methods mitigate the gradient exploding and vanishing issues (under some conditions) while learning informative representations for long/short sequence data.  The authors tried on many tasks across different domains, and the proposed methods consistently outperformed the baselines. The benefits are pretty significant in some tasks.",
    "The paper proposes a method for learning functions that take small point clouds as input, such that they are both permutation and rotation equivariant. To aggregate information from a tuple of points in a rotation equivariant way, it utilizes the geometric product of the points' 3D coordinates. Permutation equivariance is guaranteed by the standard attention framework. The model is evaluated on three scientific tasks: Crystal structure identification, Molecular force regression, and backmapping of coarse-grained operators in molecule simulations.",
    "The paper proposes a geometric algebra attention network for small point clouds. The attention based on geometric algebra\u2019s multivector is rotation equivariant and permutation equivariant. Specifically, attention is composed of four functions that operate on tuples and respect the desired equivariance. Moreover, the paper validates its proposed geometric algebra attention on three domain-specific applications including crystal structure identification, molecular force regression, and back mapping of coarse-graining operators. ",
    "This paper proposes a rotation and permutation equivariant geometric deep learning model for problems where the data is represented as small points clouds. The equivariance properties are achieved by leveraging geometric algebra formulations. More specifically, rotation-equivariance is accomplished by geometric products of multivectors and permutation-equivariance by using an attention mechanism over invariant terms of these products. This model is evaluated in three different applications showing better or comparable results than existing approaches. These models also offer additional features like the analysis of the attention maps produced.",
    "This paper presents a deep neural network for processing small sets of points in three-dimensional space with a rotation-invariance and a permutation equivariance.  The proposed method is twofold. One utilizes a geometric product of geometric algebra on input vectors to achieve the rotation-invariant attributes. The other is a permutation-equivariant reduction over the geometric products using an attention mechanism. The authors demonstrate applications in physical science such as crystal structure identification, molecular force regression, and backmapping of coarse-graining operators. ",
    "Authors propose to solve an order fulfillment problem with imitation learning backed by GNNs. The specific version of the fulfillment problem is nontrivial: discussed has a hierarchy in order (an order can be decomposed into sub-orders), and items become forbidden over time. SCIP package is used as the expert policy, and authors employ behavior cloning. The specific model they use is a Graph Attention Transformer on the tripartite graph of orders, items, and warehouses. Compared to a reasonable heuristic, Pointer Network, and GAT which ignores edge features, the propose method yields much lower inference latency. ",
    "A Graph Neural Network (GNN) model is designed to enable the supervised learning of optimal solutions for an order fulfillment problem in supply chain management. This is a problem that must be solved in real-time, making a GNN whose forward computations are quick an attractive option.  The proposed GNN model has three types of nodes corresponding to orders, items, and warehouses. Edges between the nodes of different types represent relationships between them (e.g., an item is in an order). Nodes and edges may have feature vectors representing additional information, e.g., the identity of a warehouse or certain costs on the edges. The GNN is designed to take these features into account.  The model is trained using optimal solutions as labels in a binary classification formulation. Predictions are post-processed to guarantee a feasible solution in the constraints of the order fulfillment problem.  Experimental results on randomly generated instances show that a GNN trained on small instances of this problem performs well even on larger instances, yielding near-optimal solutions in a short amount of time compared to simple GNN solutions, a non-ML heuristic, and an exact solver.",
    "This paper presents a graph based deep learning model for solving the order fulfillment problem of assigning retail (sub-)orders to different warehouses for fulfilment. It formulates the problem as a Mixed Integer Problem (MIP, although I think it is fully integer) which can be solved using a (open-source) MIP solver such as SCIP. Following up on related work, the authors train a graph neural network, specifically designed to incorporate edge features and different types of nodes, to predict the optimal solution, using supervised learning on a dataset of 100.000 generated instances solved with SCIP. Empirically, on three different test problem sizes, the trained model provides solutions within 2-3% to the results found by SCIP, while being a 2-4 orders of magnitude faster. ",
    "This paper proposes a heuristic graph based machine learning model, which can be used to solve the class of order fulfillment problems. The original mixed integer programming problem is known to be NP-hard, and thus computationally intractable. The authors treat each instance of the order fulfillment problems as a tripartite graph, which serves as the input of the proposed model.   The proposed model consists of three parts: a graph attention network (GAT) to embed the features, a feed forward (FF) layer, and an assignment layer generating the output. ",
    "This paper introduces a new dialogue summarization task that requires summaries to mention new concepts that are not explicitly mentioned in -- but may be implied by -- the dialogue. The task, CODC, repurposes the VisDial dataset (itself based on the MSCOCO captioning dataset), which involved information-seeking question-and-answer dialogues about an image, where the dialogue participants were prompted by the image's caption. The captions frequently mention some concepts that are not mentioned in, but are implied by, the dialogue. In CoDC, the task is to produce the reference caption (which is treated as a dialogue summary) from the dialogue (without using the images). Summarization models are evaluated on standard text overlap with the references, as well as an WordNet-based F1 metric that measures whether the model's output has inferred concepts in the references which were not mentioned in the dialogue.",
    "The authors introduce a new problem, inferencing Concepts Out of DIalogue Context (CODC) wherein a ML model is tasked with producing concepts that are not explicitly mentioned in the input. The authors define this problem concretely and introduce metrics to study it. Particularly they define concepts as noun phrases that follow a very specific set of rules within wordnet. The authors propose metrics and a model to test the ability of systems on these CODC problems. ",
    "The paper tackles the problem of dialogue summarization, where a generated summary should include concepts that are not literally mentioned in the dialogue but can be inferred based on one\u2019s commonsense. The paper provides precise definition of such concepts (called CODC in the paper) and evaluation metrics. It then proposes a new model that retrieves relevant concepts from ConceptNet, and feeds them to the text generator. Experiments show small improvements over a range of baselines in automatic evaluation, CODC evaluation, and manual human evaluation.",
    "This paper tackles the problem of modeling monotonic and non-monotonic reasoning rules in different embeddings spaces, mostly vectors, but under different score functions used by the vector embeddings. The paper first provides the definition of monotonic reasoning, then iterates through a few vector-based embedding and label functions to check if they are able to model the monotonic reasoning part. Then the paper proposed a Relu based model that is able to model both monotonic and non-monotonic reasoning. ",
    "This paper looks at entity embeddings and theoretically tries to answer which kinds of semantic dependencies can be modeled by them. Mainly focusing on settings where the entity embeddings are obtained by pooling the embeddings of its attributes (although this is a strong assumption), this paper presents various theoretical limitations of the embedding approaches in learning logical/structured attribute representations with known logical or structured dependencies in practice. The paper shows that some of the most popular embedding models are not able to capture basic logical rules.",
    "This paper provides a thorough analysis of the representational capacity of KB embedding models, analyzing the extent to which they can capture logical dependencies of a knowledge base. The authors consider a large range of common scoring functions, and both monotonic and non-monotonic dependencies. The authors make salient points as to the relevance of this sort of analysis - i.e. if a model is incapable of representing such dependencies then it cannot possible capture them from data - however there are a few limitations. For one, the authors are focusing on a setting where entity embeddings are pooled representations of attribute representations, which is not particularly standard (as acknowledged by the authors). Furthermore, there is a question of the extent to which the counterexamples as presented often manifest in real data, and how poorly a model which compromises to meet its objective would perform on various relevant queries. Both of these are reasonable limitations, however, in that they make the theoretical analysis possible and suggest conclusions that may reasonably apply to real-world data settings.",
    "This paper surveys the performance of BERT on tasks that requires logical reasoning. The survey first introduces basic building blocks that a model should have in order to perform reasoning on natural language (e.g. handling negations, stability to word-order, etc). Next it describes a series of reasoning tasks and report performance on BERT-based models. BERT-based model performs well on reasoning tasks when all information required to perform deductive reasoning, such as facts and rules, are provided (e.g. logical reasoning). However, when certain information needs to be inferred (background knowledge), these models fail (text understanding, mathematical reasoning). Finally, the survey discusses two tasks (Parity and Dyck-2) that has been theoretically proved that transformers cannot perform and the paper comes up with two example reasoning tasks and shows that transformer models indeed fail on them.",
    "Authors survey the literature on probing the understanding, reasoning, and commonsense properties of transformer-based models, outlining several limitations of current models. They cover mispriming, negations, the tendency of such models to learn simple heuristics, under-sensitivity to word order, reasoning with patterns resembling Horn clauses, commonsense reasoning, reasoning with temporal knowledge. Furthermore, they also cover several natural language understanding tasks such as natural language inference and mathematical reasoning.",
    "This paper provides a survey on recent work in the area of reasoning using transformer based models. It first describes common issues that are faced by transformers such as falling prey to lexical overlap and indifference to word order, and then goes on to describe different kinds of reasoning that can be tackled using transformers and the relevant work tackling each. Finally, the paper gives two examples of types of tasks that are beyond the capabilities of transformers. ",
    "This paper is about trying to learn a function from typed input-output data so that it can generalize to test data with an input-output type that it hasn't seen during training. It should be able to use \"analogy\" (if we want to translate from French to Spanish but don't know how to do so directly, we should translate from French to English and English to Spanish). It should also be able to generalize better by learning useful \"subfunctions\" that can be composed together by an RL agent. We set up the solution as having a finite number of subfunctions, including \"HALT\" which signifies the end of computation. At each timestep an RL agent chooses a subfunction to apply to the current representation until \"HALT\" is chosen. The main idea is we parameterize these subfunctions and the RL agent as neural networks which are learned based on input -output data. RL agent is also penalized for using many subfunctions. The algorithm is called compositional recursive learner (CRL). Both analogy and meaningful subfunctions should arise purely because of this design.",
    "This paper proposes a model for learning problems that exhibit compositional and recursive structure, called Compositional Recursive Learner (CRL). The paper approaches the subject by first defining a problem as a transformation of an input representation x from a source domain t_x to a target domain t_y. If t_x = t_y then it is called a recursive problem, and otherwise a translational problem. A composite problem is the composition of such transformations. The key observation of the paper is that many real-world problems can be solved iteratively by either recursively transforming an instance of a problem to a simpler instance, or by translating it to a similar problem which we already know how to solve (e.g., translating a sentence from English to French through Spanish). The CRL model is essentially composed of two parts, a set of differential functions and a controller (policy) for selecting functions. At each step i, the controller observes the last intermediate computation x_i and the target domain t_y, and then selects a function and the subset of x_i to operate on. For each instance, the resulting compositional function is trained via back-propagation, and the controller is trained via policy gradient. Finally, the paper presents experiments on two synthetic datasets, translating an arithmetic expression written in one language to its outcome written in another language, and classifying MNIST digits that were distorted by an unknown random sequence of affine transformations. CRL is compared to RNN on the arithmetic task and shown to be able to generalize both to longer sequences and to unseen language pairs when trained on few examples, while RNN can achieve similar performance only using many more examples. On MNIST, it is qualitatively shown that CRL can usually (but not always) find the sequence of transformations to restore the digit to its canonical form.",
    "The main contribution of the paper is an integral model compression method that handles both weight and activation pruning. Increasing the network weight and activation sparsity can lead to more efficient network computation.  The authors show in the paper that pruning the network weights alone may result in a decrease in activation sparsity, which may not necessarily improve the overall computation. The proposed solution is a 2-stage process that first prunes the weights and then the activation. ",
    "This article presents a novel approach called Integral Pruning (IP) to reduce the computation cost of Deep neural networks (DNN) by integrating activation pruning along with weight pruning. The authors show that common techniques of exclusive weight pruning does compress the model size, but increases the number of non-zero activations after ReLU. This would counteract the advantage of DNN accelerator designs (Albericio et al., 2016; Reagen et al., 2016) that leverage activation sparsity to speed up the computations. IP starts with pruning the weights using an existing technique to mask out weights under a threshold and then fine-tune the network in an iterative fashion to maintain the accuracy. After weight pruning, IP further masks out the activations with smaller magnitude to reduce the computation cost. Unlike weight pruning techniques that use static masks, the authors propose to use dynamic activation masks for activation sparsity in order to account for various patterns that are being activated in DNN for different input samples. In order to do this, the 'winner rate' measure for every layer (or for a group of layers in deep networks like ResNet32) is defined, to dynamically set the threshold for the generation of activation masks which eventually controls the amount of non-zero activation entries. The article empirically analyzes the sensitivity of activation pruning on validation data by setting different winner rates at every layer in DNN and decides upon a set of winner rates accordingly followed by an iteration of fine-tuning the network to maintain its performance. The authors show that their technique produced lower number of non-zero activations in comparison with the intrinsic sparse ReLU activations and weight pruning techniques. ",
    "The paper presents a deep-learning-based version of the knockoff method by Candes et al. for FDR control in feature selection problems to avoid assumptions posed on the distribution of features by the original method. In a supervised feature selection setting, the goal of the knockoff framework is to select a set of input features that are statistically associated to an output variable Y, while controling the FDR. The basic idea behind knockoff is to generate artificial input feature vectors, (i.e. knockoffs) that are independent of Y, when conditioned on the real feature vector X, but after swapping arbitrary elements with X, are distributed as X. Sets of associated features and FDR estimates are obtained by contrasting suited feature selction criteria that measure associations of knockoffs and real features with the target Y.",
    "This paper introduces a novel feature selection method by utilizing GAN to learn the distributions. The novelty of this paper is to incorporate two recent works, i.e. knockoff for feature selection and W-GAN for generative models. Compared to the latest knockoff work which requires a known multivariate Gaussian distribution for the feature distribution, the proposed work is able to generate knockoffs for any distribution and without any prior knowledge of it.",
    "In this paper, the authors propose a spatial-Winograd pruning framework, consisting of spatial structured pruning and Winograd direct pruning.  First, spatial structured pruning allows the pruned weight in the spatial domain to be kept in the Winograd domain. Then, Winograd direct pruning can further improve the sparsity in the Winograd domain. The organization of paper is OK.  The main concern is about the practical part. In the experiment, the advantage of propose framework is marginal, compared to the relevant approaches.  More comparisons with the state-of-the-art approaches should be investigated, such as light-weight design (MobileNet, ShuffleNet).  ",
    "The paper proposes a technique (well, two) to prune convolutional layers to reduce the required amount of computation when  the convolutions are done using the winograd algorithm. Winograd convolutions first transform the image and the filter, apply a multiplication in the transformed space, and then retransform the image back to the intended image space. The transformation of the filter, however, means that sparsity in the regular domain does not translate to sparsity in the winograd domain.",
    "The paper uses Generative Adversarial Networks (GAN) for unsupervised and semi-supervised clustering. Neural network based generators are used for sampling using a mixture model. The parameters of the generators are optimised during training against a discriminator that tries to distinguish between generated distributions. Experimental results on MNIST and SVHN datasets are given to motivate their models.",
    "The paper presents a generative model that can be used for unsupervised and semi-supervised data clustering. unlike most of previous method  the latent  variable is composed of both continuous and discrete variables. Unlike previous methods like ALI the conditional probability  p(y|x) of the labels given the object is represented by a neural network and not simply drown from the data.  The  authors show a  clustering error rate on the MNIST data that is better than previously proposed methods. ",
    "In this paper the authors propose a new variance-reduction technique to use when computing an expected loss gradient where the expectation is with respect to independent binary random variables, e.g. for training VAEs with a discrete latent space. The paper is interesting, highly relevant, simple to implement, suggests many possible extensions, and shows good results on the experiments performed. However the exposition leaves a lot to be desired.",
    "For binary layers, how to calculate and backpropagate gradients is a big problem, particularly for the binary neural networks. To solve the problem, this paper proposes an unbiased and low variance augment-REINFORCE-merge (ARM) estimator. With the help of an appropriate reparameterization, the antithetic sampling in an augmented space can be used to drive a variance-reduction mechanism. The experimental results show that ARM estimator converges fast, has low computational complexity, and provides advanced prediction performance.",
    "The paper presents an extension of the MXFusion language that allows the use of probabilistic modules. These modules are defined as a set of random variables and a specific probabilistic distribution. The modules also contain dedicated inference methods. Using these modules, one can use probabilistic distributions with inference methods tailored to the distribution, which are usually more efficient than generic inference systems.",
    "In this paper authors present a new Probabilistic Programming Language (PPL) MXFusion. Similarly to the languages for the deep learning (TensorFlow, PyTorch, etc.), this language introduce probabilistic modules that are used as building blocks for complex probabilistic models. Introducing modularity to the probabilistic programming, raises the problem of inference for probabilistic models. Since, we cannot obtain the exact solution on practice we have to resort to approximate inference methods. The approximate inference methods can be either generic, thus, being suitable for many probabilistic models but resulting in poor approximation, or specific, thus, having good approximation quality, but only for specific probabilistic models. Authors propose to address this problem by encapsulating specific inference methods in corresponding probabilistic modules. Doing so, one can perform approximate inference for every module with the best suitable inference technique. Authors demonstrate interface of MXFusion for three well known probabilistic models: Bayesian linear regression, deep kernel learning, Bayesian Gaussian process latent variable model.",
    "This work introduces SNIP, a simple way to prune neural network weights before training according to a specific criterion. SNIP identifies prunable weights by the normalised gradient of the loss w.r.t. an implicit multiplicative factor \u201cc\u201d on the weights, denoted as the \u201csensitivity\u201d. Essentially, this criterion takes two factors into account when determining the relevance of each weight; the scale of the gradient and the scale of the actual weight. The authors then rank the weights according to their sensitivity and remove the ones that are not in the top-k. They then proceed to train the surviving weights as normal on the task at hand. In experiments they show that this method can offer competitive results while being much simpler to implement than other methods in the literature.",
    "The paper focuses on pruning neural networks. They propose to identify the nodes to be pruned even before training the whole network (conventionally, it is done as a separate step after the nn was trained and involves a number of iterations of retraining pruned nn). This initial step that identifies the connections to be pruned works off a mini-batch of data.",
    "This paper addresses issues with the beam search decoding algorithm that is commonly applied to recurrent models during inference. In particular, the paper investigates why using larger beam widths, resulting in output sequences with higher log-probabilities, often leads to worse performance on evaluation metrics of interest such as BLEU. The paper argues that this effect is related to \u2018search discrepancies\u2019 (deviations from greedy choices early in decoding), and proposes a constrained decoding mechanism as a heuristic fix. ",
    "- The paper generalizes upon past observations by Ott et al. that NMT models might decode \"copies\" (of the source sentence) when using large beam widths, which results in degraded results. In particular, the present paper observes similar shortcomings in two additional tasks (summarization and captioning), where decoding with large beam widths results in \"training set predictions.\" It's unclear if this observation is novel, but in any case the connection between these observations across NMT and summarization/captioning tasks is novel.",
    "This paper presents a method for increasing the efficiency of sparse reward RL methods through a backward curriculum on expert demonstrations. The method in the paper is as follows: assuming access to expert demonstration and a resettable simulator, the start state of the agent in the beginning of training is sampled from end of demonstration (close to the rewarding state) where the task of achieving the goal is easy. Then gradually through a curriculum this is shifted backwards in the demonstration, making the task gradually harder. ",
    "The paper presents a strategy for solving sparse reward tasks with RL by sampling initial states from demonstrations. The method, Backplay, starts by sampling states near the end of a demonstration trajectory, so that the agent will be initialized to states near the goal. As training progresses, the initial state distribution is incrementally shifted towards earlier steps in the demonstration, until the agent is trained starting from the original initial state. The authors further provide an analysis of the sample complexity of this method on a simple MDP. The method is demonstrated on a maze navigation task and a challenging game Pommerman.",
    "The paper proposes a multi-layer pruning method called MLPrune for neural networks, which can automatically decide appropriate compression ratios for all the layers. It firstly pre-trains a network. Then it utilizes K-FAC to approximate the Fisher matrix, which in turn approximates the exact Hessian matrix of training loss w.r.t model weights. The approximated Hessian matrix is then used to estimate the increment of loss after pruning a connection. The connections from all layers with the smallest loss increments are pruned and the network is re-trained to the final model.",
    "This paper introduces an approach to pruning the parameters of a trained neural network. The idea is inspired by the Optimal Brain Surgeon method, which relies on second derivatives of the loss w.r.t. the network parameters. Here, the corresponding Hessian matrix is approximated using the Fisher information to make the algorithm scalable to very deep networks.",
    "This work proposes a novel analytic framework exploited on a semantic segmentation model to visualize GANs at unit (feature map) level. The authors show that some GAN representations can be interpreted, correlate with the parsing result from the semantic segmentation model but as variables that have a causal effect on the synthesis of semantic objects in the output. This framework could allow to detect and remove the artifacts to improve the quality of the generated images.",
    "This paper provides a visualization framework to understand the generative neural network in GAN models. To achieve this, they first find a group of interpretable units and then quantify the causal effect of interpretable units. Finally, the contextual relationship between these units and their surrounding is examined by inserting the discovered object concepts into new images. Extensive experiments are presented and a video is provided.",
    "This paper proposes first to measure distances, in a L2 space, between functions computed by neural networks. It then compares those distances with the parameter l2 distances of those networks, and empirically shows that the l2 parameter distance is a poor proxy for distances in the function space. Following those observations, the authors propose to use such constraint to combat catastrophic forgetting, and show some results on the permuted MNIST task. Finally, they propose the Hillber-constrained gradient descent (HCGD), a gradient descent algorithm that constraint movement in the function space, and evaluate it on a CNN (CIFAR10) and an LSTM (permuted MNIST).",
    "This paper proposes a method for functional regularization for training neural nets, such that the sequence of neural nets during training is stable in function space. Specifically, the authors define a L2 norm (i.e., a Hilbert norm), which can be used to measure distances in this space between two functions. The authors argue that this can aid in preventing catastrophic forgetting, which is demonstrated in a synthetic multi-task variant of MNIST.   The authors also show how to regularize the gradient updates to be conservative in function space in standard stochastic gradient style learning, but with rather inconclusive empirical results.  The authors also draw upon a connection to the natural gradient.",
    "This paper tackles the important challenge of making sense of temporal measurements made in biological systems. Among other, those have the peculiarity that they are not independent but with a dependency structure, which can be encoded as a graph or a network. The authors claim that their approach, DyMoN is adapted to the many challenges of biological high-throughput data sets: noise, sparsity and lack of temporal resolution. The paper presents three very different use of the method in complex biological systems in Section 3: (i) Calcium imaging of visual cortex neurons, (ii) T--cell development in the thymus, and (iii) Human embryonic stem cell differentiation. Section 4 assesses the performance of the method on simulated data sets as well as on a face-recognition data set. Moreover, the authors demonstrate how the features of the NN can be interrogated to shed new insight about the process under scrutiny. They also show the gain in running time a comapred to other approaches.",
    "> Even though the paper details the underlying Markovian setup in Section 2, it is unclear to the reader how this knits with the FFNN architecture, for example what are the Markovian functions at hidden layer and output layer. Are they all conditional probabilities? How do you prove that this is what occurs within each node?",
    "This paper performs unsupervised classification where the number of classes is unknown. The main idea is to use the CycleGAN framework such that one can reconstruct the original image by first moving to latent space that represents another class (via the connector network), then moving back to the original latent space and going back into image space using a generator. Experiments are conducted on MNIST and CIFAR.",
    "This paper develops an unsupervised classification algorithm using the idea of CycleGAN. Specifically, it constructs a piece-wise linear mapping (the Connector Network) between the discriminator network and the generator network. The learning objective is based on the cycle-consistency loss. Experiments show that it can achieve reasonable loss. This paper addresses an important problem, namely, unsupervised image classification, and may present interesting ideas. However, the paper is not in a good shape for publication in its current form.",
    "The authors introduce a method to learn to permute sets end-to-end. They define the cost of a permutation as the sum of pairwise costs induced by the permutation, where the pairwise costs are learned. Permutations are made differentiable by relaxing them to doubly stochastic matrices which are approximated with the Sinkhorn operator. In the forward pass of the algorithm, a good permutation (ie one with low cost) is obtained with a few steps of gradient descent (the forward pass itself contains an optimization procedure). This permutation is then either used directly as the output of the algorithm or is used to permute the original inputs and feed the permuted sequence to another module (such as an RNN or a CNN). The method can easily be adapted to other structures such as lattices by considering row-wise and column-wise pairwise relations.",
    "This paper proposed an interesting idea of learning representations of sets by permutation optimizations. Through learning a permutation of the elements of a set, the proposed algorithm can learn a permutation-invariant representation of that set. To deal with the underlying difficult combinatorial optimization problem, the authors proposed to relax the optimization constraints and instead optimize over the set of doubly-stochastic matrices with reparameterization using the Sinkhorn operator. The cost function of this optimization is related to a pairwise ordering cost, which compares the order for each pair of the elements.",
    "This paper proposes a Projective Subspace Network (PSN) for few-shot learning. The PSN represents each support set of classes as a subspace obtained by SVD. Then the method calculates distances between a query and classes by the projection error to the subspace. Instead of using the prototype of the class center, the subspace representation is more robust to outliers. Though the contribution seems to be incremental, it is a reasonable improvement upon Matching Networks and Prototypical Networks.",
    "This paper considers the problem of few-shot learning and proposes a new embedding-based approach. In contrast to previous work (such as Matching Networks and Prototypical Networks) where distance is computed in pure embedding space, this work proposes computing a low-dimensional subspace to represent a class and using the distance from an embedded query point to this subspace. The low-dimensional subspace for a class is computed by running truncated Singular Value Decomposition on the normalized embeddings of all points in the support set for that class and using the top n left singular vectors as the basis for the class's subspace. The authors also propose an extension to their model to the semi-supervised few-shot learning setting by incorporating masked-mean computation and zero-mean cluster for distractor items (both ideas borrowed from Renn 2017 for prototypical networks). Experiments are conducted on Mini-Imagenet in the few-shot learning setting and on Mini-Imagenet and Tiered-ImageNet in the semi-supervised few-shot learning setting.",
    "They are proposing a meta-learning method inspired by previous method, MAML. Their idea is separating the parameters in to two groups of context and shared parameters. The context parameters are learned through back-propagation of inner-loop and represents embedding for individual task. Shared-parameters on the other hand are shared between all tasks, and are learned in the outer-loop. ",
    "CAML is a gradient-based meta-learning method closely related to MAML. It divides model parameters into disjoint sets of task-specific parameters $\\phi$ which are adapted to each task and task-independent parameters $\\theta$ with are meta-learned across tasks. $\\phi$ are then interpreted as an embedding and fed as input to the model (parameterized by $\\theta$). Experiments demonstrate that this approach performs on par with MAML while adapting far fewer parameters. An additional benefit is that this approach is less sensitive to the adaptation learning rate and is easier to implement and faster to compute.",
    "This paper proposes a privacy framework where a privatizer, according to the utility and secret specified by users, provides a sanitized version of the user data which lies in the same space as the original data, such that a utility provider can run the exact algorithm it uses for unsanitized data on the sanitized data to provide utility without sacrificing user privacy. The paper shows an information theoretic bound on the privacy loss and derives a loss function for the privatizer to use. It then proposes an algorithm for the privatizer, evaluates its performance on three scenarios.",
    "This paper studies the problem of representing data records with potentially sensitive information about individuals in a privacy-preserving fashion such that they can be later used for training learning models. Informally, it is expected from the transformed output of data record, one should be able to learn about a desired hidden variable, but should not be able to learn anything about a sensitive hidden variable. To that end, the paper proposes a KL divergence based privacy notion, and an algorithmic approach to learn a representation while balancing the utility privacy trade-off.",
    "This paper proposes a new trick to improve the stability of GANs. In particular the authors try to tackle the vanishing gradient problem in GANs, when the discriminator becomes to strong and is able to perfectly separate the distribution early in training, resulting in almost zero gradient for the generator. The authors propose to increase the difficulty of the task during training to avoid the discriminator to become too strong.",
    "Authors argue that the main issue with stability in GANs is due to the discriminator becoming too powerful too quickly. To address this issue they propose to make the task progressively more difficult: Instead of providing only the samples to the discriminator, an additional (processed) bitstring is provided. The idea is that the bitstring in combination with the sample determines whether the sample should be considered true or fake. This in turn requires the decision boundary of the discriminator to become more complicated for increasing lengths of the bitstring. In a limited set of experiments the authors show that the proposed approach can improve the FID scores.",
    "In this interesting study, the authors show that incorporating rotation-equivariant filters  (i.e. enforcing weight sharing across filters with different orientations) in a CNN model of the visual system is a useful prior to predict responses in V1. After fitting this model to data, they find that the RFs of model V1 cells do not resemble the simple Gabor filters of textbooks, and they present other quantitative results about V1 receptive fields. The article is clearly written and the claims are supported by their analyses. It is the first time to my knowledge that a rotation-equivariant CNN is used to model V1 cells.",
    "The paper analyses the data collected from 6005 neurons in a mouse brain. Visual stimuli are presented and the responses of the neurons recorded. In the next step, a rotational equivariant neural network architecture together with a sparse coding read-out layer is trained to predict the neuron responses from the stimuli. Results show a decent correlation between neuron responses and trained network. Moreover, the rotational equivariant architecture beats a standard CNN with similar number of feature maps. The analysis and discussion of the results is interesting. Overall, the methodological approach is good.",
    "The authors present a distributed implementation of signSGD with majority vote as aggregation. The result is a  communication efficient and byzantine robust distributed training method. This is an interesting and relevant problem. There are two parts in this paper: first the authors prove a convergence guarantee for signSGD, and then they prove that under a weak adversary attack signSGD will be robust to a constant fraction of adversarial nodes. The authors conclude with some limited experiments.",
    "This paper continues the study of the signSGD algorithm due to (Balles & Hennig, Bernstein et al), where only the sign of a stochastic gradient is used for updating. There are two main results: (1) a slightly refined analysis of two results in Bernstein et al. The authors proved that signSGD continues to converge at the 1/sqrt(T) rate even with minibatch size 1 (instead of T as in Bernstein et al), if the gradient noise is symmetric and unimodal; (2) a similar convergence rate is obtained even when half of the worker machines flip the sign of their stochastic gradients. These results appear to be relatively straightforward extensions of those in Bernstein et al.",
    "This paper proposes a Generative Adversarial Network (GAN) methodology to learn the distribution of limit orders that arrive on an equity market. The proposed approach captures the (mostly discrete) structure in the generated orders; modeling is carried out with a conditional Wasserstein-GAN with a recurrent neural networks in both the generator and critic used to capture the time dependency, and convolutional layers to capture other conditioning information. Experiments are provided on both synthetic and real data.",
    "The objective of this paper is to use GAN for generating the order stream of stock market data.   The novelty of the paper is the formulation of the order stream and the use of GAN for generating the stock data.   This is a paper for the application of GAN and there are limited contribution to the technical aspect of machine learning.    The paper is clearly written.   There are two main assumptions used in the paper; one is the Markov chain and the second one is the stationary distribution.   In real case, both assumptions are unlikely  to be satisfied.  The orders are mostly affected by many external factors and financial data are known to be non-stationary.  The authors may have to justify these assumptions. ",
    "The paper aims at studying the setting of perturbed rewards in a deep RL setting. Studying the effect of noise in the reward function is interesting. The paper is quite well-written. However the paper studies a rather simple setting, the limitations could be discussed more clearly and there are one or two elements unclear (see below).",
    "The authors present work that shows how to deal with noise in reward signals by creating a surrogate reward signal. The work develops a number of results including: showing how the surrogate reward is equal in expectation to the true reward signal, how this doesn't affect the fixed point of the Bellman equation, how to deal with finite and continuous rewards and how the convergence time is affected for different levels of noise. They demonstrate the value of this approach with a variety of early and state-of-the-art algorithms on a variety of domains,, and the results are consistent with the claims.",
    "This paper discusses the effect of increasing the widths in deep neural networks on the convergence of optimization. To this end, the paper focuses on RNNs and applications to NLP and speech recognition, and designs several groups of experiments/measurements to show that wider RNNs improve the convergence speed in three different aspects: 1) the number of steps taken to converge to the minimum validation loss is smaller; 2) the distance from initialization to final weights is shorter; 3) the step sizes (gradient norms) are larger. This in some sense complements the theoretical result in Arora et al. (2018) for linear neural networks (LNN), which states that deeper LNNs accelerates convergence of optimization, but the hidden layers widths are irrelevant. This also shows some essential difference between LNNs and (practical) nonlinear neural networks. ",
    "Understanding the effects of over-parametrization in neural network training has been a major challenge, albeit a lot of progress has been made in the past few years. The present paper is another attempt in this direction, with a slightly different point of view: the work characterizes the impact of over-parametrization in the number of iterations it takes an algorithm to converge. Along the way, it also presents further empirical observations such as the distance between the initial point and the final point and the angle between the gradients and the line that connects the initial and final points. Even though the observations presented are very interesting, unfortunately, the paper doesn't have the level of rigor required that would make it a solid reference. ",
    "This paper introduces a new framework to solve online combinatorial problems using reinforcement learning. The idea is to encode the current input, the global parameters, and a succinct data structure (to represent current states of the online problem) as MDP states. Such a problem can then be solved by deep RL methods. To train such models, the authors use a mixture of input distributions. Some come from hard distributions which are used to prove lower bounds in the TCS community, and the others are carefully constructed distributions to fool a specific set of algorithms. The authors made an important point that their algorithms are uniform in the TCS sense, i.e., the algorithm does not depend on the input length.",
    "The overall goal of this paper is to solve online combinatorial optimization (OCO) problems using reinforcement learning. Importantly, the authors are not seeking to establish new results for unsolved problems, but instead they are motivated by analyzing and comparing the quality of solutions predicted by reinforcement learners with respect to the well-known near-optimal strategies for some OCO tasks. In doing so, the authors focused on an MDP framework using policy gradient and DQN methods. This framework was trained on three OCO tasks; online budget allocation, online knapsack, and the secretary problem. For each, the trained model is consistent with the near-optimal \u201chandcrafted\u2019\u2019 algorithms.",
    "This paper focuses on deep reinforcement learning methods and discusses the presence of inductive biases in the existingRL algorithm. Specifically, they discuss biases that take the form of domain knowledge or hyper-parameter tuning. The authors state that such biases rise the tradeoff between generality and performance wherein strong biases can lead to efficient performance but deteriorate generalization across domains. Further, it motivates that most inductive biases has a cost associated to it and hence it is important to study and analyze the effect of such biases. ",
    "This paper contains various numerical experiments to see the effects of some heuristics in reinforcement learning. Those heuristics include reward clipping, discounting for effective learning, repeating actions, and different network structures. However, since the training algorithms also greatly affect the performance of RL agents, it seems hard to draw any quantitive conclusions from this paper.",
    "This submission introduces a new method for vision+language navigation which tracks progress on the instruction using a progress monitor and a visual-textual co-grounding module. The method is shown to perform well on a standard benchmark. Ablation tests indicate the importance of each component of the model. Qualitative examples show that the proposed method attends to different parts of the instruction as the agent moves. ",
    "The paper considers the problem of following natural language route instructions in an unknown environment given only images. Integral to the proposed (\"self-aware\") approach is its ability to reason over which aspects of the instruction have been completed, which are to be followed next, which direction to go in next, as well as the agents current progress. This involves two primary components of the architecture. The first is a visual-textual module that grounds to the completed instruction, the next instruction, and the next direction based upon the visual input. The second is a \"progress monitor\" that takes the grounded instruction as input and captures the agent's progress towards completing the instruction.",
    "This paper proposes guiding program synthesis with information from partial/incomplete program execution. The idea is that by executing partial programs, synthesizers can obtain the information of the state the (partial) program ended in and can, therefore, condition the next step on that (intermediate) state. The paper also mentions ensembling synthesizers to achieve a higher score, and by doing that it outperforms the current state-of-the-art on the Karel dataset program synthesis task.",
    "This paper presents two new ideas on leveraging program semantics to improve the current neural program synthesis approaches. The first idea uses execution based semantic information of a partial program to guide the future decoding of the remaining program. The second idea proposes using an ensembling approach to train multiple synthesizers and then select a program based on a majority vote or shortest length criterion. The ideas are evaluated in the context of the Karel synthesis domain, and the evaluation shows a significant improvement of over 13% (from 77% to 90%).",
    "The author analyze the convergence properties of batch normalization for the ordinary least square (OLS) objective. They also provide experimental results on the OLS objective as well as small scale neural networks. First of all, understanding the properties of batch normalization is an important topic in the machine learning community so in that sense, contributions that tackle this problem are of interest for the community. However, this paper has a significant number of problems that need to be addressed before publication, perhaps the most important one being the overlap with prior work. Please address this point clearly in your rebuttal.",
    "This paper provides a theoretical analysis for batch normalization with gradient descent (GDBN) under a simplified scenario, i.e., solving an ordinary least squares problem. The analysis shows that GDBN converges to a stationary point when the learning rate is less than or equal to 1, regardless of the condition number of the problem. Some practical experiments are carried out to justify their theoretical insights. The paper is in general easy to follow. ",
    "This submission closely builds upon an earlier work (Xie et al., 2017, Gal and Ghahramani, 2016) and proposes a new data noising technique motivated by Bayesian RNNs. Specifically, the key contribution is to extend Gal and Ghahramani (2016) to word embedding noising, while drawing inspiration from trational data smoothing techniques. Some variants are discussed, including those motivated by linear interpolation and Kneser-Ney smoothing, just as in Xie et al., 2017. Empirical evaluation is performed with language modeling experiments, and the proposed methods outperforms comparable baselines. One can imagine such a technique could be useful in many other sequence tasks. ",
    "In this submission, the authors present a variational smoothing interpretation of the data noising approach presented in (Xie et al., 2017). Although the theoretical coverage of the problem gives interesting insights. However, a comparison to related work w.r.t. alternative regularization approaches is missing. Similarly, the perplexity values reported in the experimental results on Penn Treebank are far away from state-of-the-art results published by many competitors on this task, e.g. see the current state-of-the-art results on Penn Treebank by (Yang et al., 2017, https://arxiv.org/pdf/1703.02573.pdf and references therein). It is bad practice to ignore existing work completely like this. The interesting question here would be, inhowfar the presented smoothing/regularization methods are complementary to existing approaches, and if the presented methods do provide improvements on top of these.",
    "This paper proposes a classifier-agnostic method for saliency map extraction. In order to address the dependence of saliency map extraction on the classifier, the authors propose to learn a saliency mapping by considering all possible classifiers (i.e., a certain classifier structure w.r.t. the space of all its parameters). The goal is to find the relevant features in the data that work with all possible classifiers. The proposed framework is formulated as a min-max game between two players: a mask m corresponding to the saliency mapping, and a function f sampled from a set of classifiers with the same structure but different parameters. The mapping m is optimized to maximize the masked-out classification error (such that m captures all relevant features whose removal can maximally confuse the classifier), while f is optimized to minimize the mask-out classification error.",
    "This paper focuses on the extraction of high-quality model-agnostic saliency maps. The authors argue that when an extracted saliency map is directly dependent on a model, then it might not be useful for a different classifier and thus not general enough. To overcome this problem, they consider all the possible classifiers weighted by their posterior probabilities. This problem cannot be solved explicitly, and the authors suggest a scheme to approximate the solution using two networks. That is, pretrain an initial classifier and then, following an adversarial training procedure, one network is trying to confuse the classifier and the other one to maximize its accuracy. Using this formulation, the authors report state-of-the-art results for salience map extraction.",
    "This paper proposes a new set of heuristics for learning a NN for generalising a set of NNs trained for more specific tasks. This particular recipe might be reasonable, but the semi-formal flavour is distracting. The issue of model selection (clearly the main issue here) is not addressed. A quite severe issue with this report is that the authors don't report relevant learning results from before (+-) 2009, and empirical comparisons are only given w.r.t. other recent heuristics. This makes it for me not possible to advice publication as is.",
    "This paper presents a method for distilling multiple teacher networks into a student, by linearly combining feature representations from all networks at multiple intermediate layers, and gradually forcing the student to \"take over\" the learned combination.  Networks to be used as teachers are first pretrained on various initial tasks.  A student network is then trained on a target task (possibly different from any teacher task), by combining corresponding hidden layers from each teacher using learned linear remappings and weighted combinations.  Learning this combination allows the system to find appropriate teachers for the target task; eventually, a penalty on the combination weights forces all weight onto the student network, resulting in the distillation.",
    "This paper studies the problem of compactly represent the model of a complex dynamic system while preserving information. The method is based on the information bottleneck method. Basically, for a dynamic system whose states changing from X_{k-1}, X_k to X_{k+1}, the \"information bottleneck hierarchy\" method learns a variable B_k and B_{k+1} such that B_k predicts B_{k+1} well, B_k predicts X_k well, and B_{k+1} predicts X_{k+1} well, while minimizing the information of X_{k-1} contained in B_k. ",
    "This paper studied an extension of the Information Bottleneck Principle called Information Bottleneck Hierarchy (IBH).  The goal of IBH is to extract meaningful information from a Markov Chain. Then the authors studied case of the Gaussian linear dynamic and proposed an algorithm for computing the IBH. Then an experiment was conducted to show the usage of IBH to practical problems.",
    "The goal of this paper is to use deep generative models for missing data imputation. This paper proposes learning a latent variable deep generative model over every randomly sampled subset of observed features. First, a masking variable is sampled from a chosen prior distribution. The mask determines which features are observed. Then, the likelihood of the observed features is maximized via a lower bound. Inference in this latent variable model is achieved through the use of an inference network which conditions on the set of \"missing\" (to the generative model) features.",
    "The paper presents a model for learning conditional distribution when arbitrary partitioning the input to observed and masked parts. The idea is to extend the conditional VAE framework such that the posterior is a function of an arbitrary subset of observed variables. Accordingly, reconstruction loss only penalizes the error in the reconstruction of masked (unobserved) variables. The method is compared against 1) classical approaches in missing data imputation on UCI benchmarks; 2) image inpainting against recently proposed GANS for the similar task, as well as; 3) against universal marginalizer, which learns conditional densities using a feedforward / autoregressive architecture.",
    "This paper proposes to use 8/4-bit approximation of activations to save the memory cost during gradient computation.  The proposed technique is simple and straightforward. On the other hand, the proposed method only saves up to a constant cost of the storage. With the constant factor (4x, 8x) depending on whether fp16 or fp32 is used during computation. Notably, there is a small but noticeable accuracy drop in the final trained model using this mechanism.",
    "The authors detail a procedure to reduce the memory footprint of deep networks by quantization of the activations only on back propagation. While this scheme does not benefit from computational speedups of activation quantization on both passes (and indeed has a slight computational overhead), the authors demonstrate that for common convolutional architectures it nicely preserves the accuracy of computation by computing the forward pass at full accuracy and limiting propagation of errors in the backward pass. This is possible because the majority of errors are introduced in gradient calculation of the weights and not the inputs each layer. The authors also wisely perform quantization after batch normalization and use the known mean and variance of the activations to scale the quantization and reduce errors. They demonstrate very slight drops in performance accuracy for ResNets on Cifar10, Cifar100, and ImageNet with memory compression factors up to 8. They also point to natural future directions such as using vector quantization to better leverage the activation statistics. The paper is also very clearly written with appropriate references to the relevant literature. ",
    "This work uses GANs to recover clean faces from occluded counterparts. The effectiveness of the proposed method is verified qualitatively and quantitatively on CelebA-HQ. The proposed framework can be generalized to several face-related tasks, such as unconstrained face recognition. Although the novelty of the method is not really impressive, the proposed method seems to be useful for face-related applications and the experimental results are convincing to me.",
    "The paper proposes a complex generative framework for image completion (particularly human face completion). It aims at solving the following challenges: 1) complete the human face at both low and high resolution; 2) control the attribute of the synthetic content; 3) without the need of complex post-processing. To achieve so, this paper proposes a progressively attentive GAN to complete face image at high resolution with multiple controllable attributes in a single forward pass without post-processing. Particularly it introduces a frequency-oriented attentive module (FAM) to attend on finer details.  ",
    "There has been a lot of work on limited precision training and inference for deep learning hardware, but in most of this work, the accumulators for the multiply-and-add (FMA) operations that occur for inner products are chosen conservatively or treated as having unlimited precision. The authors address this with  an analytical method to predict the number of mantissa bits needed for partial summations during the forward, delta and gradient computation ops for convolutional and fully connected layers. They propose an information theoretic approach to argue that by using fewer bits of mantissa in the accumulator than necessary, the variance of the resulting sum is less than what it would have been if sufficient bits of mantissa were used. This is surprising to me, as quantization is usually modeled as _adding_ noise, leading to an _increase_ in variance (Mc Kinstry et al. 2018), so this is a nice counterexample to that intuition. Unfortunately the result is presented in a way that implies the variance reduction is what causes the degradation in performance, while obviously (?) it's just a symptom of a deeper problem. E.g., adding noise or multiplying by a constant to get the variance to where it should be, will not help the network converge. The variance is just a proxy for lost information. The authors should make this more clear.",
    "The authors conduct a thorough analysis of the numeric precision required for the accumulation operations in neural network training. The analysis is based on Variance Retention Ratio (VRR), and authors show the theoretical impact of reducing the number of bits in the floating point accumulator. And through extensive benchmarks with popular vision models, the authors demonstrate the practical performance of their theoretical analysis.",
    "In this work the authors prove several claims regarding the inductive bias of gradient descent and gradient flow trained on deep linear networks with linearly separable data. They show that asymptotically gradient descent minimizes the risk, each weight matrix converges to its rank one approximation and the top singular vectors of two adjacent weight matrices align. Furthermore, for the logistic and exponential loss the induced linear predictor converges to the max margin solution. ",
    "This paper studies the properties of applying gradient flow and gradient descent to deep linear networks on linearly separable data. For strictly decreasing loss like the logistic loss, this paper shows 1) the loss goes to 0, 2) for every layer the normalized weight matrix converges to a rank-1 matrix 3) these rank-1 matrices are aligned. For the logistic loss, this paper further shows the linear function is the maximum margin solution.",
    "This paper proposes an extension to hredGAN, which is an adversarial framework for multi-turn dialogue model, to simultaneously learns a set of attribute embeddings that represents the persona of each speaker and generate persona-based responses. The generator of the proposed system phredGAN is conditioned on both the history utterances and the speakers\u2019 persona by concatenating the utterance encoding with attribute embeddings. For discriminator, the authors explore two versions: 1) phredGAN_a takes attributes as inputs; 2) phredGAN_d adds a dual discriminator that predicts the attribute(s) for each utterance. ",
    "This paper uses the idea from 'A Persona-Based Neural Conversation Model' by Li et al and incrementally applies it to the 'Multi-turn Dialogue Response Generation in an Adversarial Learning Framework' work-in-progress by Olabiyi et al. The paper by Olabiyi uses the idea of adversarial training to the HRED work by Xing et al (Hierarchical Recurrent Attention Network for Response Generation). The paper shows very promising results for controlling the response generation based on input attributes with adversarial training. Compared to the persona based model, this work seems to outperform that model significantly as reported in Table 1 (in terms of Perplexity/Bleu). It would have been great to see the quantitative comparison in terms of other metrics (if the authors could try to reproduce their results). There are other interesting ways to incorporate attribute information into the dialogue model such as reported in the work of Lee et al (SCALABLE SENTIMENT FOR SEQUENCE-TO-SEQUENCE CHATBOT RESPONSE WITH PERFORMANCE ANALYSIS) - since this paper is primarily about personalization of responses - a comparison to some of the methods used in Lee's work would have been very relevant and made the paper much more convincing in terms of core contributions. The model and architecture is pretty convincing but the paper lacks more in-depth analysis, comparison and evaluation of the model.",
    "In this paper a new task namely CoDraw is introduced. In CoDraw, there is a teller who describes a scene and a drawer who tries to select clip art component and place them on a canvas to draw the description. The drawing environment contains simple objects and a fixed background scene all in cartoon style. The describing language thus does not have sophisticated components and phrases. A metric based on the presence of the components in the original image and the generated image is coined to compute similarity which is used in learning and evaluation.  Authors mention that in order to gain better performance they needed to train the teller and drawer separately on disjoint subsets of the training data which they call it a cross talk.",
    "This paper presents CoDraw, a grounded and goal-driven dialogue environment for collaborative drawing. The authors argue convincingly that an interactive and grounded evaluation environment helps us better measure how well NLG/NLU agents actually understand and use their language \u2014 rather than evaluating against arbitrary ground-truth examples of what humans say, we can evaluate the objective end-to-end performance of a system in a well-specified nonlinguistic task. They collect a novel dataset in this grounded and goal-driven communication paradigm, define a success metric for the collaborative drawing task, and present models for maximizing that metric.",
    "The paper proposes the inclusive neural random field model. Compared the existing work, the model is different because of the use of the inclusive-divergence minimization for the generative model and the use of stochastic gradient Langevin dynamics (SGLD) and stochastic gradient Hamiltonian Monte Carlo  (SGHMC) for sampling. Experimental results are reported for unsupervised, semi-supervised, and supervised learning problems on both synthetic and real-world datasets. Specific comments follow:",
    "This paper addresses an important problem of learning the random field using neural networks by using a inclusive auxiliary generator. Comparing to existing state-of-the-art methods for learning neural random fields, this paper used a the inclusive-divergence (KL divergence of the density approximate and the auxiliary generator) which avoids the intractable entropy term. SGLD/SGHMC are used to revise samples drawn from the auxiliary generator and these two sampling methods are examined theoretically.  ",
    "This paper studies the problem of learning a better poisoned graph parameters that can maximize the loss of a graph neural network. The proposed using meta-learning to compute the second-order derivatives to get the meta-gradients seems reasonable. The authors also proposed approximate methods to compute the graph as learning parameters, which could be more efficient since the second-order derivatives are no longer computed. The experimental results on three graph datasets show that the proposed model could improve the misclassification rate of the unlabeled nodes.",
    "This paper studied data poisoning attacking for graph neural networks. The authors proposed treating graph structures as hyperparameters and leveraged recent progress on meta-learning for optimizing the adversarial attacks. Different from some recent work on adversarial attacks for graph neural networks (Zuigner et al. 2018; Dai et al. 2018), which focus on attacking specific nodes, this paper focuses on attacking the  overall performance of graph neural networks. Experiments on a few data sets prove the effectiveness of the proposed approach. ",
    "The paper introduces a novel regularized auto-encoder architecture called the Cramer-Wold AutoEncoders (CWAE). It's objective (Eq. 7) consists of two terms: (i) a standard reconstruction term making sure the the encoder-decoder pair aligns nicely to accurately reconstruct all the training images and (ii) the regularizer, which roughly speaking requires the encoded training distribution to look similar to the standard normal (which is a prior used in the generative model being trained). The main novelty of the paper is in the form of this regularizer. The authors introduce what they call \"the Cramer-Wold distance\" (for definitions see Theorems 3.1 and 3.2) which is defined between two finite sets of D-dimensional points. The authors provide empirical studies showing that the proposed CWAE method achieves the same quality of samples (measured with FID scores) as the WAE-MMD model [1] previously reported in the literature, while running faster (by up to factor of 2 reduction in the training time, as the authors report). ",
    "This paper proposes the Cramer-Wold autoencoder. The first contribution of the paper is to propose the Cramer-Wold distance between two distributions based on the Cramer-Wold Theorem. More specifically, in order to compute the Cramer-Wold distance, we first find the one dimensional projections of the distributions over random slices, and then compute the average L2 distances of the kernel density estimates of these projections over random slices. The second contribution of the paper is to develop a generative autoencoder which uses the Cramer-Wold distance to match the latent distribution of the data to the prior distribution.",
    "This paper presents methods for (1) adding inductive bias to a classifier through coarse-to-fine prediction along a class hierarchy and (2) learning a memory-based KNN classifier through an intuitive procedure that keeps track of mislabeled instances during learning. Further, the paper motivates focused work on the many class / few shot classification scenario and creates new benchmark datasets from subsets of imagenet and omniglot that match this scenario. Experimental results show gains over popular competing methods on these benchmarks.",
    "This study explores the class hierarchy to solve many-class few-short learning problem in both traditional supervised learning and meta-learning. The model integrates both the coarse-class and fine-class label as the supervision information to train the DNN, which aims to leverage coarse-class label to assist fine-class prediction. The core part in the DNN is memory-augmented attention model that includes at KNN classifier and Memory Update mechanism. The re-writable memory slots in KNN classifier aim to maintain multiple prototypes used to describe the data sub-distribution within a class, which is insured by designing the memory utility rate, cache and clustering component in Memory Update mechanism. This study presents a relatively complex system that combines the idea of matching networks and prototypical networks.",
    "The paper proposes a Structural-Jump-LSTM model to speed up machine reading, which is an extension of the previous speed reading models, such as LSTM-Jump, Skim-LSTM and LSTM-Shuffle. The major difference, as claimed by the authors, is that the proposed model has two agents instead of one. One agent decides whether the next input should be fed into the LSTM (skip) and the other determines whether the model should jump to the next punctuation (jump). The sentence-wise jumping makes the jumping more structural than models like LSTM-Jump, while the word-wise skipping operation has a finer skimming decision. The reinforcement learning algorithm in this paper is also different from LSTM-Jump, where LSTM-Jump uses REINFORCE, while this paper applies actor-critic approach. ",
    "The paper presents a novel model for neural speed reading. In this new model, the authors combined several existing ideas in a nice way, namely, the new reader has the ability to skip a word or to jump a sequence of words at once. The reward of the reader is mixed of the final prediction correctness and the amount of text been skipped. The problem is formulated as a reinforcement learning problem. The results compared with the existing techniques on several benchmark datasets show consistently good improvements.",
    "The authors propose a new defense against adversarial examples based on radial basis features. Prior work has suggested that the linearity of standard convolutional networks may be a factor contributing to their vulnerability against adversarial examples, and that radial basis functions may help alleviate this weakness. The current paper builds on this idea and proposes a concrete way to add radial basis features to existing convnet architectures.",
    "The proposed method is too simplistic, the model being succinctly described in less than one page with many errors in the given math expressions. Only the model is given. The optimization problem, as given in (1) is not explained. the authors need to stud the optimization problem, to derive its resolution, and to describe the obtained algorithm.",
    "The authors introduce a  novel  on-policy  temporally  consistent  exploration  strategy, named Neural  AdaptiveDropout Policy Exploration (NADPEx), for deep reinforcement learning agents. The main idea is to sample from a distribution of plausible subnetworks modeling the temporally consistent exploration. For this, the authors use the ideas of the standard dropout for deep networks. Using the proposed  dropout transformation that is differentiable, the authors show that the KL regularizers on policy-space play an important role in stabilizing its learning. The experimental validation is performed on continuous control learning tasks, showing the benefits of the proposed. ",
    "This paper proposed to use dropout to randomly choose only a subset of neural network as a potential way to perform exploration. The dropout happens at the beginning of each episode, and thus leads to a temporally consistent exploration. The paper shows that with small amount of Gaussian multiplicative dropout, the algorithm can achieve the state-of-the-art results on benchmark environments. And it can significantly outperform vanilla PPO for environments with sparse rewards.",
    "I do not understand the denomination of nonlinearity coefficient provided in definition 1: although the quantity indeed does equal to 1 under whitened data distribution or orthogonal matrix, the conjecture that it should be close to 1 does not seem to be close at all just under any data distribution. Using a similar construction that section 6, we can rescale a whitened input data with a diagonal matrix D with components all equal to one except for a very large one \\lambda and also multiply the input weights by D^{-1} to compensate (and have a similar function). If you look at such construction for the linear case with identity initialization of A, the NLC is sqrt((\\lambda^2 + n - 1) (\\lambda^{-2} + n - 1)) / n which can grow arbitrarily large with \\lambda *for a linear model*. However, because of its low capacity, we would expect a linear model to have reasonable generalization. This seems to compromise the initial NLC being low as a necessary condition for reasonable generalization. ",
    "In this paper the authors introduce a new quantity, the nonlinearity coefficient, and argue that its value at initialization is a useful predictor of test time performance for neural networks. The authors conduct a wide range of experiments over many different network architectures and activation functions to corroborate these results. The authors then extend their method to compute the local nonlinearity of activation functions instead.",
    "In this paper, the authors studied bias amplification. They showed in some situations bias is unavoidable; however, there exist some situations in which bias is a consequence of weak features (features with low influence to the classifier and high variance). Therefore, they used some feature selection methods to remove weak features; by removing weak features, they reduced the bias substantially while maintaining accuracy (In many cases they even improved accuracy).  Showing that weak features cause bias is very interesting, especially in their real-world dataset in which they improved bias and accuracy simultaneously.  ",
    "In this paper the authors identify a specific source of marginal class probability bias that occurs when using logistic regression models. Using synthetic and real datasets they demonstrate this bias and explore characteristics of the data that exacerbate the issue. Finally, they propose two methods for correcting this bias in logistic regression models and neural network models with logistic output layers and evaluate these methods on several benchmark datasets.",
    "This paper studies the implicit bias of minimizers of a regularized cross entropy loss of a two-layer network with ReLU activations. By combining several results, the authors obtain a generalization upper bound which does not increase with the network size. Furthermore, they show that the maximum normalized margin is, up to a scaling factor, the l1 svm margin over the lifted feature space of an infinite-size network. Finally, in a setting of infinite-sized networks, it is proved that perturbed Wasserstein gradient flow finds a global minimum in polynomial time.",
    "The authors claim to prove three things: (1) Under logistic loss (with a vanishing regularization), the normalized margin (of the solution) converges to the max normalized margin, for positive homogenous functions. This is an asymptotic result: the amount of regularization vanishes. (2) For one hidden layer NN, the max margin under l_2 norm constraint on weights in the limit, is equivalent to the l_1 constraint (total variation) on the sign measure (specified by infinite neurons) for the one hidden layer NN. (3) Show some convergence rate for the mean-field view of one hidden layer NN, i.e., the Wasserstein gradient flow on the measure (of the neurons). The author show some positive result for a perturbed version.",
    "The authors are proposing a method for allowing the generation of multiple objects in generated images given simple supervision such as bounding boxes and their associated labels. They control the spatial location of generated objects by the mean of an object pathway added to the architecture of both Generator and Discriminator within a GAN framework. They show generated results on Multi-MNIST, CLEVR with discussions of their model's abilities and properties. they also provide quantitative results on MSCOCO (IS and FID) using StackGAN and AttGAN models with the object pathway modifications and show some improvements compared to the original models. However it must be noted (as commented by the authors) that these models are using image captions only and do not have explicit supervision of bounding box and object labels.",
    "The paper proposes a simple but effective method for controlling the location of objects in image generation using generative adversarial networks. Experiments on MNIST and CLEVR are toy examples but illustrate that the model is indeed performing as expected. The experiments on COCO produce results that while containing obvious artefacts are producing output consistent with the input control signal (i.e., bounding boxes). It would however have been interesting to see more varied bounding box locations for the same caption.",
    "In this work the authors propose an end to end approach for model based reinforcement learning from images, where the main building blocks are locally-linear dynamical systems and variational auto-encoders (VAE). Specifically, it is assumed that the input features (i.e., the images) are generated from a low dimensional latent representation mapped through parametric random functions; the latter are modeled via neural networks. A recognition model based on convolutional neural networks operates on the reverse way and is responsible for projecting the input features to the latent space, in order to proceed with the reinforcement learning task. The variational framework is employed in order to jointly learn the VAE and the linear dynamics on the latent state. As a final step, once the model is fitted a linear quadratic system (LQS) is solved in order to learn the cost function and the optimal policy. ",
    "The paper proposes SOLAR a model based RL algorithm that learns a low dimensional embedding such that the dynamics within the latent space are linear. Within this latent space the linear dynamics  are learned using a Bayesian regression. In addition, a quadratic cost function is approximated. The learned dynamics and the cost function are used to update the policy, while simultaneously bounding the change in policy by a KL-bound.  In contrast to other model-based RL algorithms the learned dynamics are not used for planning or imaginary roll-outs and are only used to improve the policy.",
    "This paper proposes a policy evaluation and search method assisted by a counterfactual model, in contrast previous work using vanilla (non-causal) models. With \u201cno model mismatch\u201d assumption the policy evaluation estimator is unbiased. Empirically, the paper compares Guided Policy Search with counterfactual model (CF-GPS) with vanilla GPS, model based RL algorithm and show benefit in terms of (empirical) sample complexity.",
    "Proposes Counterfactual Guided Policy Search (CF-GPS), which uses counterfactual inference from sampled trajectories to improve an approximate simulator that is used for policy evaluation. Counterfactual inference is formalized with structural causal models of the POMDP. The method is evaluated in partially-observed Sokoban problems. The dynamics model is assumed known, and a learned model maps observation histories to a conditional distribution on the starting state. CF-GPS outperforms model-based policy search and a \"GPS-like\" algorithm in these domains. GPS in MDPs is shown to be a particular case of CF-GPS, and a connection is also suggested between stochastic value gradient and CF-GPS.",
    "This paper argues that analyzing loss surfaces in parameter space for the purposes of evaluating adversarial robustness and generalization is ineffective, while measuring input loss surfaces is more accurate. By converting loss surfaces to decision surfaces (which denote the difference between the max and second highest logit), the authors show that all adversarial attack methods appear similar wrt the decision surface. This result is then related to the statistics of the input Jacobian and Hessian, which are shown to differ across adversarially sensitive and robust models. Finally, a regularization method based on regularizing the input Jacobian is proposed and evaluated. All of these results are shown through experiments on MNIST and CIFAR-10.",
    "The authors demonstrated that the loss surface visualized in parameter space does not reflect its robustness to adversarial examples. By analyzing the geometric properties of the loss surface in both parameter space and input space, they find input space is more appropriate in evaluating the generalization and adversarial robustness of a neural network. Therefore, they extend the loss surface to decision surface. They further visualized the adversarial attack trajectory on decision surfaces in input space, and formalized the adversarial robustness indicator. Finally, a robust training method guided by the indicator is proposed to smooth the decision surface.",
    "The paper proposes a method for neural network training under a hard energy constraint (i.e. the method guarantees the energy consumption to be upper bounded). Based on a systolic array hardware architecture the authors model the energy consumption of transferring the weights and activations into different levels of memory (DRAM, Cache, register file) during inference. The energy consumption is therefore determined by the number of nonzero elements in the weight and activation tensors. To minimize the network loss under an energy constraint, the authors develop a training framework including a novel greedy algorithm to compute the projection of the weight tensors to the energy constraint.",
    "The paper is dedicated to energy-based compression of deep neural networks. While most works on compression are dedicated to decreasing the number of parameters or decreasing the number of operations to speed-up or reducing of memory footprint, these approaches do not provide any guarantees on energy consumption. In this work the authors derived a loss for training NN with energy constraints and provided an optimization algorithm for it. The authors showed that the proposed method achieves higher accuracy with lower energy consumption given the same energy budget. The experimental results are quite interesting and include even highly optimized network MobileNetV2.",
    "In this paper, the authors propose a policy gradient algorithm for solving a Bayes-Adaptive MDP (BAMDP). At each iteration, the algorithm samples several MDPs from the prior distribution and simulates a trajectory for each sampled MDP. During the simulation, the algorithm uses a Bayes filter to update the posterior belief distribution at each time step. Finally, the algorithm uses the sampled trajectories and update the policy using the TRPO algorithm. ",
    "This paper proposes a policy optimization framework for Bayesian RL (BPO). BPO is based on a Bayesian model-based RL formulation. Using a Bayesian approach, it is expected to have better trade-off between exploration and exploitation in RL, and be able to deal with model uncertainty as well. Experiments are done on multiple domains consisting both POMDP planning tasks and RL.",
    "The submission explores a new form of word representation based on a histogram over context word vectors, allowing them to measure distances between words in terms of optimal transport between these histograms. The authors speculate that this may allow better representations of polysemous words. The approach is mathematically elegant, and requires no additional training on top of existing approaches like Glove. To improve efficiency, they use clustering on context vectors. They present results on various semantic textual similarity and hypernym detection tasks, outperforming some baselines.",
    "The paper proposes a method to augment representation of an entity (such as a word) from standard \"point in a vector space\" to a histogram with bins located at some points in that vector space. In this model, the bins correspond the context objects, the location of which are the standard point embedding of those objects, and the histogram weights correspond to the strength of the contextual association. The distance between two representations is then measured with, Context Mover Distance, based on the theory of optimal transport, which is suitable for computing the discrepancy between distributions. ",
    "The paper proposes to use a multi-step prediction model in model-based RL. The proposed model maps from current state and a sequence of actions to the state after taking those actions. The paper demonstrates on 2 tasks that in a model-predictive control loop combined with planning by cross-entropy method, this can yield better asymptotic performance than using single-step models.",
    "The authors learn a model that predicts the state R steps in the future, given the current state and intervening actions, instead of the predicting the next time step state. The model is then used for standard model predictive control. The authors find numerically that their method, termed Plan-Conditional Predictor (PCP), performs better over long horizon times (~100 time steps), than other recent model-based and model-free algorithms. This because for long horizon time scales, the model predicting the state for the next time step accumulates error when used recursively.",
    "This paper investigates the problem of neural network quantization. The main idea is to employ an end-to-end precision highway to reduce the accumulated quantization error and meanwhile enable ultra-low precision in deep neural networks.  The experimental results on the 3- and 2-bit quantizations of ResNet-18/50 and 2-bit quantization of an LSTM model demonstrate the effectiveness of the proposed method. ",
    "This paper studies methods to improve the performance of quantized neural networks.  The paper is largely centered around the idea of \"precision highways\" (full-precision residual connections) that run in parallel to fully-quantized convolutions.  However, the paper also throws in a toolbox of other methods like distillation from a teacher network, a quantization method based on the Laplace distribution, and a fine tuning scheme.",
    "This paper proposed a general method for image restoration based on GAN. In particular, the latent variable z is optimized based on the MAP framework. And the results are obtained by G(z). This method looks reasonable to achieve good results. However, the idea is very related to Yeh et al.\u2019s work which has already published but not mentioned at all. ",
    "The authors propose a method for image restoration, where the restored image is the MAP estimate. A pretrained GAN is utilized to approximate the prior distribution of the noise-free images. Then, the likelihood induces a constraint which is based on the degradation function. In particular, the method tries to find the latent point for which the GAN generates the image, which if gets degraded will match the given degraded image. Also, an optimization algorithm is presented that solves the proposed constrained optimization problem.",
    "This paper proposes a framework for few-sample knowledge distillation of convolution neural networks. The basic idea is to fit the output of the student network and that of the teacher network layer-wisely. Such a regression problem is parameterized by a 1x1 point-wise convolution per layer (i.e. minimizing the fitting objective over the parameters of 1x1 convolutions). The author claims such an approach, called FSKD, is much more sample-efficient than previous works on knowledge distillation. Besides, it is also fast to finish the alignment procedure as the number of parameters is smaller than that in previous works. The sample efficiency is confirmed in the experiments on CIFAR-10, CIFAR-100 and ImageNet with various pruning techniques. In particular, FSKD outperforms the FitNet and fine-tuning by non-trivial margins if only small amount of samples are provided (e.g. 100).",
    "In this paper, an efficient re-training algorithm for neural networks is proposed. The essence is like Hinton's distillation, but in addition to use the output of the last layer, the outputs of intermediate layers are also used. The core idea is to add 1x1 convolutions to the end of each layer and train them by fixing other parameters. Since the number of parameters to train is small, it performs well with the small number of samples such as 500 samples. ",
    "The paper proposes the H score H(f), a quantity that measure the goodness of feature f(x) for predicting some target y. This heavily builds on Makur et al. (2015) who introduce information vectors, the error exponent, and the DTM matrix. The paper connects H(f) with these quantities to justify the proposal (e.g., H(f) is proportional to the error exponent (Theorem 1)). The actual transferability is measured by the ratio between H(f) and H(f_opt) where the latter can be computed using the approach of Makur et al. ",
    "In this paper, the authors considered a source domain selection problem in transfer learning. Given a feature representation function f, the H-score is defined as the normalized correlation between the output f(X) and the label Y. The transferability is then measured by the ratio of H-score on the target domain and the optimal one. The authors introduced the information-theoretic and statistical meaning of the H-score. Validation of H-score was confirmed by numerical experimenters with image data. ",
    "The authors consider the problem of generating diverse translations from a neural machine translation model. This is a very interesting problem and indeed, even the best models lack meaningful diversity when generating with beam-search. The method proposed by the authors relies on prefixing the generation with discrete latent codes. While a good general approach, it is not new (exactly the same general approach that was used in the \"Discrete Autoencoders for Sequence Models\" [1] paper, https://arxiv.org/abs/1801.09797, for generating diverse translations, which is not cited directly but a follow-up work is cited, though without mentioning that a previous work has tackled the same problem). Also, the authors rely on additional supervised data (namely POS tags) which has no clear motivation and seems to cause a number of problems -- why not use a purely unsupervised approach when it has already been demonstrated on the same problem? Additionally, the authors compare to a weak translation baseline on small data-sets, making it impossible to judge whether the results would hold on a larger data-set. So the following ablations and comparison to baselines are missing:",
    "The authors propose modeling structural diversity of translations by conditioning the generation on both the source sentence and a latent encoding of the overall structure (captured by simplified part-of-speech tags). Specifically, they first train a conditional autoencoder to learn a latent code optimized towards reconstructing the tag sequence. They then prefix the inferred latent code to the target sentence before generation. A diversity metric which measures pairwise BLEU scores between beam items is also proposed. Experiments show that the latent codes lead to greater structural diversity as well as marginally improved translation results when combined with beam search.",
    "The paper describes an interesting tweak of the standard GAN model (inspired by IPM based GANs) where both the generator and the discriminator optimize relative realness (and fakeness) of the (real, fake) image pairs. The authors give some intuition for this tweak and ran experiments with CIFAR10 and CAT datasets. Different variants of the standard GAN and the new tweak were compared under the FID metric. The experimental setup and details are provided; and the code is made publicly available. ",
    "In this work, the authors considers a variation of GAN by consider simultaneously decrease the probability that real data is real for the generator. To include such a property, the authors propose a relativistic discriminator which estimate the probability that the given real data is more realistic than the fake data. Numerical results are performed to show that the proposed methods are effective, and the resulting GANs are relatively more stable and generate higher quality data samples than their non-relativistic counterparts.",
    "This paper proposes a method for continual learning. The model has three components: a) a data generator to be used at training time to replay past examples, b) a parameter generator that takes the input observation to produce parameters for c) the actual classifier. The authors demonstrate the method on simple datasets with a stream of 2 or 3 tasks.",
    "This paper proposes a Dynamic Parameter Generator (DPG) that given a test input modifies the parameters of a classification model. They also propose to regularize the training using a Data Generator (DG) to slow down catastrophic forgetting. DG is used to constrain the training that the internal representations of data generated by DG does not rapidly change. DG removes the need for storage of data or labels.",
    "This paper used graph neural networks to do relational reasoning of multi-agent systems to predict the actions and returns of MARL agents that they call Relational Forward Modeling. They used RFM to analyze and assess the coordination between agents in three different multi-agent environments. They then constructed an RFM-aumented RL agent and showed improved training speeds over non relational reasoning baseline methods. ",
    "This paper studies predicting multi-agent behavior using a proposed neural network architecture. The architecture, called a relational forward model (RFM) is the same graph network proposed by Battaglia et al., 2018, but adds a recurrent component. Two tasks are define: predict the next action of each agent, and predict the sum of future rewards. The paper demonstrates that RFMs outperform two baselines and two ablations. The authors also show that edge activation magnitudes are correlated with certain phenomenons (e.g. an agent walking towards an entity, or an entity being \u201con\u201d or \u201coff\u201d). The authors also show that appending the output of a pre-trained RFM to the state of a policy can help it learn faster.",
    "This paper aims to address the problem of lacking sufficient demonstrations in inverse reinforcement learning (IRL) problems. They propose to take a meta learning approach, in which a set of i.i.d. IRL tasks are provided to the learner and the learner aims to learn a strategy to quickly recover a good reward function for a new task that is assumed to be sampled from the same task distribution. Particularly, they adopt the gradient-based meta learning algorithm, MAML, and the maximal entropy (MaxEnt) IRL framework, and derive the required meta gradient expression for parameter update. The proposed algorithm is evaluated on a synthetic grid-world problem, SpriteWorld. The experimental results suggest the proposed algorithm can learn to mimic the optimal policy under the true reward function that is unknown to the learner. ",
    "This paper attempts to the solve  data-set coverage issue common with Inverse reinforcement learning based approaches - by introducing a meta-learning framework trained on a smaller number of basic tasks. The primary insight here is that there exists a smaller set of unique tasks, the knowledge from which is transferable to new tasks and using these to learn an initial parametrized reward function improves the coverage for IRL. With experiments on the SpriteWorld synthetic data-set, the authors confirm this hypothesis and demonstrate performance benefits - showcasing better correlation with far fewer  number of demonstrations.",
    "This paper proposes both a general meta-learning framework with approximate probabilistic inference, and implements an instance of it for few-shot learning. First, they propose Meta-Learning Probabilistic inference for Prediction (ML-PIP) which trains the meta-learner to minimize the KL-divergence between the approximate predictive distribution generated from it and predictive distribution for each class. Then, they use this framework to implement Versatile Amortized Inference, which they call VERSA. VERSA replaces the optimization for test time with efficient posterior inference, by generating distribution over task-specific parameters in a single forward pass. The authors validate VERSA against amortized and non-amortized variational inference which it outperforms. VERSA is also highly versatile as it can be trained with varying number of classes and shots.",
    "This work tackles few-shot (or meta) learning from a probabilistic inference viewpoint. Compared to previous work, it uses a simpler setup, performing task-specific inference only for single-layer head models, and employs an objective based on predictive distributions on train/test splits for each task (rather than an approximation to log marginal likelihood). Inference is done amortized by a network, whose input is the task training split. The same network is used for parameters of each class (only feeding training points of that class), which allows an arbitrary number of classes per task. At test time, inference just requires forward passes through this network, attractive compared to non-amortized approaches which need optimization or gradients here.",
    "This paper introduces a new dataset consisting of images of various objects placed on store shelves that are labeled with object boundaries and what are described as \u201cultrafine-grained\u201d class labels. The accompanying task is to predict the labels of each object given the individual images as well as their spatial layout relative to each other. To solve this task, a deep structured model is used consisting of CNN features for each image which are fed into a linear-chain CRF. To better deal with the large number of classes, pairwise potentials are represented as the multiplication of two lower-rank matrices which represent a sort of \u201cclass embedding\u201d for each potential label. Training efficiency is improved by considering an objective based on a form of piecewise pseudolikelihood, which allows for training-time inference to be conducted with linear complexity relative to the number of labels. This objective also allows for easy use of batch normalization for the input features to the CRF model. This model/training procedure are compared against a number of models/training procedures to demonstrate its utility.",
    "This paper proposed to tackle a large-scale fine-grained object classification problem by approximated CRF. The main motivation is to exploit the spatial conference of object labels to reduce noises in the instance-wise prediction. To this end, the task is formulated by sequential inference problem using CRF. To speed up training, several techniques are applied such as factorized pairwise-potential and approximation of CRF objective.  ",
    "This paper proposes an approach that uses GAN framework to generate audio through modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain. Experiments on NSynth dataset show that it gives better results then WaveNet. The most successful deep generative models are WaveNET,  Parallel WaveNet and Tacotran that are applied to speech synthesis, the method should be tested for speech synthesis and compared with WaveNet, Parallel WaveNet as well as Tacotran.",
    "This paper proposes a strategy to generate audio samples from noise with GANs. The treatment is analogous to image generation with GANs, with the emphasis being the changes to the architecture and representation necessary to make it possible to generate convincing audio that contains an interpretable latent code and is much faster than an autoregressive Wavenet based model (\"Neural Audio Synthesis of Musical Notes with WaveNet AutoEncoders\" - Engel et al (2017)). Like the other two related works (WaveGAN - \"Adversarial Audio Synthesis\" - Donahue et al 2018) and the Wavenet model above, it uses the NSynth dataset for its experiments. ",
    "The authors perform a careful study of mixed integer linear programming approaches for verifying robustness of neural networks to adversarial perturbations. They propose three enhancements to MILP formulations of neural network verification: Asymmetric bounds, restricted domain and progressive bound tightening, which lead to significantly more scalable verification algorithms vis-a-vis prior work. They study the effectiveness of MILP solvers both in terms of verifying robustness (compared to other complete/incomplete verifiers) and generating adversarial attacks (compared to PGD attacks) and show that their approach compares favorable across a number of architectures on MNIST and CIFAR-10. They perform careful ablation studies to validate the importance of the ",
    "This paper studies a Mixed Integer Linear Programming (MILP) approach to verifying the robustness of neural networks with ReLU activations. The main contribution of the paper is a progressive bound tightening approach that results in significantly faster MILP solving. This in turn allows for verifying the robustness of larger networks than previously studied, and even larger datasets such as CIFAR-10.",
    "This is a very interesting piece of work. We know from cognitive science literature, that there are 2 distinct modes of decision making - habit based and top-down control (goal directed) decision making. The paper proposes to use this intuition by using information theoretic objective such that the agent follows \"default\" policy on average and agent gets penalized for changing its \"default\" behaviour, and the idea is to minimize this cost on average across states.",
    "This paper studies how to use KL-regularization with information asymmetry to speed up and improve reinforcement learning (RL). Compared with existing work, the major novelty in the proposed algorithm is that it uses a default policy learned from data, rather than a fixed default policy. Moreover, the proposed algorithm also limits the amount of information the default policy receives, i.e., there is an \"information asymmetry\" between the agent policy and the default policy. In many applications, the default policy is purposely chosen to be \"goal agnostic\" and hence conducts the \"transfer learning\". To the best of my knowledge, this \"informationally asymmetric\" KL-regularization approach is novel.",
    "The paper presents a new model FlowQA for conversation reading comprehension. Compared with the previous work on single-turn reading comprehension, the idea in this paper differs primarily in that it alternates between the context integration and the question flow in parallel. The parallelism enables the model to be trained 5 to 10 times faster. Then this process is formulated as layers of a neural network that are further stacked multiple times. Besides, the unanswerable question is predicted with additional trainable parameters. Empirical studies confirm FlowQA works well on a bunch of datasets. For example, it achieves new state-of-the-art results on two QA datasets, i.e., CoQA and QuAC, and outperforms the best models on all domains in SCONE. Ablation studies also indicates the importance of the concept Flow.",
    "In this paper, authors proposed a so-called FLOWQA for conversational question answering (CoQA). Comparing with machine reading comprehension (MRC),  CoQA includes a conversation history. Thus, FLOWQA makes use of this property of CoQA and adds an additional encoder to handle this. It also includes one classifier to handle with no-answerable questions.",
    "The paper provides good baselines for predicting edits in a text (evaluated on source code) learned from a history of changes. This is an interesting problem that has not beed systematically studied in literature, with the exception of several sporadic works from the software engineering community. Fully predicting the code text writing process as opposed to the code itself is an interesting task with possible big impact, IF the accuracy of this edit model manages to significantly outperform simple left-to-right code text prediction techniques.",
    "The authors study building models for edits in source code. The application is obvious: a system to accurately predict what the next edit should be would be very valuable for developers. Here, edits are modeled by two types of sequences: one that tracks the state of all edits at each time step (and is thus very long), and one that contains the initial step and a changelist that contains the minimal information required to derive the state at any time. The authors train models on top of both of these representations, with the idea being to match the performance of the explicit (heavy) model with the implicit model. This is shown to be challenging, but a clever model is introduced that achieves this, and is thus the best of both worlds. There are synthetic and real-world code (text) edit experiments.",
    "This paper proposed how to learn multi-class classifiers without multi-class labels. The main idea is shown in Figure 2, to regard the multi-class labels as hidden variables and optimize the likelihood of the input variables and the binary similarity labels. The difference from existing approaches is also illustrated in Figure 1, namely existing methods have binary classifiers inside multi-class classifiers while the proposed method has multi-class classifiers inside binary classifiers. The application of this technique to three general problem settings is discussed, see Figure 3.",
    "The work is a special case of density estimation problems in Statistics, with a use of conditional independence assumptions to learn the joint distribution of nodes. While the work appears to be impressive, such ideas have typically been used in Statistics and machine learning very widely over the years(Belief Propagation,  Topic modeling with anchor words assumptions etc...). This work could be easily extended to multi-class classifications where each node belongs to multiple classes. It would be interesting to know the authors' thoughts on that. The hard classification rule in the paper seems to be too restrictive to be of use in practical scenarios, and soft classification would be a useful pragmatic alternative. ",
    "This paper studies how the FiLM visual question answering (VQA) model answer questions involving the quantifier \u2018most\u2019. This quantifier is chosen for study because it cannot be expressed in first order logic (i.e., high-order logic is required), and secondly because there are two different algorithmic approaches to answering questions involving \u2018most\u2019 (cardinality-based strategy and pairing-based strategy). Experiments are performed by designing abstract visual scenes with controlled numerosity and spatial layouts, and applying methodologies from pyscholinguistics. The paper concludes that the model learns an approximate number system (ANS), consistent with the cardinality-based strategy, with implications for understanding the conditions under which existing VQA models should perform well or badly (and possibly for improving VQA models). ",
    "The paper analyzes the strategy that a visual question answering model (FiLM) uses to verify statements containing the quantifier \"most\" (\"most of the dots are red\"). It finds that the model is sensitive to the ratio of objects that satisfy the predicate (that are red) to objects that do not; as the ratio decreases (e.g. 10 red dots compared to 9 blue dots), the model's performance decreases too. This is consistent with human behavior.",
    "The paper presents a probabilistic treatment of knowledge graph embeddings, motivating it in parameter uncertainty estimation and easier hyperparameter optimisation. The authors present density-based DistMult and ComplEx variants, where the posterior parameter distributions for entity and relation embeddings are approximated by diagonal Gaussians q_\\gamma. Variational EM is used to infer the variational parameters \\gamma as well as the per-entity/per-relation precision (\\lambda) hyperparameters. The training process proposed by the authors consists of three phases: (1) pretraining a MAP estimate that\u2019s used as initial means of the posterior approximating Gaussians, (2) variational EM (see above) to find better hyperparameters and (3) another MAP training phase that uses the updated per-entity/per-relation hyperparameters. Finally, experimental results indicate a slight improvement in MRR and HITS@10 across FB and WN datasets.",
    "In this paper, authors propose a probabilistic extension of classic Neural Link Prediction models, such as DistMult and ComplEx. The underlying assumption is that the entity embeddings and the relation embeddings are sampled from a prior Multivariate Normal distribution, whose (hyper-)parameters can be estimated via maximum likelihood. In this paper, authors use Variational Inference (VI) for approximating the posterior distribution over the embeddings, and use Stochastic VI for maximising the Evidence Lower BOund (ELBO) while scaling to large datasets. In Sect. 3, authors introduce the generative process, and show how MAP estimation of the embedding matrices can recover the original models. In Sect. 4, authors start from the intractable marginal likelihood over the data (Eq. 5) for deriving the corresponding ELBO (Eq. 6), which is defined over:",
    "This paper proposes an online learning algorithm for supervised dimension reduction, called incremental sliced inverse regression (ISIR). The key idea is converting the SIR problem into PCA problem by using the inverse of covariance matrix. After the transformation, we can use incremental PCA to compute the top eigenvector and obtain the approximate solution of SIR in streaming way. The authors also extend ISIR to overlapping case.",
    "Sliced Inverse Regression is a well-known technique for finding EDR space in supervised dimension reduction problems, under condition that input X is normally disributed. When the number of dimensions is large and an access to observations is online, finding eigenvalues of covariance matrices (online) could become computationally costly. So, the paper focuses the problem of updating few principal components of covariance matrices as new examples come.",
    "This paper presents 'Multimodal Factorization model' that factorizes representations into shared multimodal discriminative factors and modality specific generative factors. This work applies 'Wassertein Auto-Encoders' by Tolstikhin et al (with proofs that this setup works in the multimodal case) for handling factorized joint distributions over the multimodal space. Can this method be considered as a generalization of the wasserstein autoencoder based method with a broader application? - the authors should discuss this more broadly in the paper.",
    "Multimodality learning is an important topic in multimedia and human computer interaction.  How to efficiently leverage the additional information cross multimodality is the key to the task. Authors proposed the Bayesian latent variable model to factorize the multimodality representation into multimodal discriminative factors and modality-specific generating factors, which is interesting. Approximate inference is also proposed to learn this model via a generalised mean-field assumption. ",
    "This paper proposes  an adaptation technique for TTS using wavenet as the speech backend, with the adaptation carried out on small data. The work is extremely significant in that speech data is hard to produce  (we need many hours of speaker data), and techniques to adapt (transfer learning?) data from large networks would be quite valuable. The main idea is that we train a network containing a large amount of data, and (assuming that we have a trained model), we adapt this network to the task of generating speech from text for a much smaller dataset. ",
    "This paper investigates speaker adaption with a few samples based on an existing (pre-trained) multi-speaker TTS system. The three approaches in this paper are almost the same as the voice cloning work in Arik et al. (2018). However, it is still very beneficial to demonstrate these approaches for linguistic feature conditioned WaveNet.",
    "This paper considers the robust estimation problem under Huber\u2019s \\epsilon-contamination model. This problem is a hot topic in theoretical statistics and theoretical computer science community in recent 3 years.  From theoretical statistics community, the main approach is through depth functions. Solving the robust estimation problem can be reduced to solving a min-max problem. While the formulation is clean and can achieve the optimal statistical rate, solving the min-max problem is computationally intractable in general. On the other hand, approaches from TCS community are more involved and sometimes cannot achieve the optimal statistical rate (especially for the general distribution). ",
    "The paper considers the problem of robust high dimensional estimation in Huber\u2019s contamination model. The algorithm is given samples from a distribution (1 - eps) * P + eps * Q, where P is a \u201cnice\u201d distribution (e.g. a Gaussian), eps is the fraction of contaminated points, and Q is some unconstrained noise distribution. The goal is then to estimate parameters of P as well as possible, given this noise. The settings they primarily consider in this paper are when P is a Gaussian with unknown mean and identity covariance, or when it is a Gaussian with unknown covariance. Classical estimators such as Tukey depth or matrix depth for these problems achieve optimal minimax rates, but are computationally expensive to compute. However, recent work of [1,2] propose efficient estimators for this problem that (nearly) achieve these rates.",
    "In this paper, the authors proposed a new format of representation called scene programs, to describe the visual scenes. To extract the scene programs from scenes, the authors exploited the off-the-shelf object detection and segmentations model, mask r-cnn to extract all objects and the corresponding attributes from the images, and then detect groups for those objects, which are then used to generate the programs which matches the input scenes. The experiments are performed on a synthetics datasets which consists of multiple shapes with different attributes. The experiments shows that the proposed model can infer more accurate programs from the scenes, and those generated programs can be used to recover the input scenes more accurately. Besides, the authors also showed that the generated scene programs can be used for image editing and making visual analogy.",
    "This paper presents a system that infers programs describing 3D scenes composed of simple primitives. The system consists of three stages each of which is trained separately. First, the perceptual module extracts object masks and their attributes. The objects are then are split into several groups. Finally, each group is mapped to a corresponding DSL program using a sequence-to-sequence network similar to the ones typically employed in neural machine translation.",
    "The work takes inspiration from a recent work on phased LSTM, and proposes to add a Gaussian gate based on time to LSTM cells. With this additional gate, the network can skip updating the states by closing the time-gate, as a result enabling longer memory persistence, and better gradient flow. The authors also propose to add a budget term to force the time-gate to be closed most of the time as a way to save compute. Empirical results suggest the Gaussian-gated LSTMs perform better than regular LSTMs on tasks with long temporal dependencies. The authors also propose to use a curriculum training schedule in which the variance of the gaussian gates is continuously increased to speed up training of LSTMS.  ",
    "This paper focuses on the reduction of training time by various mechanisms. By introducing a time gate during training, it controls when a neuron (weights?) can be updated during training. By introducing and additional budget term in the loss function, training costs (number of computations) are reduced by one order of magnitude. ",
    "The authors present a simple algorithm based on the statistics of neural activations of deep networks to detect out-of-distribution samples. The idea is to use the existing running estimate of mean and variance within BatchNorm layers to construct feature representations that are later fed into a simple linear classifier. The authors demonstrate superior performance over the previous state-of-art in the standard evaluation setting and provide fascinating insights and empirical analysis of their method.",
    "There has been recent interest in using statistics and information summary measures to evaluate what deep nets are trying to do. Following the line of work, the paper suggests to use mean and variance of Z-scores accumulated across all layers/channels as features to distinguish ID and OOD samples. Simple idea but needs some work in its current format. ",
    "This paper studies the problem of learning the parameter of one hidden layer neural network with sigmoid activation function based on the negative log likelihood loss. The authors consider the teacher network setting with Gaussian input, and show that gradient descent can recover the teacher network\u2019s parameter up to certain statistical accuracy when the initialization is sufficiently close to the true parameter. The main contribution of this paper is that the authors consider the classification problem with negative log likelihood loss, and provide the local convergence result for gradient descent. However, based on the previous results in Mei et al., 2016 and Zhong et al., 2017, this work is incremental, and current results in this paper is not strong enough. To be more specific, the paper has the following weaknesses:",
    "This paper studies the problem of recovering a true underlying neural network (assuming there exists one) with cross-entropy loss. This paper shows if the input is standard Gaussian, within a small ball around the ground truth, the objective function is strongly convex and smooth if there is a sufficiently large number of samples. Furthermore, the global minimizer is actually the true neural network. This geometric analysis implies applying gradient descent within this neighborhood, one can recover the underlying neural network. This paper also proposed a provable method based on spectral learning to find a good initialization point. Lastly, this paper also provides some simulation studies.",
    "This paper proposed a feature boosting and suppression method for dynamic channel pruning. To be specific, the proposed method firstly predicts the importance of each channel and then use an affine function to amplify/suppress the importance of different channels. However, the idea of dynamic channel pruning is not novel. Moreover, the comparisons in the experiments are quite limited. ",
    "This manuscript presents a nice method that can dynamically prune some channels in a CNN network to speed up the training. The main strength of the proposed method is to determine which channels to be suppressed based upon each data sample without incurring too much computational burden or too much memory consumption.  The good thing is that the proposed pruning strategy does not result in a big performance decrease. Overall, this is a nicely written paper and may be empirically useful for training a very large CNN. Nevertheless, the authors did not present a real-world application in which it is important to speed up by 2 or 3 times at a small cost, so it is hard to judge the real impact of the proposed method.",
    "This paper proposes to consider the mixed equilibrium objective function for GANS. The authors generalize the mirror descent/mirror prox to handle continuous games. The technical challenge is to write those algorithms in infinite dimensional spaces. This reviewer finds this however to be a mere technicality, and there seems to be no conceptual obstruction. In fact other paper have already written this, see for example ``Mirror Descent Learning in Continuous Games\" by Zhou et al. at CDC 2017 (I'm sure there are other references too).",
    "This paper extends the mirror-descent and mirror-prox algorithms to infinite dimensional Banach spaces so that they can be applied to solve the mixed Nash equilibrium of the popular generative adversarial networks. The main technical results appear to be formal but straightforward extensions of existing techniques in finite dimensional spaces. A sample-based practical algorithm is proposed so that the infinite dimensional algorithms can still be computed. Experiments are a bit disappointing as the authors only used visual appeal as an evaluation criterion. (I understand why the authors chose to do so but as an algorithmic paper, resorting to an evaluation based on visual appeal is almost always unsatisfactory.)",
    "This paper explored the means of tuning the neural network models using less parameters. The authors evaluated the case where only the batch normalisation related parameters are fine tuned, along with the last layer, would generate competitive classification results, while using very few parameters comparing with fine tuning the whole network model. However, several questions are raised concerning the experiment design and analysis:",
    "the paper introduces a new way of fine-tuning neural networks. Instead of re-training the whole model or fine-tuning the last few layers, the authors propose to fine-tune a small set of model patches that affect the network at different layers. The results show that this way of fine-tuning is superior to above mentioned typical ways either in accuracy or in the number of tuned parameters in three different settings: transfer learning, multi-task learning and domain adaptation.",
    "Batch Normalization (BN) suffers from 2 flaws: 1) It performs poorly when the batch size is small and 2) computing only one mean and one variance per feature might be a poor approximation for multi-modal features. To alleviate 2), this paper introduces Mode Normalization (MN) a new normalization technique based on BN. It uses a gating mechanism, similar to an attention mechanism, to project the examples in the mini-batch onto K different modes and then perform normalization on each of these modes.",
    "The paper proposes a generalisation of Batch Normalisation (BN) under the assumption that the statistics of the unit activations over the batches and over the spatial dimensions (in case of convolutional networks) is not unimodal. The main idea is to represent the unit activation statistics as a mixture of modes and to re-parametrise by using mode specific means and variances. The \"posterior\" mixture weights for a specific unit are estimated by gating functions with additional affine parameters (followed by softmax). A second, similar variant applies to Group Normalisation, where the statistics is taken over channel groups and spatial dimensions (but not over batches). ",
    "It was believed that sparse architectures generated by pruning are difficult to train from scratch. The authors show that there exist sparse subnetworks that can be trained from scratch with good generalization performance. To explain the difficulty of training pruned networks from scratch or why training needs the overparameterized networks that make pruning necessary,  the authors propose a lottery ticket hypothesis: unpruned, randomly initialized NNs contain subnetworks that can be trained from scratch with similar generalization accuracy.  They also present an algorithm to identify the winning tickets.",
    "It is widely known that large neural networks can typically be compressed into smaller networks that perform as well as the original network while directly training small networks can be complicated. This paper proposes a conjecture to explain this phenomenon that the authors call \u201cThe Lottery Ticket Hypothesis\u201d:  large networks that can be trained successfully contain at initialization time small sub-networks \u2014 which are defined by both connectivity and the initial weights that the authors call \u201cwinning tickets\u201d \u2014 that if trained separately for similar number of iterations could reach the same performance as the large network. The paper follows by proposing a method to find these winning tickets by pruning methods, which are typically used for compressing networks, and then proceed to test this hypothesis on several architectures and tasks. The paper also conjectures that the reason large networks are more straightforward to train is that when randomly initialized large networks have more combinations for subnetworks which makes have a winning ticket more likely.",
    "This paper investigates the problem of extracting a meaningful state representation to help with exploration in RL, when confronted to a sparse reward task. The core idea consists in identifying controllable (learned) features of the state, which in an Atari game for instance typically corresponds to the position of the player-controlled character / vehicle on the screen. Once this position is known (as x, y coordinates on a custom low-resolution grid), one can use existing count-based exploration mechanisms to encourage the agent to visit new positions (NB: in addition to the x, y coordinates, extra information is also used to disambiguate the states for counting purpose, namely the current score and the state\u2019s cluster index obtained with a basic clustering scheme). To find the position, the algorithm trains one inverse dynamics model per x, y cell on the grid: each model tries to predict the action taken by the agent given two consecutive states, both represented by their feature map (at coordinate x, y) learned by a convolutional network applied to the pixel representation. The outputs of these inverse dynamics models are combined through an attention mechanism to output the final prediction for the action: the intuition is that the attention model will learn to focus on the grid cell with best predictive power (for a given state), which should correspond to where the controllable parts of the state are. Experiments on several Atari games (including Montezuma\u2019s Revenge) indeed show that this mechanism is able to track the true agent\u2019s coordinates (obtained from the RAM state) reasonably well. Using these coordinates for count-based exploration (in A2C) also yields significantly better results compared to vanilla A2C, and beats several previously proposed related techniques for exploration in sparse reward settings.",
    "This paper introduces contingency-aware exploration by employing attentive dynamics model (ADM). ADM is learned in self supervised manner in an online fashion and only using pure observations as the agents policy is updated. This approach has clear advantages to earlier proposed count based techniques where agent's curiosity is incentivized for exploration. Proposed technique provides an important insight into how to approach such challenging tasks where the rewards are very sparse. Not only it achieves state of the art results with convincing empirical evidence but also authors make a good job of providing details of their specific modelling techniques for training challenges. They make a good job of comparing and contrasting the contingency-awareness by ADM to earlier proposed methods such as intrinsic motivation and self-supervised dynamics model. Overall exposition is clear with well explained results. The proposed idea raises interesting questions for future work.",
    "This works propose a new approach to learn to sample (or generate) the parameters of a deep neural networks to solve a task. They propose a new architecture inspired by hyper networks and adversarial auto-encoders, where the parameters of the networks are generated from a low dimensional latent space. By using an ensemble of networks sampled with their approach they're able to get state of the art results on uncertainty estimation.",
    "This paper proposes a technique for learning a distribution over parameters of a neural network such that samples from the distribution correspond to performant networks. The approach effectively encourages sampled parameters to have low loss on the training set, and also uses an adversarial loss to encourage the distribution of parameters to be Gaussian distributed. This approach can improve performance slightly by using ensembling and can be useful for uncertainty estimates for out-of-distribution examples. The approach is tested on a few simple problems and is shown to work well.",
    "In computing the gradient of the ELBO, the main challenge lies in computing the gradient of the reconstruction loss with respect to the encoder parameters. VAEs traditionally rely on reparameterization in order to obtain a low-variance estimate, but there are a number of other gradient estimators that one can apply. The authors here proprose to use a trick that is known, but perhaps not widely known: If we introduce an importance sampling distribution, then we can use samples from this distribution to compute an importance-weighted estimate of the gradient. The idea is now that we can compute the gradient w.r.t. the encoder parameters as a simple importance-sampling estimate, which obviates then need for reparameterization, or likelihood-ratio estimators. The authors then apply this trick to train VAEs with discrete latent variables.",
    "This paper proposes training VAEs with discrete latent variables by importance sampling the expected log likelihood (ELL) term in the ELBO, which is the problematic term since it is not amenable to reparametrization gradients.  For the importance sampling distribution, they choose the variational distribution itself, making the ELL gradient E[(d q(z|x) / d \\theta) \\log p(x|z) / q(z|x)].  Experiments are reported for MNIST and Fashion-MNIST using Bernoulli and categorical latent variables.",
    "Authors propose a novel combination of RBM feature extractor and CNN classifiers to gain robustness toward adversarial attacks. They first train a small mean field boltzmann machine on 4x4 patches of MNIST, then combine 4 of these into a larger 8x8 feature extractor. Authors use the RBM 8x8 feature representation as a fixed convolutional layer and train a CNN on top of it. The intuition behind the idea is that since RBMs are generative, the RBM layer will act as a denoiser. ",
    "The recent work of Schott et al (which the authors compare results to) proposed the use of Bayes rule inversion as a more robust mechanism for classification under different types of adversarial attacks. The probabilities are approximated with variational autoencoders. During training the inference network is used, but during testing optimization based inference is carried out to compute loglikelihoods.",
    "Ullman et al. showed that slight changes in location or size of visible regions in minimal recognizable images can significantly impair human ability to recognize objects. This paper is a  follow-up of Ullman et al. paper, with focus on sensitivity of DNNs to certain regions in images. In other words, slight change of such regions\u2019 size or location in the image can significantly affect DNN ability in recognizing them, even-though these changes are not noticeable for humans. ",
    "This paper is a more thorough follow-up to e a previous work by Ullman et al that was comparing minimally recognizable patches by humans compared to deep neural network. This paper exhibits that a wide range of architectures features the same fragility and that these effects can combated by better training methodology and different pooling architectures. Still even with those changes deep CNNs still posses more fragile behavior than human vision. One of my criticism is that human vision is kind of different: it makes multiple passes over the same images at multiple scales, so this might contribute significantly to these differences. Still this paper makes a lot of interesting observations and analyses and represents a first methodological study of this phenomenon.",
    "This paper studies the problem of generating contracts by a principal to incentive agents to optimally accomplish multiagent tasks. The setup of the environment is that the agents have certain skills and preferences for activities, which the principal must learn to act optimally. The paper takes a combined approach of agent modeling to infer agent skills and preferences, and a deep reinforcement learning approach to generate contracts. The evaluation of the approach is fairly thorough.",
    "This paper proposes a way to train a manager agent which would manage a bunch of worker agents to achieve a high-level goal. Each worker has its own set of skills and preferences and the manager tries to assign sub-tasks to these agents along with bonuses such that the agents can even perform tasks that are not preferred by them. Authors achieve this by training a manager which tracks the skills and preferences of the agents on the fly. Authors have done an extensive analysis of the proposed approach in two simple domains: resource collection and crafting.",
    "This paper proposes a new type of recurrent neural network which takes into account five different features: in addition to the prevalent dense features, the author(s) also consider(s) sparse features, time features, global static and changing features. The differences in feature types are reflected in the cell state or output state update rules. Experiments on a modified UCI dataset and a proprietary dataset show that the proposed model outperforms the time-variant LSTM (TLSTM).",
    "The paper addresses limitations of the LTSM method for modeling time series. The work is motivated by applications where multiple time series need to be combined while they may get updated in an asynchronous fashion. Authors mention IoT applications in the Intro and give examples from a power consumption data set and a churn prediction application in their numerical experiments sections. ",
    "In this paper the authors propose a neural model that, given a logical formula as input, predicts whether the formula is a tautology or not. Showing that a formula is a tautology is important because if we can classify a formula A -> B as a tautology then we can say that B is a logical consequence of A. The structure of the formula is a feedforward neural network built in a top-down manner. The leaves of this network are vectors (each of them represents a particular occurrence of an atom) which, after the construction of the formula, are processed by some recurrent neural networks.",
    "In this paper, the authors provide a new neural-net model of logical formulae. The key feature of the model is that it gathers information about a given formula by traversing its parse tree top-down. One neural net of the model traverses the parse tree of the formula from the root all the down toward the leaves, and generates vectors for the leaves of the tree. Then, another RNN-based neural net collects these generated vectors, and answers a query asked for the formula, such as logical entailment. When experimented with Evans et al.'s data set for logical entailment queries, the authors' model outperforms existing models that encode formulae by traversing their parse trees bottom-up.",
    "This paper studies an interesting and meaningful topic that what is the potential of curriculum learning (CL) in training dnn.  The authors decompose CL into two main parts: scoring function and pacing function. Towards both parts, several candidate functions are proposed and verified.  The paper is presented quite clear and gives contribution to better understand CL in the literature of DNN.",
    "This problem of interest in this paper is Curriculum Learning (CL), in the context of deep learning in particular. CL refers to learning a non-random order of presenting the training examples to the learner, typically with easier examples presented before difficult ones, to guide learning more effectively. This has been shown to both speed up learning and lead to better generalization, especially for more challenging problems. In this paper, they claim that their contribution is to decompose the problem of CL into learning two functions: the scoring function and the pacing function, with the role of the former being to estimate the difficulty of each training example and the latter to moderate the schedule of presenting increasingly more challenging examples throughout training.",
    "The fact that a number of current generalization bounds for (deep) neural networks are not expressed on the deterministic predictor at stake is arguably an issue. This is notably the case of many recent PAC-Bayesian studies of neural networks stochastic surrogates (typically, a Gaussian noise is applied to the network weight parameters). The paper proposes to make these PAC-Bayesian bounds deterministic by studying their \"noise-resilience\" properties. The proposed generalization result bounds the margin of a (ReLU) neural network classifier from the empirical margin and a complexity term relying on conditions on the values of each layer (e.g., via layer Jacobian norm, the layer output norm, and the smallest pre-activation value). ",
    "This paper presents a PAC-Bayesian framework that bounds the generalization error of the learned model. While PAC-Bayesian bounds have been studied before, the focus of this paper is to study how different conditions in the network (e.g. behavior of activations) generalize from training set to the distribution. This is important since prior work have not been able to handle this issue properly and as a consequence, previous bounds are either on the networks with perturbed weights or with unrealistic assumptions on the behavior of the network for any input in the domain.",
    "The paper presents an alternative view on the training procedure for the VQ-VAE. The authors have noticed that there is a close connection between the original training algorithm and the well-known EM algorithm. Then, they proposed to use the soft EM algorithm. In the experiments the authors showed that the soft EM allows to obtain significantly better results than the standard learning procedure on both image and text datasets.",
    "This paper discusses VQ-VAE for learning discrete latent variables, and its application to NMT with a non-autoregressive decoder to reduce latency (obtained by producing a number of latent variables that is much smaller than the number of target words, and then producing all target words in parallel conditioned on the latent variables and the source text). The authors show the connection between the existing EMA technique for learning the discrete latent states and hard EM, and introduce a Monte-Carlo EM algorithm as a new learning technique. They show strong empirical results on EN-DE NMT with a latent Transformer (Kaiser et al. (2018)).",
    "This paper presents a multiview framework for sentence representation in NLP tasks. Authors propose two architectures, one using a generative objective, while the other uses a discriminative objective. Both combine a recurrent based encoding function and a linear model. Large experiments have been conducted on several NLP tasks and datasets, showing improvement of the introduced frameworks compared to baselines.",
    "This paper is about a multi-view framework for learning sentence representations. Two objective functions (a generative one and a discriminative one) are proposed that make use of two encoders, one of them is based on an RNN and the other on a linear projection of averaged word embeddings. Each of these objective functions has a multi-view framework where their respective objective functions are in part based on making sure their is some relationship between the two different encoders. This multi-view framework is shown to be helpful over having independent encoders in their ablation study.",
    "This paper studies distributed optimization in the presence of straggling computing nodes. In a synchronous distributed optimization approach, the stragglers delay the entire computation as the synchronization operation cannot be performed till every computing nod has completed its task. This paper aims to mitigate the effect of stragglers by proposing Anytime MiniBatch (AMB) approach, where each computing node is allowed to process the different number of samples between two synchronization steps. In particular, each node is given $T$ unit time to process as many samples as it can. After that, the nodes are allowed to aggregate the information among themselves through a consensus mechanism for another $T_c$ unit time. In contrast with this, the usual Fixed MiniBatch (FMB) approach requires each node to process a fixed number of samples before invoking aggregating step. The presence of stragglers can significantly increase the time between two synchronization step and slow down the overall optimization process. ",
    "The paper considers the problem of online stochastic convex optimization in a fully distributed topology. In particular, the authors focus on the synchronous setting and to avoid the slow progress that can be obtained by slow nodes, called stragglers, they propose an online distributed optimization method called Anytime Minibatch (AMB). In the update of AMB rather than fixing the minibatch size, they fix the computation time in each epoch. This characteristic prevents the stragglers from holding up the entire network, while allowing nodes to benefit from the partial work carried out by the slower nodes. ",
    "This submission proposes a reinforcement learning framework based on human emotional reaction in the context of autonomous driving. This relies on defining a reward function as the convex combination of an extrinsic (goal oriented) reward, and an intrinsic reward. This later reward is learnt from experiments with humans performing the task in a virtual environment, for which emotional response is quantified as blood volume pulse wave (BVP). The authors show that including this intrinsic reward lead to a better performance of a deep Q networks, with respect to using the extrinsic reward only. ",
    "Starting from the hypothesis that humans have evolved basic autonomic visceral responses that influence decision making in a meaningful way and that these are at work in driving a car, the authors propose to use such signals within the RL framework. This is accomplished by augmenting the RL reward function with a model learned directly from human nervous system responses. This leads to a ",
    "Neural process (NP) is a recent probablistic method for modeling distributions of functions. The authors claim that one substantial weakness of NP is the tendency of under-fitting. The authors give a hypoethesize: the under-fitting behaviour of NP is because the mean-aggregation step in the encoder acts as a bottleneck, as a result, it is difficult for the decoder to learn the relevant information for a give target prediction. This paper proposes to resolve this issue by adding an attention mechanism to the deterministic path. The experimental results show that the proposed method converge faster and give better results on various tasks.",
    "The authors extend neural processes by incorporating two types of attention processes: self-attention for enriching the features of the context points and cross-attention for producing a query-specific representation. By replacing MLPs and mean pooling with these attention processes, the authors resolve the underfitting problem of NPs. The experimental results show that ANPs converge better and faster than NPs.",
    "In this paper, the authors investigate the gradient calculation in the original MAML (Finn et al. 2017) and E-MAML (Al-Shedivat et al. 2018). By comparing the differences in the gradients of these two algorithms, the authors demonstrate the advantages of the original MAML in taking the casual dependence into account. To obtain the correct estimation of the gradient through auto-differentiation, the authors exploit the DiCE formulation. Considering the variance in the DiCE objective formulation, the authors finally propose an objective which leads to low-variance but biased gradient. The authors verify the proposed methods in meta-RL tasks and achieves comparable performances to MAML and E-MAML. ",
    "In this paper, the author proposed an efficient surrogate loss for estimating  Hessian in the setting of Meta-reinforcement learning (Finn.et al, 2017), which significantly reduce the variance while introducing small bias. The author verified their proposed method with other meta-learning algorithms on the Mujoco benchmarks. The author also compared with unbiased higher order gradient estimation method-DiCE in terms of gradient variance and average return. ",
    "This paper presents the NeuroSAT architecture, which uses a deep, message passing neural net for predicting the satisfiability of CNF instances. The architecture is also able to predict a satisfiable assignment in the SAT case, and the literals involved in some minimal conflicting set of clauses (i.e. core) in the UNSAT case. The NeuroSAT architecture is based on a vector space embedding of literals and clauses, which exploits (with message passing) some important symmetries of SAT instances (permutation invariance and negation invariance). This architecture is tested on various classes of random SAT instances, involving both unstructured (RS) problems, and structured ones (e.g. graph colorings, vertex covers, dominating sets, etc.).",
    "This paper trains a neural network to solve the satisfiability problems. Based on the message passing neural network, it presents NeuroSAT and trains it as a classifier to predict satisfiability under a single bit of supervision. After training, NeuroSAT can solve problems that are larger and more difficult than it ever saw during training. Furthermore, the authors present a way to decode the solutions from the network's activations. Besides, for unsatisfiable problems, the paper also presents NeuroUNSAT, which learns to detect the contradictions in the form of UNSAT cores.",
    "The paper describes a framework for training a self-driving policy by augmenting imitation loss with additional loss terms that penalize undesired behaviors and that encourage progress. The policy takes as input a parsed representation of the scene (rather than raw images) and outputs pose trajectories for a down-stream controller. The method is trained on simulated data that includes perturbations to improve generalizability. The framework is evaluated in simulation through a series of ablations to better understand the contribution of the different loss terms.",
    "The paper proposes a vehicle\u2019s trajectory planner that iteratively predict next-step (longitudinal and latitudinal) position of an ego-vehicle. Instead of using a raw image, a set of handcrafted features (i.e., the status of traffic lights, route, roadmap, etc) are mapped onto a fixed-size of bird-eye view map, which is then fed into the recurrent neural network. Additional regularizing loss terms are explored for the robustness of the model. The effectiveness of the method is demonstrated in simulation and real-world experiment.",
    "The paper presents a method for identifying and selecting the most informative subset of the training dataset in order to reduce training time while maintaining test accuracy. The method consists of training a proxy model that is smaller and has been trained for fewer epochs, and which can optionally be ensembled. Experiments show promising results, indicating that some datasets can be reduced to half the size without impacting model performance.",
    "This paper studies a very simple and intuitive method to boost the training speed of deep neural networks. The authors first train some light weighted proxy models, using these models to rank the data according to its uncertainty, and then pick the most uncertain subset to train the final model. Experiments on CIFAR10/SVHN/Amazon Review Polarity demonstrates the effectiveness.",
    "This paper proposes a sequential Monte Carlo Planning algorithm that depicts planning as an inference problem solved by SMC. The problem is interesting and the paper has a nice description of the related work. In terms of the connection between the the problem and Bayesian filtering as well as smoothing, the paper has novelty there. But it is unclear to me how the algorithm proposed is applicable in complex continuous tasks as claimed.",
    "Sequential Monte Carlo (SMC) has since its inception some 25 years ago proved to be a powerful and generally applicable tool. The authors of this paper continue this development in a very interesting and natural way by showing how SMC can be used to solve challenging planning problems. This is a enabled by reformulating the planning problem as an inference problem via the recent trend referred to as \"control as inference\". While there is unfortunately no real world experiments, the simulations clearly illustrate the potential of the approach.",
    "A nice paper that clarifies the difference between the clean accuracy (accuracy of models on non-perturbed examples) and the robust accuracy (accuracy of models on adversarially perturbed examples) and it shows that changing the marginal distribution of the input data P(x) while preserving its semantic P(y|x) fixed affects the robustness of the model. Therefore, testing the robustness of the model should be performed in a careful manner. Comprehensive experiments were performed to show that changing the distribution of the MINST (smoothing) and CIFAR (saturation) data could lead to a significant difference in robust accuracy while the clean accuracy is almost steady. In addition, a set of experiments were performed in an attempt to search for the criteria required for choosing a proper dataset for testing adversarial attack to measure the robustness. ",
    "The paper is interesting and topical: robustness to adversarial input presentation (or shifts in training data itself, even those of the nature described by the authors 'semantic-lossless' shifts). Adversarial inputs are investigated under l-inf bounded perturbations, while multiclass classification on images is the target problem considered. The theoretical parts of the paper, assigning lack of adversarial robustness to the shape of the input distribution (Section 2) is the strongest part of the paper, adding some simple and important insights. Unfortunately, the empirical part of the paper is weakened by an over-reliance of (custom perturbations of ) the popular MNIST and CIFAR10 datasets (which are themselves based on larger sets). Furthermore, the basic conclusion as to causes and remedies of lack of robustness is not evident, and it is not evident that it has been sufficiently investigated. Shape yes, differences in perturbable volume not (how does that concur with Section 2?), and inter-class distance also not. Are we to base these conclusions on 2 perturbed datasets? How are readers to synthesize the final conclusion that robustness is a 'complex interaction of tasks and data', other than what they would already expect? In short, a valiant effort, and a good direction, but one that needs more work.",
    "Authors present a new normalization technique called Equi-Norm and experimentally show its fast convergence properties over its popular competitors Batch-norm and Group-norm. The main idea in the paper is the EquiNorm method modifies the weights of a layer before forward propagating through it such that the contribution from positive and negative kernel weights to the output is same. In the experimental section, their approach is shown to be more accurate than Batch-norm and group norm on all datasets except, Imagenet. Is there any reasoning why this method performed slightly poorly on this particular dataset.",
    "This manuscript introduces a new layer-wise transform, EquiNorm, to improve upon batch normalization. As with batch normalization and related techniques, the idea is to introduce a simple linear transform at each layer to reduce the dependency of the features to the data. Unlike batch normalization, the procedure does not modify the inputs to the layers but rather the layer weights. For this purpose, a scaling factor and a shift is computed on a mini batch, separating positive and negative weights to compute easily both running estimates of shift and of spread (here in the l1 sense). The method is compared to BatchNorm and GroupNorm on several classic computer vision datasets. Empirically, the method converges faster in the beginning of the optimization, in the sense that in the first few epochs the test accuracy is higher than for BatchNorm. However, this benefit decreases with more epochs and when the results are close to peak performance the difference between methods is a small. In addition, test accuracy can decrease at the end of the optimization, which the authors interpret as a sign of increased overfit, and tackle with clever data augmentation. The paper reads well.",
    "The paper aims to remove potential examples with label noise by discarding the ones with large losses in the training procedure. The idea also applies to the setting where instances may contain large noise. The proposed method may have an implicit trade-off between the robust to label noise and feature noise, which explains why the proposed method also has good performances on instance-dependent label noise. The paper is well-written and has sufficient experiments. ",
    "This paper presents ODD, a method that rejects incorrectly labeled / noisy examples from training on the fly. The motivation is sound, that with the capacity of modern neural networks, it's easy to memorize the mislabeled data and thus hurt generalization. If we could reject such mislabeled data, we may be able to get a more generalizable model. The authors made an observation that when training with large learning rate, examples with correct labeling and incorrect labeling exhibits different loss distributions. The authors further noticed that the loss distribution of incorrectly labeled examples can be simulated using eq.(1). Therefore, by setting a threshold that corresponds to a percentile of the incorrectly labeled loss distribution, the authors are able to reject incorrect examples.",
    "[UPDATE: Thanks to the authors for engaging with the comments in the review.  I hope to see them fully addressed in the revision and look forward to seeing the next version of the paper!]  The paper investigates how pretrained representations might be expected to help prediction on a downstream task.  In some sense, they should \"obviously\" help: the downstream predictor can learn to exploit any mutual information between its target output and the pretrained representations.  That's the standard motivation for multitask learning.  However, the paper exhibits specific settings in which the target output can be *exactly* predicted from the pretrained representations, using only a *simple* probe such as a linear classifier.    The paper is primarily theoretical, although a few experiments are included by way of illustration.  It is not clear what the experiments are intended to verify.  To make the analysis possible, the pretrained representations in the paper are not underlying representations such as word embeddings.  Rather, they are identifiable given the pretraining data, which makes it clear what \"successful pretraining\" means.  For example, the representation of word x_i in a sentence is the conditional distribution of x_i given all other words in the sentence, as predicted by a pretrained cloze language model.  The analysis assumes (though the experiments do not check) that the predicted conditional distribution actually matches the true conditional distribution.  This should be the case in the limit of infinite training data, provided that the cloze language model has adequate capacity and can be trained to a global optimum of log-loss.  It is shown that if the vocabulary is large enough, or under other assumptions, then this representation of x_1 is enough to recover the posterior distributions over h_1 and h_0, which are assumed to be sufficient for the downstream task.  Caveat: In the analysis, the observed sentences are assumed to be generated by a latent-variable model.  One would then expect the downstream task target output to be predictable from the actual latent variables.  However, the paper assumes more strongly that the target is a function of the *posterior distribution* of the latent variables given the observed sentences.  In other words, the goal of the downstream task is not to recover what the speaker *actually* meant, but only to recover what a hearer who knows the true generating distribution *thinks* it meant (given only the sentence and no other context).  Two structures are considered for the latent-variable model and its relationship to the downstream task.  For the more complex version, the predictor is also more complex, requiring argmax attention over all positions i.  In both cases, the paper considers allowing the predictor to prepend an arbitrary word embedding x_1 to the input.  This soft prompt can serve to shift the posterior predictions of x_i so as to be more informative for the downstream task.   ",
    "This work puts forward a theoretical analysis of pre-trained language models and head and prompt tuning on downstream tasks. In particular it studies the assumptions on the distribution of language and downstream tasks under which the downstream label can be recovered from a pretrained LM by using head or prompt tuning, by considering a generative model of language that can be represented as a HMM. The key components of the analysis include: 1. The data distribution is generated from a HMM (or a memory augmented HMM). 2. The initial state of the HMM, $H_0$, contains all the information necessary to recover the downstream label for the sequence.  Under this setup, for head tuning, the downstream labels are recoverable under the condition that the token emission probability matrix $W$ has linearly independent columns (implying that the dimensionality of the HMM hidden states is smaller than the vocabulary size of the data generating distribution). On the other hand, prompt tuning requires only a relaxed version of this condition, only the columns corresponding to the support of the downstream task need to be independent, eliminating the condition on the hidden state dimensionality.  Under memory augmented HMMs, for downstream tasks that can be represented as a linear function of the memory (with a fixed number of cells, $N$), the non-degeneracy condition can be relaxed even for head tuning. For prompt tuning, the independence assumption can be further relaxed to hold only for the set of memory cells that the downstream task depends on.  The authors further perform simulation experiments to validate the findings on different settings of the data generating distribution. Simulation results agree with the findings: 1. Prompt tuning outperforms head tuning in the setting where hidden state size is significantly larger than the token vocabulary size. 2. When the data is generated using memory-augmented HMMs, and the downstream task information can be recovered entirely from the memory, even head tuning gets close to perfect performance for all hidden state sizes.",
    "The paper studies the question why head and prompt tuning work for pre-trained LM. Analyzing complicated neural networks is a daunting task. The paper offers an analysis framework based on the Hidden Markov Model (HMM) and memory augmented HMM. Under this framework, the paper makes a connection with masked LM (BERT) that at time step i, the output of BERT(`[mask]_i`) represents the marginal P(X_i) of the HMM. The framework further allows for analysis of a binary classification task using head tuning or prompt tuning via the posterior distribution of a HMM. To this end, the paper runs a simulation study with data generated from HMM and memory augmented HMM. ",
    "This paper proposes an analysis framework to link the pre-training and downstream tasks. In this framework, the downstream task needs to predict the properties of the posterior distribution over latent variables in an underlying generative model. And When the generative model is a standard HMM, the downstream recovery is possible with a simple classification head under strong non-degeneracy assumptions. It further shows that changing the generative model to a memory-augmented HMM or using prompt tuning can relax the non-degeneracy conditions.",
    "This paper defines a notion of \"transferability\" between features from different domains, which is different from common distribution discrepancy measures such as total variation and Wasserstein distance. This measure of transferability is measured with labeled samples from both domains, and provides a bound on the target error. The empirically test transferability of the features learned by current domain generalization algorithms, and some don't do that well in this transferability measure. They propose an algorithm based on optimizing the measure of transferability across training domains and test it on some domain generalization datasets, including a satellite dataset.",
    "Authors introduced the notion of transferability between pairs of domains (i.e. joint distributions over input x output spaces) along with a discrepancy measure, which can be used to assess how dissimilar are two data sources relative to a given class of predictors. Such a quantity may be useful in either assessing how well is a trained model likely to perform on new data, or as a training signal so that more preference is given to predictors able to generalize out of the training data distribution. The main strength of this work in my opinion is the fact that the proposed transferability measure accounts for the joint distributions over data and labels. However, while I appreciate the depth of the discussion and results in terms of the properties of the proposal, I believe a key missing discussion is the effect that commonly used sets of assumptions have in the proposed transferability measure. Moreover, the evaluation lacks in evidencing the benefits of the proposal relative to current strategies. Please refer to the following for further details.",
    "This paper aims at identifying and quantifying transferability in learning algorithms. The paper proposes a new upper bound on the target error. The proposed algorithm is an adversarial optimisation problem that empirically proved to be effective. ",
    "This paper aims to provide a formulation of transferability. The main intuition is that any near-optimal source classifier should be also near-optimal on the target domain. So the authors quantify transferability by measuring the relation between near-optimal classifiers in source and target domains and derive genralization bounds based on this. In addition, new algorithm is proposed based on the intuition.",
    "This paper studies the ability of Markovian reward functions to represent tasks defined as a set of acceptable policies, partial ordering over policies, partial ordering over trajectories. It first provides a negative result showing that some tasks cannot be specified through a Markovian reward in some environments. Then, it designs a set of linear programs to simultaneously check if a specific task can be encoded into a Markovian reward and to compute such reward. The paper includes an empirical evaluation in a simple domain.",
    "The authors consider the problem of expressing a __task__ via a reward function and discount rate. They show that for various formalizations of what a 'task' is, there exist reward functions which cannot express that task. The authors present an efficient algorithm for deciding the expressibility of a task, and for designing such a reward function. They study certain properties of how many tasks are expressible in a given environment, and demonstrate how their approach can accelerate learning. ",
    "In the reinforcement learning context, the paper proposes three possible definitions for the notion of task, as a set of acceptable policies (SOAP), a partial ordering over policies (PO), or a partial ordering over trajectories (TO). For each definition, the authors show that there exists a task and a controlled Markov process for which there is no reward function that can express that task. Furthermore, the authors notably provide a polynomial algorithm based on linear programming to find such reward function if it exists. Some experiments on random problem instances are also performed to validate the theory.",
    "- An exploration and a concrete answer to the question of what is a task, and a critical examination of the reward hypothesis. The approach that this paper proposes is to define a set of all possible tasks in a Controlled Markov Process (CMP), and then ask the question, does there exist a Markov reward that realizes the given task.  - The paper provides answers the above question in the negative through a counter-example. In summary, the authors provide three modes of expressing the task intent: set of accetable policies (SOAP), partial ordering over policies (PO), partial ordering over trajectories (TO). The key result is that there are tasks defined as per all three methods that are not realizable as a Markov reward optimization problem  - The authors finally propose a linear-programming based polynomial time reward design algorithm that generates a Markov reward for the SOAP task specification and returns Null if such a reward does not exist. ",
    "* This paper uses the insights from Bayesian RL to solve the problem of generalization in RL. In particular, the authors formulated the generalization problem as an epistemic POMDP and proposed an ensemble-based algorithm, called LEEP, to approximately solve the problem.  * The authors empirically demonstrated the performance of LEEP in generalizing to unseen contexts in the Procgen benchmark. They have shown that:   * LEEP performed better than PPO in Maze, Heist, BigFish, and Dodgeball.   * An ablation study to show that the better generalization performance of LEEP does not only come from the use of ensembles.   * An ablation study to show that the better generalization performance of LEEP does come from the inductive bias conferred by the `max_i \u03c0_i` link function proposed by the authors. ",
    "The paper addresses the problem of a reinforcement learning generalizing across different dynamics (with the same state/action space). Specifically, the paper frames this problem as a POMDP, where the properties of the environment are encoded as hidden information. An algorithm LEEP is introduced, which learns different policies for different sampled environments, regularized to make the policies similar, and then combines the policy into a single, hopefully robust policy. ",
    "The paper considers the problem of generalization in contextual MDPs, where the state of the environment consists of a context that remains fairly constant throughout an episode of the MDP. In such a setting the problem of generalization arises when an RL agent learns on a set of training MDPs (MDPs with contexts sampled from a set of training contexts) and then this trained RL agent must perform well on an unseen context test MDP. This paper underlines the challenges of learning and generalizing in such settings, namely, that methods that are not able to handle epistemic uncertainty fail at generalizing in such settings. The paper formulates this problem of generalization as a special POMDP and proposes a new sampling-based method for approximately solving this POMDP. Experimental results show that the proposed methods beats other baselines on a benchmark suite. ",
    "The paper investigates the topic of generalization in reinforcement learning. It starts from the observation that even in fully observed environments, a kind of partial observability arises from epistemic uncertainty about the true MDP the agent faces at test time. This observation gives rise to what the paper calls an epistemic POMDP, which has the property that expected return in the epistemic POMDP equals test time agent performance in expectation over the posterior distribution of MDPs (given the prior is accurate).   This insight is used to point out that, being a POMDP, the optimal policy of the epistemic POMDP is in general memory-based, and in the class of memoryless policies, stochastic. In the same vein, even a policy that is optimal on all training contexts can have very poor generalization performance, and the optimal policy for the epistemic POMDP might not be optimal in any single MDP.  The remainder of the paper focuses on memoryless policies in the empirical epistemic POMDP, where the latter arises from a finite number of samples from the MDP posterior. It is shown that one can lower-bound the performance of an ensemble of policies on the empirical epistemic POMDP by their average performance minus a disagreement penalty to the combined policy \\pi and that optimizing this bound gives the optimal policy for the empirical epistemic POMDP.  Based on these insights, the paper proposes a practical algorithm (LEEP) that combines bootstrap sampling from the training contexts, choosing max for combining the individual policies, PPO as the base algorithm, and the derived regularization term into an algorithm where the n individual policies are optimized in a round-robin fashion.  The proposed algorithm is evaluated on the procgen benchmark, where it compares favorably to pure PPO and Distral. The algorithm is also shown to avoid overfitting when only few training contexts are available. Finally, an ablation study shows that both the agreement penalty term and the max link function contribute to the performance advantage of LEEP.",
    "The paper is concerned with meta reinforcement learning. The author(s) introduced a framework for learning high-order derivatives of value functions using off-policy evaluation. Specifically, the author(s) proposed to adopt existing off-policy evaluation methods to derive the value estimator and then take the derivative with respect to the target parameters to construct the estimate. This technique is further adopted to implement meta reinforcement learning. ",
    "This paper considers meta-RL with gradient-based adaptations, which relies heavily on the estimation of the Hessians of value functions. Though there are previous approaches that focus on unbiased/biased estimations of Hessian. This paper gives a unified view for estimating higher-order derivatives of value functions, through the lens of off-policy evaluation. This subsumes several previous works, also sheds some light on the bias-variance tradeoff of the estimate. Empirically, the new proposed second-order estimate is also incorporated in meta-RL algorithms to showcase the empirical efficiency. ",
    "This paper uses Huang and Jiang (2020) to talk about gradient-based meta learning in reinforcement learning using the language of off-policy evaluation. The logical connection behind those concepts stands from the fact that policy gradient methods in reinforcement learning are in fact instances of the likelihood ratio derivative estimator, which itself stems from important sampling. Proposition 3.2 and 3.3 are obtained from Huang and Jiang. Proposition 3.1 tries to extend their results to talk about higher order derivatives. The author's finally propose to use ideas from Taylor policy optimization from Tang et al. (2020) as a variance reduction method within the doubly robust policy gradient framework of Huang and Jiang.   ",
    "The paper uses the recently developed framework of Taylor expansions for value functions (ref [29] in the paper), expands the results, and shows how they could be applied to Off-Policy Evaluation, and by a non-trivial extension to meta-learning. The main algorthmic contribution of the paper is the application of the ideas to meta-learning, but I feel the main contribution is a conceptual one, further developing the ideas from [29] and drawing theoretical connections between OPE and meta-learning.  The paper includes an experimental section demonstrating marginal improvement over baselines in several domains.",
    "The paper proposes MCM ~ algorithm to perform bidirectional compression in distributed setting. The authors claim similar convergence guarantees as vanilla setting.  They introduce the notion of sending different models to different clients while keeping the global model preserved.  ",
    "This paper proposed a new method: MCM for bidirectional compression in federated learning. Convergence analysis showed that linear convergence can be achieved with the proposed method. Empirical results also show the method could achieve non-trivial performance with high compression rate.",
    "The paper proposes a bidirectional compression algorithm for parameter-server-based distributed training. Two variants, MCM and Rand-MCM, are proposed to achieve the same improvement as the uplink-compression-only compression algorithm, where the downlink-compression-only impacts local models while the global model is preserved. The Rand-MCM also introduces the concept of (simulated) random smoothing via model compression.",
    "In this paper, the authors propose MCM, a new algorithm achieves bidirectional compression with better convergence rate. Theoretical analysis is provided. The empirical results show good performance. ",
    "This paper presents conditions that are necessary for counterfactual invariant predictions under certain assumptions. They derive these from causal graphs and show the connection to worst-case domain generalization. Experiments on natural language datasets show that the proposed conditions do lead to a decrease in worst-domain error.",
    "In this paper, the authors study counterfactual invariance in machine learning models---intervening on \u201cnon causal\u201d parts of the input should not change model predictions---and its relation to how models generalize out-of-domain. The authors show that counterfactually invariant predictors rely more on \u201ccausal\u201d features as opposed to spurious correlations, thus generalizing to unseen distributions where these spurious correlations may not hold. The authors further propose two regularization schemes (one if the underlying data generation mechanism is represented by a causal model and another if it is an anticausal model) using which we can train counterfactually invariant predictors without access to counterfactual examples---as opposed to most prior work in which researchers often seek to either automatically construct or crowdsource counterfactual examples. They show that these strategies are heavily dependent on the underlying causal mechanisms, and that applying the regularization scheme designed for a causal model could lead to worse performance if the underlying data generation mechanism was anticausal and vice versa. The authors offer empirical evidence on text classification tasks (review helpfulness classification and natural language inference) to support their theoretical findings. I have some concerns about the paper (as discussed below) but overall I believe this paper builds on an exciting line of work and offers good theoretical and empirical contributions.",
    "The paper casts robustness to spurious correlations as a model's dependence on input data that is not stable under stress testing. Stress testing here corresponds to changing part of the input data that a practitioner believes should not change the prediction. The authors term this counterfactual invariance and consider two different causal structures that could've produced the data. Identifying distribution-level implications (as opposed to unit-level) of these causal structures, the authors propose regularization schemes to enforce when learning predictors to ensure that counterfactual-invariance holds (under certain assumptions). The effectiveness of these schemes is shown both theoretically and empirically.",
    "In this work, the authors focus on how to build models that are robust to spurious correlations. The focus of the paper is language datasets. The authors work with two types of DAGs -- a) association of the label with the invariant feature is anti-causal, and b) association of the label with invariant feature is causal. The authors propose a notion of invariance, which they call counterfactual invariance, that they require the predictor to satisfy. Under this notion, the prediction $f$ has to remain invariant under all the potential outcomes that $X$ can have under variations to the spurious feature $Z$. Since the notion of counterfactual invariance is hard to enforce as counterfactuals are not observed, the authors come up with necessary conditions that are then used as proxies to enforce counterfactual invariance. The necessary conditions are different in the two directions causal and anti-causal. Further, the authors analyze the relationship between best counterfactual invariant predictor on train domain and target domain (under appropriate notion of changes allowed in target domain). Finally, the authors establish conditions for min-max optimality of the predictor that is learned. ",
    "The submission tackles the problem of training GANs with limited data. It proposes to do so by adaptively regularizing GAN discriminators by replacing some real data by generated samples when the discriminator overfits, accoding to an overfitting heuristic.  A study of the proposed objectives show that the method keep the classical GAN optima while alleviating overfitting of the discriminator.  The method is tested on various datasets with limited data, and compared, using a StyleGAN-2 backbone, against other state-of-the-art methods for training with limited data.",
    "This paper tries to solve discriminator overfitting problem.  The authors propose adaptive pseudo augmentation (APA). * APA employs the generator itself to augment the real data distribution with fake images.   * i.e., Fake images are presented as \"real\" instances to the discriminator. * Adaptiveness comes from measuring overfittingness of the discriminator. * APA has similar theoretical properties to the original GAN, but with $(1-\\alpha)p_\\text{data} + \\alpha p_g = p_g$.  APA improves systnesis quality in the limited-data regime. * on FFHQ, AFHQ-Cat, CUB, Danbooru The authors provide a theoretical analysis of APA, similar to the original GAN. ",
    "This paper introduces a data augmentation strategy for training GANs, which proves to be especially effective in the low data regime. The essence of the idea is to replace real images by images produced by the generator, using an adaptive replacement probability in the discriminator training step. By classifying some fake images as real, discriminator overfitting is prevented, which normally leads to very poor training performance and instability when very little data is available. The proposed method (named APA) improves over or can be combined with another recent data augmentation scheme for the low data regime (such as ADA).",
    "This paper proposes a new method for GAN training with limited data, named adaptive pseudo augmentation (APA). The key idea originates from the empirical observation that, when trained with limited data, the GAN discriminator tends to overfit easily, leading to poor generation performance. Therefore, the authors propose to adaptively add generated samples to the training data, so as to counteract the overfitting during training. Accordingly, they present the APA that is developed based on the output of the discriminator. Empirical experiments demonstrate the effectiveness of the proposed APA.",
    "This paper describes a method for the causal analysis of long streams of event data that can be modeled as multivariate point processes (MPPs). The paper defines the average treatment effect (ATE) between pairs of events in MPPs that occur within a window, and derives how to estimate the ATE as the expected difference of average outcome rates.  When covariates differ or assumptions are violated, this estimate may be biased, but adjusting for the propensity score yields an unbiased estimator, which the paper does through inverse probability of treatment weighting (IPTW) (including a stabilized version).  Experiments on data from known, synthetic MPPs (proximal graphical event models and Hawkes processes) show that the proposed IPTW estimation method more accurately recovers the ATE than baseline conditional intensity scores.  Similarly, experiments on a diabetes dataset show that stable IPTW recovers more true causal pairs at 2 out of 3 levels of recall compared to the conditional intensity scores.  These results extend to using the cumulative rather than the conditional intensity rate. ",
    "This paper proposes a model for estimating the average causal effect in point processes where the estimand of interest is the effect of an event occurring within a window on the rate parameter of a point process. The authors use the formulation commonly used for inverse propensity scores of generalized treatments (e.g., from Robins, Imai). The authors describe the properties of the propensity score as a balancing weight by leveraging known results and advocate for the use of stabilization of inverse propensity scores to reduce variance as in Robins(2000). The weights are then used within an outcome model which is a point process model. Empirical results show promising performance compared to a range of alternatives.  ",
    "This paper proposes a causal inference framework for a multivariate point process model. The key idea is to form a series of binary processes Z_t and X_t using a moving window [t-w,t] to indicate whether processes Z and X have at least one event in the window [t-w,t].  An average treatment event (ATE) is defined and propensity scores are proposed for unbiased estimation of ATE. The authors use synthetic experiments and real-world datasets to demonstrate how the proposed method work compared to baseline approaches.",
    "The paper provides tools to estimate average treatment effect (ATE) between event pairs. The authors first define the quantity for multivariate point processes together with the necessary concepts from Neyman\u2013Rubin causality, then they derive a propensity score in this setting. Finally, they give a method for estimating the ATE and evaluate the method on synthetic and real world datasets. ",
    "This paper discusses how message passing and feature aggregation are affected by abnormal node features, and designs a message passing module called Adaptive Message Passing (AMP) with adaptive residual connection and feature aggregation. In this way, the module can adaptively deal with the node that is inconsistent with the local feature during the message passing. The paper proposes the AirGNN that is built up with AMP as the message-passing layer in GNN, the experiment result shows that the AirGNN gets a more robust result on both the abnormal node and normal node classification comparing with the baselines.",
    "This paper targets to design GNNs with stronger resilience to abnormal node features. Empirical examination is firstly conducted by replacing the features of randomly selected nodes with random Gaussian noise. The comparison between models with and without the residual connections show the helpfulness of residual connections on learning with abnormal features. ",
    " This paper observed interesting phenomenons: feature aggregation helps smooth out abnormal features but would lead to over-smoothing for normal features, residual link helps adjust feature smoothness for normal features but may hurt the performance when we have abnormal features. Therefore, it points out that we need to tradeoff between normal and abnormal features while designing GNNs. Then, based on the observation, this work proposed the AMP method and the AirGNN model, which are shown by experiments to be effective under various abnormal feature scenarios.  ",
    "This paper examines the behavior of GNNs when node features are perturbed during test time.  AirGNN is proposed based on the observations from the standard GNNs. AirGNN adaptively computes the weight of the initial embedding and aggregated embeddings and is robust to random/adversarial noise keeping the standard classification performance.",
    "This work develops an analog to Thompson sampling by upper-bounding the expected regret in sequential decision-making problems. The two terms in the upper bound loosely resemble the evidence lower bound of variational inference: the first term encourages selecting arms with high expected reward; the second term depends on the inverse of the rate function and penalizes heavy tails and encourages exploration. The resulting variational Thompson sampling algorithm is evaluated on a random game and a constrained bandit problem.",
    "This paper introduces Variational Thompson Sampling, where rather than sampling from the posterior, which can be infeasible, a computationally tractable upper bound is optimized.  In the stochastic multi-armed bandit setting with subgaussian noise, they provide a general analysis for any algorithm that plays a \"stochastically optimistic\" policy, which includes vanilla TS and the new method.  The VTS algorithm is shown to have sublinear regret for the more challenging bilinear saddle point problems where it can be shown that TS fails.",
    "This paper proposes a novel class of policies for online learning, named variational Thompson sampling (VTS). VTS is derived from a family of stochastically optimistic policies, which includes standard TS as a special case. VTS is amenable to some interesting interpretations when compared with difference existing policies such as UCB and K-learning, and is shown to outperform TS consistently in two classes of problems, i.e., zero-sum two player games and constrained bandits.",
    "This paper presents and establishes regret bounds for a new heuristic, inspired by Thompson sampling, for selecting actions in stochastic multi-arm bandit and bilinear saddle-point problems. As in Thompson sampling, a belief state is maintained over the values of each arm. However, instead of selecting an action according to its probability of optimality, one instead computes a policy (distribution over actions) that maximizes a novel objective. The objective can be understood as combining a \"pure exploitation\" term (the expected reward of the policy, under the current belief distribution), and an \"exploration\" term that depends only on the relative concentrations (and not the expected values) of the posteriors for each arm.",
    "In this paper, the authors study a stochastic variance reduced method under sampling rules that are without replacement for smooth and non-smooth, convex and strongly convex objectives. More precisely : - they develop a proximal method call Prox-DFinito for which they study convergence rates for random reshuffling, cyclic and shuffling once samplings - in the cyclic sampling, they derive an optimal fixed ordering (and a practical adaptive variant which do not require the knowledge of $z^*$ - Finally, the authors highlight the fact that, when assuming data heterogeneity, their study lead to a convergence rate independent of the number of data samples. This was up until now just known for iid sampling.       ",
    "The paper proposes a new method called Prox-DFinito based on the proximal Finito with without-replacement sampling. The authors derive complexity bounds for the proposed method in convex (for making the squared norm of the gradient small) and strongly convex cases (for making the squared distance to the solution small) that match under some additional assumptions the rate of Gradient Descent. Moreover, under additional assumptions on the objective function, the authors show sample-size independent bound in the convex case. The proofs are non-standard but clean and easy to follow. However, the paper has several strong weaknesses.",
    "This paper develops a proximal damped version of the Finito algorithm. The algorithm is proved to achieve the same convergence rate as proximal GD, for cyclic sampling, random reshuffling and shuffling-once versions of the algorithm. Further, the authors claim that this is the first* shuffling based variance reduction algorithm to achieve the convergence rate. The paper also gives a new norm that captures the optimality of sampling orders and provides a heuristic based on that for importance based reshuffling.  Besides the theoretical results, the empirical results seem to suggest that the proposed algorithm is indeed faster than other variance reduction algorithms.   *: The authors cite a concurrent work (Malinovsky et al.) that also achieves the same convergence rates for general convex functions, but the algorithms in the two papers are different.",
    "This paper proposes a new first-order algorithm using without-replacement strategy to solve a class of composite convex minimization problems. The main idea is to modify the well-known scheme, called Finito/MISO method by applying a without-replacement strategy and a damping step. Under the convexity and L-smoothness of f, the proposed algorithm achieves O(1/k) rate in epoch on the optimality residual. When f is additionally strongly convex, the rate is improved to linear as in standard proximal gradient methods. The analysis relies on a weight norm defined through the order of the underlying shuffling strategy. The authors also compare their method with other schemes such as a coordinate descent method with cyclic rule, and standard GD. Next, the authors also investigate the optimal cyclic rule for sampling and propose an adaptive variant. Numerical examples on standard logistic regression problem are presented to illustrate the performance of the proposed methods.  ",
    "The paper studies the performance of the classic Relative Entropy Policy Search (REPS) algorithm of Peters et al. (2010) in the context of tabular reinforcement learning, focusing on the effect of optimization errors on the quality of the policy extracted from the solution. REPS is based on formulating the policy optimization problem as a regularized linear optimization problem which is equivalent to an unconstrained convex optimization problem, and calculating policy updates via approximately minimizing the dual function. The current paper sets out to understand the optimization issues surrounding solving these problems, and provides the following contributions:  - Showing that the policy suboptimality can be controlled in terms of the gradient norm associated with the approximate solution and some problem-dependent constants. - Showing that the dual REPS objective is smooth, which implies that bounds on the additive optimization errors can be translated to bounds on the gradient norm at the approximate solution. - Providing concrete performance bounds for an accelerated gradient descent method when the gradients of the objective can be evaluated exactly. This setting is rather unrealistic, but the results are insightful in that they shed light on the best attainable performance to be expected from this approach.  - Providing concrete performance bounds for a stochastic gradient descent method that uses a generative model to obtain estimates of the gradients. The challenge here is that one cannot straightforwardly obtain unbiased gradient estimates, and one has to take several sample transitions to make sure that the bias in the updates is small enough. The authors address this challenge thoroughly and obtain guarantees that are polynomial in the desired accuracy level.",
    "The paper studies the convergence of the relative entropy policy search (REPS) method for solving LP-formulated MDP problems. The authors first assume the exact computation of gradients and prove the sublinear convergence of REPS regarding the regularized primal objective function and the policy. Second, the authors propose to estimate gradients using samples and prove the convergence or sample-complexity of sample-based REPS.  The main contribution is a convergence theory of REPS in both exact and stochastic settings. ",
    "In this paper the authors the sample complexity of the relative entropy policy search (REPS). This algorithm aims at finding the optimal policy in an MDP using linear programming formulation. First the authors consider the planning setting where they assume access to the exact model of the environment. For this result they show that near stationary policies result in a near optimal policy. Next they provide the convergence when the updates are being performed by biased stochastic gradients. ",
    "This paper goes back to a well known algorithm, Relative Entropy Policy Search (REPS) and provides convergence guarantees for REPS by exploiting its relationship of RL via duality. Recently, there has been a surge of work exploiting the dual formulation of RL objectives, and this paper exploits that relation to performance convergence analysis of the REPS algorithm. Besides, very recently, a number of works has provided convergence of policy search and policy gradient algorithms - and the contributions of this work can be seen in light of recent works. The major contributoon of this work is to provide convergence guarantees for the dual objective of REPS, relying solely on on-policy samples and using accelerated gradient ascent on the dual formulation (whereas prior works exploiting duality often need to rely on off-policy samples, estimating distribution ratios). \u000b\u000b ",
    "This paper measures the sensitivity of various point cloud classification networks (like PointNet, PointNet++, DGCNN) to rotation, translation, scale, and local 3D structure. It also proposes ways to measure the 3D smoothness of a network. Based on these analyses, the work provides various insights. One of the main insights being that the DNNs don\u2019t handle rotation very well. Another insight is that training with adversarial perturbations helps.",
    "At a higher level, this paper is proposing several ways to measure the sensitivity and smoothness of representations learnt by 3D point cloud networks. This paper presents several ways to measure the sensitivity of point cloud networks to rotation, scale, translation and local structure. The Paper also proposes different metrics to evaluate the smoothness of encoded local 3d structures and the complexity of representations learnt by the network. The analysis is done using several point-based neural networks trained on the ModelNet40 classification task and shapenet part segmentation task.",
    "This paper introduces metrics that reflect the representation quality, and properties, acquired by a deep-net that is applied in 3D Point-Cloud (PC) processing tasks. Concretely, the authors introduce six novel metrics that in aggregate capture different types of regional sensitivities e.g., the sensitivity of the DNN in rotations on specific regions/rotation-angles of the input PC. They further explore the extent that modern architectures in standard benchmarks acquire \u201cspatial smoothness\u201d --  do nearby points have \u2018similar\u2019 effects/importance for the end task? And finally, they explore the acquired representation complexity of the DNN by adapting a 'multi-order interaction' metric to PC data.    These metrics are being applied on a well-selected subset of modern PC-DNN architectures such PointNet++ or DGCNN when these are trained either for PC-object classification, or part-based object-segmentation. The analysis of the metrics in these tasks/architectures highlights a number of interesting points that oftentimes are very simple/intuitive: e.g., PointNet fails to encode local 3D structures (e.g., compared to PointNet++) \u2014 or includes results that are more subtle, but still highly intuitive & rich: e.g., adversarially training a PC-DNN with rotation/translation attacks; will force it to learn more global PC structures compared to standard training; which is intuitive as the local structures, per the new metrics, are those that on average are more susceptible to rotations.",
    "This paper studies how to understand the quality of knowledge representations encoded in point cloud DNNs. Based upon the Shapley value, the paper presents six metrics to evaluate the model vulnerability toward different types of input variations. In addition, it presents an analysis regarding the smoothness and multi-order interactions of these attributions, pointing out the restrictions of current point DNNs. The paper makes interesting observations and draws useful conclusions, supported by a range of experimental evaluations.",
    "This paper studies of designing revenue optimizing auctions subject to the an additional constraint on fairness. Instead of algebraically capturing the fairness of an allocation, the authors train a neural network termed PreferenceNet that assign a fairness score to any allocation. The neural network for strategy-proof, revenue maximizing auction (RegretNet) is trained to trade-off revenue and regret with the preference loss.  The author evaluate this on small instances (2-4 bidders and 2-4 items) and contrast revenue, regret and fairness of simple RegretNet with one constrained to produce fair allocations.   One primary motivation for a deep neural network based PreferenceNet is that it can capture real world preferences from humans. To explore this aspect, the authors conducted real world studies to get user preference samples and trained a PreferenceNet on that. They also correlate preference learned from humans with mathematical models of preference. ",
    "This paper covers a somewhat interesting and novel problem: learning constraints of an auction setting, and then learning to run an auction that respects those. Fairness in allocations is cited as a justification for this in practice, where it may be beneficial to learn from a human\u2019s choices to determine how to decide who should win in the auction, for example to determine similar allocations across demographics.  The approach builds on the RegretNet line of work that learns to run revenue maximizing auctions. The approach broadly is to learn a feasibility constraint that is scored by human subjects, and then use that in the RegretNet architecture to learn to generate auctions that respect that constraint. In this work, the motivating constraint is a binary classification of fairness. The implementation is a composition of learning then constraint, followed by leveraging RegretNet to learn according to that function.   To support the approach, the authors first compare PreferenceNet to RegretNet trained with the exact constraints, and see similar performance suggesting some amount of usefulness. The authors then train PreferenceNet on responses from human subjects in two surveys regarding the binary qualitative fairness of allocations.  ",
    "This paper proposes PreferenceNet, which is a new deep learning approach for designing revenue-maximizing auctions that encodes human preferences. PreferenceNet extends RegretNet [Duetting et al. 2019] with modified loss functions and additional constraints. ",
    "This paper describes how we can encode socially desirable constraints in auction mechanisms learned using the regretNet framework.   The paper has two main contributions:   (1) A metric that quantifies how well these mechanisms adhere to these constraints.   (2) An neural network and a training procedure (called the preferenceNet) that can encode these constraints using exemplars of the desired allocation  The authors demonstrate the efficacy of the proposed approach by showing that it can match the performance of standard approaches on both synthetic preferences as well as human preferences",
    " The paper presents an algorithm for differentially private (DP) learning of personalized models. A set of users with their own private data collaborate to privately learn a good embedding of the data followed by a linear regression based on this embedding.   The paper contribution is a theoretical analysis of the proposed algorithm with DP guarantees and utility bounds.   As far as I know there is no such bounds in the literature within the same setting. The author compare their result with the bounds in the non private case and with an upper bound obtained using the exponential mechanism which provides an information theoretic bound but cannot be efficiently implemented. In the later case, the bounds on the excess risk differs by O(1/\\epsilon) and O(1/\\sqrt(m)), m being the number of samples and \\epsilon the privacy budget.  ",
    "This paper focuses on a setting, where there are multiple users each holds a training dataset. In this setting, users have to share information about their model or data to learn a meaningful representation and to solve their tasks better than they could without using the shared, low-dimensional representation. The paper proposes an approach for this problem that provides strong user-level differential privacy guarantees at the same time. For the privacy guaranteees, the method uses exponential mechanism and utility analysis of the algorithm is made by using that.",
    "The authors deal with personalized model learning under the user-level joint differential privacy. In this problem, each user aims to build a user-specified model to make a prediction for the user's data. In the training process, the users utilize knowledge from the other users' data to improve their model's performance. In this setup, we want to prevent the leakage of the sensitive information in the user's data to the other user. The authors develop the differentially private algorithms for the model personalization task and reveal the upper bounds on the personalized model's accuracy of these algorithms. ",
    "This paper studies the problem of model personalization with user-level differential privacy in the setting where users don't have enough data to find a good solution on their own but can leverage information in similar learning problems shared by other users. The problem is viewed as learning a 2-layer neural network, where the first embedding is the shared structure and the second layer is trained individually. This paper provides two types of algorithms: inefficient algorithms based on the exponential mechanism that establish information-theoretic upper bounds on an achievable error and efficient algorithms based on alternating minimization, which starts from an initial embedding and then repeatedly uses a DP minimizer to minimize the error. For the specific case of linear regression with squared error loss, the paper shows the alternating minimization framework can converge to a near-optimal embedding. ",
    "This paper collects a new validation dataset via crowdsourcing to benchmark the progress of state-of-the-art VQA models.  The dataset (containing 22K questions and 10x answers) is adversarially collected such that annotators have to come up with questions that can successfully fool a state-of-the-art VQA model, and such questions are undoubtedly more challenging to various existing models. The authors perform thorough data analysis as well as extensive experiments with a variety existing models, to validate the usefulness of the new dataset. This new dataset can potentially be a valuable benchmark to track the progress of VQA research, if there is no obvious bias in the dataset (potential dataset bias is not thoroughly discussed in this paper).  ========================================================================================  Thanks for the response from the authors. I've updated my rating after reading the rebuttal as well as the comments from other reviewers.  ",
    "This paper works on the topic of visual question answering and aims to test how well state-of-the-art models perform on adversarial examples. Specifically, the authors collect a new adversarial benchmark on VQA, named \"Adversarial VQA\" (AdVQA), including a large evaluation dataset of 28,522 examples in total. The data samples in AdVQA are collected by putting both human annotators and state-of-the-art models in the collection loop: Annotators are requested to create questions that can fool the state-of-the-art models, and these questions are further verified by other annotators. The authors benchmark state-of-the-art models on these collected adversarial questions and their performance drops significantly.  The main contribution of this paper is the collected AdVQA dataset which includes adversarial examples created by human. The experimental results suggest future research directions on VQA.",
    "Update after rebuttal: Thanks to the authors for their rebuttal in response to my questions/concerns. After reading the rebuttal and the other reviews, I am updating my score to 6, to better reflect the contributions made by the work. _______________________________________________________________________________________________________________ The paper introduces an adversarial VQA dataset collected with human-and-model in the loop by directly asking humans to write questions to attack the winning model of VQA challenge. Extensive evaluation of existing models on this adversarial VQA dataset suggest that current VQA systems are far from really solving the VQA problem. Many well-performed models on VQA v2 seem to fail on AdVQA. AdVQA potentially can be used to benchmark the advances of VQA models in the future, considering VQA v2 performance is close to human parity.",
    "This paper proposes AdVQA, a new (adversarial) test set for the Visual Question Answering.  Annotators and a SOTA model are put in the loop to make sure the model can be fooled. Experiments show that other VQA models tend to perform poorly on AdVQA, and a comprehensive analysis discusses the questions and answers that are in this dataset (compared with VQA and TextVQA).",
    "The authors employ RNN models under different conditions to model MEC cells with both well-understood (e.g., place cells) and poorly-understood (heterogeneous cells) tuning properties. By training the network to minimize the place cell-mediated path integration, the network performed incredibly well in explaining MEC-cell dynamics. By removing neurons in the model, the network's path-integration performance was found to be at least as dependent on the model's heterogeneous neurons as on the stereotypical ones. The authors then finish by introducing a reward-based foraging model, again finding responses that match experimental results very well.",
    "The authors address two important questions regarding the non-grid cells in MEC. First, is their response consistent, and not just noise? Second, can they be used as criteria for testing models of MEC functionality? The second question allows to probe the functional significance of these cells, and the effect of incorporating them on various model properties. The authors\u2019 main tool is a linear mapping from a population of cells into a single target cell. This is done using rate maps of cells, and cross validation on the spatial bins. Several existing models are compared, with one model singled out as corresponding best to experimental data. The functional relevance of grid and non-grid cells is evaluated using ablation studies on the model, where path integration ability is used as a measure. Generalization of the models is assessed using either different arenas or a reward-biased setting.  ",
    "The authors used linear regression to first demonstrate the robustness of non-grid-like responsive cells in experimental recordings of MEC cells. They then used the same regression to assess the similarity of responses derived from the goal driven training of RNNs to MEC responses. They found that responses derived from RNNS contained these non-grid-like responses and explained neural activity better than a low-rank decomposition of place fields.  These non-grid-like responses were crucial for path integration and likely explained the difference in similarity matching between goal-driven training and low rank decomposition.",
    "By adopting 'similarity transform' methods, this study compares the predictability of different computational models of MEC neurons. The best model not only can explain the firing patterns of grid cells but also that of heterogeneous cells. These findings further allow them to examine the role of heterogeneous cells which has not been clearly identified with experimental approaches. This study suggests that the heterogeneous cells might play critical roles in path integration even more than what grid cells contribute. This manuscript is well-written, and the results provide a theoretical foundation for future studies using a more experimental approach. I only have minor clarification questions and suggestions to embrace a broader readership such as neuroscientists. ",
    "This paper studies the problem of KL-regularized reinforcement learning for locomotion tasks, where the KL regularization penalizes deviations from expert demonstrations.  This work makes the observation that fitting expert demonstrations to a certain class of conditional neural density models (e.g. neural networks that output the parameters of a Gaussian distribution), results in policies whose variance collapses for states that are different enough from the expert data.   The paper argues that this collapse causes instabilities in learning KL-regularized policies: for Gaussian policies, the KL penalty grows quadratically to infinity as the expert policy variance goes to 0. To address this issue, the paper proposes to instead compute the KL penalty by fitting expert demonstrations to models that do not suffer from this collapse, in particular Gaussian Process regression models. Gaussian Process models result in variance that increases (depending on the choice of kernel) for states that are far enough from the expert data.  The paper provides some analysis on why the variance collapse affects the RL optimization process, experiments that  aim to show an empirical relationship between expert policy variance, KL penalty and magnitude of the policy gradients, and a comparison between various methods that use KL regularization with an expert policy. ",
    "The authors identify a problem with KL-based reinforcement learning from expert demonstrations. Poor out-of-sample variance predictions of NN expert policies ends up unreasonably penalizing RL exploration outside the expert data distribution, potentially causing numerical instability. To remedy this they propose to instead use non-parametric expert policies based on a scalable GP approach. ",
    "This paper presents a previously unrecognized pathology in KL-regularized RL with expert demonstrations. Specifically the commonly used parametric behavioral policies suffer from collapse of predictive variance at states far from the demonstrations. This collapse of variance hinders the algorithm\u2019s ability to learn effectively. The authors then propose to use non-parametric behavioral policies and demonstrate its effectiveness in several control tasks. ",
    "The authors identify a potential failure in KL-regularized reinforcement learning in which small predictive variance of the target policy may lead to exploding gradients, possibly destabilizing gradient-based learning algorithms. The authors discuss an uncertainty collapse of parametric models under Maximum Likelihood estimation in OOD regions of the expert, resulting in the aforementioned pathology. Finally, they suggest to use non-parametric models of the behavior policy (in which uncertainty collapse is not present), showing improved performance on several continuous control benchmarks.",
    "In this paper, the authors study the generalization error of kernel regression in a teacher-student scenario where the kernels are obtained as NTK of either one-hidden layer locally-connected NNs or convolutional NNs. They consider the teacher as a Gaussian random field of covariance the same kernel as the student kernel but with different parameters, and proceed to characterize the learning curve exponents. Based on a decomposition of the two kernels in orthonormal basis functions, they use recent (non-rigorous) statistical physics predictions to deduce an exponent that can be shown rigorously to be an upper bound in some cases. This exponent does not depend on the ambient dimension d, only on the patch size, and is the same for the two kernels. The authors deduce that locality is the important property that breaks the curse of dimensionality and notice that adding the invariance by translation only lower the prefactor.  Finally, using a Gaussian universality assumption and a recent framework, they prove a lower bound on the learning curve exponent.  They further check their predictions in numerical experiments on synthetic data.",
    "# Post Rebuttal:  I partly accept the claims of the authors in the rebuttal and have decided to raise my score a little bit to reflect that. I still believe the paper would benefit greatly from clarifications. In particular, I advise the authors to incorporate the changes mentioned in their response to Remarks 1-2 in the rebuttal, as these strengthen the paper in my opinion. As for Remarks 3-4, I disagree with the authors' claim; my point that convolutional neural networks do not provide any benefit over other simpler hypothesis classes in the regime of lazy training still stands and I strongly encourage the authors to omit any reference to neural networks as motivation for studying the problem. I find this reference to be too artificial and somewhat forced.  Lastly, I would like to wish the authors the best of luck in the future.    # Original Review:  The paper studies the expected generalization error when learning in a teacher-student setting where the teacher is a Gaussian random field and the student is a kernel exhibiting a certain convolutional structure. It is shown that under strong assumptions the expected generalization error decays at a rate which does not depend on the input dimension but rather on the filter size of the student. Additionally, experiments are performed to corroborate the theoretical findings in the paper.",
    "This paper studies the two elements of CNNS, 1. local patch; 2. translation-invariant. Under a teacher-student framework for kernel regression, the authors conclude that (under reasonable assumptions), it is the locality of CNNs that defeats the curse of dimensionality. The exponent $\\beta$ in the learning curve (with respect to the sample size) is studied theoretically and empirically verified.",
    "The authors proved that the generalization error for a CNN can be made independent of the data dimension under certain assumptions. They study the problem in a teacher-student framework and the test error proportional to $P^{-\\beta}$ with P to be the training set and $\\beta$ to be only dependent on the local kernel size of student network. The authors empirically validate this finding. Furthermore they showed that similar learning curve exponent achieved in the ridgeless case can be achieved in kernel ridge regression with decreasing ridge coefficient.",
    "This paper proposes to learn GMM priors in autoencoders, to be able to construct a generative model. They compare the generation quality of the proposed approach with VAEs using the FID metric. One interesting contribution seems to be the fact that they are using a loss function other than the GMM likelihood to fit the GMM. ",
    "The paper proposes a deterministic autoencoder that imposes a GMM on the latent space to learn a complex multimodal latent space. The model uses two regularizers including the KS distance and a constant covariance term to minimize the discrepancy between the marginal CDF of the empirical posterior and the given GMM prior. The authors provide multiple experimental results to show the reconstruction and sampling quality, deep clustering, and the latent model capability to generate discrete and complex structures such as chemical molecules.",
    "The author(s) motivate and derive a novel deterministic auto-encoder loss that naturally encourages a multi-model latent representation that follows a GMM. The author(s) motivate and derive this loss using the KS test metric and generalize it to multiple dimensions and multiple modes. Their experiments, whereby they ancestrally resample latent codes show an impressive ability to generate realistic samples.",
    "The paper builds on the ideas of Ghosh et al 2020 [10] pointing out the equivalence between Gaussian prior VAEs and deterministic AEs with noise inputation and further equivalence with regularized deterministic AEs. Since the original paper [10] needed to estimate the latent distribution ex post with a GMM, the authors here propose to use GMM prior directly and translate this into a deterministic AE with more complex regularization derived from univariate Kolmogorov-Smirnof distance combined with another term for covariance matching.They further propose a heuristic to find a reasonable heyper-parameter setting for the two regularizers. Finally, they show on a battery of experiments (generations over standard image datasets, unsupervised clustering, generating discrete structures) the favourable properties of their method.",
    "This paper presents a method to detect adversarial examples by disentangling the representation. This is done by training autoencoders over both correct and incorrect class/semantic features. The authors claim that the proposed method outperformed other SOTA methods for adversarial detection and even works against adaptive adversarial attacks. ",
    "The paper propose a new defense mechanism against adversarial attacks based on an autoencoder architecture. The proposed architecture uses self-supervised learning to disentangle the semantic and class features, which enables the autoencoder to discriminate the clean and adversarial examples at test time. The approach was shown to outperforms other autoencoder approach in the experiments, when the attacker as access to only the victim model or both the victim model and autoencoder.",
    "The paper proposes a novel adversarial example detection strategy based on disentangled latent representations. The main idea is that latents are separated into class features and semantic features. Detection then uses the fact that adversarial samples preserve semantics while at the same time changing class according to some victim model. Training is being performed through a sophisticated combination of losses accounting for begin examples and counterexamples. Experimental results on detecting various kinds of attacks on popular datasets show clear improvements over previous methods. The paper also presents an evaluation of an adaptive attack.",
    "This paper proposes to detect adversary using learned disentangled auto-encoder. The model can disentangle the class feature and the semantic feature. Class features are easily changed by adversary, while the semantic features cannot. Existing Auto-Encoder cannot disentangle those two types of features, and also has strong generalization ability---high performance on both the adversary and the benign examples, making it hard to detect. Using the proposed disentangled AE, benign example can be reconstructed faithfully while adversary examples cannot. Thanks to the tailored AE, the paper state-of-the-art adversarial detection performance on MNIST, Fashion-MNIST, and CIFAR-10 in most cases.",
    "* The authors conduct a brain encoding study testing whether fine-grained information about the content of incremental syntactic representations contribute to predictions of neural activity, over and above measures of syntactic complexity. * They design custom subgraph embedding representations to operationalize the idea of \"syntactic representation.\" They find that these subgraph embeddings capture additional variance in brain activity above what is predicted by complexity metrics, and that this improvement in prediction is distributed throughout the language system.",
    "The paper proposes a new set of syntactic tree embeddings, and uses them capture additional variance in fMRI data beyond simpler complexity metrics. I think the paper setup is compelling overall, it is well-situated relative to prior work, and the results are intriguing. My primary concern is that the paper doesn't conclusively establish that these new embeddings are purely syntactic and disentangled from either complexity metrics or (more ambitiously) anything that BERT can capture, and this damages the downstream claims about neural correlates of syntactic representations.   I hope this can be addressed and solved in rebuttal/revision, since I find the paper good otherwise and hope to see it at the conference.   EDITED: I think the authors have reasonably addressed my concerns, and am raising my rating accordingly. ",
    "The manuscript entitled \u201cCan fMRI reveal the representation of syntactic structure in the brain\u201d proposed a word embedding scheme with the consideration for incomplete sentence (used to test how future sentence structure is represented in the brain) and partial parses (used to represent the multiple top-down paths of the brain in interpreting language syntaxes). Words embedded by the proposed schemes are then mapped to the corresponding fMRI signals (ensured by the experiment design where each word is strictly 0.5 second) through ridge regression. Voxels in the brain that are significantly correlated to certain combination of the syntax structures are studied in the results.",
    "In this paper, the authors propose new representational spaces that capture syntactical information in natural language above and beyond complexity-based metrics that have been typically used in language neuroscience. First, they build representations based on the constituency tree of a sentence as every word is processed by the parser. Then, they use a subgraph embedding algorithm to convert the subtree into a 15-D representation. To test several hypothesis about the type of syntactic information being encoded, the authors look at 3 different types of subtrees- the largest subtree completed when the current word is processes, the incomplete subtrees that can explain the sequence seen thus far under PSG production rules and the set of complete parses produced by a probabilistic model that are weighted by their probabilities. The 3 subspaces are compared against 4 complexity/load-based metrics and additionally, a semantic feature space derived from BERT. They go on to build encoding models for the different feature spaces and compare them through variance partitioning. Overall, the paper finds that the 3 graph-based spaces explain additional variance across the cortex as compared to traditional complexity-based features. Further, this effect is not localized to any region. Instead, it seems to be distributed across a network that is largely explained by semantic features, suggesting that syntax and semantic share neural substrates and there exists no isolated region for syntactic processing.  The study uses publicly released fMRI data from 9 subjects reading a chapter from Harry Potter .",
    "The paper considers the task of obtaining additional control over a pre-trained generative model without re-training it. Specifically, it aims to generate conditional samples from an unconditional StyleGAN by only training a classifier with respect to the conditioning information. To achieve this, it considers the conditional distribution of StyleGAN latent codes. By Bayes Theorem, this conditional distribution is proportional to the unconditional distribution of the latent codes (which has a known standard normal distribution) times the distribution of conditioning information given the corresponding sample. The latter is modeled as a Gibbs distribution with an energy derived from the classifier. Two approaches to sample from this unnormalized distribution are evaluated: (i) Langevin sampling and (ii) Performing gradient descent on the classifier-derived energy. Experiments demonstrate good performance of this approach with significant improvements over StyleFlow for combinations of conditionings which are not in the training data.",
    "This paper studies conditional learning by training an EBM in the latent space of a pre-trained top-down generator such as StyleGANs. The EBM is a joint distribution of data and attributes together, and sampling from it is formulated as solving an ordinary differential equation. Experimental results show that the method outperforms the state-of-the-art in both conditional sampling and sequential editing. The contribution of the paper lies on obtaining state-of-the-art performance of conditional learning by combining existing technologies, such as StyleGAN, latent space energy-based learning, and score-based generative model via stochastic differential equations. ",
    "Using labelled real data, an EBM is trained in the latent space of a pretrained GAN, rather than directly in pixel space. An ODE solver is used to sample from the EBM rather than Langevin Dynamics, which is shown to be more robust to hyperparameter settings. Using properties of the EBM, conditional generation compositional editing can be demonstrated, including in zero-shot scenarios.",
    "The paper proposes an effective and efficient approach to conditional image generation using GANs. Two main advances are described 1) The use of EBM in latent space that don\u2019t require the retraining of image generators. This allows for very efficient training since the generator can be held fixed. 2) The use of an ODE solver for sampling that is less sensitive to hyperparameters than traditional LD solvers.  Results are shown on CIFAR-10 and FFHQ datasets. This includes results on sequential generation, compositional generation and zero-shot generation. ",
    "The paper studies a federated setup where each client faces a stochastic contextual bandit.  The parameters of the bandits are coupled across the clientsm. The clients share their local estimates with the server which aggregate them and share back with the clients. The client are hetogenous and the server leverages the geomereic structure of the linear rewars to facilitates the clients learn the optimal arms.  Authors propose a collaborative algorithm called Fed-PE that do not require the nodes to exchange the local feature vectors thus preserving the privacy of the nodes. The authors consider the cases where the paramers are disjoint across the arms or coupled. The performance of the algorithms are valued on both synthetic and real datasets. ",
    "This paper considers a linear contextual bandits problem in a federated setting where different users have different contexts but the rewards are generated through common global parameters. The goal is to minimise the regret for each user while sharing the exploration across users. The paper proposes an algorithm termed Fed-PE with regret bounded as O(\\sqrt{dMT}), where d is the dimension of contexts, M is the number of users and T is the time-horizon. A matching lower bound is also presented showing that this regret is tight. The main challenge in this setting is to \\emph{balance} the exploration across users as contexts might be very diverse. In order to address this challenge the paper proposes a new G-optimal design which optimises for balanced exploration across users. ",
    "This paper discusses the federated multi-armed bandit problem with linear reward functions. The formulation utilizes a linear structure with agent-dependent contexts to model differences between agent reward functions. The authors propose an algorithm based on a multi-agent G-optimal design with competitive theoretical performance under heterogeneity. The authors additionally establish minimax rates under a reasonable collinearity assumption. The algorithms FedPE and Enhanced FedPE additionally provide competitive experimental performance on both simulated and real-world benchmarks. In summary, the paper is a good contribution, however, there are some issues that I would like to see addressed as well.",
    "I think the paper sufficiently characterizes the federated linear contextual bandits problem (i) it proposes an algorithm for both the shared parameter and disjoint parameter setting (ii) proves regret guarantees and (iii) characterizes a reasonable class of policies for which a lower bound holds; this lower bound shows that the achieved regret guarantees are near optimal. The communication cost of the algorithm is also reasonable w.r.t to prior work. I think the writing of the paper can be improved in some areas and some technical points need to be explained more, but over all I think this is a good paper. ",
    "The paper presents a new approach for model-based offline RL. Here, the model is not used to estimate the return directly using roll-outs, but to generate synthetic data that is then used to train the Q-function. In a way, the method is a combination of CQL and MOPO. What is new is the idea of using this synthetic data to, penalize extrapolation instead of using uncertainty estimation. This modification performs much better on the selected benchmarks. As benchmarks a selection of D4RL benchmarks is used (3 benchmarks) and two vision based benchmarks. ",
    "This paper proposed a new model-based offline RL algorithm, COMBO. The algorithm applies model-based learning to be able to generate random rollouts, and the generated data is combined with the given fixed dataset for value function training. The paper shows by using the generated rollouts as data for Conservative Q-learning provides better constraint and better empirical performance compared to the orignal CQL algorithm. ",
    "This paper introduces a Conservative Offline Model-Based policy Optimization RL algorithm, called COMBO, that learns a pessimistic model by enabling a lower bound optimization on the policy performance without requiring uncertainty quantification. COMBO employs an actor-critic method to learn the value function on both offline and synthetic datasets. The idea is to penalize Q-values learned from state-action pairs that are out-of-support of the offline dataset.  ",
    "This work investigates model-based reinforcement learning with offline dataset. In particular, most of the work on mbrl with offline datasets requires uncertainty estimation to determine the out-of-distribution states and actions. This work eliminates the need to have uncertainty estimation by using the existing Conservative Q-Learning(CQL) algorithm for states and actions from the dataset as well as the rollouts generated from the dynamics using the policy being learned. They show that inclusion of new dataset from the generated rollouts and by being pessimistic about their values, they tend to be better than existing Model-based offline Reinforcement Learning which requires uncertainty estimation",
    "This paper proposed a stochastic differential equation model based on the local elasticity assumption of features of neural networks.  The local elasticity phenomenon says samples have greater influence to other samples in the same class than those in different classes. Starting from this assumption, a system of linear SDEs is proposed for features corresponding to each data point, with the coefficients encoding the difference of inter and intra classes impact. Two types of features are studied---the isotropic feature learning model, and the logics-as-features model. For the two models, dynamics of the class means are derived as a system of ODEs and the solutions are found, depending on the coefficients about local elasticity. From the solutions, the separability of classes is theoretically connected with local elasticity. Specifically, the classes are separable if the local elasticity effect is nonzero, while not separable otherwise. The transition between the two cases is sharp.   Numerical experiments are conducted to justify the effectiveness of the proposed model to characterize the actual dynamics of features. Experiments are done on deep convolutional networks on the GeoMNIST and CIFAR10 dataset. Firstly, the coefficients in the SDEs (and the ODEs for the class means) are estimated using real feature dynamics given by the training process (I understand this step as a kind of \"fitting\"). Then, the ODEs with estimated coefficients are simulated, and the results are compared with the real feature dynamics. It shows that in many cases (but not all) the trajectories produced by the SDEs recover the real trajectories given by the training. ",
    "The paper proposes a proxy tractable dynamics to study how the latent features of neural networks evolve inter- and intra-class during training. The core of this dynamics is a linear ODE, which is shown to exhibit inter-class separability once a \u201clocally elastic\u201d condition is met. The paper then examines this dynamics for two choices of the H matrix (which is a parameter of the dynamics), and concludes with experiments to demonstrate the relevance of the proposed theory with the actual simulation.   ===================== After rebuttal: Thanks for the detailed reply!  Overall while I am pleased that the authors made a lot of efforts to clarify, I'm not quite convinced. Some notes: - I agree that time-dependence of E(t) is a good point; my concern about linearization (which I believe is also the concern of some other reviewers) is actually about why at each time t, F(X(t),t), in the authors' response, is modeled by a linear relationship with X(t). Why ignoring higher-order terms? Are they much smaller than the linear term? I do not see why the higher-order terms can be absorbed into the noise term. - I do not agree with the argument that $c_1\\neq c_2$ assumption can be alleviated by taking the results \"in probability\". Clearly the derivation in the paper requires taking a law-of-large-numbers average.  I agree (and well understood) that the paper does not aim to mimic exactly the dynamics; the aim is to provide a reasonable proxy dynamics that can explain interesting properties. However I feel the paper needs a careful justification to convince readers that this proxy is not oversimplifying.  Given that the paper may attract interests, I'm willing to raise the score, but not fully convinced of the quality to recommend acceptance. If a reviewer is willing to champion the paper, accepting the paper would not be a bad outcome to me.",
    "This paper builds off a recently proposed phenomenon of deep learning models, local elasticity, which, says the that impact in feature space of a gradient update from an input is in general larger for feature of data in the same class as the input rather than a different class. In this work the authors propose a set of SDE's modeling SGD that captures the inter and intra class effect of back propagation. They find that there is a sharp phase transition in the dynamics governed by these SDEs when they do or don't display local elasticity. In particular, when the SDEs are locally elastic then the features of the training data are guaranteed to become linearity separable, while this is not the case otherwise. They demonstrate this theoretical analysis empirically with CIFAR-10 and connect there results to another recently proposed phenomenon, neural collapse. ",
    "The paper provides a simple phenomenological model of neural networks for K-class classification. Each sample is assigned a feature modeling NN features, and these features are evolved via SDEs in which the drift term of a sample is a linear transformation of the average features of each class. Separation, which means the case in which samples from different classes can be separated by hyperplanes, holds w.h.p. when the intra-class drift coefficients larger than the inter-class coefficients in a certain sense, and it does not hold otherwise. Two specific choices of features are considered: isotropic features and logit features. The latter are shown to be better than the former at modeling the feature evolution for NN on CIFAR and a dataset of their own creation. ",
    "The paper approaches reinforcement learning from a program synthesis perspective and proposes a new method - LEAPS - that is capable of learning programmatic policies just from weak reward signals. This is achieved in two steps: i) learning a smooth latent manifold where similar programs are encoded close to each other; ii) searching the latent space efficiently via the Cross Entropy Method. LEAPS is applied to several tasks in the Karel domain where it successfully can learn programmatic policies that are even transferable to larger state spaces for zero-shot learning.",
    "This paper suggests representing policies for MDPs as programs, and shows how to learn programmatic policies effectively from a mix of trial-and-error experience on specific tasks and a pre-training phase to create an embedding that maps programs producing similar behaviors into similar points in the embedding. The authors compare their method to a variety of baselines, including both ablations of their own model as well as more traditional approaches from hierarchical RL, deep RL, and a standard program synthesizer on the KAREL domain. The authors find that the programmatic policy representations perform better overall for many of the KAREL tasks, and generalize better to larger problems than they were trained on.",
    "This paper presents a two-stage method for reinforcement learning via program synthesis, and shows that is is effective compared to baselines for a number of simple gridworld tasks, deminstrating a degree of out-of-distribution generalisation. The first stage of the process learns a latent space for encoding programs, and the second stage searches that latent space for programs that maximise reward in  the task. Overall a very nice paper that deserves publication.",
    "- Authors use a two-stage method for program synthesis: (1) They   create an embedding space capturing the semantics of the program   space; (2) They search through the embedding space for a program   that solves the task in hand. - They use variational autoencoder to encode programs, where an   encoder maps a sequence of program tokens into a latent space, while   a decoder maps from the latent space into the original program. They   use a combination of loss functions to ensure that not only   syntactically similar programs are close to each other in the latent   space but also semantically close programs. Loss function consists   of a composition of 3 losses. (A) Classical beta VAE loss which   helps that syntactically close programs are close to each other. (B)   Program behavior reconstruction loss which helps that semantically   similar programs are close to each other in the embedding space. For   example, two syntactically different programs can make same actions   under same situations. This loss is defined by difference between   execution traces of original and reconstructed program. (C) Latent   behavior reconstruction loss. This loss is constructed by learning a   policy to predict correct action based on the latent program   embedding. This allows for backpropagating gradient through the   policy and the encoder to ensure better quality of the embeddings. - After training the variational autoencoder, authors use a cross   entropy method to find a program with maximal performance using the   latent space. They sample the latent space distribution of programs,   decode the latent program into an actual program, execute the   program to obtain corresponding rewards, and repeat the process. - Authors did a nice ablation study where they measured effectiveness   of their individual design decisions: evaluating each of the loss   function components, as well as the effectiveness of the latent   space search method for finding the best performing program. They   compared they method to other methods, deep reinforcement learning   (DRL) based as well as Viper which is a decision tree policy   obtained by mimicking a DRL agent.",
    "In this paper the authors inspect the popular Physics Informed Neural Network (PINN) set of models and characterize their behavior (specifically their failure modes) in the context of two popular PDE systems, namely diffusion and convection. In each case, the authors demonstrate that PINNs learn effective representations in simple regimes while failing to learn representations of the PDE systems in more complex regimes. In addition, authors also demonstrate that it is not the inability of the neural network to fit the functions (due to some potential inability to represent non-trivial functions), but rather the way the PINNs incorporate the PDEs into the learning pipeline that is the reason for the failure. Finally, the authors also propose casting the PINN problem as a sequential prediction task (i.e., predicting all collocation points per time period) as opposed to tasking the neural network with simultaneously learning the full spatial and temporal domain.  ",
    "This work studies two specific (yet essential) PDE learning cases in the PINN framework. Notably, the work proposes two main conclusions to explain the difficult training in PINN networks:  - the loss landscape varies greatly with the PDE coefficient values (and works well with only low diffusion/conduction coefficient),  - the loss landscape (at the end of training) varies greatly with the physics informed penalty coefficient.   The main explanation to such difficulties lies in the condition number associated to PINN penalty. The work proposes two solutions: a warm-up, and a sequence to sequence approach.",
    "The paper studies the behavior of Physics Informed NNs (PINNs) on two common PDEs of physical relevance. It observes that PINNs fail to learn a good solution under standard training regime when the convection coefficient or viscosity coefficient is high, even when the closed-form solution does not depend on the constants.  The authors then seek to explain this behavior from an optimization standpoint. They plot the loss landscape along the two dominant hessian eigenvectors. They hypothesize that the optimization problem is ill conditioned due to the regularization term in the optimization objective that enforces the pde constraint.  They also run experiments to argue that sequence to sequence learning might work better for these ill conditioned problems.",
    "The authors provide a detailed empirical analysis of the numerical difficulties encountered when training so-called \"physics informed neural networks\" (PINNs), a recent class of models which incorporate physical (often differential) equations into the loss function of a neural network. The authors perform a systematic analysis on two relatively simple but common use-cases in scientific literature, convection and diffusion equations, and demonstrate the PINNs fail to adequately learn the underlying dynamics of the system even in simple cases. They show that these failures are due to the effect of the convection/diffusion coefficients and forcing terms on the conditioning of the dynamical system, i.e. larger coefficients or forcings tend to make the problem increasingly ill-conditioned, thereby impacting characteristics of the loss function. The authors then propose two possible workarounds for these issues; improved initialization via a warm start or preconditioning and re-framing the problem as a sequence-to-sequence learning task.",
    "Proposes cycle self-training (CST) an unsupervised domain adaptation (UDA) algorithm that cycles between standard self-training of a target classifier on (source model generated) target pseudolabels, and a new cycle self-training step that updates backbone representations so as to generalize the target classifier to the source domain. An additional self-training objective based on the Tsallis entropy is introduced. Theoretical and empirical results are presented on several standard UDA benchmarks.",
    "The paper tackles the problem of domain adaptation with a newly proposed cycle self-training algorithm. Given observed that the pseudo labels are noisy and existing de-noising methods require ad-hoc hyper-parameters for specific tasks, the authors attempt to progressively refine the pseudo labels by the capability of the network itself. With the intuition of transferring the source-domain knowledge to the target domain, the authors propose to regularize the pseudo labels with a cyclic training pipeline. Tsallis Entropy is further introduced to improve the label quality. Experiments on both visual classification and linguistic sentiment classification indicate the effectiveness of the introduced method.",
    "This paper presents a novel approach for unsupervised domain adaptation (UDA) based on cycle self-training. Instead of conventional self-training, there are a generated and two attached classifiers with different purposes. The source classifier, mainly trained on the source loss, is applied to infer pseudo target labels. The target classifier is trained by the self-training loss based on the pseudo labels provided by the source classifier.  The authors also propose the Tsallis entropy as the regularization term, which can be seen as a side contribution.",
    "This paper proposes an unsupervised domain adaptation method based on cyclical self-training. There are two main components to the method: 1. a cyclical self-training algorithm that solves a bilevel optimization problem based on an in the inner loop which trains a target classifier with target pseudo-labels  and an outer loop that makes the target classifier perform well on the source domain by updating the shared representations in the outer loop. 2. an uncertainty measure based on the Tsallis entropy, which adaptively minimizes the uncertainty in target pseudo-labels, which replaces the standard Gibbs entropy used by self-training methods. Experiments on computer vision and NLP datasets show that proposed method outperforms baseline methods by a decent margin. Ablation studies show that both components of the algorithm---cyclical self-training and Tsallis entropy---meaningfully contribute to performance improvement. Qualitative and quantitative studies show that target pseudo-label quality is improved by the proposed approach. ",
    "The authors propose a single stage pruning method (DAM) that jointly prunes and refines weights during training. The method uses a monotonically increasing gate function for the neurons/channels in each layer with one trainable parameter. The gate function only discriminates neurons based on the position of them in the layer. The proposed method achieves reasonable results without any fine-tuning.",
    "This paper proposes a novel structured pruning method called DiscriminAtive Masking (DAM) for neuron-level sparsity. A relu-tanh gating function is proposed to apply on the neuron activations, and gradually zeroing out the neurons at lower order by introducing a L0 norm. The proposed method is a single stage method, and does not require further after-prune finetuning. Extensive experiments demonstrate the effectiveness of the proposed method",
    "This paper proposes a gradual structured pruning method, DAM, that can achieve good performance with various applications. The paper conducts extensive experiments to support the effectiveness of the proposed methods. The method part is reasonable and makes sense.",
    "This paper presents a simple and novel in-training model pruning algorithm to learn sparse feature representation with reduced computational load w/o compromising accuracy. To do this, authors introduce a single learnable parameter to simplify the optimization involved in enforcing L0 sparsity. Authors further provide theoretic analysis on how reducing the single learnable parameter would enforce L0 sparsity. Finally, authors demonstrate the remarkable performance over various applications comparing with the established strong baselines.    ",
    "The paper proposes a model based on self-attention, factorised in different modules. It processes a sequence of tokens and could be viewed as a generalisation of a Transformer. The key idea is to have different modules (associated with a function) that behave differently but are general and actually share parameters. The core module of ModAttn can be viewed as a self-attention module with dynamic weights that depend on a context / code c. Using n_f learnable codes, each assigned to a \u2018function\u2019 leads to n_f modules, each with different functionality. An important aspect is the fact that each function only affects a subset of tokens, just the ones that are close to a type (learnable parameters) of the function. ",
    "This paper proposes Neural Interpreter (NI), a drop-in replacement for Transformer layers that can be applied on set-valued inputs. The motivation behind the architecture is that common computation units in deep learning such as convolution layer is rigid in how they process the input, so to overcome this, NI leverages self-attention to dynamically determine computation path using its modular functions depending on the given input. The paper shows how NI performs well in transfer-learning and systematic generalization tasks.",
    "This paper proposes a method for modularizing neural networks inspired by programming functions and compilation. Building on the success of attention and transformer architectures, the neural interpreter (NI) proposes a new architecture built on layered functions, each of which is composed of stacked MLP and attention layers. Functions and input variables both have embeddings, called \u201csignature and type\u201d respectively, that allow NIs to learn specialized functions that operate over a subset of inputs. The NI is applied to a suite of image datasets as well as to Raven matrices, where it is shown to outperform vision transformers.",
    "This paper focuses on improving the generalization ability of deep models to the unseen but related distributions to training data, and thus enhancing interpretability. In specific, a Neural Interpreter is proposed, which factorizes the inference of self-attention networks as the dynamic routing within functions. The Neural Interpreter can flexibly compose computation on a per-sample basis, and it is end-to-end trainable. Some interesting experiments including image classi\ufb01cation and visual abstract reasoning are conducted to validate the effectiveness of the proposed method.",
    "This paper proposes an approach to transferring pretrained models in a deep RL context. Instead of pretraining a neural network and then simply copying the weights and retraining on a new task (as would be the naive approach taken in supervised learning), the paper instead proposes transferring the pretrained policy's behaviour. This is done by modifying the epsilon-greedy exploration strategy to include the ability to use the action suggested by the pretrained policy, which can also be used as a kind of multi-step option for improved exploration.  Pretraining is conducted using the \"Never Give Up\" (NGU) intrinsic reward in a reward-free setting, and experiments are conducted in the full set of Atari games. Results and ablation studies indicate that such a transfer approach can drastically improve the performance of an agent on a new task.   The main contributions are a) the use of NGU as an unsupervised pretraining objective in RL; b) a method for incorporating a pretrained policy when learning a new policy; c) experimental results and ablation studies across the full suite of Atari tasks that demonstrate the improvement resulting from leveraging the pretrained model when exploring in a new task.",
    "The authors present a simple, intuitive method for fine-tuning \u201cbehaviors\u201d by pretraining an exploration policy before using it as a temporally extended exploration procedure and a one-step additional action to the downstream policy on a downstream task. They extensively evaluate this on the suite of Atari games and demonstrate strong performance gains. Despite some qualms I have with assumptions and ablations, I think this paper should be accepted to NeurIPS. However, I do hope that the authors address some of my concerns in the rebuttal period. For now, this is a \"weak accept\" but if my concerns are addressed properly the score will be raised appropriately. ",
    "This paper studies the transfer of unsupervised RL agents in the Atari-57 benchmark suite.   The authors propose behavior transfer (BT), a simple method for transfer that focuses on using the behavior of the pre-trained policy, separately from using the pre-trained policy as an initialization (a.k.a. fine-tuning). BT augments a downstream off-policy learner in two ways: the downstream learner can use the pre-trained policy to explore (for a temporally extended duration), and the pre-trained policy is also added as a pseudo-action to the action space as an option during exploitation (for a single time step).  In the experiments, the authors primarily focus on using the never give up (NGU) objective to obtain the pre-trained policy and assess the impact of BT with this pre-trained policy on downstream learning via recurrent replay distributed DQN (R2D2). The protocol differs from prior works in that each learning phase is much longer: 16B frames per game for pre-training (a 64x increase over [28]) and up to 5B frames per game for transfer (a 12500x increase over [35]). This is shown to be important overall. For standard Atari-57, transfer via BT compares favorably against R2D2 baselines that lack unsupervised pre-training, with more pronounced gains for hard exploration games. Ablations show that both BT methods of using the pre-trained policy are necessary for best performance. The authors also assess on custom tasks in the Ms Pacman and Hero games, with BT causing significant improvement over R2D2 baselines despite the zero-shot pre-trained policy used for BT not achieving any success. Finally, the authors also assess BT with fine-tuning from (some subset of) the pre-trained policy's weights. For standard Atari-57, fine-tuning improves over training from scratch for both R2D2 as well as R2D2+BT. However, finetuning without BT from a partial initialization outperforms any variant involving BT, an interesting negative result. ",
    "The authors study the problem of transferring pre-trained behavior for exploration in reinforcement learning. They propose an approached called (BT) which relies on the pre-trained policy for collecting experience through temporally-extended exploration, which can be triggered with some probability at any step, or  one-step calls to the pre-trained policy based on value estimates. The experiments presented in this work show that, when combined with large-scale pre-training in the absence of rewards, existing intrinsic motivation objectives can lead to the emergence of complex behaviors.",
    "This paper proposes a new class of surrogates called PiRank for ranking metrics optimization. In particular, it uses temperature-controlled relaxation to the permutation matrix to derive a continuous and differentiable sorting operator. Due to the large size of the ranking lists in practical applications, this paper also proposes a divide-and-conquer method to reduce the complexity of metric computation. Experiment results show that the proposed methods can achieve promising results on two popular benchmarks.  ",
    "This paper proposes PiRank, a new neural learning-to-rank (LTR) approach based on differentiable sorting operators. The authors present empirical results against two widely used LTR data sets (MSLR-WEB30K and Yahoo! C14).",
    "This paper tackles the problem of Learning To Rank. The idea is to relax ranking metrics (eg DCG), that are non differentiable with respect to the model parameters theta. Originally, these metrics measure how well the predicted ranking (induced by the scores predicted by the model) places high items with high true relevance labels. The relaxed metrics replace the permutation matrix in the original metrics by a relaxed, unimodal matrix, parametrized by a temperature.  This relaxation was proposed in Neuralsort, but is of quadratic complexity in the total number of items L at each time. In this paper, the authors propose a computationally efficient version of Neuralsort, truncated at the k first items, relying on a divide and conquer strategy. This approach is of much lower complexity, expressed in terms of L,k, and d the depth of the tree.  Finally, the method is evaluated on benchmark learning to rank datasets. It obtains similar or better performance than sota methods.",
    "The authors provide a new scalable listwise loss for ranking called PiRank.  The loss is defined as 1 - a differentiable relaxation of NDCG metric with temperature-controlled inspired by NeuralSort algorithm. In this setting, the difference with the NDCG is negligeable the temperature tends to 0.  Scalability is ensured by a divide-and-conquer strategy where the sorting relaxation is applied to sub-lists of smaller size and then propagate only on the top items from each sub-list to merge the sort.",
    "# Overview  The paper proposes a framework incorporating deep reinforcement learning for resolving Ansatz optimization problems, which is with wide impacts on quantum chemistry. The authors have a good introduction and related work section, which covers most standing works in quantum reinforcement learning and variational circuit learning.   Compared with Rotosolve and COBYLA, the proposed DDQN-based method attains state-of-the-art results on estimating the ground-state energy of lithium hydride.  Overall, I like the idea but the baseline comparison and some time complexity could better incorporate to add the depth of this paper. The current version is more application-oriented and less novel as a general ML framework considering existing works in the neural architecture search (NAS) community.   - Justification of DDQN and comparison   When discussing \"why selecting DDQN for the RL\", there is very little discussion.   Since this work is not the first works on applying the heuristic method for quantum circuit architectures search (QCAS), the contribution is more on framing the Ansatz optimization and the benchmark results. It would be more valuable to address the selection and justification of the algorithm. (e.g., DRL-based vs Neuroevolution-based or at least the variants inside DQNs)  For the general audience in the NeurIPS community, instead of only showing the DDQN-based method for QCAS, providing more in-depth discussion between variants of the DRL algorithm (e.g., DQN, DQN with dueling, DDQN with dueling) and its complexity could gain better values of this paper.   ",
    "The variational quantum eigensolver (VGE) is a method that utilizes a Noisy Intermediate Scale Quantum (NISQ) computer to find the ground state of quantum systems. At its core, an Ansatz for the ground-state wave-function is parameterized in terms of a quantum circuit, i.e. a series of single-qubit and two-qubit gates acting on a reference state, and the optimal parameters of the circuit are determined by a classical algorithm that uses the NISQ to evaluate the performance (energy) of the Ansatz.In this manuscript, the authors propose a reinforcement learning (RL) based approach to identify the small circuits (i.e. with the low number of gates, and thus less prone to errors) that still allow to reach chemical accuracy. The RL method is based on double deep-Q learning and curriculum learning. The authors employ their method to find the ground state energy of LiH approximating the electronic Hamiltonian as a 4 or 6 qubits Hamiltonian. For 3 different bond distances, the method proposed by the authors identifies circuits that achieve chemical accuracy, but whose size is lower as compared to other Ansatze",
    "This paper studies the ansatz for Variational Quantum Eigensolver (VQE) quantum circuits. The authors propose a deep reinforcement learning framework to generate the ansatz for VQE circuit, aiming to achieve low estimated energy and shallow circuit depth. The authors leverage curriculum learning to gradually reduce the energy threshold (increase difficulty) to avoid learning failure. The method is evaluated on LiH molecule in different settings and shows shallower circuit than baseline HE and UCCSD circuits. ",
    "This work demonstrates that reinforcement learning with intrinsic motivation can be effectively used to search over the space of ansatzes for the variational quantum eigensolver (VQE) algorithm. This algorithm is used in quantum chemistry to approximate the ground state energy of molecules (e.g. LiH). The author(s) describe how DDQN trained with Adam can learn to optimize a VQE-relevant reward function, in an environment which runs an optimization subroutine (COBYLA or rotosolve) at each step to optimize the rotation angles of the ansatz's gates. Their LiH experiments used a simulated noiseless quantum environment, and they benchmarked the performance against two well-known ansatzes. The results show that in simulation, RL has promising potential for circuit depth improvement.",
    "This paper evaluates several transductive few-shot learning methods [15,28,20,21,23,17] on class-imbalanced FSL tasks. The class distribution in the query set follows a Dirichlet distribution. The support set is balanced. This work proposes a novel method based on $\\alpha$-divergences addressing the imbalance problem. The novel method $\\alpha$-TIM achieves competitive performance compared to several recent baselines.",
    "The paper studies transductive few-shot learning in the more realistic setting with arbitrary class distributions within the query sets. In the proposed setting, authors use Dirichlet distribution to model the marginal probabilities of the classes in the query sets as random variables and generate random samples within the simplex. Focusing on two recent transductive methods PT-MAP and TIM, they first show that class-balance prior is encoded in these two methods and then extend TIM by generalizing mutual-information loss to \\alpha divergences to more effectively deal with arbitrary class distributions. The experiments validate proposed \\alpha-divergence approach on three standard benchmark datasets (mini-ImageNet, tiered-ImageNet and CUB) and show that the method outperforms inductive and transductive few-shot learning methods in the proposed setting.",
    "This paper studies transductive evaluation in few-shot learning, which allows the model to use statistics of all the unlabeled query set examples when making class predictions. Models evaluated in transductive fashion typically attain higher metrics by using this extra information. Most work on transductive evaluation, however, assumes that the query set is evenly distributed across the possible classes. This is of course an unrealistic assumption for the real world and this paper specifically studies this aspect: (1) They evaluate in a more realistic transductive evaluation scenario where the class counts within the query set are sampled according to a Dirichlet distribution and show that most transductive evaluation-based methods perform worse in this setup; (2) They propose a modification of an existing model for transductive evaluation to work better in this scenario where the class counts can be varied in the query set.",
    "The researchers use transductive inference and introduce the effect of arbitrary class distributions within the query sets of few-shot tasks, rather than using class-balanced tasks, by removing the class-balance artefact. They do this by modeling the marginal probabilities of the classes as Dirichlet-distributed random variables, rather than from a known and fixed uniform distribution. They assess their model by comparing transductive methods over 3 datasets, and show their experiment setting\u2019s performance drops compared to inductive methods. They also propose a generalization of the mutual-information loss based on alpha-divergences, which is an extension of the Shannon mutual information and tolerates class-distribution variations more effectively.",
    "Instead of the conventional layer-by-layer execution, this paper proposes a patch-by-patch scheduler to reduce the peak memory required by a CNN for inference on MCU. The author also proposes a network redistribution method, which finetunes the network architecture (CONV kernel size), to mitigate the computation overhead caused by their patch-by-patch execution. The results show that, with a certain computation overhead, the proposed methods can effectively reduce the inference peak memory while not losing accuracy.",
    "Working memory utilization for most CNN based models typically is more than what can be afforded on Tiny devices. Thus, it is often quite difficult to extract reasonable performance for visual tasks on tiny devices.  Authors attack this problem by a) introducing a patch based inference method that improves peak memory utilization at the cost of compute and b) introducing a redistribution process that reduces the overall compute while maintaining/improving performance. ",
    "This paper addresses the problem of large activations that quickly arises in devices with little memory, such as MCUs, when deploying larger networks. The main contribution proposes a relatively simple but effective approach to reducing the memory footprint of activations (by a large 4x-8x factor) while introducing some unavoidable extra compute (resulting in up to 15% MACs, which translate into  up to ~1.27x higher latency). The impact in terms of compute overhead of the proposed per-patch processing is alleviated by redistributing the receptive filed. Which means: reducing the filter WxH in early layers and use striding>1; then stack more blocks in deeper parts of the network where the memory peak of activations is not so high anymore. A NAS-based mechanism is introduced to jointly discover architectures and receptive filed redistribution strategies. ",
    "The main problem the paper tries to tackle is reducing the peak memory footprint of the neural networks by deviating from the usual layer-by-layer execution. The main intuition seems to be very similar to tiling combined with layer fusion-like ideas. However, the main spark of the paper seems to be leveraging this dimension in the context of Neural Architecture Search, which seems to be novel.",
    "The authors formulate and study dynamic mechanism design in an MDP-like setting. The motivation is principal-agent problems. The principal commits to a policy to choose actions given observations of states; the environment evolves according to some transitions dynamics based on these actions; the agent does not act but is free to misreport states to the principal. Agent and principal receive utility; the principal\u2019s goal is to choose a policy that is incentive compatible and individually rational (standard goals of mechanism design) while maximizing its own expected total utility.  In general, from a full description of the environment and dynamics, the \u201cplanning\u201d type problem to find an optimal mechanism is NP-hard (shown via reduction from MAXSAT). If the time horizon of the problem is treated as a constant, then it is possible to formulate a linear program to find the optimal mechanism in polynomial time, and doing so is a major portion of the paper. ",
    "This paper presents and proves a linear program for unstructured dynamic mechanism design. The LP supports payments and different individual-rationality constraints. The key contributions are: 1) Presenting an LP that provably yields an optimal mechanism for an unstructured dynamic environment with a finite time horizon. 2) From this LP formulation and standard LP complexity results follows a polynomial runtime guarantee for finding an optimal mechanism.",
    "The authors study the problem of computing optimal mechanisms in a dynamic unstructured environment. Unlike a static environment, the principal is allowed to repeatedly interact with a strategic agent and take actions based on the agent's reports of the current state of the world. The authors show that when the time horizon of such a dynamic environment is not finite, the problem is intractable. When the time horizon is small, they show that an efficient mechanism can be computed using an LP",
    "This paper studies automated mechanism design in dynamic unstructured dynamic environments. In the setting of interest, a principal and agent repeatedly interact for a finite number of time steps (finite time horizon); at each time step, the agent reports the current state of the environment, the principal takes action, and the environment transitions to the new state. Importantly, the agent's and the principal's utilities are not necessarily the same, implying that the agent might misreport which further implies the need for a mechanism.  The paper considers a randomized dynamic mechanisms that consists of the policy of the principal and the mechanism's payment function. The main results are: a) an LP for finding optimal mechanisms (constant time horizon), b) a computational complexity result which shows that the principal's utility is hard to approximate within a certain factor for environments with large time horizons.  The paper has additional results, as mentioned in the abstract, but these are not presented in the main text.",
    "This paper combines the differentiable graph structure learning and neural architecture search together. By conducting the two iteratively, the framework can automate GNN design for tasks without given graph. It also provide an analysis that NAS could help balance GNN and MLP by the informativeness of graph against structure.",
    " The paper investigates the ability of gradient-based NAS method on selecting desired operators to construct GNN architectures. It shows that DARTs method can discriminate the benefits of different operators based on the graph structure but suffers from the noised in graph. Based on the findings, the authors propose to add an extra graph-structure learning term during the optimization process to denoise the graph structure and shows improved performance compared to existing baselines. ",
    "This paper analyzes how DARTS selects its desired architectures, and shows that the gradient based NAS suffers from noises hidden in the graph, resulting in searching suboptimal GNN architectures. Besides, this paper improves the gradient based NAS methods by employing graph structure learning as a denoising process in the search procedure, and thus proposes GASSO, a more effective NAS algorithm. The theoretical analysis given by this paper is important and interesting, but the technical improvement lacks experimental analysis and proof, and important comparison experiments are missing.  ",
    "This paper proposed one graph neural architecture search method to learn graph structures in one differentiable way. It makes an investigation on how NAS select the operations in GNNs, and then evaluate the NAS method on a set of synthetic datasets with different structures. This paper proposed one feature smoothness constraints which can learn the graph architecture in one differentiable way.",
    "The paper studies a new variant of fair clustering for different fairness (group utilitarian, group egalitarian, group leximen) and clustering objectives(k-center, k-median, k-means). The main approach is to optimize the fairness objective under the constraint that the clustering cost are bounded by some value U. The main result can be thought of as a bi-criteria approximation: If we allow that U is violated by a factor of (2+alpha) (where alpha is the approximation ratio of some clustering algorithm for the given objective) then we can get an additive approximation on the fairness objective.   In addition to this algorithmic upper bound, the authors also give a number of complexity theory lower bounds for different variants of the problem.   The authors also provide a proof-of-concept study of their algorithm.  ",
    "EDIT: I increased my score following the discussions and rebuttal. The main question in the paper is how can we cluster data so that we optimize for some fairness desiderata. In other words, if we have a target for the amount of clustering cost we are aiming for, how can we find the most fair solution, subject to that cost constraints? Put differently, the authors address the problem of minimizing the amount of \"unfairness\" subject to the clustering cost being below a certain threshold. The two desiderata put forth by the authors in terms of fairness have to do with \"group utilitarian\" objective and with \"group egalitarian\" (they also further study a generalization called \"group leximin\" objective. The authors give both positive results and some impossibility results. Finally, they run some experiments to validate their findings.  These three objectives are desiderata that have been studied in the past. Briefly, the group utilitarian objective minimizes the sum of all fairness violations, whereas the group egalitarian objective minimizes the maximum fairness violation. Going a step further, the leximin (LM) objective minimizes the maximum fairness violation first, then minimizes the second worst etc.   One of the hardness results they prove is that for all three objectives, both fairly clustering and fairly assigning points to fixed centers is NP-hard.  On the positive side, they give an approximation algorithm that yields a (2+a)U-approximation where U is an exogenous parameter that is the upper bound on the clustering cost and a is the approximation ratio of a color-blind clustering algorithm. The algorithms presented for the different objectives depend on some assumptions about the sizes of the clusters. The idea behind the algorithms is to first run a color blind clustering algorithm to select centers, followed by an LP to get a fair assignment and a flow computation.  The authors perform some computational experiments on the adult and the census data sets to evaluate how their fairness guarantees look like. ",
    "The paper studies the fair clustering (with balanced clusters requirement) and the goal of authors is to achieve the \u201cfairest\u201d possible clustering achievable with cost at most U. The idea here is that we know that PoF can be unbounded, and it is unrealistic to assume that in practical applications we cannot sacrifice the clustering quality for fairness with no limit. An important component is how to measure the amount of unfairness and then the goal is to minimize it while not violating the upper bound on affordable clustering cost. They have defined three notions called GROUP-UTILITARIAN, GROUP-EGALITARIAN and GROUP-LEXIMIN. Basically, in fair clustering, for each color h, we are given lower and upper bounds $\\alpha_h, \\beta_h$ and the goal is to guarantee that in each cluster the number of point from color h is at least $\\alpha_h \\cdot  |C_i|$ and is at most $\\beta_h \\cdot |C_i|$. Now, the amount of unfairness is defined by a new set of parameters $\\Delta_h$ such that instead of satisfying the fair clustering requirements exactly, we have that the number of points from color h is at least $(\\alpha_h - \\Delta_h) \\cdot  |C_i|$ and is at most $(\\beta_h + \\Delta_h) \\cdot |C_i|$. The authors consider $\\min \\max_h \\Delta_h$ and $\\min sum_h \\Delta_h$ objectives (GROUP-LEXIMIN is a lexicographical minimizing of \\Delta_h: the top priority is to minimize the min value, then among those with the same min value, minimize the second min value and so on). ",
    "This paper derives the theoretical bound of fair clustering based on porotype based algorithms. Generally speaking, the authors expect to minimize the unfairness under the given upper bound. In this paper, the authors consider two types of fairness and two fairness clustering setting. Based on this, the authors derive the upper bound of the unfairness and design the corresponding algorithm. The major contributions of this paper lie in theoretical analysis.   ",
    "The authors in this work study the limitations of edge independent models which are an important class of graph generative models. Specifically the authors demonstrate that such models are inherently limited in their ability to generate graphs with high triangle and other subgraph properties which are typical in real-world graphs. The authors demonstrate the main results of their work via empirical experiments.",
    "The main result is that certain structural properties of an edge-independent graph model, e.g. the expected number of triangles, are upper bounded by how strongly the graphs sampled from the model are expected to be overlapping.   Experiments on two datasets empirically confirm that several edge-independent baseline models require a high amount of overlap in their sampled graphs in order to match the number of triangles in the original graph dataset.",
    "In this paper, the authors analyze some properties of edge-independent generative graph models: given a fixed matrix of connection probabilities in [0,1], the edges are drawn independently. This is the basis for several methods to generate graphs that match certain statistics of a given input graph (*over the same set of nodes*). It has been observed that such models tend to produce less triangles (or generally k-cycles) than real graphs. In light of this, the authors show that the expected density of k-cycles can be bounded by the model *overlap*, which measures how much the model tends to memorize only one graph, as opposed to generating a large variety of graphs. The proofs are simple and are mostly given in the main paper. They also show that their bounds are tight, up to multiplicative constants, for Erd\u00f6s-R\u00e9nyi graphs, which are models with minimal overlap. Numerical experiments are performed to compare several edge-independent models, including a novel one introduced in the paper, and illustrate the (negative) theoretical findings.",
    "This paper studies edge independent graph models that covers a large family of graph models. The main result is that it shows under certain conditions, the edge independent models are limited to generate graphs with high triangle and other subgraph densities, which are commonly observed in real world networks. Based on this finding, this paper propose a way to generate graph which balances matching the original graph and memorizing the graph statistics. ",
    "The paper demonstrates empirically that on a variety of architectures and datasets, the derivative of ReLU at 0 is evaluated a significant number of times during training in 16 and 32 bit precision. These events are frequent enough such that defining ReLU'(0) to be anything other than 0 (default value in common DNN frameworks) hurts generalization, and sometimes training as well.  The authors perform a variety of investigations around this effect, such as the influence of training set size, network width, depth, batch size, BatchNorm, Dropout. ",
    "This paper analyzes the impact of the choice of ReLU'[0] on the fidelity of neural networks. Even though one would expect that the value of ReLU'[0] should not have any noticeable impact, the authors notice the divergence in learned parametric values that depend on this choice. They also notice that this effect is more pronounced at lower precision (due to rounding effects that are dominant at fp16 and fp32 vs. fp64). They also study this effect for neural network sizes, topologies (including networks with and without batch normalization) and datasets.",
    "The ReLU function is not differentiable at 0 which has a mathematical impact on ReLU neural networks. Nevertheless they are optimized using gradient based methods. The folk wisdom is that singular points only occur with zero probability and therefore the issue is irrelevant. This paper challenges this folk wisdom and identifies that the choice of the derivative at 0 does have a tangible impact on the optimization and classification performance.",
    "This paper studies a long-neglected problem: the gradient of the non-smooth activation function in training a neural network. Specifically, the authors study the numerical influence of the ReLU derivative at zero on gradient descent. First, a theory is presented to illustrates the trivialness of ReLU'(0), then, the authors give counter-theory experiments to show that ReLU'(0) can affect training results.  In the last two sections, authors demonstrate that low-precision training, SGD optimizer, no batch norm training can magnify the impact of ReLU'(0).",
    "This paper introduces a novel approach to learning parameterized policies. The way I understand the work: it jointly optimizes a policy objective, a probabilistic dynamic model objective, and a compression objective. A bottleneck encoding distribution is key here, which is subject to both model predictions (given previous action and encoding) and compression (given current observation). In spirit, it is similar to variational information bottleneck (VIB) but can be seen as an extension of that to RL. So, the interpretation of this optimization is that the agent is aiming for encoding distribution that is maximally predictive of the next observation and maximally compressive of the observation while the agent is maximizing the future aggregate reward. The idea is neat. The optimization can also be easily put together. Some theoretical and empirical results are given. ",
    "In this paper, the authors propose a new reinforcement learning method, called robust predictable control, that optimizes a policy under limited representational resources. Similar to previous methods, they formalize the problem in a fully observable MDP and learn a compressed representation of the state space using a variational information bottleneck constraint. Crucially, they apply the bottleneck on sequences of states. Through a clever factorization of the variational prior, they obtain a prior dynamics model in the compressed state space. This dynamics model is predictive and the agent only needs additional representational resources if the encoded states are not predicted by the prior dynamics already. Using a set of standard RL benchmarks, the authors show that this set up improves compression and enforces predictable and robust behaviors . ",
    "This paper proposes the method \"robust predictable control (RPC)\". It proposes to use a information bottleneck between inputs and actions. However, in contrast to previous works, it does so not on a per-observation basis, but on a per-sequence basis using a latent model. Similar to some of the prior work, the encoding cost is not added to the loss, but subtracted from the reward. ",
    "The paper \"Robust Predictable Control\" describes a method to learn policies with an information bottleneck between environment observations and a latent representation which is used for decision-making. The bottleneck is posed between *sequences* of observation and latent states, in contrast to prior work, where a bottleneck is posed between individual states and latents independently. A crucial component of the proposed method is an action-conditioned dynamics model in the latent space. The proposed training objective is jointly minimized by training an encoder, latent dynamics model, and policy.  First, this encourages the encoder and dynamics model to yield good predictions of encoded environment observations.  Furthermore, by training the policy, the expected task return is maximized while ensuring that the behaviour of the agent is well-predictable.  The latent dynamics model formulation can be exploited to derive theoretical guarantees between open-loop and information-constrained closed-loop control.  Several experiments show that the information-constrained agent performs well in the nominal case but also on distorted environments and offers smooth transitions between different behaviours depending on the tightness of the information constraint.",
    "The central part of the paper is the design of a learned positional encoding (LPE) that can be used in graph transformers in a similar way the positional encoding is used in text transformers. The authors propose to use eigenvalues and eigenfunctions to encode node positions in a graph, and demonstrate how to incorporate them into a transformer model that achieves high expressivity. The architectural choices are based on the theoretical introduction in which some concepts are borrowed from physics, such as the analogy to electric potential between nodes. The LPE is designed to address five principles that were overlooked by different methods. The authors also implement a new model, Spectral Attention Network (SAN), that utilizes the LPE resulting from the theoretical findings. The experimental results confirm the efficacy of the method.",
    "This paper presents an interesting idea on designing a novel graph transformer with learning positional encoding by a spectral attention network (SAN) using the full Laplacian spectrum. Three theoretical limitations from previous efforts are overcome by this spectral attention, namely WL test and universality, over-squashing and physical interactions. Experimental results on four standard datasets demonstrate the effectiveness of the proposed SAN.",
    "This paper proposes a learned position encoding mechanism which can fully make use of the eigenvalues and eigenvectors information from the graph Laplacian. The learned position encoding is then concatenated with the embedded node feature. In addition, the edge feature is also served as an input feature in order to completely leverage the graph structural information. Also, by fully connecting the graph, it helps tackle the common over-squashing problem in many GNNs. The paper also proposes an alternative version of attention so that real edges and added edges are taken into account separately when computing the attention. Eventually, the paper empirically tests the performance of the proposed model on real graph datasets.",
    "This work proposes a transformer designed for graph structured data. As opposed to GNNs, the transformer allows non-neighboring nodes to communicate. To avoid loosing information on the structure of the graph, the transformer needs some form of structure encoding of the nodes, a non trivial problem for graphs. A common PE scheme consists in using the spectrum of the graphs Laplacian but, as detailed by the authors, this raises some issues. The authors propose an improved positional encoding circumventing these problems and demonstrate that a fully connected transformer is competitive with GNNs on four datasets.",
    "This paper studies a setting that combines social choice and information aggregation.  As in a classic social choice problem, individuals with preferences want to choose between two options, but as in an information aggregation setting they do not have the knowledge to know exactly what their preferences are, instead having only a signal correlated with the true state of the world.  The paper introduces a \u201cWisdom-of-the-Crowd-Voting\u201d Mechanism, which implements the majority wish in an (approximate) strong Bayes Nash equilibrium.",
    "The authors consider elections that have two alternatives and three distinct classes of voters: candidate-friendly, candidate-unfriendly, and contingent agents. Candidate-friendly and candidate-unfriendly agents have made up their minds before the election, but each contingent voter's opinion depends on an unobservable state variable; they each receive a private signal about this state variable. The authors present a mechanism that elicits private signals from voters and which outputs the correct answer based on the state of the world. This mechanism is also strategyproof against even coalitions in the sense that truthful reporting is a strong Bayes Nash equilibrium. The mechanism draws on the \"surprisingly popular\" method of Prelec et al. ",
    "The paper considers two alternative elections in which the voters are imperfectly informed. There is an unobservable state that may affect some voters\u2019 preferences. Each voter receives a signal correlated with the state. The voter\u2019s signals are conditionally independent and follow the same publicly known distribution. The designer\u2019s goal is to elicit truthful information and aggregate the information to find the alternative that is preferred by the majority. The paper proposes a mechanism that guarantees truthful reporting is an approximate strong BNE and outputs the right alternative with high probability. ",
    "This paper considers the two-alternative voting problem with imperfectly informed voters. In this setting, each voter receives a signal which is positively correlated to voter's true preferences (over two alternatives). The goal is to aggregate these signals to find out the majority voting winner w.h.p. Specifically, the paper gives a mechanism such that  1) the mechanism will output the majority voting winner under the true preferences w.h.p.  2) the mechanism incentives every voter to truthfully report the signal they received.  The main technical contribution of this work is that their mechanism uses the idea of \"surprisingly popular\" approach (Prelec et al., 2017)  from the information aggregation literature. They show that \"surprisingly popular\" approach can be well adapted to two-alternative social choice setting and can incentivize voters to report truthfully (for two-alternative). In addition, they show their mechanism is user-friendly, and does not require voters to understand deep mathematics.",
    "This paper provides several results on the rank of the Hessian of neural networks. The main results are:  (A) upper bounds on the rank of the Hessian of a linear neural network (i.e., identity activations). These are proved by separating the Hessian into the sum of the \u201couter-product Hessian\u201d and the \u201cfunctional Hessian\u201d, and bounding the rank of these separately. (B) a conjectured formula for the exact Hessian rank that matches experiments, and is also quite close to the upper bounds. (C) experimental evidence that these results essentially hold for neural networks with nonlinear activations as well, even after training. (D) for 1-hidden layer nonlinear networks, under a mild assumption a very weak (but still nontrivial) bound on the rank is obtained. ",
    "This paper studies the rank of Hessian for deep linear networks. Theoretically, with squared loss, and assuming the weight matrices are full-rank, this paper provides rank upper bound for outer-product, functional and full Hessian, and empirically verifies that the bounds are almost tight. This paper further shows empirically that the numerical rank with nonlinear networks can still be captured by the linear rank bound, and that the Hessian rank decreases during training. Finally, Hessian degeneracy results for 1-hidden-layer networks and extension to the case with bias are also provided.",
    "This paper analyzes the rank of the Hessian matrix of fully connected neural networks. Theoretically, for a linear fully-connected neural network with square loss, the authors provided an upper bound for the rank of Hessian with respect to the population loss. They also did many experiments for small neural networks on MNIST and CIFAR-10 to show that their upper bound is almost tight, and works for different types of non-linear activations, losses, and initializations.",
    "This paper derives tight upper bounds on the Hessian rank for deep linear networks. They show that these rank formulae (derived for the linear case) faithfully capture the numerical rank in the non-linear regime. They also demonstrate that these rank bounds hold during the course of training.",
    "This paper makes two contributions: 1 - It presents a framework for measuring linear symmetry based disentanglement (LSBD). In particular, it addresses the challenge that LSBD is only defined with respect to an optimal decomposition of the latent space $Z = Z_1 \\oplus \\ldots \\oplus Z_k$ that needs to be identified by the metric. 2 - The metric serves as additional supervision in the training of a VAE on toy datasets with at most two symmetry transformations. The results show quantitative improvements in terms of disentanglement.",
    "Summary:  This paper aims to operationalize the symmetry-based disentanglement idea proposed in Higgins et al., 2018, and proposes a novel loss function that can be used to both evaluate and learn disentangled representations (including learning from datasets where only a subset of samples are fully labeled). The paper includes some experimental validation of the proposed ideas on synthetic datasets. It also includes cross-comparisons between both the LSBD-based metric and method to state of the art disentangling metrics and methods, which demonstrate the complementary aspects of the LSBD method (e.g., its ability to capture multi-dimensional disentangled factors, for example rotations in a euclidean plane).  Overall, the paper is clearly written and makes a positive contribution in pushing for disentangling metrics that are motivated by a novel formalism. The impact of this paper is slightly limited due to the strength of supervision required (full supervision of all factors of variation) for implementing both the D_LSBD metric and the loss.",
    "This work focuses on developing a metric evaluation metric and a semi-supervised VAE-based model for linear symmetry-based disentanglement (LSBD)[1]. When assuming knowledge of linearly disentangled group representation $\\rho$, the authors deduce that LSBD is fulfilled if the last requirement is met (equivariance of a map h). The authors propose to measure the equivariance by simply quantify the equivariance of the encoding map w.r.t. to the group and observations. Although a straightforward thought, computing the metric is challenging. Therefore, the authors propose an approximation by calculating the dispersion of the inverse group representation obtained through a PCA. Similar to the evaluation metric, the authors propose LSBD-VAE, a semi-supervised version of $\\Delta$-VAE to regularise the latent space based on its dispersion. They show through empirical evaluation that their method outperforms other unsupervised disentanglement approaches w.r.t. to the proposed evaluation metric. ",
    "This paper proposes a new metric $D_{LSBD}$ to measure Linear Symmetry Based Disentanglement. The metric is motivated from an idealized setting before outlining a practical upper bound that can be realized. The authors also apply their new metric as an additional loss term to a $\\Delta$-VAE model and show that it greatly enhances Linear Disentanglement while also agreeing with past notions of Disentanglement. The experiments, while simple and using only $SO(2)$ as a subgroup, are demonstrative of the proposed approach.",
    "The authors make three contributions. 1) They apply the constrained optimization framework for VAE type models to the deep state space model case. 2) They add in the hierarchical prior approach to model the initial distribution for the first state. 3) They propose a model with linear transition matrices given by a neural network weighting learned basis matrices. Auxiliary observation variables are also introduced to allow for a linear observation model along with an extra encoder/decoder. This means filtering and smoothing distributions can be computed analytically.",
    "This paper has two main contributions.  1. The authors adapt REWO for helping with disentanglement of learned representations and improving predictive accuracy 2. The authors replace the RNN encoding of the nonlinearity in [6] by the locally linear model of [11-12] while keeping closed form inference  The authors then illustrate how combining these together leads to better accuracy in learned latent dynamics for a set of models, in particular they show that their approach can recover the unobserved velocity as a latent variable in motion models.",
    "This paper proposes a framework for learning neural network-based state-space models from raw data. In comparison to the standard RNN-based approach [1], there are several modifications: (i) a modified ELBO formulated in the context of a constrained optimization (CO) framework [2]. CO prioritizes reconstruction term at the beginning of the training; (ii) hierarchical prior [3] instead of a simple Gaussian; (iii) a modified Kalman-VAE framework [4] instead of RNN-based transition model. Experimental evidence on pendulum data and the reacher environment indicates that the resulting framework outperforms baselines in predictive modeling and ELBO values.   [1] A Recurrent Latent Variable Model for Sequential Data  [2] Taming VAEs  [3] Learning Hierarchical Priors in VAEs  [4]  A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning",
    "This paper proposes various improvements to deep sequential latent variable models (or deep state space models). Namely, 1) the constrained optimization method from the Taming VAEs paper [Rezende & Viola, 2018], 2) a method for improving empirical priors over the first time step\u2019s latent variable (referred to as VHP), and 3) a new model that combines the locally linear mappings of Karl et al., 2017 and the KVAE variable separation from Fraccaro et al., 2017. These improvements are demonstrated on pendulum and reacher datasets (both with images and joint angles), showing improvements in system identification, prediction accuracy, and the ability to use the state representations from MBRL. Overall, the paper provides several helpful tips for constructing and training deep state space models.",
    "**(motivation)** Many approaches exist to generate counterfactual images, but what should be done when no training data is available? Current approaches lead to adversarial-looking approaches, which are not satisfying enough as an explanation.  **(approach)** The authors use Deep Inversion and a novel objective that ensures the data stays in distribution and propose a method to evaluate the quality of counterfactuals.  **(experiments)** The authors run experiments on Celebi and ISIC.  ",
    "Summary: The paper proposed a novel approach to achieve deep model inversion for a pre-trained deep classifier using the classifier alone, without having access to the training dataset or generative models. Given a query image, the proposed deep model inversion generates a counterfactual explanation that is realistic looking and produces the desired classification outcome.    Earlier work on image synthesis by inverting deep classifiers either creates unrealistic images or creates perturbation of query image that successfully changes the classification decision but resulting pixel-level manipulations are not interpretable/meaningful (similar to an adversarial attack).   The proposed approach has four essential components: 1.\tCounterfactual image is synthesized using an image prior. The authors experimented with an un-trained UNET-based model as a deep image prior (DIP) and Fourier mapping with SIREN activation as implicit neural representation (INR) for mapping noise to the counterfactual image. 2.\tTo ensure high similarity between counterfactual and query images, the authors used ISO to minimize discrepancies over the entire image and LSO to minimize differences between embeddings extracted from different layers of the deep classifier. 3.\tTo ensure that the generated counterfactual image is realistic and lies on the data manifold, the proposed model uses a manifold consistency (MC) loss. The MC-loss is quantified using an auxiliary loss predictor function in DEP or the radial basis kernel similarity in DUQ. Both methods provide ways to capture epistemic uncertainty due to out-of-distribution (OOD) samples. 4.\tThe model uses a functional consistency loss to ensure the counterfactual image produces a desired outcome from the deep classifier. Finally, the model uses progressive optimization to learn the image prior layer-by-layer.  ",
    "The paper proposes a deep inversion approach that uses a pre-trained classifier to generate the counterfactual explanations of a given image. In other words, the method introduces small, discernible perturbations in an image that changes its class while keeping it realistic. The method makes use of certain inductive biases such as strong image priors, manifold consistency objective, and progressive optimization strategy to generate those counterfactual explanations.",
    "In this paper authors propose to generate counterfactuals from a query image and a given trained deep classifier. One is interested to find out a semantically reasonable alternative explanation, where image would be classified from class y to y'. This is all performed without the help of an explicit generator (such as GAN). ",
    "Summary:  This paper considers settings where decisions for individuals are each made by different decision makers (agents). The paper defines the problem of finding a region in feature space in which the agents administer highly varying decisions. For example, perhaps judges mete out different sentences for misdemeanors by young men. The paper defines new causal criteria to characterize such regions in the feature space, where the choice of agent has an effect on the decision. The paper introduces an iterative algorithm to maximize this criteria to identify regions of heterogeneity, and provides theoretical results about the optimality of the proposed algorithm. The paper empirically demonstrates the algorithm on a semi-synthetic dataset and real clinical data about doctor recommendations for diabetic patients.  Contributions:  + A new criteria for defining regions where there is heterogeneity in decisions administered across agents. + Results for estimating the criteria from observational data and an iterative algorithm for optimizing the criteria. + Theoretical results about the algorithm and empirical validation of the algorithm.",
    "In this paper, the authors develop an algorithm for identifying cases (e.g., defendants or patients) on which decision makers (e.g., judges and doctors) \"disagree\" on the decision.   ## Identification The authors consider a setting in which cases are summarized by features $X$. Each case is associated with a decision maker $A$ and a binary decision $Y$. In the pretrial release setting, each case is a defendant, the features $X$ are observable characteristics of the defendant (such as demographics or charge information), the decision maker $A$ is the assigned judge and the binary decision $Y$ is to either release or detain the defendant. The authors define the potential decision Y(a), which describes the decision that would be made by decision maker $a$.   The authors propose a summary measure of agent disagreement using average contrasts of potential decisions across agents given sets of the observable features. In particular, the authors focus on the \"conditional relative agent bias\" as  $$ \\mathbb{E}[Y(a) - Y(\\pi(x) | A = a, X \\in S], $$ where $Y(\\pi(x))$ denotes the expected decision under the assignment mechanism of decision makers to cases. The authors key identification assumption is that decision makers are as-if randomly assigned to cases conditional on the features (i.e., $A \\perp Y(a) \\mid X$). This measures the extent to which decision maker a's average decisions over $X \\in S$ differs from the average decision that is made under the assignment mechanism. In other words, this measure of disagreement depends on the assignment mechanism of agents.  The conditional relative agent bias measures the extent to which a single agent a's decision disagrees relative to the average decision over $X \\in S$. The authors then propose aggregating this measure across agents. For some grouping of agents G, the authors define the estimand $$ Q(S, G) = \\sum_{a : G(a) = 1} P(A = a \\mid X \\in S) \\mathbb{E}[Y(a) - Y(\\pi(x) | A = a, X \\in S]. $$ The authors main identification result (Theorem 1) is to show that if agents are as-if randomly assigned to cases, then this estimand can be identified as the conditional covariance between the observed decision and the agent assignment $$ Q(S, G) = \\mathbb{E}[Cov(Y, G \\mid X ) \\mid X \\in S]. $$  ## Estimating Regions of Heterogeneity. Using this identification result, the authors goal is to search over regions of the feature space $S$ and groupings over agents $G$ to find the combination that maximizes this proposed measure of disagreement. To do so, the authors propose to solve  $$ \\max_{S, G} Q(S,G) \\mbox{ s.t. } P(X \\in S) \\geq \\beta, $$ which requires that the region have probability at least $\\beta$ (a tuning parameter to be specified). The authors develop an iterative algorithm to optimize this objective function, and provide some conditions under which they are able to derive a generalization bound on the solution return after the first iteration (Assumptions 2-4 and Theorem 2).  ## Empirical Applications The authors apply their proposed algorithm in two empirical applications.   First, the authors analyze the behavior of their proposed algorithm in a semi-synthetic experiment that is calibrated to data from Lin et al. (2020) on recidivism risk predictions made by MTurk workers. The authors simulate data from two types of agents that follow different decision rules for detention vs. release. The authors compare their algorithm against direct models that fit logistic regressions for the decision on agent identifiers and observable features (direct models) and TARNet. The authors report that their algorithm does better at recovering the \"region AUC.\"  Second, the authors analyze an observational dataset on medical treatment decisions for diabetes. The data contain information on 3,956 patients and 458 group practices, and the authors search for the region of disagreement across these group practices. ",
    "The authors are concerned with identifying regions in a covariate space. A region is characterised by having high variation in (potential) treatment outcome, as compared to the expected (potential) outcome. A method such as this could be used to identify variation of practice in the legal or medical domain (as indicated by the authors).   This is a relevant topic which the authors rightfully relate to the causal literature. Specifically, the authors chose the potential outcomes model, where the treatment is now a clinician or judge; the outcome is binary (amounting to a decision, e.g. bail or no bail); and the condition is an individual. Contrasting potential outcomes, the authors are interested in learning subsets of X, rather than Y(a).",
    "This paper proposes a new method to identify \"regions of disagreement\" in a setting with human decision-makers assigned to individuals (eg. judges assigned to court cases). The \"regions\" are framed as subgroups of the data (eg. males over 30 years old) which can be interpretable (based on the chosen model). The paper formalizes this task as that of identifying the subgroup where the identity of the specific decision-maker has a causal effect on the decision, proposes an optimization algorithm to find this subgroup, develops generalization bounds (under some simplifying assumptions), and demonstrates compelling performance on semi-synthetic and real-world datasets.",
    "This paper proposes TokenGAN for unconditional image synthesis. The token-based generator takes the learned content tokens and style tokens from the latent space as input, and output a series of style-modulated content tokens, which are then concatenated and reshaped to get the output image. Cross-attention is used to assign the styles to different content tokens. The model adopts the style-based generator idea from StyleGAN and introduces the recent token-based structures and transformers to the traditional style-based generator. Experiments are conducted on FFHQ and LSUN CHURCH datasets and the quantitative results are slightly better than StyleGAN2.",
    "In this paper, a transformer-based modification of the generator in the ubiquitous StyleGAN model is proposed (named _TokenGAN_). More specifically, the entire generator is replaced by a convolution-free architecture where style-content modulation is now modeled using cross-attention layers instead of AdaIN. Similar to the original StyleGAN, this should allow for decoupled control of style and content at different granularities. The paper shows that the proposed approach achieves FID scores comparable to or better than StyleGAN2 for unconditional image synthesis on FFHQ and LSUN-Churches.",
    "This paper proposes to adopt the StyleGAN architecture (i.e. individual styles that affect image generation) to a transformer based model for image generation. The model generates individual image patches which are modulated by style tokens through an attention mechanism. The model is evaluated on the FFHQ and LSUN Church datasets and performs similarly well or better than StyleGAN2 based on FID, precision, and recall.",
    "This paper investigates the application of transformer for image generation by replacing the convolutional layer with MLP(including attention). The motivation provided is the limitation of the style-based generator (e.g.,  StyleGAN), which leverages the single style over multiple image regions, allowing a less entangled representation learning in W and visible artifacts in generated images.  To combat this shortcoming, authors introduce transformer-liked architecture, and successfully generate high-quality images (1024*1024) without touching any convolutional layers in generator.",
    "This paper studies how regularization affects the robust population risk in the overparameterization regime. The authors study the behavior of linear regression and logistic regression under sufficient statistical settings. In particular, even in the noiseless regime, the population robust risk benefits from the regularization, but not the population test risk. The argument is empirically verified. ",
    "The authors analyze the generalization performance of regularized adversarial linear regression and classification models for standard Gaussian data in the overparameterized setting.  The analysis allows for l^2 weight decay as well as l^\\infty perturbation of the inputs.  Using similar methods to Hastie, Montanari, Rosset, and Tibshirani [18] and Javanmard and Soltanolkotabi [19], they are able to develop precise formula for the generalization error in the limit as n/d -> constant as n,d -> infinity.  They demonstrate that non-zero regularization has strictly better generalization in the robust setting.  ",
    "The paper studies the benefits of non-vanishing regularization for improving generalization in overparameterized classification and regression problems. In this setting, previous works studied the implicit bias effect. Particularly, it was shown that training models *without* explicit regularization can still yield good generalization performance. In contrast, in this paper, the authors show that explicit regularization can further improve generalization, especially w.r.t. the adversarial robust risk.",
    "This paper compares the effect of interpolation and regularization on robust generalization. It shows that in the case of regression under squared loss and classification under the log loss when the ground truth is a linear model robust generalization error is smaller for regularized estimators. The robust generalization error is defined as the error under consistent adversarial perturbations. ",
    "The paper proposes an autoencoder architecture that decouples point cloud\u2019s representation into the global latent vector and spherical canonical embedding (in $\\mathbb{S}^2$ space) for each of its points. It is trained in the unsupervised way on the category-specific point clouds. This canonical map turns out to be robust to missing parts due to a specially crafted regulariser. What\u2019s new related to the prior art is that the method is somewhat robust to initial orientation of the shape. The formulation is simple and elegant, however, the method is tested only on synthetic ShapeNet data, so it is unclear whether it would work well in a more practical setting. There are also other methodological concerns and clarity problems.",
    "This paper presents a novel solution for learning dense correspondence between un-aligned 3D shapes in an self-supervised manner. The key contributions this paper is to design a novel canonical space for representing all 3D shapes and learning an auto-encoder to learn a mapping to and from an input point cloud to this canonical space. The effectiveness of this approach is shown for the 3D semantic keypoint transfer and part segmentation transfer tasks across different categories.",
    "The paper suggests an end-to-end learnable method to find dense 3D point correspondences of point clouds. The authors first project the input point clouds onto a canonical spherical UV space, where corresponding points of different shape instances map to similar coordinates. Then, an instance-based feature vector is concatenated with the UV coordinates and fed to a decoder to retrieve the original point cloud. Since the UV coordinates hold correspondence information, the output point cloud is, in fact, an ordered one.",
    "The paper proposes a canonical point autoencoder for the purpose of unsupervised learning dense correspondences between 3D shapes of the same category. The canonical space is defined on a 3D sphere, but with extra flexibility that the template needs not to fully cover the full sphere. This gives the flexibility to generalize to non genus 0 shapes. The proposed method seems to give noticeable improvement over existing ones.",
    "This paper extends the idea of Stochastic Weighting Averaging (SWA) to the context of Domain Generalization (DG). Theoretically, the authors argues that finding a flat minima improves domain generalization. Algorithmically, the authors modify SWA by increasing the number of samples being averaged (e.g. per iteration) and by selecting the interval from where the samples are taken. The proposed algorithm  is evaluated in  the DomainBed benchmark and shows compelling results.",
    "This paper studies how to improve the model performance on domain generalization problems from the perspective of loss landscape. Specifically, the authors propose to apply weight averaging (WA) to find flat minima and demonstrate this could lead to improve model generalization on unseen domains. Theoretically, the authors provide generalization bounds for the proposed method. Empirically, the proposed method achieves better performance on benchmark datasets compared with previous methods.",
    "This paper studies the domain generalization (DG) problem setting and proposes a modification to the stochastic weight averaging (SWA) method that leads to better performance on DG testbeds. The proposed method, named SWAD, uses the same basic idea as SWA but samples parameters more densely and uses additional techniques for preventing the incorporation of overfit parameters. Some theoretical analysis supports the general thrust of seeking flat minima for generalization. The focus of the paper, however, is empirical, as SWAD demonstrates improved performance compared to many prior methods on several DG testbeds. Furthermore, SWAD can be combined with these prior methods, such as CORAL, for even better performance.",
    "This paper provides some theoretical justification that so-called flat solutions exhibit better domain generalization along with a strongly performing training methodology, SWAD, for improving domain generalization. They first prove theorems bounding the domain generalization performance in terms of robust risk minimization. Then they propose an approach to finding flat solutions related to previous work on in distribution generalization, and they thoroughly explore this method with regard to the flatness of solutions found, its domain generalization performance, and also perform ablations of the method.  ",
    "This paper compares 3 kinds of performance predictors, model based predictors, learning curve based predictor and zero nas predictors. They benchmark the performance of all 31 predictors against 5 benchmarks: NAS-Bench101, DARTS, NASBench201 and NLP.  In addition to this, they also incorporate SOTL-E and jacobian variance as addition features to NGBOOST and SemiNAS predictors and demonstrate that it improves the performance over all 3 of them. ",
    "Neural Architecture Search (NAS) aims to find the network architectures with the best accuracies -- or best size/accuracy tradeoffs -- from within a human-defined search space. The submission evaluates a number of different heuristics for ranking different candidate architectures in a search space. The submission claims to evaluate 31 different techniques which fall into several categories (e.g., early stopping, learning curve extrapolation, supervised learning, one-shot models, zero-shot metrics). The submission claims that different techniques work better for different compute budgets (e.g., low setup cost/low search cost vs. high setup cost/high search cost). It also claims that combining techniques from different families (e.g., supervised learning + zero-shot metrics) can lead to better results than using any one technique on its own. Experimental results are reported on NASBench-101, NASBench-201, the NASBench-301/DARTS search space, and NASBench-NLP.",
    "The paper give a large-scale comparison of performance predictors in NAS. The results act as recommendations for the best predictors to use in different settings. The author also show that certain families of predictors can be combined to achieve even better predictive power.",
    "The authors identify and benchmark a plethora of recently proposed techniques for predicting neural network architecture performance on a task without doing a full training run.   They begin by grouping each technique into categories: model-based, learning-curve-based, zero-cost, and weight-sharing. When viewed like this it becomes clear that there is a need for a common benchmark to distinguish the performance of the different approaches.   To compare under one framework, evaluation is done with respect to two variables: initialization time (time spent preparing the model) and query time (time spent retrieving predictions from the model).  The authors then present their own method, OMNI, which performs NAS using a blend of model-based, learning-curve-based, and zero-cost predictors.  ",
    "The paper studies releasing a single sample from a Dirichlet posterior with several variants of differential privacy in the two specific tasks of Dirichlet sampling and private normalized histogram publishing. Both privacy and utility guarantees are analyzed by the authors. The authors compare the results with Gaussian mechanism theoretically and empirically using a simple simulation.",
    "This paper proposes a method for releasing differentially private samples from Dirichlet posterior distribution. Authors present a privacy analysis for their proposed method and demonstrate that the method out performs Gaussian mechanism under certain conditions. Besides the empirical evaluation, authors also derive analytical utility guarantees for the method.",
    "This paper provides a posterior sampling mechanism for the Dirichlet distribution achieving tCDP and approximate DP privacy, relying on modifying the alpha parameters. It includes an application on histogram release.  The response addressed my comments.",
    "This paper studies the privacy of releasing a sample from the Dirichlet posterior. The paper shows for the Dirichlet posterior sampling with prior set to be $\\mathrm{Dirichlet}(\\alpha)$, that Dirichlet posterior sampling  satisfies a version of truncated concentrated Differential Privacy(tCDP). Now, using the relationship between tCDP and approximate DP established in Bun et al. (2018), the paper derives the approximate differential privacy of the Dirichlet Posterior sampling.   Given the result, the paper studies the utility of Dirichlet posterior sampling in 2 contexts: 1. One is interested in sampling for the posterior but changing the prior from $Dirichlet (\\alpha)$ to $Dirichlet (\\alpha\u2019)$, such that $\\alpha_i' > \\alpha_i$ so as to increase the privacy preserving properties of the the posterior sampling. In this context, the paper derives sample complexity bounds such that $D_{KL}(\\mathrm{Dirichlet}(\\mathbf{x} + \\alpha)|| \\mathrm{Dirichlet}(\\mathbf{x} + \\alpha') )<\\varepsilon$. 2. One is interested in releasing the normalized histogram $\\mathbf{p} = \\mathbf{x}/N$. One can privately release it by sampling from the Dirichlet posterior $Y \\sim \\mathrm{Dirichlet}(\\mathbf{x}+ \\alpha)$. The paper derives sample complexity bounds to incur small error $\\ell_\\infty$ norm. Authors also point out that one can get better sample complexity with Gaussian mechanism where Dirichlet posterior sampling outperforms Gaussian mechanism in small data regime.    ",
    "This paper studies the problem of implementing random walks in the Massively Parallel Computation (MPC) model using logarithmic number of rounds.  Very recently, [LMOS20] develop a MPC algorithm that using O(log \\ell) rounds, computes (independent) random walks of length up to \\ell from every node in an arbitrary undirected graph. Their main idea is based on stitching: In order to compute walks of length r, we can stick together two walks of length r/2 and we can do this stitching procedure recursively using O(log \\ell) rounds. One issue with this algorithm is that if we want to do a few walks starting from a few nodes, this algorithm still implements all walks for all nodes. In particular, for say B walks of length \\ell, the algorithm of [LMOS20] uses O(mB) total memory (for all machines).  The current paper claims to solve this issue by proposing a MPC algorithm that uses a total memory of O(mn^{eps}\\ell^4+Bn^{eps}\\ell) and computes B walks of a given vertex r. The number of communication rounds of this new algorithm is slightly more and is O(log(\\ell)/eps).",
    "This submission gives an algorithm in the MPC model (Massively Parallel Computation) for computing independent random walks from a single vertex or a subset of vertices. A previous paper, [LMOS], on the topic gave an algorithm that allowed for generating random walks from all vertices simultaneously (more specifically, the starting points of generated walks were from the stationary distribution). Suppose that you want to generate many random walks from a single vertex. [LMOS] would require generating lots of random walks from all vertices and because of that would require a lot of total space available in the system, and therefore, it would require a lot of machines. The algorithm introduced in this submission can be significantly more space efficient in this type of setting. ",
    "The paper introduces an algorithm for computing multiple random walks in parallel. Performance is measured using the MPC model. The authors also show an interesting application to local graph clustering. The proposed algorithm improves upon memory requirements of SOTA methods at the cost a logarithmically many more iterations.",
    "This paper studies the problem of parallelizing single-source and subset random walk computations. The primary technical contribution is an algorithm with the number of parallel rounds that depends on the length of the random walk in a logarithmic way. In addition, two applications are discussed in the article: personalized PageRank estimation and local clustering.",
    "The manuscript contains a theoretical investigation of the Ising model selection problem.  The task is to recover the support (the graph topology) of the interaction network from observations of Ising configurations.   An objective function in the M-estimator family, named L1-LinR by the authors, is analyzed.  It contains the typical quadratic data-dependent loss from linear regression and an L1 regularization term,  therefore it is a mismatched objective compared to L1-LogR (pseudolikelihood) and the Interaction Screening. ",
    "The submission considers the problem of recovering the underlying graph structure of an Ising model defined on N nodes, given M i.i.d. samples. More specifically, the authors focus on Ising models associated with typical random regular graphs in the paramagnetic phase. Ideas from statistical physics are borrowed to study the performance of an estimator derived from an $\\ell_1$-regularized linear regression problem. It is claimed that using $M = \\mathcal{O}(\\log(N))$ samples is enough to obtain model selection consistency. Non-asymptotic results are also given, and some numerical experiments are presented to support the findings.",
    "The authors study the Ising model selection problem and compute analytically via the replica method the typical performances of the $\\ell_1$-regularized linear regression. They confirm the theoretical result by running a good number of numerical simulations. They demonstrate the sample complexity is such that O(log N) samples are enough to correctly identify the right neighborhood of a generic variable. The theory presented is able to predict the precision and the recall rates also for finite values of the system size and a small number of samples. Moreover, the theory seems to work fine also for graphs with many loops. The methodology of the present work can be extended also to other estimators.",
    "This paper studies the problem of estimating the edge couplings in a Markov random field using ell-one regularized least-squares estimation. It is assumed throughout that all nodes have the same degree and the nonzero coupling have the same value. Using the replica method, the authors derive a set of couple equations of state (EOS), which depend on the underlying parameters of the model (e.g., the degree and coupling strength),  the ratio between the number of samples and the number of nodes, and the spectral density of the covariance of the resulting MRF. By analyzing the solutions to the equations, the authors provide numerical predictions of the reconstruction performance (e.g, precision and recall) in the limit of high dimension. Further analysis of these expressions gives a sharp predicition for the number of samples needed for exact recovery as a function of the the degree and the coupling strength. Additionally, the authors suggest a modification of the EOS that uses the observed data to produce more accurate predictions. Because the analysis depends on the replica method the results are not rigorous. The accuracy of the theoretical analysis is supported by numerical simulations. ",
    "The authors study the fuzzy k-means problem in the presence of a cluster membership oracle. For the fuzzy k-means problem this is an oracle that returns the i-th entry in the j-th cluster membership vector. The authors aim at polynomial time algorithms that in the presence of a  sublinear number of membership queries.   Under some assumptions on the structure of the input instances they give different algorithms that achieve this goal. The first algorithm takes a uniform random sample and then queries the oracle for cluster memberships. Based on the results, it guesses the cluster centers. Then it exploits the structural assumption and the oracle to compute the clusters. A second algorithm is given that uses a different method to compute the clustering. It also samples a subset of the input data and then queries the oracle to identify the cluster with the largest membership weight in the sample. Then it computes the cluster of this center. After identifying the first cluster the algorithm iterates a sequential algorithm that always predicts the center of the next largest remaining cluster.",
    "Given a set of points X in R^d, a fuzzy k-means clustering of X is an assignments of k weights in [0,1] to every point in X, so that the i-th weight represents \"how much\" that point belongs to the i-th cluster. The problem tackled in this work is to recover a hidden fuzzy k-mean clustering of a given set X by querying some similarity oracle that answers queries in the form \"how similar are the weight vectors of these two points?\". The authors develop an algorithm to approximately recover the hidden clustering (in a well-defined optimization sense) with a number of queries that grows as log |X|, and that depends polynomially on other parameters (including the desired accuracy).  EDIT: I think the authors for their response; after reading it, I will leave my rating unchanged.",
    "This work gives algorithm for the soft k-means problem using similarity queries. This means that the clustering algorithm is allowed to make queries of the form \"how similar are two data items\". There have been recent results in this setting for k-means/median problems. This paper extends such results in the context of the soft k-means problem. The soft k-means problem is a generalisation of the k-means problem where assignment of a point to a center is on 0/1. So, the goal is to output k centres and membership weights U_{ij} (the degree of assignment of point i to center j).",
    "The paper extends the results in Ashtiani, Hassan, Shrinu Kushagra, and Shai Ben-David. \"Clustering with Same-Cluster Queries.\" NeurIPS.2016 into the context of fuzzy clustering where assignments of points to centers are fractional. Analogous to the same-cluster queries proposed in the original paper, this paper proposed using similarity queries which would return a scalar reprenseting the similarity of the memberships of any two points (this is the inner product of the two membership vectors). The work first states that the similarity queries and the seemingly stronger membership queries (which directly return the fractional assignment of a point to a cluster) can be converted into each other. Then, given any \"true\" underlying fuzzy clustering solution, the paper formally defines how to measure the proximity of any fuzzy clustering solution to this underlying benchmark, and relates this proximity to a previous proposed performance metric for fuzzy clustering. The main body of the paper focuses on developing a fuzzy clustering algorithm based on similarity queries and providing theoretical guarantees of the number of queries needed, and how close the constructed fuzzy clustering is to the underlying clustering.",
    "This paper presents the idea of self-consistent reinforcement learning.  By enforcing \"consistency\" between value functions and approximate  (learned) models, a model-based learning algorithm can use synthetic experience generated from the approximate model.  This paper presents a few minor variations on this theme, and explores the results empirically.",
    "This paper considers the problem of model-based reinforcement learning. The authors introduce a new loss, which drives the learned model and value function to be consistent with each other, rather than the model being consistent with the real environment and the value function being consistent with the real environment and the learned model. Experiments show that the proposed self-consistency loss can improve the sample efficiency and final performance. ",
    "This work proposes to improve model-based RL methods by enforcing the model and value learned to be \u201cself-consistent\u201d, i.e. to satisfy the Bellman eqn where both the Bellman operator and value function are defined in terms of the model. The motivation behind this is that in classic MBRL, the model and value function are learned separately, and the value function is typically learned to be consistent with the model but not vice versa. The authors propose to enforce self-consistency by adding a \"self-consistency loss\u201d (L_SC) to the base loss and jointly learning the model and value functions. L_SC is the squared TD error with a stop-gradient on the target and is calculated using rollouts from the model. Although in MuZero/Muesli the model and value functions are learned jointly as well, the targets of the loss are all defined with respect to data from the true environment and there is not term enforcing the \u201cself-consistency\u201d between model and value functions. Experimental evaluations on a selection of Atari games show that jointly updating the model and value functions with the additional L_SC term leads to improved sample efficiency as compared to Dyna and a model-free baseline. The authors also empirically study the search control problem.",
    "The paper offers a new approach to model-based reinforcement learning with their idea of self-consistency of models and values. In the traditional (Dyna) model-based RL paradigm, an approximate model is learned with ground truth transitions and values (and policies) are updated to be consistent with the learned model. The proposed self-consistency update however, formulates a new update to the approximate model so as to make it consistent with the current value estimates using completely imagined (virtual) experience. This update is inspired by minimizing the bellman residual of the approximate model and value for a given policy (since for the true value and model, the bellman equation is satisfied and the residual is zero). An empirical analysis is presented for a set of variations of the proposed self-consistency objective with two types of (grounded) model updates -- MLE (maximum-likelihood) and value equivalent updates. In both tabular and function approximate settings, improved sample efficiency is demonstrated by the proposed method.",
    "This paper investigates the effect of episode difficulty and sampling schemes on the performance of few-shot classification algorithms. It defines difficulty based on the negative log predictive likelihood of the few-shot learner and proposes to use importance sampling to mimic various sampling strategies. Experiments demonstrate that episodic difficulty is (a) approximately normally distributed, (b) tends to transfer across architectures and learning algorithms, (c) tends to be consistent over the course of training, and (d) that a uniform sampling scheme over difficulty tends to produce the best results. An online scheme for computing importance weights is also proposed.   === Post-rebuttal ===  I have read the authors' response and other reviews and will maintain my original rating.",
    "This paper explores episode/task difficulty in few-shot learning. The task difficulty is defined as the negative log-likelihood over the query set given the support set and model parameters. The authors find evidence that episode difficulty likely follows a normal distribution and proposes a new method, called UNIFORM, based on importance sampling. The new method achieves similar or better performance than other sampling procedures (EASY, HARD, and CURRICULUM). The paper also presents two variants of UNIFORM: offline and online. ",
    "This submission studies episodic sampling, which is used to sample datasets (consisting of support and query sets) for training meta-learning models. The authors define a notion of episodic difficulty (the negative log-likelihood of the query set given the support set and model parameters) and propose using importance sampling to train using several different types of episode-sampling strategies for meta-training. By using importance sampling, there is no sampling required for the target distribution but just weighting the episode loss based on the proposal and target distribution. They conduct experiments both to confirm some of their assumptions that are critical for their proposal (that episodic difficulty is normally distributed) and to show how their episodic sampling strategies compare against random episodic sampling, which is the dominant strategy used by work in this area. ",
    "Meta-learning (few-shot learning) algorithms, in general, equally treat all tasks for the training process. Tasks are sampled uniformly at random. This paper proposes a novel meta-learning framework that controls the task sampling probabilities according to difficulties. This paper measures the difficulties of tasks using the negative log-likelihood and leverages the difficulties to introduce different weights to tasks. The main idea of the learning framework is that the prior of the difficulties follows a normal distribution while the target sampling distribution could be uniform or some other interesting forms. Then, important sampling provides different weights to different tasks. From experiments, the uniform target distribution shows good results. ",
    "The paper studies multinomial logistic (MNL) regression bandits, a generalization of binary logistic bandits. It differs from previous works on MNL bandits by considering a different decision-making process. That is, the authors do not address the combinatorial action selection of previous MNL bandits, but rather study the problem setting where the agent offers a single item, but with K different outcomes.   The paper introduces a UCB-based algorithm for this problem, for which the authors establish a sub-linear regret bound. By building on recent advances in logistic bandits, they improve the prohibitive impact of the constant \\kappa from both the design of their algorithm and its theoretical guarantees.",
    "This paper presents MNL-UCB Algorithm for contextual MNL bandits problem. At every step, the algorithm estimates a K-tuple of parameter vectors in the confidence region. Specifically, they prove that the regret of MNL-UCB scales as \\tilde{O}(dK\\sqrt{\\kappa}\\sqrt{T}) where $\\kappa$ is a parameter that captures the degree of (non)-smoothness of the MNL model. It improves the constant from linear in \\kappa to \\sqrt{\\kappa}. They further improved algorithm that achieves a regret bound with problem-dependent constant \\kappa being pushed into a second order term.  Compared to the most existing work, a major difference is that each choice is associated with a different parameter so a matrix of parameters needs to be learned. ",
    "This paper considers a version of stochastic contextual bandits where the rewards are drawn from a discrete distribution governed by a multionimal logit model. This setting is motivated by applications in online advertising where the user may give various feedbacks in the face of a recommendation beyond a binary \u2018clicked\u2019 or \u2018did not click\u2019 \u2013 e.g. \u2018show me again later\u2019, \u2018never show me again\u2019. The authors propose and analyse a UCB algorithm for this problem with the confidence sets being based on the work of Faury et al. (2020, ICML) and the regret analysis being based on that of Abbasi-Yadkori et al. (2011, NeurIPS). The particular advantage of utilising the concentration results of Faury et al is that the regret of the resulting algorithm scales favourably (square root order) with respect to a parameter $\\kappa$ characterising the smoothness of the logit function around the true parameter. A further algorithm whose dependence on $\\kappa$ is relegated to lower order terms w.r.t. the horizon is also developed \u2013 however this approach is computationally intractable. In the related (binary) logistic bandit setting, some popular algorithms have been shown to have exponential order dependence on this parameter and the design of algorithms which are robust to its value is useful. It may be useful to note that this version of a multinomial bandit is different from the combinatorial problem in the dynamic assortment selection literature (e.g. Agrawal et al (2017, 2019)) where the different outcomes represent different items.   ",
    "The paper studies multinomial logistic regression bandit problem, where the number of outcomes can be greater than two. This is an extension of the well-studied generalized linear bandit problem with two outcomes (e.g., clicks and no-clicks). The authors first propose the problem setup with real-life motivated scenarios and then propose a UCB based algorithm to minimize cumulative regret. The authors analyze its performance and derive an upper bound of \\tilde{O}(dK\\sqrt{\\kappa T}), where d is the dimension of the action space, (K + 1) is the number of outcomes, T is the number of interactions, and \\kappa is the degree of non-smoothness, which is inherent to the multi-nomial problem. At the end, the authors provide a simulation based study which supports their theoretical insights.  ",
    "The paper addresses limitation in max-entropy RL frameworks. These frameworks usually add a regularization term to the reward function to increase policy entropy to encourage exploration, but the effect can be limited in states where the Q-function dominates the expression. The authors propose a new objective that better encourages RL agents to visit rare states with low entropy, and show empirically that their method is able to outperform the baselines used for comparison.",
    "This paper proposes a conjecture that the agent should visit the state with low entropy and then do the exploration of this low entropy state with the maximum-entropy principle. To prove this conjecture, the author does a simple experiment on the 4-room maze and illustrates the empirical entropy of the action at different states. There is an interesting observation that the rarely visited states have low entropy maybe due to the function approximation error or off-policy learning explained by the author. Given this observation, the author proposes an algorithm which penalizes the reward with negative entropy \uff08eq7) . Based on this modified Q function, the agent does the policy improvement as the original soft-actor-critic algorithm. The empirical result shows that the proposed algorithm outperforms the baselines such as SAC and many others.",
    "The authors describe a positive feedback loop, that arises in SAC-based implementation of the maximum entropy reinforcement learning and hinders efficient exploration. Q values of frequently visited states are updated more, because these states are stored more into the replay buffer. The policy update increases the entropy of the visited states, i.e. if a high entropy is rewarded in the policy the frequently visited states will be selected even more. In the paper, Max-Min Entropy Rl is proposed that is supposed to break the unwanted feedback loop. It considerably improved the empirical performance in common Maze tasks and Mujoco tasks.",
    "This paper investigates the undesired behavior of soft actor-critic (SAC) algorithm that implementing maximum entropy reinforcement learning (RL).   One of the main contributions of this paper is the empirical investigation of the undesired behavior of SAC. By running SAC with function approximation on no-reward environment, the authors illustrate that the policy obtained by SAC failed to maximize the entropy, while maximizing the entropy is the optimal situation in no-reward environment and the theoretical study of SAC in finite MDP setups guarantees its optimal convergence. The authors pointed out a possible defect in SAC with function approximation: Q value of already visited states tend to be greater than the other states because the policy update increases the entropy of the visited states.   The second contribution is the proposal of a solution to the above mentioned defect. The authors propose Max-Min Entropy RL (MME). To improve the exploration, the soft Q-function has been revised. Instead of adding the entropy term to the Q-function, the revised soft Q-function subtracts the entropy, if I borrow the authors statement, to enhance the chance to visit rare states with low entropy. This is, however, counter intuitive to me as I will describe in the main review part.  The proposed approach has been tested on sparse mujoco tasks and delayed mujoco tasks, where the environments have sparse-reward shapes, as well as on some standard mujoco environments with dense rewards. The algorithm has been compared to different SOTA approaches. Promising performance has been observed.  ",
    "The authors tackle the problem of time evolution of discrete sets through the view of continuous-time markov chains. The authors provide a theoretical justification of why these problems in general underspecified in the setting of cross-sectional data. They go on to demonstrate that the underspecification can be overcome by use of additional items / features that can help determine time order by deriving a bound on the mean and variance of the observed time for these additional items. An approximate formulation for likelihood maximization is then presented without any assumptions of prior knowledge of the additional items or the structure of the additional items. The theoretical framework is then tested using simulation studies and demonstrate that accuracy of state sequence recovery can be significantly improved with use of the additional items. The framework is also evaluated using a real world cancer dataset from TCGA by ordering of pairs of mutation and copy number aberration events. ",
    "The authors model the time evolution of discrete states (e.g. genetic mutations) using a continuous-time Markov chains. They show that the resulting learning task is generally underspecified given cross-sectional data. The authors suggest including additional independent items that can help determine time order, and resolve this underspecification.  The authors implement an approximate likelihood maximization method for learning continuous-time Markov chains, which shows good performance on high-dimensional data, is faster than competing methods, and shows promising results on synthetic and real cancer data.",
    "This paper describes a continuous-time Markov Chain method for modeling the time evolution of events. By including independent items the authors are able to increase the limit on the number of items modeled. This research is particularly relevant as larger single-cell sequencing data sets are being collected.",
    "This paper deals with learning a particular class of multi-component continuous time Markov chains (CTMC) when time stamps are unobserved in the data. In this class binary components change their state irreversibly, rates follow a pairwise interaction model and one component changes at a time. The authors show that modeling independent elements provides information about the posterior distribution of observation time and provide an efficient stochastic approximation to the likelihood\u2019s gradient.",
    "This paper proposes a self-supervised pre-training framework for document understanding called UniDoc. UniDoc takes multimodal data (image feature and text feature from document) as input and uses gated cross attention for learning cross-modal correlation. The superiority of UniDoc has been empirically shown on several downstream tasks.",
    "This paper proposes a new unified framework for pre-training image/text encoders for capturing both visual and textual features in documents. The main Transformer model is pre-trained with multimodal embeddings as input features (visual & textual features) through three pre-training tasks: Masked Sentence Modeling, Visual Contrastive Learning, and Vision-Language Alignment. The pre-trained model can be fine-tuned on downstream tasks on which the proposed UniDoc model outperforms baselines.",
    "This paper proposes a multi-modal pretraining method for document understanding. It involves a new hierarchical model architecture and three pretraining tasks. It compares with previous SOTA methods on three tasks and achieves stronger performance on two of them.   The major contribution is the newly proposed multi-modal pretraining tasks and the architecture is a combinations of models from both domains.",
    "This paper presents UniDoc as a multimodal pre-trained model for document understanding. UniDoc consists of 3 layers: a feature extraction layer, which extracts sentence embeddings and region embeddings from the original document; a fusion layer, which fuses textual and visual information based on a gated cross-attention mechanism; a task layer, which uses 3 tasks as pre-training objectives to optimize model parameters. Evaluations are conducted on 4 downstream tasks, including Form Understanding, Receipt Understanding, Document Classification and Document Object Detection. Comparing to several SOTA baselines, UniDoc performs better on Form Understanding and Receipt Understanding, but worse on Document Classification. The paper also includes some ablation studies to investigate the effects of V/L/V+L, pre-training tasks and visual backbones, and some interesting future directions.  ",
    "The authors of this paper consider the individual fair k-clustering problem, as introduced by Jung et al. [FORC 19]. In this model, for every point $j$ there is a given radius $r_j$, and the goal is to choose a set of centers such that each point has an open center within distance $r_j$ from it, and also one of the standard clustering objective functions is minimized.  Specifically, under the k-median and k-means objectives, the authors provide improved guarantees compared to the state of the art results (Mahabadi and Vakilian [ICML 2020]). For the k-median objective, they give an $(8,8)$-bicriteria algorithm, while the best known result was an $(84,7)$ one. For k-means their result is an $(4,8)$-bicriteria algorithm, while the result of Mahabadi and Vakilian was a $(\\gamma,7)$ one, with $\\gamma$ being a very large constant. (an $(a,b)$-bicriteria solution has objective cost at most $a$ times the optimal, and for every $j$ it has an open center within distance at most $b \\cdot r_j$ from it).  The authors achieve their results via standard LP-rounding techniques.",
    "This paper introduces a new algorithm for fair k-clustering problem(specifically when cost is measure with l_p norm for different p values) based on LP rounding. It provides a bi-criteria approximation guarantee for the clustering objective and experiments are provided to validate the theoretical properties. It is also shown how the runtime of the algorithm can be improved using sparsification with minimal effects on the objective.",
    "The paper studies the problem of \\ell_p norm and center-based clustering with a fairness consistent. The fairness constraint roughly says that no point should be further from its assigned center than it is from its (n/k)-th furthest neighbor. The authors consider a Linear Programming based (approximation) algorithm for this problem. ",
    "This submission proposes an approximation algorithm for individual fair k-clustering in a metric space. Here, individual fairness means that each point v has an individual radius $r(v)$ and we require an open facility within radius $r(v)$ of $v$. We may use the radius $r(v)$ to provide each point $v$ with a \"fair share\" of its assigned facility by, for instance, choosing $r(v)$ as the smallest radius such that $n/k$ points lie within radius $r(v)$ of $v$; as originally proposed by Jung, Kannan, and Lutz.   The approximation algorithm is the main contribution of the submission. It works for any p-norm objective and is bi-criterial, guaranteeing an $2^{1+2/p}$-approximation of the  objective while ensuring an open facility within radius $8r(v)$ of each point $v$. However, it requires a metric space which means, in particular, that all facilities/centers have to be chosen from the point set.  The algorithm roughly works in the following way: First, the authors compute an optimum solution to a linear programming relaxation of the problem. The solution is turned into an input for a filter function by Plesnik/Rita, Moro and Cortez; this function replaces the original point set by a smaller set of representatives. In the original version of the filter, the function may be run until only $k$ representatives remain (a point may represent another if it can serve as the point's facility; hence, in the original filter, the representatives are then chosen as the facilities to open). In this case, however, it may be that the filter stops early as the fairness restriction on the connection radius may make it impossible to cover all points with $k$ representatives. Hence, a final step is required to reduce the set of representatives down to $k$ points. This is done via an LP-rounding algorithm and turns out to be a substantial amount of work. Finally, in order to improve the running time of the algorithm, the authors propose a sparsification technique for the LP-relaxation (whose size is otherwise quadratic in the number of points and could be prohibitive for larger point sets).  An empirical part shows improvements over the previous approach.",
    "This paper studies several methods for speeding up / reducing memory of computing max k-way cuts, via methods such as sampling and sparsification. They rigorously prove that the semi-definite program can be approximated to an error of \\epsilon in about m \\epsilon^{-2} space, and furthermore, the quality of approximations are preserved with the use of spectral graph sparsifiers.  A Matlab implemention of this method is then tested on a multitude of clustering instances, showing that the memory usage is quite low, but at a cost of a fairly large (between 15~40%) relative error.",
    "The paper presents an algorithm for approximating MAX-$k$-CUT to within the SDP bound that avoids the $\\Omega(n^2)$ memory requirement of the SDP formulation. The improvement is to $O(n+m)$ space. Here, $n$ is the number of nodes of the input graph and $m$ is the number of edges. Coupled with known sparsification techniques, the algorithm runs using $O(n\\log n)$ space (hiding a factor that depends on how close one gets to the SDP guarantee. The algorithm uses Frank-Wolfe with Gaussian sampling on a relaxation that replaces the constraints by some regularization. Similar results apply to correlation clustering, though such bounds were known previously.",
    "The methods with best approximation guarantees for max-K-cut and the max-agree variant  of correlation clustering involve solving semidefinte programs (SDPs) with $n^2$ variables and $n^2$ constraints, which use  a lot of memory. \tThis paper proposes a modified polynomial-time Gaussian sampling-based algorithms from [27] that reduce the memory from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n + |E|)$ and nearly achieve the best approximation guarantees. The paper further extend their approach to the dense graphs cases by combining it with graph sparsification and the memory is reduced to $\\mathcal{O}(nlog n / \\tau^2)$.",
    "The authors study two graph partitioning problems MAX-K-CUT and correlation clustering (MAX-AGREE) under a limited memory setting. The authors propose polytime sampling-based algorithms for these two problems that require $O(n + |E|)$ memory while preserving the best approximation guarantees ($n$ is the number of vertices and $E$ is the edge set). In addition, for the case of dense graphs the authors eliminate the quadratic memory requirements by utilizing spectral sparsification results in the streaming model of computation.  ",
    "This paper proposes a method for video prediction that relies on a newly proposed Motion-Aware Unit (MAU). MAU acts as a temporal receptive field based on an attention mechanism that is used to aggregate features from previous frames in order to predict future frames. The aggregate features are combined with \u201ccontent\u201d features extracted from the last observed frame and the decoder is connected to the encoder via an \u201cInformation recalling scheme\u201d that directly passes the last observed frame features from each layer of the encoder to each layer of the decoder. In experiments, the authors show superior performance against the baselines pixel based metrics and a perceptual metric.",
    "The paper proposes the Motion-Aware Unit (MAU) for video prediction. This module attempts to model the temporal information in videos by enlarging the temporal receptive field and aggregating it through an attention mechanism. The proposed module is employed in the bottleneck part of an autoencoder where the spatial and temporal information are combined at different MAU layers. The proposed method is compared to previous works on several benchmarks for next frames prediction and early action recognition showing state-of-the-art results.",
    "In this work, the authors introduce a Motion-Aware Unit (MAU) for video prediction. Basically, they discover the previous motion and aggregate it via attention module and fusion module. In the attention module, they compute correlation between spatial states and use it as attention for aggregation the previous temporal states. In the fusion module, they design spatial and temporal update gates for fusing attentive temporal state and current spatial state.",
    "This paper proposes a Motion-Aware Unit (MAU) for video prediction tasks. The MAU includes two modules, the attention module and the fusion module. The attention module aims to learn the correlation between the current spatial state and previous spatial states. The learnt attention map can be used for augmenting the motion information (AMI). The fusion module is used for aggregating the augmented motion information (AMI) and current spatial state. The authors have demonstrated superior performance compared to state-of-the-arts.",
    "This paper studies sample efficient RL with two-layer neural network function approximation with a generative model. In particular, they prove that they can learn an optimal policy with poly samples with only realizability in deterministic MDP, and that the sample complexity for learning a near-optimal policy in stochastic MDPs is in an order of $\\epsilon^{-2}$ in two cases: policy completeness assumption and Bellman completeness assumption. The algorithms they use are based on simple (non-optimistic) value regression. ",
    "This paper studies reinforcement learning with a 1-hidden layer neural network and low-rank polynomial function approximation schemes.   Under mostly standard assumptions about realizability, completness etc, they provide algorithms mainly focusing on sample complexity in cases when there is access to a perfect generative model of the transitions and in the fully online setting, where planning is not possible in episodic reinforcement learning.  They improve upon the sample complexity with respect to existing baselines for the respective function approximation schemes.",
    "The paper considers RL with neural function approximation, extending significantly previous works that only focuses on linear feature approximation. In particular, the authors propose (1) an efficient algorithm using two-layer NNs in a generative model assuming completeness, and (2) an efficient algorithm with two-layer NNs but only assuming realizability.  The results significantly extends prior research on linear methods, or methods with bounded eluder dimension.",
    "This paper focuses on analyzing sampling efficiency of nonlinear reinforcement learning with neural network approximations of the $Q$ function. It reduces the sampling complexity from $O(d^{\\text{poly}(1/\\epsilon)})$ to $O(\\text{poly}(d) \\exp(k))$ where $k$ is the width of the hidden layer of a two-layer fully connected neural network. The idea is described accurately and the paper is overall well written. ",
    "The authors of this paper investigate how generalization is affected by varying the training and testing data splits in deep metric learning (DML). Specifically, they create train/test splits (splitting on classes) which increase in difficulty (meaning that the distributions are more different) and evaluate DML generalization. To measure the gap between train and test distributions, they use FID with ResNet-50. Experimentally, they use popular benchmarks and the Recall@k metric to show that performance decreases as the train/test FID distances become larger. This, and other experiments, show that using a fixed train/test split can lead to misleading conclusions about generalization.",
    "This paper proposed a new benchmark for deep metric learning under varying degree of distribution shift. First, it introduces a method for creating train/test split with increasing FID --- thereby increasing distribution shift between train and test. Second, various metric learning methods are compared under the benchmarks of varying difficulties.",
    "The authors present a new benchmark for deep metric learning algorithms, particularly for zero-shot tasks, in order to reflect their generalization under out-of-distribution shifts performance. They propose a novel way of splitting train and test data with increasing difficulty(the gap(distribution shift) between train and test get higher). FID score is chosen to determine the distribution shift between train and test. After an initial split is chosen, the classes are exchanged between the train and test data to obtain a higher FID measure at each time iteratively. The authors suggest to use ROC curve to obtain a one single criteria, while keeping the results for each split in order to observe the performance based on task difficulty. They include experimental analysis on their proposed criteria and show results for some existing methods and architectures. The authors also analyze query-support framework in few-shot learning and its effect on the generalization performance.",
    "This work proposes a new way to measure OOD performance of metric-learning algorithms. It introduces a proxy-metric for measuring ranking dataset generalization difficulty based on FID score. They construct several train/test splits of increasing difficulty based on this score. They show that splits constructed in such a way are well correlated with performance, thus validating the proposed proxy-metric of OOD generalization difficulty.  Several experiments are performed to assess the performance of modern metric learning methods. An AUC type score over all splits (difficulties) is proposed as an overall score for various methods. Finally, additional experiments that include increasing network capacity, using self-supervised pre-trained models, and fine-tuning with few-shot learning are presented. ",
    "This paper presents a data-driven approach to model selection for unsupervised outlier detection. The proposed method, METAOD takes a large number of training datasets with outlier labels and a pool of outlier detection models (methods plus their parameters) and uses a matrix factorization method to learn a model performance predictor, which, for given a test dataset, can predict/select a high performing model from the model pool without requiring test time model evaluation.  The performance of METAOD is evaluated with two implementations with the same pool of 300+ models (8 distinct outlier detection methods with different parameter configurations) but two different groups of training datasets. ",
    "The paper proposes a model selection approach called METAOD for outlier detection. METAOD maintains historical performances of various outlier detection models on different datasets, where the performance of a detection model on a new dataset is estimated based on the historical information. The setting is thus similar to meta-learning. METAOD is motivated by Collaborative Filtering, where the compatibility of a user (i.e., a dataset) and an item (i.e., a model) is estimated. A set of meta-features are crafted for charactering a dataset. Experiments show that METAOD benefits outlier detection model selection, compared with no model-selection baselines.",
    "The paper proposes a method, named MetaOD, which for each input data set selects the most suited outlier detection model together with its relevant hyper-parameter values from a set of given models. The selection is done in a supervised manner. MetaOD works as follows. During the meta-training stage, it considers a set of $m$ models $M = \\{M_1, ..., M_m\\}$ and a set of $n$ data sets $D = \\{D_1, ..., D_n\\}$. Each model $M_i$ includes model architecture and model configuration (hyper-parameter values). MetaOD computes performance matrix $P$ where cell $P_{ij}$ is the performance of method $M_j$ on data set $D_i$. Then it learns a data matrix $U \\in R^{n \\times k}$ and a model matrix $V \\in R^{m \\times k}$ where $U_i \\times V_j^T$ approximates $P_{ij}$. The functions learnt from $U$ and the matrix $V$ are then used during test time to choose the best model (together with its configuration) for each input data set.",
    "This paper proposes a data-driven method, METAOD to unsupervised outlier model selection problem based on meta-learning. METAOD makes use of many detection models on historical outlier detection benchmark datasets and selects an effective model to be employed on a new dataset without. Authors introduce meta-features that quantify the outlying characteristics of a dataset. Experiments have shown the promise of METAOD. The authors have implemented an open-source tool METAOD and our meta-learning database for practical use. ",
    "This paper provides a method for addressing the \"prediction + programming\" problem in the case where the programming problem contains a $\\max(z,0)$ term in the objective. To do so, the authors rewrite the optimization problem as an unconstrained optimization problem by converting all hard constraints of the optimization problem to soft constraints in the objective. They then pick the coefficients of those soft constraints in a way that is meant to prevent constraint violations, and then relax these soft constraints via a surrogate function. They then embed the resultant approximate optimization problem within a method where some $\\theta$ is output by a neural network, the approximate optimization problem is solved for that value of $\\theta$, and gradients are updated by differentiating end-to-end through the approximate optimization problem. The authors demonstrate their method on three synthetic settings, and report improved performance over two-stage methods and SPO+.",
    "This paper presents an approach for \"predict, then optimize\" problems that is amenable to derivative-based learning methods. It involves converting hard constraints into soft constraints (i.e. implicitly enforced through objective penalization). The main theoretical contributions are bounds on the magnitude of objective change that can be attributed to infeasibility with respect to the original hard constraints.",
    "The paper develops a surrogate function with closed-form solution for objective functions with \"soft constraints,\" here defined as those with the term $\\alpha^T \\\\max\\\\{0,z(x)\\\\}$ for affine $z$, component-wise $\\\\max$, and $\\alpha > 0$. The goal is to apply such functions within the context of smart \"predict-then-optimize\" (SPO) by also relaxing the hard constraints with a sufficiently large penalty $\\alpha$. To develop their surrogate, the authors evaluate bounds on the utility gained when violating the soft constraints using primarly a geometric perspective, specifically evaluating the angles or corners of infeasible points with respect to the convex hull of feasible solutions (and related properties). Numerical results compare their approach with the standard SPO+ loss function and a DF metric for portfolio optimization.",
    "The paper proposes a new method to integrate soft constraints in the predict+programming paradigm that focuses on mathematical programming models with a prediction component that needs to be considered during optimization/solving. The new method works by reformulating the problem into piecewise linear constraints and then optimizing a surrogate for the original problem. A theoretical analysis and motivation is provided as well as an experimental evaluation that underlines the effectiveness of the method.",
    "The paper proposes Dropout Graph Neural Networks (DropGNNs), an approach that utlizes dropout in a way that allows GNNs to be more expressive. In DropGNN, multiple runs  are conducted where, in each run, the nodes of the graph are dropped out with a certain small probability and passed through a  GNN to produce a distinct embedding. The embeddings of the multiple runs are aggregated (with a sum) after a non-linear  transformation of the node features. DropGNNs achieve competitive results on synthetic and real-world datasets.  ",
    "This paper proposes DropGNN, a novel technique for improving the expressive power of graph neural networks. DropGNN is simple. It removes nodes randomly (even in test time unlike dropout) and aggregates the results of several runs. This paper provides some examples and theoretical results that show when DropGNN improves its expressive power compared to vanilla GNN.",
    "The authors propose DropGNN, a GNN exension where multiple forward passes of the model are aggregated. In each of the passes, each node in the graph is dropped with probability $p$ independently. Aggregating a sufficiently large number of dropout combinations effectively breaks symmetries that lead to traditional GNNs to not be able to distinguish between certain neighborhoods. The authors present theoretical results that DropGNNs can distinguish neighborhoods that traditional GNNs (e.g., GIN) cannot. The authors evaluate their method on both synthetic and real-world datasets.",
    "The paper suggests a method to the GNN toolbox. The proposed method applies multiple, independent evaluations of a graph, each including random dropout applied to the graph nodes. The different evaluations are then aggregated to a single classification/regression result.",
    "This paper presented a Dual-stream Network for image classification. It combines the representation of local and global pattern features by using self-attention and convolution together. It also proposed an Intrascale Propagation module to process two different resolutions in each block.  In addition, it also introduced such block to FPN to demonstrate the benefit.",
    "This paper proposes Dual-stream Network (DS-Net) for visual recognition. The two streams correspond to high-resolution convolutions for local features and low-resolution vision transformers for global patterns. The paper proposes an intra-scale propagation module to process the two streams and an inter-scale alignment module to fuse them into one. For object detection, it designs a Dual-stream FPN (DS-FPN) that adds dual-stream blocks to every feature pyramid. The proposed DS-Net achieves good results for image classification, object detection, and instance segmentation.",
    "This paper proposes a hybrid convolution+transformer model for 2d images. To summarize the model, it is broken up into 4 stages that operate at successively higher resolutions much like a typical Resnet.  At each stage, there are two parallel paths, one that apples a depthwise convolution at high resolution (capturing local effects), and one that applies a standard a multi-headed attention at coarse (capturing global effects) resolution.  These paths are fused by a final attention module which allows for local to attend to global and vice versa.  Another contribution is the DS-FPN (which simply slots one of the above \u201cdual stream\u201d modules into the lateral paths of a typical FPN). Experiments show strong performance on both image classification for ImageNet and detection/segmentation for COCO (relative to competing Transformer-only models like Deit). ",
    "The authors propose a new architecture for visual recognition. Like standard convolutional architectures, the representation is structured in a multi-scale hierarchy, with deeper layers being coarser and more abstract. At every level of the hierarchy, a coarse, global representation is appended and simultaneously processed with the more fine-grained, local one. Local features are processed with depth-wise convolutions, and global ones with multi-head self-attention. In addition to this separate processing of local and global features, they are co-processed by cross-attending between local and global features.   In addition to this recognition backbone, the authors adapt Feature Pyramid Networks in a similar spirit. Whereas FPN's use dense convolutions to fuse an intermediate representation with a coarser one, the authors instead use the proposed \"Dual-Stream\" block, combining local depth-wise convolutions, global self-attention, and local/global cross-attention.   The authors evaluate the recognition backbone for classification on ImageNet and detection and instance segmentation on COCO, reporting large gains over standard convolutional architectures such as ResNet, and reasonable gains over more recent transformer-based ones.",
    "This paper introduces VRDP, a method that learns to answer predictive, counterfactual, explanatory and descriptive yes or no questions about videos depicting the evolution of physical scenes. VRDP is composed of three modules, an object detector, a neuro-symbolic concept learner and differentiable physics model.  The paper shows that VRDP surpasses or closely matches the SOTA on two datasets, a synthetic dataset CLEVERER and a dataset of real world videos.",
    "This paper proposes to do visual question answering by learning a differentiable physics model from video. The pipeline is divided to several modular and interpretable parts. Firstly, a visual perception module parse the input video to several objects\u2019 features. Secondly, a concept learner parse the input questions to a set of programs and grounded concepts. The output of the above two modules are used to estimate the objects\u2019 physical parameters and fed to a differentiable physical engine, which is used to do future trajectory predictions. Finally, a symbolic execution part is used to output answer given the future predictions.",
    "The paper tackles the problem of dynamic visual reasoning by using a modular unit that is composed of three components: visual perception, concept learner, and physics simulator. This system is capable of performing system identification from visual and language modalities with assistance from a physics model. Having access to the physics model, it can produce imagined future trajectories for reasoning about possible future outcomes. This gave them an advantage of outperforming competitive methods, especially in counterfactual tasks. ",
    "- The paper presents a composite model for visual question answering in scenarios which require dynamic visual reasoning. - The model pipeline consists of a visual perception module which extracts object-centric trajectories from an input video, a concept learner which parses the natural language QA pair into a set of neurosymbolic concept vectors, a differentiable physics model which can simulate the evolution of rigid body trajectories and a neurosymbolic program executor which computes or selects the answer for a given input question using the intermediate concept and trajectory features. - As a contribution over prior art in neurosymbolic visual reasoning, the authors propose the utilisation of a differentiable physics module for accurate trajectory prediction based on physics parameters which are inferred from the video input sample. Since explicit physical properties like mass, friction and restitution are inferred in the model, the computed output is very amenable to human interpretation. - The proposed approach is comprehensively evaluated on the synthetic CLEVRER and realistic Real-billiard benchmarks and compared against related neurosymbolic and end-to-end VQA models. It demonstrates remarkable boosts in data efficiency on CLEVRER, sets a new state-of-the-art performance on counterfactual questions and significantly outperforms prior art in a few-shot setup where generalisation to modified physical attributes like 'heavier' or 'lighter' is required.",
    "This paper is in the field of Active learning, which has proven to be useful for minimizing labeling costs by selecting the most informative samples from unlabeled datasets, which are then to be labeled by a human in the loop. The goal is to achieve high accuracy of the trained model, while minimising the number of points to be labeled by the human in the loop. However, as the authors say, many existing state of the art active learning methods are trained on datasets which are not very realistic, and they do not perform well in many common real-life situations such as imbalance or rare classes, out-of-distribution data in the unlabeled set, and redundancy. Given the size of these datasets, cleaning them manually is not realistic. The authors propose an active learning framework which they call SIMILAR, which uses submodular information measures as acquisition functions. They argue that SIMILAR performs well on the realistic scenarios mentioned previously, and empirically demonstrate that SIMILAR outperforms previous state of the art methods in these scenarios.  ",
    "In this paper, the authors propose methods for selecting a query set for batch active learning. These methods select a query set by maximizing a criterion based on submodular functions such as facility location function, graph cut function, and log-determinant function. The similarity matrix between data points, used in the definition of submodular functions, is defined by the inner product of the gradients of loss functions.  The authors empirically validate the efficiency of the proposed methods for batch active learning with rare classes, redundancy, and out-of-distribution data points. They adopt standard image datasets and standard deep neural network models. In each experimental setting, some of the proposed methods outperform existing methods for batch active learning.",
    "This paper proposes a \"unified active learning framework\". The key element of this framework is a submodular information measure, denoted by $I_f(A;Q|P)$ where $f$ is a submodular score function, $A$ is a set of unlabeled samples whose \"value\" is measured, and $P$ and $Q$ are set of samples to be specified by the algorithm as parameters. $I_f(A;Q|P)$ is supposed to measure similarity and dissimilarity among $A$, $P$, and $Q$. In each round of the proposed \"unified active learning framework\", it chooses $A$ that maximizes $I_f$. By choosing $P$ and $Q$ properly (for example, for the class imbalance task, setting $Q$ to be a small labeled sample set from rare classes), this paper shows empirically the proposed algorithm outperforms other active learning algorithms on various tasks, including standard AL, AL with class imbalance, AL with redundant data, and AL with out of distribution data.",
    "In this paper, the authors propose a new diversity based active learning algorithm by utilizing a series of information functions in submodular optimization (SO) problems. Specifically, they consider three submodular information measures (SIM) in SO: Submodular Mutual Information (SMI), Submodular Conditional Gain (SCG) and Submodular Conditional Mutual Information (SCMI) and found that SCMI ($I_f(\\mathbf{A};\\mathbf{Q}|\\mathbf{P})$) is the most expressive SIM such that one could tailor $\\mathbf{Q}$ and $\\mathbf{P}$ to represent SCG and SMI, and thus propose to use it as a \u201cunified\u201d acquisition function for tackling three scenarios in realistic AL: rare class due to class imbalance, redundant data and out-of-distribution(OOD) data. The basic idea is to specify $\\mathbf{Q}$ and $\\mathbf{P}$ depending on the desired/un-desired classes, such that one could condition on data region that they want to exclude (OOD, redundant data), while up-sample regions that one want to include (rare class) by considering the mutual information w.r.t that region. To instantiate SIM acquisition function, the authors borrow the utility function from three well known graph-based SO problems for diversity coverage: Facility location (FL), Graph cut (GC) and Log Determinant (LOGDET), and use the similarity kernels computed with pairwise cosine similarity of the last layer gradients w.r.t the model-predicted label for every pair of unlabeled data points. They experiment with synthetic datasets rooted from MNIST/CIFAR-10/ImageNet to test for the three special scenarios, and show promising results against several strong baselines including BADGE.",
    "The authors propose asymptotic and non-asymptotic test for the hypothesis $\\phi = \\phi_0$ where $\\phi$ is the spread parameter of a Mallows model. To do that, they first prove that we can derive a non-asymptotic test from an asymptotic one (Prop 4.1), then show that an optimal unbiased UMP test can be defined is too computationally costly when the number of items to order ($m$) is large (Theorem 5.1), due to the calculation of the probability in Eq (2).  To alleviate this limitation, they propose to estimate the most likely spread parameter $\\hat{\\phi}$ which allows them to efficiently approximate the quantity in Eq (2) and control the deviation (Theorem 5.4). Finally, the authors address testing for spread with unknown central ranking, by showing that the average rank aggregation is asymptotically close to the central ranking. Finally, they confirm the efficiency of their method in experiments.",
    "Paper provided a UMPU test on Mallows model's spread parameter. And based on that paper introduced many variations and discussed their properties. Paper contributes to the testing literature by providing a UMPU test and associated math tools.",
    "The paper studies the problem of identity testing for the Mallows model, which is a popular parametrized distribution over rankings. It gives identity testers for the non-asymptotic and asymptotic setting which are sample optimal but not necessarily computationally efficient. It also gives a efficient identity tester, with weaker guarantees, and also extends the results to the setting where the central ranking is not unknown.  ",
    "This paper is concerned with the hypothesis testing of Mallows ranking models, which is parametrized by a central ranking and a spread parameter. The authors proposed two different methods: one based on the classical Type I error, and the other based on an optimal learning approach. The authors presented a complete theory regarding testing Mallows rankings, and also provided empirical results to corroborate the theory. ",
    "The paper solves a problem similar to Neural Body (reconstruction / free-view rendering of clothed humans from videos based on SMPL fits) but does not require training a neural network per scene; instead, it generalises from training sequences and, at test time, runs only a feed-forward model conditioned on keyframes. This is important for many applications since training a neural net per scene is not practical, and also the proposed extension is not trivial: the paper brings novel ideas (using attention for time-wise and camera-wise aggregation). Experimental evaluation is comprehensive and the quality is even superior to per-scene optimised Neural Bodies. Given this, I suggest to accept the paper, although there is some room for improvement.",
    "This paper presents a method to synthesize a novel view image of a person given the sparse multiview images. The paper proposes time-augmented skeletal features---the pixel-aligned features that encode NeRF-like rendering fields by aggregating image features across  time and views, parametrized by a human mesh model. They use transformer networks to learn fusing multiview image features over time. The resulting features are used to generate an implicit function that can predict RGB and opacity. They demonstrate that the proposed method is generalizable to unseen identities and poses, validated on ZJU-MoCap and AIST datasets.  ",
    "This work proposes a method that can synthesize free-viewpoint videos for dynamic humans in a sparse multi-camera system.  As is claimed and demonstrated in the paper, by introducing transformer modules to aggregate spatio-temporal information in the sparse multi-view data, the learned neural radiance fields are generalizable to unseen human identities and unseen poses.  The proposed method is tested on public multi-camera datasets, showing promising results.",
    "This paper presents a generalizable NeRF network that can produce novel view synthesis for novel dynamic human scenes from sparse camera views, in a feed-forward manner. It leverages visual features from tracked parametric body model and similar to PixelNeRF, it conditions the NeRF representation on pixel-aligned image features for appearance generalization. A novel combination of a temporal Transformer and a multiview Transformer is proposed to integrate multi-frame and multi-view visual observations. It demonstrated stronger generalization capability than prior work.  ",
    "This paper introduces a neural architecture search method called S3 that first searches the search space before identifying good architectures from the discovered search space.  The authors focus on applying S3 to vision transformers and design a search space modeled after ViT.  They evaluate S3 discovered architectures on various computer vision tasks and show good performance on image classification, object detection, and semantic segmentation. ",
    "This work applies NAS to the vision transformer architecture. Besides searching the architectures, it also automatically adjusts the search space guided by the E-T error that combines the error distribution and top model errors to evaluate the quality of different choices in a search dimension. By fitting a linear function to approximate the E-T error, the new search space is updated through a simple formula. They used the supernet to efficiently compute the E-T errors, and use evolutionary search to search for the best algorithm in a given search space. The discovered architecture is shown to be competitive to the state-of-the-art models, and also generalize to other vision tasks. ",
    "This paper proposes a method for searching the search space of vision. The authors propose decomposing the search space by the search dimensions and evaluating them with the proposed E-T error to explore the optimal search space. Then the new subspace is formulated as Equation (8). The results reported in this paper have achieved state-of-the-art results.",
    "This work propose to first search for the search space for transformers and then applies once-for-all NAS methods to search for architectures within the searched search space. In particular, the work proposes an E-T error metric to evaluate the quality of the search spaces. From the results of the whole search process, this work also summarizes some design guidelines for vision transformers. The experiments are extensive and they show the superiority of the proposed search method. ",
    "This work studies the problem of learning from label proportions (LLP), that is given bags of vectors and given the average of the positive labels in each bag, we need to find an LTF that satisfies most of the bags. The authors study the case where the bags contain at most 2 vectors. They study two cases, one where the vectors are taken from $\\mathcal X\\subseteq \\mathbb{R}^d$ and they are searching for an LTF; in the other case the vectors are taken from the $d$-dimensional hypercube $\\{0,1\\}^d$, and they are looking for an OR-LTF. In the first case, they provide an algorithm that satisfies $2/5$ of the bags and if all the bags are non-monochromatic (contain vectors with different labels) then the algorithm satisfies $1/2$ of the bags, for the other case they provide an algorithm that satisfies $(2/5 + \\gamma_0/d)$ bags and if all the bags are non-monochromatic it satisfies $(1/2+\\gamma_0/d)$ of the bags. Furthermore, for the last case, the authors provide an NP-hardness reduction to the Label Covering problem that shows that their result is qualitatively tight and that in general, we cannot hope for an algorithm that satisfies all the bags.",
    "This work considers the problem of learning a linear threshold function (LTF) from label proportions. In particular they consider the special case where both single (as in the standard PAC learning setting) labeled (as 0 or 1) examples are observed or pairs of points $(x_1, x_2)$ together with their average label (which can be 0, 1, or 1/2) are observed.  They give two main results: a polynomial time algorithm that finds an LTF that satisfies at least 2/5 of the labeled examples (pairs and singletons together) and a lower bound that shows that finding an LTF that satisfies more than 1/2 of the labeled examples is NP-Hard.  For the special case where only mixed pairs, i.e., with label 1/2, are observed, the provided algorithm satisfies 1/2 of the labeled examples matching the lower bound (which also assumes only mixed pairs).",
    "This paper studies proper learning of linear threshold functions (LLFs) in the learning from label proportions model.  There are two main contributions.  The first is a polynomial time algorithm that, given a collection of bags each of size at most two consistent with some (unknown) LLF, identifies an LLF that satisfies at least $2/5$ of the bags.  The second main contribution, which complements the first, shows that it is NP-hard to compute, given a collection of bags all satisfied by some monotone OR, to compute any function of constantly many LLFs that satisfies $(1/2+\\epsilon)$ of the bags for any positive $\\epsilon$.         ",
    "This paper intends to make a few theoretical contributions for the learning from label proportions framework. In this framework training data arrives in the form of bags that contain several feature vectors and the proportion of positive labels in the bag as ground truth. The authors focus on learning linear threshold functions, while making a restriction to bags of size two.   A few theoretical results are presented. A first theorem gives a lower bound on the number of bags that can be \"satisfied\" with a polynomial time algorithm -- the authors define a bag as satisfied if the predicted proportion of positive labels equals the real proportion in the bag. A second theorem states that finding a linear threshold function that satisfies all bags is NP-hard in the worst case. ",
    "This paper proposes another benchmark dataset for NAS, NAS-Bench-x11. Compared to the original benchmarks NAS-Bench-101, NAS-Bench-301 and NAS-Bench-NLP, NAS-Bench-x11 contains the full training information for each candidate architecture especially the learning curves so that it allows multi-fidelity NAS algorithms  NAS-Bench-x11 is a surrogate benchmark, which trains a surrogate model to predict the learning curve of the vast amount of candidate architectures. Prediction of the learning curve can be accomplished by singular value decomposition and noise modeling.  ",
    "Existing NAS benchmark datasets (e.g., NAS-Bench-101) do not provide full training information of architectures, which make it infeasible to evaluate the multi-fidelity algorithms (e.g., learning curve extrapolation). To address these issues, this paper create surrogate benchmark datasets, namely NAS-Bench-111, NAS-Bench-311 and NAS-Bench-NLP11, with singular value decomposition and noise modeling methods. Extensive experimental results with the full training information on these datasets show the superiority of the proposed method.",
    "The authors describe a mechanism to predict learning curves which they use to generate surrogate benchmarks from existing NAS-Bench versions without learning curves. The authors explore different ways to create learning curve embeddings, different ways to predict these embeddings using the architecture representation as an input and different ways to model the training noise. Furthermore, the authors discuss a short study on using learning curve extrapolation in context of speeding-up NAS.",
    "Existing NAS benchmarks often only include the architecture performance at the final or some selected checkpoint epochs. However, per-epoch information is essential for developing and evaluating multi-fidelity NAS algorithms. This work proposed to fit a surrogate model to predict the learning curve given an architecture encoding. Utilizing the proposed predictor, the author extends three existing benchmarks NASBench-101, NASBench-301, and NASBench-NLP to include per-epoch accuracies. Further, to demonstrate the necessity of developing multi-fidelity algorithms for NAS, the author also describes a procedure to extend the single-fidelity algorithms to multi-fidelity ones by using learning curve extrapolation to filter out candidate proposals with partial training. Despite possible room for improvements on the performance of the learning curve predictor used, the proposed method would enable researchers to develop and rapidly test multi-fidelity NAS algorithms. I vote for acceptance.",
    "In this paper, the authors propose to explain the behavior of black-box neural networks by approximating a top-level hidden layer (no non-linearities afterwards, except possibly softmax) as a linear combination of the hidden layers obtained from different examples. These examples may come from the training data, but it is not required. The contribution of each input feature is also evaluated using an extension of integrated gradient across multiple dimensions.",
    "This paper introduces SimplEx, a method that approximate the hidden representation of a test example using the linear combination of hidden representations of examples in a pre-defined corpus. Further, the hidden representation of the test instance is associated with each input feature of these examples in the corpus. The paper demonstrates the quality of approximation of SimplEx (Sec 3.1, SimplEx outperforms kNN baselines) and demonstrate its practical utility in the experiment of predicting cancer mortality (Sec 3.2) by allowing model users to interpret model predictions and determine whether to trust the prediction. Detailed math derivation and additional experiments with MNIST and time series data are included in the appendix.",
    "This paper introduces SimplEx, which is a method to post-hoc explain a model prediction by computing from a user-defined set of examples, how the set of examples decompose the prediction. For example, the clinical risk prediction of a patient can be explained by a set of other patients and how much each patient influenced the prediction.   Contributions -\tA post-hoc explanation method, called SimplEx, were users can choose the set of examples from which the explanation should be constructed. This is advantageous when the training set is not available or a user wants customized explanations, e.g. a doctor wanting to understand a predictions in terms of other patients she/he knows. -\tSimplEx combines the ideas of feature saliency and example-based explanations. For each example, the method computes the percentage of this example contributing to explaining the prediction as well as which features of this example were important. -\tA latent-space generalization of Integrated Gradients [10] -\tExperimental evaluation that show SimplEx to be more precise and robust compared to baselines. ",
    "The main contribution of this paper is SimplEx: a method that aims to explain a test prediction by decomposing it into the weighted sum of nearest neighbors (from a user-specified corpus) in the latent space. They claim this method is more precise and robust than existing explanation-by-example-comparison methods (namely, KNN-like explanations) and distinguish this method from (often gradient-based) feature saliency methods. The paper builds off work that try to explain model predictions that use comparisons in latent variable space (e.g., Concept Activation Vectors, Deep KNN). SimplEx works PROVIDED the model has a hidden layer that linearly maps to the output (this is the layer that is used for explaining predictions).   - This constraint is significant for accurate weighting of examples. Note that if this is not satisfied by the model (say for instance a softmax is added right before the final output), it is possible to consider an earlier layer that satisfies the linear-mapping constraint as the output  Note too that if the latent space spanned by the user uploaded corpus does not contain the latent representation of the test prediction of interest (it likely will not), the test's latent is projected into the space. This means that it is possible to use this method on any input, regardless of the corpus. We can then measure how good this approximation is by calculating the residual between the corpus span and the test latent.  We can then \"interpret the shift in latent space as resulting from a shift in the input space.\" This is the crux selling point of the paper, and it is accomplished using integrated (and projected) jacobians. This technique also lets us see the contribution of a feature from a corpus example.  The authors then proceed to (briefly) characterize their model on MNIST against dKNN inspired methods, and show a use case on a clinical risk dataset.  They claim the following novelty:  1. Freedom to choose comparison corpus, no need for this to equal the training set 2. The instance-level decompositions are valid in latent and output space, and are more robust than other explainability methods",
    "This paper introduces Swin Transformer in the visual domain for vision-language pretraining. Previous VL pretraining models feed image tokens and text tokens together into the cross-modal transformer, and the visual relationship learning and inter-modal alignment are encapsulated in the same transformer network. The authors propose that visual relationship between different visual objects or concepts is important for inter-modal alignment learning, and there should be independent processing of visual relationship in the framework. Motivated by this hypothesis, the authors add a visual-only transformer to learn visual relationship before feeding the image and text tokens together to the cross-modal transformer. In addition, the authors propose a metric named inter-modality flow (IMF) to measure the cross-modal interactions. They also propose masked feature regression as a new pretraining task. Pretraining is conducted on in-domain datasets COCO and Visual Genome. Evaluation is conducted on three downstream tasks VQA, visual reasoning, and visual entailment.",
    "This paper proposed to use the vision transformer as the visual backbone for vision-language pre-training. To quantize the information flow transferred between vision and language modalities, the authors proposed a metric called Inter-modality flow that aggregates the attention weight across different layers. Experiments on VQA, visual entailment, and visual reasoning validates that the proposed method achieves state-of-the-art performance.",
    "This paper provides a novel way of applying masked feature regression (MFR) to transformer-based visual encoders. In addition to this new way of MRM, the paper also provides a quantifiable measurement of how two modalities (image and text) interchange their information with the aids from the attention flow method. This quantity, the inter-modality flow (IMF), is then used to analyze the characteristics of different vision-and-language pretraining models.",
    "This paper proposes a transformer based visual backbone for vision and language understanding. It uses a vision transformer backbone (Swin Transformer) to extract visual representation, which is then passed to a mask generation module. The visual tokens(including masked tokens) and text tokens embeddings are fed to a multimodal transformer model, where different pretraining objectives are applied. This architecture achieves state-of-the-art results in VQA, SNLI-VE, NLVR^2, Image-Text Retrieval. Authors propose an Inter Modality Flow metric that measure interaction between the visual and textual modalities and correlates well with the downstream results.",
    "The paper studies the dynamics of privacy loss for noisy gradient descent algorithm, whose continuous-time analogue is the Langevin diffusion process. They obtain a tight bound on the Renyi divergence between the pair of probability distributions over parameters of models with neighboring datasets. They prove for smooth and strongly convex loss functions, the privacy loss converges exponentially in the number of iterations, instead of square root in the number of iterations as in composition-based analysis of the same algorithms in the literature. For Lipschitz, smooth and strongly convex loss functions, they prove optimal utility for differential policy algorithms with a small gradient complexity.  ",
    "This paper presents a theoretical framework for analyzing the privacy loss of Noisy Gradient Descent during its execution. Using the Renyi divergence as the differential privacy metric, the authors aims to understand how much information leaks for an optimization function $\\frac{1}{n} \\sum_{x\\in \\mathcal{D}} \\ell (\\theta; \\mathbf{x})  $ and for  the dataset $\\mathcal{D}=(\\mathbf{x}_1,\\cdots,\\mathbf{x}_n).$  In order to do that, they interpolate the discrete algorithmic method of \"Noisy Gradient Descent\" to its stochastic continuous analogue, the famous stochastic differential equation of Focker-Plank Equation. The authors carefully construct this tracing diffusion process among two consecutive steps such that $\\theta_k = \\Theta_{t=\\eta k}$ but $\\lim_{t\\to \\eta (k+1)} = \\Theta_{t=\\eta(k+1)}$ , where $\\theta_k, \\Theta_{t=\\eta k}$ are the  discrete/continuous parameters for the optimization. This semi-continuous interpolation permits the authors to analyze tightly the information disclosure of the initial method of Noisy Gradient Descent using Gaussian perturbation for the case of  of smooth and strongly convex loss functions.",
    "The paper analyze Differentially Private Gradient Descent (DPGD) for optimizing a function f, which perform gradient descent while adding Gaussian noise to the gradients. The authors consider when f is the sum of loss functions of users in a database, and we want to output a minimizer of f with approximate differential privacy. They analyze the privacy loss and error of DPGD by viewing it as an instance of Langevin Dynamics, which samples from the distribution p with pdf proportional to e^{-f(x)}. The main result of the paper is a bound on the Renyi divergences between two DPGD runs on adjacent databases. The main qualitative improvement of this bound is that the dependence on the number of iterations of DPGD, K, is something like (1-e^{-K}) when the loss functions f are strongly convex and smooth. That is, the divergence bound increases with K, but the asymptotic dependence on K is O(1). In comparison, many past bounds have a small polynomial dependence on K, since they effectively bound the divergence between the full chain of iterates produced by DPGD, rather than the final iterate. In particular, if we took K to be sufficiently large, this would enable sampling from a distribution very close to p with approximate DP. The authors show that indeed, this gets loss that has optimal dependence on dimension, epsilon, and the number of users n.",
    "This paper investigates the information leakage of noisy gradient descent (GD) algorithms for smooth and strongly convex loss functions. The authors analyze the dynamics of (Renyi) privacy loss during training (over K iterations) when the internal state of the training algorithm is not observable. This leads to an upper bound on the rate of privacy loss of the released model by way of the Renyi divergence between a pair of distributions over model parameters learned on neighboring datasets. The bound turns out to be much better than that obtained using composition-based approaches. ",
    "This paper presents a method to improve QP solving speed via reinforcement learning.  A regularization parameter used in OSQP solver is being updated via a RL policy. The approach is shown to improve OSQP performance on various benchmarks. ",
    "The paper introduces a RL formulation and training pipeline to accelerate quadratic programming. The main idea is based on learning the multi-dimensional multiplier for ADMM. The paper shows some empirical performance gains over a number of setups.  ====== updated post rebuttal =====  Thanks the reviewers for the replies. Aggregating all information so far, I think the major weakness of the paper is the following:  It does not provide a clear reason why formulating the whole problem as a multi-agent Markov game is useful (I am not fully convinced by the rebuttal). The algorithm I can see is still essentially a single agent policy but with a specialized architecture.  Now that after exchanging messages with the author a few times, I have understood how the detailed architecture works, and I am convinced about my point above. I would suggest that the authors present their architecture (such as mapping from R^6 to R^1) in a clear way, so as to make the architecture easier to understand. Also, I would like to see less stress on the Markov games, because it does not provide much gains -- once again, I'd like to frame it as a form of specialized architecture for single agent problem.  The paper is overall an application of RL to optimization problem. The gains are ok though the idea-wise contributions are not very novel (no extremely novel architecture or formulation).  Still, overall I think the paper provides a solid contribution and I am willing to raise my eval to 6.",
    "The authors use RL to tune the step size policy of OSQP, an ADMM-based solver for quadratic programming problems. They develop policies for both a scalar and a diagonal step size. Numerical tests are performed on the suite of benchmark instances used by the OSQP developers and external benchmark sets (QPLIB, Netlib, and Maros-Meszaros). The results show clear gains within specific problem classes and some evidence of generalization across problem classes.",
    "In this paper, the authors proposed a novel method to accelerate the QP  (quadratic programming) solving process using reinforcement learning. In their formulation, the state of the problem is the internal variables of the QP solver (in this case, OSQP's internal variables), the action space consists of the ADMM step size vector rho. Since the vector/matrix sizes of the QP can change between different problems, the authors used a multi-agent single-policy formulation, so each agent only observes the internal states that are relevant for a single coefficient in the step vector rho. The authors demonstrated that after training, their RLQP can converge faster for different classes of problems in the benchmark suite, especially if the problem is cold-started. ",
    "The authors study a principal component bias of deep linear neural networks when trained with gradient descent using a small learning rate. They show that when the network is sufficiently wide, deep linear networks behave like single layer linear networks during the first phase of training, where the rate of convergence is governed by the largest principled components of the data. It is further shown that at later stages of training, under some assumptions, the PC bias remains to some extent.",
    "This work studies the training dynamics of over-parameterized deep linear networks. The authors propose the Principal Components bias (PC-bias) convergence pattern that characterizes the convergence behavior of deep linear networks training, which is supported by theoretical analysis and empirical results. This works also investigates the Learning Order Constancy effect (LOC-effect) and identified the connection between PC-bias and LOC-effect. Empirically, the authors also study several implications of PC-bias, including early stopping, convergence behavior under label noise, and provide interesting observations.",
    "The paper studies the evolution of a deep over-parametrized linear network under gradient descent.  The main claim of the paper is that the convergence rate of the weights is faster along directions corresponding to the larger principal components of the data, at a rate governed by the singular values. The paper also supports its argument in an extensive experimental study.",
    "The paper argues for the existence of the so-called \u201cprincipal component bias\u201d in the learning of deep wide nets, with the main focus on linear networks. This refers to the phenomenon that the learning that is associated with larger PCs of the data is typically faster. The paper does so via a theoretical analysis of the early stage of learning in linear nets and a series of experiments, involving both linear and nonlinear models.",
    "This paper observes that deep neural networks learn backdoored data faster than benign samples. Based on this finding, the paper proposes Anti-Backdoor Learning (ABL), which can learn a benign model on poisoned datasets. Specifically, at the beginning of model training, ABL maximizes the training loss gap between clean samples and backdoored examples and detects backdoored data based on the differences in their loss values. Then, ABL unlearns backdoored model with the detected data.",
    "The proposed work identifies that backdoor attack examples converge fairly quickly compared to clean examples during training, due to the nature of their objective. Using this, the authors identify backdoor examples and use a gradient ascent method to unlearn the backdoor, while gradient descent is used for clean examples. The proposed method is shown to be effective in reducing Attack Success Rate (ASR) while increasing Clean Accuracy (CA) on multiple datasets and attacks. ",
    "Authors have introduced the concept of anti-backdoor learning to learn clean models using backdoor-poisoned data. They have proposed Anti-Backdoor Learning (ABL) to automatically break backdoor attack during training with poisoned data. They have identified two weaknesses from backdoor attack. First weakness is that models learn from poisoned data at a much faster rate than these learn from clean data. The stronger the attack, the faster the models converge to a backdoor. The second weakness is that the backdoor task is tied to a specific class (the backdoor target class). Based on the two weaknesses, the authors designed a two-step method to learn a clean model with poisoned data.  The first step is to isolate poisoned samples from the training dataset, and the second step is to use the isolated samples to unlearn backdoor. The first step happened in the early training stage and the second stage takes over the training after the first stage. As compared to other state of the arts, the isolation step is very precise, and in many case, the precision is easily to reach 100%. The second step is very effective to unlearn backdoors. Even if only 1% of the poisoned samples are isolated, it can counter up to 70% poisoned samples to learn a clean model. Overall, this is a good paper and the proposed method outperformed the competing methods under the authors\u2019 experimental setting. ",
    "This paper observes that models converge much faster on backdoored data than clean data. Within a few epochs, the training loss for backdoored data will decrease to zero, but not for clean data. Based on such an observation, this paper aims to train clean models on poisoned data without knowing the backdoored portion in the training set. Specifically, it proposes a new training procedure called anti-backdoor learning (ABL), which splits the traditional training procedure into two stages. In the first stage, ABL uses a threshold to prevent loss values for individual samples being too small by flipping the sign of the loss. It then selects a small portion (1%) of the training set with small losses as the backdoored set and the remaining as the clean set. In the second stage, ABL applies gradient ascent on the backdoored set and gradient descent on the clean set. The evaluation is conducted on three standard benchmarks and ABL is compared with three existing backdoor removal baselines. The experimental results show ABL has the best performance on both reducing attack success rate and retaining normal accuracy in most cases. A list of studies on different components of ABL and comparisons with other alternative methods are interesting and informative.",
    "This paper aims to improve the density distribution of generative radiance field models by generating relitable reflectance fields and using different lightings to shade them during training. The core idea is that artifacts will arise when the generated density distribution (\"shape\") is unnatural and is getting shaded by different lightings, which should be detected and resolved by a discriminator. Experiments verify that this shading regularization can yield naturally looking shapes induced by the generated radiance fields.",
    " This paper proposes a GAN capable of generating a relightable radiance field when trained on an unlabeled dataset of face images. The relightable radiance field generator is conditioned on the 3D location and a latent code and outputs a volume density field (\u00e0 la NeRF) and an \"albedo\" field (I strongly advise against the use of this word; see below) that allows explicit control of the light location. The training is conducted in the GAN style, where the training signal comes from only a discriminator loss. The intuition is that the generator is better off generating a meaningful 3D volume that, when rendered from a random camera view, generates a photorealistic face image that falls into the training data distribution, than generating some intricately-designed volume that gives faces of different identities when viewed from different angles.  The authors demonstrate that the model is able to learn 3D shapes in an unsupervised fashion from just 2D images. The work is mainly compared against pi-GAN, which is shown to suffer from what the authors call \"color-shape ambiguities.\" For efficient rendering, the authors also propose an auxiliary network that predicts the surface location given the latent code and a viewing direction, such that the network can sample around the predicted surface to avoid expensive sampling of unoccupied space.",
    "This paper proposes a new method to train generative radiance fields that can achieve more accurate 3D shape reconstruction. The key idea is that instead of directly synthesizing the images from different viewpoints through volume ray tracing, which may suffer from color-shape ambiguity, it synthesizes albedo and normal and then renders the image with different lighting conditions. This new method requires the synthesized albedo and normal to be able to render realistic images under various lighting conditions, providing an extra regularization for shape reconstruction. To further improve the rendering speed, it uses an extra 2D CNN to predict a depth map from latent code and camera poses so that it only needs to sample near the surface in volume ray tracing. Experiments show that the proposed method greatly improves shape reconstruction with similar image synthesis quality compared to state-of-the-arts.",
    "The paper proposes a novel generative model for neural radiance field, where the key idea is to synthetically add shading effects based on random lighting configurations. Shading will make images unrealistic when the geometry is corrupted. Therefore, the system gets trained to generate accurate shapes in its implicit radiance field representation. The system makes convincing results both qualitatively and quantitatively.",
    "The paper concerns the uncertain quantification for instrumental variable (IV) regression that it is an approach for estimating causal effect from confounded observational data and, proposes a scalable quasi-Bayesian procedure. The procedure was built upon the kernelized IV models (Muandet et al (2020)). The contribution is forming a quasi-posterior by employing a Gaussian process prior and constructing a kernel conditional expectation estimator using a randomized prior trick. Theoretical properties and simulation studies are provided. ",
    "The paper studies a quasi-Bayesian approach to instrumental variable (IV) regression, based on using an empirical estimate of the \u2018likelihood\u2019 to obtain a Gibbs posterior. Such an approach has been studied in earlier literature due to the difficulty of incorporating moment conditions in IV via a likelihood. The paper pursues a Gaussian process approach and proves some theory, namely that the resulting posterior puts most of its mass on functions (almost) satisfying the moment constraint. The paper provides a computation approach based on the randomized prior trick and illustrates the method on various simulated datasets.",
    "The paper proposes a scalable quasi-Bayesian inference for instrumental variable regression. Specifically, the paper builds a quasi-posterior on the recent quadratic kernel IV loss function. For scalability, the paper extends the randomized prior trick based on the recent dual formulation of the quadratic loss. The approach has a theoretical guarantee that incorrect solutions are excluded while valid kept. Moreover, the convergence analysis for the randomized prior trick with the stochastic gradient descent-ascent is present. Experiments validate the approach.",
    "The authors introduce a scalable quasi-Bayesian method for nonparametric instrumental variable (IV) regression that provides uncertainty quantification for the IV models. They base their approach on kernelized IV models and define a quasi-posterior as the Radon-Nikodym derivative of a generalized method of moments (GMM) objective function with respect to the standard Gaussian process prior. They go on to show that the quasi-posterior exhibits satisfies certain posterior contraction criteria that lead to asymptotically sound results, and prove a conservative posterior contraction rate under a set of typical assumptions. They then show how to achieve scalable inference for the quasi-posterior using a previously proposed \u201crandomized prior trick\u201d for Gaussian process regression, and provide a proof for the convergence of the inference algorithm. Finally, the authors showcase the performance of their method in a series of simulated experiments of varying complexity, by comparing it against other approaches that provide uncertainty quantification (Bayesian, bootstrap).",
    "The paper attempts to provide a solution to an interesting problem of cross language retrieval based question answering in a zero shot (without requirement of any language-specific annotated training data). Authors propose a new DPR algorithm that to be able to retrieve documents relevant to the question across languages (for multiple languages). The paper extends retrieve-the-generate based open domain QA system to a cross-lingual setting. ",
    "This paper addresses the multilingual open QA task by combining a cross-lingual passage retrieval algorithm with a multilingual autoregressive generation model. The approach is thus capable of answering questions where the answer and the question are in different languages.  The authors extended existing annotated data using an iterative training approach that improves retrieval for languages with limited resources. The experimental results showed that the proposed method (CORA) outperformed the previous state of the art on multilingual open question answering benchmarks across 26 languages.",
    "This paper studies the task of multilingual Open-Domain Question Answering.  The task setting requires building a system that can answer natural language questions in any language on an open set of domains. Models are required to answer in the same language the question was asked in.  The authors tackle the task using a fairly conventional retrieve-and-read ODQA model, with the necessary modifications to make both the retriever and reader component language-agnostic, by exploiting multi-lingual pretrained models, training on available multilingual training data, and using and a clever data augmentation setup to increase multilingual training data.   The proposed solution \u201cCORA\u201d, operates over wikipedias in many different languages.   The retrieval component \u201cMDPR\u201d is a multi-lingual extension of DPR, using MBERT. This model can retrieve evidence documents across different languages, rather than having to match the language of the question. This means that a question expressed in a low-resource language can benefit from retrieving evidence from high resource languages. It also allows for a question written in one language on a cultural topic associated with a different language to retrieve from the most appropriate language\u2019s wikipedia.   The reader \u201cmGEN\u201d is a generative reader, implemented using mT5, that takes as input the concatenation of the top-K retrieved passages from the retriever (which may be several different languages) and the question, and generates the answer in the question language, token by token.   The main difficulty of the proposed solution is how to train the MDPR and MGEN model components, given the limited multilingual raining data. The initial model is trained with NQ (english) and TyDi QA and Xor-TiDi QA (multilingual data). To increase the amount of multilingual training data and language coverage,  the authors introduce a data augmentation strategy where the initial model is used to harvest potential additional data. This exploits the wikipedia \u201clanguage links\u201d resource. This iterative approach works by retrieving passages, looking up passages on the same topic in other languages using \u201clanguage links\u201d, and using the reader to see whether these can be used to generate the correct answer - if they can, they are added as additional training data for the next round. Another expansion mechanism exploits the fact that most answers are wikipedia entities, and can be translated using annotations available in the wikipedia \u201clanguage links\u201d resource.  CORA is thoroughly evaluated on TyDI QA and an evaluation-only dataset called MKQA, and performs very strongly, improving the state-of-the-art by a wide margin in almost every setting.. Thorough ablations give insights and quantify the the effects of the system, and demonstrate zero-shot question answering abilities   ",
    "This paper presents a multilingual dense passage retrieval model called mDPR to deal with the multilingual/cross-lingual IR and QA tasks. The mDPR part is firstly trained using existing labeled multilingual Q-P pairs. Then, possible passage pairs are selected from a given multilingual corpus based on the trained mDPR and used to train an answer generation model called mGEN. Next, given each question, the trained mDPR is further used to retrieve more possible passage candidates in other languages from Wikipedia corpus, where the retrieved passages that can lead to correct answers are considered as positive instances, the others as negative instances. With these expanded new question-passage pairs, the training of mDPR is performed again. The above procedure is conducted in an iterative manner. Evaluations are conducted on TyDi QA and MKQA in the open-domain QA setting. Several baselines are included and compared. The key contribution is to do DPR in the multilingual/cross-lingual setting.",
    "This paper conducts a large-scale empirical study of ERM models tested in the domainBed pipeline, together with the empirical results tested, the authors also investigated the numerical values of several different measures, which allows the authors to further study the relationship between multiple different measures and the empirical performances. The empirical study suggests that there may be interesting connections between the target-entropy and the empirical performances. The paper candidly acknowledges its limitations of being purely empirical. ",
    "The paper provides a large scale study of out-of-distribution generalization measures. It first provides a brief introduction of the core theoretical foundations of the field. Then the paper trains 12000 models on DomainBed Benchmarks to examine the predictive power of theory-based measures. The paper argues that theory based measure fail to accurately capture the OOD generalization behavior. Following the methodology of Jiang 2019 et al, the paper examine how various empirical measures (sharpness, entropy, Fisher, ...) predict OOD generalization behavior. In the end, the paper lists the predictive measures and examines their performance details.",
    "This work tried to find that which measures can be used for predicting the the out-of-domain generalization for the deep neural networks trained using Empirical Risk Minimization (ERM). The authors started from the domain adaptation theory of Ben-David, 2007 but found that it had limited ability. Then they explored many other measures, including Fisher based measures, Jacobian Norm based measures, Mixup based Measures, and entropy on target data. They found the best single factor led to around 0.70 Spearman's \u03c1 and the joint use can boost the value to 0.80.",
    "Prior work has found that empirical risk minimization performs unexpectedly well on domain generalization tasks. In this work, the authors try to explain this phenomenon. First, they use theory developed for domain adaptation to bound the target domain test error, finding that theory-based measures do not adequately predict the target domain test error, especially when target domain labels are not available. Next, the authors try a variety of empirical measures. They find that some measures outperform the theory, especially when combined with the in-domain test error.",
    "This work proposes a theoretical framework to draw connections between several phenomena in machine learning observed empirically but never adequately understood- the relationship between excess model capacity, perturbation robustness, and backdoor poisoning. They show how under specific settings, adversarial training can detect backdoored data or recover a classifier robust to the backdoors at the very least. Similarly, they show how learning a backdoor-robust classifier is equivalent to pruning corrupted train data. They further demonstrate the applicability of their theorems on the MNIST dataset.",
    "The authors propose a theoretical study on the robustness of binary classifiers against backdoors. To this end, they provide a theoretical framework and define a measure to assess classifiers' memorization capacity. This formulation allows the authors to demonstrate the existence of backdoors in some settings and explain why adversarial training reduces the vulnerability to backdoors. ",
    "The paper gives a variety of backdoor-related theoretical results. In particular it,  1. gives a theoretical framework for discussing backdoor poisoning attacks, 2. shows that the attacker does not need to know the true data distribution to launch an attack against an ERM learner, 3. introduces _memorization capacity_, which measures the amount of off-distribution data a learner can memorize, and shows that nonzero memorization capacity is both necessary and sufficient for the existence of a backdoor attack 4. (the attack constructed in 4. can succeed with limited poisoned data regardless of how much clean data there is), 5. under assumption of finite VC-dimension, shows that adversarial training can be used to detect backdoor attacks, and 6. under the same assumption, shows that the problem of learning a backdoor-resistant model is equivalent to the problem of filtering poisoned data from the dataset. ",
    "The paper offers a theoretical framework to analyze and understand backdoor attacks. They define a notion of memorization capacity to characterize vulnerability of the learning problem to backdoor attacks. Under this framework they give examples of learning problems where explicit backdoors can be constructed easily and problems which are intrinsically robust to backdoors. Further, they also show that under certain assumptions, backdoor filtering and robust generalization are nearly equivalent. Which suggests, it is sufficient to design backdoor filtering algorithms. ",
    "The authors show that in the infinite width limit, deep GPs becomes a single-layer GP, generalizing the result that deep neural networks at initialization become a GP in the infinite width limit. The authors show that increasing depth of the GP makes the distribution of the final layer of deep GPs deviate from being Gaussian at finite width. The authors claim that this simplification implies that large widths are detrimental to neural network performance beyond some point.",
    "The paper argues that deep Gaussian Processes with large widths and more than 2 layers have undesirable properties. In particular, the paper shows that firstly, deep GP prior in the GP limit is essentially shallow, and secondly, deep GP posterior then loses data adaptivity in the hidden layers. The paper further examines the role of depth and argues that the deep GP prior, if not equal to a GP, has heavy-tailed behaviors.  ================================== Post-rebuttal:  Thanks for the reply and clarification!  While I agree that very large width hurts in the context of deep GP as shown in the paper, I also agree with other reviewers that the message that very large width hurts generally is overly strong. The literature has a mixed bag of results concerning widths -- theoretically or empirically, so a general statement should be validated very carefully.  I'd like to keep my score.",
    "     This paper provides a narrative of composite Gaussian process models. In specific the paper provides insights into the interplay between depth and width in the context of capacity and representative power. The paper further draws conclusions on the implications that this has for composite finite basis function models such as neural networks. ",
    "The paper shows that in the limit of infinite width a Deep Gaussian Process (DGP) converges to an ordinary Gaussian Process (GP). Indeed, in the limit of infinite width the covariance function of each hidden GP layer becomes deterministic (as a consequence of the strong law of large numbers). This allows proving that the marginal prior covariance  of the DGP becomes gaussian (Theorem1). The  consequence of this theorem is that as the width increases DGP models lose their ability to adapt the hidden covariance functions to the input data (section 4). This theoretical result is supported by numerical experiments (section 6.1). The paper also addresses the convergence of a DGP to a GP with increasing depth and width (section 5). Since it is known that deep neural networks (DNN) approach a GP as they are made wider and wider,  Theorem 1 is used to  claim that a very large width can be detrimental to the expressivity of a DNN (and not only a DGP).   ",
    "This paper proposes and analyzes a framework for Federated optimization called FedLin. It combines client-specific local steps with (possibly) biased compression at the server and/or clients and guarantees linear convergence to the exact minimum. Algorithmic contributions are supported with lower bounds for the case of infrequent communication and carefully designed synthetic experiments on least squares and logistic regression problems, which highlight theoretical claims.",
    "This paper considers a standard distributed optimization setup in which clients periodically coordinate with a server to train a global model. The focus is on the deterministic setting, in which each worker computes full local gradients. It is first highlighted that standard algorithms for this problem do not converge to the true global minimizer without trading off speed (for example through diminishing step-sizes).  Thus, the FedLin algorithm, which converges linearly to the true minimizer, is introduced to get the best of both worlds. Several theorems covering various settings (strongly convex, convex, non-convex, stochastic) are given, and show that FedLin matches the communication complexity of parallel GD, regardless of the number of local steps used. Then, a matching lower bound is given for FedLin to show that the strongly convex convergence result is tight.    Then, several gradient sparsification schemes are investigated (at the server and at the workers), which show that server-side sparsification is far less impactful than client-side sparsification. The impact of gradient sparsification is evaluated experimentally in Section 7. ",
    "This paper proposes a new algorithm called *FedLin* which,   T.1) queries a full gradient oracle,   T.2) de-biases the local gradients using a correction term (with the last synchronized iterate in memory) to deal with objective heterogeneity,  T.3) error corrects to deal with compression at the client and the server, and  T.4) uses a client-specific learning rate to deal with the different number of local steps on each client.   Thus, FedLin is able to accommodate both objective and system heterogeneity along with sparse gradients and local steps. In doing so it is an early work that can deal with these multiple aspects of federated learning at once, albeit at the cost of an expensive gradient oracle.   The paper provides the following theoretical guarantees for FedLin,  R.1) matching upper and lower bounds in the strongly convex-smooth setting without compression,  R.2) upper bounds without compression in the convex-smooth setting and the non-convex setting,  R.3) an iterate sub-optimality recursion for the strongly convex-smooth setting while using a stochastic gradient oracle,  R.4) upper bounds for client and server compression in the strongly convex-smooth setting.  See the main review for comments on these results. ",
    "This paper proposes an optimization method for federated learning, FedLin, that is specifically designed to ensure fast convergence even in the presence of heterogeneous data. Notably, the authors show that FedLin converges to the global optimum (or just a critical point, in the case of non-convex functions) without decaying the client learning rate. This is in contrast to methods such as FedAvg, FedProx, and FedNova, which require decaying the client loss in order to circumvent \"objective mismatch\", where the methods are actually optimizing an altered surrogate loss.  This work also derives lower bounds matching the convergence of FedLin on quadratics, that explain the price and cost of performing multiple local update steps. They also analyze convergence using gradient sparsification at both the client and server. Finally, the paper shows the empirical benefits of FedLin over other methods on synthetic least squares and logistic regression problems.",
    "This paper introduces a (possibly) cheaper approximation of Sliced Wasserstein (SW) distance. The proposed technique is based on calculating 1D Wasserstein distance between Gaussian projection directions. This is motivated by the fact that Wasserstein distance between Gaussian distributions admits a closed-form solution, which leads to an easy compute of the proposed approximate SW and discard a large number of uniformly sampling random projections for the Monte Carlo approximation of the original SW distance. ",
    "This paper develops a novel deterministic approximation for the Sliced-Wasserstein Distance (SWD), based on the fact that a random linear projection of a high-dimensional vector has an approximately Gaussian distribution. In many cases, the approximation involves no tuning parameters and can be computed much more quickly than the usual Monte Carlo estimate of SWD, especially for very high-dimensional data. If the $d$ dimensions of the data are not too strongly correlated, then the approximation converges no slower than $d^{-1/8}$ as $d \\to \\infty$. Experiments with synthetic data validate this theoretical result, as well as the computational benefits of the proposed approximation. Finally, the paper demonstrates an application to image generation.",
    "The paper presents a method to estimate the Sliced-Wasserstein distance. The method is based on the Gaussian approximation of the projected data, thus the SW distance could be approximated through the SW distance between Gaussians which has a closed-form. Hence, the method is better than the Monte Carlo SW distance in term of computational speed. The authors also demonstrate their method on toy data set and real data sets, i.e. MNIST and Celeb A.",
    "The paper proposes a new approach to approximate the sliced Wasserstein distance. In particular, the paper extends the central limit theorems for random projections to derive a deterministic approximation of sliced Wasserstein (based on the closed form of Wasserstein distance between two Gaussians) that is efficient (low error) in high dimension under centering assumption (weak dependence assumption). On the experimental side, the paper illustrates the derived theory on the synthetic data and compares the proposed approach to the conventional Monte Carlo approximation of the sliced Wasserstein distance.",
    "This paper is about two things: understanding learned NLP representations by finding and understanding similarities between *different* representations; and comparing these representations to fMRI data. The paper takes a new approach to both problems, and finds a dimension in the space of language representations that seems to correspond to something like \"semantic depth of analysis.\" Furthermore, the comparison with fMRI data shows that many representations are correlated with brain activations.",
    "Using a slightly modified (but relatively straightforward version) of an analysis that\u2019s recently been called \u2018neural taskonomy\u2019, this work attempts to use the relationships (read: transfer learning affinity) among different natural language representations to assess the organization of linguistic representation in human fMRI data via regularized linear encoding models.  The authors first contribute a modified version of a previously used encoder-decoder framework to create a 'task' (linguistic representation) affinity matrix that demonstrates conspicuous, interpretable structure when reduced via MDS to fewer projections. They then use the structure discernible in this matrix to ascertain whether similar structure (specifically, a hierarchy of representation from word embeddings to later, deep transformer layers) is evident in the brain. ",
    "The submission proposes to study similarities between language representations in different language models. First, a similarity measure between language representations is derived. Then, the matrix of similarities is reduced to two dimensions using MDS. The authors then discuss qualitatively this low-dimensional space of language representations. Then, linear encoding models of fMRI recordings are used to project the first MDS dimension on the cortical surface of a subject listening to narratives. Finally, the matrix of similarities is used to predict the performances of linear encoding models. ",
    "* The authors propose \"representation embeddings\" (vectors describing transfer performance from task i to task j) as a low-dimensional space describing the content of language representations. * They analyze the derived representation embedding space and claim that the main principal component tracks \"depth\" (line 192) of linguistic processing. * They conduct a brain encoding task and evaluate 100 models on this task. They claim that a model's brain encoding performance tracks with its behavior in this low-dimensional representation embedding space, and that this low-dimensional behavior also maps intuitively onto the spatial representation of language in the brain.",
    "This paper proposes to learn a joint model consisting of a VAE and a latent space diffusion. The training process is augmented with a contrastive loss.  The authors show that this approach makes possible a few-shot generation of images with desired properties. To achieve this,  one needs to train a classifier in the latent space and after that sample latent codes with high classifier scores in any way.  Also, the case of semantic editing is evaluated. The manipulation is implemented using a Langevin-like approach in the latent space.",
    "The paper describes two methods: 1) how to incorporate self-supervised learning in VAE to have a meaningful encoded representation, 2) how to use diffusion model over later to bridge the gap between posterior and prior for unconditional generation, 3) how to use the given setup to do few-shot conditional generation. Empirically, authors show highly improved representation quality, which can be attributed to the incorporation of self-supervised learning. Additionally, experiments show improved FID scores for face datasets, but not for CIFAR. Authors don\u2019t show results on ImageNet. The authors show improved FID scores for the conditional generation task. There is no FID comparison against StyleGAN2 (or any other GAN-based model), even if the authors claim to come very close in sample quality to such models. The qualitative depiction of image manipulation tasks is very impressive.",
    "The authors present Diffusion Decoding Models with Contrastive Representations (D2C) - a special VAE model with diffusion modeling in the latent space combined with contrastive learning based training of the inference network. The authors claim that D2C helps avoid the prior hole issue with VAEs due to diffusion modeling of the latent space, while contrastive learning helps learn meaningful representations allowing Few-Shot conditional generation. They further demonstrate that D2C outperforms NVAE and DDIM in few-shot conditional generation while remaining comparable to DDIM in unconditional generation. ",
    "D2C proposes three main contributions to diffusion models, a recently popularized class of likelihood-based generative models based on parameterized Markov chains, particularly successful when viewed from a denoising score matching lens. First, this paper learns a prior for the *latent space* of an image VAE (NVAE), while past work mostly applied diffusion to the data space. Second, D2C adds a SimCLR-style contrastive loss to image latents in order to improve the quality of latent representations for classification. Third, binary attribute classifiers are learned conditioned on these latents and used to guide prior sampling with rejection sampling or Langevin dynamics. Experimental results qualitatively and quantitatively show some success in conditional image generation and manipulation.",
    "This paper theoretically analyzes contrastive learning relying on a concept of population augmentation graph. In the graph, two augmented samples are connected if they can be augmented from the same original instance. Based on this setup, - This paper shows that spectral decomposition can be reformulated as a contrastive learning objective. Furthermore, this paper shows that minimizing the objective can guarantee a high linear probe accuracy under some mild assumptions. - This paper shows the guarantee can be extended to the finite-sample regime and learning the linear probe with labeled data. - This paper demonstrates the efficacy of the proposed spectral contrastive objective empirically in the standard setup: the proposed objective achieves similar performance as other state-of-the-art SSL methods. ",
    "The paper studies how does contrastive learning works from a theoretical perspective focusing on the spectral properties of the graph of the data induced by augmentations. They propose a new loss that is close up to a constant to the matrix factorization of the normalized adjacency matrix of the augmentations graph, under some assumptions they show that minimizing this loss provides downstream classification guarantees. Then, using standard Rademacher analysis they move from population guarantees to finite sample guarantees. Finally, they show empirically that their loss gives results close to state of the art. ",
    "This paper derives generalization bounds for learning using a contrastive objective under realistic assumptions on the positive pair generation process. The approach taken is to consider the so-called augmentation graph - the set of nodes comprises all augmented views of population distribution, with edges connecting nodes that correspond to different views of the same input datapoint. The core assumption made is that this graph cannot be split into a large number of disconnected subgraphs. This set-up aligns well with the intuition that in order to generalize, the contrastive notion of \u201csimilarity\u201d must extent beyond the purely single-instance-level, and must somehow connect distinct inputs points.  My view is that this work is the most significant advance in the statistical learning theory of contrastive learning since the paper \u201cA theoretical analysis of contrastive unsupervised representation learning\u201d by Arora et al. This paper under review addresses the primary weakness in the work by Arora et al., which used an unrealistic assumption on positive pair generation. I will strongly advocate for acceptance of this paper.  ",
    "The paper studies the theoretical foundations of contrastive self-supervised learning. To do so, the authors study contrastive learning through the lens of the augmentation graph - the graph of augmented examples, with edges connecting \"similar\" examples. The authors suggest a novel contrastive loss function, s.t. minimizing this loss is equivalent to spectral clustering on the augmentation graph. Using this, the authors prove that if the augmentation graph has few edges that cross between sub-graphs of different labels, then using a linear readout on the learned representation, a small loss can be achieved w.r.t the supervised objective. The authors also analyze the sample complexity of learning the representation and learning the linear probe from sampled data. Finally, the authors show empirically that the suggested contrastive loss performs similarly to some baseline contrastive loss functions.",
    "Summary.  The paper is about the parameterized complexity of Bayesian Network Structure Learning. In particular, it is focused to analyze and develop previous contributions on superstructure of the input. The author/s show/s that changing the parametrization yields to achieve fixed-parameter tractability.  The paper also anallyzes how the complexity of structural learning of bayesian networks depends on the input representation, with specific reference to non-zero representation, and additive representation. Finally the paper shows how to extend the main contirbutions presented to the problem of Polytree Learning.",
    "This paper contains a number of significant FPT results for BNSL, as well as providing a concise summary of existing FPT results. A key parameter considered is \"local feedback edge number\" which provides FPT. Results for when local scores are additively decomposable are given. The paper has many results and so many proofs are relegated to the supplementary material.",
    "This is a paper about the parametrized complexity of BN structural learning. To achieve that the authors consider the learning task as a decision problem and distinguish tasks wrt the way the local scores are represented (non-zero, additive, additive with bound on the number of parents). Separately for each class, the authors discuss tractability wrt various parameters (and not only the treewidth) used to describe the superstructure. This in particular suggests a dynamic programming approach for the additive case that is fixed-parameter tractable wrt the treewidth. Those results are also specialized to the case of learning polytree-shaped models.  ",
    "This paper investigates the fixed-parameter tractability of the Bayesian Network Structure Learning (BNSL) problem, according to new parameters related to the network superstructure. Namely, since the BNSL problem is known to be W[1]-hard for various vertex-related parameters, the authors concentrate on edge-related parameters, by showing that fixed-parameter tractability can indeed be achieved in some cases. In doing so, the authors consider two parameters, the feedback edge number (fen) and its \u201clocal\u201d version (lfen), which are less restrictive than the tree-cut width (tcw). Orthogonally, the authors examine three families of scoring (function) representations: non-zero representations, additive representations, and bounded additive representations. Finally, the authors explore the fixed-parameter tractability of polytrees.  ",
    "This paper focuses on stream-based (online) active learning for training classifiers in the binary classification setting. In particular, the authors propose a strategy, the so-called ALPS*, that trains classifiers by optimizing a surrogate loss over both the labeled instances and sequentially predicted data points by the learner. Theoretical guarantees on label complexity and error of the returned model are provided, and are shown to be competitive with the existing bounds. A set of experiments are conducted on datasets using multi-layer perceptrons as classification models, where the performance of ALPS is illustrated to have good performance with small labeling cost.   *Actively Learning over Pseudo-labels for Surrogate losses",
    "This paper studies the problem of online active learning for classification. In order to learn a classification algorithm, the paper proposes to employ surrogate loss function. The error of the proposed method is analyzed and some empirical results are presented.",
    "The authors propose an active learning algorithm in the streaming setting for binary classification tasks. The algorithm leverages weak labels to minimize the number of label requests and trains a model to optimize a surrogate loss on a resulting set of labeled and weak-labeled points. The paper contains a number of theoretical results and supporting empirical results. Overall, its a very strong paper.",
    "This paper presents Actively Learning over Pseudo-Labels for Surrogate Losses (ALPS), an active learning algorithm for binary classification with surrogate losses in the streaming setting. The main idea is to generate pseudo-labels for points whose labels are not requested and train on the union of data points with ground-truth labels and those with pseudo-labels. Since the pseudo-labels may not be accurate, the authors propose requestor functions that have a final say in whether a pseudo-label is used, and in effect, enable control over the noise generated by erroneous pseudo-labeling. Under an assumption involving the requestor function class, the authors prove bounds on the generalization error and label complexity of ALPS that are roughly on the same order of prior work (e.g., IWAL). ",
    "This paper proposes a measure of function complexity that is based on a function itself rather than the function class it belongs to. It uses this complexity measure to establish generalization upper bounds for classifiers. In addition, an empirical method for approximating this measure, and optimizing it, is proposed and evaluated on three small benchmark datasets, exhibiting slightly improved test accuracy over existing baselines. The method is also shown to improve resilience to label noise.",
    "The paper proposes a novel and theoretically inspired regularization techniques for training deep neural networks. The technique involves regulating the network by regressing the output of the model to a simpler model but the simpler model also regresses towards the output of the base model. The experimental results show that the proposed techniques are effective at reducing the generalization gap and improving performance in presence of label noise.",
    "This paper addresses the fundamental problem of the generalization ability of deep neural networks and aims to shed light on the theoretical aspects of their generalization ability by introducing a approach based on a new complexity measure called \"Kolmogorov Growth\" (KG). A practical neural network training approach called Network-to-Network (N2N) Regularization is also introduced with the aim of enforcing the low KG condition so that the generalization gap is reduced. Theoretical results are accompanied by relevant experimental evaluations, including a noisy-label case investigation, which helps in validating the proposed KG-based N2N training of neural networks. Overall, the material introduced is seemingly novel, and although tries to address a well-established problem, the results presented are good guidance for research extensions in this direction.",
    "This paper proposes a Kolmogorov Growth (KG), a novel measure of the complexity of a neural network. They derive new generalization bounds using KG and take inspiration from this bound to propose a new way of regularizing neural networks (network-to-network regularization, N2N). Finally, the paper verifies their regularization scheme on three standard image benchmarks.",
    "Summary: This paper proposes a new self-supervised learning method. It makes self-supervised learning very elegant: it does not require techniques such as weight sharing between the branches, batch normalization, feature-wise normalization, output quantization, stop gradient, memory banks, etc., and achieves results on par with the state-of-the-art results on several downstream tasks. It does not require that the inputs be of the same nature. This opens the door to the use of non-contrastive self-supervised joint-embedding for multi-modal signals, such as video and audio. I really like this paper. Still, I have some concerns about this paper. ",
    "This paper proposes a Variance-Invariance-Covariance regularization (VICReg) for self-supervised learning. The total loss function is the weighted sum of three terms: 1. distance between two views of the same input batch; 2. hinge loss on the variance of the embedding variables, encouraging them to stay away from zero; 3. loss on the covariance between different embedding variables, encouraging them to be close to zero, and hence preventing a representation collapse. The proposed model does not require the embedding branches to be identical, nor does it require mining of contrastive pairs. Experiments are conducted to demonstrate the effectiveness of the proposed regularization.",
    "This paper proposes a simple and effective method(VICReg) that prevents the collapse in self-supervised learning with two regularizations terms. The variance term maintains the variance of the embedded vector along each dimension independently. The covariance term prevents the network encode similar information to the same dimension in the embedded space.",
    "The authors propose a self-supervision technique with a more flexible structure requirements such as  not requiring batch norm, normalization, weight sharing or quantization.  Their model uses 2 encoders and a loss function with 3 variance and covariance regularization terms.  The authors mention that compared with the previous works, their main novelty lies in one of their variance terms which adjusts the variance of each input dimensions and, in return expected to mitigate collapsing problem. The authors claim that not sharing weights and having regularization terms separate on each encoder branch make their model better suited for multimodal inputs and tasks. They show results mainly on ImageNet classification, object detection tasks, with an ablation study on their and other baseline methods by varying regularization terms.",
    "This paper proposes a new active reward learning method called IDRL, designed to select the most informative query for identifying an optimal policy among a set of plausibly optimal policies. First, IDRL selects two candidate policies that maximize the entropy of the difference in expected returns given past queries. Then IDRL chooses queries that reduce the uncertainty of the return difference most among a set of candidate queries. Updating the reward model using the selected queries rather than queries maximizing the information gain about the reward stimulates identifying the optimal policy. Experimental results show that IDRL requires fewer queries than the considered baselines and works with different query types.",
    "The authors propose a Bayesian method for learning the reward function in an RL setting.  They study the setting in which the algorithm can query experts.  The form these queries can take is quite general.  They analyse their algorithm theoretically and empirically.  Their key insight is that queries should be focused on enabling the reward model to be used to find the best policy possible (as efficiently as possible), rather than decreasing the reward model\u2019s uncertainty in general. ",
    "The authors introduce a query selection strategy for reward learning in reinforcement learning. This strategy can use different query types and is not restricted to pairwise trajectory queries, as many other approaches. Additionally, the strategy is also considering the environment dynamics. The papers main contribution is a method, that reduces the number of required queries, besides the aforementioned aspects. The authors also show, that the approach is also applicable to Deep RL techniques.",
    "Information Directed Reward Learning (IDRL) actively selects queries that are most informative at distinguishing policies in terms of their value. By contrast, prior work has typically tried to maximize information gained about the reward function itself -- but some parts of the state space may be unreachable, or never visited by any plausible optimal policy, and so learning about them is irrelevant for task performance. IDRL has a pleasing theoretical motivation, although practical implementations of it require considerable use of approximations and heuristics. Additionally, IDRL is compatible with a broad variety of reward learning queries (e.g. preference comparisons, labeling trajectories with returns) whereas most prior work focuses on a single feedback modality. Experimental results show significant improvements in sample efficiency from use of IDRL relative to a variety of baselines.",
    "This paper proposes and analyzes a method for generating trained weights already optimized for a given single task for a large class of diverse architectures using Graph hypernetworks. They introduce a new DEEPNETS-1M benchmark with in-distribution and out of distribution architectures. The work also proposed three main improvements to improve performance of their GHN: normalization of predicted parameters, enhanced long-range interactions in the GHN, and meta-batching of architectures.  They demonstrate that their method is able to produce weights that do surprisingly well on unseen and diverse networks in less than 1 second on CPU or GPU for CIFAR-10 and Imagenet. They demonstrate that even for large Resnet-50s which are out of the training distribution, they could achieve 60% accuracy on CIFAR10.",
    "This paper studied the problem of parameter prediction for deep neural networks. Especially, the authors focused on the task of predicting parameters for various network structures with a single hypernetwork. The method is based GHN and introduces several important modifications. To evaluate the performance of the proposed method, a standardized benchmark is introduced.  The improved method showed impressive performance on CIFAR-10 and ImageNet even with large neural networks. Besides, the method is also proved to be useful in architecture representation learning.   ",
    "In this paper, the authors propose the task of parameter prediction with a new DeepNets-1M dataset. By using a improved Graph HyperNetwork, they can achieve reasonable performance for unseen and diverse networks without iterative optimization. The learned neural architecture representation also performs better than previous works.",
    "This paper propose a way to predict/generate the parameters of an image based deep network instead of training it via SGD. It's a thought-provoking paper and the authors appears to be very detailed in their implementation. The results are surprisingly good but not better than standard optimization algorithms.",
    "The paper characterizes the perception-distortion in the context of (image) enhancement tradeoff, complementing prior results. For example, in image super resolution, this tradeoff describes the relationship between the point-wise reconstruction quality (distortion) and how well the distribution of the reconstructions match the distribution of the high-resolution data one aims to reconstruct. The paper derives this general tradeoff explicitly and characterizes certain aspects specifically for Gaussian distributions. The theoretical results are illustrated with experiments.",
    "Distortion-perception is the phenomenon that the better a criterion (on natural images) is optimized (for instance SNR in image denoising) the stronger the deviation to the distribution of the space of natural images. This paper characterises this phenomenon under Mean Squared Error (MSE) as the criterion under a Wasserstein bound on the conditional distribution. The result is an interpolation between the distribution of the conditional distribution and the distribution itself. An explicit formulation of the optimizer of their Distortion-perception function is provided. Simulations are made, showing that interpolating different models that approximates the quantities in their theoretical formulation can achieve better visual aspect.",
    "The authors of this paper suggest that they show four novel contributions to the image compression literature that hold true for MSE distortion and Wasserstein-2 perception index: 1. They prove that the Distortion-perception function is always quadratic in the perception constraint P regardless of the underlying distribution 2.  The show that it is possible to construct estimators of the Distortion-perception curve from estimators at the two extremes of the tradeoff (the one that globally minimizes MSE and the one that minimizes MSE under a perfect perceptual quality constraint). 3.In the gaussian setting, they provide a closed form expression for optimal estimators and the corresponding Distortion-perception curve, they also show that this is a lower bound on the curve of any distribution having the same second-order stats. 4.They illustrate their results conclusively with super-resolution as their test case.",
    "The paper studies the trade-off between minimizing the mean-square error (distortion) and the Wasserstein-2 distance (perception) when constructing an estimator \\hat{X} of a random variable X. In particular, the work analyzes a distortion-perception function, which given the radius P of a Wasserstein-2 ball around X returns the minimal mean-square error of \\hat{X} constrained to be in that ball.   The analysis reveals that for estimators with small Wasserstein-2 distance to the true distribution, one can often obtain an estimator with much better mean-square error by a simple linear interpolation in the output space.   The theoretical results are applied to deep image super-resolution, where it is shown that the perceptual quality of an estimator with small MSE can be improved by interpolating it with one having small Wasserstein-2 distance. Remarkably, the interpolated estimator often still has low MSE, while significantly lower Wasserstein-2 distance, leading to a greatly improved perceptual quality. ",
    "This paper proposes a means to encode text feature for nodes in textual graphs, where a layerwise aggregation module (implemented as a multi-head self-attention) is appended after each Transformer encoder block that aggregates the hidden representations of (sampled) neighbor nodes. The produced contextual representations are dispatched to each node for the computation of next Transformer encoder block. To mitigate the possible model degradation issue that the aggregation module might be insufficiently trained, the authors also propose a two-stage training schedule where the model is first trained on nodes with corrupted inputs until convergence and then trained on normal data.",
    "For representation learning on textual graphs, Cascaded Transformers-GNN architectures have been used, as language models and GNN are independently and consecutively deployed. The authors' claims, however, this approach has a limitation of information fusion of text encoding and graph structures. The authors proposed GNN-nested Transformers named as GraphFormers, where GNN components are nested alongside the transformer layers of language models. Also, the author proposed a progressive learning strategy and unidirectional graph attention to effectively train the graph network modules. The efficacy of the GraphFormers is demonstrated on 3 textual graph datasets (DBLP, Wiki, and Product Ads datasets), achieving SOTA performance.",
    "The paper proposes GraphFormer, an architecture built on top of GAT and Transformers for textual graphs. The motivation behind the architecture is that the existing techniques on textual graphs involve a cascade process where the nodes are first encoded using a language model after which a GNN is applied. With GraphFormers, the graph aggregation and encoding can happen iteratively, allowing for better contextualization of nodes with text like \u201cnotes on transformers\u201d since transformers can be interpreted as ML models or electrical devices depending on the surrounding context.  The authors also lay out a 2-step training procedure whereby they first train on a version of the graph with injected noise via link prediction before training on the actual graph. The motivation behind this is given as the fact that training on the graph with injected noise makes the GNN component of the GraphFormer model more robust without which the transformer part will dominate.",
    "This paper proposes GraphFormers for text graph tasks where GNNs are nested in each layer of the transformer-based pretrained language model. In this way, each node can appropriate graph structure to build semantic representations more effectively. Two-stage progressive training and unidirectional graph aggregation are further proposed to improve representation quality and avoid unnecessary computation. They use three real-world million-scale textual graph datasets (DBMLP, Wikidata, Product Graph) and demonstrate consistent improvements compared with traditional cascaded transformers-GNN models.",
    "The paper studies learning problems under so-called user-level differential privacy: in this setting, each one of n users holds m data points of the training set. This type of privacy then requires that under a change of *any number of data points belonging to a single user*, the distributions over the outputs of the algorithm are close in the sense of (epsilon, delta)-DP. A trivial way this could be achieved is group-privacy, where the privacy parameters would degrade linearly with the number of samples m.   The paper first gives a private mean estimation algorithm for the 1-dimensional case, which, given an input dataset that is both bounded in [-B,B] and (tau, gamma)-concentrated (that is, with probability gamma all points are within tau of a center point), returns an estimate that is close to the empirical mean plus a Laplace noise term of order tau/epsilon*n. This is then extended to the d-dimensional setting, using a random rotation of the data to ensure that each dimension is bounded appropriately in ell-2 norm rather than the ell-infty norm, and using the 1-dimensional solution on each dimension. Both these algorithms are *not* user-level DP but are used in the rest of the paper as building blocks of user-level DP algorithms.  The first application of these is a user-level DP d-dimensional mean estimation algorithm which, given samples from a distribution P supported on the euclidean ball with radius B, has squared ell-2 error in the order of sqrt{Var(P)/(m*n)}+\\sqrt{d}*B/(\\sqrt{m}*n*epsilon). The error due to privacy in this result degrades with 1/\\sqrt{m} rather than being independent of m which is what the trivial approach would give us.  Using these tools, the authors then present user-level DP algorithms for empirical risk minimization with smooth convex, strongly convex, and non-convex losses as well as for stochastic convex optimization (SCO) with subgaussian gradients, demonstrating this improvement of 1/sqrt{m} in the error bounds.  They finally prove lower bounds that show that both the latter result on SCO (although not in all generality) as well as the d-dimensional user-level DP mean estimation bound are tight. ",
    "The paper proposes a new private mean estimation mechanism with estimation error proportional to the concentration radius of queries. The mechanism is applied to stochastic optimization algorithms to solve user-level private empirical risk minimization (ERM) and user-level private stochastic convex optimization (SCO) with improved performance for concentrated queries.  Contributions: 1. A new private mean estimation mechanism with error scaling with query concentration radius. 2. New algorithms for user-level private ERM and user-level private SCO with error scaling with concentration radius of gradients.",
    "This paper provides algorithms for various learning tasks under the constraint of user-level differential privacy. Specifically, they provide solutions for problems like mean estimation, empirical risk minimisation, stochastic convex optimisation, and learning hypothesis classes with finite metric entropy. They also provide lower bounds showing optimality of their algorithms for mean estimation and stochastic convex optimisation for different settings.  For mean estimation, they consider 1D distributions (and extend to higher dimensions, too) that are bounded within an interval, but are concentrated in some smaller sub-interval. Using this, they show that for uniformly concentrated queries, they can adaptively answer $K$ queries with a small privacy cost depending polynomially in the concentration parameter ($\\tau$) and $K$.  For empirical risk minimisation and stochastic convex optimisation, they assume that each user's data is drawn i.i.d. from different distribution, such that all the distributions are close in TV distance.  They also show that even when each user contributes infinite samples, there would still be some error.",
    "This paper deals with DP in a setting where all users contribute m datapoints to the given dataset, and the curator wishes to maintain DP on a user-level. The main result of the paper is a SGD algorithm (or an iterative aggregator) in which for each user the m datapoints are averaged then an update step takes place w.r.t the avg. Utility bounds for the approach are given in Thm 3 and 4. In addition the authors give a (close) lower bound in Thm 5.",
    "In this work, the authors solve for the infinite time mean predictor of a model with weight decay trained via noisy full batch gradient descent. The authors develop a general formalism appropriate for model weights initialized with mean zero and variance related to the weight decay and gradient noise parameters and push this formalism to explicit characterization of the model output for the case of one-hidden-layer linear teacher student CNNs trained with MSE loss and quadratic teacher student fully connected DNNs. In the former case, the authors observe a phase transition between the lazy and feature learning regimes as the model width decreases.",
    "This work addresses the question of how finite-width DNNs differ from their infinite-width GP limit. This is important since, while the GP limit is a powerful theoretical tool for studying DNNs, it's unable to capture _feature learning_, a key behavior of DNNs. The authors show that the mean predictor of a finite DNN trained with noisy gradients and weight decay corresponds to GP regression on a shifted target, and give an approximation for the shift based on the cumulants of the prior. They apply the framework to two toy models. In particular, for a two-layer linear CNN they derive a large-training-set approximation for the cumulants, and show that as the width increases, there is a phase transition out of the feature-learning regime.  ",
    "The authors develop a self-consistent Gaussian Processes (GPs) theory to account for finite size effects in Deep neural networks (DNNs). The equivalence between GPs and DNNs is a well known result that holds in the so called \u2018lazy learning\u2019 regime in the infinite width/channel limit, where the DNNs\u2019 parameters don\u2019t change during training. In practical contexts, however, DNNs are finitely sized and operate in a different regime, called \u2018feature learning\u2019, where parameters change substantially during training. This paper provides a theoretical framework to account for finite size effects, and so it allows to investigate the feature learning regime.  To accomplish this, the authors consider the partition function $Z$ associated with the DNN posterior distribution $P(f)$, in the case of training via noisy (full batch) gradient flow with MSE loss. $Z$ is given by an integral over the prior distribution $P_0(f)$, which can be expressed in terms of cumulants. Following their notation, $C$ is the hyper-parameter controlling the over-parametrization. In the infinite-$C$ limit, only the first two cumulants survive, and the standard GP-DNN equivalence is recovered, with the GP kernel given by the second cumulant. For $C$ finite, all cumulants contribute, and the authors have to rely on a saddle point approximation to make progress. By doing so, they arrive at a self-consistent set of equations for the target shift that describes the predictive mean of the DNN. In fact, the predictive mean is given by the same GP-like expression found for the infinite-$C$ limit, though with shifted targets. Next, the authors consider a second order expansion of the action so as to evaluate the posterior covariance.  In order to test their results, the authors consider two examples of DNN architectures that over-perform their associated GPs. Of the two, they mostly focus on the case of a linear two-layer CNN, in a teacher-student set up.  For this simple architecture, the cumulants can be worked out analytically. However, in order to deal with the series appearing in the expression of $P_0(f)$, the authors consider the limit of infinite number of training data, also known as Equivalent Kernel limit. This leads to an analytical expression for $\\alpha$, the proportionality factor between the discrepancy in prediction and the target value. Numerical verifications confirm their theoretical predictions (showing mismatches decreasing with the number of training samples). By modelling the empirical weight covariance matrix as a Wishart matrix with a rank-one perturbation, the authors are able to detect a feature learning transition for this model. This is marked by the appearance of outliers in the associated spiked Marchenko-Pastur eigenvalue spectrum.  Finally, the authors consider the case of a two-layer FCN with average pooling and quadratic activations, with a rank-1 teacher. They provide the expression of the cumulant generating function, as well as the equation for the targets shift, and leave the analysis to Appendix I.",
    "This paper introduces a new perspective on feature learning in wide neural networks by demonstrating that DNNs trained with noisy gradients and large training data converge to solutions with mean predictions dictated by GP regression with shifted targets when using MSE loss. The authors then consider two toy CNN models, one linear and one non-linear, where they are able to make more analytic progress with their theory, and demonstrate the benefits of of feature learning of wide enough but finite NNs compared to their corresponding infinite-width GPs in terms of sample complextiy on student-teacher tasks. Finally, they also show a phase transition (marked by a critical value of width/channels) in the distribution of eigenvalues empirical covariance of weights in the first layer of a CNN instantiation, between a feature learning regime (where there is an outlier eigenvalue that is associated to the teacher's features) and a non-feature learning regime. Experimental evidence is provided to support these claims. ",
    "This paper adds results to the literature on learning compositional emergent communication protocols. Two results are theoretical: that inductive biases are required in order for compositional communication to emerge, and that adding a noisy channel with a specific loss function leads to compositional language emergence. The third result is a small-scale empirical corroboration of the latter theoretical result in a speaker-listener game.",
    "The authors analyze the effect of a _noisy channel_ on an emergent communication protocol.  In particular, they show that languages that minimize losses involving this noise are compositional [in their sense of the term] and then conduct a very thorough set of experiments while varying noise in a standard emergent communication.  They find that compositionality tends to go up for some low levels of noise, but then goes down after that (and accuracy tends to go down consistently with more noise).  There is also a very thorough set of experiments manipulating myriad factors in the setup and finding that the overall patterns just discussed are robust.  The paper is a very interesting theoretical and experimental contribution to the emergent communication literature.  My only minor complaint would be that there are so many experimental results that it's easy for the reader to lose the forest for the trees; more synthesis of the overall trends would be welcome.",
    "The paper presents theoretical and empirical results showing that a specific type of utterance noise in a sender-receiver emergent communications architecture leads to compositional utterances, under certain constraints, and that the resulting loss function has all local minimum as global minimum (they don't state explicitly that all local minimum are global minimum, but there results strongly implies to me that they are). The following constraints need to be met in order to satisfy the theoretical proof: - message length = number of attributes - the input to the sender network should be a bag of attributes, not a non-symbolic, e.g. pixel, input (note that the paper calls attributes 'factors') - the vocab size of the utterance should exactly match the number of attribute values - the utterances are discretized using Gumbel, so we can backprop through them, and not using a discrete sampling, which would require REINFORCE - a specific type of noise is added to the utterances, which randomly flips/corrupts each specific token with an identical probability $\\epsilon$ - the noise should be more than 0, and less then (vocab size - 1) / vocab size  The paper presents theoretical results basd on Locatello et al that show that without sufficiently strong inductive biases, that one cannot the utterances to be disentangled.  The paper presents comprehensive empirical results for scenarios which both somewhat align with the theoretical constraints above, and also that deviate strongly from these constraints. For example, all the experiments use non-symbolic inputs, which is therefore not a bag of attributes input. Most of the experiments use a message length that does match the number of attributes, but some experiments are done using longer utterances, and show similar results to the shorter messages.  The paper evaluates the results using 4 existing compositional metrics: topographic similarity, conflict count, context independence, and positional disentanglement. ",
    "The community has been looking at compositional generalisation more recently, and while Fodor and Pyshylynn is an oft cited work, there is a lack of a good definition of compositionality that researchers can agree on.   This paper suggests that a noisy channel with an encoder decoder setup is crucial for the emergence of compositionality. The authors propose a simple definition of compositionality in a non-hierarchical case, and discuss how 1) if no assumptions or prior information about the data is incorporated into the training process, the resulting methods will be uncompositional, 2) if this inductive bias is injected through the use of a noisy channel, there are losses (namely J_1, J_2) that can be used to encourage the rise of a compositional encoding.   The basic setup involves communication through a noisy channel. They then discuss how, if the encoding is compositional, there are particular losses (J_1, and J_2) that will be optimal. More importantly, when J_2 is optimal, the encoding is compositional. In their experiments, they use J_1 primarily, and demonstrate compositional emergence (according to some metrics) under some circumstances.  ",
    "The paper proposes an MLP-based architecture for sequence-based DL tasks (vision, NLP). Basically, the idea is to remove the self-attention primitive from Transformers. Instead, it transposes the seq and channel dimension and applies linear projections. This is the same idea as the concurrent work MLP-Mixer from Google. The spatial mixing is now basically a DWise Conv with full receptive field shared across channels. Paper shows reasonable results on ImageNet benchmark (needs a lot more params and worse on throughput for the same top-1 accuracy wrt ViT, and also worse than pure ConvNet baselines). Paper has plenty of ablations on the training recipe and architecture. NLP tasks only include short sequence benchmarks like Translation, with promising signs.",
    "This paper introduces Residual Multi-Layer Perceptrons (ResMLP): a purely multi-layer perceptron (MLP) based architecture for image classification. ResMLP takes image patches as input, projects them with a linear layer, and sequentially updates them in turn with two residual operations: (i) a simple linear layer that provides interaction between the patches, which is applied to all channels independently; and (ii) an MLP with a single hidden layer, which is independently applied to all patches. At the end of the network, the patches are average pooled, and fed to a linear classifier. The main change from ViT to ResMLP is replacing the self-attention layer with a simple linear layer cross patches. There are some other small changes, like pooling layers and normalization layers.  The claimed contributions are: 1. despite their simplicity, Residual Multi-Layer Perceptrons reach surprisingly good accuracy/complexity trade-offs with ImageNet-1k training only. From this point of view, this \"surprisingly good\" is very subjective. At least, from the results, the accuracy/complexity trade-offs is not as good as Vision Transformers (DeiT models). 2. The ResMLP benefits from distillation methods and also works well with self-supervised method DINO. 3. The simple linear layer enables observations on the spatial interaction that the network learns across layers. 4. The authors also try ResMLP on machine translation.   ",
    "Recently, vision Transformers have been popular and achieve SOTA performance on various tasks. This paper proposes a more simple variant of the Transformer architecture, *i.e.*, connect image patches via simple linear/MLP layers. The proposed ResMLP shows promising performance under various setups, *e.g.*, supervised and self-supervised training, and on different datasets. It is a new exploration of the methodology of neural architectures.",
    "This paper introduce the ResMLP architecture. An alternative to self-attention layer in vision transformer using simply a $T \\times T$ linear layer to allow long-range communication between tokens. They show that the performance of this model is comparable to the original vision transformer in supervised, self-supervised and transfer learning as well as knowledge distillation. ",
    "The author proposed an online learning setting where the true label is determined by which of k centers is the closest from the query point for a distance function.  The goal of the learner is to minimize the total distance from each query to the region corresponding to the correct label. The authors then propose learning algorithms for these settings and provide a theoretical analysis of the proposed algorithms. The authors also show interesting properties of this learning setting that could not be achieved in the traditional multiclass learning setting.",
    "This paper proposes an online multiclass classifier that minimizes the distance between a point and the correct class partition for that point\u2019s label. They argue that this loss function punishes more harshly points that are classified as extremely wrong versus almost correct. They propose an algorithm where in every round, their classifier predicts a point and suffers the distance based loss between their predicted point and the correct class region. ",
    "The paper considers the problem of online prediction of which region of a k-centred nearest-neighbour partition (where \u201cnearest\u201d is defined via a \u201cdistance\u201d function) a point is in. The feedback on each trial is which region the point is in - as in standard online learning. However, instead of bounding the number of mistakes, this paper seeks to bound the total loss, where the loss on a trial is the \u201cdistance\u201d of the point to the region predicted (see the main review for a confusion I have here). The paper considers two types of \u201cdistance\u201d - the (negative of the) inner product and the p-norm. The paper gives loss bounds that are independent of the total number of trials and don\u2019t have a \u201cmargin\u201d term.",
    "The work addresses an online learning problem, where the algorithm receives a sequence of points q_1,q_2,... in the d-dimensional unit ball, and must guess the label of each point among k possible labels {1,...,k}. The correct label corresponds to a nearest-neighbor partition of the ball, R_1,...,R_k determined by k unknown \"centers\" x_1,...,x_k. If the algorithm predicts that a point q has label i, it incurs a loss equal to the distance between q and the subset R_i of the points labelled as i. The goal is to minimize the total loss. The main result is a set of upper bounds on the loss in the form poly(d), or similar, but in any case independent of the length T of the sequence. The work considers also the special case k=2, the case of general convex classes (for which it gives lower bounds), as well as some other implications of the upper bounds. ",
    "This paper proposes a new loss terms to encourage Transformer-based models perform \"explicit reasoning\", which is beneficial for transferring knowledge from oracle-trained VQA models to deployable ones. Specifically, the novel loss is similar with the one commonly used in modular network (e.g. converting questions to executable program/functions), but instead of relying on the predicted programs to assemble executable programs during inference, in this paper this loss is only used during training as an auxiliary regularization on top of regular Transformer-based VQA models. The authors provide theoretical proof about the benefits of using the additional loss, and empirically evaluated the advantage on GQA dataset (including out-of-distribution evaluation on GQA-OOD). The proposed system demonstrates not the best but still competitive performance especially considering the model size and training efficiency (without using extra data).  ========================================================================================  Thanks for the response from the authors. I've updated my rating after reading the rebuttal as well as the comments from other reviewers.",
    "The paper studies the problem of training VQA models on noisy/imperfect visual input (e.g., representations from existing object detectors). It proposes using program supervision as an additional task to assist in transferring reasoning patterns learned through clean/oracle visual inputs to the imperfect inputs. The experiments are performed on the GQA/GQA-OOD benchmarks, and the empirical results show gains on both frequent (head) and infrequent (tail) classes, showing improvement in reasoning skills. Furthermore, the work theoretically shows that predicting programs can reduce sample complexity.",
    "This paper targets on the application problem of visual question answering, whose recent state of the art was set by attention (typically transformer) - based deep neural networks. This work propose to use program supervision to introduce extra loss terms in the training of these transformer based models, arguing that the guidance from these signals improve the model's robustness against noise and fluctuations in the visual input during transfer learning. Theoretical analysis and experimental evaluations are conducted on program supervision, leading to plausible findings and results.",
    "This paper describes a novel approach for doing more robust VQA that doesn\u2019t just learn to exploit the biases in the data. They build on previous work which demonstrated that training a model on oracle visual data makes it less susceptible to learning biases in the data. While the previous work showed that the better reasoning skills learnt by the models trained on oracle visuals decline when transferred to the noisier visuals extracted by pre-trained vision models, here the authors demonstrate that adding the additional supervision step of making the model predict the reasoning program alongside the VQA answer makes it more robust to such distributional shifts. ",
    "The paper presents 3 main theoretical results: - An RNN with 40 unbounded-precision neurons is Turing-complete. - An RNN with 54 bounded-precision neurons and two stacks is Turing-complete. - An RNN with a finite number of bounded-precision neurons and no stacks can simulate a Turing machine with a bounded tape, where the maximum tape length is related to the number of RNN neurons.",
    "This paper analyses the Turing completeness of recurrent neural networks, and proposes a memory-augmented RNN architecture reminiscent of existing stack RNNs.   Specifically:  First, a construction for simulating any Turing machine with an unbounded-precision RNN is presented, in which effectively the left and right sides of the Turing machine's tape (with respect to its head) are encoded as two 'stacks' in the RNN. This construction is analysed and requires less simulation time than that of Siegelmann and Sonntag [1] (3T instead of 4T+O(used tape length), where T is computation time of the simulated Turing machine). Additionally the authors analyse the exact precision of the neurons necessary (as function of the simulated Turing machine's computation length) for the simulation (as opposed to previous works, which simply note a requirement for infinite precision).  Second, noting that it is unavoidable that the precision must grow when simulating longer Turing machine computations (to maintain the contents of the tape), the authors propose augmenting the RNN with a dynamic memory module, such that the neurons themselves may have constant, bounded, precision. They theoretically analyse their proposed architecture and show how a Turing machine may be simulated in it.   ",
    "This work proposes a dynamic-growing memory module for RNNs, which serves to simulate Turing machines of bounded precision.  First, the authors prove how to encode a Turing machine to an unbounded precision RNN. The encoding uses fractal encoding for symbols, like previous work, and it replaces each step of the Turing machine as 3 steps in the RNN. Leaning in the work of [14], they prove that there is a 40-neuron unbounded precision RNN to simulate any Turing machine (i.e., showing Turing-completeness). Next, they consider the previous unbounded-precision definitions with the memory module to obtain a bounded-precision RNN.The memory module is a stack of neurons, that requires two neurons in the RNN to control it: push and pop. Then it is proven that the proposed bounded-precision RNN utilizes 2 of these stack to simulate a Turing machine. Further, each stack is divided in groups of $p$ neurons, such that the most active neurons are in the RNN (near to each side of the memory head in the Turing machine). Leaning again in [14], they can show that there is a 54-neuron with $p$-precision RNN with 2 growing memory module, that can simulate any Turing machine. This proves Turing-completeness of the precision-bounded RNN. Finally, they remove the growing memory module and simulate the memory within the neurons of an RNN, showing that an infinite number of bounded-precision RNN can simulate any Turing machine. the work finishes with an interesting discussion of the results and limitations.    ",
    "This theoretical work shows the existence of un-bounded precision RNNs for simulating turing machines, with growing/shrinking memory module. Although the paper seems quite interesting and well-written, I am afraid I don't have the right background to make an accurate judgment on the novelty and potential impact of the work. I share few thoughts below, similarly due to lack-of-knowledge and limited reviewing time I was not able to check the proofs. ",
    "In this work, the authors consider linear quantile regression, paying particular attention to the \"coverage\" properties of the resulting predictor. The traditional goal of quantile regression is to learn a quantile of the conditional distribution of output $Y$, conditioned on the inputs $X$. Denoting the predictor returned by any quantile regression algorithm by $\\hat{f}(\\cdot)$, one can use this to construct a predictive interval for a freshly-drawn $Y$. The authors consider the one-sided interval $C(X) = (-\\infty, \\hat{f}(X)]$, and the event $\\\\{ Y \\in C(X) \\\\}$. The authors call the probability of this event (over the draw of a pair $(X,Y)$) the coverage of $\\hat{f}$. Their main results elucidate conditions under which the traditional pinball-loss based ERM quantile regression solution is biased below the desired quantile level, that is, the predictive interval tends to be \"too small,\" due to $\\hat{f}$ under-estimating the desired quantile.  In particular, they show that in the limit where the sample size and dimensionality are proportional, the coverage (the aforementioned probability, which depends on $\\hat{f}$ and thus the training data) converges below the desired quantile, with this error depending directly on the ratio of dimension to sample size $d/n$. Furthermore, they show (under fixed $n$ and $d$) how for a certain family of data distributions and a linear quantile model, given any estimator of the weights, the downward bias term scales with the weight estimation error. Their empirical tests also effectively highlight the phenomena described formally.",
    "This paper presents a theoretical study on the coverage of quantile regression algorithms. More specifically, the authors prove theoretically that linear quantile regression exhibits an inherent under-coverage bias, with an order d/n difference in the marginal coverage regardless of the noise distribution (but Gaussian for the covariates). They also show that the primary source of this under-coverage bias is the estimation error in the linear coefficients, while the estimation error in the bias term can have either an under- or over-coverage effect. Numerical experiments further support their findings.",
    "Quantifying predictive uncertainty is a crucial task for high-stakes prediction problems. The paper focus on quantile regression, a common approach for quantifying predictive uncertainty in regression problems. Authors consider realizable linear setting when the true model belongs to the considered functional class. With a focus on the under-parameterized setting, they theoretically justify the under-coverage of the learnt quantile regressors. Established theoretical results are backed up with supporting empirical evidence.",
    "This paper gives theoretical insights into the under-coverage phenomenon often observed in quantile regression, i.e., for a continuous distribution, the probability of observing  a true label below a learned  $\\alpha$-quantile is often below $\\alpha$, which is consider a failure in estimating the uncertainty. Two important results are shown. The first one provides a characterization of the under-coverage in the setting of a Gaussian linear model in the under-parameterized high-dimensional proportional limit (i.e. $d,n \\rightarrow \\infty$ , $d/n\\rightarrow\\kappa$ with small $\\kappa$) independently of the noise distribution. The experimental results show that the formulas match pretty well the observed coverage in realistic situations of dimension around 100, on synthetic and real data. The second important result shows that the source of the under-coverage stems essentially from the error in estimating the high-dimensional linear coefficient, under some assumptions on the underlying source.",
    "The paper proposes a RL-based memory management policy for CIL problem. They have two-step formulation of policy, which first determines how to allocate the memory to old and new tasks, then determines how many samples to store per each class within the task. A standard RL framework of policy gradient method is used to optimize their policy. Experimental results how that their RMM can further improve the recent state-of-the-art methods, such as LUCIR or PODNet. ",
    "The paper proposes a new memory sampling strategy which replaces random/herding. The strategy consists of two parts: first level determining the distribution of #samples of each class in memory and second level determining samples to be selected for every class. This is learnt via RL policy. The sampler is trained by emulating a pseudo-CL problem with the data available in the pretraining phase-- where there are an equal number of tasks made as expected in the CL setup to enable transfer. Given a sampling configuration, a CL method trains the model and the performance on the pseudo-CL test set is given as reward to the RL algorithm. This trains the policy components, which optimize sample size and samples per class and train CL. Then, the best policy is used to create the memory which is used to train the actual CL problem with state-of-the-art continual learning approaches. This memory selection achieves better performance than previously used memories across CIFAR100, Imagenet100 and Imagenet1000 datasets.",
    "This work addresses the problem of memory management in Class Incremental Learning (CLI). In this setup, models store exemplars from old classes and must decide what exemplars to drop to make space to new memories. The authors propose a hierarchical reinforcement learning approach where an agent first chooses how much of the old memory to release to make space for new samples and then it chooses how much of the new space allocate to high-entropy samples and low-entropy samples (they divide new classes in two groups). Experiments show that the the proposed method attains better performance than POD-AANets and LUCIR on CIFAR and ImageNet. In the supplementary material they show that the proposed memory management system also improves the performance of already-existing systems. Additional studies show how policies transfer between datasets, the impact of hierarchical RL, and how old and new memories balance over time. ",
    "A common approach in class-incremental learning is to retain a fixed set of examples of the old classes to help avoid forgetting. The paper presents an approach to dynamically retain exemplars for the class-incremental learning problem. Reinforcement learning is used for dynamic memory management.",
    "This paper analyzes local SGD with progressively decreasing communication frequency under the homogeneous data assumption. Unfortunately, the obtained convergence rates are worse than the best-known convergence rates for FedAC (Yuan and Ma) under the same set of assumptions. The paper also analyses One-shot averaging under a slightly different set of assumptions, showing it retains its linear convergence in settings less restrictive than pre-existing literature. Since the major result of this paper is worse than FedAC's guarantee, it is very incremental.    **References**  Yuan, Honglin, and Tengyu Ma. \"Federated Accelerated Stochastic Gradient Descent.\" Advances in Neural Information Processing Systems 33 (2020).",
    "## Update after rebuttall  I am satisfied with the authors' response and elevate my score to 6.  ##  This paper presents several new theoretical results on the convergence of Local SGD as well as numerical experiments to check the tightness of the theory. In particular, the authors try and remove logarithmic terms from the bounds of Local SGD by making the communication less frequent as the iteration counter increases. The main results of the paper are:  1. Theorem 1 gives convergence for strongly convex functions under uniform-with-strong-growth noise. I argue in my detailed review that this result looks suboptimal.  2. Theorem 2 gives a result for PL functions with sub-Gaussian noise for one-shot averaging. This result is interesting as it promises a linear speed-up, although under somewhat restrictive assumptions.   3. The experiments show that linear speed-up is lost when the number of communication rounds is chosen smaller than predicted by the theory of Theorem 1.  I tend to vote for rejection of this work, even though I appreciate some of the results obtained here. My main concerns are 1) applicability of the message to neural network training, which is highly relevant to FL; 2) the theoretical improvements appear to be small; 3) some small flaws in the proofs.",
    "In this paper, the authors study the theoretical speedup of local SGD and one-shot averaging. A synchronization scheme that communicates more frequently at the beginning is also suggested. Some simple numerical experiments are provided to verify the theoretical results.",
    "This paper investigates the gap between local SGD and One-Shot averaging in communication efficacy and linear speed-up with respect to the number of workers. Through extensive analysis, they show that they can tighten the bound for the number of communication required for local SGD to $\\Omega\\left(N\\right)$, which is the number of workers. They have proved this bound for strongly convex and objectives with PL condition, where the strong convexity can be a special case of it. They use the idea of adaptive local step to have a more frequent communication at the beginning of the training and less frequent one at the end. In their experimental section, they show that their proposal can converge to the same rate as other local SGD approaches and Sync SGD using  $\\Omega\\left(N\\right)$ communication rounds.",
    "They authors show that for linear optimization on strongly convex domains the lazy subgradient method achieves a best-of-both-worlds behavior of a expected regret bound of O(\\sqrt{N}) and O(\\log(N)) for adversarial and stochastic adversaries, respectively. The best known prior bounds were O(\\sqrt{log(N)}) adversarial regret with a more complicated algorithm (based on A,B-prod). On a technical side, the analysis for lazy subgradient is much more intricate and considers loss contributions in the direction of the comparator separately from other directions, and may be of interest in other online linear optimization settings.  Simulations are provided that convincingly argue for the proposed method in the proposed setting.  ",
    "The authors study online linear optimization in the case of known strongly convex constraints sets. They show that the simple method of online subgradient descent, which is known to achieve $O(\\sqrt{N})$ regret in the adversarial case, also achieves $O(\\log(N))$ regret in the i.i.d. case. This result is more elegant than and slightly improves upon existing results in the strongly convex case.",
    "The paper considers the problem of online linear optimization under a full information feedback setting on a strongly convex domain. In this setting, the authors show that the classical lazy subgradient method is optimal both in the adversarial and stochastic settings.  In particular, the authors show that for the same choice of hyper-parameters, the lazy sub-gradient method achieves O(\\sqrt{N}) regret in the adversarial setting and O(log{N}) regret in the stochastic setting. To show this result, the authors have to do a more nuanced analysis of the algorithm (that relies on differential geometry methods) than existing works.   ",
    "The authors study online linear optimization and show that the Lazy Online Subgradient Algorithm is *universal* on strongly convex domains: it simultaneously achieves the optimal $O(\\sqrt T)$ regret when the costs are adversarial and the optimal $O(\\log T)$ regret when the costs are stochastic. This result is a clear improvement over previous work of Huang et al, who described a more complex algorithm and didn't achieve the optimal rates. The proof is based on an intricate analysis, drawing from differential geometry, of the points selected by the algorithm, and in particular, how much of each step affects regret against the minimizer $x^*$ and how much is orthogonal to the direction $x_i - x^*$ and doesn't affect regret. This technique may be of interest to the broader ML community.",
    "The authors consider the Riemannian optimization with Bures-Wasserstein (BW) geometry for symmetric positive definite (SPD) matrix manifold. The authors compare the proposed approach with its counterpart with the popular Affine-Invariant (AI) geometry.  The authors illustrate that the proposed approach (with BW geometry) is more suitable than its counterpart with AI geometry when SPD matrices are ill-conditioned. ",
    "This paper studies the Bures-Wasserstein (BW) geometry of symmetric positive-definite (SPD) matrices and compares it to the commonly-used affine-invariant (AI) geometry in the context of Riemannian optimization. It is shown theoretically that the BW geometry has several advantages. Particularly, it is shown that (i) the BW metric is linearly dependent on the SPD matrix, (ii) the condition number of the Riemannian Hessian of the BW metric is smaller than that of the AI metric, and (iii) the curvature constant of the BW metric is smaller than that of the AI metric. Based on these properties, it is shown that the convergence of Riemannian steepest descent and Riemannian trust-region based on the BW metric is faster than based on the AI metric. The theoretical results are demonstrated on simulations of six problems: weighted least squares, Lyapunov equations, trace regression, metric learning, log-det maximization, and Gaussian mixture model.",
    "This paper provides several results about the Bures-Wasserstein  (BW) geometry on the positive definite matrices. A thorough comparison with the Affine Invariant (AI) metric is made. The main focus of the paper is on optimization: is it faster to optimize a function under the AI or under the BW metric? The authors argue that when the solution of the problem $X^*$ is ill-conditioned, then algorithms derived under BW metric have faster convergence theoretical convergence. This is due to the conditioning of the Riemannian Hessian at the optimum, which is better for the BW metric when $X^*$ has poor conditioning. The authors also demonstrate that a variety of functions that are convex for the AI geometry are also convex for the BW geometry. Experiments on an array of synthetic problems validate that both Riemannian gradient descent and Riemannian trust region methods are faster in the BW geometry.",
    "This paper investigates the advantages of the Bures-Wasserstein (BW) metric over the widely used Affine Invariant (AI) one, for the manifold of symmetric positive definite (SPD) matrices. Rewriting the two metrics in a compatible manner reveals that for a wide variety of objectives, the BW metric is a linear function of the input matrix whereas the AI has a quadratic dependence. One exception is the log-det function which is included in the analysis. The paper experimentally validates that for ill-conditioned problems BW is a better choice compared to AI.",
    "This paper introduced Dynaboard, an evaluation framework in which models are uploaded to and evaluated in the cloud in a way that is reproducible and standardized. Doing so makes it easier to track other metrics that are often neglected, such as throughput, memory usage, fairness, and robustness. Finally, the paper introduces Dynascore, a measure that aggregates performance across different metrics, the weights of which can be dynamically chosen by the user to reflect their preferences.",
    "The authors of this paper introduce dynaboard, an evaluation service framework that is integrated with the dynabench platform. The goal of this service is to evaluate and benchmark the progress of NLP models whilst having a focus on reproducibility and accessibility. Dyanboard allows the models to be evaluated directly in the cloud on multiple metrics, including a focus on memory usage. To compare and rank different models, the authors compute dynascore. Further, the evaluation platform provides flexibility to the end-user to customize the dynascore based on weights. ",
    "This paper presents a platform called Dynaboard for evaluating NLP models in a cloud server and hosting a leaderboard of submitted models. The motive of this web platform is to evaluate models on multiple metrics for performance, memory use and throughput, robustness and fairness metrics for models. Since evaluation is performed on the cloud, the platform also aims to alleviate concerns about reproducibility, accessibility and backwards/forwards compatibility. Finally, users can rank models according to an aggregated metric called Dynascore, where the aggregation criteria is determined by them. The method of computing this aggregated score is based on economic theory, representing each metric as a good, where having more of a good is more beneficial.   To compute the Dynascore measure, the authors use the idea of indifference curves, which is a set of points (models) that provide the same utility. From this curve, they compute the average marginal rate of substitution, which is the rate at which model creators are willing to tradeoff a metric for a 1-point increase in performance.   Finally, the paper presents an evaluation of multiple models on 4 NLP tasks on performance, throughput and other metrics included in Dynaboard, along with their computed Dynascore. The authors find that the rankings obtained using Dynascore are more intuitive than the average z-score and that they largely preserve the rankings on the SuperGLUE leaderboard. ",
    "The paper proposes an evaluation platform \"DynaBoard\" to automatic evaluate the models for different NLP tasks according to 5 metrics: performance, throughput, memory, fairness, and robustness. The scores from these metrics can be aggregated according to the custom preferences of each user. The models can then be ranked according to the aggregated score.",
    "In this paper, the authors propose to solve the problem of text to speech generation based on video. Thus, this is video-text guided speech generation task that they term as silent video dubbing. The method is based on a transformer architecture that combines text and visual lip motion representations as encoders and outputs the mel-spectrograms through the decoder of a transformer.   The method is compared with TTS systems and comparisons are done using human evaluation scores and audio-visual synchronisation scores. This is done over LRS2 and Lip2Wav for one out of 5 speakers. Comparisons are not done using standard PESQ, STOI or Word error rates. These are standard metrics used for TTS systems. Comparison is also not provided with single speaker Lip2Wav task or multi-speaker Lip2Wav on LRW dataset as done by Lip2Wav or Vid2Speech, or such methods that generate speech based on lip motion alone (not requiring text). ",
    "The authors describe the problem of automatic dubbing of videos, ie generating speech from a script that matches the active speaking face in a video. To the best of this reviewer's knowledge, this is the first paper addressing this particular problem. The two main contributions to solve this problem is 1. a method to synchronize the generated TTS with the speaking face 2. sampling the video for a face image to infer a timbre for the speech to better match the face.  ",
    "This paper describes a novel task 'silent video dubbing' and proposes a method to solve it. The task involves generating realistic audio to accompany silent video, with the help of text. This is essentially similar to vid2speech [14], but with text guidance. The pipeline consists of several stages. (1) generating phoneme and video embeddings; (2) aligning text and video using the embeddings from (1) and attention network; (3) generating speaker embeddings to condition the decoder from images; (4) using (2) and (3) to generate the result voice. The authors provide example in supplementary materials. The experiments are performed on both single-speaker and multi-speaker SVD.",
    "This paper presents \"Neural Dubber\", a method for dubbing silent videos based on given scripts. It essentially performs lip-synced TTS, with an added component (ISE) that ensures that the generated speech characteristics match the given face image.   Experiments verify that the proposed TTS method does not hurt SOTA TTS performance, while controlling the prosody such that the aligned speech is much more synchronized than other methods compared to. The supplementary video qualitatively demonstrates some compelling results of the proposed method.",
    "This paper presents a federated split task-agnostic (FESTA) framework that can take an effective use of the vision transformer's (ViT) to perform several CXR tasks simultaneously. The authors discover that the design of ViT is ideal for split learning, in which a network is designed into a client-server mechanism. They integrate ViT into their framework by combining the benefits of federated and split learning through its decomposable design. According to the authors, a model trained with the FESTA framework can leverage robust representations from multiple related tasks to improve individual task performance.",
    "This paper combines: split learning, federated learning, multi-task learning, vision transformers, and COVID-19 chest x-ray (CXR) classification. Specifically, the authors propose the Federated Split Task-Agnostic (FESTA) framework, motivated by privacy concerns of training models with patient level healthcare data (CXRs). This framework is for training large deep learning models based on private datasets distributed over clients (i.e. hospitals). Here, each client has a local copy of a \"head\" and \"tail\" of a vision transformer model, while the server has a shared body of a vision transformer. The training process is as follows: 1.) clients perform forward passes using their local data through their head networks and send the embedded representations to the server 2.) the server performs a forward pass with the embedded representations and sends the resulting representations back to their respective clients 3.) the clients finish the forward pass through their tail networks, compute the loss, and send gradients back through the server 4.) server continues backprop, client finishes backprop, everyone updates their weights (the server's network weights will be updated considering data from _all_ clients) 5.) occasionally, all the weights from the clients head and tail networks will be averaged together (FedAvg)  Additionally, the authors consider the case where some clients are training on different tasks (e.g. image classification, segmentation, detection) using the same modality (CXRs). Here, step 5 is applied over clients with the same task.",
    "This paper presents a federated learning (FL) framework for COVID-19 xray image analysis, which leverages the natural scalibility of visual transformer to establish a multi-task FL process. The proposed method jointly learns from different clients of various x-ray-based tasks including classification, detection and segmentation in a split learning manner, in which each client preserves their only transformer head and tail while jointly learning a shared transformer body maintained in the global server. Experimental results show that the established multi-task federated learning framework with transformer improves individual performances for each COVID-19 diagnosis task and are comparable with centralized training model.",
    "The authors proposed a multi-task learning framework with a shared feature encoder (body) and separate input embedding (head) and application-wise decoder (tail) components for each task in a distributed/federated learning setting. A number of multi-head self-attention modules from the transformer model are adopted here as the body part. The Federated Split Task-Agnostic Learning (FESTA) paradigm is proposed to compute/update the model parameters of head/tail parts on the client-side and the body parts on the server-side. A list of chest x-ray datasets is employed for the experiments, including datasets for COVID-19 classification (normal, pneumonia, and COVID-19), pneumothorax segmentation, and pneumonia detection. Superior results of the proposed method are reported in comparison to other learning paradigms. The manuscript is overall well-prepared, while several things could be improved and addressed(listed below). ",
    "This work introduces a differentiable points (+normals) to mesh layer based on a differentiable formulation of Poisson surface reconstruction. First, the proposed method is validated in point cloud optimisation tasks where the objective function is expressed w.r.t surface meshes. Then, the method is proposed as a way to represent 3D shapes with oriented point cloud in a learning setting. Crucially, this results in a shape parameterization, dubbed Shape As Points (SAP), that is more lightweight and faster than neural implicit fields, while still yielding watertight shapes and being able to handle arbitrary topology.  ",
    "This paper proposes a differentiable adaptation of the Poisson Surface Reconstruction algorithm for oriented point sets. It discretizes the Poisson equation over a 3D grid and use spectral methods to find the solution for indicator function values over this 3D grid. The final grid is fed to marching cubes algorithm to obtain the final mesh. The differentiability of the approach allows to use the proposed method in various optimization-based applications from which the authors consider optimization-based and learning-based 3D reconstruction tasks. Proposed models are evaluated on datasets with different level of details and noise present in the inputs and compared to both classical and more recent learning-based methods.",
    "This work proposes a novel shape representation using point clouds. This is enabled by unique differentiable poisson solver layer that enables to convert the oriented point clouds to full volume representing the shape. I think the main contribution of this work is the spectral technique that solves poisson surface reconstruction problem, which can be efficiently integrated into neural workflows. While this work mostly focuses on surface reconstruction, I believe this representation can become broadly applicable to various problem domains.",
    "The paper formulates a differentiable Poisson Surface Reconstruction layer, which maps an oriented point cloud to an indicator function over the interior of the object. The Poisson solver is done in the spectral domain on the GPU for computational efficiency. It shares many of its advantages with other neural implicit representations, but because it produces an indicator function over the whole space, there is no need to query a network over an entire voxel grid.   The layer is incorporated into two tasks: an optimization-based 3D shape reconstruction that fits a spherical point cloud initialization to a target point cloud, and a learning-based 3D reconstruction task that matches noisy point cloud input to a ground truth mesh. The non-differentiable step of Marching Cubes in these pipelines has its gradient approximated with the inverse surface normal, which is quite natural. The experimental results seem good, and beat out the existing state-of-the-art, and an ablation study is performed as well on the learning-based task to investigate the form of the feature extraction network there.",
    "This works suggests a novel method on how to harness the representational power of models such as CLIP. In this task the input is distorted with a known function, such as missing pixels or gaussian noise, blurring. This works proposes training a student contrastively by matching the clip representation of the clean image with student's representation of the distorted image. They propose different matching functions and explain why in their setup it will not collapse if one does not compare against every other.  The experimental setup is extensive and shows much better label efficiency when working with distorted images, they also show better noise extrapolation and better dataset tranferability in compare to baseline. Their baseline is a resnet pretrained on imagenet supervised trained on the distorted imagenet-100.",
    "This paper proposes an inversion method that exploits a pre-trained representation for regularization. Given only corrupted images, instead of working in the pixel space, it attempts to find their matching representation pairs in the pre-trained representation space that is trained with clean images by using contrastive objective function. Assuming that one has an access to a powerful representation that is already available, this method provides a robust representation against various types and levels of distortions and train/test time discrepancy. ",
    "This paper proposes to recover the feature representation, pre-trained from CLIP, of a clean input image given a corrupted version of the image. They propose to recover the features, instead of the clean image, as their goal is to use these features for downstream tasks, e.g. classification. Furthermore, this allows for the transfer of knowledge from CLIP, which reduces the amount of labeled data needed for the downstream task. To recover the features, they train a student model via L2-Loss and contrastive loss given the clean feature from CLIP. Empirically, they evaluate on a subset of ImageNet (with only 100 classes) and consider three types of corruptions, random masking, Gaussian noise, and Gaussian blur. Empirical comparison with a baseline method, trained end-to-end with corrupted images, demonstrates their approach is more robust and requires less labeled data.",
    "The paper consider the following problem: Let $x$ be an image, let $R$ be a feature map or representation obtained through the CLIP network, and let $A$ be a distortion process. The representation takes as input an image and yields a feature representation. The distortion process also takes an image as input, and yields a distorted image (e.g., it deletes pixels).  The paper assumes we are given the representations and corresponding distorted images, i.e., a collection $\\{A(x_i), R(x_i)\\}$, and the goal is to learn a student function $S(A( \\cdot ))$ that is equally useful as the original representation $R(x)$ for a classification task. The paper learns the student $S$ by minimizing a contrastive loss, and the utility of the representation obtained by the student $S$ is measured by the performance on a supervised learning task, specifically on ImageNet-100.   The paper provides simulation results demonstrating that the method learns useful representations. The paper's main result is to show that the method 'outperforms a pretrained ResNet, of the same size as the robust encoder, fine-tuned end-to-end on labeled distorted images'. In addition to this result, the paper provides a number of ablations studies and compares to two reasonable baselines.",
    "- This paper revisits an interesting (and truly under-explored) idea from the reinforcement-learning literature: coagent networks [43,44]. The original work by Philip Thomas considered endowing the standard agent, that maps from states to actions, with a richer structure whereby the state can be mapped by multiple coagents both in parallel and in sequence yielding various intermediate outputs (coagent actions) before ultimately rendering a final action to constitute the action output of the overall agent.  - In this paper, the authors consider how the concept of coagent networks may be used to ground neural network training as a finite-horizon reinforcement-learning problem, thereby offering a local, asynchronous alternative to the traditional and widespread method of backpropagation.  - The paper offers a formulation of neural network training as a finite horizon POMDP, where the partial observability arises only to accommodate the non-Markovian nature of the terminal reward signal that must depend on the initial input to the network. While the formulation allows the authors to employ policy-gradient techniques for local, asynchoronous optimization of the network, they highlight shortcomings of using the standard REINFORCE estimator, which align with early findings by [44].   - On the path to resolving these issues, the authors present numerous experiments that tease apart various hypotheses to diagnose the failures of coagent network training relative to standard backprop. While unable to outperform backprop in the standard supervised learning setting, the authors not only provide ample diagnosis of the failure but also conclude their empirical investigation with a continual learning setup that highlights the strength of using local, adaptive policies for neural network training over backprop. ",
    "This paper presents a study that investigate RL methods for the credit assignment problem in neural network. In this study, the credit assignment problem is formalized as a finite horizon RL problem. Subsequently, it is empirically demonstrated that stochasticity of coagents\u2019 policies hinders the learning performance when REINFORCE is used to train coagents. To address this issue, a Q-learning like off-policy algorithm is proposed. The experimental results show that the proposed off-policy algorithm outperformed on-policy algorithm. In addition, the proposed off-policy algorithm outperformed backpropagation in a continual learning task.",
    "The paper investigates using reinforcement learning to train neural networks. Specifically, it considers formulates the problem in which individual layers are treated as steps in a finite horizon partially observable MDP, and explores using either a global agent or individual co-operating agents at each layer to maximize the reward (the negative final error).  The paper then presents an empirical study of using REINFORCE in this cooperative agent framework to train one or two hidden layer networks on MNIST/Boston Housing while varying different parameters like the policy variance, different partitioning schemes of the network into agents, different baseline approaches to improve stability, and activations. The key takeaways of this experiment are that (1) the CoAN+REINFORCE approach generally underperforms backprop, (2) baselines to improve stability don't seem to help, and (3) the primary reason for the poor performance is the non-deterministic behavior of the other agents (as indicated by having a single agent optimizing all layers performs the best by far).   Motivated by this, the paper presents an off-policy Q learning approach to training cooperative agents, which uses bootstrapping and trains by assuming the best action is taken at the next step. While the paper shows this improves over on-policy SARSA, it still underperforms REINFORCE, which underperforms backprop.   Lastly, the paper shows that in a continual learning setting the CoAN+REINFORCE approach can be more robust than backprop. ",
    "This paper studies credit assignment problem in neural networks with RL algorithms. They first formulate the problem as a finite-horizon MDP so that they can apply RL. They find nondeterminism in the problem causes suboptimal solutions and propose to use off-policy RL with a critic to resolve it. ",
    "Motivated by the literature showing that the primate visual system has two pathways (\"ventral\" and \"dorsal\") with distinct functional specializations, the authors try to build a model of a visual system that also has representationally and functionally distinct regions. They turn to calcium imaging data from mouse visual cortex, which allows them to compare learned representations of ANN to the neural representations found in distinct cortical areas of animals shown the same images. (There aren't publicly available datasets with simultaneous recordings from ventral and dorsal areas in primates, as far as I know.) The authors find that a two-pathway 3D ResNet model trained on the contrastive predictive coding (CPC) task and a dataset of natural videos has layers that overall explain more of the mouse calcium responses in more cortical areas than several baseline models, including the same architecture trained on the same dataset but with a supervised task. In addition, the two pathways in the self-supervised model transfer better to different tasks (object recognition and motion discrimination), which is reminiscent of some of the functional specialization between primate ventral and dorsal pathways.",
    "The authors show that a two-stream 3d ResNet architecture trained using a contrastive predictive coding (CPC) objective develops a representation that resembles the ventral/dorsal stream split in visual cortex. Although I do not buy into all claims of the paper, I am generally very supportive of it. The authors make their main point and the paper is well written. With some adjustments of the claims it will be a great paper.   ### Update after discussion period  Given the results from the control experiments reported by the authors, I support publication of the paper and increased my score to 7. I do ask the authors to include those results in the final version of the paper.",
    "The authors address the challenge of training a single deep neural network, using a single loss function, which captures the specialized neural responses in both the ventral (\u201cwhat\u201d) and dorsal (\u201cwhere\u201d) pathways of mouse visual cortex. The authors demonstrate that a deep neural network comprised of two parallel convolutional hierarchies, trained with a single self-supervised predictive objective, captures neural responses in the ventral and dorsal streams better than a neural network comprised of a single convolutional hierarchy (which captures only the ventral stream), and better than either architecture trained with a supervised objective. Furthermore, by evaluating their two-pathway model on \u201cwhat\u201d and \u201cwhere\u201d downstream tasks \u2014object categorization and motion detection\u2014 the authors show that their model has learned functionally specialized representations in each of its two pathways.",
    "The paper uses contrastive predictive coding to train deep networks on UCF101 videos. It then uses representational similarity to compare their representations to those of mouse calcium-imaging data from the Allen Brain Observatory. The key result is that a two-stream network is a good match to mouse visual cortex data. One of the (structurally identical) streams develops a representation that is a good match to dorsal mouse areas, and the other matches ventral mouse areas. Deeper areas correspond better to areas higher in the mouse visual hierarchy. Furthermore, the ventral stream of the model better supports transfer to CIFAR-10, while the dorsal stream better supports discrimination of random-dot motion direction. ",
    "(Summary) This paper proposes a generative model that can learn hierarchical topics that coherently incorporate a structured prior knowledge graph. By introducing Gaussian embeddings to an existing SawETM, a neural topic model where topics in different levels can relate each other, the authors first propose the Gaussian SawETM. Then their TopicNet based on Gaussian SawETM can learn hierarchical topics coherently to an input knowledge-graph. TopicNet is not only capable of learning hypernym-induced topics as hierarchies, but also equipped with rich interpretability. ",
    "This paper mainly proposes a new hierarchical topic discovery framework that is guided by prior (tree-structured) knowledge. The construction of the framework is broken down into two steps: Modeling semantic hierarchy with a Gaussian-embedding-based topic model (Gaussian SawETM), and injecting the prior semantic knowledge by regularizing via entailment relationship. The model is evaluated on a set of benchmarks with perplexity, topic quality, and clustering/classification protocols. Qualitative studies are also shown to demonstrate the interpretability of the model.",
    "The paper builds on the recently proposed SawETM hierarchical topic model and combines it with a knowledge graph so that each node in the knowledge graph corresponds to a topic. They change it so that every topic is embedded with a Gaussian distribution. This enables to enforce a hierarchical ordering constraint on the topics. Experiments show that the model discovers deeper, more interpretable topics and finds better document representations.",
    "The authors propose a topic model that aim at embedding words and topics into a latent space via Gaussian embeddings. Additional constraints in the training procedure allows to incorporate prior knowledge on the topics, so that they are able to include semantic topic relations.  The model is evaluated on a large set of public datasets and on a number of tasks. It achieves better results with respect to baselines on clustering tasks, and comparable on classification tasks. However, the main advantage is the increase interpretability of topics and topic hierarchy.",
    "This submission addresses the problem of constructing a good initialized pretrained network for the object detection task. Compared to previous work, the authors argue that pretraining should be adapted to object detection by focusing on object-level features learning. Instead of pretraining on ImageNet, the authors pretrain the model by designing an object level contrastive learning framework. Experiments on COCO and PASCAL show that the proposed method achieves higher performance. ",
    "The paper aims to design a self-supervised pre-training method for the downstream object detection task.  The authors propose to perform self-supervised object-level representation learning. Specifically, this method uses selective search to obtain object proposals in unlabeled images and extract the object-level features as in Mask R-CNN. Clear improvements have been achieved on COCO object detection and instance segmentation with Mask R-CNN.",
    "This paper provides a self supervised method tailored for object detection (in the RCNN paradigm), inspired from BYOL.   The general idea is to use a non-parametric method (selective search) to generate some boxes, then apply a BYOL-style loss between ROI-Aligned features of each box coming from different augmentations of the image.   It differs from other SSL methods (BYOL, SWAV,...) in that it instead of pretraining solely the backbone, this methods ensures that all the components of the detector (FPN, RCNN head) are pre-trained.  It shows convincing results on COCO and pascal as well as some subsets, in a few shot setting. The code is made available as part of the supplementary, thus helping with reproducibility. ",
    "This paper proposes SoCo, a method for self-supervised representation learning for downstream object detection and instance segmentation tasks.  They argue for stronger alignment between downstream tasks and self-supervised pre-training. They demonstrate this in the case of object detection by (a) developing a representation learning scheme that encourages object level scale and translation invariance and (b) pre-training several components of the downstream detector such as FPN and R-CNN head unlike prior work which mostly just trains the ResNet backbone.  The former property will help their model detect objects at several locations and scales as is needed for object detection.  The latter property helps them get stronger alignment between the upstream and downstream setups. To this end they propose \"scale aware assignment\". The ideas is that, representations for small objects are taken from finer FPN pyramid levels and for bigger objects are taken from coarser FPN pyramid levels. This matches what happens in the actual FPN where anchors at finer pyramid levels are smaller and at coarser pyramid levels are bigger.  The overall recipe is as follows: Selective search, a hand-crafted region proposal technique, is used to suggest boxes on all images. K of these boxes are randomly selected in each training step per image and three views of that image are constructed using random resized crop and resize operations. FPN features are extracted using RoiAlign for these box locations using \"scale aware assignment\". A BYOL loss is applied between representations of the same box across the three views. As in BYOL an EMA teacher network and projection head are used.  They pretrain R50-C4 and R50-FPN  models upstream and fine-tune corresponding Mask-RCNN models downstream for MS COCO and Pascal VOC object detection and MS COCO instance segmentation. Low data regime is explored using 5% and 10% \"Mini\" COCO setups. ImageNet linear eval results are included in the appendix. Ablation experiments evaluate whether stronger alignment in terms of architecture between pre-training and fine-tuning were helpful and sensitivity w.r.t. hyper-parameters such as view size, momentum for EMA, batch-size etc.",
    "The paper introduces a local search technique for vehicle routing problems (VRP) that decomposes the general problem and delegates smaller subproblems to a subsolver, e.g. an exact VRP solver. How to decompose the problem is learned from a generated training set using a transformer model and is the main contribution of the paper. Experiments results with a comparison to recent works in the area show the effectiveness of the proposed method. ",
    "This paper proposes an iterative framework to solve large-scale Vehicle Routing Problems. At each iteration, given the current feasible solution, a learned component selects subroutes that form a VRP subproblem. Then the subproblem is solved using a standard VRP solver (LKH-3) and the subsolution is used to update the current solution. The subproblem selector uses a Transformer encoder and predicts the subsolution cost; it is trained in a supervised way. Experimental results show that the method is able to reach the performance of the VRP solver LKH with significantly shorter computation times. ",
    "The paper proposes new ways to learn good decomposition steps in a heuristic search algorithm for the capacitated vehicle routing problem. The learning algorithm can select good seed points for the decomposition, often permitting significant speed-ups (1.5x) over other baseline decomposition algorithms (random and other simple variations). Additional experiments are conducted to evaluate the impact of the client distribution on the performance of the proposed approach.",
    "The paper proposes a decomposition method for large-scale vehicle routing problems (VRPs) that leverage supervised learning. Specifically, the proposed methodology uses regression to identify a smaller, more tractable subproblem from a given initial solution, which is then addressed by another solver and incorporated into a full solution. Numerical results compare different state-of-the-art heuristics (e.g., LKH-3) and exact approaches (e.g., OR Tool) on different variations of the VRP with up to 3,000 nodes. ",
    "This paper proposes a new approach for continual learning that actively forgets the old knowledge when learning the new tasks. The approach uses Bayesian continual learning with synaptic expansion-convergence for active forgetting. The paper evaluates the new method on several continual learning benchmarks, including CIFAR10 regression, visual classification, and Atari reinforcement tasks.",
    "This paper investigates how to avoid negative transfer in Bayesian continual learning setting. The main contribution is the proposition of an active forgetting mechanisms inspired by biological neural networks for mitigating negative transfer in CL. The experiments on CL benchmarks have been conducted to validate the performances of the proposed method. ",
    "The paper proposed a continual learning method that attempts to promote better forward transfer among similar tasks. Towards this, the authors attempt to suppress the negative knowledge, the knowledge that impedes learning a new task, from the previous task while learning a new task. This is done by forgetting such knowledge from the previous task without increasing the forgetting catastrophically. The authors claim that such \u201cactive forgetting\u201d is biologically inspired. Similar to the Elastic Weight Consolidation (EWC), the authors derive the learning objective, by applying the laplace approximation to the posterior of a new task. The only difference is that the posterior of the previous task is replaced by a weighted product distribution, where a weight of \u2018\\beta\u2019 is introduced to capture active forgetting. This change allowed them to derive a new regularization penalty whereby a separate model is trained for a new task and then subsequently merged with that of the previous one. It is in this merging that the negative knowledge of the previous task is eliminated. Experimentally, the authors show strong performance on regression, classification and RL tasks. The authors further show that their method can be added to other regularization- and memory-based methods to improve their performance.  ",
    "This paper proposes a method for continual learning that aims to mitigate the problem of catastrophic forgetting by actively forgetting knowledge from previous tasks. The authors use a Bayesian continual learning framework to design their method. AFEC relies on identifying a set of expanded network parameters which are specific to the new task. The method incorporates a term in the loss function that considers the merge between these parameters and the network parameters being updated for the current task, therefore encouraging active forgetting. Catastrophic forgetting is also controlled by including a term that merges between parameters for old tasks and network parameters for the current task (i.e. the EWC term). Experimental results are reported for datasets on regression, classification and reinforcement learning tasks. These results show some advantages of the method in particular in the forward transfer setting. ",
    "The paper provides a convergence analysis of a class of prior-guided zeroth-order (ZO) optimization algorithms and gives a prior-guided variant of the accelerated random search (ARS) algorithm.  Contribution: 1. Provides a complete convergence on some prior-guided zeroth-order optimization algorithms. 2. Provides a prior-guided variant of the ARS algorithm.",
    "This work studies the problem of zeroth-order optimization in a deterministic setting, where the exact function values at each point can be observed but the gradient of the function is not accessible. The main approach for solving such problems is first to estimate the gradient of the function and then apply a gradient method by plugging in this estimator instead of the gradient. The main goal of this work is to provide convergence guarantee for prior guided zeroth order algorithms.  Assumptions on the objective function: The objective function is (strongly) convex and smooth.  Approach: Since the paper assumes a deterministic setting, at each step by two function evaluations and choosing a small enough perturbation term, roughly they can observe the gradient of the function towards any arbitrary direction (page 3, equation 1). Also, they assume that at each step they can observe $q$ random directions of the gradient, which are given priorly (or they estimate them by $2q$ additional function evaluations). Then, they take advantage of these $q$ given directions and $g_{I}$s to construct $g_t$, where $g_t$ is the gradient estimator at step $t$, and $I<t$.   Contributions: Their results in Theorems 3 and 4 outline the convergence guarantees and robustness to the learning rate.",
    "This work analyzes the convergence rates of several existing prior guided zero order optimization methods. The zero order methods studied use statistical methods to provide an estimate of the function gradient using only function evaluations. This works studies the trade offs between gradient estimation accuracy and function evaluations as well as the effect of learning rate selection for the various estimates. This work also proposes a prior guided version of accelerated random search and studies its convergence. All algorithms studied are then numerically compared on benchmark functions as well as black box adversarial attacks. ",
    "This paper studies the performance of zeroth order optimization algorithms where gradient estimation uses prior information. They provide a bound on the convergence analysis for such prior guided algorithms in terms of expected alignment of the gradient estimates to the true gradient. They use this framework to study historical priors and show that such a prior may counter the effects of using a sub-optimal learning rate. They also provide a new accelerated random search algorithm that incorporates prior information. ",
    "The paper analyzes the possibility of recovering the weight of a teacher network using a student network which is as dense as the original one. The authors prove that with enough samples drawn from the teacher network, the recovery can be done on one-hidden-layer neural networks with linear convergence speed. The authors also discuss the correlation between the needed samples and the sparsity of the teacher network.  To sum up, the well-designed structure makes the work\ufb02ow clear and easy to follow, but the further analysis and discussion are expected to clarify some contributions in the techniques as well as in the evaluation section.",
    "This paper presents a theoretical analysis of the advantages of learning pruned neural networks . This analysis considers a teacher-student setup with a finite number of training samples. The theoretical results presented in the paper show that pruned networks can have multiple advantages, such as faster training convergence, a lower number of samples required for successful convergence and an enlarged convex region.",
    "This work takes a theoretical view of LTH, leveraging the geometric structure of the objective function to analyze the generalization error of a pruned network trained in a teacher-student fashion. In particular, they prove that, as a model is pruned, the desirable (convex) region with high-guaranteed generalization performance enlarges, providing explanation for improved performance of winning tickets. Then, the sample complexity of training the pruned network to achieve zero generalization error is analyzed, finding that the number of samples required is proportional to the number of un-pruned weights. Interestingly, the work finds that pruned models enjoy faster convergence to high performance, providing another possible explanation of why winning tickets outperform dense networks. ",
    "The paper gives theoretical explanation for improved generalization error of winning tickets for which only empirical results are known. Their results are based on teacher-student setting in which training samples are assumed to be generated from an unknown teacher network and student network is supposed to learn only from those samples. They give an accelerated gradient descent method for learning the pruned  network and convergence and sample complexity analysis for this algorithm. The empirical risk function is shown to have an enlarged convex region for a pruned network, which justifies the importance of the winning ticket. Learning on pruned network with the AGD algorithm gives a model closer to the teacher network with the same number of iterations, which implies better generalization of the trained pruned network. These findings are validated with experiments on synthetic and real datasets (MNIST, CIFAR-10).  ",
    "The paper has two main contributions:  1) It proposes a unifying framework called \"Adaptive Measurements\" that covers many differentially private synthetic data generation algorithms and show how these algorithms can be derived by modifying the loss function and distributional family.  2) Based on the above framework, two specific synthetic data generation algorithms called Private Entropy Projection (PEP) and Generative networks with Exponential Mechanism (GEM) have been proposed. Since PEP attempts to explicitly model the data distribution, it does not scale well to higher dimensions. GEM uses the well-known generative neural networks to overcome the above problem and can also effectively use public data for good initialization.",
    "The authors unify several algorithms for DP synthetic data generation for query release. Using this framework they create two algorithms, private entropy projection (PEP) and generative networks with the exponential mechanism (GEM). Then they empirically evaluate their algorithms in publicly available datasets and show that their algorithms (mostly) outperform existing ones. They also show how GEM can use public data to improve its accuracy. ",
    "This paper tackles the problem of synthetic data generation for query release. First, it presents a general algorithmic framework (Adaptive measurements) for the task, and interprets a long line of prior work under this lense. At a high level, these works solve the min max problem in Equation 1.   Given this formulation, the paper proposes two algorithms, PEP and GEM. PEP selects a maximum entropy distribution to minimize the error for a given query set by solving the dual of the constrained optimization problem. They offer an iterative algorithm for this.  To avoid the exponential runtime of approaches like PEP (because they maintain a distribution over entire data domains), the paper also proposes GEM, which uses a generator network to represent this high dimensional space.  GEM can easily incorporate public data (with various missingness) by using it for pretraining.   Empirically, GEM outperforms prior work in accuracy to privacy tradeoffs on ACS and the adult datasets, and is more robust to domain shift in the public data than PMW or PEP. This gain is most pronounced when the data is high dimensional. ",
    "# Summary of contributions  The paper studies the problem of synthesizing differentially private (DP) data for query release. Here we are given a sensitive dataset $P$ together with a set $\\mathcal{Q}$ of queries of interest. The goal is to generate a DP synthetic dataset $D$ so that answering the queries using $D$ gives similar answers to those of $P$; more formally, we want to minimize the maximum error across the queries, i.e. $\\max_{q \\in \\mathcal{Q}} |q(P) - q(D)|$. Several works have proposed algorithms for this problem, including MWEM [Hardt et al., NeurIPS'12] and FEM [Vietri et al., ICML'20].  The first contribution of the paper is in observing that essentially the previously proposed algorithms all fit into a single framework which they call \"Adaptive Measurements\". Specifically, the algorithm proceeds in iterations and, in each iteration, it uses the exponential mechanism to select one or more queries, asks for noisy values of those queries and it then updates the current synthetic dataset $D$ by minimizing some objective (which involves the answers to the queries so far and the current guess dataset).  With the above in mind, the authors then decide a new algorithm which fits into this framework called Private Entropy Projection (PEP) algorithm. At each step, PEP tries to find the distribution $D$ with maximum entropy among those whose max error w.r.t. the noisy measurements is at most $\\gamma$ for some parameter $\\gamma$. The authors note that PEP also gives exponentially weighted distributions, similar to MWEM, but the weights are more elaborated. Empirically, the authors show that PEP performs better than MWEM when $\\epsilon$ is sufficiently large (and performs similarly for small $\\epsilon$) on reduced versions of ADULT and ACS datasets for 3-way marginal queries.  The reason a reduced version of those datasets are used is because the original datasets have high-dimension, which is infeasible for MWEM or PEP since they have to keep the entire distribution explicitly. To overcome this, the authors propose a different algorithm called GEM which instead assume that the distribution is generated to some network $G_\\theta$ with parameter $\\theta$ (assuming that the inputs to the network is i.i.d. Gaussian). This can help reduce the computational cost dramatically since now only the network parameters $\\theta$ is needed to be maintained. Here, GEM still works in the \"Adaptive Measurements\" framework and the authors use gradient descent to minimize the $\\ell_1$ loss w.r.t. the noisy measurements so far. Note that this might not be easily differentiable for generic queries; fortunately, for k-way marginal queries, the authors point out that they are just product of the network's outputs and as a result the gradient can be easily found.  Finally, the authors consider the setting where there is some public data which one hopes to use to improve the quality of the synthetic dataset. Previous state-of-the-art called PMW$^{Pub}$ [Liu et al., 2021] simply uses limits the distribution to only those on the _support_ of the public data and runs MWEM. This has several limitations, such as when the support of the public data is not sufficient to express the sensitive data, or when some features are missing in the public dataset. The authors show that a modified version of GEM (called GEM$^{Pub}$) is more amenable for these cases: just use the public data to find an initial generator network, and then proceed with the GEM algorithm as usual. They demonstrate that this approach indeed works well in practice: although the performances of GEM$^{Pub}$ and PMW$^{Pub}$ are similar for large & similarly-distributed public data, GEM$^{Pub}$ significantly outperforms PMW$^{Pub}$ when public data is incomplete or its support not closely resembling the sensitive data.",
    "This paper discusses per-pixel classification and mask classification for semantic segmentation. It shows that mask classification is sufficiently general to solve semantic and instance segmentation in a unified manner. Thorough experiments are conducted on several benchmarks for both semantic and panoptic segmentation. ",
    "This paper focuses on the problem of semantic segmentation. Traditional semantic segmentation methods mainly adopt the FCN kind of structure and treat the task as per-pixel classification. While in this paper, the author reformulates the task into binary mask prediction and extra-label classification. The proposed method named MaskFormer could be utilized for both semantic segmentation and panoptic segmentation tasks, and the experimental evaluations on different datasets look promising.",
    "In this paper the authors present a technique to directly predict the mask and class label for semantic and panoptic segmentation. This is different from current state of the aret where per pixel labels are produced which are then process to obtain region masks and labels. The method consists of a backbone encoder which produces an image embedding, whic is fed into the backbon decoder to get pixel level embedding and to the transform decoder, the out of the transformer decode processed by an MLP provides the mask embedding. The mask embeddings and the pixel embeddings are used to get mask prdication. Whereas the class predictions are obtained throught the MLP output.  The method is tested on semantic segmentation datsets and produce comparable or better results on four datasets.",
    "This paper proposes a transformer-based model, called MaskFormer for semantic segmentation task. MaskFormer treats semantic segmentation as a mask classification problem, and predicts a set of binary masks with the corresponding class labels.  The proposed approach can be easily extended for panoptic segmentaion task. Experimental evaluations for semantic segmentation and panoptic segmentation tasks demonstrate the effectiveness of proposed method.",
    "The paper studies adversarial examples in random depth-2 ReLU networks.  They consider depth-2 networks, where the first layer is drawn from a normal distribution such that the norms of the weights vectors are roughly 1, and the second layer is drawn from the uniform distribution on {-1/\\sqrt{k},1/\\sqrt{k}} where k is the width of the network. They assume that k is at most sub-exponential in the input dimension, and is bounded below by some polylogarithmic expression. For an input x on the sphere of radius \\sqrt{d} the output of the network is w.h.p. O(1) (the input x is fixed, and the probability is over the choice of the network). The authors show that there is w.h.p. \\delta with ||\\delta||=O(1) such that sign(f(x)) \\neq sign(f(x+\\delta)). Moreover, such \\delta can be found with a single gradient step. Thus, although the inputs are of size \\sqrt{d}, there is w.h.p. a perturbation of size O(1) that changes the sign of the output. They prove the result for both smooth and ReLU activations. Finally, they validate the results empirically, and also demonstrate that \u05e9 similar phenomenon occurs in deeper networks.  Daniely and Schacham [2020] showed that such a property holds in ReLU networks where the sizes d_1,\u2026,d_t  of the layers (where d_1 is the input dimension) are such that for every j we have d_{j+1} = o(d_j) and d_t = \\omega(1). For the special case of depth-2 networks it required width k=o(d). Thus, the improvement here w.r.t. k is exponential.  The proofs roughly follow the following steps. First, they show an O(1) upper bound on f(x) and an \\Omega(1) lower bound on ||\\nabla f(x)||. Then, they bound the variation of the gradient near x. Finally, they use standard arguments to bound f(x-\\eta \\nabla f(x)) for an appropriate \\eta. The proofs of these steps for the case of the ReLU activation is different from the case of smooth activations, and the proofs for the ReLU activation with small k is different from the case of large k. ",
    "The paper studies the phenomenon of adversarial examples for random two-layer networks with ReLU or smooth activations. It is shown that one step of gradient descent yields adversarial examples (i.e., a switching of the sign of the network output) with high probability, under a much milder condition on the number of neurons compared to previous work, i.e. sub-exponential in the dimension instead of sub-linear for Daniely and Schacham [2020]. The proof is based on characterizing the landscape of the network function at different scales, showing that at relatively small \"mesoscopic\" scale of perturbations (o(sqrt(d)),  but still O(1)), the gradient is close to constant while being Omega(1), making it easy to find an adversarial example with a single gradient step. Some experiments are provided to illustrate the theory, and to illustrate how the phenomenon extends to multiple layers.",
    "The authors consider the existence of adversarial examples in neural networks trained by gradient descent.  They demonstrate that for two layer networks, one gradient update following random initialization can find adversarial examples.  Their results extend previous work by Daniely and Schacham to more general settings (for two layer networks) and rely upon a different suite of techniques. ",
    "The authors prove that two-layer neural networks can be perturbed adversarially at a fixed data point and at random initialization (with high probability), i.e.\\ for a neural network $f$ with randomly initialized parameters and a data point $x$, there exists a small perturbation $\\delta = O(1)$ such that $|f(x)| = \\Omega(1)$, but $f(x+\\delta)\\cdot f(x) < 0$. The result holds for a wide range of widths and activation functions. They present numerical evidence for their theoretical claims.",
    "The paper at hand proposes end-to-end training of score-based generative models in the latent space of a variational autoencoder. The VAE is pre-trained using a normal prior which is then replaced by the score-based generative model that is then jointly trained with the VAE. The paper also introduces a novel training objective based on the cross entropy between the encoder distribution and the SGM prior. Two techniques for variance reduction of the loss function are discussed. ",
    "The paper proposes Latent Score-based Generative Model (LSGM) which introduces a score-based prior in the Variational Autoencoder (VAE) framework. In contrast to previous score-based models that operate in the data space, LSGM uses a score-based model in the latent space. A sample from a base distribution (standard Gaussian) is denoised using the score-based prior in the latent space and is then mapped to the data space using a decoder. The authors further discuss how the various terms in the ELBO can be computed to train the model in an end-to-end fashion without requiring the time-dependent marginal score function. Multiple variance reduction techniques and training tricks have also been proposed for the resulting objective function. Both quantitative and qualitative results demonstrate the ability of the model to generate high fidelity images.",
    "The paper proposes a generative model based on the VAE framework with a sophisticated prior / inference scheme based on denoising score-matching. Authors develop extensive machinery to adapt related ideas from score-based generation in the observed space to latent space. This greatly improves sampling time while preserving and sometimes improving sample quality and/or likelihood of data. I believe the paper is an interesting addition to the existing collection of generative modelling techniques.",
    "The paper proposes to learn a flexible VAE prior using score-based generative model. Contrary to the existing score-based model that builds on high-dim pixel space, the paper applies the score-based model directly on the latent space which is typically low-dimensional.  The effectiveness of the model has been verified using generative FID score, negative log-likelihood as well as various ablation studies. ",
    "The paper provides a theoretical analysis comparing the training dynamics and performance of a specific 1 hidden-layer convolutional neural network with those of its corresponding finite width CNTK on a simple data distribution. This analysis is used to support their claim that the gap between neural networks and kernel methods may lie in the ````''Local Signal Adaptivity'', in the sense that neural networks outperform kernel methods in distinguishing localized influential features from noisy background. Furthermore, they empirically identify a performance gap between the CNN and finite width CNTK on noise extended variants of the CIFAR-10 dataset, which emphasizes the influence of the ``''Local Signal Adaptivity''. The authors conclude that this setting degrades the performance of kernels in a more pronounced way than it affects neural networks. ",
    "This paper introduces the notion of local signal adaptivity (LSA), which the authors claim is a new perspective on the benefits of feature learning in NNs over kernel methods like the NTK. LSA denotes the ability of non-linear NNs to find a sparse signal in the presence of large noise, and the authors theoretically show that in a particular data distribution setting with a sparse signal, a single filter CNN is able to train with GD to learn the signal. On the other hand, they show that for an underparameterised linear NN (linearised at initialisation in parameter space) the model is unable to learn the signal. Experimental results are provided comparing the degradation of non-linear and linear NNs under increasing noise, demonstrating that non-linear NNs are indeed more robust to noise in line with the theory.  **update after rebuttal** raising my score to 7",
    "The authors study a toy binary classification problem where a certain CNN architecture is trained to detect one of two templates embedded in gaussian noise. The motivation is twofold: the problem is argued to capture relevant structures present in natural image classification tasks where CNNs succeed in practice (i.e., the detection of an object/motif in the image in the presence of a nuisance background), and the theoretical analysis establishes an architectural separation via the rates one gets by analyzing the problem with the neural tangent kernel approach and via the authors' analysis. Concretely, the data model consists of a fixed unknown template embedded in one of $k+1$ consecutive disjoint length-$d$ blocks of a length $d(k+1)$ 1D signal, with the other $k$ blocks containing i.i.d. gaussian noise of a certain variance (the blocks are imagined to be disjoint \"image patches\", and the template a motif of interest) -- samples from this data model have the patch where the template is contained uniformly randomized and contain independent noise, and the template is given either the positive or negative sign (representing the two classes in the problem). The noise variance is set to be large enough that it is not possible to perform naive matched filtering to recover the template. Accordingly, the CNN that is trained to solve this task contains a custom denoising nonlinearity, the standard soft thresholding function -- this corresponds to a one-layer, two-neuron ReLU network that computes two $d$-strided convolutions with specific weight sharing and output averaging (the shared biases end up corresponding to the soft thresholding function's parameter) -- which is trained using finite samples from the data generating distribution by mini-batch SGD on the logistic loss with gaussian random initialization. The authors show that this procedure yields a classifier for the data whp given polynomial samples and suitable step sizes; in contrast, they show that the network's convolutional NTK is unable to solve the task whp as long as the number of filters satisfies $o(d)$ (the neural network studied corresponds to a two filter network). Experiments involving embedding CIFAR-10 images into random backgrounds (either from ImageNet or having gaussian noise) with varying intensities and comparing neural network performance to their NTK's performance computationally on the classification tasks thus generated verifies the predicted performance gap.  ",
    "This paper tackles the question of whether neural networks can be provable better than their induce neural tangent kernel for some problem setting. This question is answered in the context of a binary classification problem, in which the signal is shift invariant and embedded in a background of noise. The authors show that for this problem, a two layer neural network with relu activations and logistic loss efficiently learns (in sample and time complexity) this problem class with constant number of neurons, whereas its neural tangent kernel counterpart requires at least order d - the dimension of the (local) inputs. The authors then illustrate this basic problem in image classification settings where the problem setting is conceptually present, with results that align with their results in the toy-like distribution. ",
    "This work studies the problem of decentralized nonconvex optimization problems and it is relevant to the conference. The paper provides convergence analysis for an existing and well-studied algorithm -- stochastic gradient tracking algorithms, without providing any improvements. The paper prove its algorithm the same convergence compared to existing works. There are some light and limited experiments associated with the paper, but only limited to quadratic case.",
    "This paper studies the gradient tracking method for decentralized optimization. While it is widely used, its convergence rate is not optimal compared with some other methods. This paper provides a tighter analysis for nonstrongly convex problems, strongly convex problems, and nonconvex problems. Faster convergence rates are proved in this paper.",
    "The paper studies  the gradient tracking (GT) algorithm for stochastic distributed optimization problems over undirected, static graphs; nonconvex, strongly convex and weakly convex local objective functions are considered. The claimed contribution is a new line of analysis unlocking tighter (asymptotic) convergence rates than those already developed in the literature. The impact of some network parameters on the convergence rate is also discussed, and validated via some (albeit limited)  numerical results. ",
    "This paper analyzes Gradient Tracking, a very common decentralized optimization algorithm, in the stochastic setting. The authors first introduce the standard gradient tracking algorithms, along with the assumptions they use to analyze it. Then, they provide convergence results in 3 main settings: non-convex, strongly-convex and weakly-convex. In each case, the leading order term matches the rates of centralized mini-batch SGD, meaning that the methods are fast (at least when this term dominates). It is argued that many interesting extensions naturally fit in this framework and could be adapted without too much efforts.  Then, a proof sketch is given, and highlights the importance of studying the consensus difference X_t - \\bar{X_t}, where \\bar{X_t} is the average over all nodes, instead of studying just X_t. The other key ingredient is that a simple recursion, can be written with the consensus difference on both GT variables. Although the operator J involved in this recursion is not contractive at each step (spectral radius greater than 1), J^i with i large enough is contractive (spectral radius smaller than 1/2), which allows to prove convergence of the recursion.  Then, the rates obtained for Gradient Tracking are compared with rates previously obtained in the literature, and they compare favorably overall. Finally, some toy experiments are given to analyze the impact of the graph-dependent constants c and p that were introduced and that appear in the higher order terms. These experiments seem to confirm the theoretical rates. ",
    "The paper studies the arm sampling behavior of UCB and Thompson sampling algorithms. For the two-arm case, the asymptotic behavior of arm sampling is characterized for different regimes (small, large, and medium) of suboptimality gap. Using this characterization, the minimax regret of UCB is shown to O(n\\logn), where n is the time horizon. They highlight the incomplete learning phenomenon in Thomson sampling where sample-split could be arbitrarily imbalanced along a sample path even when both the arms have the same mean.",
    "Classical bandit algorithms such as UCB and Thompson Sampling are well-understood in terms of their performance\u2014for example, an upper bound on their regret\u2014but, until recently, little attention has been given to their actual behavior\u2014for example, the rates at which specific arms are sampled. This work seeks to address these questions by analyzing the arm sampling distribution achieved by both UCB and Thompson Sampling. They provide results characterizing these distributions asymptotically and, in addition, characterize the distribution of the rewards obtained by running UCB.",
    "The authors study the asymptotic behavior of arm-sampling distributions under the UCB and the Thompson sampling. They provide an asymptotic characterization of the distributions, and show the arm sampling rates asymptotically deterministic regardless of the hardness of instances. With this characterization, focused on canonical UCB algorithm, they provides the first algorithm-specific worst case bound and the first diffusion-limit performance. ",
    "The paper studies the asymptotical behaviors (with respect to the suboptimality gap $\\Delta$) of key statistics in the standard upper confidence bound (UCB) algorithm in standard multi-armed bandits (MAB). The contributions are as follows.  1. The paper proves that the **asymptotical arm-sampling rate** converges to a constant, and gives its **analytical form** (Eq. 2). In particular, the paper discovers a non-trivial \"**moderate gap**\" regime for UCB.  2. The paper proves an asymptotic regret lower bound for UCB **up to $(1 + o(1))$**  in two-armed bandits.  3. The paper proves that the **asymptotical empirical sum** converges to a Brownian motion for UCB in two-armed bandits. 4. The paper proves the asymptotical arm-sampling rate for Bernoulli Thompson sampling in two-armed *deterministic* bandits.  5. The authors extend their results to MAB.",
    "This paper proposes a framework for cross-domain item cold-start recommendation. The main idea follows the algorithm of Stein Variational Gradient Descent, by iteratively transporting the auxiliary embeddings of cold items in the target domain to match the embedding distribution of warm items in the source domain. The authors further propose to reduce computational time costs by selecting typical proxies of cold items.",
    "This paper focuses on solving the cold-start issue in Cross-Domain Recommendation (CDR) setting. For this purpose, the authors propose a DisAlign framework, which mainly has two modules, i.e., rating prediction module and embedding distribution alignment module. The main novelty relies in the embedding distribution alignment module. In it, the authors propose Stein path alignment and proxy Stein path alignment. The experiments on benchmark datasets, compared with six baselines, show the superior of the proposed model. The experimental analysis also shows the effectiveness of the model ability. ",
    "Summary:  The paper addresses the cold-start item recommendation with auxiliary information. To attack the heterogeneity/ domain discrepancy across the source domain and target domain, Stein path is adopted to align the domain distributions. In specific, the distribution of target item auxiliary embedding is to be aligned with both source item auxiliary embedding and source item collaborative embedding. A proxy Stein path is proposed to reduce the cubic time complexity. Good experiments are achieved on real-world datasets by comparing with many SOTA methods. ",
    "In this paper, the authors study a relatively new problem called cross-domain cold-start recommendation (CDCSR), where the goal is to transfer knowledge from a warm source domain with user-item ratings and item descriptions to a cold target domain with item descriptions only (i.e., without any user-item interactions). Notice that the users in two domains are aligned. In particular, the authors propose a novel recommendation framework, i.e., DisAlign, which contains two main modules, i.e., a rating prediction module and an embedding distribution alignment module. ",
    "The work proposes a new attention-based architecture for computer vision (classification). The proposed architecture replaces the self-attention layer in ViT with computational blocks involving the Fourier transform. Due to the efficiency of FFT and IFFT the quadratic complexity of self-attention can be reduced to a log-linear computational cost. In order to boost performance distillation of taken features from a pre-trained vision transformer is used. Results are presented on ImageNet as well as on some transfer learning experiments. ",
    "This paper replaces the self-attention layer with a global filter layer:  a sequence of a 2D FFT, einsum, and then 2D inverse FFT. A benefit of the approach is that the attention computation is reduced from O(n^2) to O(nlogn) time-complexity. This demonstrates that GFNet is Pareto optimal versus other Transformer-like models on ImageNet on an accuracy-FLOPs basis.",
    "This paper proposes to replace self-attention in vision transformer by a *Global Filter Layer* consisting of a 2D fast Fourier transform (FFT), a point-wise multiplication with learned weights and an 2D inverse FFT. The proposed layer compares favourably with (a) self-attention as it replaces the quadratic dependency on compute cost and memory footprint with a log-linear rate and (b) variants of MLP-mixer as the number of weights scales linearly with the number of pixels instead of quadratically. The performances of the proposed model are convincing both for supervised classification on ImageNet and fine-tuning to downstream task on smaller datasets.",
    "This paper proposes Global Filter Networks (GFNet), which make use of discrete Fourier transform (DFT) and a global filter layer to mix the input tokens. According to the convolution theorem, the combination of the two operations can be regarded as a depthwise global circular convolution, and thus this work can be viewed as a kind of convolutional network with global convolutional layers. By taking advantage of FFT, the proposed method is faster than previous methods such as self-attention and spatial MLP with comparable performance on ImageNet.",
    "This paper tests methods for training a classifier for predicting trustworthiness-- formulated here as predicting whether a given image will be classified correctly or not by an target classifier -- on large scale datasets and finds that using existing loss functions like uncertainty estimates/focal loss on this binary classification task cannot detect untrustworthy samples, all samples are classified as positive resulting in 100% FPR (0% TNR). They attempt to fix this shortcoming by introducing a steep slope loss which essentially separates features w.r.t. correct and incorrect predictions from each other, and the loss is bounded in its magnitude. The paper extensively tests whether its possible to predict trustworthiness with two oracle/target classifier combinations on Imagenet and its stylized/adversarial test sets.",
    "The paper proposes the steep slope loss for learning trustworthiness under a supervised training setup. A pre-trained neural network is further trained on the steep slope loss to learn trustworthiness as a binary classification problem. The approach is evaluated on ImageNet for a ResNet and a ViT model. In addition, evaluations on MNIST and CIFAR-10 are provided for comparisons with the related work. In all experiments, the proposed approach shows good performance. ",
    "The paper proposes Steep Slope loss, a loss function that is designed to improve performance in the binary classification task of prediction trustworthiness. The paper reports that common loss functions used in this domain such as cross-entropy loss, focal loss, and true classification probability loss (TCP), all suffer from an issue where correct predictions tend to dominate over incorrect predictions, due to issues of class imbalance and evaluations on simple datasets where classifiers have achieved very high accuracy.   Steep Slope loss solves this issue by controlling the slope parameters on both the negative and positive classification thresholds with two hyperparameters that control the derivative and gradient updates for datapoints that are correctly classified and incorrectly classified separately. These two controlled slopes are a function of the signed distance of the output of the classifier from the hyperplane of classification.  The paper evaluates this loss on the MNIST, CIFAR, and Imagenet datasets and shows empirical improvements on multiple binary classification metrics such as AUPRC, AUROC, and FPR95, and importantly, SS loss shows marked improvements in the TNR, therefore being more robust to detecting incorrectly classified points.",
    "The authors find that past trustworthiness predicting methods are prone to overfitting to the training set where correct predictions are dominant. The label imbalance makes the trustworthiness predictors over-confident to even incorrect predictions. To solve the problem, this work proposes a new training loss named steep slope loss, which aims at improving the generalizability of trustworthiness predictors. The intuition behind this is to emphasize the negative class during training. The experiments are conducted in ImageNet. The results show the shortcomings of past methods with cross-entropy loss, focal loss, and TCP loss and then demonstrate the effectiveness of the proposed method. ",
    "This paper introduces the \"clustering effect\" of linear components of adversarial robust models. To be specific, the authors propose to remove the non-linear functions in networks and further integrate all linear components into a single weight matrix W in order to directly study the effect of linearity in adversarial models. By conducting experiments with W, the authors find that adversarially trained models tend to show clustering effects in both weight and feature dimensions. This effect further benefits some downstream tasks such as adversarial attack and transfer learning and can be enhanced with additional supervision. In all, the phenomenon showed in this paper is interesting and deserves more and deeper research. ",
    "Adversarial robustness has received a lot of attention along with the study of adversarial data. So far, almost works have shown that robust classifier not only outperform under comprehensive adversarial attack evaluations but also boost the performance in some downstream tasks. However, the underlying mechanism of adversarial robustness is still not clear.  In this paper, they investigate adversarial robustness from the perspective of linear components. From this very novel perspective, they find that there are some statistical properties for comprehensively robust classifiers. Specifically, robust classifiers show an obvious hierarchical clustering effect on their linear sub-networks. Based on the above investigation, this paper applies this on more tasks, such as robustness boosting and domain adaption.",
    "The paper analyses adversarially robust models in terms of their clustering behavior with respect to the learned weights as well as with respect to the class-wise feature representations. For this purpose, the CNNs are linearized, i.e. non-linearities (ReLUs) are removed from the trained network such that it can be represented by a single weight matrix W, where each column corresponds to one class. The paper comes to the conclusion that hierarchical clustering of these representations is an indicator for adversarial robustness. Consequently, it formulates a regularization term which encourages such clustering behavior. The resulting models are evaluated in terms of adversarial robustness and in the context of domain adaptation. ",
    "This paper explores adversarial robustness via focusing on linear sub-networks. Through back propagation on linear sub-networks of a pre-trained network, an implicit weight expression which represents approximated class-wise responses can be obtained. With this matrix, the correlation among classes can be computed for exploring the hierarchy of classes. Similarly, the feature distance for different classes aligns well with class hierarchy through empirical observations. Based on these observations, the authors propose to impose feature distance regularization based on the computed class hierarchy.",
    "The paper proposed a novel method of linear model exploration by extracting their implicit linear matrix expression and find the weight clustering effect. The paper also claimed that the adversarial robustness shows close relationship with such clustering effect, which enables the further understanding and improvement of various tasks in the experimental parts. Overall, I like the analysis in the paper, it provides an interesting and reasonable way to understand adversarial robustness via linearity of weights.",
    "This paper develops a learning based approach for end-to-end reconstruction of operators for ill-posed problems. In particular it examines the problem of image reconstruction. The main contribution is to combine traditional variational approach with an optimal transport based regularizer.",
    "This paper proposes a method for adversarial regularization, to be used in image reconstruction. This method relies on a joint training of the regularizing part of the system and the reconstruction. Several properties regarding convergence are proven, and the method is shown to outperform similar regularization methods for this task.",
    "This paper proposes a deep learning based reconstruction for ill-posed inverse problems that combines ideas from end-to-end supervised training with learned regularization in a variational setting. The method adversarially trains the weights of a deep neural network (used as a prior for regularization) while also learning an end-to-end, unrolled deep network. The unrolled network takes the form of a learned primal-dual algorithm, and the regularizer aims to discern between ground-truth images and images generated by the unrolled network. After training, the end-to-end network can be used for reconstruction alone, or as an initialization for a separate reconstruction that strictly uses the learned regularizer in a variational setting. The authors claim that this combines the best of both worlds, as an end-to-end model can be used for fast reconstruction, while the variational model can be used for refinement (while also being more amenable to analysis). The authors provide theoretical and empirical evidence that their approach is successful and outperforms other state-of-the-art methods. ",
    "This paper proposes a framework for training an adversarial network, where the discriminator is a regularization functional, for image reconstruction.  A similar work mentioned in the paper is [14]. The key difference between [14] and the proposed method, UAR, is that the former is based on the variational inference while the latter replaces it with an unfolding network, making UAR a pure end-to-end training deep learning model. Since UAR incorporates the forward model in the loss function, it is self-supervised requiring only $y$ to impose supervision.  The author also addresses the theoretical properties of UAR, presenting interesting results on the optimality, influence of $\\lambda$, and justification of end-to-end learning & regularization.",
    "This paper proposes a framework, named UAR, for jointly training an iterative deep unfolding neural network (DUNN) and an adversarial discriminator based on Wasserstein distance for solving image inverse problems, inspired by adversarial regularization (AR) method (Lunz\u20192018). Unlike original AR method that takes pseudo-inverse reconstruction as input images, the proposed method assimilates the reconstruction from DUNN that unrolls the iterative primal-dual algorithm in each training step. The authors also provide theoretical analysis about when such adversarial training with unrolling networks would be successful. The theoretical results are well established by with thorough proofs. Finally, the performance of the proposed method is evaluated for solving CT inverse problem with satisfactory results compared to both supervised and unsupervised deep learning methods such as U-Net, LPD, and AR.",
    "This paper introduces a method  to perform text-image matching and demonstrate that  it can be used to solve several language-vision downstream tasks  ranging from image-text retrieval, VQA and national language for visual reasoning among others.   * Given an  image and a textual input visual and  textual embedding are obtained  that are then fed  to a multimodal encoder with  cross-attention layers.  * The first key idea of this paper lies in the image-text contrastive loss employed between the image/text embeddings before feeding them to the multimodal  decoder with the intuition behind that being that forcing these embeddings to align before fusing them through the multi-modal encoder results into better representations for downstream tasks * The second key idea is in the usage of  a momentum model that generates pseudo-target labels by keeping a moving average that are then used for supervision at training time.   An in-depth discussion is provided: 1) for each of the losses used, 2) on the fact that the proposed approach maximizes a lower bound on the mutual information between different \u201cviews\u201d of an image-text pair  Extensive Results for several tasks and datasets are provided and strong results are reported. The qualitative results demonstrating where the learned attention is focusing for each downstream task are also quite insightful",
    "This paper proposes a new vision-language representation learning framework, ALBEF, which uses image-text contrastive (ITC), masked language modeling (MLM), and image-text matching (ITM) losses with momentum distillation to learn SOTA representations. The ITC and MLM losses are adapted to be convex combinations of the original loss and the KL divergence between the predicted probability distribution (of the image or text or masked tokens) and the soft pseudo targets obtained from the momentum model.   The pipeline is evaluated on image-text retrieval, visual entailment, NLVR, VQA, and grounding and shows improved performance on all tasks compared to prior work, and with fewer training samples in comparison to several prior methods. Qualitative visualizations also verify the quality of the learned representations, with convincing heat maps suggesting well grounded, semantically aligned embeddings. ",
    "This paper presents an vision-and-language pretraining framework that utilizes momentum distillation to address the issue of training on noisy web data. More specifically, it presents a self-training approach to learn from pseudo-targets that are generated by a momentum model. In contrast to existing approaches which simply use cross-modal attention to reason about concatenated sequences of image regions and words, this work also leverages contrastive learning to learn more effective representations before using cross-modal attention.",
    "The paper proposes to learn joint vision and language representations by addressing several limitations in the existing methods. Firstly, they learn separate image and text representations using unimodal encoders without the need for bounding box annotations. Second, they fuse these two representations using a multimodal encoder based on cross modal attention and, third, they address the noise in large scale web based image-text datasets using a Momentum Distillation approach that generates pseudo-targets as additional supervision. They demonstrate the effectiveness of their approach on various downstream V+L tasks and gain substantial improvement over SOTA methods. Their main contributions are: removing the need for pre-trained object detector and high resolution images and combining it with the contrastive loss function for learning effective multi-modal representations, image-text contrastive learning loss (ITC). They also generate pseudo-targets for the ITC loss and the masked language modeling (MLM) loss using the momentum encoder model to address the weak correlations in the noisy image-text web data. This achieves high performance on both reasoning and retrieval tasks unlike other methods. The paper  is very well written and easy to follow and understand.  ",
    "In this paper, the authors study the vision-transformer-like vision-language-pretraining (VLP) methods. The raw image and text are first encoded by a vision transformer and a text transformer respectively, and are then sent into a multimodal transformer for fusion. There are two major technical contributions, i.e., 1) the proposed ITC loss and 2) the moving average \u201cteacher\u201d to generate the pseudo targets.     The proposed method (ALBEF) outperforms previous E2E VLP methods, and achieves comparable performance to the VLP methods that take object region features. ",
    "They analyze the linear DM method in detail. They prove that the estimator has an error form, which is written as an inner product of two residual functions. One is associated with the misspecification of Q-functions. Another is related to the misspecification of W-functions.  ",
    "The paper consider off-policy evaluation using linear function approximation under unrealizability setting. Under such more relaxed assumption, they provide characterization of the linear direct method(DM) as an error governed by two approximation residual $\\mathcal{R}_B$ and $\\mathcal{R}_X$, $$     \\hat{J}(\\pi) - J(\\pi) = \\mathbb{E}[\\mathcal{R}_B(s,a)\\mathcal{R}_X(s,a)] + O(1/\\sqrt{n}), $$ with $\\mathcal{R}_B$ corresponding to Bellman residual and  $\\mathcal{R}_X$ corresponding to residual of marginal density ratio. Leveraing this result, they establish a nonparametric tile-coding estimators  to solve the unrealizability though with a slower convergence.",
    "This is a theoretical paper which addresses the RL off-policy evaluation with linear function approximation. It proves convergence results of linear function approximations and shows that the direct method (model the dynamics) is asymptotically equivalent to FQE (modeling the value function) and analyzes its convergence properties. Additionally, it proves consistency results for such methods under tile-coding, allowing for consistency (using non-parametric estimation) even under unrealizability of the linear approximators.",
    "This paper characterizes the offline policy evaluation (OPE) error with linear function approximation in the discounted reward setting. With certain assumptions, this paper proves that the error of Linear Direct OPE algorithm (which is equivalent to the limit of Fitted Q-Evaluation algorithm) converges to the expectation of the product of two residuals. As a corollary, when either the function class is closed or the density ratio is realizable, the asymptotic error is zero. In addition, in the same setting the paper upper bounds the OPE error for tile-coding estimator.  ",
    "In this paper, the authors analyze the off-policy evaluation error of a direct estimator with linear function approximation under unrealizability. In Theorem 6, they derive the closed form of the asymptotic bias term as the number of samples approaching \\infty. Besides, in section 3.2, they study another method where the feature mappings can be selected adaptively and provide the convergence analysis for their estimation to ground-truth J(\\pi).",
    " The submission presents convergence results for clipped stochastic gradient methods without the sub-Gaussian assumption.  The subject of the submission is of interest to the NeurIPS community. As we find that some of our most difficult problems exhibit heavy-tailed noise, how to handle it in stochastic optimization is becoming more and more relevant.   My understanding of the main contributions of the paper over existing work is that this submission considers $\\nu$-H\u00f6lder continuity (interpolating between Lipschitz functions and function with Lipschitz gradients) without assuming the stochastic gradients be sub-Gaussian (but still having bounded variance) - For the case $\\nu = 0$ (Lipschitz functions), recovers tighter bounds (logarithmic dependence on the confidence level $\\beta$ instead of polynomial) than na\u00efve applications of Markov's inequality to results in expectation.  - For the case of $\\nu = 1$ (Lipschitz gradient), the claimed contribution over the existing results of Gorbunov et al. [14] is that the problem need only be smooth in a ball around a minimum.   ",
    "The authors proposed  clipped-SSTM and its restart version for stochastic nonsmooth optimization with heavy tailed noise. A detailed convergence analysis shows the theoretical advantage of the proposed algorithm. Experiments on real models (Bert) show that clipped-SSTM outperforms standard SGD methods.",
    "The paper tackles the important problem of high-probability convergence bounds for machine learning optimisation problems. Traditional analyses are done in expectation, which have been shown to not accurately represent all possible training outcomes; hence the need for tighter studies. In this paper, in the specific setting of convex, non-smooth losses with heavy tailed noise, a new high-probability bound is introduced for two algorithms. What sets it apart from previous bounds is that there is no direct negative dependency on the confidence bound (only logarithmic ones); and that in some cases it matches the non-heavy tailed noise bound. Numerical experiments illustrating the theoretical results are presented.",
    "This paper aims to obtain the high probability convergence for the convex stochastic optimization problem when the stochastic gradient of the objective function is not assumed to be sub-Gaussian. While this goal has been achieved in two recently proposed optimizers by exploiting the gradient clippings technique under the smoothness assumption on the objective, this paper considers the more general setting when corresponding gradient only satisfies a Holder continuity condition. This condition recovers the smooth and non-smooth settings when an extra parameter takes extreme values. In such a more general problem formulation, the authors propose new step-size schemes such that the convergence rate of the aforementioned optimizers (designed for smooth problems) can be smoothly extrapolated to the non-smooth setting.     ",
    "This paper analyzes the clipped SGD and clipped SSTM algorithm on generalized smooth objectives with H\u00f6lder-continuous gradients. They consider the case where the assumption of sub-Gaussian noise is not needed. They modified the stepsize in the clipped SSTM algorithm to fit the H\u00f6lder-continuity assumption. Theoretical analysis is conducted with convergence rates presented. ",
    "This paper studies long-horizon time series forecasting where the historical input length is shorter than the forecast horizon, i.e, output length. This approach extends the transformer by replacing the self-attention unit by autocorrelation and decomposition units.  The autocorrelation unit chooses the top $k$ highly correlated time lags from $L$ time lags between the query and key embeddings of a time series of length $L$. The normalized correlation of lag j between the query and key embeddings multiplied by the j-item rotated value embedding.  The decomposition block decomposes a time series to seasonal and trend components. The trend component is defined by using an average pooling, which is an average value of the neighbouring values. And the seasonal is then defined as the difference between the (observed) time series and the trend component. The proposed approach autocorrelation unit is compared with standard attention, logsparse attention, LSH and probsparse attention.  ",
    "This paper studies the problem of long-term forecasting for time series. There are two challenges: (1) it is difficult to directly study the entangled temporal dependencies for long time series; (2) the traditional self-attention mechanism in Transformer is computationally expensive. To address these two problems, the paper proposes a novel Autoformer with a novel auto-correlation mechanism and a series decomposition module. ",
    "This paper presents Autoformer to perform long-term time series forecasting. The key idea is to leverage an auto-correlation mechanism to discover the sub-series similarity based on the series periodicity and aggregate similar sub-series from underlying periods. The experiment results on several datasets showed the effectiveness of the proposed method.",
    "This paper focuses on the long-term forecasting problem of time series. This work introduces the traditional idea of decomposing time series into seasonality and trend-cycle components into deep Transformer architecture. This work also proposes an auto-correlation mechanism that replaces the original self-attention in Transformers.  Further, they improve the computation efficiency by computing power spectral density. Experiments on several datasets show that the proposed method achieves better performance compared to SOTA methods.",
    "This paper introduces a new approach for long-term time-series forecasting that is based on decomposition and auto-correlation. Essentially, the authors define a series decomoposition block which extracts the mean (trend-cyclical) and subtracts it from the series, obtaining the seasonal part. In addition, the authors design an auto-correlation component that identifies local structures across periods. The method is evaluated on six benchmark datasets and in comparison to several baseline approaches. The presented results show improvements over existing work.",
    "Authors 1) provide a dataset of cryptic crosswords; 2) explore baselines performances on this dataset; 3) provide interesting insights on those performances and come up with a pretraining strategy that increases performances.  Briefly, cryptic crosswords are puzzles that require both mastering definitions and wordplay (i.e. reordering of letters, extracting letters, composing parts of several words to form a novel word, etc.) to be solved. Authors provide a large dataset of such puzzles (in english), that they introduce as a stepping stone to solve more complex real-life settings.  They show that carefully crafted non-neural baselines are not very good (either rule-based following previous work on this, or KNN) and that even T5 (state of the art text-to-text transformer pretrained on many tasks, such as translation, summarization, etc.) cannot be finetuned for optimal performances on this dataset. Worst, when considering adversarial splits, such that for instance all puzzles with answers starting with the same subword are found in the same split, T5 performances drop dramatically.  They hint at a solution for this problem via curriculum learning, and devise the following strategy: first pretrain T5 on a series of tasks resembling the final wordplays (e.g. unscrambling a word using its definition: \"etalp + flower part\" --> \"petal\") and only then finetune T5 on the actual cryptic crosswords dataset. T5 performances indeed increase, but authors note that they are far from human performances, or even acceptable performances for a machine. ",
    "This paper presents a new dataset of cryptic crossword clues. The work presents an extensive evaluation study on this dataset with 3 non-neural baselines and one neural baseline, namely the T5 transformer-based model. The authors investigate as well a kind of pre-finetuning stage (a phase of finetuning before the final finetuning stage on the main dataset) as a way to improve the performance of the model on this task.  Contributions: New dataset of cryptic crossword clues that has the potential to foster more research on complex reasoning tasks  Strengths: - The writing is compelling and the paper is a very enjoyable read - The author do a detailed analysis to understand better the limitations and abilities of transformer-based models on the task, including interesting ways of looking at data splits - The authors investigate the use of a pre-finetuning stage as a way to improve the performance of the T5 model on the task - The evaluation is convincing with multiple baselines, non-neural and neural.  Weaknesses: Sometimes, the paper seemed to be a bit condensed ",
    "**What is the task?**  Cryptic crossword puzzles task  **What are the contributions of the paper?**  * Presented a dataset of cryptic crossword clues as a challenging new benchmark for NLP systems that seek to process compositional language in more creative, human-like ways.  * A novel curriculum approach, in which the model is first fine-tuned with related, synthetic tasks (e.g., an augmented word descrambling task) before tackling actual cryptic clues.  * Introduced a challenging word-initial disjoint data split to test composition and generalization and investigated model behavior by systematically perturbing the wordplay part of clues, showing that the model exhibits behavior partially consistent with human solving strategies. ",
    "This paper describes a new corpus of cryptic crossword clues as a challenging NLP task.  Cryptic crossword clues are composed of a literal (synonym) clue and wordplay.  Cryptic wordplay has a conventionalized inventory of ways to clue an answer.  This is a compelling NLP challenge ``1) because it is hard and 2) because it requires a system to process both surface, syntactic and semantic content of the examples.  This is related to being able to understand statements like \"Al and Bob got married and bought a house together, but not in that order\".  The paper includes a curriculum training approach where a T5 model is presented with data to improve cryptic clue solving.",
    "The paper focuses on data and methods for studying compositional language through UK-style cryptic crossword puzzles. These puzzles contain a definition and a wordplay cipher which together read like fluent natural language. The output is a word or phrase related to the wordplay cipher for which the definition is a valid description. Expert humans typically use creativity and linguistic and world knowledge to solve this task. The paper makes two main contributions: (1) a new dataset of cryptic clues as a new benchmark for NLP systems that process compositional language, and (2) baselines and an improved curriculum learning approach in which the model is first fine-tuned on related tasks (e.g., unscrambling words). Their experiments suggest that there is significant room for improvement for future work on this new benchmark.",
    "This work addresses some fundamental questions on Vision Transformers including 1. how are Vision Transformers solving vision tasks? 2. Do they act like convolutions, learning the same inductive biases from scratch? 3. And what is the role of scale in learning these representations? To answer these questions, they investigate the internal representation structure of ViTs and CNN by using representational similarity techniques like CKA (Centered Kernel Alignment). ",
    "The paper studies the representation of features learned by convnet and transformers. It evaluates the similarity of representations within and between architectures using Centered Kernel Alignment. It studies models trained on datasets of different sizes.",
    "Neural network architectures based on self-attention instead of convolutions (e.g., the Vision Transformer, ViT), have recently be shown to reach similar or better performances on ImageNet classification than CNNs. In this work, the authors investigate whether the \"internal representation structure\" learned by Vision Transformers is also similar to CNNs. Using Centered Kernel Alignment as main metric to compare internal representations, the authors perform several analyses comparing aspects of three Vision Transformer variants (ViT-B/32, ViT-B/16, ViT-L/16) and two ResNet variants (ResNet50x1, ResNet152x2). The analyses performed look at similarity of representations across different depths, local vs. global information aggregation, importance of skip connections, spatial localization of information and effects of the amount of training data. The analyses reveal several differences between the ViTs and ResNets, indicating that despite similar classification performance, the image processing strategies are quite different for the two model families.",
    "The paper presents a comparison study between internal representations of recently Vision Transformers and ResNet networks for image classification, using various established tools: Centered kernel alignment, attention distance analysis, effective receptive fields, representation propagation analysis, spatial localization analysis and linear probes. The also train some new models for additional analysis. The findings show significant difference between the models.",
    "In this work, the authors explore how representations learned with vision transformers (ViT) compare with those of convolutional neural networks (resnet). Making use of centered kernel alignment (CKA), they compare the representations learned at different layers of the same mode, between models, and at different spatial positions. They find that ViT tends to learn similar representations  across all layers while resnets tend to show a clear distinction between lower-level and higher-level representations. They also provide experiments showing that residual connections play a crucial role in transformers, i.e. removing a residual connection causes a big change between preceding and following representations. Another interesting phenomenon in ViT is that residual connections tend to preserve information of the classification token during the first half of the model while it tends to change during the second half of the model. In addition, they compare how ViT and ResNets treat spatial information. They find that both process local information in the first layers but ViT uses global information earlier than ResNets. In fact, they show that while local processing is \"hardcoded\" in convolutions, ViT requires larger training sets to learn such inductive bias. Finally, they show that MLP Mixer is closer to ViT than to ResNet.",
    "This paper studies a setting where Thompson Sampling with greedy approximation oracles is applied to combinatorial semi-bandit. The main contribution is to theoretically reveal how the suboptimality of greedy oracles can affect Thompson sampling in the worst case. Specifically, the greedy regret is shown to be lower bounded by $\\Omega(\\log T / \\Delta^2)$. The authors also prove an almost matching upper bound.   --- After rebuttal ---  I appreciate the authors' kind response. Having read all the responses and review comments, I've found that the result is more significant than I thought. Therefore, I increased my score to 6.  ",
    "The paper studies the performance of Thompson-Sampling (TS) when applied to combinatorial multi-armed bandit (CMAB) problems with semi-bandit feedback. It is well known that the combinatorial TS (CTS) algorithm might suffer from linear regret when the combinatorial maximization is solved using an approximation oracle [30]. In this work, the authors apply CTS with a specific family of combinatorial maximization oracles \u2013 greedy oracles. They analyze the greedy regret of CTS (which compares the played actions to the greedy solution of the combinatorial problem) and derive regret upper bounds of $O(\\log T/\\Delta^2)$, where $\\Delta$ is a suboptimality gap. They also provide a matching lower bound for CTS on a specific small-scale problem.",
    "The paper studies the combinatorial multi-armed bandit (CMAB) problem in a setting where exactly solving the corresponding offline optimization problem is not feasible (due to its computational hardness) and the learning agent only has access to a greedy oracle which approximately solves the offline optimization problem. In this framework, the paper analyzes the behavior of a natural variant of the Thompson sampling algorithm called Combinatorial Thompson sampling (CTS). The paper first gives an algorithm-dependent and problem-dependent lower bound showing that CTS faces a fundamental limit, then provides an almost matching upper bound.",
    "The paper studies the combinatorial semi-bandit problem. It provides the first analysis of Thompson sampling (TS) with the greedy oracle. It shows instances that the TS with Gaussian priors suffers $\\Omega(\\log T / \\Delta^2)$ regret from. It proposes a modified TS with Beta priors and shows that the proposed algorithm achieves $O(\\log T / \\Delta^2)$ regret for the instances. The proposed algorithm enjoys near-optimal regret for the multi-armed bandit problem.",
    "The paper presents a TS algorithm that uses Greedy oracle to minimise the cumulative regret on combinatorial multi-armed bandit (CMAB) setting. beside presenting an upper bound, they have also established a lower bound (on the cumulative regret) for their approach. The paper discuss the intuition of behind the proof of their proposed analysis for upper bound assuming the \"Greedy\" step (Line 4 in  Algorithm 1) returns a unique solution, and then in section 6.2 it relaxes that assumption.  CMAB is a well-known framework in the MAB literature, that generalises probabilistic maximum coverage (PMC), online influence maximization (OIM), multiple-play MAB (MP-MAB), minimum spanning tree (MST) and many others. TS based regret-minimisation algorithms are very efficient for the family of single parameter reward distribution; there are recent studies that apply TS under the CMAB setup. Again, finding the optimal solution (in offline learning) for many problems (like PMC, OIM etc.) is NP-hard. On the other hand, Greedy oracle is a popular choice in various optimisation methods (including submodular maximisation).   Hence, the idea to attack the CMAB setup with TS using a Greedy oracle is very natural. ",
    "This paper examines the game theoretic aspect of federated learning. In the proposed model, the players are strategic and may not provide their data to the learning platform and choose to federate in a small coalition. The authors provide an algorithm to compute the optimal federating arrangement, and also analyze the bound of the price of anarchy in theory.",
    "The paper studies a coalition formation process in federated learning. When agents form a coalition, they aggregate their learned parameters in the hope of a more accurate result. The paper presented an algorithm to obtain the optimal way of partitioning the agents in coalitions, so that the total weighted error of the agents is minimized. In addtion, the paper also analyzed the price of anarchy and provided upper bounds of it.",
    "This paper studies price of anarchy (PoA) in federated learning. Following the prior work of Donahue and Kleinberg [2021] which initiate a game theoretic model for federated learning, the authors propose a notion of optimality given the average error rates among agents. Under this notion of optimality, the authors first provide an efficient algorithm to compute the optimal solution, and then give PoA bounds that depend on parameters of settings.",
    "This paper studies a basic federated learning problem, in which some agents, each one with their own dataset, have to jointly agree on a global model. The paper focuses on the trade-off between stability (enforcing that agents are incentivized to collaborate in the global model) and optimality (maximizing social welfare). The paper studies this trade-off by means of a Price of Anarchy analysis.",
    "This paper studies the stable coalition in federated learning, where the agents can choose to join one coalition or leave with incentives to minimize their own errors. The paper focuses on the task of mean estimation, where the error has a closed-form solution. The main contributions are: 1. proposing an optimal algorithm to minimize the weighted sum of errors; 2. providing the upper bound on PoA.",
    "This paper proposes a way of learning a capsule-based representation of 3D point clouds. The representation decomposes an input point cloud into parts, each corresponding to a capsule. This decomposition is trained to be consistent across SE(3) transformations of the point cloud using loss terms that encourage feature invariance and pose equivariance across two random presentations of the input point cloud. Moreover, the model learns a canonical pose for each part that is tied to the identity of the object (not its presented pose).  The experiments show that 1. The reconstruction quality is high, showing that the model has capacity to fit point clouds from ShapeNet. 1. The canonical pose is indeed consistent (measured by low std deviation in relative angle of rotation). 1. The model can be used for pairwise registration (but DeepGMR does even better using RRI features, but doesn't do any of the other things this model can do.) 1. The learned features lend themselves well to unsupervised clustering/classification. 1. All the proposed loss terms are useful and contribute to better reconstruction and canonicalization.",
    "The paper proposes a capsule-based network architecture that allows self-supervised representation learning from 3D point clouds. While existing methods rely heavily on pre-canonicalized (aligned) 3D models for training, this work proposes to automatically discover the \"optimal\" canonical transformation for alignment while learning to decompose and reconstruct the input point clouds.  Specifically, it exploits the transformation invariance and equivariance properties of object parts (capsules) to learn a latent representation. The experimental results on the (unaligned) ShapeNet dataset show that the method can effectively learn to decompose the 3D point cloud into consistent parts across objects and canonicalize unaligned data. It outperforms the state-of-the-art methods in terms of reconstruction accuracy, canonicalization accuracy and stability, as well as unsupervised classification accuracy from latent representation. It is very encouraging to see that the need of 3D pose/viewpoint annotations can be removed and such competitive performance is reached.",
    "This paper proposes to learn a Canonical Capsule decomposition of shape point clouds in a self-supervised manner.  Given an unaligned 3D point cloud dataset, the proposed method constructs pairwise data with random SE(3) transformations, and then extracts the per-capsule pose and a transformation-invariant descriptor. The experiment results show the importance of the object-centric representation with capsule decomposition in many applications, including reconstruction, canonicalization, and classification. ",
    "The paper proposes a self-supervised capsule architecture for 3D point clouds. In order to circumvent the customary need to train on pre-aligned datasets, the authors introduce the Canonical Capsules to compute the K-part decomposition of a point cloud that allows unsupervised \"object-centric\" learning of 3D representations without requiring a semantically aligned dataset. The main idea of the canonical capsules is to enforce invariance/equivariance by relating the decomposition result of two random rigid transformations.  The authors compare the proposed method against state-of-the-art methods on 3D point cloud reconstruction, canonicalization, and unsupervised classification.",
    "The paper proposed a self-supervised capsule based architecture for 3D point cloud. The main goal is to learn a  canonicalization operation that allows unbiased object-centric reasoning.  The idea is that an object is decomposed to K keypoints using canonical capsules, the whole system is trained in an unsupervised fashion based on pairs of randomly rotated/translated  of the same object. The capsule pose equivariance is enforced by requiring the equivariance of two keypoint sets based on the known relative transformation of the pair images and the capsule descriptor invariance is enforced by matching the pair keypoints. The proposed framework have been evaluated in 3D autoencoding and reconstruction, unsupervised classification and canonicalization on ShapeNet dataset.",
    "This paper introduces a new method to construct conformal prediction intervals based on histograms of the conditional distribution of an outcome variable. Given a histogram of the conditional distribution of the outcome variable the method finds the shortest interval whose associated mass is no less than the desired coverage probability of the prediction interval. This yields intervals that automatically adapt to the skewness of the data. The intervals have provably correct marginal coverage in finite samples and correct conditional coverage and optimal length in large samples. A simulation study and numerical experiments on several benchmark data sets corroborate the theoretical results and demonstrate the advantage over several competing methods. ",
    "This paper proposes a new nonconformity-score based on conditional density estimates P(Y|X). The main idea is to approximate the optimal prediction interval based on the conditional density estimate. The proposed non-conformity score is experimentally assessed using the conformalization technique of split conformal. The overall method provably achieves marginal coverage, performs comparably to other methods for conditional coverage, and achieves the shortest prediction intervals on all datasets. ",
    "This paper proposes an extension to conformal prediction that adapts to skewed data, and can achieve better conditional coverage (and provably achieves conditional coverage asymptotically). Conformal prediction in general is a methodology for constructing confidence sets that output likely response candidates $\\widehat{\\mathcal{C}}(X) \\subseteq \\mathcal{Y}$ for and input $X$, rather than a single value. The goal is to ensure that $\\widehat{\\mathcal{C}}$ covers the true response variable, $Y$, with specifiably high probability. While many prior methods provably control *marginal* coverage, *conditional* coverage is a much harder (and more practically important) goal (albeit impossible in finite samples in the general case). This paper attacks this problem by developing a novel conformalization strategy that leverages calibrated estimates of the conditional density $Y \\mid X$ to obtain approximate conditional coverage in finite samples (empirically), and asymptotic conditional coverage (theoretically). ",
    "This paper introduces a conformity score that aims to decrease average interval lengths and improve conditional coverage from a black-box estimate  $\\hat{P}(y \\mid x)$ for split conformal prediction. The method, conformal histogram regression (CHR), involves first binning the space of $Y$, resulting in a conditional histogram from which approximate oracle intervals can be computed. A nested sequence of these intervals is then created for a sequence of predictive miscoverage values $\\tau$, where $\\tau$ will be close to $\\alpha$ if $\\hat{P}(y \\mid x)$ is a good estimate. The value of $\\tau$ is selected through a conformity score, and the authors show their method obtains finite marginal coverage and asymptotic conditional coverage. The authors then demonstrate the method on a few examples. ",
    "The paper shows how to obtain *short* prediction intervals that approximately have the right conditional coverage. In order to do so, the method estimates the conditional distribution of a new label given its features, and then uses a conformal score based on the quantiles implied by such estimate to create the prediction intervals. The experiments show that the method outperforms other quantile-based conformal methods in terms of width while still approximately controlling conditional coverage. Some theoretical results that prove converge to the oracle (i.e., the shortest prediction interval) are also shown.",
    "This article extends to a kernel setting the idea of Elesedy and Zaidi to leverage a decomposition of L^2 into invariant and null-orbit subspaces. The authors claim to prove the benefit for generalisation of projecting the solution of KRR on the invariant subspace. The article mainly consists of the lemmas and proofs to reach the main theorem on generalisation bounds.",
    "This paper proposes a theoretical analysis of the generalization benefit obtained for some classes of problems which exhibit invariance with respect to a group action. Especially, the paper focuses on kernel ridge regression in the statistical model $Y = f^*(X) + \\epsilon$ and shows that using orbit-averaging on the learnt model provide strictly positive benefit whenever $f^\\star$ is invariant with respect to the group action used in avering. Some decomposition of the involved RKHSs in terms of invariance is provided, and the generalization benefit is characterized in terms of the number of samples and typical quantities related to the kernel. ",
    "The paper aims at quantifying the possible benefits of incorporating invariances to kernel methods. The approach takes the hypothesis returned by kernel ridge regression and enforces invariance by orbit averaging relative to actions of a compact group, i.e., the test prediction at a point $x$ is the average of predictions over the orbit set $\\\\{ gx\\ |\\ g \\in G \\\\}$, with $G$ denoting the group defining an invariance principle. The main contribution is a theoretical result showing that for target hypotheses which are G-invariant, i.e., $f(gx)=f(x)$ for all $g \\in G$ and $x \\in X$, the excess risk is strictly positive (relative to kernel ridge regression hypothesis) and the sample complexity when enforcing invariance can be much lower compared to pursuing standard kernel ridge regression learning (Theorem 5). The main idea is to observe that orbit averaging is a linear operator which defines a subspace of the original RKHS and by exploiting this orthogonal decomposition one gets a lower bound on the excess risk, similar to treatments in low-rank approximations via sub-space restricted inner products.",
    "The authors present a theoretical generalization gap based on the invariance incorporated by the kernel. An orbit-averaged functional is defined with a set of invariant transformations G on data to produce an operator which maps a function to another function that averages the functions of the transformed data. The functional is used as the projection operator to produce the set of orthogonal functions to the invariant functions, and the generalization gap has been derived for kernel ridge regression using the effective dimensionality of those orthogonal functions. ",
    "This paper proves a benefit, in terms of expected risk, of orbit-averaging the solution of kernel ridge regression (with respect to actions by a given compact group) compared to the original solution of kernel ridge regression. The extent of this benefit depends on the \"effective dimension\" of the space orthogonal to the space invariant to group action, as well as what the authors call \"differences in bias\". Finally, the authors demonstrate a simple example in which the input domain is the unit sphere in d-dimensions, and the kernel is linear. The contributions are entirely theoretical. ",
    "This paper presents an approach to simultaneously train a prediction network along with a generative model to map the neural network activations back to inputs. The use cases of doing so include (1) interpreting the information encoded in an activation, (2) composing the network with itself and other pre-trained networks, which in turn provides a means to get uncertainties and to regularize the network, and (3) to assert that the network satisfies some constraints on what it can and cannot learn in the intermediate layers. The paper is evaluated on several image benchmarks and speech benchmarks and showcases all the above benefits.  ",
    "This paper proposes to jointly train a generative model that maps activations back to the input space. The work demonstrates several benefits of this approach.  * Probing: It provides a way to decode the activations which enables the users to make sense out of it since the decoded activations are in the input space.  * Composing networks: The decoded activations allow to compose a DecNN model with another model with the same input type.  * Data Augmentation: The DecNN model can be composed with itself. This can be viewed as data augmentation since the decoded activations are of the same \"type\" as the input and retain the features that are relevant to the prediction task. * Ensemble network. The DecNN model can be recursively composed with itself to get the \u201cRecursively Decodable Neural Network\u201d (ReDecNN) model. This model can be viewed as an ensemble network. The paper shows the usefulness of ReDecNN for the tasks of measuring uncertainty, OOD detection, and calibration. * Constrain the activations: The decodable activations makes it possible to specify the kind of information an activation is not supposed to capture. This provides assertion-like capability to the neural network. ",
    "This work proposes DecNN, and the main goal is to allow people to interpret the intermediate neural network activations. The base model is an 8-layer MLP. The core idea is to train another generative model that takes the MLP activation as the input, and the generative model aims to decode an image in the model input space. During training, the loss of the generative model aims to reconstruct the input image given the activations of all intermediate layers. They further design ReDecNN, which recursively composes DecNN by taking the output of the generative model as the input of DecNN. They demonstrate that the generative model produces interestingly interpretable outputs to explain why the classifier makes correct or wrong predictions. They also show some promising results for out-of-distribution detection, calibration, and fairness.",
    "This paper argues for inverting intermediate latent representations of convolutional classifiers -- predicting the original input -- as a tool for improving robustness and interpretability. The ability of the model to learn invertible intermediate hidden representations acts as a regularizer during training.  This basic premise is used in several ways. For example, a recursive version of this idea (using the reconstructed input to classify, and the intermediate hiddens of that to re-reconstruct the input, adding that reconstruction loss into the overall loss calculation) leads to an interesting form of drop out: choose which reconstructions (from which layer, and which recursive depth) to use in the final output. That can be used for enhanced forms of Monte Carlo Dropout, improving uncertainty computations over regular MC Dropout.  Another use is in placing constraints on intermediate hidden layers. For a fairness goal, such a constraint might be that, given a good classifier for some protected attribute, that classifier has poor performance on the reconstructed inputs from the original model's hidden layers. In a sense, this constrains the training of the model to lose the information that would allow the external classifier to predict the protected feature.",
    "This paper explores jointly training generative model probes alongside a neural architecture to imbue the model with capabilities analogous to \"debugging\" in traditional software. By training the generative model probes to reproduce the model inputs, every intermediate activation can be decoded to input space (images). The authors use this (1) to interpret the partial progress of the model made at intermediate layers, (2) to restrict the model from using sensitive information from the inputs, and (3) as an interface to compose the model with itself and with other pretrained image models. The authors further use self-composition to produce an ensemble from a tree of connected classifiers, which in turn gives uncertainty measurements that enable (4) out-of-distribution detection and (5) calibration. Experimental evidence backs each of these contributions.",
    "This article proposes a study on the rates of estimation of Brenier maps using the plug in \"barycentric mapping\" estimator. As a consequence of this study authors obtain rates of convergence for $W_2^{2}$ in various context (depending on the regularity of the measures and on the setting: discrete-discrete of semi-discrete). They apply their results for Wasserstein barycenter estimation and Nonparametric independence testing. ",
    "This paper analyze the statistical behavior of the general plug-in estimators of OT defined by barycentric projections. The authors provide a thorough analysis of the rate of convergence for the transport cost and the transport map. They also consider kernel smoothed plug-in estimators and relate its rate of convergence to the smoothness of the densities, which alleviates the curse of dimensionality suffered by the plug-in estimator.",
    "Summary =======  Context: --------  This paper tackles the problem of estimating the rate of convergence of empirical Monge maps (through its Kantorovich barycentric map approximator) to the true Monge map for  absolutely continuous Lebesgue measures.    Contribution ------------  - The authors provide new rates of convergence of the barycentric map using standard  empirical plug-in estimators (O(n^{-2/d})) - If the measures are regular enough (Holder smooth), the dependence on the dimension completely vanishes (which was established for Gaussian distributions https://arxiv.org/pdf/1905.10155.pdf) - The authors propose to take advantage of this smoothness result to sample from smoothened distributions (using a Kernel density estimator) and provide the sufficient conditions to obtain a desired rate. Higher smoothness however requires more samples: a tradeoff between statistical accuracy and computational cost cannot be avoided.  ",
    "In standard OT problem, marginal distributions of the data are unknown. The current work considers plug-in estimation using Barycentric projection and derived rate of estimation. The idea of Barycentric projection is to plug the estimated marginal distributions of the data in the OT problem. Conditional mean of given us estimated and rate of estimation is derived. Various plug-in estimators of density of are considered such as empirical CDF and kernel density estimator.",
    "This paper studies the problem of estimating an optimal transport map between two probability distributions on Euclidean space, given IID samples from each of the distributions. The main result (Theorem 2.1) gives a general upper bound, in terms of the dual representation of the 2-Wasserstein distance. This is used to give upper bounds, in probability, on the rate of decay of the estimation risk both for the plugging in empirical distributions in the absence of smoothness assumptions and for kernel estimates under smoothness assumptions. Finally, implications for two applications (Wasserstein barycenter estimation and nonparametric independence testing) are discussed.",
    "The paper proposes to use infinitely wide CNNs to perform dataset distillation \u2013 obtaining a tiny dataset that enables high accuracy. The approach is an extension of a prior work (Kernel Inducing Points (KIP), etc.). Results are shown on MNIST, Fashion-MNIST, SVHN, CIFAR-10/100 datasets.",
    "In this work the authors extend the Kernel Inducing Points (KIP) method for dataset distillation to a new set of kernel functions and achieve new state of the art results on dataset compression. Since the KIP algorithm is a key algorithmic mechanism in this work, I will summarize it: The KIP method optimizes what can be seen as a test residual of a target dataset fitted by a kernel regression model that is created using a support dataset. This means that given a target dataset distribution, one can differentiate through the kernel computations to evolve the support data points in the support dataset freely in the input space and optimize them. After optimization the support dataset (Which is usually taken to be much smaller than the target distribution) can be used as a distilled version of the dataset. This compressed dataset enables classification and training without training with extensively large datasets. In this work the authors use the KIP algorithm using a family of kernels corresponding to infinitely wide neural networks that were discovered in the realm of NTK. Such infinite NTK convolution kernels are known to provide state of the art results (when compared with other kernels) on classic classification tasks such as MNIST, CIFAR, etc. The biggest issue of such infinite-network kernels is that they require immense amounts of computation to construct the kernel. In this work, the authors construct such kernels at each training step (!) and then back-propagate through the kernels (!!) to optimize the datapoint. This impressive feat is made possible by considering 3 layer convolutional neural networks and working with a relatively small number of data-points (5K as opposed to the whole dataset). This is still highly computationally challenging and the authors create a careful implementation including an orchestration system working with 100s of GPUs for optimizing the support dataset. With this new kernel family the authors achieve state of the art results on dataset compression and analyze the compressed dataset using high dimensional statistics tools.",
    "Paper mainly extends the dataset distillation algorithms KIP and LS (Nguyen et al. 2021) to infinitely wide neural networks. To that end, authors present a distributed framework that draws upon huge hardware resources and show improvement on the distillation performance. Paper also analyzes the synthesized data samples (images, labels) via multiple studies.",
    "The paper performs thorough analysis and exploration on the implication of the proposed KIP and LS methods by Nyugen 2021 for dataset distillation. KIP and LS are based on the inf-width network limit as kernels, and devised based on kernel Ridge regression, and has been shown in prior work to have good dataset distillation performance. This paper greatly extends the analysis in Nyugen 2021, by investigating how KIP and LS can be used to achieve SOTA dataset distillation results in a kernel setting, and also sometimes in a neural network (NN) transfer setting. Furthermore, the authors provide impressive and insightful analyses on (1) how the dataset distillation performance behaves as knobs of the algorithms are tuned (2) what are the properties (spectral, intrinsic dim., visual) of the distilled data. Not every paper needs to propose a new method or new theory. Here, thorough analysis and understanding of an existing good method should still be appreciated.",
    "This paper performs dataset distillation to improve the deep learning training efficiency. By using the algorithm made by [1] and some expanded methods, the authors achieved the state-of-the-arts accuracy on CIFAR-10, MNIST, Fashion-MNIST, CIFAR10, CIFAR100, and SVHN datasets.  [1] DATASET META-LEARNING FROM KERNEL RIDGE REGRESSION, ICLR 2021",
    "This paper focuses on semi-supervised learning with outlier unlabeled data. This problem has attracted much attention in the semi-supervised learning community. The authors propose a method that contains two parts: First, detect outliers based on the OVA classifier. Second, propose an open-set soft-consistency regularization loss that can help improve the outlier detection performance.",
    "This manuscript introduces OpenMatch for open-set semi-supervised learning. The OpenMatch integrates a one-vs-all classifier (OVA-classifier, working as an outlier detector) and FixMatch. The main contribution should be the soft open-set consistency regularization (SOCR) in Figure 1 and the OpenMatch Framework in Alg 1. Specifically, the SOCR follows the same self-supervised framework in FixMatch but it uses OVA-classifier to output consistent anomaly score distribution. After using the model in Figure 1 to identify inliers from unlabeled data, the FixMatch is allowed to reach a higher accuracy on the OSSL tasks.",
    "This paper tackles open-set semi-supervised learning (OSSL) where outliers exist in unlabeled data. The key idea for detecting outliers is to learn class-specific, one-vs-all (OvA) classifiers\u2014if all classifiers produce negative outputs for an unlabeled data, the data is considered an outlier. In addition to the classification loss computed on labeled data, the OvA classifiers are also trained on unlabeled data with an entropy minimization loss and a consistency regularization loss\u2014the latter is computed on two views of the same data. The results on CIFAR and ImageNet show that the proposed approach largely outperforms the baselines in terms of both recognition accuracy and outlier detection accuracy.",
    "The authors propose an idea to improve model's performance under the open-set semi-supervised learning setting. This work proposed to leverage OOD detector, combined with FixMatch, and soft open-set consistency regularization (SOCR) to improve the model training during open-set semi-supervised learning. I think the usage of OOD on ignore outliers is not new and an unsupervised method on learning the consistency between augmentations for unlabeled data is also not new. Thus, I am not sure if I can find too much of novelty from this work itself, but I do appreciate the author's effort in putting them together to be a complete model, which in fact make solid progress on the open-set semi-supervised learning setting. ",
    "The paper proposes a model for open-set semi-supervised learning. As a semi-supervised learning model, it tackles classification where only a portion of the training data is labeled. \"Open set\" refers to the fact that the unlabeled data are noisy and can contain out of distribution examples, for which the class is not among the known classes. Out of distribution samples are present also during test, and the model has to recognize them and avoid classification on them. The proposed model builds on top of existing works, combining several loss terms and ideas such as one-versus-all classifiers and FixMatch as the main semi-supervised learning engine. The main technical contribution is a loss term enforcing the out-of-distribution score for two augmented versions of the same unlabeled example to be similar. Extensive experiments validate the proposal against recent state-of-the-art models.",
    "This paper proposes a method to learn goal-conditioned policies by combining ideas from goal-conditioned RL and model-based exploration. It operates by training an exploration policy within the model to maximize model disagreement (as proposed in previous works), as well as a goal-conditioned policy to reach states in the replay buffer. These are then both deployed to grow the replay buffer, and the process is repeated. The approach is evaluated on a newly-defined set of benchmark tasks based on the Deepmind Control suite, as well as simulated robotic manipulation. They report better performance compared to previous methods such as Skew-Fit, DIAYN and two others. They also investigate two different choices of distance functions for the goal-conditioned RL component, and show that the optimal one depends on the setting. ",
    "This paper proposes a model based RL setting where an agent learns a task agnostic model, learns two policies to explore and reach input goal states (specified as images) respectively and is able to operate in a goal conditional mode during evaluation time.   The key thesis is to use the world model to incentivize the agent to explore the environment by maximizing expected information gain and reach input goal states by learning to reach states from its past experiences.   There have been other model free and model based approaches studying the same problem but the claim is that its the first to combine model based exploration and reachability on new benchmark environments. ",
    "This paper proposes to jointly train two agents in a differentiable world model: an *explorer* that is rewarded to explore uncertain states and an *achiever* whose task is to achieve a given goal state. After training, the *achiever* can be deployed as a goal-reaching policy without further tuning. Authors also spent time investigating how to design the loss function for the *achiever*. In the experiments, three new benchmarks are introduced and the proposed method is shown to outperform baselines. ",
    "Summary: This paper proposes a model-based method with an ensemble disagreement-based exploration bonus for learning universal goal-conditioned policies. The world model and policy learning methods are adapted from DREAMER. In addition to that, the paper first introduces an explorer to first explore the state with large uncertainties, and then train the achiever to reach the proposed goals. The use of the world model enables data-efficient learning and exploration. The paper makes solid experiments and evaluates their approach on various domains. The paper also discusses two different distance metrics for learning goal-conditioned policy on images.",
    "This paper introduces a framework to train policies for visual goal oriented tasks. The framework comprises two policies, the first, an explorer, which is trained to seek out novel states (where novelty is defined as the level of agreement between an ensemble of future state predictors - an approximate measure of epistemic uncertainty), while the second, an achiever, is trained to reach these states. A model based approach to train the achiever, where the achiever is trained using trajectories generated by a learned dynamics model. The paper also introduces a new benchmark for testing goal oriented polices of this form, comprising a kitchen manipulation task, a block handling task, and a yoga task. ",
    "Shapeshifter reparameterizes dense kernels into a product of two lower-rank matrices. Shapeshifter introduces reshapes and transposes to make this reparameterization more efficient. The paper provides a theoretical justification for its expressivity and strong experimental results in machine translation.",
    "This paper proposes a method to reduce the number of parameters by weight factorization. Unlike traditional low-rank factorization (n x r and r x m), this work decomposes the matrix into two sqrt(mn) x r matrices. The algorithm includes the reordering of elements to recover the desired shape. The authors find connections to Kronecker products and theoretically support the expressiveness of the proposed method. Experiments on NMT tasks show that Shapeshifter can achieve better parameter efficiency (fewer parameters with comparable performance). The results are compared to two similar works: PHM and DeLighT.",
    "This paper presents an approach called ShapeShifter to compress large language models. The paper follows the approach of reducing number of parameters by using factorized matrix representations. The primary idea is to represent the matrix as a sum of Kronecker products, instead of standard low-rank factorizations. The paper theoretically shows that for non-square matrices, the proposed approach allows for increased reduction in parameters for the same decomposition rank. For square matrices, it allows for increased expressiveness of the decomposition for the same rank. Experimental results on machine translation tasks show that the proposed approach performs much better than the state-of-the-art model compression approaches and is just slightly worse than the large models.",
    "A sizable effort has been made in recent history to obtain the accuracy of very large language models at a fraction of the parameter of the large models. Broadly these methods fall into various categories like model compression, factorized representation, distillation etc. This paper underlines another such attempt at obtaining a factorized representation of matrices to reduce the parameter space. The authors justify the use of Kronecker products to factorize parameter space, by showing that stacked layers of low rank matrices increase expressiveness. They also show the effectiveness of their proposed method by achieving a 4 to 14-fold reduction in parameters without sacrificing accuracy.",
    "This paper proposes an algorithm they call \u2018Shapeshifter\u2019 to reduce the number of parameters needed for Transformer-based models while preserving expressiveness and performance. The proposed algorithm is based on the idea of low-rank factorizations of weight matrices, but uses a different factorization method involving sums of Kronecker products that leads to greater expressiveness. They show theoretical analysis to prove their factorization can accurately represent any $n \\times m$ matrix or stack of matrices (in an idealized case), and experimental results using transformer-based models for translation on English-German, English-French and English-Romanian. They demonstrate superior or comparable performance with vastly fewer parameters compared to some other model compression techniques.",
    "The paper presents a way to incorporate the tree-structure information into a transformer architecture to better learn representation for code. The tree structures are first dispatched as leaf-to-leaf \"relative paths\" and leaf-to-root \"absolute paths\", and then embedded and modulated as additional learnable parts of the query, key, and value components within the transformer attention. The authors evaluate their proposal on the task of extreme code summarization -- predicting function names. Results show improvements over 4 previous non-transformer and transformer models on 3 out of 4 programming languages tested. The authors also carry out ablation studies to understand the effect of absolute paths and pointer networks but many important questions remain unanswered. ",
    "This paper introduces a new neural network architecture for code, TPTrans (Tree Path Transformer), by modifying the attention calculation in the Transformer architecture to use information about paths in the syntax trees of programs. The modification works by computing path embeddings between pairs of leaf nodes (\"relative path embeddings\") and between leaf nodes and the root (forming nodes' \"absolute path embeddings\"), and incorporating these into the Transformer's attention module. The paper evaluates TPTrans, including baselines and variants, on code summarization -- the task of predicting a function's name given its body -- for four different programming languages. The main experiments reveal the value of including embeddings of sequences (the paths) in the attention calculation over baselines, and subsequent experimentation compares the impact of relative and absolute paths, and the effect of pointer network outputs on the model.",
    "This work continues on earlier advances in how positional and relational encoding is used by the self attention primitive of Transformers, in particular in the context of source-code understanding. Prior work has biased self attention to encode relative relational information between inputs (e.g., edges or distance on some graph), and to separate the self-attention term due to position from that due to input.  For the former, TPTrans runs the path between any two tokens (specifically, the path in the code Parse Tree between two leaves -- the authors call this the \"relative path\") through an RNN, and uses the resulting embedding to bias the self attention between those tokens.  For the latter, TPTrans-$\\alpha$ runs the path from the parse-tree root to a token through an RNN (the \"absolute path\"), and uses that to construct a separate positional self-attention term.  The results show that both TPTrans and TPTrans-$\\alpha$ outperform prior work (most notably, Code Transformer), but TPTrans seems to dominate TPTrans-$\\alpha$ with a smaller set of trainable parameters.",
    "The paper proposes an Transformer-based architecture for embedding source code snippets that integrates encoding of absolute and relative AST paths for all code tokens into self-attention. Following up on prior work in relative position encoding, they map AST paths into the position encoding framework, modify the self-attention computation accordingly, and evaluate on method summarization. The approach is compared to recent Transformer-based baselines on the standard method summarization benchmark, as well as to code2seq, which pioneered path-only source code encoding. The results improve performance significantly on almost all benchmarks.",
    "The authors present a technique for modeling source code. They point out that modeling code is different from language because of the tight binding between ASTs, data, and control flow. Also they mention some weakness of GNNs. To compete with GNNs, they introduce a new method which is a sequence-based transformer that incorporates graph structure through the attention weights. The model is shown to be effective for code summarization.",
    "The paper proposes a transformer based generative model which shows competitive results on multiple image generation benchmarks. It combines existing techniques of blocked and axial attention to reduce the computational complexity of self-attention mechanism. To further reduce the complexity, the proposed attention mechanism is only used at lower resolution blocks. The paper also employs technique similar to self-modulation to condition image generation process on the input latent code at all levels.  ",
    "This paper has presented HiT, a Transformer-based generator for high-resolution image synthesis based on GANs. Instead of using full attention, this paper has proposed the multi-axis blocked self-attention, which captures local and global dependencies within non-overlapping image blocks in parallel. In addition, HiT introduces the cross-attention mechanism to integrate noise information into multi-stages of the generator. Extensive experiments demonstrate the superiority of the proposed method.",
    "To address the quadratic complexity of the self-attention operation, this paper proposes a new Transformer-based generator for high-resolution image generation based on GANs, denoted as HiT. In the low-resolution stage, the authors propose a multi-axis blocked self-attention. In the high-resolution stage, they keep multi-layer perceptrons reminiscent of the implicit neural function. Extensive experiments demonstrate the effectiveness of the proposed method. ",
    "This paper proposes a new transformer-based generator for high-resolution image generation. It addresses the quadratic scaling problem of the attention operator with multi-axis blocked self-attention which considering the within blocks and across blocks attention. The proposed cross-attention for input and intermediate features is also novel. The evaluation is done in ImageNet and FFHQ datasets.  Promising results are provided. ",
    "The paper describes a purely attention-based GAN generator architecture where low-resolution deeper layers feature larger-scale (more distant) communication and higher-resolution layers synthesize locally using MLPs,  but still conditioned (indirectly) on the initial latent code.  State-of-the-art results are claimed for 128^2 unconditional ImageNet synthesis (but I believe this claim to be false, see below). In addition, results are shown for CelebA-HQ and FFHQ. While the architecture have some similarities to the near-concurrent work of Hudson and Zitnick (ICML 2021), lack of comparisons should not be held against this paper.  I remain unconvinced by the argumentation and how the results support them. Visually high-quality results are only shown for the simple face image datasets, for which attention mechanisms do not appear to be as necessary as for more complex ones that feature scene compositions. I feel I do not walk away feeling that I learned something.",
    "The authors study the problem of  learning geodesically convex halfspaces on graphs within an active learning setting. They propose a new algorithm and rigorously analyzed it by showing lower and upper bounds of the query complexity. They also carry out an experimental evaluation to validate their theoretical results. ",
    "This paper presents novel bounds on the query complexity of learning halfspaces on graphs via convex analysis. Two general upper-bounds were derived along with a simple general lower bound based on extreme vertices. Based on these bounds, the authors developed two querying strategies based on greedy and selective sampling approaches. One interesting practical aspect of the proposed active learning algorithm is the evidence that ground-truth communities in real-world graphs are typically convex. The proposed bounds are compared to previous results based on the cut-size, which show that the halfspace assumption enables learning with large cuts, whereas previous bounds become less applicable.",
    "This paper studies the query complexity of learning geodesically convex halfspaces on graphs.  In the present context, a geodesically convex set of a graph $G = (V,E)$ is a subset $C$ of $V$ such that each shortest path containing any two vertices of $C$ is contained in $C$, and a halfspace of $G$ is any convex set of $G$ whose complement is also convex.  The main contributions are upper and lower bounds for the query complexity of a class of halfspaces on a weighted graph in terms of various graph parameters.  One upper and almost matching lower bound is given in terms of the size of the minimum shortest cover and the graph diameter.  Another upper bound is given in terms of the minimum size of a hull set, the graph diameter and the maximum size of a set $W_{=ab}^*$ of vertices over all pairs $(a,b)$ of vertices, where $W_{=ab}^*$ is defined to be the set of all points that avoid the intersection of rays from $a$ (resp. $b$) to any point neither in the convex hull of $a/b$ nor in that of $b/a$ and are themselves not in these convex hulls.  The size of the set $W_{=ab}^*$ can also be bounded in terms of the treewidth.  It is shown, moreover, that increasingly tighter lower bounds can be obtained as more stringent separation axioms are assumed.         ",
    "This work studies the query complexity of active learning geodesically convex halfspaces on graphs (that is given a graph $G=(V,E)$, the class of subsets $S \\subseteq V$ such that $S$ and $V \\setminus S$ are both convex). While most prior works gave hypothesis-dependent upper bounds, here the authors give two novel worst-case bounds based on natural graph parameters: the first on the smallest shortest path cover, the second on the hull size, diameter, and tree-width. While neither algorithm is computationally efficient in its original form, the former can be efficiently approximated to within a (multiplicative) logarithmic factor in the diameter, and the latter can be computed efficiently on graphs with bounded tree-width.  The authors also prove a complementary series of lower bounds. The first show both bounds are tight in a weak sense for general graphs in the sense that there exist examples matching the upper bound. They then provide a series of lower bounds based on four (successively stronger) standard convexity properties of the underlying graph $G$. Their final (and tightest) bound holds for graphs on which every two disjoint convex sets are halfspace separable. In this case the only gap between the upper and lower bounds is that between the Radon number and Tree-width of the graph. The authors also provide a number of reasonably natural classes on which their bounds are exactly tight, including trees, $K_{2,3}$ minor-free graphs, partial cubes, and weakly median graphs.   Finally, the authors provide some experimental motivation for their setting, along with a number of heuristic implementations of their algorithm. They compare performance to two non-trivial baseline algorithms, the label propagation algorithm of Zhu et al. (2003), and the $S^2$ algorithm of Dasarathy et al. (2015), and show preliminary experimental evidence that their algorithm outperforms both.",
    "The paper studies the problem of active learning on graphs to identify two classes. The main assumption is that the vertices of the same class form a geodesically convex set, and the two classes are halfspace separable.  The authors propose a simple halfspace querying algorithm, and analyzes the upper and lower bounds on the number of queries required to deduce all labels of the graph for binary classification on connected undirected graphs. In particular this number of queries is related to the graph properties and the separation condition between two classes. Furthermore the VC dimension of the hypothesis class is related to the aforementioned properties.  ",
    "The paper proposes a simple yet effective method of pretraining the feature encoder in TAL models. The motivation comes from the distribution-shift as well as the task-shift between the classical image-/action-classification pretraining and the TAL training. To make the encoder also adapt to the TAL task, the authors propose to unfreeze the encoder and pretrain under the TAL task. Due to GPU memory limit, the authors use spatially/temporally low fidelity data to pretrain the encoder. Experiments are conducted to verify the authors\u2019 motivation and show the advantage of such a pretraining routine.",
    "Updating after the rebuttal: The rebuttal well addressed some of my concerns. I would raise the rating to 6: Marginally above the acceptance threshold  ---  The paper presents a low-fidelity video encoder optimization approach to relieve the large memory constraints in the temporal action localization problem. The proposed approach is easy to implement and reasonable results have been obtained on ActivityNet and HACS datasets. However, the proposed approach is more like an engineering solution. The technical novelty of the proposed approach is limited. ",
    "** Update 8/16/21 **   Thanks to the authors for their rebuttal in response to my questions/concerns. After reading the rebuttal and the other reviews, I am updating my score to 6, to better reflect the contributions made by the work.  **   The paper aims to tackle the hardware constraint for end-to-end optimization of both video encoding and TAL head models. Different from prior works that freeze the video encoding network when training the TAL head, the proposed method optimizes both of them jointly on low-resolution (spatially and temporally) video frames and then finetunes the TAL head on full-resolution videos. The main contribution of this paper is resolving the task discrepancy problem for the video encoder when training TAL models. Extensive experiments are conducted in the paper to compare the lofi setting with several state-of-the-arts, as well as similar models under different pretraining conditions. Results indicate the proposed method outperforms the baselines. ",
    "In this paper, the authors propose a new method to allow video encoder optimization in training temporal action localization (TAL) models, which is often ignored by existing TAL methods due to GPU memory constraints. The proposed method LoFi reduces the demanding GPU memory requirement by using a lower temporal and/or spatial resolution in the mini-batch construction. The proposed LoFi technique has shown to help enhance the performance of off-the-shelf TAL models on ActivityNet and HACS-v1.1. Also, the performance improvement is universal across different types of video encoder.",
    "Models for temporal action localization (TAL) in long, untrimmed video are typically trained in two stages, a video encoder pretrained on a auxiliary video clip classification dataset and then frozen, followed by a TAL head. End-to-end training of the encoder and TAL head is infeasible because the encoder activations for an entire, long video will not fit in GPU RAM. This paper proposes a solution: use the ideas of mulgrid training [51] to do end-to-end training of a lower resolution video encoder and TAL head. They explore strategies for cycling through regimes of lower spatial, temporal, and spatio-temporal resolution training, and demonstrate performance gains on the ActivityNet and HACS datasets, using a number of backbone networks and TAL heads.  ",
    "This paper studies the derivatives of regularized M-estimators and distribution of the residual.  These results give rises to a new novel adaptive criterion for tuning loss and penalty function. Numerical experiments are conducted on various models to validate the theoretical result.",
    "The paper is dedicated to the analysis of robust linear regression, where the proposed estimation is based on sparse M-estimation. The statistical criterion corresponds to a penalised M-estimation problem, where both the non-penalised loss function and penalty function are assumed convex. The contributions of the paper can be summarised as follows: - the authors provide a criterion for the optimal selection of the non-penalised loss and penalty function so that some out-of-sample distance, say D, is minimal.  - the authors quantify the behaviour of the penalised estimator \\hat\\beta using quantities depending on the observations only (idest no unknown quantities such as true sparse support) in a regime where p/n has finite limit. - some explicit derivative formulas of the penalised estimator are provided.  - the distribution of the estimated residuals is provided, which allows for a selection of the tuning parameter for regularization. - the authors derive an approximation formula of the distance D.  ",
    "The authors study M-estimators with convex penalties. They give algebraic forms for derivatives of the estimator with respect to response $y$ and the design matrix $X$. They describe the distribution of residuals or certain functions of residuals. Given a loss function and penalty (with tuning parameters) they propose a criterion that can effectively approximate the out-of-sample error. This criterion can be computed without the knowledge of the covariance matrix $\\Sigma$ (rows of $X \\sim N(0,\\Sigma)$). They give finite sample bounds that show how fast the criterion converges to the out-of-sample error.   ",
    "Finding the right parameter when doing robust estimation is a recurring problem in the robust community. This article propose to choose the parameters in a robust regularized linear regression model by minimizing a completely data-driven criterion. This criterion is shown to be a good approximation to the out of sample error, this is also illustrated on practical experiments.",
    "This paper studies M-estimators in linear models, with convex and gradient-Lipschitz loss function and a convex penalty.   Main contributions:  1. The authors provide a criterion to select tuning parameters (the loss function and the penalty function) of M-estimators, such that minimizing the criterion provides a proxy for minimizing the out-of-sample error, since the criterion is an approximation of the out-of-sample error up to a constant shift. One advantage of this criterion is that it does not require the prior knowledge of the covariance matrix of the design and the noise distribution.  2. The authors provide simulation results that confirm theoretical findings.",
    "This paper proposes a generalization of the attention coverage penalty in seq2seq models (Wu et al 2016), where instead of encouraging a uniform coverage of the source, this work first predicts the expected coverage of each source word. During beam search, beam hypotheses that violate the expected attention coverage constraints receive a penalty. Experiments on 9 summarization benchmarks show that the proposed coverage loss outperforms using existing attention coverage losses during beam search.",
    "This paper thinks that cross attention distribution in transformer\u2019s encoder-decoder framework can help the performance of beam search. At the same time, this paper also proposes an algorithm to predict distribution to help beam search. This paper conduct experiments on 9 datasets to prove its effectiveness. ",
    "This work proposes to add a global attention feature component to the beam search scoring procedure for conditional generation, which typically just considers the fitness of successor tokens conditioned on the predicted history of tokens in the beam. This augmentation basically keeps track of cumulative local autoregressive attention on the source tokens during beam search and penalizes major deviation from the predicted desired \"global\" attention over the source tokens. Specifically, this approach proposes a finetuning step of neural language generators, which is responsible for predicting cumulative global attention on each token and the training is done via regression. During training, the \"reference\" global attention is computed by using the full reference in the decoder transformer instead of just the left prefix of the reference to compute attention.  A relatively simple scheme is proposed to measure deviation of cumulative local attention from the global attention in a decomposable iterative manner. This scheme also involves a form of length reward that encourages the generation to match the length predicted by the global attention.  Experiments are performed on the task fo summarization with pretrained summarization system on 9 datasets. The results show that the proposed beam search augmentation outperforms standard beam search in general. Most strikingly, the ablation experiment with the \"Oracle\" global attention (instead of prediction, if we had access to the actual global attention and hence the actual reference length) significantly outperforms beam search and the proposed approach demonstrating the potential of global attention.",
    "This paper tackles the problem of suboptimality of beam search as it is not able to have a global perspective of the probability of the generated beams due to truncated beam size (less than vocabulary size) for space and time complexity purposes. This paper proposes a global-aware beam search which is calibrated using the global attention distribution to guide the local decisions at every time step during beam search. The global attention distribution prediction is formulated as a regression task, which is then fed into a global scoring function to guide the beam search-based generation. This approach solves the mismatch between the local optimality of beam search with the global optimal generation. This modified search strategy has been shown to boost the summarization of two SOTA models BART and PEGASUS. ",
    "This paper presents a method to improve beam search by learning and predicting the global attention. A global scoring function is developed to regulate beam search to generate summaries. In Phase I, the global attention distribution is predicted in order to be included as a protocol to calibrate beam search. In Phase II, a step-wise global scoring function is used to guide beam search based on the predicted global attention distribution.  Experiments on 9 datasets show that the global-aware inference improves state-of-the-art summarization models.  ",
    "The paper presents a gauge equivariant transformer for geometric learning. The gauge equivariance aims to solve the orientation ambiguity when doing the convolution or local aggregation operations within a neighborhood. Specifically, this work achieves the gauge equivariant self-attention within the neighborhood defined by mesh data. Different from existing gauge equivariant layers, the paper proposes to accommodate the parallel transport in the regular field. As a result, the gauge equivariance is up to a certain error bound. Further, this work validates the effectiveness on two datasets including shape classification (SHREC) and human body segmentation.",
    "This paper addresses the main challenge in attention to manifolds, namely, that there are no coordinates to use as input in positional encoding. The network uses regular fields of cyclic groups and a parallel transport method for transporting features to these fields. Invariance to global rotations is achieved by taking only local position vectors. Experiments are performed on SHREC and Human Segmentation using a fraction of the usual transformer capacity.   ",
    "This paper considers the problem of introducing attention to data lying on manifolds (without a global symmetry). Since there is no canonical coordinate system available in such cases to parameterize neighborhoods, the authors instead use the notion of gauge equivariance, proposing a so-called gauge equivariant transformer. Some additional innovations in the intermediate layers are introduced to improve expressivity, and equivariance error is characterized. Experiments are reported on SHREC and Human Body Segmentation tasks, showing good performance with significant parameter efficiency compared to prior art. ",
    "This paper proposes a gauge-equivariant transformer (GET) for manifolds. The challenging issue for self-attention on a manifold is the lack of canonical coordinate systems on a surface, which results in rotation ambiguity. To address it, this work introduces the regular field of cyclic groups as feature fields, proposes a novel parallel transport approach that puts the feature vectors in these fields, and develops the gauge-equivariant self-attention by adopting Taylor expansion in solving equivariant constraints. The proposed method is validated on the tasks of 3D shape classification and segmentation, achieving SOTA on SHREC dataset and the Human Body Segmentation dataset.",
    "The authors address an important gap in existing literature at the intersection of self-attention networks (transformers) and the equivariant neural networks -- how to apply self-attention to manifolds or meshes (discretized versions of manifolds). This has immediate applications in the area of 3D shapes which are 2D manifolds embedded in 3D. The key challenge is that of gauge-equivariance as there is no canonical coordinate system and we would like the self-attention blocks to be equivariant to the choice of the gauge. To this end, the authors build a provably (approximate) gauge-invariant score function and a gauge-equivariant value function. The experiments show the importance of the proposed methods. ",
    "The paper presents a modified version of the EM algorithm that allows for faster fitting of mixture models. The approach is based on the idea of evaluating and updating a single mixture component per iteration. Furthermore, they present a generalized version that extends beyond the standard case of the exponential family.   The authors then follow with an empirical demonstration of the benefits: up to two orders of magnitude faster training while in some cases increasing the likelihood compared to the standard SGD approach.  The evaluation is carried on two architectures, SPTNs and mixture of real NVP flows. ",
    "The paper suggests a method for efficiently evaluating mixture models. The main idea is to use Expectation-Maximization (EM) and Metropolis-Hastings (MH) to evaluate only a small number of mixture components, reducing the computational cost by consequence. The theoretical contributions of the manuscript are two-folded. First, the authors proposed an EM-based algorithm for training, which uses MH for sampling from a smaller set of mixture components. Second, the manuscript generalizes the EM-based algorithm by making it compatible with gradient-based optimization methods. The practical contributions include experiments with Gaussian mixture models (GMMs), sum-product networks (SPNs), and mixtures of real-valued flows. Results show a benchmark speed-up of 100x.",
    "This paper proposes a new method for scalably fitting mixture models. The authors tackle the problem of fitting with a large number of mixture components. While there exist some works handling this problem, these methods are all limited to mixtures of exponential family distributions, whereas the authors\u2019 method applies to generic mixture models (as long as the model provides a likelihood p(data point i | cluster k)). They do so by proposing a modified version of the EM algorithm: instead of exactly computing the expectations in the E step, the authors propose to use a Metropolis Hastings algorithm to approximate the required expectations. In experiments, the authors show that their method (1) outperforms pre-existing large-K methods (where such previous applications are applicable), and (2) show that their method outperforms standard stochastic gradient descent in settings where other large-K methods are not applicable. The authors\u2019 method seems to work well, but I have a few clarification questions about the technical ideas behind the proposed algorithm and its empirical evaluation. Currently, I put a borderline score for the paper, but I\u2019m definitely open to increasing it after discussion.",
    "This paper proposes a stochastic EM algorithm. Specifically, the authors use a minibatch to approximate the data and use samples obtained from Metropolis-Hasting (MH) to approximate the likelihood component per datum. The proposed method is tested on a synthetic dataset and several UCI datasets.",
    "This paper proposes a stochastic approximation to the E-step of the EM algorithm to reduce the computational cost of fitting mixture models when the number of components $K$ is large. Specifically, the paper proposes using $M << K$ samples of the latent variables $z$ from a Metropolis-Hasting (MH) sampler to approximate the E-step. This lets us only use $M$ likelihood evaluations instead of $K$ for each observation in the E-step. The paper compares there proposed method against other EM-based methods on Gaussian mixture models on synthetic data, and sum product  transform networks and non-volume preserving flows on 19 UCI datasets. ",
    "This paper proposes an efficient sparse training method to solves the problem of accelerating the training speed of deep neural networks and save memory usage.  The authors first formulate the training process as a continuous minimization problem under global sparsity constraints.  Then, separating the optimization process into two steps, corresponding to weight update and structure parameter update. A variance-reduced policy gradient estimator is proposed to update the structure parameter. Finally, the experimental results are solid and strong. The problem has lots of meanings for engineering implementation.  ",
    "This paper addresses the topic of sparse training of neural networks. They target channel-level sparsity with the goal of realizing practical training speedups with existing software and hardware. The authors study the limitations of existing techniques in terms of their ability to exploit sparsity during training and show a wide array of empirical results with their proposed technique.",
    "Paper proposes a variational based pruning method where, with 2 structurally sparse forward passes and 1 sparse backward, the training can be significantly faster. Description is clear and theoretically sounds, equations are easy to follow, code is provided, results are encouraging. The paper might be a great benchmark and starting point for faster pruning-while-training with efficient inference. ",
    "The authors propose a channel-level sparse training algorithm that can effectively utilize the channel sparsity to accelerate both forward and backward propagation process. They divide the sparse training process into weight updating step and mask updating step. And solve the problem separately. More specifically, they develop a variance-reduced policy gradient estimator to update the trainable pruning mask without the need for backpropagation, and hence a sparse computation on both forward and backward propagation.",
    "Network sparsity has historically targeted only inference.  Recent explorations in training with sparsity fall short of their potential, though, by not fully exploiting sparsity in the forward and backward propagation steps.  The authors decompose training a channel-wise sparse network into two parts: training the weights themselves (as usual) and learning the sparse structure.  Rather than using a chain-rule based gradient step for the structure, a unique policy gradient estimator with reduced variance is used; it is composed of two forward passes, eliminating the need for the chain rule to be used to learn the sparse structure.  Experiments show competitive accuracy for saved parameters and FLOPs for a number of networks, as well as actual time saved during training with the proposed technique for VGG19 on CIFAR-10.",
    "Based on Non-Equilibrium IS (NEIS), the authors propose the new importance sampler NEO-IS. The main advantage of NEO-IS over NEIS seems to be that NEO-IS provides unbiased estimates of the normalization constant. They prove the unbiasedness and also propose an MCMC extension for sampling (which was not provided by NEIS). They empirically show that NEO-IS (and its MCMC variant) can be better that other recent methods for tasks of  (1) finding the marginal likelihood, (2) Sampling from posterior distribution, (3) Inpaiting. ",
    "The paper proposes a new family of importance samplers based on iterating an invertible map $T$ forwards and backwards, thus generating orbits that serve as importance samples after proper weighting. If normalized importance weights can be computed, the resulting IS estimate is unbiased. Also a self-normalized version is proposed, which is biased but still converges against the correct expectation for $N\\to\\infty$. Since the map $T$ is not assumed to leave the target invariant, the proposed algorithm is called non-equilibrium orbit importance sampling (NEO-IS).   The authors propose to use conformal Hamiltonian dynamics as a mapping (standard Hamilton dynamics based on the negative log target plus a friction term). The dissipative friction term allows the authors to control how exhaustively phase space is explored.  The second main contribution is an MCMC algorithm based on the ideas used in NEO-IS. NEO-MCMC applies iterative Sampling Importance Resampling (SIR) within the NEO-IS framework. NEO-MCMC jumps from one point on an orbit to a point on another orbit. Orbits are sampled according to their importance weight.  The algorithms are benchmarked on various targets (25 Gaussian mixture, Funnel) and applied to training a VAE.  ",
    "The paper puts forward a new family of algorithms, NEO, for computing normalizing constants and sampling from complex distributions. NEO-IS is an importance sampling estimator of the normalizing constant. NEO-MCMC combines NEO-IS unbiased estimator of the normalizing constant with iterated sampling- importance resampling methods.",
    "The paper introduce two sampling approaches named NEO-IS and NEO-MCMC respectively. The former method aims to estimate normalizing constant for an unnormalized target distribution, and the latter method can be executed to do sampling from unnormalized distribution. Empirical experiments reveal impressive performance for both the approaches on Normalizing Constant Estimation and Sampling tasks.  Exact theoretical analysis, especially convergence guarantees are also given in this paper. ",
    "This paper proposes NEO which extends Non-Equilibrium Importance Sampling (NEIS) to use discrete orbit and extra weights. The probability distribution and sampling process is derived based on the Jacobian determinant. This method could be applied to estimate the partition function and a biased estimation called self-normalized IS is proposed based on estimated partition function. This paper also derive upper bound for the bias and MSE. A damped Hamiltonian system is adopted to equip the original system with extra momentum and provide orbit trajectory for NEO. NEO is also combined to Sampling Importance Resampling to derive the NEO-MCMC procedure. The authors present reasonable experiments to evaluate their methods.",
    "This paper studies the problem of set encoding in the setting where the cardinality of the set is prohibitively large or unbounded. For example, this is the case when dealing with streaming data. A property called Mini-Batch Consistency (MBC) is defined, and it is argued that set encoding algorithms must have the MBC property to learn useful representations of the entire set when partitions of the set are being processed incrementally. A slot-based algorithm that is MBC is proposed. It models interactions between the inputs and slots to learn strong representations. The algorithm, called the Slot Set Encoder (SSE), is compared against Deep Sets and the Set Transformer on a variety of relevant tasks. ",
    "The authors proposes the use of attention based set encoder which can scale to arbitrary set sizes. Attention in Transformers has the quadratic dependence on number of positions (i.e. cardinality of the set). The proposed method makes the problem easier by enabling the use of slots while preserving a property which method defines as mini-batch consistency. The proposed method is invariant to the order of the subsets, and invariant to permutations on the set elements.  ",
    "The paper addresses the problem of set encoding when the set is too large to fit in the memory, or given as a stream of data. The proposed method randomly partitions the set,  encodes each random subset and then aggregates all the encodings. The key contribution of the proposed method is that the aggregation of the encodings is required to be equal to the encoding of the full set and it satisfies permutation invariance and equivariance. This property is formally defined and named as Mini-Batch Consistent Set Encoding in the paper. Compared to DeepSets, which also satisfy Mini-Batch Consistent Set Encoding, the proposed method can model pairwise interactions, while DeepSets lack this property. The encoding is implemented using previously introduced slot attention [8] (the attention is done over \u201cslots\u201d instead of self-attention) with the two differences: softmax is replaced with sigmoid in constructing the attention matrix and GRU update of slots is omitted here. The experiments compare the proposed method with two previous methods for set encoding in three tasks showing some improvement.",
    "This paper addresses the problem of set encoding when the dimensionality and/or cardinality of the set it too large to fit into memory to feed into an encoder or when set elements arrive in a stream. This paper defines a property, mini-batch consistency, for set encoding functions that encode the set in non-overlapping subsets (mini-batches) then aggregate the mini-batch encodings to achieve the set encoding. If obeying mini-batch consistency, the encoder achieves the same set encoding as if the encoding function was applied directly to the entire set. Finally, the paper proposes an encoding function, Slot Set Encoder, to satisfy mini-batch consistency.",
    "This paper introduces a new concept called \u201cmini-batch consistency\u201d (MBC), which is presented as necessary for efficiently training large-scale set encoding models using mini-batch processing of sets.  MBC is appropriate when the cardinality of the sets in the data is very high, and thus all set elements cannot be loaded into memory, or when the data arrives in a stream.  MBC adheres to the required properties of invariance and equivariance for set encoding models.  A MBC-based set encoding mechanism is also proposed, called the slot set encoder.  Extensive experimental results are provided, which demonstrate that the proposed method is scalable and generally outperforms competing approaches.",
    "This paper builds off of Gray et. al. by swapping out the blueprint that is trained on human data with one that is trained from scratch using a deep learning variant of Nash-Q learning. The new method is able to achieve what appears to be superhuman performance in 1v1 Diplomacy and also does well but with mixed results in 6v1 Diplomacy against existing methods. ",
    "The paper proposes learning methods for the No-Press variant of the board game Diplomacy.   The method uses an equilibrium search method (similar to [9]) to solve for Nash in a single turn of the game, estimating future returns with a value function one turn in the future. Then a policy is trained to predict the equilibrium found, while the value function is trained to predict the values of the Nash equilibrium, which implements value iteration.  The equilibrium search method is based on prior work [9]. This tackles the large action space by restricting search to only the most likely actions from a policy network. This is extended in this work by using Double Oracle to expand the action set, and using a Diplomacy-specific method to generate proposal actions, which exploits the graph structure of the game. The paper also introduces a transformer-based model for learning to play Diplomacy, which outperforms previous Graph-Network approaches, and advances methods to estimate the exploitability of a Diplomacy agent.  Experimental results show that this results in an agent that can defeat human opponents convincingly in a 2-player variant of Diplomacy. ",
    "Diplomacy is a complex 7-player strategy game that poses a challenge for RL due to its simultaneous moves and combinatorially large action space. In recent years significant progress has been made on learning human-level play by starting from imitation learning on a dataset of human play from websites, and then using some policy improvement algorithms. This paper tackles the exploration problem, introducing a policy improvement algorithm that reaches competitive-quality play without requiring a dataset, using Nash Q-learning, a double oracle-like method, regret matching, and geographically local perturbations for action proposals. They also find advantage from switching to a transformer-based architecture.  Their method (DORA) exhibits strong results in 1v1 human play, as well as being the first from-scratch agent able to play on par with DipNet (an imitation baseline) in a 1v6 setting, in a metagame that DORA wasn\u2019t trained in.  Separately, their policy improvement method on top of an imitation network beats previous SOTA (SearchBot).",
    "This paper describes an algorithm that trains agents through self-play with no human data and no reward shaping, and can accommodate the large action space of Diplomacy. It is an algorithm for action exploration and equilibrium approximation in games with combinatorial action spaces. This algorithm simultaneously performs value iteration reinforcement learning while learning a policy proposal network. Meanwhile, a double oracle step is used to explore additional actions to add to the policy proposals. They train an agent completely from scratch for a 2-player variant of Diplomacy and show that it achieves superhuman performance. They also train an agent for the 7-player no-press Diplomacy entirely from scratch with no human data for the first time and show that this agent differs radically from past agents that required human data. This approach therefore opens up the ability to investigate novel ways of playing the game. ",
    "The paper proposes an approach called DORA for building agents for the Diplomacy board game, which is a long standing AI challenge. The key achievement in the paper is constructing agents in a way that does not rely on imitating human gameplay (as opposed to some recent works which at least in part leverages historical game data). Diplomacy is hard because it has a large action space and as it is a game with many players (7 in the full game, but only two int eh France/Austria variant). The results are very good for the two player (France/Austria) variant against people. The results are more mixed in the 7 player game - when there are many copies of DORA, it does very well, but less well when there are many copies of another bot and one DORA player. ",
    "This work proposes an approach to learn to share attention heads in multitask (multilingual, multi-domain) transformer models with multi-head attention layers. Given a multi-head attention layer with $H'$ heads being trained on a set of tasks, each task learns to use $H$ heads, and the choice of attention heads is dictated by learnt latent variables. 2 strategies are proposed for this attention head selection: 1. Subset selection, selects top-$H$ heads for each task. 2. Group selection, where $H'$ heads are divided into groups of $H'/H$ heads, and 1 head is selected per task from each group.  This approach is compared against baseline approaches with full parameter sharing (transformers for MT, speech-transformer for other tasks) and baselines enhanced with adapter modules [1] on multilingual Machine Translation, multilingual ASR, multi-domain ASR, multilingual speech translation and multi-domain speech translation. On all these tasks the proposed head-sharing approach shows modest improvements over the fully-shared baselines.  References: [1] Simple scalable adaptation for neural machine translation, Bapna et al.",
    "This paper address the problem of negative interference which happens when a single transformer model is shared among the different tasks in a multi-task learning setup specifically those of multilingual translation, speech recognition, and multi-domain speech translation.  The proposed approach is to adaptively make use of specific attention heads for a particular task among a pool of attention heads. In this way, the common attention heads between tasks can reinforce the positive transfer while the attention heads unique to each task will avoid the negative transfer. Extensive experiments on multiple tasks of multilingual translation and speech translation demonstrate improvements in performance over strong baselines.",
    "The paper proposes a transformer architecture for multi-task learning, based on sharing some attention heads in multi-head attention between different tasks. The model is supplied with more heads than necessary and a neural module using gumbel-softmax is used to select a subset of these heads for each task.  A variant of this is described, where heads are distributed between groups and exactly one head is selected from each group.",
    "Multi-head attention is an essential component for popular Transformer models. This paper proposes to learn shared and specialized attention heads for different languages and domains. The authors formulate attention selection as latent variables and adopt Gumbel softmax to select attention heads.  Experiments on text-to-text and speech-to-text translation verify the effectiveness of the proposed approach. ",
    "This paper aims to mitigate the problem of negative interference when learning models across different languages and domains. In particular, it proposes an approach that learns to share or specialize attention heads based on two different strategies, namely subset, and group selection.  The evaluation of multi-lingual/domain settings shows that this approach outperforms standard transformers and adapters without increasing the number of parameters. ",
    "The paper studies the test error, as well as the bias and variance, of random feature regression in the asymptotic regime, in a setting with covariate shift \u2014 i.e., when the covariance matrix of the features is different at testing time than at training time. The paper defines a partial ordering over covariance shifts, and it proves that this corresponds to increased or decreased performance compared to the case of no shift. It also obtains a few results that relate these notions to overparameterization.",
    "This paper presents a theoretical study of covariate shift under the setting of kernel ridge regression in the asymptotic regime. They charaterize the limiting test error, bias, and variance in this setting. They relates these with a quantity named hardness. They claim that their findings agree with several interesting empirical phenomena. ",
    "This paper studies random feature regression in high dimensional setting with the presence of covariate shift between train and test data. The authors compute the high-dimensional asymptotic limit of the test error for Gaussian covariates with a shift in the covariance matrix. They also provide results characterizing the bias and variance decomposition.",
    "The authors study covariate shift in over-parameterized random features models.  They provide an analysis of the test error, as well as an analysis of the decomposition of the test error into the bias and variance components.  This results in a partial ordering over test errors WRT the \"hardness\" of the covariate shift.  Further, the theoretical results provide a concrete explanation of the linear trend that has been observed in past work between the test error on clean and corrupted error.  ",
    "This work provides theoretical insight for why overparameterized models perform well when there is some covariate shift between the training and test sets. The authors' characterize their results by introducing a notion of \"relative hardness\". They present empirical evidence to match their intuition, and corroborate the main results in the paper using several empirical benchmarks.",
    "This paper focus on the performance of the Thompson sampling algorithm under the misspecification of the prior distribution. The authors propose a general family of n-Monte Carlo algorithm, which contains the canonical TS algorithm as a special case. The authors then proceed to show that the regret difference of a misspecified prior up to horizon H of an n-MC algorithm is of order H^2*eps, where eps is the amount of misspecification measured by the total variation distance. The results are applied to the meta-learning setting, in which one also aims to learn the prior. The paper concludes by a synthetic numerical experiment to show the benefit of meta-learning.",
    "The paper establishes the theory for quantifying the sensitivity of a class of Bayesian bandit algorithms under misspecified prior, with Thompson sampling being a special case. It is also shown that the sensitivity bound is tight in the worst-case sense. Using the sensitivity analysis, the paper studies the sample complexity of Bayesian meta-learning in two special cases (Beta prior+Bernoulli reward and Gaussian prior+Gaussian reward). Finally, the aforementioned theory is generalized to the more general setting, the Bayesian POMDPs.  ",
    "In this paper, the authors study how prior mis-specification would impact the performance of bayesian bandit algorithms. In particular, the authors provide an upper and a lower bound for a wide class of algorithms, which include Thompson sampling algorithms as a special case. The results are complemented by applications in meta learning and numerical experiments.",
    "This paper studies the effect of prior misspecification in Thompson sampling (TS) and related posterior sampling bandit algorithms. They are able to show that the regret due to such algorithms using a misspecified prior incurs additional regret that is linear in the total variation distance between the improper and true prior.  Additionally, the paper considers estimating such priors in a meta-learning setting, where an agent interacts sequentially with multiple bandit instances whose model parameters are sampled from the same unknown prior. The authors provide bounds on the total variation distance for the estimated priors when the prior is Beta or Gaussian. ",
    "This article presents some very nice results on posterior-sampling-based bandit algorithms with mis-specified priors. The algorithms are those like Thompson sampling, in which the actions selected are functions of draws from the posterior distribution to date (an approximation of knowledge gradient is also analysed as part of a wider class of posterior-sample-based decision algorithms, and this is shown to be an improvement on TS). Results apply both to standard bandit settings and to meta-learning settings in which a series of short episodes are attempted. Theory and experiments are impressive.",
    "The paper studies the problem of approximately learning a target function (in the realizable case) when having access to an equivalence-query oracle. In this direction an exponential separation is shown between the two learning models by using an algorithm that borrows ideas from boosting techniques. Furthermore, the authors connect the counterexamples returned from the equivalence query oracle to adversarial examples and thus try to connect their work with adversarially robust learning. ",
    "This work studies the query complexity of learning general hypothesis classes $(X,H)$ in the randomized equivalence query model (w/ PAC guarantees). In this interactive model, the learner has access to the \u201cEQ oracle\u201d which upon input of a hypothesis in H, outputs a random counterexample (based upon the target concept and marginal distribution chosen originally by the adversary). The authors use a boosting procedure to show that learning in the randomized EQ model requires only $d*\\text{polylog}(1/\\varepsilon)$ queries where $d$ is the VC-dimension of $(X,H)$. This provides an exponential separation with the PAC model, which takes $\\Omega(d/\\varepsilon)$ queries to achieve the same guarantees.  The authors motivate this theoretical result by tying it to recent research in adversarial robustness. They argue that the EQ model can be seen as adversarial training against a restricted adversary. They claim that their results give a theoretical explanation of recent experimental work showing that (on-manifold) adversarial training achieves good generalization, and argue that the exponential separation could be used as a potential tool to prove robustness against such adversaries. ",
    "The paper studies the query complexity of learning a VC class under a certain query model called the Equivalence-Query (EQ) model by Angluin'98. In this model, given a distribution $\\mathcal{D}$ and the ground truth $g$, the learner interacts with the data in the following way: (1) learner selects a function f and (2) learner receives a random counter-example distributed according to $\\mathcal{D}$, that is, a random draw from $\\mathcal{D}|_{f \\ne g}$. Under this model, the authors prove an exponentially improved upper bound of $d \\cdot \\mathsf{polylog}(1/\\epsilon)$ compared to the $d/\\epsilon$ bound for PAC learning. The paper further draws connections between this model of learning and adversarial robustness. The main argument here relies on viewing the equivalence-query sample oracle as the adversary restricted to on-manifold attacks.",
    "The main result of the paper is showing a separation between the sample complexity of PAC model and the query complexity of an interactive model called Equivalence-Query-learning. The interactive model requires exponentially fewer queries/samples (in the mistake parameter - epsilon). Further, the implication of this result on the adversarial robustness is discussed. ",
    "This paper introduces a new abstract learning model called the EQ-learning, in which the oracle returns examples that the current classifier gets incorrect (rather than arbitrary examples drawn from the data distribution) and returns YES if no such examples exist (indicating the current classifier is correct). They then provide an algorithm which achieves a sample complexity (assuming finite VC dimension d)that is polylog in $1/\\epsilon$ as opposed to $O(1/\\epsilon)$. This is an exponential increase, and is a very interesting theoretical result on its own.  They then argue how their formalism plays a role in learning from on-manifold adversarial examples. In particular, each of these examples reveals a point that the classifier gets incorrect, and their result consequently suggests that learning from these results should improve the training procedure. ",
    "The paper studies methods to select source models from a diverse set, considering both the quality of the proxy for downstream performance, and the speed of computing the proxy. The paper introduces a new benchmark for evaluating the ability to choose from diverse source models, studies a number of existing methods, and highlights some shortcomings. It then proposes some tweaks to improve these. Finally, the paper proposes a new proxy PARC, which performs well on their benchmark (also using the aforementioned tricks), and also on an extended evaluation on crowd-sourced models.",
    "This paper introduced a unified benchmark to test the performance of existing transferability estimation algorithms. The main contribution is firstly its unified benchmark, and then, its experiment models and datasets are large, which show a fair comparison for all methods. Finally, they modified an existing algorithm to propose a new one, which achieves better Person correlation score over others.",
    "The paper studies model selection for transfer learning: given a number of source or upstream models, and a new downstream or target data, how can we choose the best model to finetune? The paper offers two main contributions. First, it proposes a specific benchmark with source models, target tasks, and an evaluation metric to compare different approaches. Second, after testing on a number of methods from the recent literature, it identifies some algorithmic aspects that seem to hurt these methods and proposes an alternative approach called Pairwise Annotation Representation Comparison (PARC) which addresses those. Experiments suggest PARC outperforms the original algorithms.",
    "The authors introduce the \u201cscalable diverse model selection\u201d task and introduce several tools and benchmarks for evaluating model selection methods in this setting. They show that current transferability and model selection methods fail to beat simple baselines in this new setting. They analyze the reason for this case and provide techniques to improve performance. They develop PARC, a method that outperforms other methods on diverse model selection.",
    "The paper proposes a model selection method wherein best experts are selected from a model zoo to fine-tune on the target task. The proposed method \"Pairwise Annotation Representation Comparison\" is an improvement over RSA [8], instead of using a small dnn trained on target task (or probe network) the authors use spearman correlation between RDM of features and label as model selection score (called PARC score). The proposed method is compared to many baselines NCE, LEEP, RSA, DDS etc. and shows better correlation to fine-tuning accuracy.",
    "This paper gives a new empirical approach for learning schemes for compressing high-dimensional neural representations into binary codes over a small number of dimensions. Given labeled examples and a fixed neural architecture with d-dimensional output, they give a two-phase algorithm for learning weights for the network, a low-dimensional projector to a k-dimensional subspace of R^d, and a binary \"codebook\" matrix B(C) mapping the k-dimensional subspace to R^L, where L is the number of classes. The goal is to do this for k as close to log_2(L) as possible while mostly preserving test accuracy.  Concretely, the embedding g maps any input x to the Boolean vector given by the entrywise sign of the k-dimensional projection of the network's output under x, and B(C) maps any such g(x) to an L-dimensional vector corresponding to the scores of the different classes. In the first phase of the algorithm, they simply run ERM to simultaneously find some weights, projector, and codebook, using a standard heuristic to get around the fact that B(C) is discrete-valued. In the second phase, they train the weights and projector further by essentially encouraging the embedding to align with the codebook.   The distinguishing feature of this approach is that the codebook and embedding are learning in conjunction rather than separately. Empirically over ImageNet-1K, they found that under two natural decoding schemes, the resulting classifiers beat a number of baseline approaches that separately constructed a codebook and then learned an embedding. Additionally, the accuracy is only ~3% less than the standard ResNet50 baseline.  As other applications, they showed that for image retrieval, the learnt embedding can be used as a hash function, outperforming HashNet and GreedyHash. They also gave an application to out-of-distribution detection which is comparable to certain baselines but notably does not need samples from the out-of-distribution domain.",
    "This work proposes a two-phase method for learning low-dimensional binary codes via the standard classification task without side-information. Specifically, binary codes for classes are learned via a surrogate classification task in the first phase. On top of that, instance codes are learned using the Error-Correcting Output Codes approach.",
    "This paper studies the problem of learning binary vector representations of instances and classes. We pick a small dimension k (the paper uses k=20) and aim to learn a k-dimensional binary vector for each input and each label. Compressing the data into small-dimensional binary codes like this is challenging, but provides many benefits in terms of the space usage (the representations are very small) and the time to do lookups and find nearby neighbors.  The paper presents a new method called LLC which simultaneously finds codewords for both inputs and labels without using any side-information. They claim (and I have no reason to doubt this) that this is the first time a method for this has been designed. LLC consists of two phases:  In the first phase, the LLC method learns a codebook (low-dimensional bianry code for each label) by using the popular Straight-Through Estimator technique to do empirical risk minimization.   In the second phase, the ECOC framework is used to classify the inputs according to this codebook. The algorithm treats each of the k bits of the code completely separately, and hence solves k disjoint binary classification problems instead of one multi-class (with L or 2^k classes) problem. This gives an additive 2% improvement to accuracy over just solving the optimization problem to classify all k bits together, since out of the box optimization finds fairly suboptimal solutions when trying to classify a length k vector all at once. (In other words, the second phase uses a heuristic where sepaartely learning each of the k bits works better than learning all k at once for the current optimization software which is well-suited to doing binary classification.)  The resulting classification accuracy seems quite good: 68.82% of inputs are assigned exactly the same binary code as their label, and 74.57% are assigned a binary code which is closer to the code of their label than any other label.  The result of this binary code classification can now be used in a number of applications, including: - the binary codebook can be naturally used to make a taxonomy visualization for the labels.  - the system can be used for efficient (in terms of representation size and running time of retrieval) multi-class classification. - out-of-distribution detection can be done by seeing whether an input is mapped to the same codeword as any label. (I'm confused about how effective this can be when the original inputs are only correctly mapped to the codeword of their label 69% of the time.)",
    "Low-dimensional binary codes are important for a variety of large-scale ml tasks, especially retrieval. This paper proposed a method called LLC for learning semantially meaningful low-dimensional biary codes. Compare to the existing literature, LLC can learn both class and instance codes together without side-information:  (1) couple the learning process of both feature and class embedding and capture the sematic structure better (2) naturally benefits downstream tasks like OOD.    ",
    "This work propose a method for learning low-dimensional binary codes for instance and classes. It is appealing in classification with large scale number of classes. The method is claimed super-efficient in learning and able to ensure nearly optimal classification accuracy. The learnt class code discovers some intuitive taxonomy over subset of classes selected from ImageNet. The method is applicable in image retrieval and out-of-distribution detection.",
    "1. The paper proposes GDWS with an error optimization strategy to replace regular convolution for enhancing both throughput (FPS) and adversarila robustness. 2. Experimental results on CIFAR-10, SVHN, and ImageNet validate that the replacing a CNN's regular conv with GDWS can achieve significantly higher FPS and preserve adversarial robustness.",
    "The paper proposes a post-training transformation of a pre-trained 2D convolutional layer into a general depth-wise separable convolution operation. The optimization primarily focuses on minimizing error and limiting computation complexity. The paper claims to achieve a higher robustness (i.e., defend adversarial input attack) and higher frame per second than existing methods.",
    "This paper proposed a method named  Generalized Depthwise-Separable (GDWS) to improve the throughput on real-life hardware while simultaneously preserving robustness. The advantage of GDWS is that does not need any additional training.  This paper has demonstrated the effectiveness of GDWS via extensive experiments on CIFAR-10, SVHN, and ImageNet datasets.  ",
    "The paper proposes a generalization of depthwise-separable convolutions (called GDWS) where each channel can have multiple depthwise filters (instead of just one) that are subsequently combined using a pointwise convolution. Two algorithms are proposed to minimize the error/complexity of mapping general convolutions to GDWS as a post-processing step after training. Results show small degradation on natural and robust accuracy while increasing the FPS substantially.",
    "The authors propose Generalized Depthwise-Separable (GDWS) convolutions for processing images for the purpose of getting high throughput in efficiency and robustness. This is carried out by introducing channel distribution vectors in the standard 2D CNNs. The efficiency is managed by means of the singular value decomposition of the matrix in the convolutional operations after vectorizations. Experiments show that the method provides similar results for some benchmark data. ",
    " This paper presents GraphRetro, a single-step retrosynthesis model that represents an advance from last years' NeurIPS state of the art model on semi-template-based modeling of the USPTO-50k dataset. GraphRetro uses a graph neural network that predicts edits to transform a target into synthons and then expands the synthons into full molecules by attaching leaving groups (with the synthons and leaving groups learned from the training set). The authors compare the predictions on the USPTO-50k to existing baselines, and show examples of predictions, including wrong ones. Because of the particular construction of the model, the authors can decompose the sources of errors as wrong edit predictions or wrong synthon completions. ",
    "## Summary.  The authors propose a new method for single-step retrosynthesis prediction. Their method first predicts graph edits using a message passing network yielding synthons which are then completed by adding leaving groups. The leaving groups are chosen from a fixed set using another MPN. ",
    "This paper deals with molecular graph generation via synthon, incomplete molecular graphs.  Unlike existing works, this paper formulates the completion of incomplete molecular graphs not as a generation problem but as a classification problem to select one of a set of pre-computed leaving groups fragments. The training and evaluation are performed using the standard dataset USPTO-50k. The proposed model has high retrosynthesis performance, covering a large number of responses with a small set of leaving groups.",
    "This paper proposes a new retrosynthetic prediction model using neural networks. The algorithm proposed to make the prediction based on breaking the target product into synthons and adding leaving groups to the synthons. The main difference of the proposed algorithm to the existing synthon-based retrosynthetic model is on introducing the vocabulary of leaving groups to complete the synthons in an efficient way.  Extensive evaluation verifies that the proposed method is competitive with the existing algorithms, and each algorithmic component plays a meaningful role.",
    "This paper proposes a new strategy for reactants generation for the retrosynthesis prediction. Motivated by the fact that the graph topology of precursor molecules is largely unchanged during the chemical reaction, the authors propose to expand intermediate synthons into reactants by selecting and attaching leaving groups (molecule sub-graphs extracted from training data) to the synthons. The product molecule is transformed into synthons through graph edits. The proposed method achieves 53.7% top-1 accuracy.",
    "The authors consider the problem of refining low-res (LR) spatial observations using high-res (HR) covariates.   Basically, the problem is as follows. The analyst observes LR outcome Z, HR covariate X, and LR covariate Y from the process Z=E[f(X)|Y]+e. The analyst wishes to recover the function f.  In more detail: the analyst observes two datasets: D1 and D2. D1 consists of N observations (x_j, y_j) where x_j may be a bag.  D2 consists of M observations (y_j, z_j). The function f is modelled as a function in an RKHS (with Bayesian or frequentist approach).  The authors characterize the Bayesian version of this problem and derive the GP posterior. The authors characterize the frequentist version of this problem and prove minimax optimal finite sample rates. ",
    "This paper extends on the work of deconditional mean embeddings (DMEs) and task transformed Gaussian processes (TTGPs) from Hsu and Ramos (2019) from both an application and theoretical stand point.  From a theoretical stand point, the authors developed the framework around deconditional mean embeddings further by three ways: (1) formulating another elegant way to arrive at deconditional posteriors from Hsu and Ramos (2019), (2) establishing deconditional mean operators (DMOs) as vector-valued regressors in a manner that mirrors Grunewalder et al (2012) which highlights its interpretation as a reconstruction operator, and (3) enhancing guarantees on the convergence rate of deconditional mean operators from what was established in Hsu and Ramos (2019) using the setup and results from  Caponnetto and De Vito (2007), Szab\u00f3 et al (2016), and Singh et al (2019).  From an application stand point, the authors apply DMEs for refining low resolution spatial fields with high resolution information. This is the special case of DMEs and TTGPs where the task dataset consists of collections of low resolution covariates ($\\tilde{y}$) and aggregated targets ($\\tilde{z}$), and the transformation dataset consists of collections of (another potentially unmatched set of) low resolution covariates ($y$) each matched with bags of high resolution covariates ($^{b}\\bf{x}$). The latter constructions regarding the transformation dataset is what makes this a non-trivial special case due to having bagged high resolution covariates, which allows for a slightly different empirical estimator for the cross-covariance operator. This leads to an alternative conditional mean operator (CMO) which they call the conditional mean shrinkage operator. Finally, the authors then apply their work to toy experiments (swiss roll) and downscaling of atmospheric temperature (CMIP6), where to scale it they also derive a variational formulation to approximate the deconditional posterior. ",
    "The paper considers the problem of learning a function  $$f:\\mathcal{X}\\to \\mathbb{R}$$ from the relationship  $$g(y) = \\int_x f(x) \\mathbb{P}[x|y]dx$$ where the training data consists of two datasets. The first set is  $\\mathcal{D}_1 = ( x^b_i, y_i )$ where each $x^b_i$ is a bag of points in $\\mathcal{X}$ and $y_i$ is a single point in a space $\\mathcal{Y}$, these are empirical samples from some distribution $\\mathbb{P}[x|y]\\mathbb{P}[y]$. The second dataset is of $\\mathcal{D}_2 = (\\tilde y_j, \\tilde z_i)$ with $\\tilde y_j \\in \\mathcal{Y}$ and $\\tilde z_i \\in \\mathbb{R}$ is a set of input-output pairs to from $\\tilde z_i = g(\\tilde y_i)$.  Learning models for $f(x)$ from aggregate data, (input bag, output) pairs e.g. $( x^b_i, z_i )$ has been studied, similarly the use of  there are intermediate covariates $y_i \\in \\mathcal{Y}$ with a dataset of the form $( x^b_i, y_i, z_i )$ has been studied. As I undertsand, the novel constributino of this work is the extension to the case where there are two datasets, $( x^b_i, y_i)$ and $(\\tilde y_j, \\tilde z_j )$ that both contain points from the domain $\\mathcal{Y}$ yet they are not the same points, they are mismatched.  The paper proposes a \"conditional mean process\", a Gaussian process model that interpolates aggregated data as well as the marginalization operater in order to infer the un-aggregated latent function under this above problem setting.   ",
    "This paper presents a GP model for refining coarse-grained spatial data, which can be used for handling aggregated data that are unmatched spatially and temporally. The authors also develop the two-stage regression algorithm for downscaling. The effectiveness of the proposed model is demonstrated using synthetic and real-world datasets.",
    "The paper proposes a novel Gaussian process approach for settings in which we have two datasets, D_1={(x_i, y_i)}_i=1 ^N and D_2=((y_i,z_i))_i=1^M  that are linked by the mediating variable Y. The datasets are not matched, and we want to learn a function from X to Z. In contrast to existing work, the algorithm generalizes to settings in which the resolution of the two datasets differ.",
    "The authors consider the problem of designing accurate and computationally efficient deep sparse networks (DSNs), which are an important problem in applications with sparse features such as click-through rate or movie recommendation. The authors propose a new approach based on neural architecture search (NAS) using two techniques: distillation of the search space (of cross-features), and a progressive search algorithm. They show that their approach leads to improvements in both accuracy and inference time, on three datasets.",
    "This paper targets applying NAS to Deep Sparse Network (DSN) domain. To search for a good DSN, previous methods that apply DARTS based method to search an encoding vector, where each element represents the probability to select feature-interaction. Due to the interaction grows in a factorial way, the search parameters will soon become intractable. This work proposes to decompose this vector into multiple low-rank ones, to reduce the search space dramatically.  Experiments on various datasets show a clear improvement comparing to the previous baseline AutoFIS. I would recommend accepting this one but since I am not really familiar with the DSN domain, I might change my mind based on other reviews.",
    "This paper proposes a method for searching for the interaction of the feature columns in a CTR prediction application. The paper title suggests an application for deep sparse networks but it doesn\u2019t seem to be explicitly tied with the requirement of the input being sparse. To this end, the paper proposes an iterative algorithm that incrementally learns the interaction tensor from lower rank to higher rank, and from lower order to higher order. Empirically it observes some benefits compared to current competitive methods on Criteo, Avazu and ML1M datasets.",
    "This paper proposes a neural architecture search approach, PROFIT,  for deep sparse networks.  PROFIT introduces a distilled low-rank search space and a progressive search algorithm from the lower orders. The proposed method is evaluated on three benchmark datasets and the authors conduct extensive ablation study and discussion on the method. The paper is well written and very easy to follow even for people without a NAS background.   ",
    "In this paper, the authors study the problem of deep sparse prediction based on NAS. In order to reduce the search cost, they propose a distilled search space, which is a low-rank approximation of the full space. They also propose a progressive differentiable search to capture the order-priority in sparse prediction. Numerous experiments are conducted to demonstrate the effectiveness of the proposed method. ",
    "This paper studies the generalization and robustness of regularized fine-tuning. They present a PAC-Bayes generalization bound that depends on the distance traveled in each layer during fine-tuning and the noise stability of the pre-trained model. They empirically measure these quantities to analyze the behavior of fine-tuning. They present an algorithm that interpolates between two components: (i) regularization over the amount of distance traveled in each layer; (ii) iteratively correcting mislabeled data points that the model is highly confident and down-weighting less confident data points. ",
    "This paper includes a PAC-Bayesian analysis of distance-based regularisation during fine-tuning. Using this analysis and supplementary experiments, the authors propose a new means for tuning hyperparameters for distance-based regularisation with constraints and heuristics for dealing with label noise during fine-tuning. The experiments show that the method works slightly better than previous approaches designed for both fine-tuning and training with label noise.",
    "The paper proposes a new regularization method for training and fine-tuning large neural networks. The paper proposes to constrain the maximum change in network parameters during fine-tuning. This constraint is different in each layer. Experiments demonstrate that the proposed method outperforms previous approaches.",
    "The paper analyses the fine-tuning of neural networks. It provides a PAC-Bayes bound for the generalization of a fine-tuned network. The paper then provides three tricks to improve finetuning: layerwise regularization, label correction, and label removal. The resulting fine-tuning algorithm improves performance on various image classification tasks, including those with artificially-added label noise.",
    "This paper studies the aspects of fine-tuning a model (pre-trained on a separate dataset) in order to learn a new task. It has the following contribution:  (i) Generalization properties of fine-tuning explained by the PAC-Bayes generalization bound that depends on two terms: (a) distance between each layer from the pre-trained model and (b) noise stability of the pre-trained model.  (ii) Inspired by the generalization analysis, the paper presents an algorithm to perform fine-tuning. This algorithm includes (a) regularization term that computes the distance between the current parameters and the pre-trained model, and (b) iteratively corrects mislabeled examples where model has high confidence and down-weighting less confident examples.  (iii) Proposed algorithm is evaluated on a suite of benchmark tasks including transfer learning and few shot classification tasks.  ",
    "The paper studies the problem of identifying the arm with smallesst CVaR and VaR. The lower bound for the specific structured best-arm identification problem is studied. The paper also proposed an algorithm that achieves asymptotic optimality in sample size. ",
    "The paper studies the problem of identifying the arm with the minimum CVaR, VaR, or a conic combination of the mean and CVaR. It provides an \\delta-correct algorithm that operates on possibly heavy-tailed arm distributions and matches the asymptotic lower bound on the expected number of samples needed as delta approaches 0. The paper also provides a result of separate interests, i.e., an anytime-valid confidence interval for CVaR estimation, which is tighter than truncation-based intervals (under certain conditions). Finally, the empirical studies show that the asymptotic sample complexity result of the proposed algorithm is indicative of its performance in practice. ",
    "The authors study the problem of multi armed bandits with the goal of identifying the arm with smallest (i) CVaR (ii) VaR or (iii) conic combination of CVaR and mean. This problem has applications in finance and clinical trials and captures a notion of risk sensitivity towards undesirable outcomes. The authors show that in the parametric case where the arm reward distributions follow a canonical SPEF, the problem reduces to best arm identification.  The authors study the VaR problem without any assumptions on the distributions, and study the CVaR problem assuming that distributions satisfy bounded $(1+\\epsilon)$ moments. The proposed algorithm projects the empirical distribution to the considered family of distributions and considers an exploratory transform that guides the arm sampling distribution. At each time the empirical reward distribution suggests an arm with empirical minimum CVaR - this is the null hypothesis which is tested against all alternatives using GLRT. The algorithm upon satisfying the termination condition outputs the arms with the empirical minimum CVaR.  The authors show that the proposed algorithm asymptotically achieves the optimal sample complexity as the error threshold $\\delta \\to 0$. The results are supported by numerical simulations demonstrating good performance on instances with Bernoulli arms. The performance of the algorithm hinges on the asymptotic convergence of the track-and-stop exploration protocol which is often fast even when the error parameter delta is moderate.",
    "This paper addresses the multi-armed bandit best arm identification problem which aims to identify the arm with the minimum tail risk measured by VaR, CVaR, or a weighted sum of CVaR and the mean. It proposes an optimal $\\delta$-correct algorithm that works with a mild restriction on the arm distributions for CVaR and works with any arm distributions for VaR. In particular, the paper develops a lower bound for the problem and shows that the proposed optimal $\\delta$-correct algorithm has the sample complexity that matches the lower bound asymptotically (as $\\delta \\rightarrow 0$). Additionally, the paper also suggests a solution to control the trade-off between the time computational complexity and the sample complexity, which is useful in practical applications.",
    "The paper considers best CVaR arm identification in a fixed confidence setting. They can also deal with conic combinations of mean and CVaR, as well as VaR based criteria.  Main contributions include a lower bound which involves optimization over reals, and an algorithm which is asymptotically optimal in terms of expected sample complexity.",
    "The paper propose to inject inductive bias (IB) for vision tasks to boost the performance of vision transformers (ViT). The main contributions of the paper are two-fold: a reduction cell that aggregate the features from different scales by controlling the dilation of a  few of parallel convolution branches and a parallel convolution branch with the multi-head self-attention (MHSA) block. The results on ImageNet is promising compared with the selected baselines but I found it is hard to get a conclusive result on downstream classification tasks. ",
    "This paper proposed two types of basic cells to modify the vanilla vision transformer structure: reduction cell (RC) and normal cell (NC). RCs are used to down-sample and embed the input images into tokens and NCs are to jointly model locality and global dependencies in the token sequence. Specifically, they used paralleled attention module and convolutional layers followed by a feed-forward network (FFN) to construct these two cells. Experiments on ImageNet and downstream tasks verified the superiority of the proposed network design.",
    "The standard vision transformer model lacks the capability to model inductive biases desirable for images e.g., local features encoding, and scale invariance. It, therefore, requires large-scale training data (300 million images), or other variants (e.g., Data Efficient ViT) distilling Knowledge from a pertained CNN. The paper proposes an architecture, which tries to take care of these inductive biases. The architecture comprises of 3 \u201cReduction cells\u201d at the beginning followed by multiple \u201cNormal Cells\u201d. A reduction cell gets a pyramid effect using dilated convolutions at the beginning which gradually downsamples features. The normal cell doesn\u2019t have any dilated convolutions. Each block has Convolution and attention running in parallel.  The assumption here is that convolution captures local relationships, pyramid structure (via diluted convolutions) captures scale invariance, and attention captures global relationships. ",
    "A new vision transformer architecture VITAE, with a better use of intrinsic inductive bias IB via a new architecture using convolutional dillated layers. Both scale and locality IB are enabled by that architecture. Empirical results show that the new method can achieve excellent results with much less parameters than other recent methods.",
    "This work incorporates two architecture changes which induce the inductive biases of 1) locality and 2) scale-invariance. It does so though a sequence of Reduction Cells followed by Normal Cells. In doing so, the authors demonstrate comparable performance to strong CNN baselines and improvements over Transformer-based ImageNet models -- the top performing ViTAE model achieves a 83.0% Top-1 accuracy. ",
    "This paper introduces a novel adversarial fine-tuning method, which they apply to language model fine-tuning. Their method, named RIFT, takes an information-theoretic perspective to define the new loss; this paper is very clearly written and includes mostly useful figures that help explain their novel approach. They show strong experimental results with a number of baselines, and run an ablation study for the hyperparameters introduced by their approach.",
    "This paper argues that applying adversarial training into the fine-tuning of the pre-trained language model suffers severely from catastrophic forgetting. It then proposes Robust Informative Fine-Tuning (RIFT) to encourage an objective model to retain the features learned from the pre-trained model. The results on sentiment analysis and natural language inference tasks show that the proposed method is able to outperform the strong baseline models in terms of Genetic and PWWS attacks.",
    "This paper studies the catastrophic forgetting problem when fine-tuning pre-trained language models towards adversarial robustness. They argue that existing robust training methods, such as adversarial training, make the objective model deviated too much from the pre-trained model, resulting in bad generalization. Starting from an information-theoretical perspective, the authors propose RIFT, a fine-tuning method that maximizes the mutual information between the outputs of the objective model and the outputs of the pre-trained model when conditioned on the labels. The experimental results show that RIFT has a better performance than other baselines, which supports the better generalization as the authors claim. In addition, they give explanations why considering I(S;T|Y) in the objective is better than considering I(S;T).   ==== After Rebuttal ====  Thanks for the response. All my questions are properly resolved.",
    "This paper proposes a new method for finetuning pretrained NLP models to achieve both high standard and high robust accuracy. They argue that finetuning on the more difficult and plentiful adversarial examples can lead to catastrophic forgetting, more so than standard finetuning of models. They propose an additional loss wherein the model is encouraged to get high accuracy while also retaining features from the pretrained weights. This improves the accuracy over standard finetuning and various other ways of regularizing adversarial finetuning.",
    "The paper studies the problem of adversarial fine-tuning of pretrained NLP models, that is fine-tuning them in a way that makes them robust to adversarial attacks. It proposes a new method called RIFT. RIFT alters the usual adversarial training by adding a regularization term that maximizes the conditional mutual information between feature vectors produced by the original pretrained model and the currently fine-tuned one. The motivation is to alleviate catastrophic forgetting. The experiments show RIFT getting a slightly higher adversarial robustness than the baselines methods, such as e.g. using the L2 penalty instead of the proposed regularizer.  ",
    "In this manuscript, the authors proposes a Stochastic Anderson Mixing (SAM) scheme to solve nonconvex optimization problems. Under the smoothness, unbiased gradient estimate with bounded variance assumptions, the authors show different variants of the scheme (SAM, SAM with variance reduction, Ada-SAM) have asymptotic and non-asymptotic convergence. Experiments on MNIST, CIFAR and Penn Treebank seem to show the superior performance over other baselines. ",
    "This paper proposes a stochastic Anderson mixing method to solve non-convex stochastic optimization problems. The main contribution is a  convergence theory and the applications of this method for deep learning problems. Adaptive, variance reduced, and preconditioned versions of this methods are also studied.  ",
    "The paper applies Anderson mixing to stochastic optimization problems and shows its effectiveness in training neural networks. To make Anderson mixing work in stochastic settings, the paper proposes a series of strategies to handle noise and uncertainty, including damped projection, adaptive regularization, variance reduction, and preconditioned mixing. Proof of convergence is provided, together with numerical evaluations.  ",
    "The paper under review consider the stochastic Anderson Mixing algorithm and  shows its convergence analysis. An enhanced variance reduction of the algorithms is also derived. The algorithms are tested on extensive data sets with other existing method. This paper seems to be the first one to address the theoretical convergence analysis in this direction.",
    "In this paper, the author propose a stochastic version of Anderson acceleration (widely used in fixed point iterations)  to solve non convex optimization problem. Some important modifications of the deterministic  version are introduced in order to stabilize and improve the algorithm. The paper theoretically shows that the new algorithm can achieve O(epsilon^{-2}) sample complexity. Numerical results are provided to verify the performance of SAM.",
    "This manuscript describes a novel method for sampling from the posterior in a linear inverse problem subjected to noise for an arbitrary measurement matrix. This is achieved by combining a black-box prior (such as that derived from a minimum MSE Gaussian denoiser) whose score function is easily computable with an annealed Langevin dynamics framework. The novelty is the construction of the Langevin noise term, which guarantees that the conditional score function is tractable. In addition, the authors propose a heuristic for step size calculation inspired by Newton's method in optimization. The method is evaluated on a variety of linear inverse problems: image deblurring, super resolution, and compressive sensing. For each task, realistic results are achieved and the residual is shown to conform to the imposed statistical model. ",
    "This paper proposes an algorithm called SNIPS that solves noisy linear inverse problems via an approximate MMSE estimator which makes use of pre-trained Gaussian denoisers. The estimator is based on MCMC sampling which is driven by a synthetically annealed version of Langevin dynamics. The motivations and background leading up to the algorithms derivation are well discussed. Experiments show interesting results with regard to the diversity and faithfulness of the images generated.   ---Edit after author responses---  Having read the other reviews and the responses posted by the authors, I am reducing my original scores from 6 --> 4.  My main issues are that the submission lacks (i) a comparison with an experimental baseline, and (ii) clarity in explaining the technical sections of the paper.",
    "The authors address the problem of conditional sampling using Langevin dynamics. It is known that annealed Langevin dynamics speeds up convergence, and prior work that uses Langevin dynamics for conditional sampling does not correctly model the effects of annealing. Specifically, since there is some annealing noise added to the estimate, the likelihood distribution of the measurements given an estimate will change, and the authors derive approximations to the correct functional form. Experiments show that their new estimator can be implemented in practice. ",
    "This paper proposes a technique based on annealed Langevin dynamics to solve noisy linear inverse problems. The technique is built on top of [18, 19] and proposes to perform the Langevin dynamics in the spectral space of the linear degradation operator $H$. To improve the performance of the proposed method, the authors use coordinate wise step sizes obtained by approximating the hessian with its diagonal. Qualitative results from the proposed method are presented for compress sensing, inpainting, super-r\u00e9solution and deblurring.",
    "The paper describes an apparently new approach to solving noisy inverse problems.  It shows how the approach can be applied to three different noisy inverse problems: which it calls image deblurring, super-resolution, and compressive sensing.   It validates the approach on synthetic data which is synthesized (eg blurred and noise added) starting from publicly available imagery.  It is carefully written and I find it readable.",
    "This work studied the task of detecting online drug trafficking using social media data. In particular, the authors proposed to use graph convolutional networks to model various types of entities in social media and the relations between them. Also, a meta-learning algorithm is used for the model optimization.",
    "The paper proposes a novel model MetaHG to automatically detect illicit drug traffickers on social media. It firstly builds a heterogeneous graph based on post content and relational structure information on social media to characterize the drug trafficking system. Then it integrates graph structure learning and relational-based GCN to learn robust node embedding on HG. Afterwards, it leverages meta-learning and knowledge distillation to optimize model parameters and further to detect drug traffickers on social media. Finally, it conducts extensive experiments to validate the effectiveness of the framework.",
    "This paper presents a novel heterogeneous graph learning model for automatically detecting illicit drug traf\ufb01ckers on Instagram. The proposed model addresses two challenges: 1) sparse graph structure, and 2) limited labeled samples for model training. The authors also collected a large social media dataset from Instagram and conducted a lot of experiments to evaluate the proposed model.",
    "This paper propose a novel framework MetaHG based on R-GCN for illicit drug trafficker detection on social media. A series of methods including meta learning(MAML), self-supervised learning(AS-SSL) and knowledge distillation(KD) are used to MetaHG, and obtain better metrics than traditional models with few labeled samples. In addition, the paper also creates a new dataset from Instagram for the task.",
    "Summary:  The authors propose a model to detect drug-trafficker profiles on Instagram. The model consists of many steps and phases, but in short: they create a heterogeneous graph from users, keywords, and posts, and in addition to the regular cross-entropy loss they propose to add multiple regularizer terms extracted from several stages of their algorithm (i.e., a term to build the graph, a term to learn the node representations, and a term to distill the knowledge from an out-of-domain model).  To evaluate their model, the authors created a dataset and compared their model with many baselines and their combinations. They also reported several experiments, including user visualization and a case study.",
    "EDIT: After reading authors' responses, I decided to keep my score as is.  The paper studies the problem of exact representation of continuous functions via neural networks with the ReLU activation. The literature on the approximation power of neural nets is large, however the paper here delves into the less studied question of whether the class of *exactly* representable functions strictly increases when adding more layers (with no restrictions on size).  The authors want to understand the function classes exactly represented by different architectures and a step towards this direction is to analayze the class of functions captured by a depth-d neural net (without width constraints) and how this class of functions changes as we get to depth-d+1 neural nets.  It is obvious that ReLU nets will output continuous piecewise linear functions (CPWL for short) and a non-trivial fact from previous works is that $\\log(n+1)$ hidden layers suffice to represent *any* CPWL in n dimensions, via a ReLU net. Let d is a parameter for the depth and and ReLU(d) is all functions representable exactly via ReLU nets of depth at most d. The paper tries to understand ReLU(d) as d goes from 0 to $\\log(n+1)$.  The authors put forth two equivalent conjectures about the relations between the class of functions ReLU(d) for different d. Conjecture 1.1 states that every additional layer will indeed be substantial in terms of the representational capabilities of ReLU nets up to $d\\le \\log(n+1)$ of course, at which point all CPWL are representable. The authors reformulate this with Conjecture 1.2 that is a simple statement about max functions.   The authors then show a special case of Conj. 1.2 that corresponds to showing that the max function on 5 variables cannot be representted with 2 or 3 hidden layers, with the caveat that they need a certain assumption on the breakpoints of the function represented by any intermediate neuron. Along the same lines,  the authors show that the class ReLU(k) contains more functions than just taking the max on $2^k+1$ variables. To achieve this they use the theory of polyhedral complexes associated with CPWL functions.  Finally, the authors find upper bounds on the sizes of the networks needed for expressing arbitrary CPWL functions with p linear pieces, as given in Theorem 4.4, which basically involves depth O(logn) nets with width growing as $p^{n^2}$.   ",
    "This paper studies the role of depth in exactly representing real functions by ReLU networks.  Unlike the common ML setting, the focus is on neural nets that are equal in every point to the target function.  Some partial results are given as well as a conjecture that networks of depth k+1 have strictly more expressivity than networks of depth k.  ",
    "It is known from the universal approximation theorem that ReLU networks with one hidden layer can approximate any continuous function on compact sets arbitrarily well. Instead of approximations, this paper investigates  the set of functions that can precisely be described by a network of certain depth. For a given input dimension D, a ReLU network with L=ceil[ log2(D+1) ] (or more) hidden layers (and arbitrary width) can describe the entire set of piecewise continuous functions. Here, new insight is provided for networks with having between 1 and L layers. In particular, under an unproven assumption, the paper shows that L is a strict lower limit for the depth and that adding layers to a network strictly increases the set of describable functions. This is achieved by studying a natural candidate function to require a larger number of hidden layers. The candidate function suggests a conjecture on a nice description of ReLU network functions of finite depth, which is shown to not hold true. Finally, the paper derives a bound on the width and depth of networks that can describe any piecewise linear function with fixed number of linear pieces.",
    "This paper considers the problem of characterizing exact representations for ReLU networks of a given depth, but any width. It was previously shown that the functions represented by ReLU networks of depth logarithmic in dimension is exactly equal to the set of all continuous piecewise linear functions. This work provides some results which suggest that this result is tight. That is, a depth logarithmic in dimension is necessary to exactly represent all piecewise linear functions.   Proposition 1.3 simplifies this conjecture by giving a simple equivalent condition in terms of representing max(0,x_1,\\dots,x_n) and proves the conjecture up to dimension 4 under the assumption 2.4 which is unproven. In section 3 it is shown that the set of functions representable by a depth k network is a strict super set of Max(2^k) - i.e, set of all functions which can written as a linear combination of max of 2^k affine functions. This provides further evidence in support of the conjecture.  Section 4 then extends the results of Arora et. al 2018 to provide an upper bound on the width required for a relu network to exactly represent affine function with p pieces. This bound is $p^{O(n^2)}$.",
    "The authors study the class of functions that can be represented by a fully connected neural network with ReLU activations. First, They conjectured that for any $k\\in\\mathbb{N}$, $n=2^k$, the function $f_n(x)=\\max\\{0,x_1,\\dots,x_n\\}$ cannot be represented by a fully connected network with $k$ hidden layers, and prove this conjecture for $k=2$ under some mild assumption. Second, they proved the class of functions that can be represented by a $(k + 1)$-layer NN is strictly larger than the class of functions that are linear combinations of $2^k$-term max functions. Finally, they provided a bound on the width of the NN required to represent continuous piecewise linear functions. ",
    "This paper proposes a unified alternating projected gradient descent-ascent (APGDA) attack by considering the min-max operation for adversarial attack settings. The proposed method can be applied in generating model ensemble attacks, universal adversarial attacks, and robust attacks over data transformations. Extensive results show that the proposed method can achieve better attack performances for these three applications.",
    "This paper proposed a APGDA attack method, in which the model ensemble attack, universal attack, and robust attack are unified. The authors proved their APGDA's superiority in theory, ${i.e.}$, convergence rate and strong attacking ability. All of the mentioned tasks (ensemble attack, universal attack, robust attack) are investigated through experiments.",
    "The paper provides a general min-max framework to formulate several popular problems in the literature including Ensemble attack over multiple models, Universal Perturbation over multiple examples, and adversarial attack over data transformations. For each case, a standard first-order approach converging to a stationary point of the problem is provided. The effectiveness of the min-max approach compared to the standard empirical risk minimization has been demonstrated by extensive experiments.  ",
    "This paper adapts the min-max problem proposed for multi-domain robust optimization [45] to the problem of generating adversarial attacks. They show how several adversarial attacks scenarios can be formulated using this min-max, for example they show that this min-max formulation can be used to find successful attacks against an ensemble of models. They also show how this min-max can also be used to train robust models against multiple $\\ell_p$ attacks. They show experimentally that the approach outperforms several baseline in several setting.",
    "The work proposes a min-max framework APGDA that can take in different models related to adversarial robustness. APGDA can generate model ensemble attack, universal attack over multiple images, and robust attack over data transformations. They perform experiments to evaluate their method.",
    "This paper studies the problem of sparse tensor PCA (a generalization of sparse PCA and tensor PCA). The main result is an algorithm that -- for the highly sparse regime in which the sparsity is at most the square root of the signal dimension -- naturally interpolates between a poly-time efficient algorithm and exponential exhaustive search. This result is complemented by lower bounds for the rather popular computational model captured by low-degree polynomials. The lower bounds match the algorithm guarantees (although for the different problem of distinguishability) in the regime of constant tensor order $p$.   The results of this paper recover several results of the literature, and provide a non-trivial extension. ",
    "# Review for \"The Complexity of Sparse Tensor PCA\"  This paper studies the \"Sparse Tensor PCA\" problem, which is a common generalization of two well-studied problems: sparse principal component analysis and tensor principal component analysis. The problem is as follows: given a \"single-spike\" tensor of the form  $T = \\lambda \\cdot x^{\\otimes p} + W$  where $W$ has i.i.d. Gaussian entries, $\\lambda > 0$ is the \"signal strength\", and $x \\in R^n$ is $k$-sparse for some $k \\ll n$, find $x$. (The problem can be generalized to more than one spike $x$; this is treated carefully in the paper.)  The paper contains interesting new algorithms and computational lower bounds for this problem. ",
    "The authors propose a family of algorithms for solving the sparse tensor PCA problems, which is based on smooth interpolation between a polynomial-time algorithm and exponential-time search algorithm. Improved results are achieve for sparce PCA in the lower signal/noise ratio regime in distinct sparse signal cases, compared with existing guarantees. Lower bound analysis is also provided for the proposed algorithm.",
    "This paper focuses on the tradeoff between computational complexity and conditions for recovery in a symmetric sparse tensor estimation problem. There has been a great deal of work on related problems recently in the case of matrices (order 2 tensors) and the case of tensors (without necessarily imposing sparsity constraints). The main achievability result (Theorem 1) provides sufficient condition for single spike model in terms of the ambient dimension, the order the tensors, the degree of sparsity, the signal strength, and an integer parameter the interpolates between a ````\"low complexity\" algorithm  \"high complexity\" algorithm (essentially brute force search). Similar results of for a multiple spike model are given in Theorem 2.   Necessary conditions for a certain testing problem are considered in Theorem 3 which provides necessary conditions such that a polynomial of bounded degree can \"distinguish\" between a planted model (with a signal of a given strength) and a null mull of only Gaussian noise. Here the criterion for distinguishability is a certain L2 test.  While similar results have been obtained in the literature, the authors argue that their results improve upon the existing ones in a number of ways. ",
    "This paper studies the estimation of a rank-one (or more generally a low-rank) tensor $x^{\\otimes p}$ ($x \\in \\mathbb{R}^n$ is assumed to have unit norm) given $Y = \\lambda x^{\\otimes p} + W$, where $\\lambda > 0$ and $W$ is a Gaussian noise tensor. Here the signal vector $x$ is assumed to have only $k$ non-zero entries.  The main contribution of the paper is an algorithm that recovers with high probability the support of $x$ in time $O(n^{p+t})$ provided that $\\lambda \\geq O(\\sqrt{t} (k/t)^{p/2})$. The number $t$ can be arbitrarily chosen between $1$ and $k$, illustrating a tradeoff between statistical constraints on the signal-to-noise ratio $\\lambda$ and runtime constraints on the estimation algorithm. This generalizes to the 'tensor settings' previous results obtained about sparse PCA.  The authors also prove an information-theoretic lower bound for low-degree polynomials. More precisely, they prove that no test based on polynomial of degree at most $D$ can distinguish between the planted model $Y = \\lambda x^{\\otimes p} + W$ and the pure noise model $Y=W$, when $\\lambda$ is smaller than some quantity depending on $D, n, k, p$. This bound generalizes previously obtained results for PCA and tensor PCA. This bound is tight for low-degree polynomials. However there is a gap with the  bound $\\lambda \\geq O(\\sqrt{t} (k/t)^{p/2})$ needed for the algorithm that recovers the support.   ",
    "The submission presents a way of improving training of deep implicit networks, that take Cartesian coordinates (e.g., 2D or 3D) as inputs. The method uses additional embeddings of the input coordinates, similarly to Positional Encodings and variations (SIREN, FFN), with 2 differences: - embeddings corresponding to higher spatial frequencies are only be made available later during the optimization phase, and only if the network does not fit well enough - they can be made available selectively on different parts of the input space, based on a spatial grid. This method makes it possible to better represent inputs where the maximal spatial frequency changes a lot between regions (e.g., an image with large smooth regions, and regions of higher detail), and compares favorably to similar methods.",
    "This paper proposes an improvement of implicit function approximation for image and mesh generation. The main contribution is to use a progressive low resolution to high resolution optimization as well as spatially adapt this `masking`. Performance is shown to be better than FFN by a significant margin.",
    "This paper highlights a problem with Position Encoding models that use Fourier features: they're very sensitive to a bandwidth parameter that trades-off between reproduction of low- and high-spatial frequency features. Their solution is an iterative feedback algorithm that reconstructs images in a coarse-to-fine manner. They describe incremental improvements across-the-board, and large and impressive improvements in their 2D silhouette reconstruction task.",
    "Implicit neural representations are a promising approach to learning compressed representations of data --- for example they can learn to represent an image where the network inputs are the (x,y) coordinates and the outputs are the RGB pixel values. This idea has all sorts of applications in data science and physics.   This work provides a method for improving the optimization of these implicit neural representations. It addresses the challenge that standard MLPs are biased towards learning low-spatial frequencies, and that a dataset (e.g. an image to compress) can have different frequency distributions in different regions. ",
    "The paper presents a technique for dealing with the problem of choosing bandwidths for positional encodings in implicit functions. The method presented uses higher frequency positional encodings as training progresses and clips the maximum frequency when a quality criterion has been reached for a position (therefore it is spatially adaptive) in order to avoid the appearance of artifacts.  Results on several domains (images, 3d occupancy, and mesh deformations) are presented with good results in all cases.",
    "The authors provide an analysis of an entropy regularized extra-gradient method for zero sum games. The proposed algorithms have last iterate convergence guarantees to the equilibrium of the regularized game at rate that is dimension free (up to double logarithmic factors) regardless if the unregularized game has a unique equilibrium. The algorithms can be used to find approximate equilibria of the unregularized game and in Markov zero sum games.",
    "The paper studies two standard classes of games with entropy regularization: two-player zero-sum matrix games and zero-sum Markov games. For the regularized matrix games, the authors apply the mirror descent approach (using KL distance) to the regularized objective, and propose two first-order descent/ascent algorithms using different optimistic predictions: the Predictive Update (PU) and the Optimistic Multiplicative Weights Update (OMWU). The authors prove that both algorithms converge to the unique Nash equilibrium of the regularized game with constant stepsizes, linearly. The authors characterize the linear convergence via four measures: KL distance, infinity norm, optimality gap, and duality gap. It is featured by last-iterate convergence and almost dimension-free. For the regularized Markov games, the authors apply the proposed PU and OMWU to the $Q$-value functions at each state and prove the convergence in infinite norm to the optimal $Q$-value function of the regularized game. The convergence rate is slightly worse than the linear rate, but it is also almost dimension-free. The authors also provide computational experiments to verify the usefulness of the proposed algorithms. ",
    "The authors propose to use mirror descent to solve classic entropy-regularized competitive games. Linear convergence rates are obtained for the proposed algorithm. In addition, the authors propose to use such an algorithm to solve the subproblem in the entropy-regularized Markov game and obtain a linear convergence rate to the regularized equilibrium.",
    "This paper proposes to leverage entropic regularization and optimistic-type methods to solve zero-sum (ZS) matrix games and ZS Markov games. The authors begin with ZS matrix games on the simplex: they add entropic regularization, thus transforming this game into a strongly-concave/strongly-concave problem. Slight variants of Mirror-prox/extragradient and optimistic mirror descent with multiplicative updates are introduced, and the authors show that, for several performance measures, the last-iterate of these methods converge linearly to a solution of the regularized problem thanks to the added strong convexity/concavity. Their rates are (almost) dimension-free, and do not require the uniqueness of the solution. As a consequence, they explain how to obtain $\\epsilon$-Nash-equilibrium with $O(1/\\epsilon)$ iterations by tuning the regularization parameter. Finally, the authors propose to put to use their results to tackle ZS infinite-horizon Markov games.",
    "In this work, the authors aim to complete the recent line of research in last-iterate convergence guarantees for saddle-point optimization (applicable to game theory, GANs, etc.) with efficient methods that converge to an approximate Nash equilibrium *without* the equilibrium uniqueness guarantee. The key is to simply apply the previously analyzed methods (OMWU in particular) on a regularized version of the payoff. The regularization ensures uniqueness of what is called QRE, quantal response equilibrium, which can be used for finding an approximate Nash equilibrium. As a bonus, the authors show that their results apply to Markov games too.",
    "The paper proposes a transformer-based image super-resolution method for screen content images which have many thin edges. The transformer is designed to learn the mapping from coordinates to rgb values. It additionally has a scale token representing the magnification factor. Due to targeting a new application, the paper also constructs suitable training and testing datatests.",
    "This work addresses the SCISR problem by combining transformers to the network architecture. The backbone of the architecture utilizes a CNN to extract feature maps, to enlarge the receptive field, an implicit transformer is used. After that the implicit position encoding is conducted via MLP. Natural images are suitable for SR but there is a lack of SR techniques that are suitable for screen content, which this paper tries to address.  ",
    "This work presents a continuous image super-resolution based on an implicit transformer. Authors extend LIIF [6] with some modifications including transformer-like formulation in (2), scale token in (5), and implicit position encoding (7). The proposed implicit transformer learns the transformation weight from query (high-resolution) coordinate, key (low-resolution) coordinate, and scale token. A pixel intensity is then computed by transforming the pixel features (obtained from CNN backbone) with the transformation weights. The pixel intensity is further refined with the implicit position encoding, which is an adaptive weighting scheme with learned weights. Experimental results on screen content images demonstrate superior performance over existing continuous super-resolution methods [5,6].",
    "This paper addresses the problem of arbitrary screen content image super-resolution, which is quite different from natural image super-resolution.  The author proposed two datasets specifically designed for this scenario, which can greatly motivate research  effort into this field. Besides, the authors proposed Implicit Transformer Super-Resolution Network (ITSRN) to achieve arbitrary scaling for screen content images. The ITSRN is largely inspired by LIIF, the main novelty of ITSRN includes the proposed  implicit transformer and the implicit position encoding, these schemes are empirically evaluated to show its effectiveness. ",
    "This paper presents a novel method called implicit transformer for the task of super-resolution of screen content images. The proposed method is able to integrate the advantage of transformer in capturing relation between pixels and that of implicit neural representation in producing continuous and sharp results. The effectiveness of the proposed method is validated on both newly collected datasets w/o and w/ compression degradation, and datasets originally created for image quality assessment. Ablation study also demonstrates the role of the proposed modules.",
    "The paper proposes to learn interventional distributions using a family of generative models known as sum-product networks (SPN). SPNs are models based on gate functions that allow for tractable inference. Specifically, the authors propose interventional SPNs (iSPN) which are conditional SPNs (they model conditional distributions) that, licensed by a causal graph and samples from the interventional distribution, are shown to be expressive and causally adequate.",
    "The paper proposes a new causal inference framework based on so-called \u2018interventional Sum-Product Networks\u2019 to target the problem of a lack of tractability in causal inference. It is based on standard SPNs and employs deep learning techniques to capture complex nonparametric functions describing multivariate conditional probability distributions. It is evaluated on several small synthetic data sets. ",
    "This paper proposes a modification of sum product networks termed iSPN to estimate interventional distributions from data. The proposed model performs a manipulation to the structure of the SPN in order to provide estimates from the mutilated distribution. The authors motivate the use of this model in terms of computational complexity and the ability to represent estimates of arbitrary causal quantities on the graph. Empirical results show the proposed model having impressive running time and comparable error results to modern software packages for causal effect estimation. ",
    "This submission proposes interventional sum-product networks, a tractable method for estimating causal effects from interventional data. The authors prove that iSPNs are universal function approximators. They show that iSPNs produce accurate estimates of interventional queries from interventional data on collection of synthetic data generating processes.",
    "This paper discusses a variant of sum-product networks (SPNs) called \"interventional sum-product networks\" which is a variant of SPNs that take as input a causal graph and use this to model interventional distributions. The claim is that this is the first paper that applies tractable probabilistic models to causality. Theoretical aspects are discussed and the method is evaluated and compared to existing methods. ",
    "The paper presents a deep Markov factor analysis (DMFA), which is a generative model that employs Markov property in a chain of low dimensional temporal embeddings as well as spatial inductive assumptions in order to capture temporal dynamics in functional magnetic resonance imaging (fMRI). The paper shows that DMFA has capability to cluster fMRI data in its low temporal embedding in regards to subject and cognitive state variability. The advantages of DMFA are demonstrated both through synthetic and application data.",
    "The paper Deep Markov Factor Analysis (DMFA): Towards Concurrent Temporal and Spatial Analysis of fMRI Data proposes a scalable approach to factorize the data of each subject into a product of a small number of spatial and temporal components. Following on the work of (Manning et al., Topographic Factor Analysis, Plos ONE 2014) on topographical factor analysis, each spatial component is given by a radial basis function. The temporal components are modeled from a set of latent satisfying the Markov property. The first latent is conditioned on the data class giving to the model clustering capabilities. Variational inference is used to derive a lower bound of the log-likelihood which is then optimized via stochastic gradient descent. In a first experiment on resting state data (Autism dataset), DMFA is used to obtain subject specific atlases that allow to seggregate ASD and control subjects with an accutacy of 60 % (it is definitely hard to read). On a second experiment (Depression dataset), MDD and controls are exposed to different musical stimuli and DMFA is able to seggregate well the data of different subjects without supervision. In some extend it gives some hint about the kind of stimuli and the conditions of the subjects but results are not so convincing (the authors are honest about this).  In a third experiment they show that DMFA gives better results than other methods in terms of held-out log-likelihood and prediction of the next time point given the history. The code for DMFA is available. Pre-trained model are given and the code to generate the figures from pre-trained model works. ",
    "This paper introduces Deep Markov Factor Analysis (DMFA). DMFA can model spatiotemporal BOLD fMRI time series by using time-varying latent factors that govern time-varying spatial maps consisting of spatial mixtures of RBFs. Latent time series are associated to a categorical clustering variable in order to enable grouping. Certain links in the Bayesian diagram are modeled using deep neural networks. Optimization is done by a variational approach. Experiments are performed on a simulated data set with known ground truth, the ABIDE autism data set, and a Depression study data set. Some clustering of relevant clinical outcomes is observed.   ",
    "The authors present deep Markov factor analysis (DMFA) to capture temporal dynamics in functional magnetic resonance imaging data. The method chosen by the authors is relevant since existing methods overlook the highly nonlinear and complex temporal dynamics of neural processes when factorizing their imaging data. The authors claim that their method (DMFA) is able to cluster fMRI data in its low dimensional temporal embedding, which enables validation of fMRI related hypotheses.",
    "The paper proposes deep Markov factor analysis (DMFA) that uses the Markov process to capture the temporal dynamics in the fMRI dataset and maps the high spatial dimensions to a low-dimensional feature space. DMFA can cluster fMRI responses into \u201clow dimensional temporal embedding\u201d based on subject or cognitive state. The empirical studies on synthetic and real fMRI datasets illustrate that DMFA generates better performance in comparison with state-of-the-art techniques --- such as NTFA and HTFA.",
    "The paper tackles the problem of learning flow-based generative models. The proposed approach, a new instance of continuous normalizing-flow methods, models the density as a difference between the prior and a divergence term, parameterized by a neural network.  The claims are that: * MF constitutes a universal density approximator, * MF is more efficient to train than alternative CNFs; this is demonstrated empirically and the intuition is that MF does not require invoking or backpropagating through an ODE during training (note however that solving an ODE is required for sampling), * MF improves upon alternative CNFs in terms of density estimation, sample quality, and training complexity, * MF demonstrates for the first time the use of flow models for sampling from general curved surfaces.",
    "This paper proposes an alternative way to train a continuous normalizing flow (CNF), inspired by the Dacorogna-Moser transport. The proposed training does not require numerical integration; instead, the likelihood of the flow can be directly evaluated by computing the divergence of the mass flow rate. The idea is tested on boundaryless manifolds, such as the flat torus for toy data and implicit surfaces. ",
    "The paper introduces a new type of continuous normalizing flow (CNF) for manifold-valued data. Unlike in previous works, this Moser Flow (MF) models a density as a base density minus the divergence of a neural network. The authors prove that under certain assumptions this defines a probability distribution over the manifold. This approach has a different trade-off between inference and generation from other approaches: while the model density can be evaluated very cheaply, sampling from this model requires an ODE solver. The approach is qualitatively demonstrated on toy datasets on tori and the Stanford bunny, and quantitatively evaluated on a few datasets on 2-spheres.",
    "This paper presents Moser Flow a new class of Continuous Normalizing Flows for Riemannian Manifolds. The main approach exploits results in differential geometry (Moser 1965) to construct a vector field that satisfies the normalizing equation given by the pullback of the volume form under $\\Phi$. The approach is both sensible and provides direct advantages over Riemmanian CNF's as training does not require solving the ODE using a solver. The authors also consider Moser Flows for Euclidean Submanifolds under the Induced metric and show that Moser Flows can learn arbitrary distributions on manifolds of interest (---i.e. compact, boundryless etc...). Finally, the experiments conducted are both interesting in their variety and illuminating in that they show the effectiveness of the proposed method. Overall, this paper represents a non-trivial step forward---manifold or otherwise---for Continuous Normalizing Flow research.",
    "The authors define a continuous normalizing flow on an arbitrary Riemannian manifold through the divergence of a neural network using the Moser theorem. They motivate their approach and show how this flow can be represented and learned. By applying their method to a toy distributions and a real world earth and climate dataset, they demonstrate the effectiveness of the method and that they can outperform competing procedures. Furthermore, they show that their method is much faster and more efficient than FFJORD when learning a complex two dimensional density.",
    "The paper proposes applying the theory of independent causal mechanisms (ICM), from causal discovery, to nonlinear ICA approaches to the blind source separation problem (BSS).  ICM is based on the idea that variables in a system are algorithmically independent or do not share information with each other. The paper shows, however, that ICM is not sufficient for BSS as spurious solutions exist which are not equivalent to the truth.  To address these difficulties, the paper proposes a new condition for identifiability which places an orthogonality condition on the columns of the Jacobian and provides information theoretic and geometric interpretations. The paper then shows theoretically that a large class of spurious solutions are not admitted under the IMA formulation.   Experiments on toy examples demonstrate that the model is identifiable under these spurious solutions.",
    "This work proposes a new regularization scheme to improve identifiability in the _nonlinear blind source separation problem_ (nonlinear ICA) inspired by the notion of _independence of mechanism_ coming from causal inference. The idea is to consider only mixing functions which have a Jacobian matrix with orthogonal columns everywhere. They show how this extra assumption allows to exclude two classical types of degeneracies in nonlinear ICA, although without showing identifiability. The theoretical claims are validated by synthetic experiments.  ",
    "The paper proposes a criterion for non-linear ICA as applied to Blind Source Separation inspired by Independence of Causal Mechanisms in the causal discovery literature. The general idea is to constrain the gradients of the output with respect to the input sources to be orthogonal to each other; this is linked to the notion that the mixing mechanism is in some sense independent (or not \"too fine-tuned\") to the input sources. The authors show that this constraint eliminates a number of known counterexamples to identifiability in non-linear ICA, and test it experimentally to show that helps to characterize true solutions (both as an evaluation metric, and as a regularizer). The authors conclude with a discussion putting their contributions into context.",
    "The authors propose to borrow concepts from causality, in particular \"independent causal mechanisms\" , to propose a novel framework termed \"independent mechanism analysis\" (IMA), which can provide non-spurious solutions to nonlinear blind source separation. IMA can be seen as a restricted nonlinear ICA model, where the contributions of the latent variables $z_i$ to the nonlinear mixing $\\mathbf{f}$ are independent, i.e. the columns of the Jacobian $J_\\mathbf{f}$ are orthogonal. ",
    "The paper aims at the identifiability of nonlinear ICA. It proposes a principle as a constraint of mixture functions based on the modified independent causal mechanism principle in the causal discovery literature; investigates the identifiability of nonlinear ICA under such an assumption; then applies it to nonlinear ICA. It also shows that the identifiability results can cover some non-identifiable cases in the existed literature.",
    "The authors introduce a variational inference method that leverages Annealed Importance Sampling (AIS) and Langevin/HMC MCMC. In particular HMC dynamics are used to target a sequence of intermediate bridging densities in order to generate approximate samples from the target posterior distribution. Importantly, since the method is uncorrected (i.e. does without a accept/reject step) the resulting lower bound is fully differentiable. This makes various hard-to-set parameters (e.g. temperatures for bridging densities) learnable. In experiments the authors demonstrate that their method, Uncorrected Hamiltonian Annealing (UHA), leads to tight lower bounds on the log evidence. ",
    "The paper proposed to use the uncorrected HMC kernel in an AIS-type variational scheme. This enables optimizing the ELBO via reparameterization gradients for many algorithm tuning parameters, including step size, momentum covariance, and annealing schedule. The method is shown to outperform competitors in most cases. ",
    "The paper proposes UHA, an original and clever modification of Hamiltonian AIS. The idea is to change the AIS ratio such that it becomes tunable, but can still be computed in closed form (ratios of momentum distributions). This is achieved by dropping the accept-reject step in the HMC update such that a single UHA step only involves (re)sampling momenta and leapfrog integration. This modification allows the authors to tune parameters such as the proposal distribution, the step size and damping coefficients (used in momentum resampling). Many interesting ideas for future extensions are proposed. Experiments on various models demonstrate that UHA obtains a tighter ELBO than other combinations of VI and HMC.  ",
    "The paper propose to use uncorrected HMC kernels (i.e. HMC kernels without accept-reject steps) in AIS to make the estimate of log normalisation constant differentiable w.r.t. to various parameters (e.g. step-size for numerical integration). The author(s) name(s) the method UHA. The promise is that one can then using reparameterisation gradient to tune these parameters. Through experiments on inference tasks, the benefit of tuning parameters in UHA is demonstrated against other methods that use HMC in AIS. For experiments on VAE training, UHA with tuned parameters has shown better test ELBO than IW.",
    "This paper studies the annealed important sampling (AIS) using the Hamiltonian dynamics kernels in each interpolant. To circumvent the problem that the Hamiltonian dynamics involves the non-differentiable operations, this paper proposes to discard the accept-reject operations in the kernel, and derives the resulting density ratios in a simple form related to the momentum variables. The resulting approach, named Uncorrected Hamiltonian Annealing (UHA), is a fully differentiable AIS method. This paper validates the effectiveness of UHA through extensive experiments and highlights the importance of differentiability. ",
    "This paper studies certified robustness from the perspective of computing Lipschitzness bounds. Prior work compute global bounds on the Lipschitz constant of the network; this paper takes an alternative approach which computes local Lipschitz bounds around a specific input. These local Lipschitz bounds are based on interval bounds for the hidden layers on each data point, and computing a tighter Lipschitz constant based on eliminating rows/columns of the weight matrices when the interval bounds indicate that a neuron is inactive.   To train certifiably robust models, the worst-case loss is optimized based on these Lipschitz bounds. There are several other ingredients for the proposed method: a modified ReLU activation which truncates when the output is a large positive value, and a sparsity-inducing regularization meant to limit the number of neurons where the upper and lower activation bounds differ. The authors compare certified robustness w.r.t. $\\ell_2$ perturbations against other Lipschitzness-based baselines and demonstrate improvements. ",
    "This paper provides a trainable local Lipschitz upper-bound for a neural network that is tighter than the global Lipschitz upper-bound computed via multiplying the Lipschitz constant of each individual layer. By making use of the interaction between the weight matrices and the piece-wise linear activation functions, the authors demonstrate that the global Lipschitz bound could be improved when the activation functions are constant locally. In addition, the authors proposed a variant of ReLU that is clipped at a certain upper threshold to increase the constant region to help achieve a tighter Lipschitz upper-bound. Empirically, the authors showed that optimizing the local Lipschitz bound, along with using the modified ReLU, improved the certified robust performance of existing algorithms on several standard image classification tasks.",
    "Per data-example, a local Lipschitz bound on the neural network output is computed and then used to certify robustness. This bound is made tighter by exploiting invariances of the ReLU activations throughout the network under small perturbations around the given data point. The paper further increases invariances by clipping ReLU and training the clipping threshold.",
    "This paper proposes a new method for certified robustness that tightly bounds the local Lipschitz constants for models by exploiting zero-activation of ReLU. For each data point, the proposed method first calculates the positions where feature maps become zero by ReLU. Next, since the row vector of the weight matrix before the ReLU outputs zero does not affect the output, the proposed method eliminates such row vectors and computes the Lipschitz constants of the modified weight matrix. Experiments demonstrate that the proposed method outperforms previous methods in terms of clean accuracy, robust accuracy against PGD, and certified robust accuracy. ",
    "This paper proposes using local Lipschitz bound to obtain certified robust neural networks. The use of local Lipschitz constant strictly results in a provable tighter bound than the commonly used global Lipschitz bound. To incorporate the proposed certification method into training, the authors further proposed a modified ReLU function with a learnable upper threshold, and hinge loss to encourage the pre-activation states to be constant past ReLU function.  The proposed method is sound, numerical experiments show promising improvement over the existing certified robust training methods.",
    "This paper proposes a scalable method for conformal Bayesian prediction, by estimating the modified posterior predictive density using \"add-one-in\" importance sampling.  On several tabular datasets with sparse and hierarchical models, estimation is shown to be efficient for non-extreme miscoverage levels, and the produced credible intervals have good coverage.  **Post-rebuttal update:** Thank you for the response.  I am keeping my score unchanged: on the plus side, the method is sensible and easy to implement; on the other hand, there are some (understandable) limitations when scaling to large datasets or applied on approximate posterior samples; and some reviewers raised questions about novelty, which I'm not most suited to judge, as I'm not an expert in this field.  In aggregate, the rating of \"marginally above the acceptance threshold\" still describes my opinions well.",
    "The authors present an approach to using a Bayesian model to provide predictive intervals with  frequentist coverage within the framework of conformal prediction.  This work generalizes existing Bayesian methods for conformal inference that apply only to conjugate models.  The authors provide a straightforward generalization of their approach to partially exchangeable data.  Empirical validation on several datasets, and comparison to a baseline approach is provided.",
    "This article proposes a novel approach to constructing prediction intervals with approximately correct frequentist coverage, even on misspecified models.  The basic idea is to employ the conformal prediction technique using the Bayesian posterior predictive density as the conformity (goodness-of-fit) measure.  The main innovation of the article is to use an importance sampling approximation to the posterior predictive density at candidate values of outcome $y$.  This leads to a computationally fast and generally applicable algorithm for using samples from the standard Bayesian posterior to construct well-calibrated prediction intervals, even under misspecification of the Bayesian model.  An extension to hierachical models is also provided, and empirical results are presented demonstrating the performance of the method.",
    "This paper introduces Bayesian and importance sampling techniques into a previously known conformal prediction framework.  I had troubles identifying what exactly is the novel contribution of this paper. It could use a brief section stating \"our own contributions are A, B , C\". In my understanding the conformal prediction framework was known before and the novel items are using the Bayesian posterior predictive density as a conformity score and additionally estimating the predictive distribution given new data from a weighted importance sampling where the weights are just the likelihoods of the prameter draws based on the new data point.  There are modelling extensions from completely exchangeable models to partial exchangeability, i.e., where we have groups and complete exchangeability is still valid in the groups, but not outside the groups. From this flat hierarchical structure there is a further extension to hierarchical models that may model deeper hierarchies and via hyperpriors may share information between groups.  ",
    " The authors develop a fast conformal Bayesian computation approach.  The original conformal prediction method can be computationally intensive:  It often requires refitting the model for every augmented value y. The authors avoid this refitting step by using importance sampling. The authors also show the extension to conditionally exchangeable data, which is especially useful for hierarchical data. The resulted conformal interval has finite sample correct coverage and is immune to model misspecification or distribution assumptions.",
    "Summary:  - This submission deals with designing stable and smooth denoisers that could be directly used for regularization, or for plug-and-play (PnP) methods to solve inverse problems.  - This is an improvement upon existing denoisers such as RED and PnP which are not necessarily stable.  - The key idea is to craft neural networks that output scalar-valued potential function g whose gradient is the denoiser residual. To guarantee convergence and stability, g has to be smooth and h=1/2x^2 - g convex.  - Advantages: the denoisers lead to symmetric Jacobians, allowing for a MAP estimation; denoisers can be integrated into optimization schemes with backtracking step size, and thus no need for enforcing Lipschitz continuity. - To construct such a network, GraDnCNN stacks conv layers and nonlinear activations, and proposes DnICNNs with non-negative weights and convex activations. Variants of DnICNN are discussed that achieve better denoising/recovery performance for Gaussian deblurring, and image superresolution.  Contributions: - construct stable denoisers based on neural networks as gradients of smooth potential functions g - integrate the denoisers as a regularizer for solving inverse problems and test it out for gaussian image deblurring and superresolution which outperforms RED and traditional PnP methods ",
    " This paper considers the problem of designing an image denoiser that can be used as a prior within plug-and-play priors (PnP) or regularization by denosing (RED). Prior work has proved the convergence of PnP/RED for contractive, nonexpansive, and/or firmly nonexpansive denoisers. The design of denoisers that enable PnP/RED convergence is an active research area.  This paper focuses on denoisers that correspond to the gradients of some potential functions. By using such denoisers within RED, one can guarantee convergence via traditional optimization. The key idea in the paper is to use a deep neural network to parameterize a potential function (instead of the denoiser), then train that function for denoising by using its gradient. Additionally, when the weights of the network are nonlinear and activation functions are nondecreasing and convex, the denoiser corresponds to a convex function.  The key contribution of the paper is the formulation of a procedure for training a potential function that can be used to obtain a denoiser. The theoretical arguments presented in Lemma 2 and Theorem 1, are well known in optimization (see below for reference). Similarly, Algorithm 1 corresponds exactly to the RED-SD algorithm using a potential-driven denoiser. The empirical results compare three proposed variants of denoisers against PnP-PGD and RED-SD on problems of image deblurring and superresolution.",
    "The paper proposes image denoising based CNNs as regularizers that can be constructed as the gradient of smooth potential functions $g$. The main promise is mentioned to be making an optimization algorithm has explicit regularization, when equipped with those denoisers. Unlike original regularization by denoising (RED) that the explicit regularizer exists if the denoisers satisfy several strict conditions, the proposed denoisers only rely on smoothness. Particularly, the denoisers consist of smooth activation functions to ensure the differential continuity and are trained in a residual denoising fashion using MSE loss. As a result, the proposed algorithm can be formulated as steepest descent variant of RED optimized by directly adopting the gradient of the objective function $F$. Standard back-tracking is used to ensure convergence. A convergence analysis is provided following the common optimization theory. Finally, the performance of the proposed method is evaluated over two image inverse problems such as gaussian deblur and super-resolution, with satisfactory results compared to existing methods based on PnP and RED. ",
    "Motivated by the RED algorithm for solving inverse problems, the authors propose a neural-net denoiser that is the gradient of an explicit potential function.  This guarantees that the Jacobian is symmetric definite, which then guarantees that the RED algorithm minimizes an explicit cost function, which in turn makes convergence straightforward to prove, thereby solving an important open problem about the convergence of RED and plug-and-play (PnP)-type algorithms.  The fact that there is an explicit cost also enables the use of adaptive stepsize selection within RED, with one particular scheme proposed by the authors.  Numerical comparisons to RED and PnP algorithms show improved PSNR and SSIM performance, as well as enhanced stability.",
    "**Summary**: This paper addresses an important issue in the framework of regularization by denoising (RED), which is that the explicit RED regularizer $\\frac{1}{2}x^T(x-D_\\sigma(x))$ exists only if a set of strict conditions on the denoiser are met. Due to this problem, RED fails to formulate explicit regularizers for advanced denoisers (e.g. CNN) since they generally do not satisfy the conditions. Although some work has established some theoretical analysis for RED algorithms using deep denoisers, a linkage between the denoiser and the regularizer is generally missing.   In this paper, the authors proposed to formulate the regularizer as a *smooth potential functional* $g(x)$, which is parameterized by a CNN with smooth activation functions. To link the potential functional to a denoiser, the authors trained the CNN such that the gradient $\\nabla g(x)$ outputs the noise residual for the AWGN. In this way, the proposed method can formulate the gradient-based RED update by directly taking the gradient of the objective function $F(x)$.  Since the objective function is available, the authors also proposed to use the standard back-tracking trick in their framework to guarantee convergence. Additionally, a convergence analysis is also introduced by following the common nonconvex optimization analysis given the handy $F(x)$. ",
    "The authors propose a RhythmicNet that can generate a musical soundtrack associating with human movements in a video. Unlike most existing works that aim to generate sync sounds of audio sources in videos, this work focuses on generating musical rhythm and beat along with visual motions. It mainly consists of three parts: Video2Rhythm, Rhythm2Drum, and Drum2Music. Experiments can validate that the proposed RhythmicNet can generate plausible soundtracks for different body movements.   ***Post-Rebuttal***  The rebuttal has successfully addressed my major concerns. Thus, I would like to keep my positive rating. The authors should revise the main paper by improving writing and adding new results and discussions provided in the rebuttal.",
    "In this paper, the authors propose to generate music based on human motion videos. The authors propose the Video2Rhythm to capture the  rhythmic nature of free body movements. Then they use Rhythm2Drum module to generate drum. Finally, piano and guitar tracks are added to enrich the music through Drum2Music. Experiments show that they can generate plausible music that aligns with the videos.",
    "The paper proposes an approach to generate rhythmic music from a human movement video. In detail, the model is three step process: 1) Video2Rhythm: Uses the patterns in the motion of human skeleton to detect a rhythm. 2) Rhytm2Drum: Convert the rhythmic patterns to drum beats and 3) Drum2Music: Use the drum beats to update the remi representation of another instrument (or multi-instrument song). These three steps are trained independently in a supervised learning paradigm. ",
    "The authors propose a method to generate musical soundtracks for silent videos of human activity. The method is named RhythmNet and is composed of three parts: Video2Rhythm, Rhythm2Drum, and Drum2Music. These three are sequential modules which take an input silent video and generate a musical soundtrack to accompany the video.  The Video2Rhythm component predicts musical beats given the video. It uses keypoints extracted from the video and encodes the rhythm as the beat and style. The Rhythm2Drum component uses the predicted rhythm and generates a drum pattern following the setup of GrooveVAE using a transformer-based encoder-decoder architecture followed by U-net for velocity and offset prediction. Finally, the Drum2Music component adds either piano or guitar accompaniment to the drum track to make a full musical soundtrack. Each of these individual components are independently trained. ",
    "The paper proposes a new method to produce a rhythmic sound consisting of basic instruments such as (piano roll, guitar chords and drum beat) given an input video containing at least one human activity. The authors leverage the input human action dynamics first using a keypoint estimation network and their velocity features. The latter features as used consequently to produce a rhythmic pattern which is used to generate a sequence of drum beats. The aforementioned drum beat sequence is then used as an output or as conditioning to a late-stage generation of a piano roll or a sequence of guitar chords. The intermediate representations and the architecture choices are discussed for each staged of the process. The authors provide both qualitative and quantitative results (opinion scores, video examples) for showing the effectiveness of their proposed architecture.",
    "Popular RL (both online and offline) algorithms iterate between two stages: policy evaluation where a Q-function: $S \\times A \\rightarrow \\mathbb{E} \\sum r$ is estimated and policy improvement where the policy $\\pi: S \\rightarrow A$ which maximizes the rewards is constructed. Typically, the stages are interleaved through the training process. The paper evaluates and argues for the idea of using, in the case of offline RL, only a single step of policy improvement after training Q-function to convergence.",
    "# Offline RL Without Off-Policy Evaluation  ## Summary  The paper examines an issue with existing offline RL methods and proposes a way to prevent the issue that leads to a strong family of baselines. The key idea is not to perform multiple steps of off-policy evaluation and improvement in offline RL.  In addition to providing evidence to the claim that one-step methods outperform multistep and iterative ones, the paper also provides explantion and a toy example that shed light on the issues faced by multistep and iterative offline RL methods. I believe these examples can be useful in the future as \"unit tests\" for new offline RL methods.  ## For the response  Could you please comment on Gulcehre et al. (https://arxiv.org/pdf/2103.09575.pdf) in relation to your work?   Please include a discussion of the broader societal impact of your work.",
    "The paper investigates the well-known 1-step heuristic for Q-function based offline RL methods. The method is evaluated for a model-free, Q-function based offline RL method on various benchmarks and the overall good performance of the approach is shown. The paper differs from results published in [1] mainly by the benchmarks used and the analysis of the reasons for the good performance.   [1] Gulcehre et al, Addressing Extrapolation Error in Deep Offline Reinforcement Learning, preprint 2021. ",
    "The authors study the notion of iterative policy improvement in offline reinforcement learning, notably finding that a single policy improvement step can outperform standard iterative benchmarks on the D4RL benchmark. To provide more insight on this, the authors also compare to an intermediate version, \u201cmulti-step\u201d, and analyze the performance of the three variants (one-step, multi-step, and iterative) with different regularization hyperparameters. They also show results for the MSE of the estimated Q function, as well as illustrate multi-step overestimation on Gridworld environments. Finally, the authors discuss when multi-step algorithms are better, namely when noise signal is low and more propagation of signal can help.",
    "This paper applies a simple baseline to the offline-RL paradigm. Rather than iterating through steps of policy evaluation and improvement as done by most current offline-RL algorithms, in this work the authors investigate the performance of one-step of constrained policy improvement on the D4RL benchmark. This simple baseline is shown to perform considerably well when compared to existing methods. The paper then claims that the reason for this is likely due to the deleterious effects of off-policy evaluation. A simple experiment of different algorithms shows that strong regularization against the behavior policy during learning can be crucial in the offline setting. The authors then analyze the potential pitfalls of off policy evaluation through simple analysis on an existing task and a convincing gridworld experiment. Finally the paper tries to shed some intuition as to when multi-step approaches may perform better than the one-step methods.  ",
    "This paper considers the problem of minimizing a non-smooth matrix function\u00a0 $f(X)$ over the spectrahedron $S_n$, i.e., positive semidefinite matrices with trace equal to 1. Such optimization problems often arise as the convex relaxation of various low-rank matrix recovery problems. In general solving these problems with projected subgradient descent requires a projection onto the spectraherdon at every iteration, which is expensive because of the need to compute a full SVD at every step.  Under the assumption that the non-smooth objective function $f(X)$ can be written as the pointwise maximum of a family of smooth functions,\u00a0 the authors reformulate the original optimization problem as a saddle point problem which can be solved via the projected extragradient method. The key contribution is that under a \u201cgeneralized strict complementarity\u201d condition and when close to the ground truth, the projection onto $S_n$ can be replaced by a low-rank projection. Therefore, the overall algorithm can be significantly more efficient, because only a low-rank SVD is needed.",
    "This paper develops an extragradient method for low-rank and nonsmooth matrix optimization problems. Under certain conditions, the proposed method converges to an optimal solution with rate O(1/t). Numerical experiments are provided to support the theoretical results.",
    "In this paper, motivated by a new efficient method in solving smooth low-rank matrix optimization problems, the authors propose to extend the method to nonsmooth problems. However, direct generalization is not possible, as is shown for a specific failure case. Thus, the authors propose to introduce some auxiliary parameters and transform the original nonsmooth problem to a smooth saddle-point problem. The authors then extend to the method of this new problem and derive a new algorithm that is suitable for the saddle-point problem. Theoretically, the authors proved the convergence of their proposed method. And empirical results verify the correctness of their proposed method.",
    "This paper studies the problem of minimizing a convex, non-smooth objective function of matrices with low-rank constraints. For the smooth counterpart of the same problem, it has been previously shown that SVDs computed during the iterations of algorithms such as projected sub-gradient descent can be replaced by low-rank SVDs, thus improving the computational complexity. This paper studies the conditions under which such a replacement can be used for non-smooth objective functions.   The main result of the paper consists of describing the class of non-smooth functions for which low-rank SVDs can be used. The paper proves theoretically and empirically that for non-smooth functions that have a saddle point structure (can be written as a sum of a smooth function and a point-wise maximum of affine functions), and when the initialization is within a certain radius w.r.t the ground truth, low0rank SVDs lead to the same solution as full SVDs and a O(1/t) convergence can be achieved.   Further, the paper also shows empirically that using low-rank SVDs on non-smooth objectives leads to the same solution as using full SVDs. ",
    "The paper considers a class of nonsmooth and low-rank matrix optimization problems. Major contributions include: (1) Discuss strict complementarity for nonsmooth problems and challenges of low-rank projected subgradient steps. (2) Under certain assumptions, a special type of nonsmooth problems can be reformulated as maximum of smooth ones and thereby a minimax form, and develop a projected extragradient method with low-rank projections. (3) Use the proposed method to solve several classical low-rank approximation problems in applications. ",
    "This paper proposed a CATE estimation approach when the treatment variable $T$ is a graph. Under a separable assumption (A3) between confounders $X$ and the treatment $T$ in the outcome structural equation ($Y$), Robinson's decomposition of CATE for binary $T$ can be applied. The performance of the authors' proposal was evaluated in both synthetic experiments and real data analysis.",
    "The paper proposed a CATE estimation method for graph-structured treatment by Robinson Decomposition. It is an extension of Robinson Decomposition, and the experiment shows the effectiveness of GIN on two small world datasets. The writing is good, but some contents are missing, so that the paper is not that easy to read. My detailed comments and concerns are described in the following.",
    "This paper proposes graph intervention network (GIN) to estimate conditional average causal effects when treatments are graph-structured. GIN builds on an extension of traditional Robinson decomposition to arbitrary treatment types. In particular, GIN factorizes the outcome Y into an inner product of two terms $g(X)^\\top h(T)$. During training, GIN first estimates a mean outcome model $m(X)$ and then estimate $g,h$ using the estimated $m(X)$ function. The method is evaluated on two datasets with synthetic outcome functions.",
    "The paper considers the problem of estimating conditional average treatment effect when the treatment is a graph. The paper generalizes the Robinson decomposition, adapts the R-learner to this graph-treatment setting and introduces a two-stage algorithm. The performance of the proposed algorithm is compared to a few benchmarks through numerical experiments. ",
    "This paper studies the estimation of conditional average treatment effect (CATE) with multiple treatments that are graph structured. The proposed method extends the R-learner (Nie and Wager, 2020), which is designed for binary treatment, by learning a representation that reduces the dimension of the treatments. The representation is parametrized by a graph neural network that takes the graph structure into account. Unlike the standard R-learner that learns the nuisance components $E[Y|X]$ and $E[T|X]$ separately from the CATE, the proposed method only estimates $E[Y|X]$ separately while learns the representation $h(T)$, the propensity features $E[h(T)|X]$, and CATE jointly via gradient-based methods. ",
    "This paper considers causal inference in the discrete case, where probability axioms can be represented with matrix equations. Specifically, the paper characterizes the relationships between certain graphically driven formulae and matrix multiplications. With such characterizations, the authors then broaden the spectrum of proxy variable-based identification conditions and further propose novel intermediary criteria based on the pseudoinverse of a matrix. ",
    "This paper presents a synthesis between literatures on using matrix equations to characterize causal effect identifiability, and using proxies/surrogates to obtain identifiability when the effect of interest is not identifiable using the canonical ID algorithm. The authors highlight examples of identifiability under the various identification paradigms. They then describe notation used for their synthesis and highlight how it applies to each of the known cases. The main results entail an algorithm for determining identification of a broad class of effects via the matrix equations paradigm. The authors show that some key existing results, which had been proven sound, are not complete and show that their approach, while not yet proven complete, generalizes the existing approaches for the literatures studied.",
    "Two primary methods exist for graph based identification. The first relies only on the assumptions in the graph while the second exploits assumptions  between unobserved confounders and the observable variables via proxy variables. This paper develops a new approach by combining both these methods. The new approach thus developed is able to solve problems that are not solvable by any of the methods alone. ",
    "This paper considers the causal effect identification problem, and proposes an approach making use of both graphical criteria and matrix equations. More precisely, the authors connect the graphical and matrical approaches by characterizing matrix equations of probability distributions driven by graphical constraints in a causal graph. Building on this new characterization, the authors generalize proxy-based criteria and devise novel intermediary pseudoinverse criteria so as to identify a causal effect by utilizing the general inverse of a matrix and diverse collection of distributions.",
    "This paper provides a graphical identification approach that combines both graphical and matrical approaches. In particular, they apply certain matrix chain-rule and inversion criteria, previously used in for example certain proxy-based approaches, to a matrix version of the C-factorization to arrive at a new causal effect identification algorithm. They show that their algorithm applies to cases that could not be identified with certain previous algorithms and thereby rendering them incomplete. ",
    "This paper proposes to theoretical analysis of the Prioritized Level Replay (PLR) from prior work and proposes an environment generation framework named Dual Curriculum Design (DCD). The proposed framework is composed of teacher agents that keep generating new environments and a student agent that learns to solve the generated environments. The teacher agents are co-adapted to generate new environments by maximizing the student's agent's regret. In a grid world domain and the CarRacing domain, the proposed method outperforms previous baselines such as PAIRD.",
    "This paper studies the problem of automatically designing a distribution of environments that adjusts to the learning agent, called unsupervised environment design. Specifically, they propose Dual Curriculum Design in which two co-evolving teachers, i.e. one is a generator and another one is a replay teacher, introduce new levels/environments to the learning agent (a.k.a student) to learn a policy that can be effectively generalized to new and unseen environments. Besides, this paper proposes a new theory about PLR and REPAIRED robustness guarantees. The paper evaluates zero-shot generalization, emergent complexity, and scalability of their proposed method in multiple environments and scenarios.",
    "This paper considers a recent proposed problem, unsupervised environment design, that provides an environment selection scheme to enable the policy being trained under a curriculum learning setting. The proposed method combines two new approaches in this direction, PAIRED and PLR, where the former one learns to generate an environment while the latter one does not include a generator but instead gives a sampling scheme to choose previously encountered environments. The combined method is explained as a two-teacher dual curriculum game and explained theoretically. Experiments demonstrate the effectiveness of the combined method compared to PAIRED and PLR, respectively.",
    "This paper considers two forms of curriculum design, unsupervised environment design and prioritized experience replay, and highlight their complementary nature. It then considers the games induced by both these approaches and combines them into a dual curriculum game where the agent faces one teacher or the other with certain probability. Further, the paper analyzes the equilibria of this joint game and the equilibria of the two component games.  The paper then proposes two new algorithms, a robust version of PLR that does not learn on experienced trajectories but only on trajectories sampled by the PLR teacher, and a replay-enhanced PAIRED that improves the UED technique with PLR.  The various approaches are then compared on mazes and car racing domains.",
    "In this paper, the authors propose a common framework,  Dual Curriculum Design, that augments\u00a0PAIRED with a PLR-based replay mechanism, named as REPAIRED. The theory also suggests convergence to Nash Equilibrium should be assisted by training on fewer data when using PLR\u2014namely by only taking policy-gradient updates from data that originates from the PLR buffer, and only using samples from the environment distribution to populate the buffer. The authors further conducted experiments on a maze environment and on car-racing tracks. Results showed that the proposed approaches outperformed the PLR and other baselines in general.",
    "This paper studies the problem of multi-armed bandits under the shuffled model of DP. The authors provide two algorithms, one of which almost matches the regret of the best known algorithms for the centralized model. To do so, they give a variant of the arm elimination algorithm that leverages the private summation algorithm by Cheu et al. [9] and uses exponentially growing batches. ",
    "The paper proposes a shuffle model of DP for multi-armed bandits. The paper proposes two algorithms, SDP-AE and VB-SDP-AE, for bandits with shuffle DP and Bernoulli rewards. Distribution-dependent and independent regret bounds are derived for both the algorithms. VB-SDP-AE achieves additive regret due to privacy which has same order of dependence on $\\epsilon$ but logarithmically worse dependence on $T$ than centralised DP.",
    "This paper studies the multi-armed bandit problem under the constraint of approximate differential privacy. Previously, multi-armed bandits have been studied in other models of privacy such as the centralized pure DP model, the centralized approximate DP model, and the local pure DP model. However, this is the first work to consider the multi-armed bandit problem under the shuffle model of privacy.  To be clear, the model that the authors consider is as follows. At each round $t$, a batch of $m$ random users are selected. An action (e.g. an ad) is then selected for each user. The reward for each user is then presented to a shuffle DP mechanism.  In terms of results, the authors prove a regret bound which is slightly weaker than the result one can obtain in the central DP model but significantly stronger than the result one can obtain the local DP model. In particular, it removes a multiplicative $1/\\epsilon^2$ dependence that appears in the regret bound for the local DP model.  In terms of techniques, the authors combine some ideas from the bandit literature and the differential privacy literature. In particular, their algorithms are based on the non-private arm elimination algorithm and they show how one can use private binary summation from the shuffle DP literature to obtain a shuffle DP algorithm for MAB. The authors also give two differential algorithms. The first algorithm uses static batch sizes in each round. The second algorithm uses dynamic batch sizes and they show that this improves the regret.",
    "This paper adapts the shuffle model of differential privacy to the multi-armed bandit setting, and aims to design a bandit algorithm which has privacy guarantees similar to that in the local model, while simultaneously having regret guarantees similar to the central DP model. The authors propose two arm-elimination style algorithms, which uses a private binary summation mechanism with optimal error guarantees as a subroutine, in order to obtain improved regret guarantees over the local model. In particular, they show how a simple, constant batch size policy already gets rid of the multiplicative dependence on $1/\\epsilon^2$. Then, they show how to adapt this policy to exponentially increasing batch sizes, improving the additive dependence from $\\approx k/\\epsilon^2$ to $\\approx k/\\epsilon$. ",
    "The paper studies the classic multi-armed bandit problem in the shuffled model of differential privacy. Paper's first contribution is the definition of shuffled differential privacy (SDP) in the multi-armed bandit setting.  The paper's main contribution is an SDP algorithm with the same regret guarantees as the best-known multi-armed bandit algorithm in the central privacy model.",
    "This work applies the concept of calibrated regression into a decision making framework where the decision is confined to threshold decisions. The Bayes optimal decision w.r.t. the predicted distribution is derived, and the concept of threshold calibration is defined. Threshold calibration is a sufficient and necessary condition for the reliability gap to be 0, meaning the absolute difference between the predicted expected loss and the true expected loss is 0 for a given decision rule. Further, a simple algorithm is proposed which threshold recalibrates a distributional prediction. ",
    "As pointed out by the paper, threshold calibration is related with practical hospital scheduling problem, in which hospital needs to make the decision to acquire new patients based on predicted length-of-stay to the existing patients. The paper proposed an efficient and practical threshold calibration method, which calibrated the non-calibrated results based on CDF prediction, and is shown to have better calibration results as compared to average calibration and distribution calibration.  Additionally, the paper proposed an algorithm to do threshold calibration, and empirical results on real data sets shows reduced reliability gap and true decision loss. ",
    "This paper considers the problem of calibrating the conditional CDFs from a regression model.    The authors propose a new definition of threshold calibration, which requires the conditional CDFs to have calibrated quantiles when these CDFs have a $\\alpha$-quantile that are all on the same side regarding a given $y_0$ (either above or below).    The proposed definition is a stronger notion of quantile calibration in regression (called averaged calibration in this paper), and a weaker notion of distribution calibration in regression. To further justify the proposed definition, the authors consider measuring the so-called reliability gap, which is based on a given loss function and the corresponding decision rule. The authors then show that having threshold-calibrated results can ensure a 0 reliability gap. The necessity and sufficiency among different calibration definitions are later demonstrated.  On the method level, the proposed approach is hence to iteratively search for quantile levels and thresholds with large calibration errors and applies isotonic regression to calibrate the corresponding quantiles. The final calibrated model will include the uncalibrated models and a sequence of calibration maps.  Experiments are performed with real datasets with a cost-sensitive setup. The proposed method is compared with uncalibrated model, quantile calibrated model and distribution calibrated model.  ",
    "This paper discusses calibrated regression from a decision-making perspective, by introducing the concept of 'threshold calibration'. The popular notion of calibrated regression, average calibration, is insufficient for decision-making. On the other hand, the notion of distribution calibration is sufficient for decision-making, but may be difficult to achieve. In practice, decisions based on regression predictions are often made on the basis of whether the prediction is smaller or larger than some threshold. Thus, a decision-oriented goal is to ensure calibration with respect to such a threshold, called threshold calibration. The paper proposes an algorithm to achieve threshold calibration. ",
    "This paper focuses on the task of \"calibrating\" forecasts used in downstream decision-making tasks to ensure accurate estimation of the loss or \"cost\" of using each decision rule (i.e. the decision loss). The paper is specifically focused on forecasts of real-valued quantities (regression) and binary decisions (or actions) made by thresholding the forecast (for example, deciding whether to accept or reject a new patient based on the forecasted length of stay of a current patient being above or below some threshold).  In this setting, the paper shows that average calibration -- a common type of calibration -- does not ensure accurate estimation of the decision loss. The paper then introduces threshold calibration, proves that threshold-calibrated forecasts maximize the accuracy of decision loss estimates (and, moreover, that threshold-calibration is necessary and sufficient to maximize this accuracy), and provides an efficient algorithm to generate threshold-calibrated forecasts from a finite data sample. The paper validates the performance of their algorithm on real-world data (although with a synthetic downstream decision-making setup), and demonstrates more accurate decision loss estimates than those obtained by average and distribution calibration. The paper also derives the relationship between distribution, threshold, and average calibration in Proposition 1, which may be of independent interest.",
    "This paper proposes a method called Argmax Centroids for learning an approximation to the distribution of the minimizer of a random function. The central idea is to learn a set a particles such that the expected distance between the minimizer of a randomly drawn function and the closest particle is small. The method is shown to be connected theoretically to Wasserstein distance. Experiments on few-shot classification, personalized dialogue modeling, and multi-target domain adaptation demonstrate improvements when the technique is applied to baseline models.",
    "This paper proposes a natural and simple (yet general) method for approximating the argmax distribution through optimizing a set of centroid points. It is also shown theoretically that under suitable assumptions such an approximation minimizes a bound based on the Wasserstein distance with the actual argmax distribution. Extensive experimentation is carried to support the usefulness of the method. The data include a toy dataset, a few shot learning task, a dialogue system task and a domain adaptation task.",
    "The paper proposed a method that optimizes a set of centroid points that approximates the argmax distribution p*. Rather than using the Monte Carlo sampling that draws samples randomly, their approach choose the location of each points that approximate target distribution p*.  This approach can be an alternative for bootstrap and can be applied to deep learning applications. The paper showed the effectiveness of the proposed method on few shot image classification, personalized dialogue systems and multi-target domain adaptation. The proposed algorithm boosts the SOTA performance for few-shot classification and meta learning tasks.  ",
    "   This paper proposes optimizing centroid points to compactly approximate the argmax distribution with a simple objective function. The proposed method is theoretically minimizing a bound of Wasserstein distance between the empirical distribution of the centroids and the ground-truth distribution. Argmax centroids have many applications for machine learning tasks; the author validates the proposed method on multiple meta-learning and mult-task learning tasks.  ",
    "The paper proposes a generic method for approximating the argmax distribution of a random function using optimized centroids without explicitly sampling from the argmax distribution. While the closest application for the method is in meta-learning and multi-task learning, the proposed method can find application as an alternative to bootstrap among other applications. In short, for a random function $f_\\xi(\\theta)$ (think of $\\xi$ as data, $\\theta$ as parameters, and $f_\\xi(\\theta)$ as the loss function), the method finds a set of parameters $\\boldsymbol{\\theta}:=\\\\{ \\theta_i\\\\}_{i=1}^n$  such that it minimizes  $E_\\{\\xi\\sim\\pi\\}\\[ min_\\{i\\in\\\\{1,...,n\\\\}\\} f_\\xi(\\theta_i)\\]$. During inference and for a new task, the authors first find the appropriate parameters for the task (based on a validation set) from the set $\\boldsymbol{\\theta}$ and then use the corresponding model to solve the task. The method is shown to minimize a bound in Wasserstein distance between the approximated argmax distribution and the real distribution. Finally, the authors show the method's superior performance in various numerical experiments spanning few-shot supervised learning, personalized dialogue systems, and multi-target domain adaptation compared to various baselines. ",
    "This paper investigates multi-objective reinforcement learning (MORL) in the online setting and the so-called preference-free setting, where the preference vector is given by an adversary. It proposes a model-based algorithms for each setting under tabular episodic MDPs, respectively. Both algorithms are shown to attain nearly optimal regret or sample complexity bound.  ",
    "The authors propose to study an multi-objective RL in an online, episodic and tabular setting. In each episode, there is an adversarial chosen weight vector $w^k$  revealed to the agent, whose aim is to achieve a sublinear-time regret compared to an oracle who uses the optimal policy every episode. The authors propose the MO-UCBVI algorithm, which incorporate the adversarial chosen weight vectors with the learning approach by the classical UCBVI. Then the authors harness their framework on a recent proposed reward-free exploration problem, and they show that their algorithm's performance is superior to the state-of-the-art.",
    " This paper studies the multi-objective reinforcement learning (MORL) problem where the reward function is an inner product of two d-dimensional vectors, an objective vector and a preference vector. Two algorithms have been proposed for known and not known preference vectors. Both algorithms are proved to achieve sub-linear regrets.",
    "This work studies the multi-objective RL (MORL) with unknown transition, where the reward function can be parameterized with d-dimensional preference vectors. In the beginning of each episode, an adversary selects the weight vector and reveals it to the learner, the learner then selects corresponding policy and suffers a regret comparing with the optimal policies with respect to the given preference vector.   Besides this online MORL setting, the authors further study a preference-free exploration (PFE) setting where the learner manually separates the learning and planning phases and her performance is measured by the number of samples that are required to ensure PAC-bound. Then, the authors introduce a lower bound for PFE, which shows there is only an H factor loose. ",
    "This paper tackles the reinforcement learning problem in a multi-objective and online setting. Two different cases are considered: (i) when preferences over the multiple objectives are given at the start of each episode and (ii) when preferences are unknown and the environment needs to be explored in preparation for any arbitrary preferences. For both cases, the paper proposes optimal solutions (up to logarithmic factors, and a factor of $H$ in the second case).",
    "This paper proposes a model-agnostic explanations model, local explanation of response generation (LERG), for dialogue response generation task. Due to the sequence-to-sequence natrual, previous works, which normal produces a single label as output, are no longer suitable for this task. This paper regards the explanations as the mutual interaction of segments in input and output sentences. Specifically, it views the sequence prediction as uncertainty estimation of a human response and creates explanations by perturbing the input and calculating the certainty change over the human response. The experiment shows that the proposed approach extract both explicit and implicit relations between input and output segments.",
    "This paper studies the model-agnostic explanations of dialogue response generation and proposes a new called local explanation of response generation (LERG). LERG extracts the sorted importance scores of every input-output segment pair from a dialogue response generation model. It views the sequence prediction as uncertainty estimation of a human response and creates explanations by perturbing the input and calculating the certainty change over the human response. The authors show the proposed LERG adhere to three properties of  an ideal explanation of text generation: (1) unbiased approximation, (2) intra-response consistency and (3) causal cause identification. The experiments on a popular benchmark DailyDialog empirically verify the effectiveness of the proposed approach.",
    "This work proposes a method to locally explain the dialog response generation process. This method is motivated by the intuition that, such method should answer the question \"which parts of the response are influenced the most by parts of the prompt\". So the importance scores of every input-output segment pairs are calculated. They also proposed two metrics to evaluate explanations: \"necessity\" and \"sufficiency\". The former is defined as the perplexity change after removing top \"salient\" input features, and the latter is defined based on the intuition a complete explanation should recover model's prediction without the original input.",
    "The authors propose a method for \u201cexplaining\u201d dialogue responses from sequence generation models; that is, determining what parts of the input influence or \u201cexplain\u201d certain elements of the output. The method, LERG, is \u201clearned\u201d in one of two ways to assign a score for each input/output token pair indicating the measure of relevance, and ultimately to link the intent between the two. The authors propose that their method must satisfy three properties: unbiased approximation (LERG should explain benefits of picking response given the context); consistency (LERG should explain each generation step); and cause identification (LERG should sort input features by importance). The authors measure the effectiveness of the proposed method in both automatic evaluations and user studies. The automatic evaluations measure the **necessity** and **sufficiency** of the explained segments of the input text by capturing the model perplexity difference when stripping the segments and only including the segments, respectively, essentially measuring how accurate the method\u2019s explanations are at capturing the relevant segments of the input context. Human evaluations display the segments to humans and ask if they can predict the gold response. Both evaluations show their explanation method significantly outperform both random baselines and other methods from the literature.",
    "The paper addresses the local explanation of sequence generation models, specifically under the dialogue response generation setting, and proposes local explanation of response generation (LERG) that computes the mutual interactions between input and output sequences under perturbations as the explanations. Automatic and human evaluations show that LERG is more effective than other baselines.  Contributions:  1. A new local explanation method for dialogue response generation 2. Such an explanation method could be generalized to other generation models as well 3.  A systematic framework to evaluate the dialogue model explanation quality involving both automatic evaluations and human studies.",
    "The authors consider accelerated training algorithms using gradient compression with error compensation. For this purpose, they incorporated gradient compression and error compensation in the Katyusha algorithm and developed ECKL. The algorithm quantizes both the SG and VR term and keeps track of the quantization error for error compensation in the next iteration.  The paper analyzed the convergence rate and iteration complexity of ECKL for the smooth convex functions and compared it with variants of DIANA both theoretically and via some simple simulations on logistic regression.",
    "The paper introduces an error compensation variant of the loopless Katyusha, ECLK. Theoretical convergence analysis is given and accelerated linear convergence rate is obtained using contraction operators. Experimental study of ECLK is given on the logistic regression problem for binary classification.",
    "This paper presents accelerated methods for communication-efficient learning applications. In particular, a loopless Katyusha strategy is introduced to attain the O(\\sqrt{L/\\mu}) rate for error-compensated methods using stochastic gradient information. These methods are called ECLK. In terms of theoretical iteration complexity and empirical experiments, ECLK is explicitly shown to be more communication efficient and to have a better rate than existing error compensation methods.",
    "This paper proposed an error compensated based Katyusha method for finite-sum convex problems. The proposed method achieves the same asymptotic convergence rate as its full precision accelerated counterpart. Compared to another related work ADIANA, the proposed method can be applied to contractive compressor. ",
    "This paper considers communication efficient algorithms for SGD. In this model, there are $n$ total workers and each worker has a local smooth convex loss function $f_i$ on $R^d$. The objective is for a coordinator to find an approximate global minimum for an objective function that represents the average loss across all workers while minimizing communication between the workers and the coordinator.   A common approach is for each worker to compute a sketch on their local batch of gradients that allows the coordinator to recover of the top $k$ gradients in magnitude, ideally improving the rate of convergence. However, the challenge with this approach is that the estimator formed by the coordinator using the sketches sent from the workers may not be an unbiased estimator of the overall gradient, which allows error to accumulate over multiple iterations. This paper introduces provable accelerated gradient-methods, in the sense of Nesterov momentum for contractive compressors, which are a general class of stochastic functions that form estimators of the gradient, including the top $k$ estimator. ",
    "Liquid State Machines (LSM)  circumvents the need for backpropagation and allows the training of recurrent neural networks by local plasticity in the readout weights. Previous studies have shown that optimal performance is achieved near a critical phase transition of the reservoir (the liquid). However, the exact parameters of the critical phase transition in the liquid vary and depend on the input. In this work, the authors present a biologically inspired model that allows self-organization near the critical transition. Here, the authors propose a biologically inspired model in which the liquid self-organizes near the critical point. The model is composed of a reservoir of integrate-and-fire neurons. The synaptic efficacies within have unsupervised spike-time dependent plasticity (STDP). The authors propose an additional dynamical variable akin to the activity of astrocytes in the circuit, which modifies the STDP learning rates. The model self-organizes close to the critical point. The authors train several networks on the MNIST and N-MNIST dataset (a spiking version of MNIST, made for neuromorphic computing). They show that the SLM model with astrocyte-dependent STDP plasticity outperforms other LSM models.",
    "The authors propose of a way modulating the connections in a liquid state machine (LSM) so that it moves towards the edge of chaos (EOC) to maximize its performance for various tasks. They do this using by introducing an additional \"astrocyte\" that modulates the parameters of STDP in the neuron model -- specifically the depression term. The authors compare their model to other forms of LSMs. ",
    "This paper extends liquid state machine (LSM) with a biologically inspired astrocyte model (NALSM) to optimize the neuronal dynamics in LSM at the edge-of-chaos, to improve the accuracy and stability of LSMs. With NALSM, the spiking model can maintain a high accuracy without re-tuning parameters for different datasets. Experiments with MNIST and N-MNIST dataset demonstrate that NALSM outperforms classic LSM and other STDP-based LSM approaches, and most existing spiking neuron models including multi-layer SNNs.",
    "This paper presents a novel type of liquid state machine - neuron-astrocyte liquid state machine (NALSM), which introduces feedback from the network activity to the synaptic plasticity. The proposed mechanism helps to position the liquid (reservoir) layer in the edge-of-chaos dynamics regime, a known key factor to achieve good computational performance. The main contribution of this paper is transforming a biological observation (the role played by astrocytes for modulating the synaptic plasticity) into a novel idea of modulating the liquid activity. It uses feedbacks to obtain edge-of-chaos property in liquid state machine (LSM), and further showing meaningful improvement over the previously proposed LSM-based methods for real-world tasks.",
    "The paper proposes a new version of LSM by adding a factor intended to mimic a proposed role for astrocytes: modulating STDP. The effect is homeostatic in nature and works to keep the network in a computationally efficient regime. It works. The result is a higher performance on MNIST and N-MNIST data sets. ",
    "The paper studied the problem of imbalanced classification on graphs, by proposing to unify the quantity imbalance and topology imbalance together. The authors develop a label propagation algorithm that locates the topological position of the labeled nodes, and then re-weight nodes to alleviate the imbalanced data distribution. Experimental results on various benchmark datasets show the performance of the proposed model. ",
    "This paper first points out the topology-imbalance problem of node representation learning on graph-structured data. To address the problem (which is denoted as Topology-Imbalance Node Representation Learning, TINL), this paper presents a conflict detection-based metric (named Totoro) based on label propagation algorithm and Personalized PageRank matrix. Then, the authors introduce the ReNode algorithm that considers the Totoro of each node in semi-supervised training of GNN models. The ample experimental results show the superiority of ReNode in addressing the TINL problem. ",
    " The issue of imbalance is a very critical problem in ML, especially in a realistic setting. In general, imbalance is quantitative, but this paper points out topological imbalance as a graph-specific problem. As a solution to topological imbalance, a method of reweighting called ReNode is proposed and its effectiveness is verified.",
    "The authors concerns the topological imbalance problem in node classification problem. The imbalance caused by  asymmetric topological structure during the semi-supervised learning process. The authors introduces the intuition with classical label propagation problem and extended it to the case of learning GNN. To alleviate the pain of the imbalance issue the author introduced the Node reweighting loss, which puts more effort on learning with nodes that have less distance weighted conflicts.   ",
    "Authors study a problem named topology imbalance which is led from the topological difference of labelled nodes in a given graph. It degrades the performance of node classifiers by 'shifting' the decision boundary. The main contributions of this paper are (1) it points out the topology imbalance problem in node classification tasks; (2) it proposes a metric (Totoro) to measure the topology imbalance; (3) it designs an annealing method to reweight samples based on their topological importance; (4) authors provide vast experimental results over multiple scenarios, datasets, and baselines.",
    "This paper studies a problem called lattice partition recovery, where piecewise constant signals over a d-dimensional lattice are corrupted by noise and require to be recovered. A method called dyadic classification and regression tree (DCART) is studied. It is shown that DCART achieves one-sided consistency, but suffers from over-partitioning. To achieve partition recovery, this paper proposes an additional merging stage, where dyadic rectangles that are close are merged. This is shown to achieve partition recovery under mild conditions. A minimax lower bound is also given, and numerical experiments are shown to support the methodology.",
    "This paper considers a piecewise constant signal on a $d$-dimensional lattice. The observed signal is corrupted by additive Gaussian noise. The task is to recover the partition of the lattice such that the signal within a partition is constant. The paper proposes an algorithm that builds upon the scalable DCART algorithm.  The contributions of the paper are threefold:  (i)\tThe authors first analyze the performance of the vanilla DCART algorithm to recover the partitions. They prove the one-sided consistency of the vanilla DCART algorithm. One-sided consistency guarantees that the recovered partitions have large subsets which have constant signal, but a partition of the ground truth signal could potentially be over-partitioned by the DCART algorithm. They demonstrate by an example that it is indeed the case.  (ii)\tIn order to address the issue of over-partitioning, the authors propose a two-step algorithm where the first step is the vanilla DCART algorithm while restricting to partitions with size above a threshold. In the second step, the partitions which are close and whose signals have a small difference are merged. They prove that this estimator is consistent.  (iii)\tThey prove that the proposed 2 step estimator is minimax optimal if the number of partitions is constant. Finally, they demonstrate the efficacy of their algorithm by simulations. ",
    "The authors consider the problem of recovering the partition underlying a piecewise constant function over a $d$-dimensional lattice, _i.e._, a signal with support $L_{d,n} = \\lbrace 1, \\dots, n\\rbrace^d$. That is, we wish to recover the structure such that within each rectangular partition of the lattice, the function $\\theta^* \\in \\mathbb{R}^{L_{d,n}}$ is piecewise constant, from noisy measurements ${y_i = \\theta_{i}^* + \\epsilon_i}$ for $i \\in L_{d,n}$ where $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$ i.i.d. A straightforward formulation would be NP-hard, so they the consider the dyadic CART (DCART) algorithm, which simplifies the search space by restricting it to partitions that can be formed by repeated bisections of partitions, starting with a single partition containing all $N = n^d$ points in the lattice.  The authors provide a number of bounds of the form $\\sigma^2 k_{\\mathrm{dyad}}(\\theta^*) \\log(N) / \\kappa^2$, where $\\kappa$ is the minimum jump size (difference between signal in adjacent partitions) of $\\theta^*$. First, they show that using DCART, the number of lattice points in recovered partitions where the true signal is not actually piecewise constant scales at most with the above expression (\"one-sided consistency\"). They then propose a two-step estimator that adds a step merging rectangles in recovered partitions whose measurements are \"close\" to each other, and show that under certain assumptions, the Hausdorff distance between the recovered (estimated) partition and the actual partition (accounting for the need to merge rectangles to assure definitional uniqueness) scales at most with the above expression. Finally, they provide a simple example to demonstrate an order-matching lower bound.",
    "In this work the authors consider the problem of learning the partition of a piecewise constant signal supported on a $d$-dimensional lattice $\\{1, \\ldots, n\\}^d$.  They assume access to a noisy signal $y = \\theta^\\ast + \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I)$ is a Gaussian noise vector and $\\theta^\\ast$ is the true signal that is assumed to be piecewise constant over a rectangular partition of the latice.  The goal is to recover the underlying partition.  This work focuses on the performance of (variants of) the Dyadic CART (DCART) algorithm for the task of partition recovery.  Prior work [1] has shown that the DCART estimator achieves the optimal error for the task of recovering the true signal $\\theta^\\ast$.  The authors argue that the partition produced by the vanilla DCART algorithm may contain a large number of rectangles.  However, they show that inside each rectangle of the partition of the vanilla DCART, the signal is indeed almost constant.  The second result of this work proposes simple modifications for DCART so that the corresponding partition is close to the true underlying partition.  In particular they enforce a lower bound on the size of the rectangles of DCART and, at the end, merge cells that are close and have similar value.  They show that the modified DCART algorithm outputs a partition at distance roughly $\\sigma^2 k^\\ast \\log(N) / \\kappa^2$, where $N = n^d$ is the size of the grid, $\\kappa$ is the minimum signal difference between contiguous cells of the true signal, and $k^\\ast$ is the minimum number of dyadic cells required to create a partition consistent with the true signal.  The authors show a lower bound of $\\sigma^2 \\log(N)/\\kappa^2$ for the error. Therefore, their upper and lower bounds differ by a factor of $k^\\ast$.  Finally, the authors are able to remove the extraneous factor $k^\\ast$ under the additional assumption that the underlying partition is not very dense, i.e., around every rectangle of the true underlying partition there are not many other rectangles.   [1]: Sabyasachi Chatterjee and Subhajit Goswami Adaptive estimation of multivariate piecewise polynomials and bounded variation functions by optimal decision trees",
    "This article investigates the problem of the recovery of constancy regions of a noisy high dimensional piecewise constant signal. The authors proposed to use the DCART estimator to build up a rectangular partition and proved a weak consistency result. Then, they proposed a two steps estimator based on an appropriate merging of the rectangles that DCART output. For this variant (DCARTAM), they proved consistency: the estimator converges to the ground truth partition in the sense of Hausdorff (after an appropriate normalization by the number of rectangles in the partitions).\u00a0 Finally, DCART and DCARTAM were compared to the TV-based estimator empirically using two metrics. The first one is the Hausdorff distance between the estimator and the ground truth partition, and the second one is the difference between the cardinality of the estimator and the cardinality of the ground truth partition. Visually, DCARTAM seems to be superior to DCART. Moreover, DCARTAM seems to be superior to the TV-based estimator using the second distance, yet it does not show a systematic superiority if the first distance was used.",
    "The paper tackles the problem of spurious correlations caused by observed confounders and offers two potential solutions: implicit and explicit counterfactual maximum likelihood estimation. Specifically the paper deals with the setup of predicting the outcome Y of some action T on X and considers X to potentially be a confounder. The paper compares the performance of the proposed methods to on a natural language inference and an image captioning task and shows improvements in terms of human evaluation but little difference in terms of automatic evaluation.",
    "This work proposes counterfactual maximum likelihood estimation (CMLE), a new training objective for suppressing the spurious effect of confounding variables. The authors derive two types of upperbound formulation for interventional log-likelihood (i.e. implicit CMLE and explicit CMLE). Using natural language inference (NLI) and image captioning as the intervention modeling tasks, the proposed method demonstrated superior performance in terms of human-perceived performance.",
    "This paper applies methodology from CATE estimation to do maximum likelihood with respect to samples from the interventional distributions Y|do(T),X, which they call Counterfactual MLE (CMLE). They provide two algorithms, Implicit CMLE and Explicit CMLE. The implicit variant uses the CATE generalization bounds from Shalit's CATE generalization bounds paper to get bounds on the likelihood from the desired counterfactual sampling distribution. The Explicit variant writes bounds in terms of the distribution T|Y,X. The two methods are applied to natural language inference and image captioning tasks. The authors suggest that this methodology and the surrounding literature on causally-inspired prediction should play a large role in the standard approach of deep learning in order to avoid shortcut learning / relying on spurious correlations.",
    "In this work, authors propose the Counterfactual Maximum Likelihood Objective CMLE, where the parameters of the statistical model are inferred by maximizing the likelihood of the data under the interventional distribution, as opposed to the observational data. For the assumed model X -> Y <- T and X -> T, where X is the covariate, T is the treatment and Y is the outcome, the objective is to learn the parameters \\theta that predict Y|X=x,T=t using just the causal link T->Y and not the spurious features in X=x. Ideally, if one could intervene on T and set do(T=t), it is possible to collect data where the outcome is observed upon the intervention done on T. Then maximizing the following likelihood: (CMLE objective) \\argmax_\\theta \\sum_t E_{X|t}  E_{Y|x,t} p_\\theta(Y|X=x,do(T=t)) would give us the MLE estimate of the parameter \\theta under the set of interventional distributions do(T=t), thereby eliminating any effect of the spurious features in X on the prediction of the outcome label Y. The paper proposes two upper bounds for the above CMLE objective: i) Implicit MLE: focuses on obtaining better representations of the covariates X, such that the distribution of these representations is similar (by Wasserstein distance) for every value of T; and ii) Explicit MLE: where counterfactual examples are generated during training. Expectations in the theoretical derivations of the above upper bounds, can be estimated by Monte Carlo evaluations using only the observational data. Results are provided on two downstream tasks where models often rely upon spurious correlations: i) Natural Language Inference (NLI); and ii) Image Captioning (IC).",
    "This paper proposed to use counterfactual maximum likelihood estimation to learn deep learning models that are less susceptible to spurious correlation relationships. In particular, it proposes two general algorithms, Implicit CMLE and Explicit CMLE, for learning causal predictions of DL models under observational data. The proposed method shows improvement over the regular MLE method in two real data sets.",
    "Authors propose a multitask learning approach to reduce gradient conflict by minimizing harm to the worst-performing task given any gradient update. Proofs are provided for convergence and pareto optimality of the resultant weight configuration. Experiments are run on a variety of settings, including computer vision and multitask reinforcement learning, with good results throughout. ",
    "Multi-task learning (MTL) is an efficient way of learning multiple tasks efficiently by training all tasks together, amortizing their cost by sharing some parameters across tasks. In order to perform this, a weighted sum of the task losses is usually optimized, which can lead to poor final results due to sub-optimal optimization, an effect produced by the competition between tasks for the shared resources. Specifically, when computing the gradient updates for the shared resources, gradients of different tasks can conflict with each other, cancelling each other out (an effect known as *conflicting gradients*).  This work introduces CAGrad, an algorithm which minimizes the average loss function (the network's loss), while maximizing the worst local improvement across all tasks, provably converging to a local minimum of the average loss. This algorithm results in a generalization of the usual gradient descent, as well as the MGDA algorithm. Empirical results show the effectiveness of the method.",
    "This work proposes a method to reduce conflicting gradients during training of multi-task learning paradigms via gradient modification. Rather than simply take an average of the per-task gradients, the authors propose to learn a model-wide gradient direction $d$ to update the shared parameters by solving a dual objective to find per-task loss weights. Simply, the proposed method (CAGrad) finds a direction which maximizes the worst local improvement among all tasks, and then applies this gradient update to the shared parameters. ",
    "This work presents a first-order multi-task learning method which uses, in place of the average task gradient, a vector which maximises the minimum local single-task improvement in a neighborhood of the average task gradient.  In multi-task learning, the goal is to find the optimal point achieving low losses across all tasks. However, gradient descent methods commonly used for single tasks in computer vision and reinforcement learning achieve suboptimal performance when applied on the average task loss due to conflicting gradients (single tasks gradients pointing in opposite directions). Recently, several methods have proposed modification to the update direction that alleviate this problem. However, these methods are either heuristics or can converge to any point in the pareto optimal set of the task losses (e.g. MGDA [5]), which might not be a minimum of the average task loss.   The proposed method, called Conflict-Averse Gradient descent (CAGrad), introduces an additional hyperparameter $c \\geq 0$ which allows to interpolate between gradient descent ($c = 0$) and MGDA ($c \\to \\infty$). Furthermore, CAGrad provably converges to a stationary point of the average task loss with the same rate as gradient descent (when $c < 1$) or to a pareto stationary point (when $c \\geq 0$). At each step of the method, the update direction is obtained by solving  an optimization problem in $K$ dimensions, where $K$ is the number of tasks, but has an overhead comparable to state of the art multi-task learning methods of the same kind (see last plot of Figure 5). Experiments on several computer vision and reinforcement learning multi-task benchmarks, where the method is used to optimize deep network parameters, show that the method achieves state of the art performance in all the settings. ",
    "The paper proposes a new solution to multi-task learning  that should improve in cases with gradients conflict of a task loss and the average loss gradient. The solution optimizes for an update vector that maximizes the worst task loss relative improvement. Experiments show the superiority of the proposed solution over similar prior methods. ",
    "This paper proposes to empirically investigate to what extent large language models like GPT-3 learn (or \"distill\") a simplicity prior, i.e., a prior that favors concepts with shorter description length. The authors investigate this by randomly choosing 8 concepts/programs in the P3 language whose total number of P3 instructions number from 1 to 8, respectively. Using the framework of Telle et al. (2019), the authors are able to determine the \"witness set,\" the minimal number of examples necessary for a learner with the correct simplicity prior to distinguish the intended concept from others. This witness set is fed to a learner, which is then evaluated on 5 randomly selected test examples of the concept. The authors also consider feeding additional sets of 2 and then 3 examples to the learner, each with its own random test set. The authors evaluate the accuracy of GPT learners, human learners, and 2 inductive program learners on these 3 test sets. They also elicit explanations from the learners.",
    "This paper empirically compares humans, language models, and inductive programming systems through the framework of machine teaching. Concepts and example sets are selected using a simplicity prior with reference to the P3 language. The main experiments present the example sets to the humans or machines and ask them to infer the corresponding concept. This setup leads to several experimental questions regarding the alignment between humans and the computational approaches and the extent to which language models like GPT have distilled a simplicity prior.",
    "This paper studies the type of patterns learned by large pre-trained language models (LMs) in a few-show setting. The authors differentiate between external patterns (e.g., common-sense or world-knowledge), and internal patterns, such as ABAB, and focus on the latter. They frame this as a teaching problem with strong priors, and study the size of the example set (number of shots in the few-shot setting) compared to the length of explanation that can be provided to the model in order to teach it the given pattern. The authors focus on the simplicity prior, and study whether it is implicitly encoded in such large models. Experiment that compare LMs, program induction systems and humans are performed. The main findings are that LMs perform as well as humans in few-shot settings, but the two populations differ in their ability to generate explanations.  I would say upfront that I am not an expert in this topic, and have found many points in the paper unclear, perhaps due to this. However, I wasn't fully convinced by the setup used by the authors. I am looking forward to the author response that might clarify some of these points. ",
    "This paper attempts to ask whether language models have a bias that allows them to learn from fewer examples in cases where a rule is simpler. They compare exploitation of rule simplicity in a variety of models, including human participants. This prior towards simplicity is most strongly observed in larger models, but the minimal example set is rarely enough to train any system, so with the exploitation of simplicity is not a perfect prior.  The paper also provides an analysis of the capability of these systems to provide explanations of the rule, but only humans and the algorithm that they specifically select for this purpose were capable of providing such explanations.",
    "In this paper, the authors compare the few-shot learning abilities of humans and GPT* language models (and inductive programming systems) from a machine teaching point of view. Models (and humans) are given a minimal witness set (examples using as few bits of information as possible) that should be sufficient to uniquely determine a program (function from a sequence of bits to another) under a pretty strict simplicity prior. The authors also examine whether additional examples (on top of the minimal witness set) help performance. They consider 8 different P3 programs of increasing complexity based on the number of operators. Examples are presented as English prompts.  The minimal witness set is often not sufficient for humans and LMs to generalize correctly. Nevertheless, there is some evidence that GPT models favor simplicity to some degree. Overall, larger GPT models generally perform better than smaller ones, but the correlation is not perfect. GPT-3 models often generalize better than the human candidates based on the few provided examples. However, humans sometimes provide acceptable explanations (for the shorter programs), but the authors could not get GPT models to explain their reasoning. ",
    "This study aims at distilling feature representations (mainly the last convolution layer) into robust and non-robust features using information bottleneck. For every layer, the feature maps are partitioned into robust and non-robust for each individual example. After finding this, the paper first illustrates that selectively propagating robust features of adversarial examples built for a robust network will not degrade the accuracy but propagating non-robust features does which to some extent illustrates that the information bottleneck method has correctly identified the robust and non robust features. They also illustrate that the adversarial class label has high correlation to the Non-robust features. ",
    "This paper categorizes the intermediate features of a DNN into robust ones and non-robust ones. Through visualization, the non-robust ones display different semantic information from the true label, and thus potentially leads to the existence of AE.  The paper proposes a new AE generation algorithm targeting the non-robust feature, and beats the common attack baselines.",
    "This work utilizes an Information Bottleneck (IB) to distill robust and non-robust features in neural networks (NNs). Experiments are performed to show that the distilled features are correlated with adversarial prediction and are human-perceptible. Finally, an attack mechanism intensifying the gradient of non-robust features is proposed.",
    "The paper proposes to explicitly separate intermediate representation into robust and non-robust categories by information bottleneck, and demonstrate that the non-robust feature is related to adversarial prediction. An attack mechanism based on enforcing non-robust features gradient is proposed. The experimental results show the effectiveness of the proposed approach. ",
    "This paper focuses on robust and non-robust features in adversarial examples. This paper proposes a method of distilling robust and non-robust features via information bottleneck. Through analysis, this paper has shown the high correlation between the distilled features and the adversarial prediction. Based on that, the authors design a new attack that intensifies the gradient of non-robust features.",
    "This paper explores the generality of support vector proliferation and makes the following three contributions: (1) proving a super-linear lower bound on the dimension (in terms of sample size) required for support vector proliferation in independent feature models. (2) identifying a sharp phase transition in Gaussian feature models. (3) investigating `the phenomenon of support vector proliferation for $\\ell_1$ variant of the SVM.",
    "The paper considers the conditions under which the solution to the classic, hard-margin SVM classifier collapses to the solution of the ordinary linear regression problem.  This is known as support vector proliferation and occurs when all training vectors for the SVM are support vectors.  SVP has been observed previously, and an upper bound placed on the dimension (relative to training set size) required to induce it given.  The paper further elaborates on these results, providing improved lower bounds on the dimension for which it occurs.  The transition region in which SVP occurs is characterised and it's width bounded.  Finally, the authors speculate as to the conditions required for SVP in the $\\ell_1$ variant of the SVM, and show experimentally that SVP appears to require much higher dimension for this case.",
    "This paper investigates the phenomenon of support vector proliferation (SVP), that is, when linear classification with minimum-$\\ell_p$-norm hard-margin SVM and minimum-$\\ell_p$-norm interpolation yield the same solution. A previous paper showed for $p=2$ that SVP occurs with high probability for certain distributions with (effective) input dimension $d = \\Omega(n \\log n)$, but not for $d = O(n)$. The authors close this gap by showing that SVP does not occur for $d = o(n \\log n)$. The authors further specify a more precise bound for standard Gaussian inputs and provide empirical evidence showing similar behavior for other distributions. Finally, the authors present some other theoretical and empirical results to illuminate the behavior for different $p$.",
    "This paper proves a super-linear lower bound on the dimension of support vector proliferation (SVP) when features are anisotropic subgaussians. The exact asymptotic threshold of the phase transition in the isotropic Gaussian distribution is also proved. Finally, this paper discussed the case of SVP phase transition for $\\ell_1$-SVMs. The experiments on synthetic data sets are also conducted.",
    "This manuscript investigates the phenomena of \\emph{Support Vector proliferation} (SVP) [1,2], in which all points in the training set $x_{i}\\in\\mathbb{R}^{d}$, $i=1,\\cdots, n$ become support vectors, i.e. satisfy $y_{i}\\hat{w}^{\\top}x_{i}=1$, where $\\hat{w}\\in\\mathbb{R}^{d}$ is the SVM estimator and $y_{i}\\in\\{-1,1\\}$ are the training labels. SVP implies that the SVM estimator coincides with interpolating least-norm linear regression, a fact which has been used in many recent works to study overparametrisation in generalised linear models. In particular, the authors focus in a data model defined by fixed labels $y_{i}$ and sub-Gaussian features $x_{i}$ with zero mean and diagonal covariance $\\lambda_{k}$, $k=1, \\cdots, d$ (i.e. the labels are independent of the features). The key results are:  - Different equivalent characterisations of SVP for generic $\\ell_{p}$, $1< p< \\infty$ norm SVM (proposition 1).   - Establishing a lower bound showing that one needs at least $d=n\\log{n}$ for SVP to occur in the anisotropic model defined above and $\\ell_{2}$-SVM  (Theorem 3). This result tightens the a previous bound from [2] (Theorem 1).  - Establishing a sharp transition at $d = 2n\\log{n}$ for SVP in the particular case of isotropic Gaussian data $x_{i}\\sim\\mathcal{N}(0,I_{d})$, also for $\\ell_{2}$-SVM (Theorem 4).  The authors also provide numerical simulations corroborating the theorems, and suggesting that their results apply beyond the theorem's assumptions. Finally, they also provide a conjecture for the equivalent result in the $\\ell_1$-SVM case.   [1] Vidya Muthukumar, Adhyyan Narang, Vignesh Subramanian, Mikhail Belkin, Daniel Hsu, and Anant Sahai. *Classification vs regression in overparameterized regimes: Does the loss function matter?*, 2020.  [2]: Daniel Hsu, Vidya Muthukumar, and Ji Xu. *On the proliferation of support vectors in high dimensions*.  In Twenty-Fourth International Conference on Artificial Intelligence and Statistics, 391 2021.",
    "This paper deals with online learning of policies for MDPs. Its main novelty is considering the \"navigation constraints\" related to this online setting where, in contrast with an episodic setting, the system must learn the policy in a single episode without being able to reset to an initial state. Bounds on sample complexity are derived and an algorithm for learning the best policy by exploiting the lower bounds is proposed.  ",
    "The paper studies the best policy identification (BPI) problem in Markov Decision Processes, under navigation constraints, i.e., when accessing a single trajectory from the environment, as opposed to the generative model setting. The paper focuses first on a lower bound on the sample complexity obtained by extending existing results. Then, an algorithm is introduced, and the corresponding sample complexity is analyzed. The contribution is mainly theoretical.",
    "The paper studies best-policy identification in discounted MDPs with online interaction. The authors first derive an information-theoretic lower bound on the sample complexity of any \\delta-correct algorithm for this problem. The lower bound is given as the solution to a non-convex optimization problem for which a convex relaxation is provided. The authors then design an algorithm using the standard template for building pure exploration strategies from asymptotic lower bounds (GLR test + tracking + forced exploration). For this algorithm, the authors derive an asymptotic (as \\delta -> 0) upper bound on the sample complexity that matches the value of the relaxed optimization problem up to a factor 2.",
    "The paper studies problem-dependent sample complexity bounds for best policy identification (BPI) in finite MDPs under the infinite horizon discounted criterion. The agent interacts sequentially (online) with the MDP, a weaker assumption than the generative model required by previous work in the same setting. Its main contributions are:  (i)  A problem-dependent lower bound on the sample complexity that takes into account navigation constraints;  (ii) Since the lower bound is defined as the solution to a non-convex optimization problem, the paper uses a convex relaxation introduced by [MP20] to derive a relaxed lower bound;  (iii) An algorithm whose upper bound matches the relaxed lower bound up to a factor 2. ",
    "This work talks about best policy identification problem in discounted infinite MDP. Instead of assuming a generator, this work is on the online setting of MDP, where the agent can only collect state action pairs through online interaction with the environment. In theory, the work provides a lower bound of the BPI problem. Then the work provides a model-based algorithm MDP-NaS, which is shown to converge to the optimal policy. ",
    "This paper represents a novel approach to learning embeddings for entities and relations from a knowledge base that are capable of directly encoding *reasoning* (i.e. FOL). The principal representation proposed for this representation is a *cone* (i.e. a set which is closed under multiplication by a positive scalar) which is motivated by the fact that cones are closed under intersection and complements. In practice, the authors use *sector cones*, which leads to some incongruity between the original motivation and the model in practice (eg. sector cones are not closed under intersection or union). Even so, the authors apply this embedding method to several standard logic embedding tasks and demonstrate significant performance improvements.",
    "A recent line of knowledge graph (KG) query systems \"compiles\" the query into an embedded representation, which is interpreted as a geometric region and then used to find response entities whose embedding representations are contained within the region.  Query2box is an early example, where the regions are multidimensional boxes or rectangles.  To be useful, the regions have to be simple, closed under query operators, and capable of being characterized using a few parameters.  Union (disjunction) and negation have therefore created problem for boxes.  This paper replaces boxes with a Cartesian space of cones in 2d.  By restricting the family of permitted cones and disjunction to the last step of any query, the authors argue that their cone family is closed under query operators.  Experiments with benchmarks that have a good diversity of query graph structures show promising results. ",
    "The paper proposes a new framework for embedding first-order logic (FOL) queries over knowledge bases using region-based embeddings. The embedding space is a Cartesian product of 2D cones. Entities are embedded in the same space with 0-aperture cones (ray starting at origin).  - Authors provide the relevant foundation to cones in 2D space, the final Cartesian product space, and suggest parameterizations of projection, intersection, union, and complement operations. - The choice of using cones facilitates complement operation. - Authors demonstrate empirical improvements over past work in FOL query embedding. - While the proposed cone-based region embeddings allow for clear descriptions for intersection, union, and complement, the implementation does not strictly enforce these geometric concepts.",
    "The paper presents a novel geometric embeddings called cone embeddings for solving query answering. Query answering requires embeddings of queries that are represented using first order logic. This includes conjunction, disjunction, negation but excluding Universal Quantification. Given this as basis, the related work until now has focused on two different types of embeddings (1) Geometric; and (2) probabilistic query based model. The progression from Geometric based embeddings to probabilistic models was primarily due to the fact that geometric embeddings cannot handle negation.",
    "The paper proposes a new embedding model for multi-hop reasoning over knowledge graphs. The idea is to embed a complex query as n arc segments each on a 1-sphere. The paper designs several neural logic operators including the intersection, projection and complement operators. For union, the model uses the DNF technique to reorder the operators so that the union operators always appear in the last step. The authors evaluate the model on standard benchmarks and achieve better results than prior methods.   Overall the paper is clean and easy to follow. A general question I have is that the current modeling is to embed the query into several independent arc segments. Have you tried to embed the query into the surface (sphere cap) of a n-sphere?  ",
    "This paper studies the problem of dynamic programming with continuous state and action spaces.  The authors first propose the VI which naively discretizes the state and action space and performs the classical value iteration. The authors use this method as a baseline for comparison with CVI developed in this paper.  Regarding the CVI, this algorithm performs VI in the the conjugate domain. In particular, by taking the dual of the objective function, we take the problem to the dual space. By doing so, instead of taking minimum over all the actions, the problem is reduced to a summation. Hence, the complexity of the CVI is better than the VI in the order of the cardinality of the action space.",
    "The authors consider value iteration [TJ](x) = min_u [c(x,u) + gamma E J(x\u2019)] for problems where the transition function and cost functions are additively separable: c(x,u)=c1(x)+c2(u) and x\u2019=f1(x)+f2(u) + w (Assumptions 3.1). Furthermore, f1(x) is Lipschitz continuous, f2(u) is linear, c1(x) is convex and Lipschitz continuous, and c2(u) is linear in u. The disturbance w has a finite support (Assumption 2.1). The state space for x and decision space for u are continuous. Thus, the authors consider problems such that [TJ](x) = c1(x) + min_u [c2(u) + gamma sum_i  p_i J(f1(x)+Bu+w_i)]. A problem that fits this description is the stabilization of an inverted pendulum with discretized disturbances, studied in Section 4. With this choice of assumptions, and assuming the value function is convex (which holds true if f1(x) is linear or linearized, that is, if x\u2019=Ax+Bu+w), convex duality can be applied to the minimization problem over (u,x\u201d) given x and subject to x\u201d=Ax+Bu, which gives another representation of the optimization problem, based on the convex conjugate of c1 and the convex conjugate of e(x\u201d)=gamma E J(x\u201d+w).  The authors propose and study an algorithm that relies on computing these convex conjugate functions numerically in order to provide an alternative way to the computation of the value function J. They establish error bounds (Theorem 3.13) in terms of theoretical quantities of the problem data.",
    "This paper presents a fast method for solving certain classes of optimal control problems, by implementing a value iteration (VI) algorithm that takes advantage of convex duality.  The basic idea is to take advantage of the fact that for two functions $f_1, f_2$, we have $(f_1 \\square f_2)^* = f_1^* + f_2^*$, where $f^*$ denotes the Legendre-Fenchel transform of $f$, and $(f_1 \\square f_2)(x) = \\inf \\\\{f_1(x_1) + f_2(x_2) : x_1 + x_2 = x \\\\} $ denotes the infimal convolution of $f_1, f_2$. Thus, the slow $\\inf$ operation can be replaced with a fast addition operation. The paper provides analyses of the convergence, time complexity, and error of the algorithm. When compared to a \"naive\" VI algorithm in which each iteration takes $O(X U)$ (where $X$, $U$ are the grid sizes of the state and input spaces, respectively), the algorithm presented in this paper can achieve $O(X+U)$. Finally, the paper provides a numerical example implemented in MATLAB.",
    "This paper proposed a new value iteration algorithm (CVI) for optimal control of stochastic system with continuous state space. The proposed algorithm discretizes the state space and performs the value iteration step in the \"conjugate domain\" to reduce one-step computational complexity. It was shown the proposed algorithm converges under conditions on the stochastic system, discretization, and etc. The proposed algorithm CVI, its variant CVI-d are compared to classical value iteration (VI) over a noisy inverted pendulum experiment.",
    "The paper develops an approximate value iteration method for an infinite-horizon, discounted-cost Markov Decision Processes (MDPs) that satisfy a given set of regulatory assumptions. The idea is to work on a dual space that replaces the DP value function by a reformulation written in terms of biconjugate operations. The authors present an algorithm that applies the conjugate operators iteratively, and present convergence and other structural results associated with the resulting errors. Numerical results compare the proposed approach against a traditional value iteration and a variant that generated dynamic discretization grids.",
    "This submission is about multi-modal representation learning from unlabeled data (self-sup.) using Transformer. This work deals with video, audio, and text data as multi-modal data. The approach to tackle representation learning is based on Transformer + contrastive learning. The contrastive learning in this work is interesting in that 1) noisy association is considered in multiple instances learning way [64], and 2) the different level of semantic granularity is carefully considered. Also, the authors adopt a simple DropToken to improve efficiency.  The training requires very large-scale training using HowTo100M and AudioSet. The authors demonstrated its effectiveness on action recognition, audio event classification, zero-shot video retrieval, image classification.  Multi-modal data is encoded by independent feature extractors, which is a small difference from other Vision Transformers. Naturally, the authors extend the positional encoding to 3D positional encoding (horizontal, vertical, and temporal axes) with relativeness.  Overall, the technical contribution is a bit weak, but this submission contains interesting analyses that are worthwhile to report in the community and also achieve state-of-the-art in downstream tasks.",
    "This paper describes a self-supervised pure transformer-based multimodal representation learning including video-audio-text, i.e., VATT. VATT consists of  linear projection of input for each modality, modality-specific or agnostic transformer encoder, and multimodal projection head. VATT uses NCE loss for video-audio feature learning and MIL-NCE loss for text-video features. Also, the authors proposed DropToken as an efficient method for training.  They employ HowTo1M and AudioSet datasets for pretraining and evaluate their VATT for diverse finetuning tasks including video action recognition, audio event classification, and zero-shot text-to-video retrieval. With intensive experiments and ablation studies, they provide promising results and constructive analysis.  ",
    "The paper proposes a transformer-based architecture for learning representations from video-audio-text triplet data without manual data annotation. The paper studies modality-specific transformers (one transformer for one modality) and modality-agnostic transformers (a shared transformer for all modalities). The learned representation is evaluated on various downstream tasks on image, video, audio and video-text.",
    "This paper concerns multimodal self-supervised learning. It adopts the now ubiquitous contrastive learning framework to learn video, audio, text representation from each raw signal in joint embedding spaces. The proposed architecture heavily relies on MMV [1], with a twist on Visual/Audio Transformer encoders and modality-agnostic Transformers. Comprehensive experimental results are conducted on four diverse video(-text) tasks across ten datasets.",
    "This paper provides a framework for self-supervised multimodal representations from unlabeled data with Transformer backbones. The authors study two styles of Transformer encoders: modality-specific or modality-agnostic.  Finally, they achieve good performance on various downstream tasks including action recognition, audio event classification, text-to-video retrieval and image classification.",
    "The paper proposes a method (Skyformer) to apply Nystrom approximation to the attention matrix. It embeds the attention matrix inside a larger PSD matrix (unlike Nystromformer), allowing Nystrom method to work well. Theoretical and empirical validation shows that the method is competitive with other forms of efficient attention (e.g. BigBird, Performer, Reformer).",
    "The paper presents an alternative approach to attention in the Transformer. There are two modeling contributions:  1. Kernelized attention that omits the typical normalization term used for softmax attention. 2. A Nystrom method approach that allows efficiently approximating the output of the attention mechanism  The contributions also include theoretical results regarding the accuracy of the Nystrom approximation, and experimental results showing better convergence, higher accuracy, and medium efficiency gains from the approach.  Below I summarize my understanding/takeaways from the two key methods; please correct me in the author response if these are inaccurate: 1. As I understand it, \"kernelized attention\" mean that target keys don't compete with each other, the only thing that matters is their distance to the query. In standard softmax attention, suppose that all key vectors are orthogonal to a query vector -- in that case, attention would weigh all values uniformly. In kernelized attention, on the other hand, if key vectors are all far away from the query vector, then all value vectors would be attended to with near-zero weight. 2. The Nystrom approximation involves sampling some queries and keys, and then computing kernels between all pairs. But whereas Nystromformer computes similarity for query+key pairs only, the proposed approach also computes kernels for query+query and key+key pairs as well.",
    "The author proposes a modified Nystr\u00f6m method named Skyformer to approximate the Kernelized Attention. They also provide a theoretical guarantee that the approximation error is small in terms of the spectral norm. Extensive experiments are also conducted to show that Skyformer achieves comparable performance to vanilla self-attention with fewer computational costs.",
    "The paper proposes a new form of self-attention for use in transformer models using Gaussian Kernels. They show that the new attention method is comparable in accuracy to traditional softmax self-attention. They then go on to show that kernel based attention can be approximated by taking a Nystrom sketch of the kernel matrix. They give rigorous bounds on the spectral norm of the approximation (assuming that the kernel matrix has a high condition number). ",
    "The authors reformulate soft max structure of the self-attention mechanism in Transformers in terms of a Gaussian kernel evaluation. They claim that such a model is empirically stable during training, while allowing the use of various Kernel approximation strategies to improve the quadratic computational complexity.   In this work, approximation strategy used by the authors is the popular Nystr\u00f6m approximation. However, since the kernel matrix formed between the query and the key matrices is not symmetric (hence not PSD), the Nystr\u00f6m approximation is not directly applicable. The authors propose to form a PSD kernel matrix by first evaluating the Gaussian kernel on the row concatenated  query and key matrices which is PSD, performing the Nystr\u00f6m approximation and then choosing the appropriate block in the resulting matrix.  By adapting an existing theorem [Musco, Musco 17],  the authors claim that such a low-rank approximation of the kernelized attention score is bounded in terms of the relative spectral norm. This is claimed to be due to the observed fast decay of the eigenvalues in an empirical kernel matrix.   The matrix inversion required for the Nystr\u00f6m approximation, however is a potential issue in terms of numerical stability on a GPU. To circumvent the problem, instead of a standard conjugate gradient method, they use a Schulz type iteration which only uses matrix products, without any floating point divisions.    Empirical evaluation shows marginal improvement on most tasks on the LRA benchmark, as compared to the naive Nystr\u00f6m approximation [Xiong et al 2021]. However, this is at the cost of relatively larger time and memory usage. ",
    "This paper proposes Augmented Policy Cloning (APC) approach to improve the data efficiency of expert behavior by augmenting expert trajectory data with virtual, perturbed states and the expert actions in these virtual states. This method is simple by applying the existing image-based data augmentation method, but it can increase the data efficiency of policy cloning and transfer high-DoF behaviors. The proposed method outperforms BC and Naive ABC.",
    "The paper explores a novel approach to using expert policies in RL context. The main idea is to enrich expert demonstrations by perturbing a state by Gaussian noise and querying expert policy to produce an action from the perturbed state. These additional state-action pairs are used in the policy learning algorithm. The authors show experimentally that the proposed Augmented Policy Cloning (APC) can significantly improve the quality of cloned policy, compared to Behaviour Cloning.",
    "This paper proposed an data-augmentation technique -- \"augmented policy cloning (APC)\" to enable efficient policy learning from parametric experts. It achieve a high level efficiency in transferring knowledge from an expert to a student policy for high Degrees of Freedom environment. The augmentation is introduce not only for the states but also to the actions of underlying policy.",
    "The paper proposes a policy cloning method that transfers an expert to a student. In the considered setting, the expert policy is accessible at all times, while there is no access to the environment to perform RL. The proposed method leverages data augmentation to successfully train the student policy.",
    "This paper proposes to study the non-interactive imitation learning setting where access to the parametric expert policy is available. The paper proposes to augment the logged expert data\u2019s states with noise, and then determine then sample corresponding actions from the expert\u2019s policy. These perturbed states and corresponding action are then use to train the agent. They show this method outperforms Behavior cloning and an approach where the logged states are perturbed but the corresponding actions are kept fixed on imitation learning tasks and RL tasks where IL is used for warmstarting. ",
    "This work proposes and studies two techniques to generate unadversarial images (images which cause a computer vision deep learning model to more reliably give accurate predictions). One technique is for creating unadversarial patches which can be overlaid on testing images to increase the robustness of a pre-trained classifier, the other is for creating unadversarial textures for 3D meshes which when applied to 3D meshes. The work provides strong empirical evidence for unadversarial patches on ImageNet and CIFAR, including results where images are corrupted after applying the patches. Evidence is provided for unadversarial textures on simulated data and a small scale real world experiment.",
    "In this work, the authors leverage techniques from the adversarial examples literature to design patches and textures that aid in classifying an object *correctly.* In a fixed-model setting, they construct patches / textures using gradient-based methods and demonstrate effectiveness on clean CIFAR-10 and ImageNet and various robustness benchmarks such as ImageNet-C (common perturbations). The authors also compare their patches / textures to simple baselines such as QR codes, smaller-sized images from the training set, and predefined fixed patterns.",
    "This work introduces and studies \"unadversarial\" input modifications (patches or object textures) designed to *increase* classifier accuracy, particularly in corrupted images. The work is inspired by research on adversarial examples (in particular \"adversarial patches\" which trick a classifier into predicting a particular class when the patch is present in the scene, regardless of what other class might be present).  Given access to a known, fixed, pre-trained network, a small patch (or the entire object texture) are optimized by gradient descent to increase prediction accuracy. When applied, the method is shown to be quite effective for increasing classification accuracy (and performance on a simple regression task) under a variety of simulated image corruptions (blur, fog, etc.). In addition, the patch method is shown to significantly aid classification even when printed and affixed to real physical objects.",
    "This paper exploits the  known-sensitivity of deep models to perturbation in the input data in order to improve (rather than decrease) the performance of a pre-trained model in a classification task. Specifically, the authors propose to alter the input data (i.e. images)  by 1) adding a patch to the image 2) altering the texture of specific objects. The paper shows experimentally that this improves both in-domain performance and robustness to data corruptions.",
    "The paper considers a scenario where a fixed computer vision system (such as CNN based classification or regression models) is given and one tries to adapt the design of objects in order to increase their chance of being correctly detected by the system. This setting is similar to the design of marker systems for computer vision with the difference that the detection algorithm is considered fixed.  Two approaches are presented to design (i) patches that can be printed and sticked onto objects and (ii) complete textures that cover the surface of 3D objects. Both approaches follow the design of adversarial perturbations with the difference that instead of maximizing the loss of the system, it is now minimized to improve its performance instead of weakening it.  Experiments evaluate how these approaches can improve the overall performance of the given system as well as its robustness against a variety of different corruptions. Experiments are performed on synthetic 2D and 3D data, as well as on real objects, where the designed patches are printed out and attached to physical objects. Overall, they demonstrate consistent and significant improvements over non-modified objects and simple baselines.",
    "(Auxiliary Review only -- the authors need not respond to this).  This work proposes issues with data augmentation in RL and proposes a couple of techniques to address those issues. It applies augmentation only on the current state and not future state to address erroneous bootstrapping. It also proposes a Q objective that uses both the augmented and un-augmented data. Also, for actor critic experiments, the actor is optimised only with un-augmented data and learn a  policy that is general via sharing parameters between the networks. These are simple techniques that help the paper demonstrate good results in a range of tasks.  This is a clear paper with good set of experiments. The problem has been described clearly and the work proposes simple refinements to the data augmentation strategies used in RL. While I am convinced of the quality of the method itself and the experiments, this work could have benefitted from more rigour with the baselines to make a stronger case for the method. Hence, I am offering a score of 6 noting that the paper is marginally above acceptance threshold.",
    "This paper studies the problem of high-variance Q-targets under data augmentation, and proposes a method to reduce the variance of the targets called SVEA. The key idea contains three parts: (1) Apply augmentation to the Q-value estimation of the current state and not the next state Q-targets for bootstrapping, and (2) modify the objective to include both the targets using augmented and original observations and (3) optimize the actor using only the unaugmented data for actor-critic algorithms, with parameter sharing.   The paper performed experiments in DeepMind control suite and its variants (with raw pixel inputs). Compared to other data augmentation methods (e.g. DrQ) their proposed SVEA method is robust to the type of data augmentation and is more sample efficient with a better final performance. Some ablations were also presented among the above components to indicate the usefulness of all components. Generalization performance was demonstrated in the DistractingCS and robotic manipulation environments. The method also appears to help when using a Vision Transformers architecture.  ",
    "This work proposes a simple technique to improve the robustness and sample-efficiency of reinforcement learning. The technique can be applied to any algorithm via a simple modification of the input pipeline to said algorithm's Q-learning subroutine. The claim is that this modification reduces the variance of Q-targets and therefore stabilizes learning.",
    "The paper addresses the question of zero-shot or fast generalization of value-based deep reinforcement learning agents using visual inputs to image transformation which do not change the (conceptual) state of the environment. The long term goal is therefore training agents which learn efficient, high return control policies both which are robust to irrelevant variations in high dimensional input observations. The ultimate goal seems to be generalization of learned skills to novel environments, but as far as I can tell this particular evaluation philosophy is implemented in experiments.  The paper reviews previous attempts to learn robust state representations to visual variations and formulates clear hypotheses for explaining the causes of difficulties which prior methods faced and were hindered by. The said hypotheses suggest a simplified approach (SVEA) which is empirically developed and evaluated in the remainder of the paper. Control tasks from widely used benchmarks are used to evaluate the method, somewhat less usual is the focus on vision-based high-dimensional versions of such tasks, instead of standard domains such as Atari games and benchmarks for generalization such as Natural Atari [1], CoinRun/ProcGen [2].  ",
    "The paper presents a way of improving training stability of DrQ (an image-based RL algorithm that uses data augmentation) by applying image augmentation more carefully. The authors propose to input a mix of augmented and un-augmented observations into the critic, and stop augmenting the actor's inputs. On the considered benchmarks the proposed method demonstrates better generalization results. ",
    "The paper proposes a new method to solve the finite sum problem in federated learning where each local model is an expectation function. The STEM algorithm uses momentum variance-reduced estimator in local updates (similar to STORM estimator in stochastic optimization) and also send these estimators to the server when performing server-side update. Therefore, STEM includes momentum updates for both local and server updates. Convergence analysis reveals that STEM nearly match the best known sample complexity in centralized setting and it also matches the lower bound communication complexity up to a log factor. Numerical experiments on neural network training not only show advantage of STEM compared with FedAvg and SCAFFOLD but also presenting the tradeoff between communication frequency and minibatch size.",
    "This paper introduced a two-step momentum method for federated learning. The proposed method achieves the best achievable sample and communication complexities for first-order stochastic FL algorithms. The theoretical analysis provides guidance on selecting synchronization interval and batch size for achieving the nearly optimal complexities.",
    "The authors presented a momentum extension of the classic FedAvg method for non-convex federated learning, along with a unified framework for convergence analysis. The core result shows that the proposed method can achieve near-tight sample and communication complexities under mild conditions, whilst also revealing a trade-off between local update frequencies and local minibatch sizes. The actual performance of the proposed method was evaluated in CIFAR-10 and MNIST image classification tasks.",
    "Authors propose Stochastic Two-Sided Momentum algorithm, that utilizes certain momentum-assisted stochastic gradient directions for both the WNs and SN updates. Authors show that this method achieves near optimal sample complexity $\\tilde{\\mathcal{O}}\\left(\\epsilon^{-3 / 2}\\right)$ and $\\tilde{\\mathcal{O}}\\left(\\epsilon^{-1}\\right)$ communication complexity.  Also, authors provide interesting observations about trade-off between the minibatch sizes and the local update frequency.    ",
    " The paper proposes STEM for federated learning under *sample gradient smoothness condition*. By using momentum-based techniques, the proposed STEM algorithm achieves the optimal sample complexity of $O(\\epsilon^{-3/2})$ and communication complexity of $O(\\epsilon^{-1})$ for non-convex functions. The paper also shows how to balance the batch size and the number of local steps. ",
    "This paper study the interplay between generalization bound and the covariance of perturbed gradient descent. The authors invoke a recent (information-theoretic) bound for stochastic optimization methods. Then, they optimize the upper bound with respect to trace constraint on the covariance of noise in each step and experimentally show that this optimization may be effective for training neural networks. ",
    "This paper considers the problem of understanding the generalization of the SGLD algorithms using information-theoretic techniques. This line of work initiates by [27],[24], and [13]. The goal in this paper is to \"modify\" the SGLD algorithms such that it has a good generalization properties and good performance on the training set. Basically, the modification that the authors considered is to make the covariance of the Gaussian noise in the SGLD update to depend on the trajectory. Note that in the usual setting the noise is isotropic. Then, authors claim that controlling the trace of the SGLD ensures we have good performance on training set and good generalization. Then the authors provide a generalization bound which uses reverse KL between posterior and the prior distribution. I think this bound is not true as stated in my review. Since this bound has been used in the paper, I think the authors should comment on the validity of the theorem.",
    "This interesting paper studies the connection between generalization abilities of of SGLD and the covariance structure of its noise term. It first proves that with constraint to guarantee low empirical risk and commonly used data-dependent priors, the optimal noise covariance of SGLD in terms of the bound is similar to the empirical gradient covariance. The paper further proves that if the generalization bound is jointly optimized with respect to both prior and posterior, the optimal noise covariance is the square root of the expected gradient covariance. These facts can be used to further support the belief of the superiority of SGD noise over isotropic noise.",
    "From usual isentropic noise to data-dependent priors, the authors extend the existing information-theoretic analysis of SGLD. Additionally, they identify the optimal choice of prior distribution covariance. Last but not least, the paper includes empirical observations to validate its technical findings.",
    "This paper studies optimization of the information theoretical generalization bounds of Stochastic Gradient Langevin Dynamics (SGLD) with respect to the noise covariance. Here are the main findings: * When updating rule is fixed and only optimizing noise covariance under the constraint that the trace of the covariance is fixed, the noise covariance of SGLD is similar to the empirical gradient covariance * When both updating rule and the noise covariance are jointly minimized, the noise covariance of SGLD is the square root of the expected gradient covariance.  The two results can potentially be used to improve information theoretical generalization bounds obtained in the literature. The theoretical results are validated by some numerical experiments.  ",
    "First, the paper introduces the idea of using multiple predictions (e.g. M=25) for learning-based video coding. Second, to reduce the required motion bits, a flow prediction method using polynomial approximation is developed. The idea is reasonable, and the reported performance seems promising. However, the paper is written rather poorly, and how the algorithm is actually designed is not clear. Thus, the reported performance is not convincing either. ",
    "The authors introduce VLVC, a new neural video compression codec. Thanks to a new 3D motion compensation structure based on spatio-temporal interpolation, a single trained model can be run in arbitrary prediction modes (such as low-delay or random-access settings). In addition, each frame can be compressed with an arbitrary number of reference frames. There are a number of smaller changes to established neural video codecs. The resulting VLVC codec is demonstrated on standard datasets, showing good rate-distortion results (in particular when trained and evaluated on MS-SSIM).",
    "This paper introduces multi-frame references for learned video coding, which estimates multiple optical flows as voxel flows for motion compensation. With the weighted map, it can achieve weighted trilinear warping to combine the multiple predictions into  the final prediction. It is a good idea to obtain a better predcition to search information across multiple frames.  The author introduces  the polynominal motion modeling to use multiple backward optical flow to generate the single optical flow. Based on the method of softmax spaltting, they convert the backward flow into a forward flow using the flow reversal layer. Then use the forward flow and softmax spaltting for motion compensation. The overall architecture is a hybrid video coding system and the main contribution is inter coding. Residual coding is applied on the feature domain. ",
    "This paper proposes a neural video compression method that is designed around the idea of using a voxel flow instead of the more traditional pixel warping idea. The key difference here is that a volume of reference frames is used, and flow is computed to all of them. This allows the compression method to be quite liberal in terms of what information from the GOP can be used, yielding a better RD performance than methods that rely on a single reference frame.  Overall I think this is a step in the right direction, but I fear that such a method is completely impractical for the foreseeable future.",
    "Learned video compression is a promising field and has demonstrated that it can be as effective as the classic video compression method. In terms of rate distortion it has caught up with the classical methods greatly. However binding the prediction mode and fixed network is what hinders the field to go forward. This paper proposes a versatile learned video compression framework that learns one mode to predict all possible modes. The paper proposes versatile compression where the motion compensation applies 3D motion vector fields, trilinear warping. Motion estimation here acts as a decoupler of prediction modes away from framework design, allowing its dependence to be not affected by framework design. For multiple reference frame prediction, the network predicts the motion fields with a unified polynomial function. The flow prediction can lead to reduction of computation by reducing voxel flow transmission. ",
    "Inspired by the analysis in [10], this paper shows bounds on multitask online convex optimization w.r.t. an arbitrary strongly convex regularizer. The task relatedness is expressed I.t.o. task variance, defined by means of a task relatedness matrix. Experiments on real data are presented at the end. ",
    "This paper studies the online multi-task learning setting and proposes a multi-task variant of online mirror descent that works with convex losses, a general class of Bregman divergences, and any positively weighted task-interaction matrix. They provide regret guarantees that, on two different instantiations, improve over the baseline of running independent mirror descent algorithms. The algorithms have straightforward implementations that are used on experiments on four datasets.",
    "The paper proposes MT-OMD, which allows update sharing among tasks. It is shown that it achieves a regret of O(sqrt{sigma^2(N-1)}sqrt{T}). The paper also extends the OGD and EG and obtains closed-form updates. Numerical results are presented to validate the theoretical findings. ",
    "The paper presents MT-OMD and related variants on multi-task online learning with strongly convex loss functions.  The proposals can improve naive optimization when the task similarity is small measured by the distance of reference vectors. Specifically, it proves a regret bound of the form $sqrt{1+\\sigma^2(N-1)}\\sqrt{T}$, as opposed to the standard $\\sqrt{nT}$. This $\\sigma$ measures the task similarity (The smaller $sigma$ is, the closer the tasks are). ",
    "This paper considered multitask online convex optimization (OCO), in which each of $N$ agents learns a possibly different task on a common convex decision set.  The goal of this paper is to minimize multitask regret, defined as the sum of the regret of all agents. A simple way to independently run $N$ instances of OMD  for $N$ agents can achieve a multitask regret bound of $O(\\sqrt{NT})$, where $T$ is the time horizon. The main contribution of this paper is to develop multitask OMD (MT-OMD) and establish the regret bound of $O(\\sqrt{1+\\sigma^2(N-1)}\\sqrt{T})$, where $\\sigma^2$ is the task variance. If $\\sigma<1$, their regret bound is better than that established by the simple way.  ",
    "The paper considers methods for approximating underdamped Langevin diffusion processes with sum-decomposable strongly convex potential. The main contribution in the paper is the proposal of the Accelerated ULD-MCMC algorithm and its variance-reduced variants. This is followed by a detailed analysis of convergence for each of the algorithms, and the derivation of an information-based lower bound for gradient complexity in the task of estimating ULD that matches the upper bound (in dimensionality, component number, and target accuracy). The authors conclude with a discussion of the optimality (or lack thereof) of ALUM with respect to all the variables. Comprehensive experiments are presented to compare the performance of various algorithms on estimation ULD processes, showing that ALUM and its variants achieve better performance than previous algorithms.",
    "In the context of sum-decomposable, smooth, and strongly convex potential functions the authors propose algorithms to improve the upper bound on the approximation error for estimating a Underdamped Langevin Diffusion (ULD) process and on the sampling error of the strongly-log-concave sampling problem. The continuous time ULD process has the strongly-log-concave distribution as its invariant distribution so approximating this process and sampling from this distribution are closely related. In the full gradient setting, the authors present a novel algorithm, ALUM which has optimal iteration complexity in $d$, $N$ and $\\epsilon$ for the ULD approximation problem. Here, $N$ is the number of terms in the sum-decomposable function, $d$ is the input dimension and $\\epsilon$ is the accuracy parameter. In comparison to the RMM algorithm (Lee et al), the dependence on $d$, $N$ and $\\epsilon$ in the iteration complexity are matched, but the number of gradient evaluations are reduced by a factor of 2. Next the stochastic gradient oracle setting is considered: here the authors propose algorithms (SVRG-ALUM and SAGA-ALUM) and analyze the corresponding sampling/discretization error. Finally an improvement in the lower bound for the gradient complexity of the ULD approximation problem to $\\Omega(N + d^{1/3}N^{2/3}/\\epsilon^{2/3})$ is presented. This shows that the gradient complexity of the presented Variance reduction modifications of ALUM match the lower bound in $d$, $N$ and $n$ in the sum-decomposable setting with a stochastic gradient oracle.",
    "The paper makes new contributions to the literature on sampling from a strongly log-concave smooth measure. This is done by approximating the Underdamped Langevin Diffusion (ULD), and so, a fortiori, the paper also contributes to this approximation problem.  The main result is a new algorithm to approximate the ULD, which is well suited to a stochastic setting, where the gradient of the potential is replaced by certain estimators.  In the full gradient (i.e. without using an estimator for the gradient) setting the new algorithm matches the asymptotic performance of previous works while cutting the number of Gradient queries by about half. In the stochastic setting, if the potential can be represented as a sum of $N$ smooth functions, then the authors also show how to modify their algorithm to accommodate estimators to the gradient and reduce the overall query and iteration complexity.  The results of the stochastic setting are also complemented by a lower bound which essentially show that the dependence on the parameters $N$, and $d$, the dimension are essentially optimal. ",
    "The paper studies the underdamped Langevin diffusion for strongly-convex potential consists of finite sum of smooth components. The authors propose ALUM, which achieves optimal asymptotic complexity in the full gradient setting, and only requires one gradient at each iteration compared to RMM. For the stochastic gradient setting, VR-ALUM methods are proposed which improve over the previous methods in gradient complexity. The authors also accompany with a lower bound showing that the proposed methods are optimal in related parameters for the approximation problem.  ",
    "This paper proposes a randomized algorithm for approximating a trajectory of underdamped Langevin dynamics, similar to the RMM method cited in the paper. It further uses variance reduction method to improve the error over sum-decomposable problems. An information theoretic lower bound is established, which the proposed method matches.",
    "This paper proposes a model for continual learning. Specifically, it intends to merge parameter regularization methods and gradient projection methods. The regularization is achieved by taking a bayesian perspective over the distribution over parameters, that is approximated by a Laplace distribution in a variational fashion, with online updates. The gradient projection is addressed by trust-region optimization, resulting in an update rule that uses the precision matrix to precondition the gradient of the current task objective, plus a term that keeps the parameters close to the previous mean. Experiments are carried out for sequential problems on a stimulus-response dataset and on stroke MNIST. ",
    "The paper addresses the problem of catastrophic forgetting during sequential task learning with recurrent neural networks, a notoriously difficult continual learning setting.   The main theoretical contribution is a formalism, Natural Continual Learning (NCL), which generalizes several related continual learning approaches in the regularization-based family, including several recent SOTA techniques. This formalism applies to the probabilistic learning setting using neural networks, so it is not restricted to supervised learning or recurrent models.  Experimental evidence is provided to support the claim that NCL outperforms previous approaches.  Finally, interesting analogies are made to models of biological learning, which are also supported by accompanying experiments; similar analysis tools are applied to practical instantiations of the NCL framework in controlled experimental settings. ",
    "This paper proposes a novel regularization based continual learning approach, NCL, which is mainly used for recurrent neural network (RNN). Since NCL is based on Bayesian continual learning, NCL utilizes the approximate posterior of previous tasks as a prior for current task, and the Laplace approximation is used to compute the approximate posterior. Through simple toy analyses on convex and non-convex loss landscapes for NCL and other baseline methods, authors show that previous methods have a problem on the trajectories of convergence when learning a new task. Based on the results on simple toy analyses, authors proposed a novel trust region based regularization method that modulate the gradient by considering the curvature of prior distribution via its precision matrix. The proposed technique is highly similar to projection based methods, but its origin is quite different from previous methods. Experiment results show that NCL outperforms other baselines in stimulus-response and MNIST tasks. ",
    "The authors propose a method called Natural Continual Learning (NCL). NCL unifies the concepts of weight regularization and gradient projection into non-interfering subspaces. Gradient projection is implemented as a trust region optimization using the Fisher information matrix. The authors also introduce a Kronecker-factor approximation to improve the scalability properties of their method. The comparison against other continual learning approaches is conducted using recurrent neural network (RNN) architectures. ",
    "The authors introduce an extension to Bayesian continual learning whereby updates in successive tasks are constrained to be close to a \u201ctrust region\u201d of the parameters found in preceding tasks. Exploiting the Bayesian nature of the model, the trust region in question can be defined in terms of the prior precision matrix. The authors show that the method, when applied to RNNs, is effective against baselines in a) a suite of neuroscience related tasks, and b) stroke MNIST datasets.",
    "This paper addresses the problem of constructing injective normalizing flows, which connect some low-dimensional space with the data manifold of interest in the high-dimensional space. Typically injective (or rectangular) flows are composed of two square flows with the \u201cupsampling\u201d padding layer between them. Because the volume change term in the case of injective flows is seemingly intractable, current approaches find workarounds by training these two square flows separately step-by-step. Though this decision has certain drawbacks and may result in suboptimal performance. Current work suggests to employ numerical linear algebra methods to make volume change computation tractable. Experiments demonstrate that taking into account volume \u0441hanging term improves the generation results both for synthetic and real-life data. Interestingly, it also improves out of distribution detection score, allowing the model trained on FashionMNItST to assign lower probability for the MNIST data samples.",
    "The paper addresses the challenge of learning a normalizing flow, under the assumption that the data probability function is concentrated on a low dimensional manifold. Utilizing the manifold assumption introduces a challenge in computing the volume change term. This paper suggests addressing this computational challenge in two ways: i) If the manifold dimension is low enough, it is reasonable to calculate the map differential exactly based on AD forward mode; ii) alternatively, an unbiased stochastic estimator for the log det can be used. ",
    "This paper is motivated by the desire to circumvent a problematic requirement in Normalizing Flows (NFs) on the function $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}^D$ that produces the pushforward measure --- namely, that $f$ must be strictly invertible. This is difficult for generative models, since the dimension of the latent space $d$ is usually much smaller than that of the target data space $D$, i.e. $d << D$. The invertibility requirement centers around the change-of-variables formula, which is crucial for computing the cost function in NFs, and which requires computing the Jacobian of $f^{-1}$. To enable the use of NFs on latent/data spaces where $d << D$, the authors propose \"Rectangular\" NFs (RNFs). The name comes from the fact that the Jacobian of $f$ is now rectangular in the $d << D$ case. This involves the use of a differential geometric variant of the change-of-variables formula, and is much more computationally taxing, but provides superior density estimation performance to previous work. ",
    "The paper presents new methods for estimating densities using rectangular normalizing flows. Rectangular normalizing flows, unlike squared normalizing flows, allow considering injective instead of bijective flows. This property is exploited for estimating the density of data residing on a low (d) dimensional manifold in R^D, for D>d. Existing works using rectangular flows to estimate densities supported on low dimensional manifolds assume that the manifold is known, and therefore are restricted to tori, spheres, etc. In contrast, this work does not make this assumption and shows that density estimation for injective flows based on ML is tractable. Two methods are proposed, which are based on incorporating and estimating the \u201cJacobian-transpose-Jacobian\u201d in the objective. One is based on an exact derivation, which is computationally demanding. The other is based on stochastic gradient estimates. Experimental results on a simulation and a couple of datasets are shown, demonstrating the advantage of the proposed methods compared to an existing method as well as the tradeoff between memory and variance incurred by the two proposed methods.",
    "The task of interest is to simultaneously learn a manifold (with a fixed predefined dimensionality) and the density on it, from training data. The proposed method, rectangular flows, is developed based on an existing work (Brehmer and Cranmer [6]) that used a two-step training procedure (for manifold matching and density matching, respectively). The main contributions include: (1) revealing that the two-step training can be improved by joint training; (2) a new technique to enable computing the Jacobian-transpose-Jacobian term of the joint training objective with better efficiency. Experiments on simulated data and MNIST/FMNIST are conducted to demonstrate the proposed method.",
    "This paper proposes a biologically motivated mechanism that could allow a network of slow-responding neurons (primarily due to the response lag) to perform computation at a much faster timescale. The key modeling idea is to assume that the neurons compute a \"prospective\" latent state, by linearly extrapolating from the current position in the phase space, by the current momentum and a specific timescale. The authors then assume that neural dynamics is along the extrema of an energy function in the latent state space; hence called the \"Latent Equilibrium\" framework. Using synthetic data, the authors demonstrate that the proposed model can indeed lead to fast computation and learning; they also apply the model to real data from cortical microcircuits. The authors also go further and discuss how the model can be modified to self-correct timescale mismatches.",
    "This paper asks an important question, proposes novel ideas, and presents compelling contributions. The problem being addressed is fundamental and yet has received not much attention,  with no existing good solution. The problem is that physical and biological elements in the brain are slow. Computations propagating through a neural network hierarchy with such elements will introduce time lag.  The mismatch between teaching signals and the current state of the system,  when the input is constantly changing, presents a problem for learning.  The two existing solutions involve (1) separating inference and learning into the \"relaxation\" phase for the computation to complete and the \"learning\" phase for weight update, or (2) use a very slow weight update rate. Both of these are suboptimal.  They proposed a prospective energy function in which the membrane potential of a neuron is trained to map onto a latent equilibrium space where during the relaxation state, the instantaneous outputs of the neurons are the prospective target membrane potentials of the neurons with those recurrent computations. This will allow weight update to be done concurrently with relaxation and solving a problem of achieving arbitrary fast computation with arbitrarily slow neurons.  The resulting model can be interpreted as a biologically plausible approximation of error backpropagation in deep cortical networks with continuous-time leaky neuronal dynamics and continuous active local plasticity. They showed this method work in MINST and CIFAR100, and in fact, the method works better than BP during the early epochs of training.",
    "The authors propose a framework from which a neuron model with (slow) neural dynamics close to physical substrates can be derived  along with a plasticity rule for learning that is similar to backprop. The neuron model allows fast propagation of signals through the network in spite of the slow dynamics of the components, which avoids having to control the timing of learning to turn it on only after the signal has propagated. The authors perform empirical evaluations of networks based on this model on various tasks.",
    "The authors introduce a novel framework called Latent Equilibrium that enables quasi-instantaneous inference regardless of network depth and learning without phased plasticity in networks with slow neuronal elements.  Notably, the framework offers a biologically plausible model of back-propagation. Authors show that the models generated according to the framework have reasonable prediction quality on standard benchmark datasets. The authors also show that the framework can generate good models of cortical networks. Finally, authors explore heterogeneous substrates and conclude that framework is robust.",
    "The paper introduces Latent Equilibrium, a new framework for inference and learning in networks of slow components.   Authors use the leaky integrator dynamics that characterize biological neurons to jointly derive disentangled neuron and synapse dynamics. The neuronal dynamics evolve along a constant-energy manifold, called the Latent Equilibrium.   They show that LE allows for performance gains after the beginning of training, when the disruptive effects of relaxation begin to dominate, as well as robustness of LE on a MNIST classification task. ",
    "This paper proposes a new architecture to strengthen message passing GNNs. Since the weaknesses of GNNs usually come from  the unidentifability of nodes, the authors suggest to first preprocess given graphs and add each node a new initial attribute, and then apply the outer GNN. The new node attributes come from another message passing GNN (called based GNN) applied to a subgraph of a certain depth (or height according to the paper's terminology) around each node. Then they prove that the new architecture can distinguish regular graphs with probability $1-o(1)$ (over the choice of a random regular graph), and so the new model is more expressive than MPNNs, since MPNNs can't. They finally evaluate their model in various settings.    For me the contributions of the paper are: (1) proposing nested GNNs (NGNNs); (2) showing that NGNNs can distinguish almost all regular graphs; (3) and evaluating the new model through various experiments. ",
    "This paper introduces Nested Graph Neural Networks (NGNNs), a novel kind of graph neural network that overcomes the limitations of typical message passing approaches by representing each node as a function of its nested subgraph, rather than its nested subtree.  The result is a model provably more expressive than 1-WL and 2-WL, at the cost of a constant increase in computational complexity (although this has practical limitations, as the authors point out).  NGNN works on two levels:   1. A \"base GNN\" is used to compute representations for each node, applying the GNN to the nested subgraph around the node and eventually pooling the subgraph to obtain the representation.   2. An \"outer GNN\" processes the resulting graph to obtain the final node representations, and a global pooling is optionally applied to get graph-level embeddings.   Therefore, NGNN can surpass 1-WL expressivity using only standard message-passing GNNs, making it very convenient and more computationally efficient than previous higher-order GNN variants.   The authors prove the expressive power of NGNN in distinguishing n-sized r-regular graphs.   The paper concludes with a thorough experimental analysis of NGNN on several benchmarks of graph classification and regression: QM9, ogb-molhiv, ogb-molpcba, and some TU datasets.  The method achieves state-of-the-art performance on ogb-molpcba and several QM9 subtasks. ",
    "This paper presents a framework that applies GNN to subgraphs around each node independently to enhance node representations, followed by a global pooling layer to get graph-level embedding. The framework can be applied to any GNNs. The paper also demonstrates it's relative improvement over several real-world datasets, although the improvement seems marginal. From theoretical side, the paper proved formally that this framework can distinguish k-regular graphs where most traditional message passing based neural network cannot. ",
    "This paper proposes Nested GNN, which encodes each node based on the subgraph rather than the subtree (as what GNN does) around it. The main difference between NGNN and GNN is that subgraph captures more information than the subtree, such as the interactions between a node's neighbors. The whole-graph representation can be pooled from each node representation, and can be applied in tasks such as graph classification. From theoretical perspective, this paper studies the limitations of expressive power of GNN and show that NGNN is more powerful. The proposed method shows good performance on multiple datasets. ",
    "Since GNNs based on rooted subtrees are known with limited expressive power, this paper proposes to represent nodes with their rooted subgraphs. Its expressive power with respect to graph isomorphism testing is proven beyond 2-WL. Such a method is compatible to plug into popular GNNs to enhance their representation power. Enhanced GNNs show strong performances on graph classification and regression tasks.",
    "The paper describes a framework for learning and inference in probabilistic models with structured latent spaces. It operates in the tradition of IWAE and VSMC-like methods that use importance sampling to tighten a variational bound (or equivalently, uses a variational bound as an objective for learning importance sampler proposals). Unlike methods that optimize a single global bound, NVI is defined in terms of local pairwise divergences between a sequence of target distributions, which acts to decouple the stochastic optimization, reducing gradient variance and potentially offering a strategy for parallel inference.",
    "The author proposes a nested variational inference (NVI) framework that combines nested importance sampling and variational inference. This framework allows the training of the important sampling proposal by minimizing KL divergences at each level of nesting. This also provides us a way to learn intermediate densities, which serves as a heuristics for guiding the importance sampler. Empirically, the author evaluates NVI by (1) sampling from a multimodal distribution with a learned annealing path; (2) learn heuristics for future observations in the state-space model; (3) perform amortized inference in the hierarchical deep generative model.",
    "This paper proposes an inference procedure that combines ideas from variational and nested inference, resulting in a sequence of forward and reverse proposal distributions that are optimized with local objectives that encourage the forward and backward edge marginals to be similar. This allows the objective and therefore gradients to decouple. The addition of resampling, afforded by the connection to nested inference, additionally improves sample diversity.",
    "The authors present a method to jointly learn a series of proposals and intermediate densities for e.g. SMC, or annealed importance sampling. They use a novel objective which sums divergences between distributions over each adjacent pair of variables in the chain, and argue that this leads to lower-variance gradient estimates than prior work which uses a single objective for the entire sequence of variables. They show experimentally the benefits of this method in three different settings.",
    "The authors introduce a new inference and approximate weighted sampling framework that combines f-divergence variational inference and nested importance sampling. An original variation sampling density is transformed through a series of weight preserving operators that map the proposal to an approximation of an unnormalized target distribution. On the other hand, reverse transformations are use to transform the target back to the sampling distribution. The transformations are trained by minimizing an f-divergence at each nesting level. ",
    "  In this paper, the authors consider the problem of finding global solutions   to a possibly non-convex optimization problem under possibly non-convex   constraints using only access to function values of the objective function.   In particular, they focus on certified algorithms, i.e., algorithm that   together with a solution they also output certificate of the optimality of the   solution.    Their main result is an instance optimal bound for any Lipschitz continuous   functions. In particular if f is a Lipschitz continuous function with unknown   Lipschitz constant that is less than L, then the number of zero-order queries   needed to find an $\\epsilon$-approximate global optimum together with a   certificate of optimality is    $\\sigma = \\int_{\\mathcal{X}} \\frac{1}{(f(x^*) - f(x) + \\epsilon)^d} dx$    where $f(x^*)$ is the value of the global optimum and d is the dimensionality   of the problem. The authors provide both an algorithm and a lower bound that   is equal to $\\sigma$ up to dimension dependent constants. Surprisingly the fact   that the Lipschitz constant is not exactly known but only upper bounded is   crucial for the proof of the lower bound.",
    "This paper studied the problem of zeroth-order Lipschitz optimization, and mainly showed that under mild geometric assumptions and a noise-free zeroth-order oracle, the sample complexity of finding the \\varepsilon-optimal point for a function f is of the order $\\int dx/(f(x^\\star) - f(x) + \\varepsilon)^d$ (up to logarithmic factors). More specifically, the main contributions are as follows:   1. The authors proposed a certified DOO algorithm which could provide an error certification at each step, and achieves a sample complexity provided by the sum of packing numbers S_C(f,\\varepsilon), a quantity already proposed in Bouttier et al. (2020).   2. Under a mild geometric assumption, the quantity S_C(f,\\varepsilon) is bounded by the integral from both above and below, thereby proving the upper bound.   3. For the instance-dependent lower bound, the authors used a simple perturbation idea to reduce to a proper packing number: if the packing number of some shell is too large, then there must be points not queried by the algorithm, and a local perturbation of the functions around the non-queried points made the certification break down. ",
    "The paper studies the complexity of certifiable zeroth-order optimization of Lipschitz functions. Formally, given oracle access to evaluations of a $L$-Lipschitz function $f$ over a known compact domain $\\mathcal{X}$ and an error parameter, $\\epsilon > 0$, the goal is to find a point $\\hat{x}$ satisfying $f (\\hat{x}) \\geq \\max_x f (x) - \\epsilon$ making as few oracle queries as possible. The paper characterizes the optimal oracle complexity of the problem in an instance dependent sense where the number of queries made to the oracle depend on the behavior of the particular function. Concretely, they show that the number of queries that necessarily must be made to the oracle is $\\int_{\\mathcal{X}} d \\mathbf{x} / (\\max(f) - f(\\mathbf{x})  + \\epsilon)^d$ up to constant factors depending (exponentially) on the dimension.",
    "The authors introduced the Certified DOO algorithm, which is a zero-order method, to find the maximal point of a Lipschitz function on a compact feasible set. The authors also provided the convergence rate of the Certified DOO algorithm and an instance-dependent lower bound for all certified algorithms. And the lower bound matches the upper bound op to a logarithm term. ",
    "This paper presents tight, instance dependent upper and lower bounds for certifiable zeroth-order Lipschitz function optimization. It was known from prior work that in 1-d, the optimal sample complexity is nearly proportional to the integral $\\int_{\\mathcal{X}} \\frac{\\mathrm{d} x}{\\max (f) - f (x) + \\epsilon}$.  This paper extends this result to dimension $d$, establishing that the DOO algorithm of Perevozchikov 1990 can be made certifiable, achieving the sample complexity $\\int_{\\mathcal{X}} \\frac{\\mathrm{d} x}{(\\max (f) - f (x) + \\epsilon)^d}$.  The sample complexity bound of this algorithm matches that derived by Bouttier et al (2020) for an algorithm of Piyavskii and Shubert. The bound in Bouttier et al, however is provided in terms of covering numbers of the ground set at different error scales.  The main contribution of this paper is to (i) show that the c.DOO algorithm runs in near linear time and (ii) a sample complexity bound with of the same order as that derived by Bouttier et al (ii) To relate this sample complexity bound to the quantity $\\int_{\\mathcal{X}} \\frac{\\mathrm{d} x}{(\\max (f) - f (x) + \\epsilon)^d}$ (iii) establish a lower bound for certifiable algorithms which matches the upper bound up to an order of $(c( 1 - \\text{Lip} (f) / L ))^d$ where $L$ is a known upper bound on the Lipschitz constant of the true function.  The authors also complement these results with a sample complexity upper bound of a constant when $L = \\text{Lip}(f)$ (i.e. the Lipschitz constant of the function is known) for $d \\ge 2$, which surprisingly does not hold for the case of $d=1$.",
    "The paper presents an interesting method to create adversarial examples that do not change the class label, but rather flips the confidence in that label.  In other words, the accuracy of the classification system is not changed.  Rather, the idea is that the attack will force a system with well calibrated confidence to become confidently wrong and unconfidently correct rather than the desired behavior of being unconfidently wrong and confidently correct. The overall approach is basically the same as a standard label adversarial attack (i.e., follow the gradient), but at a lower magnitude as not to change the label.  The other minor difference is to determine the direction of the gradient depending on the ground truth label of the test sample.  That is increase confidence if the classification label prediction is incorrect and reduce the confidence otherwise. The paper does include extensive experimentation over various neural network models including uncertainty-aware models such as ensembles, MC dropout and SelectiveNet. ",
    "The paper presents a novel way for adversarial attacks.  This work studies the problem of attacking networks to change their confidence without affecting the accuracy. Such attacks increase the confidence of the network on wrong predictions and decrease the confidence of the networks on correct predictions. Since the accuracy of the network is not the target, this enables the. attacker to use smaller attacks that might not be easily detected. The paper studies both white-box and black-box attacks on different kinds of uncertainty estimation methods including MC-dropout, SelectiveNets, and Ensemble methods. Finally, the paper presents extensive empirical evaluations that support the proposed method.",
    "Contribute an attack where the DNN is more confident of its incorrect predictions than about its correct ones without having its accuracy reduced. Attacks contributed in the white-box and black-box regime, where the black-box regime here constitutes \"the attacker has no knowledge of the target network\". Demonstrate minimal perturbations successfully attack existing uncertainty estimation methods. ",
    "This paper presents a novel uncertainty estimation attack technique. Unlike most existing adversarial attacks, which cause incorrect prediction results, this novel attack technique only cripples the network\u2019s capacity for uncertainty estimation. The result is that, after the attack, the DNN is more confident of its incorrect predictions than its correct ones without having its accuracy reduced. Also, as this proposed attack can be accomplished without harming the model\u2019s accuracy, and thus avoid raising suspicion about a possible attack.",
    "The paper shows that one can manipulate the uncertainty estimation of a neural network without harming its accuracy by perturbing the inputs. To this end, the paper proposes a greedy heuristic to decrease the perturbation size of FGSM until the adversarial example does not flip the original prediction. Experimental results show that the proposed method indeed can increase several uncertainty estimation metrics (i.e., AURC, NLL, and Brier Score) of several types of neural networks regarding the uncertainty, e.g., softmax-based or MC dropout, without reducing their accuracy. ",
    "A streaming Stochastic Block Model (SBM) is proposed as null model to analyze streaming community detection algorithms on growing graphs. A online algorithm based on Belief Propagation (BP) is proposed to estimate community membership in this setting. It is proven to achieve the same accuracy as its offline variant BP in a simplified setting. ",
    "This paper tackles a streaming version of community detection, where the vertices of a graph generated with the classical stochastic block model are revealed sequentially, in a random order.  The authors restrict themselves to what they call $R$-local algorithms, wherein the new information brought by the arrival of a vertex is only propagated at distance at most $R$ of this revealed vertex.  In the absence of side information (i.e. additional information correlated with the ground truth community of each vertex), they show that this class of algorithms is unable to yield meaningful reconstruction when $n$ goes to infinity. In contrast, when side information is present, they provide an algorithm (StreamBP) for community detection, and show that this algorithm matches the performance of the classical belief propagation algorithm (OfflineBP) on the whole graph.   Those results are complemented by experiments on both synthetic and real-world datasets, comparing the StreamBP and OfflineBP algorithms, as well as several alternatives : simple voting algorithms, and a modified version of StreamBP (StreamBP*), modified to better deal with real-world datasets while enjoying the same theoretical guarantees as the original algorithm.",
    "This paper proposes to do community detection in a variant of the stochastic block model for which nodes arrive in a streaming fashion, and there may exists noisy estimates of the real labels. They prove that if the noise render the side information uninformative, a local streaming algorithm is equivalent to a local algorithm, which cannot achieve non-trivial accuracy. If the side information is informative, they provide a belief propagation algorithm in the streaming setting which achieves comparable accuracy to offline BP asymptotically. Offline BP has been conjectured to be optimal, so their algorithm would also be optimal if the conjecture is proven (it is in special cases). They also provide another algorithm which is in practice more consistent than StreamBP.",
    "The paper considers the problem of recovering the communities in a streaming version of stochastic block models, using information within a bounded radius. The main technical results are the limits of recovery with no side information, and a streaming version of belief propagation which has the same reconstruction accuracy as the offline BP algorithm using side information. The algorithms are evaluated on synthetic and real networks, and show good performance.",
    "This paper studies a dynamic version of the stochastic block model, named as streaming stochastic block model (StSBM). The authors consider a sparse regime and analyze the asymptotic behavior of the model. In particular, the authors show that without some side information about the node labels, recovery of the true labels through a R-local streaming algorithm is no better than random guessing (Corollary 1). The authors also propose a streaming R-local belief propagation algorithm (StreamBP), and show their streaming algorithm perform as good as the offline version algorithm (Theorem 2). Empirical evaluations using synthetic and real-world datasets are provided in the paper.",
    "This paper studies various ways to parameterize linear neural nets and explore the regularization on the linear mapping (in terms of the final function obtained by multiplying all weight layers in the linear net) induced by l2 regularization in parameter space.   A large number of architectures are studied -- fully connected deep networks, diagonal networks, convolutional networks, and residual nets, with a characterization of the induced regularization for each of these settings. In addition, the paper also studies how to construct architectures to induce a particular desired regularizer. First, they study \\ell_p norms and show that the \\ell_p norm can be the induced regularizer if and only if p = 1, 2, with structural requirements on the architecture of the network. They also analyze which architectures can induce \\ell_{p, q} group norms. All of the results in this paper are for linear neural nets.",
    "This paper studies the representation cost of linear neural networks. Considering a target linear function with parameter matrix $B$, the authors investigate the effect of $\\ell_2$ regularization in the predictor space. It is shown that a fully connected network regularizes the trace norm of $B$, diagonal network regularizes the $\\ell_{1,2}$ norm of $B$, convolutional network regularizes a certain norm of the discrete Fourier transform of B, etc. The authors also discuss how one can design a linear neural network architecture to achieve certain regularization effects. ",
    "This paper investigates the correspondence between the architecture of a linear neural network and the complexity measure induced by putting $l_2$ regularization on the weights. On one hand, the authors study the complexity measure induced by fully-connected networks, diagonal networks, convolutional networks with full or limited filter width, as well as residual networks. On the other hand, the authors also present the architectures that induce $l_p$, $l_{p, q}$ as well as $k$-support norms as complexity measures.",
    "This paper studies the representation cost in the setting of linear networks. It is shown that an l^2 regularization on the parameters corresponds to adding a penalty on the functional space governed by the representation cost. This paper shows how the representation cost depends on the architecture and how the bias depends on the representation cost. ",
    "The paper studies representation costs of linear networks and their induced complexity measures. First the representation costs of some standard architecture are given (fullly-connected nets, diagonal nets, convolutional nets, and residual nets), then for shallow networks a general formula for the representation cost (and its dual norm, given that the representation cost is convex) of any network is given. The second part of the paper is dedicated to the characterization of which complexity measures can appear from the representation cost of a neural network. Though this question is not answered in general, the authors study a number of related questions: a characterization of which $l_p$ can be represented by a neural network is given, then some example architectures are given to obtain group $l_{p,q}$ norms or $k$-support norms, then it is shown that $l_{p,q}$ group norm with overlapping groups and elastic nets cannot be recovered by a neural network representation cost (though it is possible for the representation cost of a general homogeneous parametrization). ",
    "This paper provides a very simple approach to the problem of knowledge base completion. The idea is this - given a query (subject, relation), you find other entities similar to subject, see which other paths they can take to their corresponding object if they express the relation, and check if the subject express those paths. Object reached this way are candidate answers. The one with most paths reached is marked correct.",
    "This paper proposes a non-parametric reasoning method for reasoning on incomplete knowledge bases. Specifically, for the task of finding a target entity given a source entity and a relation, since this specific relation might be missing for the source entity, multi-hop reasoning is required to get the answer. To get the reasoning paths, this paper proposes to first retrieve similar entities from the knowledge base that have the same outgoing relation, and then gather all possible reasoning paths from these retrieved entities. Finally, these reasoning paths extracted from other entities can be applied to the source entity in the query and get the answer. ",
    "The paper describes an evaluation of several pre-training strategies for the task of entity linking, using the AIDA and TAC-KBP baselines. In particular, the authors look at the impact of entity candidate selection strategies, adding noise during pre-training, and context selection methods. The model employed for entity disambiguation is a 4-layer transformer for the language representation, with an MLP final layer to perform disambiguation. The analysis of the pre-training strategies is detailed, and could be interesting for others using the transformer architecture to perform entity linking. Minor issue, but the paper is missing a conclusion section - this could be used to discuss how these results can generalize to other methods for entity linking.",
    "This paper investigates the use of a simple architecture for entity disambiguation: encode the mention and its context with BERT, use an MLP over the mention's fenceposts to compute an embedding, then compare that embedding with embeddings of entity candidates and take the one with the highest dot product. Notably, it uses a transformer pre-trained on Wikipedia to do entity resolution, but does *not* use the BERT model or its pre-trained parameters directly.  The paper deals with several design decisions along the way: how to pre-train this model on Wikipedia, how to generate candidates at train and test time, whether or not to mask the input as in BERT, and other hyperparameters. Results show state-of-the-art performance on CoNLL (with a good candidate set) and TAC-KBP, as well as good performance on end-to-end entity linking (detecting and linking mentions).",
    "This work makes use of uncertainty estimation methods from active learning to select a subset of training data that produces models with similar (or better) performance compared to models trained on the full training set. It proposes a way to improve the Monte Carlo estimation of model uncertainty by including multiple checkpoints that are generated \"for free\" during a training run, thereby increasing the number of samples from 5-10 in previous work to 100 in this work. It compares several initialization schemes for the subset model using mutual information as the acquisition function, finds that a \"build-up\" approach (based on Chitta et. al 2018a) works best, and uses that for the rest of the studies. It then compares several acquisition functions, using the build-up approach, finds that variation ratio performs best, and uses that for the rest of the studies. Next, it compares the Top-1 accuracy on ImageNet obtained by evaluating the ensemble models produced by different ensembling schemes, and finds that ensembling 20 checkpoints from 5 training runs with different random seeds work best. Then, it uses acquisition models that use ensembles from each ensembling scheme to select subsets of the ImageNet data to be used for training the subset model, and then compares the performance of the subset models. Finally, it demonstrates this method of selecting a subset of the training data works even if the subset is used to train a model with a different architecture from the acquisition model.",
    "Overall, I'm not quite convinced this method would be worth the trouble to implement. On the more realistic benchmarks, they need to keep ~80% of the total dataset size and the claimed \"improvement\" is rather small (less than 0.6% absolute gain in accuracy, e.g. from 81.86% to 82.37% on CIFAR100 and from 72.33% to 72.78% on ImageNet). There is no runtime comparison, there are missing baselines, and most of the method development seems guided by trying out many options instead of taking a principled approach. Without these, the paper is just not ready for a top conference like ICLR.",
    "Authors improve upon dynamic routing between capsules by removing the squash function (norm normalization) and apply a layerNorm normalization instead. Furthermore, they experiment with concurrent routing rather than sequential routing (route all caps layers once, then all layers concurrently again and again). This is an interesting development since provides better gradient in conjunction with layerNorm. They report results on Cifar10 and Cifar100 and achieve similar to CNN (resnet) performance.",
    "This paper presents a new simpler routing mechanism for capsule networks and achieves good performance on real world data sets making use of this new capsule structure along with a restnet backbone. Strong performance on the cifar10 and cifar100 datasets are presented and the network outperforms earlier versions of capsule networks. This new structure also performs well on an augmented MNIST dataset of overlapping digits (similar to the one used by Sabour et al 2017). ",
    "This work presented an improvement of grid search algorithm for certain hyperparameters in deep neural nets training. These hyperparameters, such as learning rate and drop out, have \"temperature\" like meaning to control the noise injected in the training. With this analogy, the author proposed to use the idea of parallel tempering in statistical physics to allow exchange these hyperparameters during the training. Their empirical results showed this improves standard grid search.",
    "The paper proposes a new paradigm to perform hyperparameter search by proposing a way to jointly optimize over the hyperparameter space and the parameter space as opposed to the traditional way to performing these in separation (with the hyperparameter search invoking the parameter optimization) The paper\u2019s main claim is that this allows the seach to follow non-local paths in the joint space. The main methodology proposed in the paper is inspired by the idea of parallel tempering from physics. The paper proposes to view parameter learning under a certain hyperparameter as running a langevin chain at a particular temperature. This is motivated by considering common hyperparameters as batch size, dropout rate or learning rate as inducing a specific level of noise to the training process, the variance of which is analogous to the inverse temperature in Langevin diffusion. ",
    "In the context of neural machine translation, limitations of some reinforcement learning methods, in particular REINFORCE and contrastive minimum risk training (MRT), are analyzed. The authors argue that MRT doesn't optimize the expected reward. Moreover, they show that using REINFORCE, with either realistic or dummy constant rewards, may lead to a peakier distribution. Similar BLEU scores are obtained with either type of rewards, which is an interesting and perplexing result (in my opinion). For both REINFORCE and MRT, the paper shows that unless the gold token was already amongst the most probable after pre-training, it takes many samples for it to become the most likely output, which limits the usefulness of on-policy RL approaches.",
    "This paper first theoretically demonstrates that a commonly used reinforcement learning method for neural sequence-to-sequence models (e.g. in NMT), contrastive minimum risk training (CMRT), is not guaranteed to converge to local (let alone global) optima of the reward function. The paper then empirically demonstrates that the REINFORCE algorithm, while not subject to the same theoretical flaws as CMRT, in practice fails to improve NMT models unless the baseline model is already \"nearly correct\" (i.e. the correct tokens were already within the few most probable tokens before the fine-tuning steps with REINFORCE). In fact, some of the performance gains of using REINFORCE/CMRT can be attributed to making the model's output probability distribution more peaked, and not necessarily from making the target tokens more probable as commonly assumed.",
    "This paper studies the asymptotic properties of action value function $Q$ and value function $V$. Specifically, the authors assume that we can collect $n$ data points $\\{(s_t,a_t,r_t(s_t,a_t),s_{t+1})\\}_{t=1}^{n}$. Based on the collected data, the authors calculated the sample mean of the unknown reward function $\\widehat r_n$ and transition probability $\\widehat{P}(\\cdot|s,a)$. They further defined an estimator $\\widehat Q_n$, which is the fixed point of the empirical Bellman operator $\\widehat{\\mathcal{T}}_n$ derived from $\\widehat r_n$ and $\\widehat P_n$. The authors proved under certain assumptions that $\\widehat Q_n\\rightarrow Q^*$ almost surely. Based on this argument, they also derived a similar convergence of value function $\\widehat V_n$ in distribution. Confidence intervals can also be established based on these results.",
    "This paper studies the inference problem of reinforcement learning. With a given exploration policy that satisfies some strong property to collect n data, the paper studies the distribution of the estimated optimal value function and Q-function when n goes to infinity. Both unique and non-unique optimal policy cases are studied. The non-unique case has a very different behavior as it is no longer Gaussian. The paper then uses these estimations to design a method that better explores and proposes a method Q-OCBA. Experiments were performed to compare this method with previous algorithms, e.g., UCRL.",
    "This paper introduces a collaborative generated hashing (CGH) method to learn hash funcations of users and items from content data. The approach first provides a strategy to discover potential users by the generative step and inference through adding balanced and uncorrelated constraints. The experiments demonstrates some effectiveness on improving accuracy for both warm-start and cold-start recommendations.",
    "The work considers the problem of efficient user and item recommendations in the warm- and cold-start settings. It aims at improving computational efficiency of the best candidate selection in these settings by utilizing binary codes representation. The transformation from an actual to a binary code representation is learned in a hybrid manner using both collaborative and content information. In order to keep such representations compact yet expressive enough, the authors impose a set of constraints that ensure balanced and uncorrelated transformations. Once binary codes are learned, the inference can be made by virtue of efficient Hamming distance computations. Moreover, the search for candidate entities can be performed via the generative step that projects binary codes onto actual feature space, where kNN-based techniques can be further utilized.",
    "The paper proposes an adversarial transfer learning network that can handle the adaptation of both the input space and the output space. The paper is motivated by the application of drug response prediction where the source domain is cell line data and the target domain is patient data. Patient data are usually scarce, hence motivating transferring the knowledge learned from the more widely available cell line data to improve the predictive performance based on the patient data.  The idea of making use of adversarial networks is to learn a representation of the data points that is invariant to whether the data points come from the source domain or the target domain. Experiments on real-world data over four drugs demonstrate the effectiveness of the proposed methods compared to other methods that are not specifically designed for this scenario.",
    "the paper studies transfer learning, which addresses the inconsistencies of the source and target domains in both input and output spaces. usually, we only worry about the inconsistencies in the input domain but here we worry about input and output. the paper proposes adversarial inductive transfer learning which uses adversarial domain adaptation for the input space and multi-task learning for the output space.",
    "This paper focuses on model based reinforcement learning (RL). Specifically, the authors consider the setting of combining model based and model free RL algorithms by using the learned dynamics model to generate new data for training the model free algorithm. In order to capture the uncertainty of the environment and the model, the author applied Baysian neural network to learn the dynamics of the environment. The authors approximated the true Bayesian inference process by keeping an anchored ensemble of neural networks, where the prior and posterior of network weights are approximately Gaussian. The ensemble of dynamics model is then used to generate data to train a PPO[1] based agent. In order to prevent the agent from exploiting the learned dynamics model, the authors propose a heuristic way of balancing the amount of real data and model generated data by comparing the rewards.",
    "This paper presents a new model-free + model-based algorithm, MBPGE, that trains a policy using a policy gradient algorithm on top of the learned models. Contrary to previous approaches, they use a true Bayesian distribution by means of the randomized anchorized MAP. Furthermore, they combine rollouts from the real environment and from the learned dynamics directly for the policy training, instead of relying just on the ones of learned dynamics, which induces a larger distributional shift.",
    "This paper proposed a new defense method for capsule networks. For both white-box and black-box settings, the proposed CapNets has shown superior performance than two variants of CNNs. The visualizations of adversarial examples generated by the CapNets are more aligned with the human perception which is very insightful. On the corrupted MNIST dataset, the results show the proposed defense method can also be used well as an out-of-distribution detector. Overall the paper is clearly written and easy to follow.",
    "This paper studies the problem of detecting and generating adversarial images using class-conditional capsule networks. Specifically, this paper first introduced a novel method that detects adversarial examples by class-conditional image reconstruction. Motivated by this defense method, this paper further proposed a novel reconstructive attack that minimizes both classification and reconstruction loss. Experimental evaluations are conducted on MNIST, FashionMNIST, SVHN, and CIFAR-10 dataset. Results demonstrate the effectiveness of the proposed defense and the novel reconstructive attack method.",
    "This paper discussed the property of the NTK with the increasing depth L with the help of the Edge of Chaos initialization. The authors show that if deep neural networks are not properly initialized, the NTK can have a large condition number, which leads to the poor performance of training and generalization. Moreover, the authors also introduce the conditions that make the neural network trainable by decreasing the convergence rate to a nearly constant kernel w.r.t the depth L by using the specific Edge of Chaos initialization as well as different activations and use residual connections. Experiment results show that the theoretical results are well aligned with the practice.",
    "The paper studies the limiting behavior of neural tangent kernels when the depth grows to infinity. They show that the obtained limit kernels are trivial (a constant) unless one uses 'edge of caos' initialization, in which case they are close to the identity. The authors compare the convergence for different activations, showing a slower convergence (hence better propagation) for some piecewise smooth activations compared to ReLU. For residual networks, the 'edge of caos' behavior is claimed to be in place regardless of the initialization.",
    "The paper proposes a new sentence embedding method. The novelty is to use dependency trees as examples in the self-supervised method based on contrastive learning. The idea to use linguistic knowledge in the design of sentence embeddings is attractive. The sentence representation is computed by a bi-LSTM and dependency tree representations are computed by Tree LSTM. The softmax classifier is trained using the negative log-likelihood loss.",
    "This paper describes a self-supervised sentence embedding approach that incorporates a different view from plain text where some extent of linguistic knowledge is incorporated through the application of tree LSTM. The training procedure is standard contrastive framework where the model is encouraged to distinguish between context sentence (sentences appearing close to the target sentence) and negative samples. Evaluations are conducted on 1) downstream tasks, but with a simple logistic regression model on top of sentence embeddings; 2) probing tasks that more focus on surface information prediction, syntactic and semantic tasks; and 3) qualitative analysis with nearest 5 sentences.",
    "This paper proposes a domain adaptation type of task via proposing fine-tuning of pre-trained models such as BERT on data from financial domains. The paper starts off with a good motivation about requiring some kind of domain adaptation particularly when performing tasks such as sentiment analysis on data sets from the financial domain. However, there is not much novelty in this paper.",
    "This paper described the application of BERT in the field of financial sentiment analysis. Authors find that when fine-tuned with in-domain data, BERT outperforms the state-of-the-art, demonstrating that language model pre-training can transfer knowledge learned from unsupervised large corpus to new domain with minimum effort. Experiments are conducted to explore 1) the utility of different in-domain dataset for further pre-training; 2) strategies to avoid catastrophic forgetting, and 3) effectiveness of fine-tuning a subset of the full model. ",
    "This paper claims to be the first to tackle unconditional singing voice generation. It is noted that previous singing voice generation approaches leverage explicit pitch information (either of an accompaniment via a score or for the voice itself), and/or specified lyrics the voice should sing. The authors first create their own dataset of singing voice data with accompaniments, then use a GAN to generate singing voice waveforms in three different settings:",
    "This paper has set a new problem: singing voice synthesis without any score/lyrics supervision. The authors provide a significance of such a problem in section 1. Also, the authors successfully design and implement a novel neural network architecture to solve the problem. It\u2019s also notable that the authors kindly open-source their code to mitigate the reproducibility issue. This paper may serve as baseline results for the proposed problem in the future.",
    "This paper tackles the problem of designing neural network architectures that are robust to adversarial attacks. Several defense techniques against adversarial attacks have been proposed, mainly adversarial training (train on perturbed inputs) and introducing random perturbation to the weights or activations of the network. The paper claims that one limitation of the second approach is that it introduces artifacts (e.g. sparsity). The authors propose a simple but original idea to address this issue: parameterize the network's weight matrices as low rank tensors (in the Tucker format) and randomize the weights by sketching the core tensor of the Tucker decomposition (in effect, the sketching amounts to randomly setting fibers of the core tensor to 0). ",
    "In this paper, the authors propose a randomization-based tensorization framework towards robust network learning. The high-level idea of this work is to reparameterize the network parameters W of each layer with low-rank tensors, where the factor matrices are injected with randomization through randomly sampled sketching matrices. Since the randomization is is done within a subspace than directly on the weight matrix itself, the authors claim that this brings certain advantages such as less sparsity.",
    "This paper proposes a clustering attention-based approach to handle the problem of unsmoothness while modeling spatio-temporal data, which may be divided into several regions with unsmooth boundaries. With the help of a graph attention mechanism between vertices (which correspond to different regions), the CGT model is able to model the (originally unsmooth) cross-region interactions just like how Transformers are applied in NLP tasks (where words are discrete). Experiments seem to suggest a big improvement when compared to baselines.",
    "In this paper, the authors developed a neural network architecture to address the spacial and temporal unsmoothness problem, which was claimed to be neglected by existing works. The proposed model, CGT, has an encoder-decoder structure, and is characterized by clustering modules for spacial regions based on their temporal patterns. To handle temporal unsmoothness, additivity-preserved multi-view position encoding was proposed to characterize different temporal relationships. The experimental results on real ride-hailing datasets demonstrate the effectiveness of the proposed method to some extent.",
    "The authors provide a theoretical analysis of deep Q-learning based on the neural fitted Q-iteration (FQI) algorithm [1]. Their analysis justifies the techniques of experience replay and target network, both of which are critical to the empirical success of DQN. Moreover, the authors establish the algorithmic and statistical errors of the neural FQI algorithm.",
    "This paper provides an analysis of fitted Q-iteration in the off-policy reinforcement learning setting, for the setup where the value function class of interest is a class of neural networks. The provide bounds on the rate at which fitted Q iteration converges to a near-optimal policy under the assumption that the transition dynamics satisfy a certain notion of Holder smoothness. This result is motivated by the problem of understanding why deep Q-learning works, which the authors relate to the problem above via certain simplifying assumptions. The authors also extend this result to give similar guarantees for two-player zero-sum stochastic games.",
    "This paper addresses an issue of compositionality in self-attention models such Transformer. A simple idea of composing multiple words into a phrase as a hypernode and representing it using a non-linear function to capture the semantic mutation is proposed. In the machine translation and PoS tagging tasks, the proposed PhraseTransformer achieves impressive gain, especially +13.7 BLEU score compared to the Transformer.",
    "This submission proposes to consider to put attention on \"phrases\" in NLP. The phrases are generated by taking consecutive words in sentences. Each phrase is treated as a \"node\" in the same way as words. Then representations of phrases are learned in the network. The algorithm is applied to two applications, translation and pos tagging. The proposed method achieved better performance than transformer. ",
    "This paper proposes a novel modular neural architecture for algorithm induction. The modules are fixed and a controller policy is learned which outputs a distribution over modules and input/output locations on a memory tape. An oracle (which knows the correct answer) is necessary to decide when to stop computing. The controller is trained by a variant of REINFORCE.",
    "This paper proposes Modular Algorithm Induction Network (MAIN) that learns algorithms given input-output examples. MAIN is equipped with several components that make it perform better than baselines, but probably the most important part is its use of modules to break-down algorithmic tasks into simpler problems. MAIN is learned end-to-end using reinforcement learning and demonstrated to perform well in several tasks.",
    "The paper studies the sensitivity of a neural network with respect to quantizing its weights and activations. The idea is to use Monte Carlo Arithmetic (MCA) in order to calculate the number of significant bits in the training loss (e.g. cross entropy) that are lost due to floating-point arithmetic. The results show that the number of significant bits lost correlates with the reduction in classification accuracy when quantizing the weights and activations of the neural network.",
    "The authors propose a scalable method based on Monte Carlo arithmetic for quantifying the sensitivity of trained neural networks to floating point rounding errors. They demonstrate that the loss of significance metric K estimated from the process can be used for selecting networks that are more robust to quantization, and compare popular architectures (AlexNet, ResNet etc.) for their varying sensitivities.",
    "The paper claims that it identifies a fundamental issue in model-based reinforcement learning methods. The issue is called objective mismatch, which arises when one objective is optimized (for example, model learning objective) without taking into consideration of another objective (for example policy optimization). The author shows several experiments to illustrate the issue and proposes a method to mitigate it by assigning priorities to samples when training the model. ",
    "This paper discusses the old problem of mismatch between the ultimate reward obtained after optimizing a  decision (planning or control) over a probabilistic model (of dynamics) and  the training  objective for the model (log-likelihood). Experiments highlight that the NLL and reward can be very poorly correlated, that improvements in NLL initially improve reward but can later degrade it, and that models with similar NLLs can lead to very different rewards. A  reweighting trick is proposed and summarily evaluated.",
    "This paper presents an adversarial attack based on the feature representations at different layers given the classes. Instead of only looking at the final layers, class samples in intermediate feature space information is used to attack and increase transferability at the same time. Then the noise is optimized to perturb the input so that the a specific wrong output will be more likely to chosen. The paper is clear and well-written and different interesting experiments support the claims.",
    "The paper proposes a new adversarial attack for the targeted blackbox model Unlike previous approaches which use the output layer possibly with some additional terms and regularization, the proposed approaches only rely on intermediate features. In fact, the adversarial example is based on a single intermediate layer. The adversarial examples are built by training, for each target class, a binary classifier for the class based only on the features of that layer.",
    "This paper proposes using Wasserstein Distances to measure the difference between higher-level functions of policies, which this paper terms as \"behaviors\". For example, one such behavior could be the distribution over final states given the policy, or the distribution over returns given policy. Through the lens of these behavioral embeddings, this paper recovers a few important special cases that are well-known in the literature including WD-based TRPO and distributional RL. This paper shows that the dual formulation of the Wasserstein Distance gives the ability to score individual policies based on a given \"behavioral mapping\".",
    "this paper proposes a new regularized policy optimization (PO) method which is based on Wasserstein distances. Its idea is to use SGD to optimize the dual form of the WD, then used in two different policy search approaches TRPO and Evolution Strategies. The evaluations are carried out on a variety of control tasks from OpenAI Gym. ",
    "This paper proposes a new gradient descent methods for training deep neural network which can take the adaptive step size with only one hyper-parameter to tune -- the maximum learning rate -- and achieve comparable results to stochastic gradient descent (SGD) on various tasks and models. In order to achieve that, they develop a stochastic extension of the Polyak step-size for the non-convex setting, namely the adaptive learning-rates for interpolation with gradients (ALI-G), in which the minimal value of the objective loss is set to 0 due to interpolation in neural networks and the learning rates are clipped by a chosen maximal value. The problem is formulated clearly, and the review on the Polyak step-size and related works are well done. Another main contribution of the paper is to provide the convergence guarantees for ALI-G in the convex setting where the objective loss is Lipschitz-continuous (Theorem 1 in the paper). Their theorem also takes into account the error in the estimate of the minimal value of the objective loss. In addition, they derive the connections between  ALI-G and SGD and show that compared to SGD, ALI-G take into consideration that the objective loss is non-negative and set the loss to 0 when it is negative. They perform empirical study to compare their algorithm with other methods including Adagrad, Adam, DFW, L4Adam and SGD on learning a differentiable neural computer, object recognition, and a natural language processing task. Their experimental results show that ALI-G performance is comparable with that of SGD with schedule learning rate.",
    "This paper proposes a new adaptive learning rate method which is tailored to the optimization of deep neural networks. The motivating observation is that over-parameterized DNNs are able to interpolate the training data (i.e. they are able to reach near-zero training error). This enables application of the Polyak update rule to stochastic updates and a simplification by assuming a zero minimal training loss. A number of proofs for convergence in various convex settings are provided, and empirical evaluation on several benchmarks demonstrates (a) ability to optimize complex architectures, (b) performance improvements over, and (c) performance close to manually tuned SGD learning rates.",
    "This paper proposed a dataset and designed a relevant network structure to analyze the function of horizontal and top-down connections for perceptual grouping. The used two datasets smartly isolate the requirements for exploiting Gestalt cues and object-based strategies. Appendix A detailed describes the cABC dataset, and the control experiments in Appendix B further validate the designing of the cABC. The proposed network flexibly integrates three types of connections and successfully solves both two challenges. The visualization results in Figure 4, S8 and S9 are insightful and also validate the intuitions. Overall the paper is clearly written and easy to follow.",
    "The article tries to examine existing hypotheses from the neuroscience and perception literature by using neural networks as a computational model of the brain. Namely, the authors assess the efficiency of different strategies for solving two visual challenges, one of which is novel. The authors also evaluate the level of consistency between the performance of humans and different types of neural architectures.",
    "To enforce sparsity in neural networks, the paper proposes a scale-invariant regularizer (DeepHoyer) inspired by the Hoyer measure. It is simply the ratio between l1 and l2 norm, which is almost everywhere differentiable, and enforces element-wise sparsity. It further proposes the Hoyer measure to quantify sparsity and applies the DeepHoyer in DNN training to train pruned models. The extension of Hoyer-Square is also straightforward. ",
    "The paper focuses on sparse neural networks. Typically, l1 regularization is the go-to strategy, however, it is not scale invariant. That is, all weights are affected by the regularization, not only those that are being driven to 0. l0 regularization is theoretically optimal, however, it is not smooth and has no gradients almost everywhere, so it cannot be used for training. As a compromise the paper proposes Hoyer regularization, that is the l1/l2 ratio. The Hoyer regularization has the same minima structure and leads to sparse solutions while being scale invariant, that is it does not affect all weights in the process. Additionally, the paper proposes structured Hoyer regularization. Last, it employs the said regularizations in deep networks: LeNet, AlexNet and ResNet on several datasets: MNIST, CIFAR, ImageNet.",
    "In the setting of online convex optimization, this paper investigates the question of whether adaptive gradient methods can achieve \u201cdata dependent\u201d logarithmic regret bounds when the class of loss functions is strongly convex. To this end, the authors propose a variant of Adam - called SAdam - which indeed satisfies such a desired bound. Importantly, SAdam is an extension of SC-RMSprop (a variant of RMSprop) for which a \u201cdata independent\u201d logarithmic bound was found. Experiments on optimizing strongly convex functions and training deep networks show that SAdam outperforms other adaptive gradient methods (and SGD).  ",
    "In this paper, the authors propose a variant of Adam, named as SAdam, and establish a data-dependent O(log T) regret bound. The key idea is using a faster decaying yet under controlled step size to exploit strong convexity. Some experiments are carried out to demonstrate the effectiveness of the proposed algorithm. The idea seems interesting, the writing is well-written, and the analysis seems correct (I did not fully check all steps, but the key steps seems ok to me). ",
    "This paper introduces a optimisation for BERT models based on using block matrices for the attention layers. This allows to reduce the memory footprint and the processing  time during training while reaching state-of-the-art results on 5 datasets. An interesting study on memory consumption in BERT is conducted. No results are given at test time : is there also a memory and processing time reduction ?",
    "The paper propose to sparsify the attention matrix to decrease memory usage and to speed up training. The authors experiment the model on multiple tasks. The model gains ~20% efficiency with ~20% decrease in memory use while maintaining comparable performance to the state of the art model. To keep the performance comparable, the authors use the same training corpus. The authors also discuss how block size could change the performance of the model. The paper is clear and well organized with good experiment results.",
    "This paper mainly studies the relationship between the generalization error and mean/variance of the test accuracy. The authors first propose a new score for pruning called E[BN]. Then, the authors observe the generalization error and the test accuracy mean/variance for pruning large score weights and small score weights for VGG11, ResNet18, and Conv4 models. From these experiments, the authors observe that pruning large score weights generates instable but high test accuracy and smaller generalization gap compared to pruning small score weights. The authors additionally study some other aspects of pruning (e.g., pruning as a noise injection) and conclude the paper.",
    "The paper is an empirical study that looks into the effect of neural network pruning on both the model accuracy as well as the generalization risk (defined as the difference between the training error and the test error). It concludes that while some pruning methods work, others fail. The authors argue that such discrepancy can be explained if we look into the impact of pruning on \"stability\". ",
    "This paper borrows the idea of word-to-vector from NLP and applies it in reinforcement learning based Neural Architecture Search (NAS). It suggests a pretrained encoder to transform the search space to a dense and continuous architecture-embedding space. First it trains the architecture-embedding encoder and decoder with self-supervision learning like Auto-Encoder.  Then it performs reinforcement learning based Neural Architecture Search(NAS) in the architecture-embedding space.",
    "The paper proposes an interesting idea to perform Neural Architecture Search: first, an auto-encoder is pre-trained to encode/decode an neural architecture to/from a continuous low-dimensional embedding space; then the decoder is fixed but the encoder is copied as an agent controller for reinforcement learning. The controller is optimized by taking actions in the embedding space. The reward is also different from previous works which usually only considered validation accuracy but this work also considers the generalization gap.",
    "In this paper, the authors propose the Homotopy Training Algorithm (HTA) for neural network optimization problems. They claim that HTA starts with several simplified problems and tracks the solution to the original problem via a continuous homotopy path. They give the theoretical analysis and conduct experiments on the synthetic data and the CIFAR-10 dataset. ",
    "The work proposes to learn neural networks using homotopy-based continuation method. The method divides the parameter space into two groups (extendable to multiple groups) and introduces a homotopy function which includes the original optimization problem as an extreme case.  By varying the homotopy parameter, one can construct a continuous path from a supposedly easier to solve optimization problem to the problem of interest. The authors prove convergence in the non-convex case, the existence of solution path in the convex case and demonstrate the effectiveness of the proposed method on synthetic and real datasets.",
    "The paper proposes a transformer block with higher-order interactions. More precisely, instead of computing a dot product between a query vector and a key vector, 2-simplicial attention computes scalar triple product. Instead of computing a weighted average of value vectors, 2-simplicial attention computes the weighted average of tensor products of value vectors. The resulting architecture has improved representation power which is demonstrated using experiments on bridge BoxWorld environment.",
    "C1. Simplicialization of attention. Interpreting standard attention weights of a head as the model\u2019s estimate of the probability of an edge = 1-simplex linking the variables encoded by 2 blocks of the Transformer, representing that the blocks stand in a binary relation encoded in the head, a generalization to 2-simplexes is made: now attention also estimates the probability of a 2-simplex indicating that three blocks stand in an arity-3 relation. ",
    "This paper proposes to employ conditional variational autoencoder (CVAE) to estimate the geometry of 2D rotations of objects given images partially labeled. Here, the label represents the geometry of the 2D rotation. The proposed method introduces two latent representation. z is the ordinal latent variable and r a latent representation for the rotations where the latent variable is defined in the 1-dimensional circle in R^2 so that it can naturally represent a hyperspherical latent space. ",
    "This paper presents a semi-supervised approach to learn the rotation of objects in an image. The primary motivation is that for rotation estimation datasets may not always be fully labeled, so learning partially from labeled and partially for unlabeled is important. The approach is to use a CVAE with a supervised loss and an unsupervised loss and to jointly train the network. Limited experiments that show performance are presented.",
    "The paper proposes a kind of curriculum for large-scale multi-agent learning. The related work section mentions some obvious points of comparison (note: see also https://science.sciencemag.org/content/364/6443/859.abstract). However, the authors do not compare with ANY of this work (either in terms of algorithm design or performance). It is therefore difficult to evaluate the contribution. ",
    "This paper proposes a new method of scaling multi-agent reinforcement learning to a larger number of agents using evolution. Specifically, the procedures (EPC) involves starting with a small number of agents, training multiple sets in parallel, and doing crossover to find the set of agents that generalize best to a larger number of agents. This is motivated by the intuition that agents that perform best in small groups may not be the ones that perform best in larger groups. These claims are empirically verified in three games based on the particle world set of environments. ",
    "The paper proposes a novel, feedforward, end-to-end trainable, deep, neural network for abstract diagrammatic reasoning with significant improvements over the state of the art. The proposed model architecture is reasonable and is designed to exploit the information present at multiple granularities \u2013 at the level of objects in the diagram, their relations across diagrams, and diagram subsets. As a multimodule neural pipeline, it seems a reasonable design. Further, it shows significant performance gains over the state of the art.  ",
    "In this paper the authors solve for the task of Raven Progressive Matrices (RPM) reasoning. They do so by considering multiplexed graph networks. They present an architecture for the same. The basic premise is a combination of object level representation that is obtained by a method similar to region proposal and combining them with graph network. The approach uses gated graph networks that also uses an aggregation function. These are combined and result in node embeddings. Detailed analysis of the network is provided. This provides improved results over earlier WREN method. However, the performance is slightly lesser than another paper simultaneously submitted that achieves similar results. That approach uses transformer network for spatial attention while here the spatial attention is just based on object level representation.",
    "The authors propose the adaptive thermostat Monte Carlo sampler for feedforward neural networks. The proposed approach dynamically adjust the amount of momentum and noisy applied to each model parameter during updates. ResNet++ (ResNet without batchnorm/dropout but adding SELU, fixup and weight normalization) is introduced. Further, the authors claim that the need for hyperparameter setup is reduced provided that early stopping, stochastic regularization and carefully tuned learning rate schedules are not required.",
    "This paper proposes a novel MCMC algorithm (ATMC) that estimates and samples from the posterior distribution of neural network weights. The motivation for this approach is that applying Bayesian inference to deep learning should lead to less overfitting and better uncertainty-calibrated models. Unlike previous work, the proposed method scales to large models (ResNet) and data sets (ImageNet).",
    "This paper presents a method to speed up training of deep neural networks. The main contribution is a method to quickly identify winning lottery tickets (denoted early-bird, or EB by the authors), without running the model to convergence. The authors present interesting preliminary experiments that motivate their method, and show that it works on two image recognition datasets using two models.",
    "The authors further study the lottery ticket hypothesis formulated by Frankle and Carbin. They demonstrate that the sparsity pattern corresponding to a lottery ticket for a given initialization can be uncovered via low-cost training. By doing so, they propose a method to: 1) first identify the lottery ticket efficiently and 2) exploit the sparsity of the resulting network to train it at a lower cost.",
    "The paper proposed a adversarial learning framework that tries to align the hidden features of data with simple prior distributions.  A training strategy similar to GAN  was exploited. The proposed framework was argued that it can well deal with the adversarial perturbations. Some experiments were conducted, verifying that the proposed algorithm seems useful and robust.",
    "This paper proposes a new regularization technique called Embedding Regularization to improve the adversarial robustness.  The idea is to use generative adversarial networks (GAN) to perform inference on the latent space by matching the aggregated posterior of the hidden space vector with a prior distribution. The proposed strategy could be combined with adversarial training to achieve state-of-the-art adversarial accuracy on several benchmark datasets. ",
    "The paper proposes a new joint learning algorithm that works for two tasks, NER and RE. The model is based on a pre-trained BERT model, which provides the word vectors of the input word sequence. Then it solves two tasks with two network branches: the first branch minimizes the loss for NER, and the second branch minimizes the loss for RE. The second branch uses entity labels predicted by the first branch, so joint learning may benefit both tasks. ",
    "The paper proposes an end-to-end joint model for named entity recognition (NER) and relation extraction (RE), using pre-trained language models. The model is very simple, with the key is to use BERT and take NER output as input to RE. The experimental results show the model, without the need for handcrafted features, get state-of-the-art results on five datasets. ",
    "The paper proposes to use the triplet loss as a convex relaxation of the ordinal embedding problem. The loss is solved using feed-forward neural network with the input to the network being the ids of the items encoded in binary codes. The benefit of using a deep network is to exploit its optimization capability and the parallelism on GPUs. The experiments presented in the paper include a set of simulation experiments and a real-world task.",
    "Many prior works have found that the features output by the final layer of neural networks can often be used as informative representations for many tasks despite being trained for one in particular. These feature representations, however, are learned transformations of low-level input representations, e.g. RGB values of an image. In this paper, they aim to learn useful feature representations without meaningful low-level input representations, e.g. just an instance ID. Instead, meaningful representations are learned through gathered triplet comparisons of these IDs, e.g. is instance A more similar to instance B or instance C? Similar existing techniques fall in the realm of learning ordinal embeddings, but this technique demonstrates speed-ups that allow it to scale to large real world datasets.",
    "This paper proposes a method for assigning values to each datum.  For example, data with incorrect labels, data of low quality, or data from off-the-target distributions should be assigned low values. The main method involves training a neural network to predict the value for each training datum. The reward is based on performance on a small validation set. To make  gradient flow through data sampling, REINFORCE is used. The method is evaluated on multiple datasets. The results show that the proposed method outperforms a number of existing approaches.",
    "This paper proposes a meta learning approach based on data valuation for reinforcement learning tasks. The core idea is to train a second network (the data value estimator) in conjunction to a regular predictor network. The predictor is then trained with samples chosen via the data value estimation. The authors motivate this construction with the goal to filter out unreliable and corrupted data. ",
    "The paper studies the mean and variance of the gradient norm at each layer for vanilla feedforward, ResNet and DenseNet, respectively, at the initialization step, which is related with Hanin & Ronick 2018 studying the mean and variance of forward activations. They show that ResNet and DenseNet preserve the variance of the layer gradient norm through depths. In comparison, for the vanilla feedforward network, although the mean of the gradient norm is preserved if  is properly initialized, the variance of the layer gradient norm increases over depths, which may explode or decay the gradient at deeper layers. ",
    "This paper studies the effects of residual and dense net type connections on the moments of per-layer gradients at random initialization. In particular, using duality, bounds on the variance of the square norm of Jacobian (with respect to the randomness of random initialization) are derived for vanilla networks. By noticing that connections that bypass a specific layer does not affect the expected square norm of the gradients of a particular layer, the paper continue to characterize the bounds for residual networks and densely connected networks that have special skip connections. In particular, with properly chosen initialization scales for each layer, the architectures with skip connections can be initialized so that the gradient norm does not explode with increasing depth.",
    "The authors proposed a method for code optimization for deploying neural networks. The main idea is to formulate it as a search task over tuning knobs in the code template, and to apply reinforcement learning to optimize the configurations for the tuning knobs with respect to a cost model. The cost model is trained based on a subset of representative samples from the RL controller and their corresponding hardware cost measurements.",
    "This paper proposes an optimizing compiler  for DNN's based on adaptive sampling and reinforcement learning, to drive the search of optimal code in order to reduce compilation time as well as potentially improve the efficiency of the code produced. In particular, the paper proposes to use PPO to optimize a code optimization \"search\" policy, and then use K-mean clustering over a set of different proposed compilation proposals, from which to perform adaptive sampling to reduce compilation time while still keeping a high diversity of the proposed solution pools during exploration. At the same time the authors claim that using RL will learn a better search strategy compared to random search - such as simulated annealing which is used by competing methods - thus producing faster and better solutions.",
    "The paper proposes an extension to the work of Cohen et al. where a certified radius is deduced using a randomized smoothing approach. In particular, the authors show the radius at which a smoothed classifier g at under Gaussian perturbations is certified for the top k predictions. That is to say that the prediction will remain within the top k predictions of g. Setting k=1, one recovers Cohen et al. results. The authors show that the derived radius is tight.",
    "This paper studies the certifiable bounds for adversarial perturbations in \\ell_2 radius for top-k predictions instead of top-1 predictions.  The paper obtains a certifiable radius of \\ell_2 perturbations in the case of top-k predictions (Theorem 1) and shows that the bounds are tight (Theorem 2). The result thus generalizes the results obtained in Cohen et al. (2019) by setting k=1.",
    "In this work, the authors suggest a new point of view on generalization through the lens of the distribution of the per-sample gradients. The authors consider the variance and mean of the per-sample gradients for each parameter of the model and define for each parameter the Gradient Signal to Noise ratio (GSNR). The GSNR of a parameter is the ratio between the mean squared of the gradient per parameter per sample (computed over the samples) and the variance of the gradient per parameter per sample (also computed over the samples). The GSNR is promising as a measure of generalization and the authors provide a nice leading order derivation of the GSNR as a proxy for the measure of the generalization gap in the model. After the derivation, experimental results on MNIST are presented and suggest that empirically there is a relation between the generalization gap of neural network trained by gradient descent and the GSNR quantity given in the paper. Next the author analyze the GNSR of DNNs as opposed with shallow models or other learning techniques and observe that the GSNR differs when using random labels (lower GSNR) as compared with true labels and exhibits different behavior along training for DNNs and gradient descent.",
    "This paper introduces a quantity termed the \"one-step generalization ratio\" . They derive approximate relations between OSGR and GSNR then show experimental results demonstrating the validity of these approximations, thus linking GSNR and a quantity related to generalization. They investigate the empirical value of GSNR during training of a neural network on Cifar10 with real labels vs. random labels. The final section derives a relation which attempts to explain the correlation between the size of the expected gradient and the learning of features.",
    "The paper introduces an approach to answering queries on knowledge graphs, called Query2Box. The idea is to work with the embeddings of the vertices of the knowledge graph as if they were kind of sets. In this way, from a set, called box, of entities embeddings it is possible to project them to find other boxes using the relations specified by the query (these boxes contain the embeddings of the entities linked with those of the previous box by the relation specified in the query), or to intersect them to find the common entities.",
    "This paper proposes a method to answer complex logical queries in large incomplete knowledge bases (KB). Specifically it considers the class of existential first-order logical queries (EPFO) which includes the logical and, or and existential operator.  The key contribution of this paper is to represent sets of entities via regions, more specifically as boxes or hyper-rectangles. This is well motivated because such logical queries often involves working over sets of entities at once and involves applying set based operators. Previous work which represented queries as a point in vector space are not well suited for these queries.",
    "The authors study SGD algorithms for problems where obtaining unbiased gradients is potentially computationally expensive. In such cases while obtaining, unbiased gradients is expensive, it might be possible to establish consistent estimators of the gradient. The authors then establish that SGD algorithm when run with consistent gradient estimators (but not necessarily unbiased) have similar convergence properties as SGD algorithms when run with unbiased gradient estimators.  The example problem class considered is the problem of learning embeddings for graph problems, where the task is to get embeddings for nodes. Such embeddings can be used to do node classification or solve any other downstream task that involves the nodes of the graph. For such graph problems learning embeddings requires us  to look at the neighbours of a node, neighbours-of-neighbours and so on, which means that in the worst case calculating gradient w.r.t. a single node can be of time complexity O(N).  Consistent gradient estimators have been proposed for such graph problems in the past but this paper establishes theoretical properties of SGD with such estimators.  ",
    "The paper studies stochastic optimization with consistent (may not be unbiased) estimators. This problem is well-motivated through the example of learning graph representations where consistent estimators are easier to obtain than unbiased one. Under the assumption that the estimate converges to the consistent gradient exponentially fast w.r.t. the sample size, the authors give convergence rates for convex, strongly-convex and non-convex optimization. The authors validate their theory through synthetic experiments.",
    "In this papers, the authors learn a Once-for-all net. This starts as a big neural network which is trained normally (albeit with input images of different resolutions). It is then fine-tuned while sampling sub-networks with progressively smaller kernels, then lower depth, then width (while still sampling larger networks occasionally, as it reads). This results in a network from which one can extract sub-networks for various resource constraints (latency, memory etc.) that perform well without a need for retraining.",
    "This paper tries to tackle the problem of searching best architectures for specialized resource constraint deployment scenarios. The authors basically take a two-step approach: First train a large network including all the small networks with weight sharing and some specially designed trick (e.g., progressive shrinking). Second, use prediction based NAS method to learn the performance/inference prediction module, from which the good sub architecture corresponding to a particular scenario is obtained. The experiments show that the proposed method is promising.",
    "This works applies neural module network to reading comprehension that requires symbolic reasoning. There are two main contributions: (1) the authors designed a set of differentiable neural modules for different operations (for example, arithmetics, sorting, and counting) that is required to perform reasoning over a paragraph of text. These modules can be compositionally combined to perform complex reasoning. And the parameters of each module (which can be viewed as executor of each operation) are learned jointly with the parser that generates thee program composed of those modules. (2) To overcome the challenge of weak supervision, the authors proposed to use auxiliary loss (information extraction loss, parser supervision, intermediate output supervision). The model is evaluated on a subset of DROP, and outperforms the state-of-the-art models. Ablation studies supported the importance of the auxiliary losses.",
    "The paper offers a new deep learning approach to symbolic reasoning over text. They propose using Neural Module Networks to perform explicit reasoning steps that are nevertheless differentiable. The process is separated into a semantic parsing of the question, and a resolution using MNMs. Auxiliary tasks improve performance and enable using a BERT pretrained model as a seed. The proposed model's performance surpasses previous SOTA on several question types. ",
    "This paper analyzes how signals propagate through randomly initialized neural networks that have undergone a kind of pruning/sparsification. The pruning method utilizes a metric called 'connection sensitivity', which has been used in prior work and which measures the infinitessimal impact of turning off specific parameters. The distribution of singular values in the layer-to-layer Jacobian matrices for pruned networks becomes increasingly pathological as the depth increases. This observation motivates the concept of 'layerwise dynamical isometry' (LDI), a slight generalization of the concept of 'dynamical isometry' that has been studied in prior work. Several methods for approximately obtaining differing amounts of LDI are investigated in a series of in-depth experiments that show a strong correlation between increased signal propagation and improved trainability of sparse networks.",
    "In this paper, the authors studied and formalized the effect of initialization to connection-sensitivity-based pruning. The authors first pointed out that a previously studied pruning criterion -- connection sensitivity (CS) -- is a normalized magnitude of gradients. Based on signal propagation theory, to achieve a 'faithful' (with minimal amplification) CS, the gradients must be also faithful. Then by using relation of Jacobians and gradient, the authors proved that orthogonally initial weights guarantees faithful on linear networks and certain distribution property on nonlinear network can achieve layerwise dynamic isometry, which is to ensure faithful signal propagation. Based on these findings, the authors proposed an initialization setup for improving pruning performance, with the goal to ensure dynamic isometry by orthogonal initialization and approximation.",
    "This paper tackles the problem of finding a sparse network architecture before training, so as to facilitate training on resource-constrained platforms. To this end, the authors propose to replace dense layers with series of sparsely-connected linear layers. They then study how to initialize such sparse layers to avoid gradient vanishing. Furthermore, they propose an approach to finding the best topology by measuring how well the sparse layers can approximate random weights of their dense counterparts.",
    "This paper proposes to replace dense layers with multiple sparse linear layers.  The idea is that the product ABC (for A, B, C all sparse matrices)  can accurately approximate a dense matrix D, but A(B(Cx))) requires much less work than Dx.  The paper then continues with the assumption that topology of the sparse matrices should be fixed before training, and that given this assumption we would like to find the \"best\" fixed topology to pick.  The paper introduces a new task to determine the \"best\" topology - that of reconstructing a random dense matrix.  On somewhat of a tangent the paper also introduces a minor modification to the Xavier initialization scheme that works better for deep stacks of sparse layers.",
    "This paper touches the signal processing/long term propagation problem in gated recurrent neural networks from the mean field theory. The paper starts from a dynamic system view of the recurrent neural networks and calculates the time scale of converging to the fixed point. In order to avoid the system to converge to the fixed point, the authors utilize some initialization strategy to keep the time scale to infinity. The authors also relate the time scale to state-to-state Jacobians. ",
    "The aim of this paper is to suggest randomized initializations for the various weights of a recurrent neural network (GRUs and various LSTMs are covered), such that training these networks gets to a successful start, when the model is trained on long sequences. Instead of being heuristic, their approach follows first principles of analyzing signal propagation through time, using ideas from statistical thermodynamics (mean field approximations). Some experiments, on toy datasets, validate their approach.",
    "This papers proposed a solution to the problem of disease density estimation using satellite scene images. One common challenge in this type of applications is having a high intra-class diversity and a high inter-class similarity. The solution proposed by the authors is based on the use of siamese networks to extract features from pairs of neighbouring images, and merge the features only if they are similar. The authors claim that this approach alleviate the need of a post-classification smoothing.  ",
    "The paper proposes to do a coupled inference over pairs of geographically close images instead of a single image for satellite imagery. The coupling is done with an average pooling of the feature vectors when the neighbouring patches are detected to be similar enough based on a threshold on the L2 distance of these features. The method is applied to tasks of estimating crowding population, and diseases density, from satellite images. ",
    "This work proposes to leverage a pre-trained semantic segmentation network to learn semantically adaptive filters for self-supervised monocular depth estimation. Additionally, a simple two-stage training heuristic is proposed to improve depth estimation performance for dynamic objects that move in a way that induces small apparent motion and thus are projected to infinite depth values when used in an SfM-based supervision framework. Experimental results are shown on the KITTI benchmark, where the approach improves upon the state-of-the-art.",
    "The paper proposes a using pixel-adaptive convolutions to leverage semantic labels in self-supervised monocular depth estimation. The semantic features are predicted by a pretrained network rather than relying on a ground truth. Moreover, a two-stage training process in proposed in order to filter out images leading to erroneous SfM predictions. The method is evaluated with different networks on the KITTY dataset.",
    "The paper investigates data poisoning type of attack. In such attacks, an adversary can alter/flip the labels of some of the training examples. The paper proposed a new approach towards certified robustness against this type of attack. In particular, the new classifier will output a prediction along with a certificate in which the prediction would not change if certain number of labels in the training data were flipped.",
    "This paper proposes a certifiable defense against data poisoning attacks by using a randomized smoothing approach. An adversary in such a setting is permitted to flip any r labels from a dataset of size n. The smoothing procedure (stated roughly) is to train on a dataset with \"noisy\" or \"smoothed\" labels, obtained by flipping each label with some probability q. The authors obtain a lower bound on r in terms of q. Directly using this technique requires training multiple classifiers on multiple noisy datasets. To show that this method is useful, the authors study the effectiveness of this model against a classifier that performs linear regression on a pre-trained feature extractor. ",
    "This paper leverages differential privacy\u2019s stability properties to investigate its use for improved anomaly and backdoor attack detection. Under an assumption (called \u201cuniformly asymptotic empirical risk minimization\u201d), the authors show that difference between the expected loss of a differentially private learning algorithm on an outlier (where the expectation is taken over the randomness of the learning algorithm) and the expected loss of the same algorithm on data from the underlying distribution (expectation taken over data & randomness of the algorithm) is lower bounded by a (possibly/hopefully) non-negative quantity with high probability. The authors then conduct a set of experiments to show that differential privacy improves the performance of outliers, novel examples, and backdoor attack detection. ",
    "This paper proposes the idea of using differential privacy (DP) to improve the performance of outlier and novelty detection. Differential privacy was proposed as a privacy metric which limits the contribution of a single data point in the training set to the output. This property naturally controls how poisoned data would affect the output of the learned model. Under the assumption that a well-trained model would incur a higher loss on the outliers, the paper gives a theoretic bound on how this loss will decrease if there are poisoned samples in the training set. ",
    "This paper focuses on the calibration for the regression problem. First, it investigates the shortcomings of a recently proposed calibration metric [1] for regression, and show theoretically where this metric can be fooled. Later, it introduces new metrics for measuring the calibration in regression problem which are instantiated from similar idea as the ECE calibration metric [2] used for classification problem. The paper defines the uncertainty as the mean square error and like the ECE idea, it divides the samples into different uncertainty bins and for each bin, it calculates RMSE of network output uncertainty. The RMSE versus variance of estimated uncertainty is depicted as the reliability diagram.",
    "This paper is concerned with uncertainty calibration diagnostics and re-calibration methods, applied to neural network regression. It is motivated by a flaw in the diagnostic proposed by Kuleshov+ 2018 (abreviated K2018 below), as explained around eq4, and proposes a replacement diagnostic for uncertainty calibration quality (sec 3 before 3.1). It then specialises by considering the class of uncertainty prediction schemes qualified as \"direct\" uncertainty modeling (defined sec1), in which the network predicts the parameters of a parametric distribution over the target output, typically mean and variance of a Gaussian. For this class of schemes, it proposes a recalibration method (sec 3.1), which consists, as shown eq12, of rescaling (with a single parameter $s$) the square root of the variance predicted by the neural network. It then presents experiments (sec4) to demonstrate that the motivating flaw can be evidenced by their diagnostic, and fixed by their recalibration method where it makes sense (ie where predicted uncertainties are not random, i.e. statistically independent of the empirical uncertainty).",
    "This paper proposes a fine-tune technique to help BERT models to learn & capture form and content information on textual data (without any form of structural parsing needed). They key addition to the classic BERT model is the introduction of the R and S embeddings. R &S are supposed to learn the information in text that is traditionally represented as the structural positions and the content-bearing  symbols in those positions. ",
    "This paper proposes a layer on top of BERT which is motivated by a desire to disentangle content (meaning of the tokens) and form (structural roles of the tokens).  Figure 1 shows this clearly. The paper considers two variants of the disentangling layer (TPR), one with LSTMs (figure 2) and the other with attention (figure 3). The aim in both is to obtain a decomposition of the form x(t) = S a_s(v_t) a_r(v_t) R where S and R are shared matrices of parameters and v is the output of BERT. ",
    "The submission proposes a method for hierarchical RL in multiagent settings. In particular it proposes to explicitly decouple training of a high-level and low-level controller with grounded the controller interface as goals in the environment to reach for the low-level controller. The model is trained via PPO with GAE and evaluated on a small set of multi agent locomotion tasks.",
    "This paper proposes a multi-agent hierarchical reinforcement learning algorithm so that multiple humanoid robots can navigate in multi-agent settings (e.g. avoid collisions, collaboration, chase and escape) in a physically simulated environment. The key difference of this paper with the prior work on MARL is that it used an accurate physics simulation of humanoid robots. This is the main reason of using the hierarchical RL. ",
    "In this work the authors point out an issue related to graph neural networks. Specifically, if two nodes, that may be far apart in the graph, may be represented as (almost) the same vector. This is simply because when no features/labels are associated with nodes, and the local structure around those two nodes is very similar then the local aggregation of information will result in a similar representation.  Therefore the authors introduce an embedding first of the graph in the Euclidean space using DeepWalk and then use this embedding in combination with the design of a CNN. The authors propose a pooling method that outperforms several state-of-the-art pooling techniques on real data. Overall, the empirical results are supportive of the fact that the proposed method can help improve the performance of GNNs. ",
    "The authors propose in this paper to complement the node attributes in a graph with vectors obtained using a graph embedding algorithm. More precisely, they propose a graph neural network that apply several layers of graph convolution in parallel to the node attributes and to the embedding, then takes an average of the result, which is fed to another series of graph convolution. This is combined with some form of sampling which strongly resembles median based quantization but is solved with some basic heuristics and without acknowledging the resemblance (I might be missing something). ",
    "This paper proposed \"F pooling\" for Frequency Pooling, which is a pooling operation satisfying shift equivalence and anti-aliasing properties. The method is very simple: first, transform the input 1D/2D signal into the spectrum domain based on discrete Fourier transform (DFT), then cut the high-frequencies, then transform back to the time domain using the inverse DFT. The method can be implemented using FFT and auto differentiation frameworks. The method is tested on Resnet/Desnet on CIFAR-100 and subsets of ImageNet, showing better performance than the original models.",
    "This paper researches the pooling operation, which is an important component in convolutional neural networks (CNN) for image classification. Taking the perspective from signal processing, this paper proposes a pooling operation called frequency pooling (F-pooling). The key motivation is to make the pooling operation shift-equivalent and anti-aliasing. This paper gives an improved definition on shift-equivalent functions and shows that the proposed F-pooling is optimal in the sense of reconstructing the orignal signal. The F-pooling is then implemented with matrix multiplications and tested with recent convolutional neural networks for image classifiation on CIFAR-100 and a subset of ImageNet dataset. ",
    "This work proposes using a randomly parameterized convolutional layer as additional processing of the input observation to provide data augmentation to make policies more robust to environments with different observation spaces. The empirical results are thorough, comparing with other regularization techniques, including dropout, L2 regularization, and batch normalization with the same policy gradient method, PPO on a variety of generalization in RL benchmarks. There are additional experiments of this method to check that it actually removes visual bias in a computer vision problem better than other methods. ",
    "This paper proposes applying random convolutions to the observation space to improve the ability of deep RL agents to generalize to unseen environments. To encourage the learning of invariant features, the authors further include a loss term to align features of perturbed and unperturbed observations. Thorough experiments on multiple generalization benchmarks show that this method outperforms many previously used regularization and data augmentation techniques.",
    "This paper proposes a novel method for image similarity models explanation, introducing Salient Attributes for Network Explanation (SANE). The method identifies attributes that contribute positively to the similarity score, thus explaining the important image properties, and pair them with a generated saliency map unveiling the important regions of the image. The method combines three major components: ",
    "This paper introduces SANE, a new approach for explaining image similarity models by combining a saliency map generator and an attribute predictor. In this way, the method is not only able to highlight what regions contribute the most to the similarity between a query image and a reference image, but also predict an attribute that explains this match. During training, SANE jointly optimizes the attribute prediction of the query image and maximizes the overlap of the saliency map of the image similarity and the attribute activations.",
    "This submission belongs to the field of text-to-speech synthesis. In particular it looks at a novel way of formulating a normalising flow using 2D rather than conventional 1D representation. Such reformulation enables to provide interpretations to several existing approaches as well as formulate a new one with quite interesting properties. This submission would benefit from a discussion of limitations of your approach. ",
    "This paper re-organized the high dimensional 1-D raw waveform as 2-D matrix. This method simulated the autoregressive flow. Log-likelihood could be calculated in parallel. Autoregressive flow was only run on row dimension. The number of required parameters was desirable to synthesize high-fidelity speech with the speed faster than real time. Although this method could not achieve top one in ranking in every measurements, the resulting performance was still obtained with the best average results. ",
    "This paper studies a problem of graph translation, which aims at learning a graph translator to translate an input graph to a target graph. The authors propose an adversarial training framework to learn the graph translator, where a discriminator is trained to discriminate between the true target graph and the translated graph, and the translator is optimized by fooling the discriminator. The authors conduct experiments on both synthetic and real-world datasets. The results prove the effectiveness and the efficiency of the proposed approach over many baselines.",
    "In this work the authors tackle the problem of generating a given graph to a target output graph.  To achieve this they develop a novel deep graph generative model. The authors place a lot of emphasis on scalability. This is indeed a major computational bottleneck in prior work, allowing the deep generative models to generate graphs with few tenths of nodes.   The authors propose an architecture that consists of a graph translator, and a conditional graph discriminator. The GAN approach is able to give significant insights into the conditional distribution p(G|H) where H is the input graph. For the graph translator, the authors design novel graph encoders and decoders. The proposed encoder-decoder achieve the best possible results, compared to using established encoder/decoders as shown in ablation study.  The authors analyze the computational complexity of their work, and while they do not discuss the computational complexities of the other methods, it is clear from the experiments that their method scales better (e.g., Figure 4). To evaluate the output of the architecture, they use a variety of different graph characteristics. The proposed method outperforms the state-of-the-art. Furthermore, the proposed method is able to detect interesting anomalies as illustrated in the appendix  (hacker detection). ",
    "The authors propose a variant of gating functions for recurrent neural networks and feed-forward layers of Transformer and apply it to variety of tasks including toy tasks such as sorting, tree traversal and more realistic tasks such as machine translation. The gating function is applied recursively for N number of steps and depth of recursion is learned softly in data-driven function. Authors show similar or slightly better performance of their approach when applied to LSTM and Transformer compared to vanilla LSTM and Transformer.  ",
    "This paper proposes a neural sequence modelling unit called METAGROSS.  In principle, the aim of this unit is to introduce recursive parametrization of  gating functions, building on the gated RNN paradigm.  The authors motivate this work by arguing that while gated-RNNs tackle vanishing gradient problems and facilitate learning long-range dependencies in sequences, improvements can be made with respect to learning on hierarchically-structured data.  The authors propose a method to do so by also learning the depth of the parametrization, and claim that the inductive bias that emerges from this configuration is beneficial to learning such tasks.",
    "This paper is dedicated to proposing a self-supervised objective, local prior matching (LMP), for speech recognition. This approach can take advantage of vase quantities of unlabeled speech data. What' more, the objective is simple to implement and theoretically well-motivated. In the paper, based on a supervised pretrained model, it then finetunes 360 hours with unlabeled data and LPM reduces the WER consistently. They also conduct extensive ablation experiments to show the effect of their self-supervised approach.",
    "This work proposed a distillation approach which use ASRs to generate hypotheses for unsupervised data, run a LM to get probability for the hypothesis, and perform distillation with the resulting probability. The ASRs being used for generating hypotheses can be either a model trained with the supervised data or the student model, and can switch between the two during training. In the experiments, ASR models are pre-trained with the subset of Librispeech data and use the rest of Librispeech data as unsupervised data, and the LM is trained with Librispeech LM data. The experiments shown the proposed approach improve baseline model trained with the Librispeech subset significantly.",
    "This paper introduces a new method for training a classifier that simultaneously optimizes for a fairness criterion and robustness to data poisoning. The method is shown to increase measures of fairness and reduce inaccuracy on poisoned data relative to classifiers that only consider accuracy or fairness. Extensive results are shown for both synthetic and real benchmark data sets.",
    "This paper combines adversarial fair training with adversarial robust training. The basic idea is that a classifier is combined with two adversaries: one tries to predict the sensitive attribute $Z$ from the output of the classifier (essentially the approach by Edwards&Storkey 2015) and the other adversary tries to recognize if a label was predicted or is from a clean hold-out dataset. The latter is intended to harden the classifier against data-poisoning of the training set.",
    "The paper presents a method for point-based learning that is inspired by a hybrid Eulerian-Lagrangian fluid simulation method. The work first explains how the simulation algorithm is mapped to the learning problem: MLPs are employed to learn sets of particle based features which are mapped to a Eulerian grid. A second MLP infers a particle based velocity, which is likewise mapped to the grid and used to advect the grid quantities. This is repeated for a certain number of steps to obtain final positions. The \"warped\" features are then projected back onto the particles to solve, e.g., a classification task. In contrast to a typical flow solver, the motion can be divergent, i.e., not necessarily conserves volume.",
    "The paper is about using classical PIC/FLIP scheme in Computational Fluid Dynamics for solving the learning problem of 3D object detection and segmentation. In general, there are extrinsic CNNs like the Vox net etc. which look for global features which the authors refer to as Eulerian formulation of the data representation, and there are intrinsic CNNs like the GCN(graph convolutions), Point nets etc. which look for localized neighborhood information which the authors refer to as Lagrangian formulation. The authors acknowledge that hybridizing the extrinsic CNNs and intrinsic CNNs is not new and several works are cited. The key contribution is to look at this problem from the perspective of PIC/FLIP scheme which has been used in CFD for decades. ",
    "Gradient clipping has been studied as an optimization technique and also as a tool for privacy preserving, but in this paper, it studies the robustness properties of gradient clipping.  More specifically, the main question of the paper is: Can gradient clipping mitigate label noise?  The paper reveals that the answer is no, but further proposes a simple variant of gradient clipping is robust and has nice property of classification calibration.  Experiments show that the proposed variant works under label noise.",
    "This paper studies the relationship between gradient clipping in stochastic gradient descent and robustness to label noise. Theoretical results show that gradient clipping in general is not robust to symmetric label noise. The paper then proposes a variant of gradient clipping (cl-clipping) that induces label noise robustness. Experiments support these claims on synthetic datasets and typical classification benchmarks.",
    "The paper proposes an imitation learning method that aims to align state distributions rather than state-action distributions to account for cases where the imitator dynamics differ from expert dynamics. They achieve this by two objectives: one local, the other global. The local objective aligns the next state to be close to the expert's next state in each transition by first training a VAE on the expert demonstrations, and using the trained VAE in conjunction with a pretrained inverse dynamics model to compute the action that the imitator needs to imitate. The global objective tries to do a global alignment of states encountered in the imitator and expert trajectories, by minimizing the Wasserstein distance between the two trajectory distributions. The paper claims that using these two objectives results in a method that outperforms existing inverse reinforcement learning and behavior cloning approaches in settings where the imitator and expert dynamics differ.",
    "This paper seeks a solution to the problem of performing imitation learning when the dynamics of the demonstrator are different from the dynamics of the imitator. The authors present a novel approach that combines global alignment by minimizing the Wasserstein distance between state occupancies with local alignment via a state-predictive VAE and inverse dynamics model. The experimental results support the claims that the method works for different dynamics and the proposed approach usually outperforms existing imitation learning methods.",
    "This paper propose an extention method of SGD, deep gradient boosting (DGB), which views the back-propagation procedure as a pseudo-residual targets of a gradient boosting problem. To apply DGB to the real CNNs, DGB is simplified to a input normalization layer, conditioned on the assumption that the convolution kernels should be small. After applying the input normalization layer to CNNs, the model could achieve comparable performance to the model with BN on CIFAR-10 and ImageNet recognition.",
    "The paper proposes an a new idea of treating the back propagated gradients using chain rule as pseudo residual targets of a gradient boosting problem. Then the weight update is done by solving the boosting problem using a linear base learner. Furthermore, to reduce computational cost incurred by solving the boosting problem, an idea proposed is only keep the diagonal terms of the matrix inversion involved. ",
    "The authors propose with this paper a simple extension of DARTS, a popular neural architecture search (NAS) method. This extension addresses one of the shortcoming of DARTS: the immense memory cost. This achieved in a simple way. Instead of using all channels only a random subset is used. To account for that, the authors propose a method to normalizes edges.",
    "This paper proposes to improve the previously work DARTS in terms of the training efficiency, from the large memory and computing overheads. The authors propose a partially-connected DARTS (PC-DARTS) with two components: 1. Partial channel connection 2. edge normalization. To be detailed, they sample a small part of channels to perform connection and add edge normalization to eliminate the potential optimization problem. The results on CIFAR-10 and IamgeNet show the approach is effective, especially in ImageNet, the approach achieves SOTA results. ",
    "This paper studies optimal control problems where a physical simulator of the system is available, which outputs the gradient of the dynamics. Using the gradients proposed by the model, the authors propose to add two additional terms in the loss function for critic training in DDPG, where these to terms corresponding to the prediction error of $\\nabla_{a} Q(s,a)$ and $\\nabla_b Q(s,a)$, respectively. However, my main concern is that the form of gradient given in equation (2) might contains an error.",
    "DDPG is a popular RL method for continuous control problems. It is more widely applicable than traditional model-based approaches like MPC, since it doesn't require differentiable models of the dynamics. However, in many environments, dynamics are differentiable. This paper proposes a method for extending DDPG to exploit simulator gradients. In particular, the Bellman error objective (which is defined in terms of critic values) used for training the critic is augmented with additional terms defined in terms of gradients of the critic. This leads to faster convergence in practice on a range of benchmarks.",
    "This paper proposes a novel approach to hierarchical reinforcement learning approach by first learning a graph decomposition of the state space through a recurrent VAE and then use the learned graph to efficiently explore the environment. The algorithm is separated into 2 stages where in the first stage random walk and goal conditioned policy is used to explore the environment and simultaneous use a recurrent binary VAE to compress the trajectory. The inference network is given the observation and action and the reconstruction is to, given the hidden state or hidden state+observation, reconstruct the action taken. The approximate posterior takes on the form of a hard Kumaraswamy distribution which can differentiably approximate a binary variable; when the approximate posterior is 0, the decoder must reconstruct the action using the hidden state alone. The nodes of the world graph are roughly states that are used to reconstruct the trajectories in the environment. After the graph is constructed, the agent can use a combination of high-level policy and classical planning to solve tasks with sparse reward.",
    "This paper proposes an approach to identifying important waypoint states in RL domains in an unsupervised fashion, and then for using these states within a hierarchical RL approach.  Specifically, the authors propose to use a binary latent variable VAE to identify waypoint states, then an HRL algorithm uses these waypoints as intermediate goals to better decompose large RL domains. The authors show that on several grid world tasks, the resulting policies substantially outperform baseline approaches.",
    "This paper investigates the question of identifying concise equations from data to understand the functional relations. In particular, a set of base functions are given in hand and the goal is to obtain the right composition of these functions which fits the target function. The main contribution of the paper is to introduce a selection layer, which enhances sparse connections in the network. Several experiments are conducted to show the effectiveness of the method. ",
    "This paper presents White Box Network (WBN), which allows for composing function blocks from a given set of functions to construct a target function. The main idea is to introduce a selection layer that only selects one element of the previous layer as an input to a function block. This allows for both introducing function priors as well as interpreting the learned function. The paper also presents a setting where each function block is a neural network that can be learned end-to-end using a PathNet style setting and shows positive transfer across MNIST and CIFAR classification tasks.",
    "This work presents the goal-conditioned supervised learning algorithm (GCSL), which learns goal conditioned policies using only behavioral-cloning of the agent's own actions.  The intuition behind the algorithm is the goal of an observed trajectory can be identified after the fact, by simply looking at the states reached during that trajectory.  GCSL treats each executed action as a sample from the expert policy conditioned on each of the states reached after that action is taken.  Given a distribution over goal states, GCSL alternates between executing its current goal-conditioned policy on randomly selected goals, and learning to imitate the generated actions conditioned on the states they actually reached.  Experimental results demonstrate superior performance against a base (non-goal conditioned) RL algorithm (TRPO), and against another approach to learning goal-conditioned polices (TD3-HER), on a relatively diverse set of control problems.",
    "This paper proposes a method to learn to reach goals in an RL environment. The method is based on principles of imitation learning. For instance, beginning with an arbitrary policy that samples a sequence of state-action pairs, in the next iteration, the algorithm treats the previous policy as an expert by relabeling its ending state as a goal. The paper shows that the method is theoretically sound and effective empirically for goal-achieving tasks. ",
    "This paper addresses security of distributed optimization algorithm under Byzantine failures. These failures usually prevent convergence of training neural network models. Focusing on the asynchronous SGD algorithm implemented with a parameter-server, the authors propose to use stochastic line search ideas to detect whether the gradients are good descent directions or not. It applies to a general scenario including repeated and unbounded Byzantine failures. ",
    "This paper investigates the security of distributed asynchronous SGD. Authors propose Zeno++, worker-server asynchronous implementation of SGD which is robust to Byzantine failures. To ensure that the gradients sent by the workers are correct, Zeno++ server scores each worker gradients using a \u201creference\u201d gradient computed on a \u201csecret\u201d validation set.  If the score is under a given threshold, then the worker gradient is discarded. ",
    "The paper proposes cAdv and sAdv, two new unrestricted adversarial attack methods that manipulates either color or texture of an image. To these end, the paper employes another parametrized colorization techniques (and texture transfer method) and proposes optimization objectives for finding adversarial examples with respect to each semantic technique. Experimental results show that the proposed methods are more robust on existing defense methods and more transferrable accross models. The paper also performs a user study to show that the generated examples are fairly imperceptible like the C&W attack. ",
    "This paper introduces two new adversarial attacks: one is generating adversarial examples by colouring the original images and the other is by changing textures of the original images. Specifically, the former one minimises the cross-entropy between the output of the classifier and the target label with the network weights of a pre-trained colourisation network. While the latter minimises the cross-entropy as well as the loss that defines the texture differences.",
    "In this paper, the authors present a method, Learning to Control (LTC), that enables a reinforcement learning agent to learn to read and write external memory. They follow the intuition that human has two degrees of plasticity for memory, which leads to the dense-sparse memory design in this paper. The proposed method can be applied to a few-shot setting. ",
    "The paper proposes a memory network architecture with a sparse memory. Each memory entry contains a key (vector) and a value (class label). The memory is addressed using a policy pi_theta, which selects a single memory entry to be updated at each time step. The policy pi_theta is trained using policy gradient with the reward being the increase in the policy's certainty (measured as entopy). The model is evaluated on an online NER task that mimics the meta-learning setting of http://proceedings.mlr.press/v48/santoro16.html. In that work, the examples are provided in episodes. The labels are renamed at the beginning of each episode (to prevent fitting to the labels). The model has to predict the label of each example in sequence, and the correct label is given after each prediction.",
    "The authors build on work regarding few-shot learning with memory augmented networks, specifically [Kaiser, et al., ICLR17] where the goal is to learn a memory address mapping such that generalization is achieved by finding the nearest neighbor memory address when predicting the label. For correct predictions, the memory key is updated to include the associated (predicted) address while new memory locations are written for mistakes. Whereas [Kaiser, et al., ICLR17] follows a LRU-like procedure for replacing memory, the current work proposes performing policy-gradient RL where the action space is the memory locations and the reward is reduction of entropy over the memory address assignment distribution over the memory locations. This approach is empirically studied for an RNN approach to NER, specifically considering few-shot learning for NER in the Stanford Task-Oriented Dialogue (STOD) dataset \u2014 showing non-negligible improvements over Memory Augmented Networks [Santoro, et al., ICML16] and Matching Networks [Vinyals, et al., NeurIPS16].",
    "The paper proposes a method for learning a set of primitives for robotic movements from a dataset of demonstrations, showing a diverse set of tasks, in an unsupervised fashion. The central underlying idea is that robotic tasks can be solved by combining fundamental building blocks, the so-called \"motor programs\", in the right way. The described algorithm takes a demonstration and uses a transformer network to embed the trajectory into a sequence of latent variables. Then each individual latent is transformed to a 10 step trajectory for the joint space of the robot via an LSTM network. Finally the individual trajectories are concatenated and the reconstruction is compared to the original demonstration through dynamic time warping. In this structure the latent variables represent a query to a specific learned primitive, which can be accessed using the LSTM. ",
    "This work presents a novel approach to extracting reusable motor primitives from task demonstrations.  The approach taken in this work involves learning a deep encoder network which translates an arbitrary length trajectory in a robot's configuration space (is this right?) into a sequence of vectors describing different motor primitives.  A second decoder network translates these vectors into a sequence of trajectory segments.  These networks are trained to minimize the distance between the original trajectory, and the trajectory generated by encoding and reconstructing the original as a sequence of primitives and reconstructing.  An additional regularization term discourages the network from learning trivial, one step primitives.  The decoder network is also initialized by training on a set of simple trajectories generated by a robotic planning algorithm.",
    "The paper aims to learn middle-level motor task primitives from unlabeled actions. The main insight is that the decomposition of motor tasks can be learned using a set of LSTMs with a loss function that minimizes the differences between the original task and the recomposed task. They evaluate their approach on MIME dataset that includes 20 different tasks.",
    "This paper addresses the problem of transfer in RL. After an agent is given an opportunity to train from a distribution of environments, we want an agent to perform well on the test environment. This paper specifically focuses on the setting where the state space, action space, reward space, and discount factor are the same across all environments, while the transition dynamics may differ. An environment's transition dynamics is assumed to depend on a hidden parameter that is not observed by the agent, in contrast to some previous work which assumes observability.",
    "The main contribution of this paper is to learn a universal policy that is able to perform near-optimally on test tasks with transition dynamics that were never observed during training. This is achieved by using a \"probe policy\" to generate short trajectories that are then used to learn a latent encoding to categorise the transition dynamics of the current task. The universal policy is then conditions on both the state and this encoding so that the learned policy can perform well on tasks with different dynamics.",
    "This paper presents a strategy for single-trajectory transfer of a reinforcement learned policy.  They follow a typical approach in the few-shot supervised-learning community, of assuming that the plausible set of solutions may be modelled as a much lower dimensional latent variable, and then try to quickly infer that latent variable at test time.  In this case, the latent variable is \u2018Z\u2019.",
    "The paper applies three-head neural network (3HNN) architecture in AlphaZero learning paradigm. This architecture was proposed in [1] and the paper builds upon their work. In AlphaGo and AlphaZero 2HNN is used, which predicts policy and value for a given state. 3HNN also predicts action-value Q function. In [1], the three new terms are added to the loss to train such a network, and the network is trained on a fixed dataset. The paper utilizes the same 3HNN idea with the same loss, and the contribution is that 3HNN is trained synchronously with MCTS iterations on an updating dataset (\u201cAplhaZero training style\u201d). Learning speed of 3HNN is shown to be higher than that of 2HNN. The special attention is drawn to varying the threshold expansion parameter, as the 3HNN architecture allows to set it above zero, while 2HNN does not. The approach is demonstrated on the game of Hex. Results are presented on two test datasets: positions drawn from a strong agent\u2019s games and random positions. Labels in both datasets are perfect, obtained by a special solver.",
    "The paper proposed to use three-head network for AlphaZero-like training. The three-head network is used to predict policy, value and q function after an action is taken. While three-head network is presented by a prior work [1] and is learned via supervised learning on a fixed dataset, this paper mainly applies it to AlphaZero training for the game of Hex 9x9 and shows preliminary results. ",
    "This paper applies the three-head neural network architecture as well as the corresponding training loss proposed in (Gao et al., 2018b) to alphazero style learning of the Hex game. The paper is mainly an empirical study, and shows that the architecture leads to faster and better learning results for Hex. The evaluation is done on two datasets, one with examples from near-optimal players produced by MoHex 2.0, and the other from randomly sampled but perfectly labelled examples generated by benzene. Performance improvement is evaluated from several different perspectives, including state-value errors, action-value errors and policy prediction accuracies. Finally, the match performance is also reported for competing with MoHex 2.0, one of the state-of-the-art agent for Hex.",
    "The authors propose an algorithm for transferring policies across domains differing in their transition model. The idea is to \"regularize\" the target policy being learned to generate a trajectory distribution similar to the one induced by the source optimal policy in the respective MDP. The method is proved effective in standard simulated robotic tasks (Mujoco).",
    "This paper addresses the actively studied problem of efficiently transferring policies across domains in reinforcement learning. Authors propose a framework to transfer policies between tasks in domains with significantly different state transition. The proposed algorithm is based on a policy adaptation mechanism, with the idea that provided that a source optimal policy of a task is available, that policy is adapted to derive the optimal policy of the target task at a low sample complexity. ",
    "This paper tackles the problem of transferring a policy from source to target MDP, which differ in the state transition function. The idea is to add an additional cost that is the KL divergence between the trajectory likelihood under target policy (being learned) and target dynamics and the trajectory likelihood under the source policy (assumed optimal and deterministic) and source dynamics. The intuition is that the target policy will learn to match the state distribution of the optimal source policy. Results on MuJoCo locomotion robots with varying physics show that the proposed method performs better on target than warm-started RL or learning from scratch. ",
    "This paper proposed scale-equivariant steerable convolutional neural networks that is able to preserve both the translation and scaling symmetry of the data in the representation. To achieve this, the authors developed the scale-convolution blocks in the network, and generalized other common blocks, such as pooling and nonlinearity, to remain scale-equivariant. Extensive experiments have been conducted to show that the proposed scale-equivariant network",
    "The paper describes a method for integrating scale equivariance into convolutional networks using steerable filters.  After developing the theory using continuous scale and translation space, a discretized implementation using a fixed set of steerable basis elements is described.  Experiments are performed measuring the error from true equivariance, varying number of layers, image scale and scales in scale interactions.  The method is evaluated using MNIST-scale and STL-10, with convincing results on MNIST-scale and bit less convincing but still good results on STL-10.",
    "This paper proposes a framework (SESN) for learning deep networks that possess scale equivariance in addition to translation invariance. The formulation is based on group convolution on the scale-translation group. Filters are represented as the coefficients of a set of continuous basis functions, which are sampled (once) at a discrete set of scales. The theoretical formulatioin is clear and interesting. The approach is evaluated in terms of image classification accuracy. The set of baselines is quite exhaustive, including recent papers and papers that are not widely-known.",
    "This manuscript focuses on reconstructing 3D shapes from point clouds, with applications for instance to 3D scanners. The contribution builds on an adversarial formulation of the reconstruction, as in GANs. The method uses an encoder to map the observed noisy set of points into a lower-dimensional latent space and a decoder for the inverse mapping. The training loss is based on an Earth Mover's Distance between points. The training is done with an adversarial (min-max) strategy, that seeks to align the behavior of the encoder / decoder across a clean complete dataset and a partially-observed noisy one, with a Hausdorff distance loss, to cater for partial matching. The method is benchmarked on simulated and real data. It outperforms the state of the art for unsupervised settings (no known reconstructions) but for supervised settings it is slightly below the PCN approach.",
    "The paper addresses the task of point cloud completion within an unpaired setting, where explicit correspondences between the partial and the complete shapes is not given. The setting represents significant interest in practice, e.g. in autonomous driving applications, where the precise completions of scanned objects, e.g. surrounding cars, are not necessary. ",
    "This paper proposes a new method for making 3D point clouds by automatically completing 3D scans. It does not require paired data samples for training which makes it possible to train it on real data instead of synthetic data. The authors use a generative adversarial network (GAN) to \u201cgenerate\u201d complete point clouds from noisy or partial point clouds obtained by 3D scanning. The generator learns to perform mapping from point set manifold of scanned noisy and partial input X_r to manifold of clean shapes X_c. The discriminator tries to tell between encoded clean shapes (synthetic data point clouds) and mappings of noisy input (point clouds from real-life data 3D scans). ",
    "This paper addresses the issue of malicious use of generative models to fool authentication/anomaly detection systems that rely on sensor data. The authors formulate the scenario as a maxmin game between an authenticator and an attacker, with limitations on the number of samples available to the authenticator to fix a decision rule, the number of samples required at test time for the authenticator to take a decision and the number of leaked samples the attacker has access to. The authors prove that the game admits a Nash equilibrium and derive a closed form solution for the case of multivariate Gaussian data. Finally, the authors propose an algorithm called \"GAN In the Middle\" and perform experiments to show consistency with the theoretical results, better authentication performance than state of the art methods and usability for data augmentation.",
    "This paper proposes a new threat model for generative impersonation attacks: The attacker has access to several leaked images of a person; the authenticator knows several registration images per person and decides a person's identify by comparing some newly-sampled images from that person with corresponding registration images. The authors formulate this threat model as a minimax game and analyzed its Nash equilibrium. In the simplified case that observations are multivariate Gaussian, the authors are able to characterize the optimal strategies of the attacker and authenticator explicitly, which gives a nice intuition on how the theoretical optimum changes with respect to data dimension, number of leaked images, etc. Additionally, the authors implemented this attack (named Gan-in-the-middle attack) with an objective similar to GANs, empirically verified the theoretical results, and demonstrated the success of their approach on VoxCeleb2 and ",
    "The authors investigate an attack-defense problem in which an attacker attempts to pass authentication by generating a faked input, while an authenticator attempts to detect the fraud. They formulate this problem as a zero-sum game and reveal the closed form of the optimal strategies. Furthermore, they reveal a more insightful closed form of the optimal strategies in the Gaussian case. This result clarifies the relationship between the success rate of the attacker and the numbers of the source, registration, and leaked observations. The analysis for the Gaussian case also gives an interesting insight that the optimal attacker\u2019s strategy is to generate fake inputs so that its sufficient statistics are matched to that of the leaked observations. Based on this insight, the authors propose a new learning algorithm for the authenticator and demonstrate by some empirical evaluations that the proposed algorithm is robust against the faked input.",
    "The paper studies the phenomenon of trade-off between robust and standard accuracies that is usually observed in adversarial training. Many existing studies try to understand this trade-off and show that it is unavoidable. In contrast, this work shows that under a sensible definition of adversarial risk, there is no trade-off between standard accuracy and sensible adversarial accuracy. It is shown that Bayes optimal classifier has optimal standard and sensible adversarial accuracies. The authors then go on to propose a new adversarial training algorithm which tries to minimize the sensible adversarial risk. Experimental results show that models learned through the proposed technique have high adversarial and standard accuracies. ",
    "Motivated from the so-called trade-off between robustness and standard accuracy in the existing adversarial learning, this paper has proposed a \"sensible\" adversarial example framework without losing  significantly  performance in natural accuracy. Some toy examples have been presented, showing its reasonableness of the model. The proposed algorithm looks very simple, but it appears that it could be effective through some experiments on two data sets.",
    "The paper proposes the notion of a \"sensible\" adversary that does not perturb data points on which the Bayes-optimal classifier is incorrect. The authors then provide theory showing that minimizing robust risk against such a sensible adversary yields the Bayes-optimal classifier, which addresses the question about standard vs. robust risk posed in prior work. On the experimental side, the authors then introduce a simple yet effective variation of adversarial training / robust optimization. Instead of maximizing the loss over the perturbation set, the proposed variant stops as soon as the loss exceeds a certain threshold. This can be seen as a variant of gradient clipping that reduces the influence of examples with a very high loss. The authors show that their modification yields an 8 - 9% improvement in robust accuracy on CIFAR-10, which gives state-of-the-art performance.",
    "In this paper, the authors study the online knowledge distillation problem and propose a method called AFD (Online Adversarial Feature map Distillation), which aims to transfers the knowledge of intermediate feature map (first propose) using adversarial training. Then, a cyclic learning scheme is proposed to train more than two networks simultaneously and efficiently. Ablation study on CIFAR100 shows that the adversarial training in AFD can improve the accuracy significantly, while the direct method such as using L1 distance is worse. The comparison experiments with several online distillation methods also show the effectiveness of proposed method.",
    "A new online knowledge distillation is investigated by utilizing feature map information next to the logits via GAN. Instead of direct feature map alignment, the algorithm tries to transfer the distribution of the feature maps. There is no teacher per se, but the big and small nets are trained via an adversarial game where 2 discriminators try to minimize the distributions of the two nets. The idea is understandable but some issues remain:",
    "This paper presents a new deep mutual learning (i.e., online peer-teaching) method based on Knowledge Distillation (KD) in a feature map level. The target task is similar with the original KD in the sense that the a network is taught by another network as well as groundtruth labels, but different with the KD in the sense that the networks are not a (frozen) teacher and a student but teaching each other in an online manner. Most approaches in this relatively new line of research rely on logit-based KD for transferring knowledges between networks, and the paper demonstrates that by an additional feature map level KD the performance can be further improved.",
    "The paper aims at extending GloVe word embedding model so that the resulting embeddings should capture sentiments (e.g. \"good\" is positive while \"bad\" is negative). The key idea is to employ an extension term to deal with the fact that some words appearing in text with sentiment information. Furthermore, to deal with the fact that many words an infrequent, besides maximum likelihood estimation, the paper proposes to use bayesian estimation. In the experiments, Stanford sentiment tree (SST) corpus is used. The word embeddings from the two models (each trained on different estimation methods) show their capability of expressing sentiments, compared with popular methods like Glove, word2vec. ",
    "This paper proposes a method to learn word embedding by incorporating additional sentiment information. The proposed method extends from D-GloVe by adding the probability of positive sentiment to the loss function. The paper presents three experiments: word similarity, word-level sentiment analysis, and sentence-level sentiment analysis. The experiments show that the method performs comparably with other baseline methods and outperforms in the low-frequency sentence setting (i.e. sentence containing lower frequency words).",
    "The paper proposed a word embedding model to incorporate the sentiment information. The paper provided both maximum likelihood estimation and maximum posterior estimation for the proposed framework. Improved experiment results on word similarity and low frequency embeddings are presented. Overall, the paper incorporates the sentiment information in a neat way. And my main concern is the around the Bayesian inference and the prior knowledge distilled into the model.  Detail comments are as following, ",
    "The paper proposes to study how early stopping in optimization helps find confident examples. Overall, the paper is well-organized and easy to read. Although there is some parallel study regarding the theoretical aspect of how early stopping help finds confident examples (i.e., Gradient Descent with Early Stopping is Provably Robust to Label Noise for Overparameterized Neural Networks, which has unfortunately not been cited), the paper focuses on the empirical perspective. A thorough empirical study illustrating how early stop works would interest the label noise community.",
    "This paper presents a training approach on label noise datasets and outperforms state-of-art methods. It defines the samples whose average probability on assigned label in recent q iterations is largest among all labels as memorized samples, in the sense of the network memorize these samples. Then authors proposed two stage method which firstly early-stops at minimum validation error (or $\\tau$ memorized rate), and then trains on maximal safe set that gathers memorized samples. The experiments compared several state-of-art approaches and showed that the proposed method benefits from early-stopping and safe set. Authors also showed that the prestopping idea can also be used to improve other approaches.",
    "This paper proposes a training strategy for robustness against label noise. The training strategy is simple and straightforward. The neural network will first be trained on the entire dataset with all the noisy labels. After obtaining the network with lowest validation error, the network will be used to make a prediciton on the original training set and select a subset of it to construct a maximal safe set. Finally, the network will be findtuned on this maximal safe set. The training strategy is very similar to tradictional  self-training in semi-superivsed learning and co-training for domain adaptation ([Co-training for domain adaptation, NIPS 2011]), except that the proposed prestopping only iterate the procedure once.",
    "This paper addresses the very interesting problem of generalising to new actions after only training on a subset of all possible actions. Here, the task falls into different contexts, which are inferred from an associated dataset (like pixel data). Having identified the context, it is used in the policy which therefore has knowledge of which actions are available to it. ",
    "This paper studies the problem of generalization of reinforcement learning policies to unseen spaces of actions. To be specific, the proposed model first extracts actions\u2019 representations from datasets of unstructured information like images and videos, and then the model trains a RL policy to optimize the objectives based on the learned action representations. Experiments demonstrate the effectiveness of the proposed model against state-of-the-art baselines in four challenging environments. This paper could be improved in the following aspects:",
    "This paper deals with the problem of how to enable the generalization of discrete action policies to solve the task using unseen sets of actions. The authors develop a general understanding of unseen actions from their characteristic information and train a policy to solve the tasks using the general understanding. The challenge is to extract the action's characteristics from a dataset. This paper presents the HVAE to extract these characteristics and formulates the generalization for policy as the risk minimization.",
    "The paper presents two methods to learn word embedding matrices that can be stored in much less space compared to traditional d x p embedding matrices, where d is the vocabulary size and p is the embedding size. Two methods are proposed: the first method estimates a p-dimensional embedding for a word as a sum of r tensor products of order n (tensor product of n q-dimensional embeddings).  This representation takes rnq parameters which can be much less than p, since p = q^n. The second method factorizes a full d x p embedding matrix jointly as a tensor product of much smaller t x q matrices and can obtain even larger space savings. Algorithms for efficiently computing full p-dimensional representations are also included. When only dot products are needed, the p-dimensional representations do not need to be explicitly constructed.",
    "This paper proposes word2ket - a space-efficient form of storing word embeddings through tensor products. The idea is to factorize each d-dimensional vector into a tensor product of much smaller vectors (either with or without linear operators). While this results in a time cost for each word lookup, the space savings are enormous and can potentially impact several applications where the vocabulary size is too large to fit into processor memory (CPU or GPU). The experimental evaluation is done on several tasks like summarization, machine translation and question answering and convincingly demonstrates that one can achieve close to original model performance with very few parameters! ",
    "This paper explores two related methods to reduce the number of parameters required (and hence the memory footprint) of neural NLP models that would otherwise use a large word embedding matrix. Their method, inspired by quantum entanglement, involves computing word embeddings on-the-fly (or by directly computing the output of the \"word embedding\" with the first linear layer of network). They demonstrate their method can save an impressive amount of memory and does not exhibit big performance losses on three nlp tasks that they explore.",
    "The paper proposes behavioral repertoire imitation learning (BRIL) which aims to learn a collection of policy from diverse demonstrations. BRIL learns such a collection by learning a context-dependent policy, where the context variable represents behavior of each demonstration. To obtain a context variable, BRIL rely on user\u2019s knowledge, where the user manually defines a feature space that describes behavior. This feature space is then reduced by using a dimensionality reduction method such as t-SNE. Lastly, the policy is learned by supervised learning (behavior cloning) with a state-context input variable and an action output variable. The method is experimentally evaluated on the StarCraft environment. The results show that BRIL performs better than two baselines: behavior cloning on diverse demonstrations and behavior cloning on clustered demonstrations. ",
    "This work examines the problem of using training a policy which can emulate a variety of different strategies based on a set of demonstrations representing this space of strategies.  The proposed method, BRIL, computes a feature vector for each demonstration, and then employs a dimensionality reduction technique to map the demonstrations to a latent space of strategies.  BRIL then preforms behavioral cloning on these demonstrations, with the reduced representation of the current strategy as an additional input to the policy model.  Empirical evaluation of BRIL is conducted in StarCraft II, where the agent is tasked with scheduling the construction of different units (other aspects of play are controlled by built-in AI).  Results show that when conditioned on good strategies, the BRIL model is superior to a base imitation learning model trained without strategy information.",
    "This paper presents Behavioral Repertoire Imitation Learning (BRIL) which is a way to learn a policy via imitation learning that can be modulated with different behavior inputs that adjust the policy's behavior.\u00a0 Demonstrations used in training are labeled with differences in behavior across dimensions (which are then reduced to two dimensions using t-SNE), and then these behavior labels are provided as additional input when training a NN from demonstrations using behavior cloning.\u00a0 Experimental results are shown for learning a BRIL policy from 7000+ demonstrations of humans playing StarCraft, and are compared to that of learning a single behavior cloned policy trained on all demonstrations as well as behavior cloned policies trained on subsets of demonstrations clustered by their behavior. ",
    "This paper carefully observes the behavior of weight magnitudes during training, finding the is a stage of saturation that is closely related to the winning lottery tickets drawing. Based on this observation the authors hypothesize that we can draw lottery tickets early but too early pruning can irreversibly hurt the learning capability for complex pattern. To remedy this and draw the tickets as soon as possible, the authors propose to adopt gradual pruning, which 1) can start early without hurting the learning capability too much; 2) avoid computation-heavy iterative pruning in previous works.",
    "The paper is dedicated to conducting an in-depth investigation of the structure of winning lottery tickets. The author provides supporting evidence for the structure of the early winning tickets: 1) lottery tickets emerge when the weight magnitude of a model saturates with SGD optimization. 2) pruning before model saturation may result in accuracy degradation. In the experiment part, they employ the memorization capacity analysis and discover the early wining tickets without expensive iterative pruning. The author also conducts extensive experiments with various ResNet architectures on both CIFAR 10 and ImageNet, achieving state-of-the-art results with only 1/5 of the total epochs for iterative pruning.",
    "This paper attempts an in depth study of the lottery ticket hypothesis. The lottery ticket hypothesis holds that sparse sub-networks exist inside dense large models and that the sparse sub-networks achieve at least as good an accuracy as the underlying large model. These sub-networks are discovered by training and iteratively pruning the dense model. This paper investigates the epoch at which pruning should occur as well as the epoch at which weights should be rewound when retraining. Then, the authors conduct experiments with different pruning strategies (one-shot vs. gradual) in an attempt to find such sparse models (or \"winning tickets\") earlier than they otherwise would have been found.",
    "This paper proposes a neural network architecture for image classification, which can more accurately recognize the unknown class that is not presented in the training data than the prior work. The key idea is to organize the features into a binary tree and use the product of probabilities along the paths to the leaf node to predict whether the test image has all the relevant features that should present in known classes. This proposed method is compared to multiple baselines and demonstrates superior results in image classification, especially for correctly predicting the unknown class.",
    "This paper proposes the unknown-aware deep neural network (UDN), which can be used to discover out-of-distribution samples for neural network classifiers. Its main idea is to introduce PR subnets to model the product relationship instead of the dot product of regular networks, then it can avoid over-fitting. Experimental results demonstrate that UDN can discover unknown samples more precisely than several baselines.",
    "This paper is about a novel method to detect unknown samples which are of a different class than the trained ones. The idea is to use an output subnet which use a fully connected layer and a binary tree which encode the product relationship instead of the sum currently used in state of the art method (particularly the softmax with low confidence). The binary tree is made of split nodes which are responsible to produce a probability distribution from the root to each leaf. The max path i.e. the path with the largest probabilities determines the class of the input and can be used to measure how confident the classifier is about the classification decision. Combine multiple subnets and the tool obtained is able to do complex predictions and maintain a good generalization performance. The method also uses an information theory based regularization which decrease the probability of having subnets with uniform probability distribution i.e. a large entropy. Experiments on CIFAR-10 and MNIST against CIFAR-100, SVHN show that the method has an improved rejection accuracy while maintaining a good classification accuracy on the test set.",
    "The paper proposes to improve standard variational inference by increasing the flexibility of the variational posterior by introducing a finite set of auxiliary variables. Motivated by the limited expressivity of mean field variational inference the author suggests to iteratively refine a \u2018proposal\u2019 posterior by conditioning on a sequence of auxiliary variables with decreasing variance. The key requirement to set the variance of the auxiliary variables such that the integrating over them leaves the original model unchanged. As noted by the authors this is a variant of auxiliary variables introduced by Barber & Agakov. The motivation and theoretical sections seems sound and the experimental results are encouraging, however maybe not completely supporting the claim of new \u2018state of the art\u2019 on uncertainty prediction. ",
    "This paper describes a method for training flexible variational posterior distributions, which consists in making iterative locale refinements to an initial mean-field approximation, using auxiliary variables. The focus is on Gaussian latent variables, and the method is applied to Bayesian neural nets to perform variational inference (VI) over the weights. Empirical results show improvements upon the performance of the mean-field approach and some other baselines, on classification and regression tasks.",
    "The paper proposes a new way to improving the variational posterior. The q(w) is an integral over multiple auxiliary variables. These auxiliary variables can be specified at different scales that can be refined to match different scales of details of the true posterior. They show better performance regression and classification benchmark datasets. They also show that the training time is at a reasonable scale when being parallelized.",
    "The paper presents experimental results on the application of the gradient ARSM estimator of Yin et al. (2019) to challenging structured prediction problems (neural program synthesis and image captioning). The authors also propose two variants, ASR-K which is the ARS estimator computed on a random sample of K (among V) labels, as well as a binary tree version in which the V values are encoded as a path in a binary tree of depth O(log(V)), effectively increasing the length of sequences to be predicted but reducing the action space at each tilmestep.",
    "The authors propose a new algorithm for unbiased stochastic gradient estimation for use in reinforcement learning of sequence generation tasks (specifically neural program synthesis and image captioning). The method consists in performing correlated Monte Carlo rollouts starting from each token in the generated sequence, and using the multiple rollouts to reduce gradient variance. An interesting property of the proposed algorithm is that the number of rollouts automatically scales with the uncertainty of the policy.",
    "The paper presents a novel reinforcement learning-based algorithm for contextual sequence generation. The algorithm builds on the previously proposed MIXER algorithm and improves it by integrating gradient estimates with lower variance (augment-REINFORCE-swap-merge). To further improve the runtime complexity of the proposed algorithm, binary tree-based hierarchical softmax is applied. The algorithm is evaluated on the Karel dataset for neural program synthesis and the MS COCO dataset for image captioning.",
    "This paper studies goal recognition control given a deceptive opponent, who selects actions to intentionally mislead or confusing the learner to learn the true goal. The problem has been studied in the security game, resource allocation game and Stackelberg game, where the defender is to play a resource allocation game given the best response of the attacker. in this paper, the authors use stochastic-shortest-path MDP to model the attacker's planning problem. The defender's objective is stated in eq (2) and (3) but not explained clearly.",
    "This paper proposes to use reinforcement learning to model an agent that is reaching goal that it is intended to reach. The authors consider the case where the agent is (1) indifferent to being observed, (2) trying to help an observer reach its goal, and (3) trying to fool the observer into not reach its goal. The paper propose to use a value function to quantify how easy it is to predict where the agent is going (\"worst case distinctiveness\"). The authors propose to then train an agent to modify the action space to make it difficult for an agent to fool the observer.",
    "This paper aims to provide a goal recognition framework. The paper reviews previous literature and outlines a model, but it seems to be at the draft stage as it stands as the experiment section is missing (section 4). Also, in some parts the sentences are broken and hard to follow, for example, \u201cHere we formulate the stochastic goal recognition control (S-GRC) problem as an extension of the GRD problem to allows non-optimal agents and stochastic actions, which means the agent\u2019s action are not deterministic and the possible successor states are with probability, the measures we can take are interdictions with cost.\u201d",
    "Training with large batches provides a disproportionate improvement for GANs (e.g. FID drops from 18.65 to 12.39 by simply increasing the batch size by a factor of 8 for BigGAN). The authors point out that not everybody has access to the computing power which is required to run large batches. Therefore, this paper proposes a method to select the image of the batch and thereby obtaining the benefits of large batches while running only small batches.",
    "This paper applies core-set selection to the training of GANs. The motivation is to limit the minibatch size with suitably sampled sets of datapoints. The proposed technique is relatively reasonable: e.g. extract features from an image, reduce dimensionality by the taking random projections, then run Core-Set selection. The Core-Set selection part of the method is modular from the rest of the GAN training, and can be applied easily. ",
    "This paper addresses the challenging problem of how to speed up the training of GANs without using large mini-batch sizes and causing significant performance drop. To achieve this, the authors propose to use the method of core-sets, mainly inspired by recent use of core-set selection in active learning. The proposed method allows us to generate effectively large mini-batches though actually small during the training process, or more concretely, drawing a large batch of samples from the prior and then compress that batch using core-set selection. To address the curse of dimensionality issue for high-dimensional data like images, the authors suggest using a low-dimensional embedding based on Inception activations of each training image. Regarding the experimental evaluation, it is clearly shown that the proposed core-set selection greatly improves GAN training in terms of timing and memory usage, and allows significantly reducing mode collapse on a synthetic dataset. As a by-product, it is successfully applied to anomaly detection and achieves state-of-the-art results.",
    "The paper investigate how optimal recurrent neural networks (RNNs) are at storing past information such that it is useful for predicting the future. The authors estimated optimality in terms of mutual information between the past and the future. If the RNN was able to retain MI between the past and the future, it then has kept optimal information from the past for predicting the future. The experiments suggest that RNNs are not optimal in terms of prediction of the future. It also suggest that this is due to the maximum likelihood training objective.",
    "This manuscript shows that good ability to compress past information in RNNs help them to predict the future, and that improving upon this ability leads to more useful RNNs. The manuscript first adapts modern mutual-information estimators to mini-batch settings in order to measure the information that an RNN has on the past. It then considers stochastic training, adding Gaussian noise to the hidden states during the training of the RNNs to limit past information. A significant section is dedicated to an empirical study that shows that classically-train MLE RNNs lead to internal representations with a suboptimal mutual-information to the past and the future. For LSTM and GRU architecture, stochastic training actually significantly helps. Experiments on applications such as synthetizing hand-drawn sketches suggest that stochastic training leads to more useful RNNs.",
    "This paper certainly poses an interesting question: How well do RNNs compress the past while retaining relevant information about the future. In order to quantitatively answer this question, the authors suggest to look at (the optimal solutions of) the Information Bottleneck Lagrangian (IBL). The investigated RNNs need to solve the task of next-step prediction, which can be used to evaluate the IBL. In the paper, the (deterministic) hidden state h is transformed through simple additive Gaussian noise into a stochastic representation which then is utilized to compute the IBL. In general the IBL is not tractable and hence the paper uses approximate computations.",
    "A recent paper by Lu et al introduced delusional bias in Q-learning, an error due to the max in the Bellman backup not being consistent with the policy representation implied by the greedy operator applied to the approximated value function. That work proposed a consistent algorithm for small and finite state spaces, which essentially enumerates over realizable policies. This paper proposes an algorithm for overcoming delusional bias in large state spaces. The idea is to add to the Q-learning objective a smooth penalty term that induces approximate consistency, and search over possible Q-function approximators. Several heuristic methods are proposed for this search, and results are demonstrated in Atari domains.",
    "This paper presents a solution to tackling the problem of delusional bias in Deep Q-learning, building upon Lu et.al. (NeuRIPS 2018).  Delusional bias arises because independently choosing maximizing actions at a state may be inconsistent as the backed-up values may not be realizable by any policy. They encourage non-delusional Q-functions by adding a penalty term that enforces that the max_a in Q-learning chooses actions that do not give rise to actions outside the realizable policy class. Further, in order to keep track of all consistent assignments, they pose a search problem and propose heuristics to approximately perform this search. The heuristics are based on sampling using exponentiated Q-values and scoring possible children using scores like Bellman error, and returns of the greedy policy. Their final algorithm is evaluated on a DQN and DDQN, where they observe some improvement from both components (consistency penalty and approximate search).",
    "This paper focuses on addressing the delusional bias problem in deep Q-learning, and propose a general framework (ConQUR) for integrating policy-consistent backups with regression-based function approximation for Q-learning and for managing the search through the space of possible regressors. Specifically, it proposes a soft consistency penalty to alleviate the delusional bias problem while avoiding the expensive exact consistency testing. This penalty encourages the parameters of the model to satisfy the consistency condition when solving the MSBE problem. ",
    "In this paper, the authors propose a generative latent variable model, which is named as SPACE, for unsupervised scene decomposition. The proposed model is built on a hierarchical mixture model: one component for generating foreground and the other one for generating the background, while the model for generating background is also a mixture model. The model is trained by standard ELBO with Gumbel-Softmax relaxation of the binary latent variable. To avoid the bounding box separation, the authors propose the boundary loss, which will be combined with the ELBO for training. The authors evaluated the proposed on 3D-room dataset and Atari. ",
    "This paper studies the problem of unsupervised scene decomposition with a foreground-background probabilistic modeling framework. Building upon the idea from the previous work on probabilistic scene decomposition [Crawford & Pineau 2019], this paper further decomposes the scene background into a sequence of background segments. In addition, with the proposed framework, scene foreground-background interactions are decoupled into foreground objects and background segments using chain rules. Experimental evaluations have been conducted on several synthetic datasets including the Atari environments and 3D-Rooms. Results demonstrate that the proposed method is superior to the existing baseline methods in both decomposing objects and background segments.",
    "The paper proposes SPACE: a generative latent variable models for scene decomposition (foreground / background separation and object bounding box prediction). The authors state the following contributions relative to prior work in this space: 1) ability to simultaneously perform foreground/background segmentation and decompose the foreground into distinct object bounding box predictions, 2) a parallel spatial attention mechanism that improves the speed of the architecture relative to the closest prior work (SPAIR), 3) a demonstration through qualitative results that the approach can segment into foreground objects elements that remain static across observations (e.g. the key in Montezuma's Revenge).",
    "The paper proposes a CNN compression method, based on the so called EHP operation, which can be used to  analyze and generalize depthwise separable convolution. Based on EHP, the paper develops depthwise separable convolution to compress CNNs, and extend it to a rank-k approach with further improved accuracy. Some analysis is provided about the operation equivalence. The experiments on standard benchmark datasets show the effectiveness of the method. ",
    "The paper is dedicated to studying fast and lightweight convolution for efficient compression and retaining original accuracy. In this paper, the authors interpret existing convolution methods based on depthwise separable convolution and derive FALCON. They claim their FALCON mathematically approximate the standard convolution kernel and achieves a better TA/efficiency tradeoff. They conduct extensive experiments to show that FALCON based method 1) outperforms previous state-of-the-art methods; 2) achieve 8X efficiency while ensuring similar TA.",
    "This paper proposed a model compression method: Falcon and rank-k Falcon. Both are used to compress CNN type of models by replacing standard convolution layer with a compact Falcon or rank-k Falcon layer to compress the model. Falcon's main idea is to decompose the traditional convolution kernel K into two smaller tensors, one is depthwise convolution kernel D and pointwise convolution kernel P. And DP will reconstruct the original kernel K. Since D+P's memory is  D*D*M+N*M which is smaller than the original size D*D*M*N, and thus when N is large, the memory saving could be large. The paper is in general in good writing and very easy to read.",
    "The paper performs an empirical study of four batch-normalization improvements and proposes a new normalization technique for small batch sizes, based on group and batch normalizations. Among others, the authors address the inconsistency between the train and the test stages and the problem of small batch sizes. The authors conducted an empirical ablation study of the four techniques and proposed an intuition when each method should be used.",
    "The authors discuss four techniques to improve Batch Normalization, including inference example weighing, medium batch size, weight decay, the combination of batch and group normalization. Equipped with the proposed techniques, the authors obtain promising results when training deep models with various batch sizes. However, the novelty of this paper seems very limited and more experiments are required.",
    "The paper introduces four techniques to improve the deep network model through modifying Batch Normalization (BN). The inspirations are from the gaps between train&test and between batches in multi-gpu training, comparison to other normalization methods, and weight decay in regularizing convolution weights training. The paper studies each techniques with the support from experiments. The paper is easy to follow. The techniques seem effective.",
    "This work presents a method for using generative models to gain insight into sensitive user data, while maintaining guarantees about the privacy of that data via differential privacy (DP) techniques. This scheme takes place in the federated learning (FL) setting, where the data in question remains on a local device and only aggregate updates are sent to a centralized server. The intended application here is to use the trained generative models as a substitute for direct inspection of user data, thus providing more tools for debugging and troubleshooting deployed models in a privacy conscious manner.",
    "The paper identifies a key challenge in a large class of real world federate learning problems where we also have to ensure user level data privacy. In these settings the modeler can not inspect the raw data samples from the user (due to privacy concerns) and hence all modeling tasks (from data wrangling to hypothesis generation to labeling to model class selection to validation) become far more challenging. The paper proposes that in these circumstances one may use a generative model that learns the data distribution using federated learning methods with provable differentiable privacy guarantees. The generative model can then produce data (unconditional, or conditional on some features or class labels) which can be inspected by the modeler without compromising user privacy. ",
    "This paper proposes a differentially private federated learning method to learn GAN with application to data bugging situations where privacy protection is needed. The proposed method tries to leave the data at the user-end to train the discriminators, and learn the generator at the centralised server. To support the debugging data related issues as claimed, two specific examples related to text and image modeling were presented. It is the generator which is DP-protected (as the discriminators are DP-protected) makes it possible where the generated data can hint the potential bugs. ",
    "This paper aims at taking techniques from motion interpolation into the regime where one is able to generate longer range motion sequences, in the domain of physically plausible computer animation of characters. In the way that the authors have set up the problem, an initial database seeds the search for plausible transitions between two given poses. So, the technique being proposed must address how to keep physical realism (the long-standing question of \"dynamics filtering\" along the lines of Yamane, Katsu, and Yoshihiko Nakamura. \"Dynamics filter-concept and implementation of online motion generator for human figures.\" IEEE transactions on robotics and automation 19.3 (2003): 421-432. Of course the problem here also needs to address \"style\" which needs different models). ",
    "The paper tackles the problem of generating long-range, diverse and natural looking motion sequence between initial and end states, and proposes to use a semi-parametric approach consisting of local and global models. Specifically, first the proposed approach extracts local motion feature from a reference subsequence and style feature from another, and then generates a new motion sequence. Then, global motion composition is done to interpolated generated local subsequences by bi-directional composition. In experimental validation, the approach outperforms two baselines (GAN and VAE). ",
    "The paper proposed ''composable semi-parametric modeling'' for generating long-range diverse and distinctive behaviors to achieve a specific goal location. The non-parametric part is a memory bank that is used to retrieve motion patterns from source materials. The parametric part contains several deep neural networks which are to compose the retrieved materials for high quality and smooth motion generation. The overall idea is novel in the sense that they aim to combine the strength of the non-parametric method (with rich pattern and diversities) and the parametric method (powerfull ability to generate coherent results). The proposed ideas are evaluated on two datasets and outperform compared approaches qualitatively.",
    "The authors proposed a method for generating hierarchical importance attribution for any neural sequence models (LSTM, BERT, etc.) Towards this goal, the authors propose two desired properties: 1) non-additivity, which means the importance of a phrase should be a non-linear function over the importance of its component words; 2) context independence, which means that the attribution of any given phrase should be independent of its context. For example, in the sentence \"the film is not interesting\", the attribution of \"interesting\" should be positive while the attribution of \"not interesting\" should be negative.",
    "The paper addresses the problem of hierarchical explanations in deep models that handle compositional semantics of words and phrases. The paper first highlights desirable properties for importance attribution scores in hierarchical explanations, specifically, non-additivity and context independence, and shows how prior work on additive feature attribution and context decomposition doesn\u2019t accurately capture these notions. After highlighting the said properties in context of related work, the authors propose an approach to calculate the context-independent importance of a phrase by computing the difference in scores with and without masking out the phrase marginalized over all possible surrounding word contexts (approximated by sampling surrounding context for a fixed radius under a language model). Furthermore, based on the above, the authors propose two more score attribution approaches -- based on integrating the above sampling step with (1) the contextual decomposition pipeline and (2) the input occlusion pipeline. Experimentally, the authors find that the attribution scores assigned by the proposed approach are more correlated with human annotations compared to prior approaches and additionally, the generated explanations turn out to be more trustworthy when humans evaluate their quality.",
    "This paper proposes a hierarchical decomposition method to encode the natural language as mathematical formulation such that the properties of the words and phrases can encoded properly and their importance be preserved independent of the context. This formulation is intuitive and more efficient compared to blindly learning contextual information in the model. The proposed method is a modification of contextual decomposition algorithm by adding a sampling step. They also adapt the proposed sampling method into input occlusion algorithm as another variant of their method. The proposed method is tested on LSTM and BERT models over sentiment datasets of Stanford Sentiment Treebank-2 and Yelp Sentiment Polarity and TACRED relation extraction dataset and showed more interpretable generated hierarchical explanations compared to baselines.",
    "The authors present a method that computes a saliency map after each scale block of a CNN and combines them according to the weights of the prior layers in a final saliency map. The paper gives two main contributions: SMOE, which captures the informativeness of the corresponding layers of the scale block and LOVI, a heatmap based on HSV, giving information of the region of interest according to the corresponding scale blocks. The method is interesting as it does not require multiple backward passes such as other gradient-based method and thus prove to be more time-efficient.",
    "This paper presents a method for creating saliency maps reflecting what a network deems important while also proposing an interesting method for visualizing this. The central premise for the method of characterizing relative importance of information represented by the network is based on an information theoretic measure. A variety of results are presented to examine the impact of keeping or removing information deemed important by this measure and a comparison is made to existing approaches as a justification for the proposed methods.",
    "The paper presents a new approach, SMOE scale, to extract saliency maps from a neural network. The approach is deemed as efficient, because it does not require one or multiple backward passes, as opposed to other approaches based on gradients. The main idea is to process the output activation tensors of a few selected layers in a deep network using an operator combining mean and std.dev. called SMOE scale. The result of this operator can be combined through different scales to obtain a global saliency map, or visualized in such a way that shows the consistency of saliency maps at different scales. Experiments show some improvement against traditional gradient-based approaches.",
    "This work proposes an alternative approach to non-autoregressive translation (NAT) by predicting positions in addition to the word identities, such that the word order in the final prediction doesn't matter as long as the positions are correct. The length of the translation is predicted similar to Gu et al 2017, as well as smoothly copying the source sequence to decoder input. However, since the positions are unknown, this paper employs a heuristic search method to find the nearest neighbors in the embedding space to obtain position supervision.",
    "This work builds on the non-autoregressive translation (NAT) by using position as a latent variable. Unlike the work by Gu et. al. 2018, where they assume the output word order to follow the word order of the input sentence, this work explores predicting word order supervision as an additional train signal. It shows that predicting the position of the words improves the performance of the translation and paraphrase task. This paper uses a heuristic that the inputs positions and output positions of the decoder with close by embeddings are more likely to represent the position mapping. ",
    "This work proposes a non-autoregressive model for conditioned text generation. The non-autoregressive decoder conditions on a sequence of discrete latent variables, which represent the generation order and can be autoregressively calculated. Instead of doing marginal inference, the paper takes the top 1 generation order that best match inputs. Experiments on machine translation and paraphrase generation show strong result in comparison to other non-autoregressive models.",
    "This paper proposes the Random Path Generative Adversarial Network (RP-GAN) to serve as a tool for generative model analysis.  The main idea is to have several different buckets in each block of the generator and then train the generator with random paths. To interpret the features captured by each block, the authors unfreeze one block and show the variance of the generated images via different buckets.",
    "This paper addresses the issue of interpretability of GAN generation through an alternative approach to the introduction of variability. To seed the generation, instead of providing a random input vector (typically sampled from a standard Gaussian distribution), the authors instead modify the generator architecture so as to allow for randomization in the routing: each layer is replaced by a bucket consisting of several blocks, and in forward propagation only through randomly chosen blocks. In this case, the input vector is chosen to be a constant - the only source of randomization",
    "This paper presents a variation on the generator of GANs. The authors modify the generator by adding a concept of \"blocks\" which are randomly activated based on part of the random input vector. It is similar to adding random dropout in the generator, except that the dropout would apply to larger sets of activations instead of single component.",
    "In this paper, CNNs specialized for spherical data are studied. The proposed architecture is a combination of existing frameworks based on the discretization of a sphere as a graph. As a main result, the paper shows a convergence result, which is related to the rotation equivalence on a sphere. The experiments show the proposed model achieves a good tradeoff between the prediction performance and the computational cost. ",
    "The paper studies the problem of designing a convolution for a spherical neural network. The authors use the existing graph CNN formulation and a pooling strategy that exploits hierarchical pixelations of the sphere to learn from the discretized sphere. The main idea is to model the discretized sphere as a graph of connected pixels: the length of the shortest path between two pixels is an approximation of the geodesic distance between them. To show the computational efficiency, sampling flexibility and rotation equivariance, extensive experiments are conducted, including 3D object recognition, cosmological mode classification, climate event segmentation and uneven sampling.",
    "The paper presents DeepSphere, a method for learning over spherical data via a graphical representation and graph-convolutions. The primary goal is to develop a method that encodes equivariance to rotations, cheaply. The graph is formed by sampling the surface of the sphere and connecting neighbors according to a distance-based similarity measure. The equivariance of the representation is demonstrated empirically and theoretical background on its convergence properties are shown. DeepSphere is then demonstrated on several problems as well as shown how it applies to non-uniform data.",
    "This paper introduces the compression risk in domain-invariant representations. Learning domain-invariant representations leads to larger compression risks and potentially worse adaptability. To this end, the authors presents gamma(H) to measure the compression risk. Learning weighted representations to control source error, domain discrepancy, and compression simultaneously leads to a better tradeoff between invariance and compression, which is verified by experimental results.",
    "This paper presents a revisit of existing theoretical frameworks in unsupervised domain adaptation in the context of learning invariant representation. They propose a novel bound that involves trainable terms taking into account some compression information and a novel interpretation of adaptability. The authors mention also contribution showing that weighting representations can be a way to improve the analysis. ",
    "This submission provides a new theoretical framework for domain adaptation. In order to tackle the adaptability term in the classical domain adaptation theory, this submission proposes a new upper bound that enlarge the hypothesis space in the adaptability term. A weighted version of this theory is also given. Authors further support their conclusion by empirical results.",
    "Authors proposed an algorithm to predict the attribute of GUI elements from rasterized design images. The problem is separated into two steps. The first step is to predict initial values of the attributes (border width, color, padding etc) from the image where the type of UI element and set of attributes are already known. Authors designed a typical convolutional DNN for each of the attributes. The second step is to learn a policy \\pi to iteratively adjust one attribute a time until the final rendering matches input image pixel-perfect. ",
    "This paper proposes an approach for reverse-engineering webpages using Siamese networks and imitation learning. While the idea of using synthetic data (which can be easily procedurally generated) to do this reverse-engineer training is very clever, prior work has exploited it also. Novel elements include the attribute refinement using imitation learning, and the authors show the effect of this step, but the improvement is small. Thus, the limited novelty and not very convincing results make the question the potential impact of this paper.",
    "The paper proposes an approach to infer the attribute values of an input image representing a user interface. The model first infers the most likely initial attribute values, and iteratively refine them to improve the similarity between the input image and the interface generated from the newly inferred attributes. The model is trained on synthetic datasets generated by a black box rendering engine, and generalizes well to real-world datasets. To address the issues of pixel based metrics and mean squared error, the authors instead uses the probability that two images are equal in the attribute space to define the cost between these two images.",
    "Paper summary: This paper explores the problem of robustly transfer learning using only standard training (as opposed to adversarial training (AT)) on the target domain. The authors start by highlighting that intermediate representations learned by adversarially trained networks are themselves fairly robust. Then they propose two strategies for robust transfer from a robust model trained on the source domain: (1) naturally fine-tuning the final linear layer on the target domain and (2) naturally fine-tuning all the layers using lifelong learning strategies. They study transfer between CIFAR10 and CIFAR100, as well as, from ImageNet to CIFAR10/100.",
    "The paper studies transfer learning from the point of view of adversarial robustness. The goal is, given a robust deep neural network classifier for a source domain, learn a robust classifier for a target domain as efficiently and with as few samples as possible. The authors empirically evaluate different strategies and compare with relevant baselines.",
    "This paper addresses the problem of performing robust transfer learning. A first contribution of the paper is to robust and classic training with respect to usual validation accuracy and robustness to adversarial attacks on the CIFAR task. Then, the same comparison is made on a transfer learning task. The transfer learning setting is then completed by studying transfer from ImageNet-based models with a particular attention to low-data regime and training deeper networks on top of the feature extractor. An analysis of robust features is provided and finally the authors studies the interest of  Learning without Forgetting strategies to provide robust transfer. The tendency s to obtain the Best performance from robust-trained source models having a good validation accuracy.",
    "This paper proposed a neural iterated learning algorithm to encourage the dominance of high compositional language in the multi-agent communication game. The author shows that the iterative training of two agents playing a referential game can incrementally increase the agent to use the language with high topological similarity. The authors also demonstrated that topological similarity is correlated with zero-shot performance. And Experiment results show the authors could propose alternative pre-training strategies for the neural agent can prefer high compositional language and achieve high task performance. ",
    "This paper studies the emergence of compositional language in neural agents. They propose an iterated learning method that consists of three phases: a supervised learning phase for a randomly-initialized speaker and listener, a self-play phase (where both agents are updated together), and a phase where a new dataset is created based on the current speaker\u2019s language. This dataset is then passed on to the next \u2018generation\u2019 of speaker and listener. The paper finds that this procedure, with the right hyperparameters, leads to the emergence of more compositional languages in a simple symbolic referential game.",
    "The paper \"Compositional languages emerge in a neural iterated learning model\" address the problem of language emergence in two-players games. In particular, the authors proposed a neural iterated learning model which seeks comopsitional languages. Authors claim that compositional languages are easier to be learned and that they allow listeners to more easily understand provided messages. ",
    "This manuscript proposes a new approach to fitting Markov Random Fields (MRFs).  The general structure of the algorithm is amenable to many MRF structures and can be fairly straightforwardly applied to learning on a wide variety of problems.  The theoretical analysis supports that the algorithm is reasonable.  Experimental results show strong results on several different MRF models, albeit on relatively small problems.",
    "The work proposes using variational distributions to model the model the inference of latent variables and model the partition function building on NVIL, thereby providing an algorithm that would work on general MRFs for both inference and learning. Since the two terms in the NLL are opposite in sign, it is a minimax operation and GAN like adversial training can be used. The paper shows providing tighter results to estimate the log partition function and comparisons on the digits dataset and Anneal importance sampling.",
    "This paper presents a black-box style learning algorithm for Markov Random Fields (MRF). The approach doubles down on the variational approach with variational approximations for both the positive phase and negative phase of the log likelihood objective function. For the negative phase, the authors use two separate variational approximations, one of which involves the modeling of the latent variable prior under the approximating distribution,",
    "The authors propose to apply HER to image-based domain, assigning rewards based only on exact equality (and not using an epsilon-ball). The authors also propose to (1) filter transitions that are likely to cause false negative rewards and (2) balance the goal relabeling so that the number of positive and negative rewards are equal. The authors demonstrate that these two additions result in faster and better learning on a simulated 2d and 3d reaching, as well as a rope task. The authors also show that the method works on training a real-world robot to reach different positions from images.",
    "The paper tackles the problem of self-supervised reinforcement learning through the lens of goal-conditioned RL, which is in line with recent work (Nair et al, Wade-Farley et al, Florensa et al, Yu et al.). The proposed approach is a simple one - it uses the relabeling trick from (Kaelbling, 1993; Andrychowicz et al., 2017) to assign binary rewards to the collected trajectories. They apply two simple tricks on top of relabeling:",
    "In this paper, the authors focus on the problem of goal conditioned reinforcement learning. Specifically, the authors consider the setting where the agent only observes vision as input and the ground truth state is not observable by the agent. In this setting, it is hard to specify a reward function since the reward function has to compute rewards from images.",
    "This paper is dedicated to developing robustness verification techniques. They claim their methods can deal with verification problems for Transformers which includes cross-nonlinearity and cross-position dependency. The paper solves these key challenges which are not traceable for previous methods. Moreover, the author demonstrates their certified robustness bounds are significantly higher than those by naive Interval Bound Propagation. They also point out the practice meaning through sentiment analysis.",
    "This paper builds upon the CROWN framework (Zhang et al 2018) to provide robustness verification for transformers. The  CROWN framework is based upon the idea of propagating linear bounds and has been applied to architectures like MLP, CNNs and RNNs. However, in Transformers, the presence of cross-nonlinearities and cross-position dependencies makes the backward propagation of bounds in CROWN computationally intensive. A major contribution of this paper is to use forward propagation of bounds in self attention layers along with the usual back-propagation of bounds in all other layers. The proposed method provides overall reduction in computational complexity by a factor of O(n). Although the fully forward propagation leads to loose bounds, the mixed approach (forward-backward) presented in this work provides bounds which are as tight as fully backward method. ",
    "This paper develops an algorithm for verifying the robustness of transformers with self-attention layers when the inputs for one input word embedding are perturbed. Unlike previous work the present work can deal with cross nonlinearity and cross position dependency and the lower bounds derived in the paper are much tighter than the Interval Boundary Propagation (IBP) method which uses backward propagation. The core contribution is expounded by developing bounds for multiplication (xy) and division (x/y) and using this to compute tight bounds on self-attention layer computations. Further by introducing a forward process then combining it with a backward process, they can substantially reduce computation time as compared to the IBP method (in experiments demonstrated to be over an order of magnitude). ",
    "This paper aims to incorporate world knowledge for the pretraining approach so that (1) pretrained models contain useful information about the world, and (2) benefit downstream NLP tasks. The paper does so by introducing the objective which distinguishes the groundtruth entity and the false entity in the Wikipedia text. This was carefully done by detecting entities in the text, find the corresponding entity in Wikidata, randomly choose another entity which has the same type as the original entity, and make sure this doesn\u2019t happen for neighboring entities or too much in order to avoid context change. Adding this objective to the original masked LM objective, this pretrained model is shown to be effective and outperform baselines significantly in many tasks such as zero-shot fact completion, question answering, and fine-grained entity typing.",
    "This paper proposes to trained better entity centric text embeddings by switching entities mentioned in the text to some other entities with the same type. The target is modeled as a binary classification task, which is trained jointly with the MLM loss. The authors do experiments on multiple tasks, and the model shows strong performance on all tasks. And the ablation study justifies that \"knowledge pre-training\" is crucial. The idea is novel and the experiment results suggest that the additional \"adversarial\" target helps. The writing is clear in general, but misses some implementation details. ",
    "This paper proposed to improve pre-training of language models (e.g. BERT) by incorporating information around entities based on English Wikipedia. The idea is very simple and straightforward: it takes all the anchor links from Wikipedia and replaces some entities by randomly sampling negative ones of the same entity type (according to Wikidata) and adds an extra binary prediction task which predicts if the entity has been replaced or not. ",
    "  This paper tackles the problem of unsupervised object discovery, whereby a labeled dataset must be leveraged in order to then cluster an unlabeled dataset with a set of unknown categories. The paper contributes three main ideas to succeed at this task, namely 1) use of self-supervised learning to initialize the representations in a way that doesn't bias them to the labeled data, 2) a robust rank-based metric to generate estimates of similarity/dissimilarity along with consistency-based regularization to improve optimization, and 3) Joint optimization/refinement using a combination of labeled/unlabeled losses, as well as ability to learn incrementally without forgeting the original labeled classes. Results are shown on a range of datasets including OmniGlot, ImageNet, CIFAR-10, CIFAR-100, and SVHN. The results demonstrate improvement over the current state of art for this task. ",
    "This paper addresses the problem of clustering unseen classes. To learn a robust feature extractor, this paper proposes a multi-stage training framework, which leverages different supervised manners in each stage. Specifically, they initialize the network using the self-supervised learning on the union of all available data and then further finetune it using labelled data. Based on this, they propose the rank statistics which leverages the activation knowledge on labelled classes and rank the activated dimensions. Unseen data having similar rank results are clustered to obtain the initial pseudo labels. Finally, the network is jointly optimized with the ground-truth and generated pseudo labels (the pseudo ones will be updated during training). Extensive experiments on 5 datasets show that their method has significant advantages over SOTA owing to the learned robust feature extractor.",
    "The authors propose a methodology to discover new categories in an unlabeled dataset with the help of a label one. The authors propose the following methodology. First bootstrap some features using self-supervised learning on labeled and unlabeled data. Then transferring the knowledge of the labeled data to the unlabeled one by supposing that the representations of both are similar, the similarity being a rank statistic. Then using this knowledge a joint supervised-unsupervised objective.",
    "The paper presents a method for learning agents to solve visual planning, in particular to navigate to a desired goal position in a maze, with a learned topological map, i.e. a graph, where nodes correspond to positions in the maze and edges correspond accessibility (reachability in a certain number of steps). The work extends previous work (semi parametric topological memory, ref. [22]) in several ways. It claims to address a shortcoming of [22], namely the fact that the graph is calculated offline from random rollouts, by using a conditional variational auto-encoder to predict a set of observed images which could lie between the current position and the goal position, and, most importantly from a context image which describes the layout of the environment. These predicted images are then arranged in a graph through a connectivity predictor, which is trained from rollouts through a contrastive loss. Training is performed on multiple environments, and the context vector provides enough information for this connectivity network to generalize to unseen environments.  At test time, the agent navigates using a planner and a policy. The planner calculates the shortest path on a graph where edges are connectivity probabilities, and the policy is an inverse model trained on the output of the planner.",
    "The paper propose a novel visual planning approach which constructs explicit plans from \"hallucinated\" states of the environment. To hallucinate states, it uses a Conditional Variational Autoencoder (which is conditioned on a context image of the domain). To plan, it trains a Contrastive Predictive Coding (CPC) model for judging similarities between states, then applies this model to hallucinated states + start/end states, then runs Dijkstra on the edges weighted by similarities.",
    "The paper presents HTM, an extension of the semiparametric topological memory method that augments the approach with hallucinated nodes and an energy cost function. The hallucination is enabled by a CVAE, conditioned on an image of the environment, and allows the method to generalize to unseen environments. The energy cost function is trained as a contrastive loss and acts as a robustness score for connecting the two samples. The underlying graph is then used to plan for several top view planning problems.",
    "This paper proposes to learn a subset of a given dataset that acts as an adversary, that hurts the model performance when used as a training dataset. The central claim of the paper is that existing datasets on which models are trained are potentially biased, and are not reflective of real world scenarios. By discarding samples that add to this bias, the idea is to make the model perform better in the wild. The authors propose a method to do so, and then refine it so that the resulting solution is tractable. They implement the method on several datasets and show that by finding these adversarial samples, they indeed hurt model performance. ",
    "This paper hypothesizes that even though we are able to achieve very impressive performance on benchmark\u00a0datasets as of now (e.g. image net), it might be due to the fact that benchmarks themselves have biases. They introduce an algorithm that selects more representative data points from the dataset that allow to get a better estimate of the performance\u00a0in the wild. The algorithm ends up selecting more difficult/confusing instances.",
    "the paper proposes an algorithm that adversarially filters out examples to reduce dataset-specific spurious bias. the key intuition is that the datasets are curated in a way that easy to obtain samples have higher probability to be admitted to the dataset. however, not all real world samples are easy to obtain. in other words, real world samples may follow a completely different distribution than curated samples with easy-to-obtain ones.",
    "This paper looks at the problem of few-shot classification in the regime when only a single class is present. The task at hand is as follows: given a number of support images of a previously unseen class (not present during training) and a single unlabeled image, we need to decide if this image belongs to the class or not. While previous approaches would explicitly construct negative examples to contrast the positive ones with during training, the authors bypass this by using batch norm in the last layer, which, on average, centers embedding feature vectors at 0, defining effectively the embedding for the negative class. In addition, the authors look at modelling the distribution of support image embeddings to improve the performance of their model.",
    "Authors consider the 1-way few shot classification task. Argue that modeling it as a 2-way with a random negative sample is not efficient. Propose a novel technique applicable for prototypical networks. Their proposal is to use 0 as the prototype of null class. So the distance to the prototype is compared against the norm of the query embedding. They also propose modeling the distribution and not just the centroid using a multivariate gaussian. But in practice there is no benefit in doing so. Therefore, the main contribution is proposing to compare against norm of the embedding rather than a prototype for random negative samples. The benefit of this proposal decreases by more shots. Probably because the prototype of 20 random images is 0 anyway.",
    "This paper addresses a method of applying prototypical networks (which are popular for few-shot learning problems) to few-shot one-classification problems where only one group of examples are available without any counter-examples. The main idea of prototypical networks is to learn an embedding function such that in the embedding space a distance metric well reflects the class structure. When such models are applied to one-class problems, a basis for comparison is required. ",
    "The authors propose a way to fuse information on nodes of a graph with the topology of the graph in the large scale setting. The proposed approach is done in four phases where (i) the covariates in the nodes of the graph is first mapped in the graph space for fusion and fused using linear combination of the topological graph and feature graph, (ii) the resulting \"adjacency\" matrix will almost surely not be sparse even if the original graph space, so they use eigenvalues of the graph laplacian to coarsen the graph -- remove edges; (iii) they then propose to embed the coarsened graph using \"any\" unsupervised learning technique; (iv) then the embedded representation is refined using iterative procedures. Cheap procedures are introduced to do Phases (i) and (iv). Experimentally the authors see improvements in the performance using their approach compared to the baselines considered.",
    "This paper proposes GraphZoom, a framework for augmenting unsupervised graph embedding methods by (a) fusing feature information into the graph topology, (b) learning embeddings on a coarsened graph, and (c) refining the coarsened embeddings to obtain embeddings for the original graph nodes. In particular, a nearest neighbor graph over node features is computed and this adjacency matrix is linearly combined with the original adjacency matrix to obtain a graph with feature information \"fused in\". The graph is then coarsened using a spectral approach, embeddings are learned on the coarsened graph (via any strategy), and the embeddings are then refined back to the original nodes (again using a spectral approach). The authors take care to heed the advice of Maehara et al. and remove high-frequency information from the features.",
    "The paper provides a multi-level graph-coarsening approach that can improve the predictive and computational performances of numerous existing unsupervised graph embedding models. The proposed approach is a pipeline consisting of 4 steps, viz: 1) Graph Fusion - that fuses attribute similarity graph with network topology, 2> Graph Coarsening - that reduces the graph size iteratively, 3> Graph embedding - using existing models and 4> Embedding refinement. While such a pipeline for scaling using a graph coarsening and refinement based approach is not new, the authors have carefully designed the pipeline to be effective and be scalable such as without any costly learning components (as in mile). The effectiveness of the proposed approach is evaluated with the node classification task on 6 datasets.",
    "The paper bases its methodology on well known developments in image analysis/synthesis about similarity of pixel values in adjacent locations. Many techniques have been used for modelling this similarity, including predictive models, cliques and graphs. The paper uses a simple autoregressive model for generating pixel values based on the values of previously processed pixels, estimating the differences between these neighboring pixel values. ",
    "The paper proposes an approach for image generation that relies on an autoregressive model for the image pixels. These models are popularly used in image coding and compression settings, and have been used in generative models like PixelCNN. In contrast to this prior work, the proposed model is based on the selection of a previously available pixel and the modeling of the differences between the old pixel and the new one. The copy and adjustment models, i.e., eqs (3) and (5-6), are straightforward. Applications to image-to-image translation are also presented.",
    "In this paper the authors present a new way to use autoregressive modeling to generate images pixel by pixel where each pixel is generated by modeling the difference between the current pixel value and  the preexistent ones. In order to achieve that, the authors propose a copy and adjustment mechanism that select an existing pixel, and then adjust its sub-pixel (channel values) to generate the new pixel. The proposed model is demonstrated with a suite of experiments in classic image generation benchmark. The authors also demonstrate the use of their technique in Image to Image translation.",
    "This paper generalizes the recent state-of-the-art behavior agnostic off-policy evaluation DualDice into a more general optimization framework: GenDice. Similar to DualDice, GenDice considers distribution correction over state, action pairs rather than state in Liu et al. (2018), which can handle behavior-agnostic settings. The optimization framework (in equation (9)) is novel and neat, and the practical algorithm seems more powerful than the previous DualDice. As a side product, it can also use to solve offline page rank problem.",
    "This paper proposes a new estimator to infer the stationary distribution of a Markov chain, with data from another Markov chain. The method estimates the ratio between stationary distribution of target MC and the empirical data distribution.  It is based on the observation that the ratio is a fixed point solution to certain operators. The proposed method could work in the behavior-agnostic and undiscounted case, which is unsolved by the previous method.",
    "In this paper the authors proposed a framework for off-policy value estimation under the scenario of infinite horizon RL tasks. The new proposed method utilize the variational representation of $f$-divergence, which quantifies the difference between $\\mathcal{T}\\tau$ and $\\tau p$, where $\\tau$ is the parametric density ratio between the unknown behavior policy data and the target policy. If only if $\\tau$ is the true density ratio, the loss $\\mathcal{D}_{f}(\\mathcal{T}\\tau || \\tau p) = 0$. ",
    "This paper seeks to separate \"causal\" features from ones with spurious correlations in the context of natural language machine learning tasks. The proposed approach is to ask human annotators to alter examples in a minimal way that changes the label. Thereby the humans separate out the causal features (those changed) from the spurious or irrelevant features (those left unchanged).",
    "The authors propose a new way to augment textual datasets for the task of sentiment analysis, in order to help the learning methods to generalize better by concentrating on learning the different that makes a difference. The main idea of the paper is to augment existing datasets with minimally counteractual versions of them, that change the sentiment of the documents. In this way, all spurious factors will naturally cancel out. The authors use the newly created datasets and show that indeed, the retrained algorithms on the augmented datasets generalize much better.",
    "This paper addresses the problem of building models for NLP tasks that are robust against spurious correlations in the data by introducing a human-in-the-loop method: annotators are asked to modify data-points minimally in order to change the label.  They refer to this process as counterfactual augmentation.  The authors apply this method to the IMDB sentiment dataset and to SNLI and show (among other things) that many models cannot generalize from the original dataset to the counterfactually-augmented one.",
    "In the article the authors propose to measure quality of CNN-features by quantifying the orientation tuning and spatial frequency sensitivity of the features. The underlying hypothesis is that properties of features in the human visual cortex are also indicators for quality in CNNs. The authors devise an experiment similar to experiments performed on mammals to check which features are active under which types of basic patterns. Afterwards, a loss-function is devised that uses proportions of the best or worst features according to the metrics and it is shown that features that have high values on the metrics also lead to good performance.",
    "This paper proposes an analysis of convolutional neural networks (CNNs) features the basis for making perceptual quality comparisons. The analysis is based on the proposed Perceptual Efficacy (PE) Score that measures spatial frequency and orientation selectivity of CNN features. The hypothesis put forward by the authors is that a CNN features with high PE score can be used to formulate a perceptual loss (Eq. 1) that correlates well with human image quality judgement. The authors use a dataset of human image quality judgements to assess their hypothesis. ",
    "The submission aims to analyze deep neural network (DNN) features in terms of how well they measure the perceptual severity of image distortions. It proposes to characterize each DNN feature in terms of two well known properties of the human visual system: a) sensitivity to changes in visual frequency and b) orientation selectivity. Both properties are evaluated with respect to the known human Contrast Sensitivity Function (CSF) and measured empirically from the feature\u2019s response to (oriented) sinusoidal gratings. The results are quantified by a composite score termed Perceptual Efficacy (PE).",
    "Understanding drug-drug interactions (DDI) is an important task in drug development and prescription management. The authors proposed a new graph energy neural network (GENN) for DDI prediction. Comparing to the existing Decagon model (Zitnik et al. 2018), the proposed new model considered correlations between DDI types and used a new energy function to capture this information. By comparing to the previous baselines, the authors demonstrated their approach was able to achieve the SOAT performance in terms of prediction accuracy, be more robust to missing DDI data, and better capture the correlations between DDI types.",
    "This paper proposes a framework to learn correlated drug-drug interaction based on structured prediction energy networks (SPEN). The core idea is to model the dependency structure of the labels (multi-label) by minimizing a designed energy function. The graph energy is designed as MLP over the mean of all nodes embeddings, where the nodes embeddings are obtained through a graph convolutional network. The edge information is included in the node embedding when aggregating neighborhood information. The proposed method also introduces an additional test inference network to jointly train with the cost-augmented training network under the semi-supervised setting. The authors tested on two DDI datasets and the result shows improvement compared to several baseline methods.",
    "This paper presents a graph neural network for drug-to-drug interaction (DDI) prediction, which explicitly models link type correlation. Basically, the drug-to-drug interaction prediction problem is a specific type of link prediction task, with drugs as vertices and interaction as edges, and the authors propose a graph neural network with an energy-based formulation where the link types are encoded as the graph edges. The authors validate their method against feedforward GNNs on two DDI prediction datasets, and achieve significantly improved performances.",
    "This paper considers unsupervised (or self-supervised) discrete representation learning of speech using a combination of a recent vector quantized neural network discritization method and future time step prediction. Discrete representations are fine-tuned by using these as input to a BERT model; the resulting representations are then used instead of conventional speech features as the input to speech recognition models. New state-of-the-art results are achieved on two datasets.",
    "The paper proposes a way to pre-train quantized representations for speech. The approach proposed is a two-stage process: 1. train a quantized version of wav2vec [my understanding is that wav2vec is the same thing as CPC for Audio except for using a binary cross-entropy loss instead of InfoNCE softmax-cross entropy loss]. the authors propose to use gumbel softmax / VQ codebook for the vector quantization.",
    "Though rather dense in its exposition, this paper is an interesting contribution to the area of self-supervised learning  based on discrete representations. What would make it stronger imo is to address the issue of how much is gained from a discrete vs. continuous representation. The authors take it as a given that discrete is good because it allows us to leverage work in NLP. That makes sense -- but at what cost?",
    "The authors propose a novel reinforcement learning (RL) based recommendation algorithm (i.e., Ranking-Critical Training, RaCT) for modeling users' implicit feedback, which is illustrated in Figure 2(b). Specifically, the authors apply the actor-critic RL paradigm to approximately optimize the ranking-oriented loss/objective function in collaborative filtering with implicit feedback, which is a difficult and important problem. In particular, the critic network is used to approximate the ranking-oriented metric, and the actor network is used for optimizing this metric. Moreover, for efficiency, the authors also propose a feature-based critic to replace the original one.",
    "The work presents a two-level architecture for building an efficient ranking solution for standard collaborative filtering task in recommender systems. The core of this solution is the actor-critic approach, where the critic (motivated by ideas from RL) tries to directly approximate a ranking-based metric using as an input prediction from the actor (VAE framework) and the ground truth knowledge from an Oracle. Both actor and critic require a pre-training step, after which the critic is set to propagate adjustments to actor parameters. Experiments demonstrate the advantage of such approach over competing methods.",
    "This paper builds on the line of work of developing latent variable models (LVMs) for collaborative filtering with implicit feedback (e.g. which items a user has previously clicked on).  While variational autoencoders allow convenient construction of nonlinear LVMs, they are trained by maximizing the multinomial likelihood for the items selected.  Thus the training objective is not perfectly matched to the evaluation objective, which is typically something like NDCG @N or RECALL @N, neither of which is differentiable.  This paper proposes an actor-critic RL approach to train the nonlinear LVM directly for the NDCG loss.  The idea is to create a critic model that learns to approximate NDCG, and to train the actor to optimize this approximate objective.  However, they find that they are unable to build an effective critic when taking the predictions and ground truth directly.  However, they find that with a simple set of 3-features, they can build an effective critic that gives improved or competitive performance on several metrics on 3 large-scale datasets.  When their method (RaCT) is not the best, it is beaten by EASE, which is computationally much more expensive.",
    "This paper proposes the Composite Q-learning algorithm, which combines the algorithmic ideas of using compositional TD methods to truncate the horizon of the return, as well as shift a return in time. They claim that this approach will improve the method's data efficiency relative to standard Q-learning. They demonstrate its performance relative to Q-learning in a tabular domain, as well as in deep RL domains which use the compositional idea as an off-policy critic.",
    "This paper introduces a new Q-learning formalism that helps reduce the bias of single step bootstrapping in Q-learning by learning multiple single step bootstrapping Q functions in parallel. This is accomplished by composing multiple n-step returns, showing that a recursive definition of n-step returns allows each return to be learned using only a single step of bootstrapping instead of at most n steps of bootstrapping. The paper solves the problem of the n-step fixed horizon by additionally composing a gamma discounted Q function that is shifted by n. In the end, the Q function used for behavior still predicts the same values as vanilla Q-learning, but with significantly less bias without a large increase in variance.",
    "  This paper proposes to split the value function into two separately learned components (a short-term truncated value function, and a long-term shifted value function) suggesting the short term truncated returns should learn faster as compared to the tail of the returns. They provide temporal difference formulations for a truncated value function and shifted value function, enabling efficient learning of the two components. They also provide derivations of other similar approaches to the off-policy case. Finally, they compare their algorithm to several approaches on a subset of the MuJoCo tasks, and a novel tabular domain.",
    "The paper takes seriously the question of having a robotic system learning continuously without manual reset nor state or reward engineering. The authors propose a first approach using vison-based SAC, shown visual goals and VICE, and show that it does not provide a satisfactory solution. Then they add a random pertubation controller which brings the robot or simulated system away from the goal and a VAE to encode a compressed state, and show that it works better.",
    "This paper presents approaches to handle three aspects of real-world RL on robotics: (1)learning from raw sensory inputs (2) minimal reward design effort (3) no manual resetting. Key components:(1) learn a perturbation policy that allows the main policy to explore a wide variety of state. (2) learn a variational autoencoder to transform images to low dimensional space.",
    "  This paper focuses on current limitations of deploying RL approaches onto real world robotic systems. They focus on three main points: the need to use raw sensory data collected by the robot, the difficulty of handcrafted reward functions without external feedback, the lack of algorithms which are robust outside of episodic learning. They propose a complete system which addresses these concerns, combining approaches from the literature and novel improvements. They then provide an empirical evaluation and ablation testing of their approach and other popular systems, and show a demonstration on a real robotic system.",
    "The authors study the sample complexity of adversarially robust learning with access to unlabeled samples. Theoretically, they consider the setting of Schmidt et al. 2018 (separating two class-conditional Gaussians) and present an algorithm which can learn a robust classifier with only a few labeled samples and a large number of unlabeled samples (circumventing the sample complexity separation of the original work). Then, the authors propose a modification of the VAT algorithm (Miyato et al. 2018) to train deep networks utilizing unlabeled samples. They find that, empirically, their algorithm achieves better performance compared to standard adversarial training on the labeled samples.",
    "Paper summary: This paper seeks to improve robust generalization performance with the help of unlabeled data. The authors first consider the toy model presented in Schmidt et al. and show how the labeled sample complexity in the robust setting can be lowered to match the standard setting if sufficient unlabeled data is available. They then propose a practical algorithm to improve robust test accuracy and evaluate it on the MNIST and CIFAR datasets.",
    "This paper considers the problem of adversarial robustness. The paper shows that (Theorem 1) robust generalization error can be bounded in terms of the standard generalization error and a stability term, that does not depend on the labels. The paper also shows that for a simple classification problem involving learning the separator for a symmetric 2 gaussian mixture data, we can solve this problem robustly without additional labeled examples. The paper suggests that we can use unlabeled data to improve the robust generalization. Towards this the paper regularizer on the unlabeled data, that promotes stability in the model prediction. The paper evaluates this on Mnist and Cifar showing the better performance of the proposed regularization over PGD adversarial training.",
    "The paper studies the problem of advantage estimation for actor-critic RL algorithms. The key observation is that the advantage can be computed using 1-step returns, 2-step returns, etc. The paper suggests that, instead of choosing a fixed n, we should aggregate these advantageous together. If the maximum is taken, the resulting policy will be exploratory (i.e., have a \"promotion focus\"); if the minimum advantage is taken, the resulting policy will be risk sensitive (i.e., have a \"regulatory focus\").",
    "This paper focuses on risk-aware reinforcement learning, where an agent could be encouraged to take more risk (high reward, high variance states) or avoid risk (low variance states). Risk control is instantiated by different ways of estimating the advantage of a state (max/min instead of average). Experiments on several environments show good performance of the proposed algorithm.",
    "This paper presents a modification to policy gradient methods that are computed from advantage function estimates. For a given trajectory of n steps, there are n different advantage function estimates: from 1-step to n-step. GAE (Schulman, 2016) proposes to take an exponentially weighted average of these estimates to compute the policy gradients. This paper proposes instead to use order statistics to compute the policy gradient; e.g. the most optimistic estimate, the most pessimistic estimate, or the most extreme estimate.  The paper introduces a regulatory ratio: the probability of using the averaged advantage estimate vs using the order statistic, for computing the policy gradients. This hyper-parameter is justified on the optimistic case (max advantage), as a way to prevent overtly optimistic estimates. The paper conducts experiments on  different domains (sparse and dense rewards, discrete and continuous actions, fully observable and partially observable environments) which show the effect of choosing different order statistics and regulatory ratio on the policy performance.",
    "This paper presents an interesting quantization technique that is, unusually, end-to-end trainable and not just an inference technique. According to the experiments, the method achieves better performance and computational savings as compared to other quantization method baselines. The results are admirably demonstrated on a variety of models, including CNN and RNN-based neural nets, as well as on several datasets in different domains, including ImageNet, CIFAR10, and PTB. We see the method seems to generalize across all of these.",
    "This paper outlines a new method that allows using a variety of precision in the numerical representation of the network to increase performance (both in terms of accuracy and speed). They learn a threshold value for which all activation values above the threshold are learned at full precision, while all below are learned at reduced precision. This enables substantial performance gains. ",
    "This paper introduces Precision Gating, a novel mechanism to quantize neural network activations to reduce the average bitwidth, resulting in networks with fewer bitwise operations. The idea is to have a learnable threshold Delta that determines if an output activation should be computed in high or low precision, determined by the most significant bits of the value. Assuming that high activations are more important, these are computed at higher precision.",
    "This paper introduces the idea of wildly unsupervised domain adaptation, where the source labels are noisy and the target data is unsupervised. To tackle this, the authors propose an architecture based one two branches: one acting on the mixed source-target data and the other on the target data only. During training, each branch is updated using the idea of co-teaching, by finding the samples with the lowest loss values. Pseudo-labeling is then applied to the target data, and the process iterates.",
    "This paper proposes a new problem setting in the domain adaptation field. Since it is impossible to obtain perfectly clean labeled source data in the real world, existing UDA methods cannot well handle real-world data. However, in wildly unsupervised domain adaptation (WUDA), we do not need a perfectly clean source data, which means that WUDA problem is a more general and realistic problem than existing ones. ",
    "This paper presents a method for unsupervised domain adaptation. The problem is well known in literature and follows the setting of labeled source and unlabeled target set. This work proposes the \u201cbutterfly network\u201d suitable to train on noisy data (labels) and assign pseudo-labels to the target set. The butterfly network consists in two branches one for source+target and one for target only data. Both use the same optimization objective and a \u201cchecking\u201d mechanism has been devised for pseudo-labelling the data.",
    "The paper aims to tackle the problem of improving sample efficiency of model-free, off-policy reinforcement learning in an image-based environment. They do so by taking SAC and adding a deterministic autoencoder, trained end-to-end with the actor and critic, with the actor and critic trained on top of the learned latent space z. They call this SAC-AE. Experiments in the DeepMind control suite demonstrate that the result models train much faster than SAC directly on the pixels, in some cases reaching close to the performance of SAC on raw state. Ablation studies demonstrate their approach is most stable with deterministic autoencoders proposed by (Ghosh et al, 2019), rather than the beta-VAE autoencoder proposed in (Nair et al, 2018), end-to-end learning of the autoencoder gives improved performance, and the encoder transfers to some similar tasks.",
    "This paper proposes an approach to make the model-free state-of-the-art soft actor-critic (SAC) algorithm for proprioceptive state spaces sample-efficient in higher-dimensional visual state spaces. To this end, an encoder-decoder structure to minimize image reconstruction loss is added to SAC's learning objectives. Importantly, the encoder is shared between the encoder-decoder architecture, the critic and the policy. Furthermore, Q-critic updates backpropagate through the encoder such that encoder weights need to trade off image reconstruction and critic learning. The approach is evaluated on six tasks from the DeepMind control suite and compared against proprioceptive SAC, pixel-based SAC, D4PG as well as to the model-based baselines PlaNet and SLAC. The proposed method seems to achieve results competitive with the model-based baselines and significantly improves over raw pixel-based SAC. Further ablation studies are presented to investigate the information capacity of the learned latent representation and generalization to unseen tasks.",
    "This work presents a simple method for model-free RL from image observations. The key component of the method is the addition of an autoencoder that is trained jointly with the policy and value function, in contrast to previous methods which separate feature learning from policy learning. Another important modification is the use of a deterministic regularized autoencoder instead of a stochastic variational autoencoder. The method is evaluated a variety of control tasks, and shows strong performance when compared to a number of state-of-the-art model-based and model-free methods for RL with image observations.",
    "This paper propose an ensemble of dropout: it applies multiple copies of a neural net with different dropout configurations (i.e., dropout masks) to the same mini-batch, and the training loss is computed as the sum of losses incurred on the multiple copies. They claim that such ensembling can improve training performance over the original dropout without increasing too much computation. Experiments on several datasets show that the proposed method can achieve slightly better validation accuracies than the original dropout.",
    "The paper proposes a new variation of Dropout -- Multi-Sample Dropout. The method is said to 1) accelerate training, and 2) decrease validation error. To achieve that, the authors propose to average a loss function over several dropout samples per object during training. This leads to faster convergence in terms of iterations, though at the cost of multiple forward-passes. In order to decrease the computational time of one iteration, the authors propose to evaluate the part of a network before the first dropout layer only ones and duplicate the remaining part with different dropout masks and shared weights. This decreases the run time of the naive approach and leads to faster convergence in terms of time in comparison to the original dropout. The authors also show that the model trained with the proposed method achieves lower validation error.",
    "PAPER SUMMARY: The paper proposes a new and efficient implementation of dropout in which multiple dropout samples are obtained from a single input during training. The authors claim that this enhanced dropout technique (i) accelerates training and (ii) improves generalization by achieving lower error rates than standard dropout in training and validation sets. Experiments in image classification tasks for 4 different datasets (CIFAR-10, CIFAR-100, IMAGENET and SVHN) are presented and the effect of the number of dropout samples and dropout ratio are investigated.",
    "Contributions: The paper proposes a novel Label Sensitive Gate (LSG) structure to enable the model to learn disentangled filters in a supervised manner. The novelty of the paper is to introduce the Label-Sensitive Gate path during the training, on top of the standard training path. This encourages the filters to extract class-sensitive features. ",
    "This paper proposed an interesting idea of using Label Sensitive Gate (LSG) structure to enforce models to learn disentangled filters for better interpretability of the DNN model. By periodically training with the sparse LSG structure, the model is forced to extract features from only a few classes. The model is trained efficiently in an alternate fashion (with respect to both the network parameters and the sparse gate matrix.) By disentangling the class-specific filters, the model becomes less redundant and more interpretable.",
    "This paper proposes a method to improve the interpretability of a convolutional neural network (CNN). The main idea is to force the CNN filters to be class specific, i.e. to be associated to a specific class. This is accomplished by a gating function that enforces filters to be sparsely activated.  This would make the model more interpretable by allowing to check which filters/classes have been activated. Results are evaluated in terms of performance, sparsity of the filters and localization accuracy on CIFAR10.",
    "The authors propose a framework for combining value function factorization and communication learning in a multi-agent setting by introducing two regularizers, one for maximizing mutual information between decentralized Q functions and communication messages and the other for minimizing the entropy of messages between agents. The authors also discuss a method for dropping non-informative messages. They illustrate their approach on sensor and hallway tasks and evaluate their method on the decentralized StarCraft II benchmark. The paper addresses an interesting problem, and the authors show that their approach gives good performance compared to alternative approaches even when a large percentage of communication is cut off between the agents.",
    "Authors propose a new method for multi-agent reinforcement learning by using nearly decomposable value functions. The main idea is to have local (agent specific) value function and one global value function (for all agents). They also try minimizing the required communication need for multi-agent setup. To this end they deploy variational inference tools and support their method with an experimental study.",
    "The paper tackles the collaborative multi-agent RL problem as the problem of finding almost-decentralized value functions, where the loss tries to minimize communications between the agents. The core idea is around maximizing the mutual information between each massage and the existing knowledge of its receiver. This way, redundant messages are naturally removed. The authors then assert an entropy regularization to (almost) prevent the agents from *cheating*. The paper is in general well-written and motivated. There are however certain issues that should be addressed. [The second one is my main issue.]  ",
    "In this paper, the authors propose a new class of programs they call programming puzzles. The authors argue that this class of programs is ideal for helping learn AI systems to reason. The second contribution of the paper is an adaptive method of puzzle generation inspired by GAN-like generation that can generate a diverse and difficult set of programs. The paper shows that the generated puzzles are reasonably difficult to solve (using the time to solve as a measure of difficulty) and reasonably diverse. ",
    "This paper proposes a method for generating hard puzzles with a trainable puzzle solver. This is an interesting and important problem which sits at the intersection of symbolic and deep learning based AI. The approach is largely GAN inspired, where the neural solver takes the role of a discriminator, and the generator is trained with REINFORCE instead of plain gradient descend.",
    "This paper proposes a trainable 'puzzle' program synthesizer that outputs a program f with a specific syntax. These 'puzzles' are structured as boolean programs, and a program solver solves the puzzle by finding an input x such that f(x) = True.  The authors motivate this task by making a case that puzzles of this sort are a good domain for teaching computers how to program.",
    "\tThis paper takes a different approach for tackling the hierarchical RL problem. Their approach is to decompose the policy into a bunch of primitives. Each primitive acts according to its own interpretation of the state. All the primitives are competing with each other on a given state to take an action. It turns out that these primitive policies can be transferred to other tasks as they represent subtasks of a bigger task. The paper performs extensive experiments to show that this scheme improves over both flat and hierarchical policies in terms of generalization.",
    "The paper draws upon the idea of information bottleneck to do task decomposition so as to learn policy primitives similar to hierarchical reinforcement learning that combine together in a competitive manner to specialize in different parts of the task's domain. These policy primitives don't need a higher-level meta-policy to stitch them together. Instead the decision is made in a decentralized manner balancing the cost of information acquisition with maximizing rewards.",
    "This paper is about a policy design, where the policy is expressed as a mixture of policies called primitives.  Each primitive is made of an encoder and a decoder, mapping state to actions, rather than temporally extended actions (or options in RL).  The primitives compete with each other to be selected in each state and thus do away with the need for a meta-policy to select the primitives.  The selected primitive in each state trades between reward maximization and information content.  ",
    "This paper claims that one only needs a reward prediction model to learn a good latent representation for model-based reinforcement learning. They introduce a method that learns a latent dynamics model exclusively from multi-step reward prediction, then use MPC to plan directly in the latent space. They claim this is sample efficient in the model-based way, and is more useful than predicting full states. They learn a model that predicts only current and future rewards conditioned on action sequences, and that observation reconstruction is unnecessary to learn a good latent space. They provide planning performance guarantees for approximate latent reward prediction models. ",
    "This paper presents a technique for model based RL/planning with latent dynamics models, which learns the latent model only using reward prediction. This is in contrast to existing work which generally use a combination of reward prediction and state reconstruction to learn the latent model. The paper suggests that by removing the state reconstruction loss, the agent can learn to ignore irrelevant parts of the state, which should enable better performance in settings where state reconstruction is challenging. ",
    "This paper proposes a novel algorithm for planning on specific domains through latent reward prediction. The proposed model uses an encoder to learn embedding the state to the latent state, a forward dynamics function to learn dynamical system in latent state space, and a reward function to estimate the reward given a latent state and an action. Using these functions, the authors define the objective using the mean-squared error between true and multi-step prediction of rewards. To justify the proposed method, the authors provide a theoretical analysis and experimental results on specific RL domains, multi-pendulum and multi-cheetah, which contain irrelevant aspects of the state.",
    "The authors present ALBERT, a modification of the BERT architecture with substantially fewer parameters. They show that despite being much smaller, the performance is very strong and achieves state of the art on a variety of different tasks. There are several ideas proposed here: embedding factorization, sharing layers, and sentence ordering as a training objective. ",
    "This paper investigates improving upon BERT by reducing complexity in terms of free parameters and memory footprint as well as computation steps. They propose 2 strategies for doing this: 1) Splitting the embedding matrix into two smaller matrices (going from V x A to V x B + B x A where B <<<< A); 2) layer-wise parameter sharing. They also utilize sentence order prediction to help with training. These coupled with a bunch of other choices such as using the lamb optimizer, certain hyperparameters etc help show dramatic empirical gains across the board on a wide variety of NLP/NLU tasks.",
    "This paper proposes a new pre-trained BERT-like model called ALBERT. The contributions are mainly 3-fold: factorized embedding parameterization, cross-layer parameter sharing, and intern-sentence coherence loss. The first two address the issue of model size and memory consumption in BERT; the third corresponds to a new auxiliary task in pre-train, sentence-order prediction (SOP), replacing the next sentence prediction (NSP) task in BERT. These modifications lead to a much leaner model and improved performance. As a result, ALBERT pushes the state of the art on GLUE, RACE, and SQuAD while having fewer parameters than BERT-large. ",
    "This paper proposes a unified architecture in the context of multi-task learning where they demonstrate that training four tasks (with a variety of modalities like image, text, and videos) together results in about three times compressed model, while maintaining the performance similar to their respective individually trained models. The major components of this archtiecutre are (1) peripheral networks: used to encode the domain specific input into feature representations. (2) central neural processor: a fully attention based encoder-decoder model similar to the Transformer networks which encodes the spatio-temporal information. Further, this paper suggests that their unified architecture enables to perform decent on unseen tasks during its training. In this paper they test such scenarios on video captioning and video question answering. ",
    "This paper describes the \"OmniNet\" architecture, which is essentially a transformer to convert any 2-dimensional (time and spatial) input into a sequence of output tokens. The idea is that a single model (the \"Central Neural Processor\") would learn to perform multiple tasks on multiple inputs at the same time. This seems like a reasonable approach, and would allow a single model to be able to process text, image, as well as video or potentially speech input just the same. Dedicated modality-specific \"input peripherals\" would \"normalize\" the data appropriately, and a \"start token\" seems to provide the model with information on what type of input data is to follow.",
    "The authors propose an extended and unifying learning architecture \u2013 OmniNet- based on transformer, which tackles tasks with various modalities such as images, text and videos. This is attained with a spatio-temporal cache mechanism, that can both capture and store temporal information and spatial information. In addition, this proposed framework supports asynchronous multi-task learning with pre-trained neural networks on different modalities. OmiNet\u2019s generalization capability is illustrated and demonstrated with experiments. The proposed model has multiple peripheral networks each majoring on one unique modality of data. These peripheral networks project input data into the same shared format/space that can be uniformly processed in a central neural processor working like a CPU. The central neural processor uses self-attention and RNN for temporal encoding and spatial encoding. The output of the encoding components are stored in temporal and spatial caches respectively. The two caches are then used as input to the spatial temporal decoder for different tasks. ",
    "The authors propose using influence functions to efficiently estimate pointwise confidence intervals for regression models. Their central idea is to construct a confidence interval around a point $x$ as a function of how much the model $f$ changes around $x$ when individual training samples are left out. Their technical innovation is to combine a marginal error term that does not depend on $x$ (which ensures coverage) with a local variability error term that does depend on $x$ (to allow for greater variability in areas where the model is more uncertain and there is less data). The authors provide experimental support for the superiority of their method (in terms of coverage and discrimination) as well as theoretical support for consistency.",
    "This paper studies how to construct confidence intervals for deep neural networks with guaranteed coverage. The authors propose an algorithm, \u201cdiscriminative jackknife\u201d, based on the standard jackknife confidence interval estimate which they augment by a \u201clocal uncertainty estimate\u201d based on the variability of the n leave-one-out fitted versions of the underlying algorithm (n = # data points). The whole study is concluded with toy and real-world examples showing the proposed algorithm is competitive with existing methods while also achieving the desired coverage.",
    "In this work, the authors develop the discriminative jackknife (DJ), which is a novel way to compute estimates of predictive uncertainty. This is an important open question in machine learning and the authors have made a substantial contribution towards answering the question of \"can you trust a model?\" DJ constructs frequentist confidence intervals via a posthoc procedure. Throughout, the authors provide excellent background and exposition. They develop an exact construction of the DJ confidence intervals in Section 3.1. This is an intuitive approach that the authors explain well. Next, they explain and then develop the concept of higher order influence functions. They do a great job of communicating this concept. Section 3.4 provides the theoretical guarantees for DJ. The related work section is extensive and thorough. The authors have thoughtful experiments that demonstrate positive attributes of DJ. ",
    "This paper presents a method for training a generative adversarial network on high resolution videos and complex datasets. They propose decomposing the discriminator in Adversarial Networks into a spatial and temporal discriminator similar to previous works, however, the temporal discriminator downsamples the input using average pooling before forwarding it through the network. In experiments, the presented method outperforms previous state-of-the-art methods in the used metrics. In addition, the videos generated from the Kinetic-600 dataset in a non-conditional setting are the most realistic looking up to date. ",
    "This paper tackles the problem of efficient video generation. The authors present a Dual-Video-Discriminator Generative Adversarial Network (DVD-GAN) composed of an image-level spatial discriminator and video-level temporal discriminator. DVD-GAN achieves state-of-the-art results when benchmarked against the FID, IS and FVD quantitative metrics. Compared to previous video generation works, DVD-GAN is the first model to present compelling qualitative results on the UCF-101 and Kinetics-600 dataset.",
    "The paper proposes a class-conditional GAN model for video generation called DVD-GAN. The generator uses a single latent variable and uses ConvGRU modules and ResNet blocks to generate N frames. The model uses a dual discriminator, with one discriminator that discriminates individual frames, i.e. an image discriminator, and one that discriminates the whole video. This is similar to the MoCoGAN model, with the main difference being that the video discriminator operates on a smaller resolution video, thus reducing the dimensionality of the input to discriminate. The model is used to generate videos after being trained on the large-scale Kinetics-600 dataset, which contains multiple examples and has a lot of variability across videos. The main contribution of the paper is to successfully train this large GAN model on the very large-scale Kinetics dataset. The samples from the model are very visually appealing and are qualitatively  superior to any previous video prediction model.",
    "A new task is suggested, similarly to FSL the test is done in an episodic manner of k-shot 5-way, but the number of samples for base classes is also limited. The model is potentially pre-trained on a large scale dataset from another domain. The suggested method is applying spatial attention according to entropy criteria (or certainty) of the original classifier (from a different domain).",
    "This paper proposed a new realistic setting for few-shot learning that we can obtain representations from a pre-trained model trained on a large-scale dataset, but cannot access its training details. Also, there may be a large domain shift between the dataset of the pre-trained model and our dataset. For the pre-trained model, they will not only use its weights but also use it to generate a spatial attention map and help the model focuses on objects of images. Back to the standard few-shot classification problem, they will first adapt the model with base class samples and then adapt to novel classes.",
    "The paper introduces a problem \u201cfew-shot few-shot learning\u201d that aims to firstly transfer prior knowledge from one domain to the domain where the base training tasks reside, and then train a few-shot learning model on training tasks and apply it to novel test tasks. The two \u201cfew-shot\u201d in the name refers to base training tasks and novel test tasks. In their algorithm, they use a model pre-trained on another dataset as the prior knowledge and fine-tune it on training tasks. During the test, they use the weighted average of samples\u2019 representations per class as the prototype of each class, where the weight is large for samples with more discriminative prediction over pre-trained domain\u2019s classes. Afterward, classification is reduced to finding the nearest neighbor among the class prototypes. Some experiments show that the pre-trained model can improve few-shot classification accuracy.",
    "In this paper the authors present a Generative Adversarial Neural Networks with Xu et al.\u2019s semantic loss applied to the generator. They call this GAN a Constrained Adversarial Network or (CAN) and identify it as a new class of GAN. The authors present three different problem domains for their experiments focused on the generation of constrained images, chunks of Super Mario Bros.-style levels, and molecules. For each domain they include particular constraints for the semantic loss, which biases the generator towards creating valid content according to these constraints. ",
    "This paper proposed Constrained Adversarial Networks (CAN), which incorporates structural constraints by augmenting a penalty term in the training object. The penalty term is formulated as the semantic loss proposed in [1] which can handle any logical constraints. Experiments are demonstrated to show the advantage of CAN over standard GAN in terms of whether the generated samples satisfy the hard constraints, and whether they are novel and unique.",
    "The authors describe a method to improve the performance of generative adversarial networks in the task of generating structured objectives that have to satisfy complicated constraints. The proposed solution involves using an additional term in the GAN objective that penalizes the generation of invalid samples. This term, called the semantic loss, is given by a multiple of the log probability of the model generating valid samples.",
    "This paper proposes a learnable piece-wise linear activation unit whose hinges are placed symmetrically. It gives a proof on the universality of the proposed unit on a certain condition. The superiority of the method is empirically shown. The change of the activation during training is analyzed and insight on the behavior is provided. The robustness to adversarial attacks is also empirically examined.",
    "This paper proposes the S-APL (Symmetric Adaptive Piecewise Linear) activation function, based on the APL activation function proposed by (Agostinelli et al, 2014). This activation function is constructed as a piecewise linear function that is learned concurrently with training, and, in the case of S-APL, the activation function is forced to be symmetric. S-APL is claimed to help both with trainability and robustness of neural networks to adversarial examples.",
    "In this paper, a new activation function, i.e. S-APL is proposed for deep neural networks. It is an extension of the APL activation, but is symmetric w.r.t. x-axis. It also has more linear pieces (actually S pieces, where S can be arbitrarily large) than the existing activation functions like ReLU. Experimental results show that S-APL can be on par with or slightly better than the existing activation functions on MNIST/CIFAR-10/CIFAR-100 datasets with various networks. The authors also show that neural networks with the proposed activation can be more robust to adversarial attacks.",
    "In this paper, the authors propose to use a dirichlet prior over the multinomial distribution outputted by blackbox DL models, to quantify uncertainty in predictions. The main contribution is to learn the parameters of the prior and use it as a wrapper over the black box, to adjudicate whether to retain or reject a particular prediction made by the model. The dirichlet parameters are learnt in conjunction with the model parameters as a fine tuning step in transfer learning tasks. Experiments on NLP and CV domains and multiple datasets demonstrate the efficacy of the method. ",
    "This paper presents a method for learning a \u201cwrapper\u201d model which endows a multiclass predictor with an estimate of model uncertainty. The base model is treated as a black box which emits a categorical distribution, while the wrapper model estimates the parameters of a Dirichlet distribution. The wrapper is trained against silver labels from the base model, and the sampled predictive entropy is used to threshold predictions so as to withhold a decision on uncertain examples.",
    "Motivated by real-world challenges in applying pre-trained models, the authors propose a model for selective prediction (prediction with an option for abstention) that wraps an existing black-box classification model. The resulting model output is a Dirichlet distribution with mean equal to the categorical distribution produced by the black-box and concentration parameter specified by a separate auxiliary model. This additional model is trained to minimize negative log-likelihood of observations under categorical distributions sampled from the aforementioned Dirichlet along with an L1 regularization term on the concentration parameter. To infer the model\u2019s level of uncertainty, the authors propose computing the entropy of the average of sampled categorical distributions.",
    "This paper proposes blockwise adaptivity.  We divide the parameters into blocks, for example in a linear threshold unit the bias term is in a bias term block while the input weights are in an input weight block.  We then average the square norm of the gradients over each block and use the same adaptation based on this average square norm for all parameters in the block.  theoretical and experimental results are given.",
    "In this paper, the authors propose a generalization of AdaGrad, called BAG, that operates on blocks of parameters instead of each individual parameter. The authors also propose a momentum version of BAG called BAGM. Convergence rate results are proved for the algorithm, and some uniform stability results show situations where BAG would generalize better than previous adaptive gradient methods.",
    "The paper proposes adaptive gradient approaches where the step-size is not determined on the per-coordinate basis but rather for blocks of coordinates. Theoretical results are presented in terms of regret in online convex optimization, regarding convergence in non-convex optimization,  and with respect to uniform stability and generalization. These indicate that under certain conditions adaptivity at the block level could outperform coordinate-wise adaptivity. The approach is evaluated against alternatives on simulated and real-world problems.",
    "This paper introduces a new synthetic video understanding dataset, borrowing many ideas from the visual question answering dataset CLEVR. The new dataset is the first to account for all of the following fundamental aspect of videos: temporal ordering, short- and long term reasoning, and control for scene biases. Due to the inherent biases in available action recognition datasets, models that simply averages video frames do nearly as well as models that take temporal dependencies into account. In contrast, the authors show that with the proposed dataset, models without spatiotemporal reasoning largely fail.",
    "The paper introduces CATER: a synthetically generated dataset for video understanding tasks. The dataset is an extension of CLEVR using simple motions of primitive 3D objects to produce videos of primitive actions (e.g. pick and place a cube), compositional actions (e.g. \"cone is rotated during the sliding of the sphere\"), and finally a 3D object localization tasks (i.e. where is the \"snitch\" object at the end of the video).  The construction of the dataset focuses on demonstrating that compositional action classification and long-term temporal reasoning for action understanding and localization in videos are largely unsolved problems, and that frame aggregation-based methods on real video data in prior work datasets, have found relative success not because the tasks are easy but because of dataset bias issues.",
    "This paper proposed a new synthetic dataset (CATER) for video understanding. The authors argue that since current video datasets are heavily biased over static scenes and object structures, it is unclear whether modern spatial-temporal video models can learn to reason over temporal dimension. In order to address this problem, they design this fully observable synthetic dataset which is built upon CLEVER, along with three tasks that are customized for temporal understanding. They further conduct a variety of experiments to benchmark state-of-the-art video understanding models and show how those models more or less struggle on temporal reasoning. ",
    "In this work authors consider a problem of 'model compatibility' of GANs, i.e. usefullness of the generated samples for classification tasks. Proposed 'Boundary Calibration' GAN attempts to tackle this issue by adding non-adversarial terms to discriminator, obtained as outputs of the classifiers trained on the original data. For evaluation, it is proposed to compare accuracies obtained by classifiers trained on generated and on real data (termed 'relative acurracy'). Experiments show that the proposed methods improve such scores.",
    "In this paper the authors propose a method for improving \"model compatibility\" in GANs. For this reason they add to the loss of the generation procedure a term that depends on the maximum mean discrepancy between the following datasets: (1) the output of a classifier with input the real dataset, (2) the output of the same classifier with input GAN-generated samples. They authors show that in essentially all the datasets they tried, the model compatibility of the produces generator is increased after adding the aforementioned cost, while the visual quality of the data is not decreased.",
    "This paper aims at training a GAN that can generate data matches the real data distribution well especially at the boundaries of the classifiers. A Boundary-Calibration loss (BC-loss) base on multi pretrained classifiers is introduced to match the statistics between the distributions of original data and generated data. The motivation is interesting. The story is clearly explained. However, the experiments part is weak.  ",
    "The authors propose a framework where one component is an attacker network that keeps learning about how to perturb the loss more, and one component is a defense network that robustify learning with respect to the attacker network. The framework is flexible on how the attacker network can be trained, and advances over previous works where the attacker is a human-designed algorithm rather than a learning model. Experiment results show that the framework reaches superior defense performance. The authors also extend the framework to help imitation learning.",
    "In general, this paper follows the min-max training framework for adversarial robustness. Instead of using a gradient-based attack to solve the inner maximization, the authors use a neural network to learn the attack results. From the experimental results, this method can effectively defend against CW and PGD on CIFAR-10 and CIFAR-100. But the clean accuracy is lower than Madry et al. ",
    "The paper proposes a new way of adversarial training by placing another neural network called \"attacker\" network, and let the attacker to learn how to generate adversarial examples during training. This training scheme is formulated to solving a joint training according to min-max problem. Experimental results show that the method outperforms existing adversarial training in CIFAR-10/100 once the gradient information can be provided into the attacker network. ",
    "The paper considers learning of constraints in MDPs in an IRL setting with the goal of maximizing the likelihood of demonstrations (in the constrained MDP). The constraints come in the form of avoiding certain states, actions or features. The authors propose an algorithm for learning the constraints and evaluate their approach in synthetic and a real-world experiment.",
    "The submission considers estimating the constraints on the state, action and feature in the provided demonstrations, instead of learning rewards. The authors use the likelihood as MaxEnt IRL methods to evaluate the \"correctness\" of the constraints, and find the most likely constraints given the demonstrations. While the problem is challenging (NP-hard), suboptimality of the proposed algorithm is analyzed. Experiments are provided to demonstrate the performance of the proposed method. ",
    "In this work, a novel inverse constraint learning method is proposed, where the goal is to find out the constraints over state-action pairs for given demonstration and MDP **including a reward function** (so different from inverse cost learning). The novelty of this work comes from introducing maximum entropy inverse reinforcement learning (MaxEntIRL) framework to previous works [1, 2], and this work mainly focused on the tabular setting. The objective of this work is to solve the optimization in (8), which tries to find out the constraint that maximizes the probability of trajectories that cannot be generated if that constraint is applied. (Such an objective minimizes the normalization constant in (5) and results in maximization of the demonstration likelihood under the constraint.) To solve this objective, the proposed algorithm first computes the feature occupancy (Algorithm 1), and then use those feature occupancy with greedy iterative constraint inference (Algorithm 2 that motivated by maximum coverage problem) to get constraints. Two experiments in the GridWorld show that the proposed method effectively works. ",
    "The authors propose a new artificial neural network architecture that is derived from a human visual model (M\u00e9ly et al., 2018). The original (human vision) model can explain some of the human visual illusions, specifically contextual ones. While the adaptation from this human visual model to artificial neural networks was previously done by (Linsley et. al., 2018a), in this paper the authors extend (Linsley et. al., 2018a) to better capture some of the constraints in the human visual model, and also to add a formulation that can also model top-down connections (across layers).",
    "The paper introduces a complex hierarchical recurrent model for contour detection loosely inspired by the organization of cortical circuits. Their model performs state-of-the-art on sample-limited versions of popular contour detection (BSDS500) and cell segmentation (SNEMI3D) datasets, and it reproduces the well-known tilt illusion when transfer-learning orientation estimation. Interestingly, \"untraining\" the tilt illusion degrades performance on contour detection.",
    "The presented paper introduces a novel neural network architecture to explore the question whether visual illusions are corner cases of the human visual system, or whether they represent limitations of perception. The developed recurrent network architecture aims at being more sample efficient than existing methods. The findings discussed in the paper suggest that visual illusions are a byproduct of neural circuits that help to increase the robustness of the human visual system, which in turn suggests that neural networks for processing visual data could benefit from integrating circuits in similar ways. While existing work predominantly aims at explaining whether visual illusions are features or artifacts of the visual system, this work focuses on finding a computational solution to support the hypothesis that visual illusions are features. In particular, the contributions of this work are: (1) novel neural network architecture, called \\gamma-networks, which is derived from the work of [Meley et al. 2018] and (2) that the proposed architecture is more sample efficient than SOTA convolutional architectures on contour detection tasks. ",
    "This paper introduces a context-aware neural network (conCNN) that integrates context semantics into account for object detection. The proposed approach achieves this by embedding a context-aware module into the Faster R-CNN detection framework. The context-aware module simulates the learning process of Conditional Random Fields (CRF) model using a stack of common CNN operations. Specifically, this paper employs the mean-field approach of [1]. Experiments are performed on COCO dataset.",
    "The paper proposes a contextual reasoning module following the approach proposed by the NIPS 2011 paper for object detection. Specifically, the algorithm proposed by NIPS 2011 are first converted to end-to-end modules step-by-step, and then added to the detection framework Faster R-CNN. The comparison is only to one other baseline (Relation Module), and some improvements are show especially for small objects.",
    "This paper proposes a CRF-based context module for CNN-based object detectors. In particular for the two-stage region-based detector, like Faster RCNN, the context module is added right before the output layer of the classification head. Every box proposed by the RPN is a node in the CRF, and its label is the classification label. Message passing is unrolled as neural network layers. Potentials are defined based on object detector outputs, box overlap, and co-occurrence of class labels. Experiments are performed on the MS COCO object detection task. ",
    "This paper addresses a limitation of BatchNorm: vulnerability to adversarial perturbations. The authors propose a possible explanation of this issue and correspondingly an alternative called RobustNorm to tackle this problem. Specifically, the authors observe that the statistics of BatchNorm for training and inference are different, resulting in different data distributions for training and inference. To solve this problem, the authors propose to use min-max rescaling instead of normalization. In addition, the running average is calculated with mean and the running mean of the denominator during inference. Experimental results show significant improvement of robustness and also comparable accuracy for clean data.",
    "Review: This paper investigates the reason behind the vulnerability of BatchNorm and proposes a Robust Normalization. They experimentally show that it is the moving averages of mini-batch means and variances (tracking) used in Normalization that cause the adversarial vulnerability. Based on this observation, they propose a new normalization method not only achieves significantly better results under a variety of attack methods but ensures a comparable test accuracy to that of BatchNorm on unperturbed datasets. The paper is clearly written, easy to read.",
    "This paper proposes an interesting perspective that BatchNorm may introduce the adversarial vulnerability, and probes why BatchNorm performs like that (the tracking part in BatchNorm). In experiment, the robustness of the networks increases by 20% when removing the tracking part, but the test accuracy on the clean images drops a lot. Afterwards, the authors propose RobustNorm, which performs better than BatchNorm for both natural and adversarial scenarios.",
    "This paper proposes two regularization methods for learning on noisily labeled data: the first penalizes the distance w.r.t. Euclidean norm from an initial point and the second uses an additional auxiliary variable for each example to learn a noise. In the theoretical part, the paper shows that an original clean dataset can be learned from a noisily labeled dataset based on NTK-theory. Finally, the effectiveness of proposed regularization methods is well verified empirically for 2-layer NN, CNN, and ResNet on image classification tasks (MNIST, CIFAR-10).",
    "This paper studies the topic of learning with noisy labels, in particular, classification problem where the labels are randomly flipped with some probability. The main technical contributions of this paper are two folds: 1) proof of generalization bounds for kernel ridge regression solutions that depends on the clean labels only. 2) two regularization techniques that are shown to be equivalent to the kernel ridge regression when the neural networks approach the neural tangent kernel regime.",
    "In this paper, based on the effectiveness of early stopping in the training of noisily labeled samples, the authors proposed two intuitive (and novel) regularization methods: (1) regularizing using distance to initialization (2) adding an auxiliary variable b_i for every input x_i during training. In terms of theory, the authors showed that in the NTK regime, both regularization methods trained with gradient descent are equivalent to kernel ridge regression.  Moreover, the authors also provided a generalization bound of the solution on the clean data distribution when trained with noisy label, which was not addressed in previous research.",
    "This paper shows that there is a one-to-one correspondence between pixel-shift based data augmentation and average pooling operations in CNN-NNGP/NTK based ridge regression. Interestingly, the authors show that standard average pooling + flatten can lead to a better performance than simple global average pooling. This paper further shows that using the data pre-processing step proposed in (Coates et al., 2011) can boost performance of CNN-NNGP/NTK based ridge regression by ~7% which allowed the authors to achieve classification accuracy in high 80s which is AFAIK SOTA on CIFAR-10 when not using learned representations.",
    "This paper considers architectures that do not involve learning (up to the classification layer) and tries to improve their accuracies. They're based on CNTK and CNN-GP works. This is purely a numerical paper and its contribution is to show that despite being not learned, the obtained representations are competitive with supervised neural networks.",
    "This paper builds on recent developments of CNN-GP and CNTKs in multiple fronts obtaining significant performance boost on CIFAR-10 dataset (and some mild boost on Fashion-MNIST). One way is by usage of Local Average Pooling (LAP) layers which interpolates between Global Average Pooling (GAP) and no Pooling layer. The authors also introduce flip data augmentation by doubling the dataset. With the help of additional feature extractor, this paper obtained 89% classification accuracy on CIFAR-10 which is the best among methods not using trained neural networks. ",
    "This paper proposes Search with Amortized Value Estimates (SAVE), which combines Q-learning and Monte-Carlo Tree Search (MCTS). SAVE makes use of the estimated Q-values obtained by MCTS at the root node (Q_MCTS), rather than using only the resulting action or counts to learn a policy. It trains the amortized value network Q_theta via the linear combination of Q-learning loss and the cross-entropy loss between the softmax(Q_MCTS) and softmax(Q_theta). Then, SAVE incorporates the learned Q-function into MCTS by using it for the initial estimate for Q at each node and for the leaf node evaluation by V(s) = max_a Q_theta(s,a). Experimental results show that SAVE outperforms the baseline algorithms when the search budget is limited.",
    "This paper proposes SAVE that combines Q learning with MCTS. In particular, the estimated Q values are used as a prior in the selection and backup phase of MCTS, while the Q values estimated during MCTS are later used, together with the real experience, to train the Q function. The authors made several modifications to \u2018standard\u2019 setting in both Q learning and MCTS. Experimental results are provided to show that SAVE outperforms generic UCT, PUCT, and Q learning.",
    "This paper proposes an approach, named SAVE, which combines model-free RL (e.g. Q-learning) with model-based search (e.g. MCTS). SAVE includes the value estimates obtained for all actions available in the root node in MCTS in the loss function that is used to train a value function. This is in contrast to closely-related approaches like Expert Iteration (as in AlphaZero etc.), which use the visit counts at the root node as a training signal, but discard the value estimates resulting from the search. ",
    "The paper considers the problem of performing stereoscopic view synthesis (i.e., generating a new view seen from a different camera position) at an arbitrary position along the X-axis from a single input image only. This is an important problem as it enables 3D visualization of a 2D input scene. The paper focuses on the particular problem of generating a stereoscopic view from a single image (i.e., a right and left view from a center image). ",
    "The submission proposes a method to perform stereoscopic view synthesis. The method consists of a neural network model that estimates a novel viewpoint either to the left or to the right of a given image. The two key insights of the proposed method is 1) to learn the weights of a t-shaped kernel when performing novel view synthesis, and 2) to estimate and use adaptive dilations on those kernels.",
    "This paper proposes a deep learning method to produce \"pans\" of an input image. That is, simulated images of the scene from translated viewpoints. Unlike some previous work that considers only a fixed baseline (such as the 2nd view of a stereo camera), this approach allows generation of a range of views. A specially crafted convolutional architecture is shown to be well-suited to this problem. Results demonstrate visually pleasing image generation and low metric errors on several datasets.",
    "The paper develops an information-theoretic training scheme for Variational Auto-Encoders (VAEs). This scheme is tailored for addressing the well-known disentanglement problem of VAEs where an over-capacity encoder sometimes manages to both maximize data fit and shrink the KL divergence between the approximate posterior and prior to zero. Consequently, the latent representations of the observations become independent, making them unusable for any downstream task.",
    "Overview: This paper describes the Variational InfoMax AutoEncoder (VIMAE), which is based on the learning principle of the Capacity Constrained InfoMax. The core idea behind VIMAE is that the encoding information is not bounded while network capacity is. The issue that VIMAE can handle, and where VAE fails, is that representations are not informative of input data, due to the information bottleneck idea that VAE is built upon. The authors describe InfoVAE and \u03b2-VAE, which both attempt to solve this problem. The theory behind VIMAE is then described and tested against VAE and \u03b2-VAE, in their abilities to evaluate the entropy of Z, in reconstruction and generative performance, and in robustness to noise and generalization. ",
    "I went over this work multiple times and had a really hard time judging the novelty of this work. The paper seems to be a summary of existing work reinterpreting variational autoencoding objectives from an information theoretic standpoint. In particular, the paper seems to follow the same analysis as in Wasserstein Autoencoders (Tolstikhin et al., 2017) and InfoVAE (Zhao et al., 2017).  It is unfair to say that the objectives were \"derived independently\" since these works are from a couple of years ago. ",
    "This paper proposed an attributed network embedding method by leveraging a node\u2019s local distribution over attributes. The neighborhood attribute distribution of a node is considered in both a pooled and a multi-scale way. The multi-scale embedding approach considers the neighborhood nodes with different distance to the interested node distinctly, providing more flexibilities to the model. Then, the paper proved theoretically that the proposed embedding methods, both the pooled and multi-scale versions, can be equivalently written the factorization of a node-feature pointwise mutual information matrix.",
    "This manuscript introduces embedding algorithms that consider attribute distribution. To address the multi-scale attribute information, the multi-scale version of AE is derived (MUSAE). Then the proposed algorithms are proven theoretically to implicitly factorize the PMI matrix, which enhance their interpretability. The experiments are conducted on various scenarios including node classification, transfer learning, regression and link prediction. showing the quality of learned embeddings. The results show the benefits of multi-scaling and several conclusions are drawn.",
    "This paper introduces Skip-gram style embedding algorithms that consider attribute distributions over local neighborhoods. Algorithm 1 and 2 shows that in fact they propagate randomly selected node features to neighbors. The reviewer doesn\u2019t think this random-walk way for selecting node feature is appropriate.  Node features describe node content. The features of neighboring nodes may complement each other. However, there is no benefit to select random features and then propagate, given that there already many approaches smartly combining node content in neighborhood. ",
    "This paper studies the phase transition problem in the information bottleneck (IB) objective and derives a formula for IB phase transitions. Based on the theory developed in the paper, an algorithm is developed to find phase transition points. The interesting observation is phase transition can correspond to learning new class and this paper conjectures in IB for classification, the number of phase transitions is at most C-1, C the number of classes.  This observation deserves to be further explored and may be a key to a deeper understanding of neural networks. ",
    "This paper contributes theoretically to the information bottleneck (IB) principle. In particular, the author(s) provided theoretical reasoning on the phase transition phenomenon: when the beta parameter of IB varies, the generalization performance changes in a stepwise manner rather than continuously. The core result is given by theorem 1: the phase transition betas necessarily satisfy an equation, where the LHS is expressed in terms of an optimal perturbation of the encoding function X->Z.",
    "In this paper, the authors studied the phase transition in the information bottleneck, which is defined as the point where the IB loss landscape changes. The authors give a theorem showing the practical condition for IB phase transitions which is related to Fisher information. Then an algorithm finding IB phase transitions are proposed and applied to MNIST and CIFAR10 dataset.",
    "This paper proposes a novel advantage estimate for reinforcement learning based on estimating the extent to which past actions impact the current state. More precisely, the authors train a classifier to predict the action taken k-steps ago from the state at time t, the state at t-k and the time gap k. The idea is that when it is not possible to accurately predict the action, the action choice had no impact on the current state, and thus should not be assigned credit for the current reward, they refer to this as the \"independence property\" between current action and future states. Based on this idea, the authors introduce a \"dependency factor\", using the ratio P(s_{t+k},a_{t+k}|s_t,a_t)/P(s_{t+k},a_{t+k}|s_t). They later show that this can be reworked using Bayes theorem into a ratio of the form P(a_t|s_t,s_{t+k})/\\pi(a_t|s_t) which is more convenient to estimate. The authors show mathematically that, when the dependency factor is computed with the true probabilities and use to weight each reward in a trajectory, the result is an unbiased advantage estimator. Importantly the expectation, in this case, is taken over trajectories sampled according to the policy pi conditioned only on S_t. This is distinct from the Monte-Carlo estimator which is based only on samples in which A_t, the action whose advantage is being estimated, was selected.",
    "This paper proposes a new advantage estimator in reinforcement learning based on importance sampling. This form allows for a significantly lower-variance estimator for situations where the current action \"stops mattering\" to the future state. A control variate, as in Grathwohl et al., is used to combine the importance sampling estimator with the \"standard\" estimator in a way that is always unbiased and attempts to minimize the overall variance.",
    "This paper tries to control the variance of advantage function by utilizing the independence property between current action and future states. The practical approach they are using is to learn a dependency model of reward function as a control variate to lower the variance. Using the control variate technique they derive a (maybe complicated) algorithm to update the policy by PPO. Empirical results seems competitive.",
    "  This paper provides a new doubly robust estimator for off-policy policy evaluation, based on the new infinite horizon technique (i.e. using an estimate of the state density ratio as opposed to long products of action importance weights). They show the doubly robust estimator's bias is dependent on a product of the error of the value function estimate and stationary distribution ratio estimate, which provides improvements over the initial infinite horizon estimator. They also provide some nice discussion of the relation of their method and Lagrangian duality, which was quite interesting and insightful. Finally, the paper shows the usual empirical comparisons.",
    "This paper provides an approach for reducing bias in long horizon off-policy evaluation (OPE) problems, extending recent work from Liu et al., 2018 that estimates the ratio of the stationary state distributions in off-policy evaluation for reducing variance. The paper provides a doubly robust method for reducing bias, since it requires separately estimating a value function. The key idea of the paper is to provide low variance, low bias OPE since their approach relies on accurately estimating the state distribution ratio and also the estimation of the value function. ",
    "This paper proposes a new algorithm for the off-policy evaluation problem in reinforcement learning. It combines the value function learning method and the stationary distribution ratio estimators. The proposed method achieves double robustness, which means the proposed estimator is consistent as long as the value function or ratio estimator is consistent. Empirical results on some control domains are presented to verify the effectiveness of the algorithm.",
    "Authors propose a new method for adaptation in a few-shot learning setting. Their method comprises two different steps; first they propose a new metric-softmax loss, which aims at improving the transferability of features pre-trained on base data to novel data. They achieve this via redefining the probability score calculating function, which in practice means they replace the exponent term found in the softmax loss with a Gaussian kernel-based radial basis function. This first step improves the feature learning process at large scale but does not solve the problems found when trying to fit arbitrary novel classes. At this point comes step two, where a fast task adaptation process is proposed, i.e. Task-Adaptive Transformation based on affine transformation. This method converges fast and is learnt from the support set, vs step 1 which is trained on the training/base set. Post-training the affine transformation is applied to both support and query image sets.",
    "This paper deals with few-shot learning from a metric-learning perspective. The authors propose replacing the softmax loss, i.e. softmax + cross-entropy loss, with a so-called \"metric-softmax\" loss which imitates a Guassian kernel RBF over class templates/weights. This loss is used in both stages of training on base and on novel classes and the authors argue that it helps learning more discriminative feature while preserving consistency between train and test time.",
    "This paper develops a new few-shot image classification algorithm. It has two main contributions. The first one is to use a metric-softmax loss used to train on the meta-training dataset without episodic updates. The second is that the features learnt thereby are further modified using a linear transformation to fit the few-shot training data and the metric soft-max loss is again used for classifying the query samples. The authors provide experimental results for 5-way-1-shot and 5-way-5-shot testing on mini-Imagenet and CUB-200-2011 datasets.",
    "The authors aim at improving the accuracy of numerical solvers (e.g. for simulations of partial differential equations) by training a neural network on simulated reference data. The neural network is used to correct the numerical solver. For different tasks they set up an approximation scheme via minimizing a square loss plus a task specific regularization (e.g. volume preservation in the Navier-Stokes equation example). This is then trained in a supervised manner. They also explore an unsupervised version by back-progagating through a differentiable numberical solver.",
    "The paper proposes learning NN to correct for inaccuracies in numerical solvers of PDEs, with experimental focus on fluid flow simulation. It lists two approaches: (1) compute correction in high resolution simulation from reference states, convert to low-resolution correction, and train NN to predict low-res correction (optionally with temporal regularization, and (2) directly simulate forward using correction prediction and differentiable PDE solver and optimize to match the given reference states. It shows empirical results on better approximating fluid flow simulation. ",
    "Numerical solvers for partial differential equations take a lot of time to get high resolution results since they have to explore high dimensional grid in function domain.\u00a0Thus, it is important to interpolate between grids to get high resolution results.\u00a0In this paper, the authors propose the model that assists PDE solver by correcting residuals in a data-driven way.\u00a0Specifically, they try to approximate NN to correction function in supervised and unsupervised manners.\u00a0They also propose a temporal regularization method that smooths behavior of fluid between times.\u00a0As a result, proposed method can generate high resolution results in efficient way with smoke rising simulation dataset.",
    "This work contributes to introducing a problem called Online Continual Compression. This problem requires to avoid catastrophic forgetting and learn in an online way. Generative methods should be one of the popular ways to do continual learning. This work\u2019s model can be categorized into this clue since it also aims to save samples from old tasks by learning a generative model. In this way, the generator plays a similar role Experience Replay (ER) (here is called Generative Replay). The main core of this work should be the stacked quantization modules (SQM) which can be regarded as a hierarchical variant of the VQ-VAE model. In their SQM, hidden encodings z_q^i will be encoded and its input is z_q^{i-1} which is from previous layer. ",
    "This paper presented a Stacked Quantization Modules (SQM) for the problem of Online Continual Compression, based on the VQ-VAE framework by van den Oord et al. (2017). Experiments were conducted on online continual image classification benchmarks to show the effectiveness of the proposed SQM. In general, the novelty of the paper is a little bit limited and the writing of the paper is not very easy to follow.",
    "The study tackled the problem of limited storage for ever-growing data for a long-term learning scenario. The authors proposed to stack Quantization Modules while separating them during training to obtain an online compression system that has multiple resolutions, different memory horizons, and reduced catastrophic forgetting. They also proposed a modified reservoir sampling to accommodate this architecture. ",
    "The paper addresses the problem of multi-label prediction.  It proposes a method that uses a co-embedding of instances and labels into a joint embedding space in a way that related instances and labels fall close by and unrelated ones fall far away.  For this purpose, embeddings from input space and label space to a common space are learned from training data. At the prediction time, KNN to the embedding of the test instance in the co-embedding space is used to predict relevant labels.",
    "This paper aims to solve multi-label problems via learning a share embedding space for instances and its label sets. Specifically, the author considers deep neural networks F(x) as an encoder for the instance (either raw input or features) and a shallow MLPs G(y) as an encoder for the label outputs. In the training stage, the instance embedding and its label embedding are forced to be close. An additional constraint is instances with different labels should be far from each other. After training, the inference can be done in the embedding space by looking up the labels of the query\u2019s kNN instances. ",
    "This paper presents a metric learning approach for the multi-label classification problem. It basically maps the input features and the output labels into the same space and then uses k-NN to find the closest labels for each inputs. During training, it minimizes the squared Euclidean distance between the input embedding and label embedding. In the experiments, some image datasets and text datasets are used to compare with several multi-label learning algorithms. ",
    "The authors introduce a theoretical model for delayed gradients in asynchronous training. It is a very nice model and solving the corresponding differential equation allows to study its stability. Authors derive stability bounds for pure SGD (learning rate needs to decrease with delay) and for SGD with momentum, where they introduce a nice momentum formulation that improves stability. These are nice insights and good results and they are validated by experiments. More experiments and practical analysis would be welcome though. Some example questions: would introducing some sychronization help? Is the lower learning rate hurting training speed when measures as wall-clock time to accuracy?",
    "This paper studies how asynchrony affects model training by investigating dynamic stability of minimum points that A-SGD can access. They point out that not all local minimum points are accessible, and asynchrony can affect which minimum points can be accessed, and thus helps to explain why models trained by A-SGD have higher generalization gap. The authors also propose shifted-momentum that utilize momentum for asynchronous training.",
    "The authors model A-SGD as a dynamical system, where parameters are updated with delayed gradients. The authors analyze the stability of this system, and they first derive that the learning rate must scale linearly with the inverse of the delay around a minimum to remain stable. Using a similar analysis they show that the standard way of incorporating momentum into A-SGD requires small learning rates for high momentum values, and they propose \"shifted momentum,\" which allows for stability under higher momentum values. Experimentally, the authors show that around minima the learning rate needed to retain stability scales linearly with the inverse of the delay, that there appears to be an analogous threshold when training models from scratch, that shifted momentum allows for higher momentum values, and finally that on several datasets A-SGD with an appropriate learning rate is able to generalize at least as well as large batch synchronous training.",
    "This paper presents a new model-based reinforcement learning method, termed hindsight modelling. The method works by training a value function which, in addition to depending on information available at the present time is conditioned on some learned embedding of a partial future trajectory. A model is then trained to predict the learned embedding based on information available at the current time-step. This predicted value is fed in place of the actual embedding to the same value model, to generate a value prediction for the current time-step. So instead of just learning a value function based on future returns, the method uses a two-step process of learning an embedding of value relevant information from the future and then learns to predict that embedding.",
    "The paper proposes a way to learn better representation for RL by employing a hindsight model-based approach. The reasoning is that during training, we can observe the future trajectory and use features from it to better predict past values/returns. However to make this practical, the proposed approach fits an approximator to predict these features of the future trajectory from the current state and then subsequently, use them to predict the value. The authors claim that this extra information can be used to learn a better representation in some problems and lead to faster learning of good policies (or optimal value functions)",
    "Value-Driven Hindsight Modelling proposes a method to improve value function learning. The paper introduces the hindsight value function which estimates the expected return at a state conditioned on the future trajectory of the agent. How use this hindsight value function is not obvious, since an agent does not have access to the future states needed in order to take actions (for Q-Learning) and the hindsight value function is a biased gradient estimator for training policy gradient methods. ",
    "In this paper, the authors studied the adversarial attack problem for graph classification problem with graph convolutional networks. After observing that traditional attack by adding or deleting edges can change graph eigenvalues, the author proposed to attack by adding rewiring operation which make less effects. Rewiring does not change the graph edge number and the average degree. Further, the authors propose an RL based learning method to learn the policy of doing rewiring operation. Experiments show that the proposed method can make more successful attack on social network data than baselines and previous methods.",
    "This paper proposes a new type of adversarial attack setting for graphs, namely graph rewiring operation, which deletes an edge in the graph and adds a new edge between one node of the first edge and one of its 2-hop neighbors. This new attack is proposed to make the perturbations unnoticeable compared with adding or deleting arbitrary edges. To solve this problem, a reinforcement learning based approach is proposed to learn the attack strategy in the black-box manner. Experiments conducted on several datasets prove the effectiveness of the proposed with over an existing method and baseline methods.",
    "This paper proposes the ReWatt method to attack graph classification models by making unnoticeable perturbations on graph. Reinforcement learning was leveraged to find a rewiring operation a = (v1; v2; v3) at each step, which is a set of 3 nodes. In the first step, an existing edge (v1, v2) in the original graph is selected and removed. Then another node v3 that is 2-hop away from v1 and not 1-hop away is selected.  Finally (v3, v1) is connected as a new edge. Some analysis shows that the rewiring operation tends to make smaller changes to the eigenvalues of the graph's Laplacian matrix compared with simply adding and deleting edges, making it difficult to detect the attacks.",
    "The authors address the problem of efficiently employing the SURE estimator as a network training regularizer. They show that for CNN autoencoders this can be efficiently computed. Their other contribution is a bagging/boosting technique which is proved to avoid trivial solutions. The proposed architecture, motivated by the theoretical statements, is shown to outperform classic and 2019 state of the art image reconstruction algorithms in MRI and EDX.",
    "The authors consider an encoder decoder setup for linear deblurring problem and propose efficient boosting estimators. Specifically, they use the Stein's unbiased risk estimator for the problem when the noise is gaussian. In the case when the encoder and decoder is represented by a convolutional neural network with RELU activations, they show how they can exploit the recent theoretical results that show the kernel type results to make their procedure efficient. They then propose using a set of models (boosting) and prove that the boosted loss function lower bounds the \"nonboosted\" loss function.",
    "This paper proposed a piecewise linear close form expression for the Stein\u2019s unbiased risk estimator and use this formulation to construct a new Encoder-decoder convolutional neural network. The author claimed that this closely related to bagging. Improved experimental results on two inverse problems are presented. Overall, the experiment results are encouraging but the paper need clarification on a few points.",
    "This paper proposed to improve existing meta learning algorithms in the presence of task imbalance, class imbalance, and out-of-distribution tasks. Starting from the model-agnostic meta-learning (MAML) algorithm (Finn et al. 2017), to tackle task imbalance, where the number of training examples of varies across different tasks, a task-dependent learning rate decaying factor was learned to be large for large tasks and small for small tasks. In this way, the small task can benefit more from the meta-knowledge and the large task can benefit more from task-specific training. To tackle class imbalance, a class-specific scaling factor was applied to the class-specific gradient. The scaling factor was large for small class and small for large class so that different classes can be treated equally. To tackle the out-of-distribution tasks, a task-dependent variables was learned to emphasize meta-knowledge for the test task similar to training tasks. Additional model parameters are learned through variational inference. Experimental results on benchmark datasets demonstrate the proposed approach outperformed its competing alternatives. Analysis of each component confirm they work as expected.",
    "The paper proposes a Bayesian approach for meta learning in settings were the tasks might be OOD or have imbalanced class distribution. The proposed approach has 3 task-specific balancing variables with a prior and an inference network. Using an amortized inference scheme, the model unifies the meta-learning objective loss with the lower bound of probabilistic model marginal likelihood. ",
    "This paper introduces a mechanism for gradient-based meta-learning models for few-shot classification to be able to adapt to diverse tasks that are imbalanced and heterogeneous. In particular, each encountered task may have varying numbers of shots (task imbalance) and even within each task, different classes may have different numbers of shots (class imbalance). Further, test tasks might come from a different distribution than the training tasks. They propose to handle this scenario by introducing three new types of variables which control different facets of the degree and type of task adaptation, allowing to decide how much to reuse meta-learned knowledge versus new knowledge acquired from the training set of the given task.",
    "The authors propose SQUIL, an off-policy imitation learning (IL) algorithm which attempts to overcome the classic drift problems of behavioral cloning (BC). The idea is to reduce IL to a standard RL problem with a reward that incentivizes the agent to take expert actions in states observed in the demonstrations. The algorithm is tested on both image-based tasks (Atari) and continuous control tasks (Mujoco) and shown effective against GAIL and a simple supervised BC approach.",
    "This paper proposes an imitation learning approach via reinforcement learning. The imitation learning problem is transformed into an RL problem with a reward of +1 for matching an expert's action in a state and a reward of 0 for failing to do so. This encourages the agent to return to \"known\" states from out-of-distribution states and alleviates the problem of compounding errors. The authors derive an interpretation of their approach as regularized behavior cloning. Furthermore, they empirically evaluate their approach on a set of imitation learning problems, showing strong performance. The authors also stress the easy implementability of their approach within standard RL methods.",
    "This paper proposes a simple method for imitation learning that is competitive with GAIL.  The approach, Soft Q Imitation Learning (SQIL), utilizes Soft Q Learning, and defines high rewards as faithfully following the demonstrations and low rewards as deviating from them.  Because SQIL is off-policy, it can utilize replay buffers to accelerate sample efficiency.  One can also interpret SQIL as a regularized version of behavioral cloning.",
    "This paper proposed a deep network for point cloud sequence super-resolution/upsampling. Building on the basis of pointNet and PU-net, the main contribution of the paper is identifying the problem of temporal incoherence in the process of upsampling a point cloud shape representation as well as a training loss to encourage temporal coherence. In the cases showed in the paper, the proposed method seems effective comparing to previous work which is not done on sequence data. My main concern about the work is that the experimental evaluation is limited.",
    "The paper addresses the task of learning temporally stable features for point clouds with an application to upsampling point clouds. Learning point-based descriptors has been a major topic of research in the recent vision and graphics meetings, where approaches have been proposed focusing semantic labeling, geometry-oriented tasks (e.g. normal estimation), and point-based graphics. However, as the paper states, and to the best of my knowledge, no methods have been proposed to learn features in fourth dimension in a temporally stable way. Thus, the very topic of research is significantly novel and promising. ",
    "The paper tries to learn temporally stable representations for point-based data sets and focus on varying size and dynamic point sets, and demonstrate its usefulness in the context of super-resolution. To deal with a difficult target that dynamically moves and deforms over time with variable input and output size, they take a novel temporal loss function for temporally coherent point set generation and siamese network setup for temporal loss calculation. Their novel temporal loss is based on EMD to minimize differences between an estimated point cloud and a desired super-resolution point cloud. The discussion and evolution on multiple loss functions are mostly well done. Except spatial loss is considered, taking the ground truth acceleration and estimated velocity into account is beneficial to this task. Their main contribution is taking permutation invariant loss terms and a siamese training setup and generator architecture, enabling improved output variance by allowing for dynamic adjustments of the output size, and identifying a specialized form of mode collapse for temporal point networks. ",
    "The authors consider the alignment problem for multiple datasets with side information via entropic optimal transport (Sinkhorn). The authors formulate it as a transport cost learning in optimal transport framework with constraints giving by side information. Empirically, the authors illustrated the effectiveness of the proposed approach over state-of-the-art on several applications (e.g. single-cell RNA-seq, marriage-matching, MNIST with its perturbed one. ",
    "This paper proposes a new way to learn the optimal transport (OT) cost between two datasets that can utilize subset correspondence information. The main idea is to use a neural network to define a transport cost between two examples instead of using the popular Euclidean distance and have a L2 regularizer that encourages the resulting transport plan to be small if two examples belong to the same subset. The results on synthetic datasets (2D, MNIST image) and real-world datasets (RNA sequence) show that the learned transport cost outperforms the Euclidean distance and Procrustes-based OT. ",
    "The paper presents a gradient-based method for learning the cost function for optimal transport, applied to dataset alignment. The algorithm is based on the Sinkhorn-Knopp iterative procedure for approximating the optimal transport plan. The current paper proves that the Sinkhorn transport plan with a parameterized cost function is infinitely differentiable. The cost function can thus be optimized by unrolling the Sinkhorn iteration for a fixed number of steps and then backpropagating through the iterative updates. The cost function is optimized via a loss function derived from side information, specifically subsets of the two datasets to be aligned that contain elements that should be matched in the optimal transport plan. Experiments on a variety of synthetic and real datasets show that the proposed method is often better than, and almost always competitive with, other modern approaches.",
    "In the article, the authors solve the problem of anomaly detection using a fully unsupervised approach. They try to deal with the main challenge of anomaly detection: a lack of certainty on what defines normal data and anomaly one. For this purpose, the authors iteratively use: 1) autoencoders to learn the representation of the data; 2) applying in the latent space clustering to get a new training set and retrain autoencoders. The experimental results show that the author\u2019s method performed better results than such a baseline model as one-class SVM and one-class NN. ",
    "In this paper the authors propose a framework for anomaly detection. The method is based on autoencoders and reconstruction error, but instead of training the autoencoder using all the data-points, the method iteratively uses some form of clustering to determine the points which presumably belong to the normal set, and uses them for training the autoencoder. This helps make the method robust when the portion of anomalous data-points is high.",
    "The paper proposed an unsupervised anomaly detection method for the scenarios where the training data not only includes normal data but also a lot of anomaly data. The basic idea of this paper is to iteratively refine the normal data subset, selected from the whole training data set. Specifically, the paper first train an auto-encoder (AE) and determine which are the normal data samples according to the reconstruction errors. Then, using the normal data to retrain the AE again, and re-select the normal samples. Repeat the above two steps until convergence. ",
    "This paper introduces a constrained policy optimization algorithm by introducing a two-step optimization process, where policies that do not satisfy the constraint can be projected back into the constraint set. The proposed PCPO algorithm is theoretically analyzed to provide an upper bound on the constraint violation. The proposed constrained policy optimization algorithm is shown to be useful on a range of control tasks, satisfying constraints or avoiding constraint violation significantly better than the compared baselines.\u000b\u000b",
    "This paper proposes a new algorithm - Projection based Constrained Policy Optimization, that is able to learn policies with constraints, i.e., for CMDPs. The algorithm consists of two stages: first an unconstrained update for maximizing reward, and the second step for projecting the policy back to the constraint set.  The authors provide analysis in terms of bounds for reward improvement and constraint violation.  The authors characterize the convergence with two projection metrics: KL divergence and L2 norm.  The new algorithm is tested on four control tasks: two mujoco environments with safety constraints, and two traffic management tasks, where it outperforms the CPO and lagrangian based approaches.",
    "The paper proposes a technique to handle a certain type of constraints involved in Markov Decision Processes (MDP). The problem is well-motivated, and according to the authors, there is not much relevant work. The authors compare with the competing methods that they think are most appropriate. The numerical experiments seem to show superiority of their method in most of the cases. The proposed method has 4 main variants: (1) define projection in terms of Euclidean distance or (2) KL-divergence, and (a) solve the projection problem exactly (usually intractable) or (b) solve a Taylor-expanded variant (so there are variants 1a,1b,2a,2b).",
    "In this paper, the authors study the word embedding, with a particular emphasize on the word2vec or similar strategies. To this end, the authors consider the matrix factorization framework, previously introduced in the literature, and also study the influence of an hyperparameter denoted by alpha. Roughly speaking, there are two major parts in the paper. On one hand, it explains the reasons why the word embedding schemas provide nice properties, by defining the embedding as a low rank transformation mechanism. On the other hand, they propose to choose optimally the hyperparameter alpha in order to ameliorate word embedding by better preserving the distance structure. Conducted experiments are convincing.",
    "This paper explores the role of the implicit alpha parameter when learning word embeddings. More concretely, word embeddings work by either implicitly or explicitly factorizing a co-occurrence matrix, and the underlying parameter alpha controls how the singular values are weighted between the word and the context vectors. The authors provide theoretical insights on the role of alpha in relation with the original co-occurrence matrix, and propose a new method to find its optimal value.",
    "This paper provides a closer look at the well-studied problem of learning word embeddings. In particular, it looks at the set of embedding methods that explicitly or implicitly perform a matrix factorization and tries to understand why the word embeddings exhibit analogy structure and why words that are semantically similar get embedded close together. The mechanism it comes up with has to do with the alpha parameter that represents the powers of singular values of the matrix that was factorized to estimate the embeddings. It turns out that alpha controls the distance between the words in the embedding transformation process. Next the paper discusses how to choose/estimate alpha to get better quality embeddings. Results are shown on several word similarity tasks. ",
    "The paper considers random projection forests for similarity measurements (which have been proposed earlier) and proposes to accelerate them by reusing projections. Tree levels up-to level-X use distinct random transformations, and subsequent levels cycle through existing projections (X of them). As this kind of reuse reduces the quality of trees, the paper proposes to (greatly) increase the number of trees in the forest. The paper also introduces a sensible \"beta-similarity\" which is based on average tree-distance between leafs into which the two data-points fall, rather than fraction of trees in which they fall into the same leaf-node. ",
    "This paper proposes the similarity measure called 'beta-similarity' generated by an ensemble of Random projection trees (RP trees) by Dasgupta & Freund (2008). To reduce the computational costs for building many RP trees, the paper develops an efficient approximate version called X-Projection trees by first generating X independent random projection directions, and then by sharing them at layers in turns. X-Forest is a set of X-Projection trees with X different random projections, and the proposed 'beta similarity' between x and y is defined by distances between a leaf region having x and one having y in PR trees. Experimental evaluations demonstrated that the use of beta similarity improves the clustering accuracy using it within three types of methods (kernel k-means, DBSCAN, Spectral clustering). ",
    "This paper proposes a new method for measuring pairwise similarity between data points. The idea is to define the similarity between two data points to be the probability (over the randomness in constructing the trees) that they are close in an RP tree. More concretely, the proposed method constructs a collection of RP trees (albeit with some modifications), and takes the similarity to be the average over different RP trees of a strictly decreasing function of the distance between the leaf nodes containing the data points in each RP tree. The key modification to the RP tree is to limit the number of projection vectors used in an RP tree and re-use previous projection vectors. ",
    "This paper proposes a new combination of Markov chain Monte Carlo (MCMC) and variational inference (VI) for improving approximate inference. The main contribution is the optimization objective that allows improving the quality of samples obtained from the combination of VI and MCMC. Specifically, the authors minimize the \"approximate\" version of the Kullback-Leibler (KL) divergence between the distribution of MCMC + VI and the true distribution. The authors validate the effectiveness of their formulation through experiments on 6 synthetic benchmarks and generative modeling of MNIST (experiments on Bayesian neural networks are also provided in the appendix). ",
    "The presented method is very useful to deep learning in the era of uncertainty modelling, which requires the use of Bayesian inference arguments. It's a valuable improvement upon variational inference, it's novel, and the derivations are correct. The presentation is elaborate and covers all expected aspects. The literature review is up to date. ",
    "The paper presents a new hybrid method to unify MCMC and VI. The key idea is to interpret a \ufb01nite-length MCMC/HMC chain as a parametric procedure, whose parameters can be optimized via a VI-motivated objective. Specifically, the authors propose to modify the well-known ELBO (which is now non-trivial due to the intractable entropy) to form a new constrained and tractable objective. The presented techniques are tested on synthetic datasets and with the experiments of a VAE on MNIST. ",
    "This paper introduces MissDeepCausal method to address the problem of treatment effect estimation with incomplete covariates matrix (missing values at random -- MAR). It makes use of Variational AutoEncoders (VAE) to learn the latent confounders from incomplete covariates. This also helps encoding complex non-linear relationships in the data, a capability that is missing in the work of Kallus et al. (2018) -- the work which this paper extends. They employ the Missing data Importance Weight AutoEncoder (MIWAE) approach (Mattei & Frellsen, 2019) to approximate the posterior of their latent factors Z given the observed incomplete covariates X*. The main contributions of this work are presented in sections 3.2 and 3.3, where they use the approximated posterior derived from MIWAE to sample Z to be used for estimating outcomes and finally calculating the Average Treatment Effect (ATE). This is done according to the doubly robust estimator developed for data with incomplete covariates (Mayer et al., 2019b). ",
    "       The paper considers average treatment effect estimation treatment T and an unobserved confounder Z causes the outcome Y with an added constraint that the observed X is a noisy measurement of the underlying Z and some of the entries of observed X are missing at random (MAR). Previous work (Kallus et al. 2018) on similar settings assumed a low rank model connecting Z and X along with some entries missing at random which we do not observe. Further, Y (outcome) is related to the treatment and Z with a linear model. They actually show that matrix factorization techniques with these assumptions form an unbiased estimator for the Average Treatment Effect. There is prior work on doubly robust estimators under ignorability assumptions.",
    "This contribution considers deep latent-factor models for causal inference -inferring the effect of a treatment- in the presence of missing values. The core challenge is that of confounders not directly observed, and accessible only via noisy proxys, in particular in the missingness. The contributed method relies on using the latent-factor model for multiple imputation in doubly-robust causal treatment effect estimators. As a consequence, it requires the missing at random assumption to control for the impact of imputation. Given that the confounders are not directly assumed, a first approach estimates their effect via an estimate of P(Z|X*)  (probability of confounder given observed data), which is then plugged in the doubly robust estimator in a multiple imputation strategy. A second approach uses heuristically the estimated latent confounders as regressors of non interest in a linear-regression model. The approaches are empirically compared to other imputation strategies used as plugins in the doubly-robust estimator. The contributed approach show marked benefits when the problem is highly non-linear.",
    "The authors propose to construct reinforcement learning policies with very few parameters. For this purpose, they force a feed-forward neural network to share most of its weights, reducing the total number of different weights to at most 23 and therefore compress the network. Instead of manually encoding which weights are shared, the authors propose to use a reinforcement learning method to learn this mapping. The values of all parameters are learned with a gradient-based method.",
    "This paper focuses on neural architecture search for constructing compact RL policies. It combines ideas from the popular ENAS and ES methods for optimisation. Recent work defined a family of compact policies by imposing a fixed Toeplitz structure. This paper introduces the so-called \u201cchromatic network\u201d architecture, which partitions weights of the RL network into tied sub-groups. The partitioning is searched with ENAS and shared weights are updated via ES. Experiments on continuous control benchmarks show that good performance can be obtained using a very small number of parameters. Favourable reward-compression outcomes can be achieved compared to some baseline alternatives.",
    "This paper compresses policy networks using approaches inspired by neural architecture search. The main idea is to have a fixed size weight matrix, but learn how to share weights, so that the resulting network can be compressed by storing only unique weights values. Both the partitioning and weights are trained simultaneously, inspired by ENAS. The partitioning is modeled by an autoregressive RNN and trained via REINFORCE. The weights are modeled by a single set of weights (as opposed to a distribution) which is then updated by using a gradient approximation based on ES. The experiments carried out include comparing to existing works on policy network compression, ablating against random partitioning, as well as a few experiments meant to increase understanding of the learned partitions.",
    "The authors design a learnable time-series pre-processing, which they refer to as a learnable group transform (LGT). This is a generalization of the wavelet transform, which maps a time-series signal onto the affine group. In the wavelet transform, multiple scaled and shifted versions of a mother wavelet are \"inner-producted\" with a signal; the resulting coefficents are the output of the transform. In the LGT, a more flexible transform that just scaling and shifting is applied to the shape of the mother wavelet, which is piece-wise linearly stretched. This elegantly encompasses time-warping and many other wavelet-style transforms into one learnable preprocessing step.",
    "This paper defines a set of learnable basis functions and a joint learning algorithm to estimate them. It is based on the premise that the common learning approach in time-series is to first represent them in some spectral domain; thus, the main problem is to define and estimate the basis functions. However, this premise is not accurate and many learning algorithms operate just in the actual time domain (even in speech).",
    "A typical Wavelet Transform is built through the dilation and/or rotation of a mother wavelet, which can been viewed as a group action on a mother wavelet. This work proposes to extend this construction beyond the Euclidean group, and to supervisedly learn operators that will be applied on a mother wavelet. Competitive numerical performances are obtained.",
    "This paper builds a new graph convolutional network (GCN) based on hyperbolic representations of the graph nodes: all latent representations of the nodes are points on Poincare disks. The authors adapted the Hyperbolic Neural Networks by Ganea et al. (2018) into the Kipf & Welling's (2016) version of GCN. Specifically, the authors variated the right matrix multiplication in GCN with Ganea et al.'s Mobius matrix-vector multiplication (that can be regarded as a transformation between two Poincare disks). Moreover, as a non-trivial adaptation, the author defined the left matrix multiplication in GCN (that can be regarded as a weighted linear combination of several points on the same Poincare disk) with Ungar's (2010) weighted barycenter, which is from computational geometry but not the machine learning community. The resulting method is tested on a toy problem and semi-supervised node classification of commonly used datasets, showing the possibility of improvement.",
    "The authors propose using non-Euclidean spaces for GCNs. This is inspired by the recent work into non-Euclidean, and especially hyperbolic, embeddings. A few papers have recently tried to go past embeddings into building non-Euclidean models, requiring the lifting of standard operations in Euclidean space to non-Euclidean settings. This has been done in particular in hyperbolic space, but some datasets benefit from more complex spaces. The authors combine the mixed-curvature product formalism that uses products of Euclidean, hyperbolic, and spherical spaces for embeddings, but use these for GCN operations. ",
    "In this paper, the authors address representation learning in non-Euclidean spaces.  The authors are motivated by constant curvature geometries, that can  provide a useful trade-off between Euclidean representations and Riemannian manifolds, i.e. arriving at more suitable representations than possible in the Euclidean space, while not sacrifising closed-form formulae for estimating distances, gradients and so on.  "
]